{
  "sources": [
    {
      "title": "cs.CL updates on arXiv.org",
      "feedUrl": "http://export.arxiv.org/rss/cs.CL",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2101.06983",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1\">Luyu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yunyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Callan_J/0/1/0/all/0/1\">Jamie Callan</a>",
          "description": "Contrastive learning has been applied successfully to learn vector\nrepresentations of text. Previous research demonstrated that learning\nhigh-quality representations benefits from batch-wise contrastive loss with a\nlarge number of negatives. In practice, the technique of in-batch negative is\nused, where for each example in a batch, other batch examples' positives will\nbe taken as its negatives, avoiding encoding extra negatives. This, however,\nstill conditions each example's loss on all batch examples and requires fitting\nthe entire large batch into GPU memory. This paper introduces a gradient\ncaching technique that decouples backpropagation between contrastive loss and\nthe encoder, removing encoder backward pass data dependency along the batch\ndimension. As a result, gradients can be computed for one subset of the batch\nat a time, leading to almost constant memory usage.",
          "link": "http://arxiv.org/abs/2101.06983",
          "publishedOn": "2021-06-16T00:27:38.461Z",
          "wordCount": 593,
          "title": "Scaling Deep Contrastive Learning Batch Size under Memory Limited Setup. (arXiv:2101.06983v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04563",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_S/0/1/0/all/0/1\">Subhabrata Mukherjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awadallah_A/0/1/0/all/0/1\">Ahmed Hassan Awadallah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>",
          "description": "While deep and large pre-trained models are the state-of-the-art for various\nnatural language processing tasks, their huge size poses significant challenges\nfor practical uses in resource constrained settings. Recent works in knowledge\ndistillation propose task-agnostic as well as task-specific methods to compress\nthese models, with task-specific ones often yielding higher compression rate.\nIn this work, we develop a new task-agnostic distillation framework\nXtremeDistilTransformers that leverages the advantage of task-specific methods\nfor learning a small universal model that can be applied to arbitrary tasks and\nlanguages. To this end, we study the transferability of several source tasks,\naugmentation resources and model architecture for distillation. We evaluate our\nmodel performance on multiple tasks, including the General Language\nUnderstanding Evaluation (GLUE) benchmark, SQuAD question answering dataset and\na massive multi-lingual NER dataset with 41 languages. We release three\ndistilled task-agnostic checkpoints with 13MM, 22MM and 33MM parameters\nobtaining SOTA performance in several tasks.",
          "link": "http://arxiv.org/abs/2106.04563",
          "publishedOn": "2021-06-15T22:41:24.981Z",
          "wordCount": 604,
          "title": "XtremeDistilTransformers: Task Transfer for Task-agnostic Distillation. (arXiv:2106.04563v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04102",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1\">Mina Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Donahue_C/0/1/0/all/0/1\">Chris Donahue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1\">Robin Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iyabor_A/0/1/0/all/0/1\">Alexander Iyabor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1\">Percy Liang</a>",
          "description": "We release a new benchmark for lexical substitution, the task of finding\nappropriate substitutes for a target word in a context. To assist humans with\nwriting, lexical substitution systems can suggest words that humans cannot\neasily think of. However, existing benchmarks depend on human recall as the\nonly source of data, and therefore lack coverage of the substitutes that would\nbe most helpful to humans. Furthermore, annotators often provide substitutes of\nlow quality, which are not actually appropriate in the given context. We\ncollect higher-coverage and higher-quality data by framing lexical substitution\nas a classification problem, guided by the intuition that it is easier for\nhumans to judge the appropriateness of candidate substitutes than conjure them\nfrom memory. To this end, we use a context-free thesaurus to produce candidates\nand rely on human judgement to determine contextual appropriateness. Compared\nto the previous largest benchmark, our Swords benchmark has 4.1x more\nsubstitutes per target word for the same level of quality, and its substitutes\nare 1.5x more appropriate (based on human judgement) for the same number of\nsubstitutes.",
          "link": "http://arxiv.org/abs/2106.04102",
          "publishedOn": "2021-06-15T22:41:24.969Z",
          "wordCount": 638,
          "title": "Swords: A Benchmark for Lexical Substitution with Improved Data Coverage and Quality. (arXiv:2106.04102v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04476",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Damonte_M/0/1/0/all/0/1\">Marco Damonte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monti_E/0/1/0/all/0/1\">Emilio Monti</a>",
          "description": "Semantic parsers map natural language utterances to meaning representations.\nThe lack of a single standard for meaning representations led to the creation\nof a plethora of semantic parsing datasets. To unify different datasets and\ntrain a single model for them, we investigate the use of Multi-Task Learning\n(MTL) architectures. We experiment with five datasets (Geoquery, NLMaps, TOP,\nOvernight, AMR). We find that an MTL architecture that shares the entire\nnetwork across datasets yields competitive or better parsing accuracies than\nthe single-task baselines, while reducing the total number of parameters by\n68%. We further provide evidence that MTL has also better compositional\ngeneralization than single-task models. We also present a comparison of task\nsampling methods and propose a competitive alternative to widespread\nproportional sampling strategies.",
          "link": "http://arxiv.org/abs/2106.04476",
          "publishedOn": "2021-06-15T22:41:24.890Z",
          "wordCount": 592,
          "title": "One Semantic Parser to Parse Them All: Sequence to Sequence Multi-Task Learning on Semantic Parsing Datasets. (arXiv:2106.04476v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.01408",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1\">Rui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sisman_B/0/1/0/all/0/1\">Berrak Sisman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haizhou Li</a>",
          "description": "Emotional text-to-speech synthesis (ETTS) has seen much progress in recent\nyears. However, the generated voice is often not perceptually identifiable by\nits intended emotion category. To address this problem, we propose a new\ninteractive training paradigm for ETTS, denoted as i-ETTS, which seeks to\ndirectly improve the emotion discriminability by interacting with a speech\nemotion recognition (SER) model. Moreover, we formulate an iterative training\nstrategy with reinforcement learning to ensure the quality of i-ETTS\noptimization. Experimental results demonstrate that the proposed i-ETTS\noutperforms the state-of-the-art baselines by rendering speech with more\naccurate emotion style. To our best knowledge, this is the first study of\nreinforcement learning in emotional text-to-speech synthesis.",
          "link": "http://arxiv.org/abs/2104.01408",
          "publishedOn": "2021-06-15T01:45:21.295Z",
          "wordCount": 582,
          "title": "Reinforcement Learning for Emotional Text-to-Speech Synthesis with Improved Emotion Discriminability. (arXiv:2104.01408v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.04779",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1\">Yu Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiusheng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_W/0/1/0/all/0/1\">Weizhen Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhendawade_N/0/1/0/all/0/1\">Nikhil Bhendawade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1\">Yeyun Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1\">Nan Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ruofei Zhang</a>",
          "description": "Transformer model with multi-head attention requires caching intermediate\nresults for efficient inference in generation tasks. However, cache brings new\nmemory-related costs and prevents leveraging larger batch size for faster\nspeed. We propose memory-efficient lossless attention (called EL-attention) to\naddress this issue. It avoids heavy operations for building multi-head keys and\nvalues, cache for them is not needed. EL-attention constructs an ensemble of\nattention results by expanding query while keeping key and value shared. It\nproduces the same result as multi-head attention with less GPU memory and\nfaster inference speed. We conduct extensive experiments on Transformer, BART,\nand GPT-2 for summarization and question generation tasks. The results show\nEL-attention speeds up existing models by 1.6x to 5.3x without accuracy loss.",
          "link": "http://arxiv.org/abs/2105.04779",
          "publishedOn": "2021-06-15T01:45:21.283Z",
          "wordCount": 589,
          "title": "EL-Attention: Memory Efficient Lossless Attention for Generation. (arXiv:2105.04779v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01797",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qin_P/0/1/0/all/0/1\">Pengda Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuhong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_K/0/1/0/all/0/1\">Kefeng Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qiang Wu</a>",
          "description": "Among ubiquitous multimodal data in the real world, text is the modality\ngenerated by human, while image reflects the physical world honestly. In a\nvisual understanding application, machines are expected to understand images\nlike human. Inspired by this, we propose a novel self-supervised learning\nmethod, named Text-enhanced Visual Deep InfoMax (TVDIM), to learn better visual\nrepresentations by fully utilizing the naturally-existing multimodal data. Our\ncore idea of self-supervised learning is to maximize the mutual information\nbetween features extracted from multiple views of a shared context to a\nrational degree. Different from previous methods which only consider multiple\nviews from a single modality, our work produces multiple views from different\nmodalities, and jointly optimizes the mutual information for features pairs of\nintra-modality and inter-modality. Considering the information gap between\ninter-modality features pairs from data noise, we adopt a \\emph{ranking-based}\ncontrastive learning to optimize the mutual information. During evaluation, we\ndirectly use the pre-trained visual representations to complete various image\nclassification tasks. Experimental results show that, TVDIM significantly\noutperforms previous visual self-supervised methods when processing the same\nset of images.",
          "link": "http://arxiv.org/abs/2106.01797",
          "publishedOn": "2021-06-15T01:45:20.243Z",
          "wordCount": 623,
          "title": "TVDIM: Enhancing Image Self-Supervised Pretraining via Noisy Text Data. (arXiv:2106.01797v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.03743",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_J/0/1/0/all/0/1\">Jiehang Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1\">Xiaoqing Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jianhan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Linyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1\">Liping Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuanjing Huang</a>",
          "description": "Recently, few certified defense methods have been developed to provably\nguarantee the robustness of a text classifier to adversarial synonym\nsubstitutions. However, all existing certified defense methods assume that the\ndefenders are informed of how the adversaries generate synonyms, which is not a\nrealistic scenario. In this paper, we propose a certifiably robust defense\nmethod by randomly masking a certain proportion of the words in an input text,\nin which the above unrealistic assumption is no longer necessary. The proposed\nmethod can defend against not only word substitution-based attacks, but also\ncharacter-level perturbations. We can certify the classifications of over 50%\ntexts to be robust to any perturbation of 5 words on AGNEWS, and 2 words on\nSST2 dataset. The experimental results show that our randomized smoothing\nmethod significantly outperforms recently proposed defense methods across\nmultiple datasets.",
          "link": "http://arxiv.org/abs/2105.03743",
          "publishedOn": "2021-06-15T01:45:20.192Z",
          "wordCount": 596,
          "title": "Certified Robustness to Text Adversarial Attacks by Randomized [MASK]. (arXiv:2105.03743v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.11387",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Boateng_G/0/1/0/all/0/1\">George Boateng</a>",
          "description": "Introductory hands-on courses such as our smartphone-based coding course,\nSuaCode require a lot of support for students to accomplish learning goals.\nOnline environments make it even more difficult to get assistance especially\nmore recently because of COVID-19. Given the multilingual context of SuaCode\nstudents - learners across 42 African countries that are mostly Anglophone or\nFrancophone - in this work, we developed a bilingual Artificial Intelligence\n(AI) Teaching Assistant (TA) - Kwame - that provides answers to students'\ncoding questions from SuaCode courses in English and French. Kwame is a\nSentence-BERT (SBERT)-based question-answering (QA) system that we trained and\nevaluated offline using question-answer pairs created from the course's\nquizzes, lesson notes and students' questions in past cohorts. Kwame finds the\nparagraph most semantically similar to the question via cosine similarity. We\ncompared the system with TF-IDF and Universal Sentence Encoder. Our results\nshowed that fine-tuning on the course data and returning the top 3 and 5\nanswers improved the accuracy results. Kwame will make it easy for students to\nget quick and accurate answers to questions in SuaCode courses.",
          "link": "http://arxiv.org/abs/2010.11387",
          "publishedOn": "2021-06-15T01:45:19.615Z",
          "wordCount": null,
          "title": "Kwame: A Bilingual AI Teaching Assistant for Online SuaCode Courses. (arXiv:2010.11387v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.13856",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mao_Z/0/1/0/all/0/1\">Zhuoyuan Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_P/0/1/0/all/0/1\">Prakhar Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chu_C/0/1/0/all/0/1\">Chenhui Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaggi_M/0/1/0/all/0/1\">Martin Jaggi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurohashi_S/0/1/0/all/0/1\">Sadao Kurohashi</a>",
          "description": "Large-scale models for learning fixed-dimensional cross-lingual sentence\nrepresentations like LASER (Artetxe and Schwenk, 2019b) lead to significant\nimprovement in performance on downstream tasks. However, further increases and\nmodifications based on such large-scale models are usually impractical due to\nmemory limitations. In this work, we introduce a lightweight dual-transformer\narchitecture with just 2 layers for generating memory-efficient cross-lingual\nsentence representations. We explore different training tasks and observe that\ncurrent cross-lingual training tasks leave a lot to be desired for this shallow\narchitecture. To ameliorate this, we propose a novel cross-lingual language\nmodel, which combines the existing single-word masked language model with the\nnewly proposed cross-lingual token-level reconstruction task. We further\naugment the training task by the introduction of two computationally-lite\nsentence-level contrastive learning tasks to enhance the alignment of\ncross-lingual sentence representation space, which compensates for the learning\nbottleneck of the lightweight transformer for generative tasks. Our comparisons\nwith competing models on cross-lingual sentence retrieval and multilingual\ndocument classification confirm the effectiveness of the newly proposed\ntraining tasks for a shallow model.",
          "link": "http://arxiv.org/abs/2105.13856",
          "publishedOn": "2021-06-15T01:45:19.596Z",
          "wordCount": null,
          "title": "Lightweight Cross-Lingual Sentence Representation Learning. (arXiv:2105.13856v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.07639",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_H/0/1/0/all/0/1\">Hongyu Gong</a>",
          "description": "Multilingual models are parameter-efficient with the prospect improving\nlow-resource languages by leveraging crosslingual transfer. Despite recent\nadvance in massive multilingual translation with ever-growing model and data,\nhow to effectively train multilingual models has not been well understood. In\nthis paper, we show that a common situation in multilingual training, data\nimbalance among languages, poses optimization tension between high resource and\nlow resource languages where the found multilingual solution is often\nsub-optimal for low resources. We show that common training method which\nupsamples low resources can not robustly optimize population loss with risks of\neither underfitting high resource languages or overfitting low resource ones.\nDrawing on recent findings on the geometry of loss landscape and its effect on\ngeneralization, we propose a principled optimization algorithm, Curvature Aware\nTask Scaling (CATS), which adaptively rescales gradients from different tasks\nwith a meta objective of guiding multilingual training to low-curvature\nneighborhoods with uniformly low loss for all languages. We ran experiments on\ncommon benchmarks (TED, WMT and OPUS-100) with varying degrees of data\nimbalance. CATS effectively improved multilingual optimization and as a result\ndemonstrated consistent gains on low resources ( to BLEU) without hurting high\nresources. In addition, CATS is robust to overparameterization and large batch\nsize training, making it a promising training method for massive multilingual\nmodels that truly improve low resource languages.",
          "link": "http://arxiv.org/abs/2104.07639",
          "publishedOn": "2021-06-15T01:45:19.347Z",
          "wordCount": 685,
          "title": "Robust Optimization for Multilingual Translation with Imbalanced Data. (arXiv:2104.07639v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.00148",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1\">Haoyue Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1\">Luke Zettlemoyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Sida I. Wang</a>",
          "description": "Bilingual lexicons map words in one language to their translations in\nanother, and are typically induced by learning linear projections to align\nmonolingual word embedding spaces. In this paper, we show it is possible to\nproduce much higher quality lexicons with methods that combine (1) unsupervised\nbitext mining and (2) unsupervised word alignment. Directly applying a pipeline\nthat uses recent algorithms for both subproblems significantly improves induced\nlexicon quality and further gains are possible by learning to filter the\nresulting lexical entries, with both unsupervised and semi-supervised schemes.\nOur final model outperforms the state of the art on the BUCC 2020 shared task\nby 14 $F_1$ points averaged over 12 language pairs, while also providing a more\ninterpretable approach that allows for rich reasoning of word meaning in\ncontext. Further analysis of our output and the standard reference lexicons\nsuggests they are of comparable quality, and new benchmarks may be needed to\nmeasure further progress on this task.",
          "link": "http://arxiv.org/abs/2101.00148",
          "publishedOn": "2021-06-15T01:45:19.323Z",
          "wordCount": 625,
          "title": "Bilingual Lexicon Induction via Unsupervised Bitext Construction and Word Alignment. (arXiv:2101.00148v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.15082",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_A/0/1/0/all/0/1\">An Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Junyang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Men_R/0/1/0/all/0/1\">Rui Men</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Chang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1\">Le Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_X/0/1/0/all/0/1\">Xianyan Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_A/0/1/0/all/0/1\">Ang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jie Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiamang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Di Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1\">Wei Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_L/0/1/0/all/0/1\">Lin Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jingren Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hongxia Yang</a>",
          "description": "Mixture-of-Experts (MoE) models can achieve promising results with outrageous\nlarge amount of parameters but constant computation cost, and thus it has\nbecome a trend in model scaling. Still it is a mystery how MoE layers bring\nquality gains by leveraging the parameters with sparse activation. In this\nwork, we investigate several key factors in sparse expert models. We observe\nthat load imbalance may not be a significant problem affecting model quality,\ncontrary to the perspectives of recent studies, while the number of sparsely\nactivated experts $k$ and expert capacity $C$ in top-$k$ routing can\nsignificantly make a difference in this context. Furthermore, we take a step\nforward to propose a simple method called expert prototyping that splits\nexperts into different prototypes and applies $k$ top-$1$ routing. This\nstrategy improves the model quality but maintains constant computational costs,\nand our further exploration on extremely large-scale models reflects that it is\nmore effective in training larger models. We push the model scale to over $1$\ntrillion parameters and implement it on solely $480$ NVIDIA V100-32GB GPUs, in\ncomparison with the recent SOTAs on $2048$ TPU cores. The proposed giant model\nachieves substantial speedup in convergence over the same-size baseline.",
          "link": "http://arxiv.org/abs/2105.15082",
          "publishedOn": "2021-06-15T01:45:18.811Z",
          "wordCount": 674,
          "title": "Exploring Sparse Expert Models and Beyond. (arXiv:2105.15082v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.07003",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1\">Gyuwan Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1\">Kyunghyun Cho</a>",
          "description": "Despite transformers' impressive accuracy, their computational cost is often\nprohibitive to use with limited computational resources. Most previous\napproaches to improve inference efficiency require a separate model for each\npossible computational budget. In this paper, we extend PoWER-BERT (Goyal et\nal., 2020) and propose Length-Adaptive Transformer that can be used for various\ninference scenarios after one-shot training. We train a transformer with\nLengthDrop, a structural variant of dropout, which stochastically determines a\nsequence length at each layer. We then conduct a multi-objective evolutionary\nsearch to find a length configuration that maximizes the accuracy and minimizes\nthe efficiency metric under any given computational budget. Additionally, we\nsignificantly extend the applicability of PoWER-BERT beyond sequence-level\nclassification into token-level classification with Drop-and-Restore process\nthat drops word-vectors temporarily in intermediate layers and restores at the\nlast layer if necessary. We empirically verify the utility of the proposed\napproach by demonstrating the superior accuracy-efficiency trade-off under\nvarious setups, including span-based question answering and text\nclassification. Code is available at\nhttps://github.com/clovaai/length-adaptive-transformer.",
          "link": "http://arxiv.org/abs/2010.07003",
          "publishedOn": "2021-06-15T01:45:18.309Z",
          "wordCount": 633,
          "title": "Length-Adaptive Transformer: Train Once with Length Drop, Use Anytime with Search. (arXiv:2010.07003v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.02194",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Le_D/0/1/0/all/0/1\">Duc Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_M/0/1/0/all/0/1\">Mahaveer Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keren_G/0/1/0/all/0/1\">Gil Keren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Suyoun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yangyang Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahadeokar_J/0/1/0/all/0/1\">Jay Mahadeokar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_J/0/1/0/all/0/1\">Julian Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shangguan_Y/0/1/0/all/0/1\">Yuan Shangguan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fuegen_C/0/1/0/all/0/1\">Christian Fuegen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalinli_O/0/1/0/all/0/1\">Ozlem Kalinli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saraf_Y/0/1/0/all/0/1\">Yatharth Saraf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seltzer_M/0/1/0/all/0/1\">Michael L. Seltzer</a>",
          "description": "How to leverage dynamic contextual information in end-to-end speech\nrecognition has remained an active research area. Previous solutions to this\nproblem were either designed for specialized use cases that did not generalize\nwell to open-domain scenarios, did not scale to large biasing lists, or\nunderperformed on rare long-tail words. We address these limitations by\nproposing a novel solution that combines shallow fusion, trie-based deep\nbiasing, and neural network language model contextualization. These techniques\nresult in significant 19.5% relative Word Error Rate improvement over existing\ncontextual biasing approaches and 5.4%-9.3% improvement compared to a strong\nhybrid baseline on both open-domain and constrained contextualization tasks,\nwhere the targets consist of mostly rare long-tail words. Our final system\nremains lightweight and modular, allowing for quick modification without model\nre-training.",
          "link": "http://arxiv.org/abs/2104.02194",
          "publishedOn": "2021-06-15T01:45:17.513Z",
          "wordCount": 626,
          "title": "Contextualized Streaming End-to-End Speech Recognition with Trie-Based Deep Biasing and Shallow Fusion. (arXiv:2104.02194v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.13878",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaonan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_Y/0/1/0/all/0/1\">Yunfan Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_T/0/1/0/all/0/1\">Tianxiang Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_H/0/1/0/all/0/1\">Hang Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1\">Xipeng Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuanjing Huang</a>",
          "description": "Both performance and efficiency are crucial factors for sequence labeling\ntasks in many real-world scenarios. Although the pre-trained models (PTMs) have\nsignificantly improved the performance of various sequence labeling tasks,\ntheir computational cost is expensive. To alleviate this problem, we extend the\nrecent successful early-exit mechanism to accelerate the inference of PTMs for\nsequence labeling tasks. However, existing early-exit mechanisms are\nspecifically designed for sequence-level tasks, rather than sequence labeling.\nIn this paper, we first propose a simple extension of sentence-level early-exit\nfor sequence labeling tasks. To further reduce the computational cost, we also\npropose a token-level early-exit mechanism that allows partial tokens to exit\nearly at different layers. Considering the local dependency inherent in\nsequence labeling, we employed a window-based criterion to decide for a token\nwhether or not to exit. The token-level early-exit brings the gap between\ntraining and inference, so we introduce an extra self-sampling fine-tuning\nstage to alleviate it. The extensive experiments on three popular sequence\nlabeling tasks show that our approach can save up to 66%-75% inference cost\nwith minimal performance degradation. Compared with competitive compressed\nmodels such as DistilBERT, our approach can achieve better performance under\nthe same speed-up ratios of 2X, 3X, and 4X.",
          "link": "http://arxiv.org/abs/2105.13878",
          "publishedOn": "2021-06-15T01:45:17.117Z",
          "wordCount": 671,
          "title": "Accelerating BERT Inference for Sequence Labeling via Early-Exit. (arXiv:2105.13878v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.13648",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1\">Yu Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yang Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Heyan Huang</a>",
          "description": "Parallel cross-lingual summarization data is scarce, requiring models to\nbetter use the limited available cross-lingual resources. Existing methods to\ndo so often adopt sequence-to-sequence networks with multi-task frameworks.\nSuch approaches apply multiple decoders, each of which is utilized for a\nspecific task. However, these independent decoders share no parameters, hence\nfail to capture the relationships between the discrete phrases of summaries in\ndifferent languages, breaking the connections in order to transfer the\nknowledge of the high-resource languages to low-resource languages. To bridge\nthese connections, we propose a novel Multi-Task framework for Cross-Lingual\nAbstractive Summarization (MCLAS) in a low-resource setting. Employing one\nunified decoder to generate the sequential concatenation of monolingual and\ncross-lingual summaries, MCLAS makes the monolingual summarization task a\nprerequisite of the cross-lingual summarization (CLS) task. In this way, the\nshared decoder learns interactions involving alignments and summary patterns\nacross languages, which encourages attaining knowledge transfer. Experiments on\ntwo CLS datasets demonstrate that our model significantly outperforms three\nbaseline models in both low-resource and full-dataset scenarios. Moreover,\nin-depth analysis on the generated summaries and attention heads verifies that\ninteractions are learned well using MCLAS, which benefits the CLS task under\nlimited parallel resources.",
          "link": "http://arxiv.org/abs/2105.13648",
          "publishedOn": "2021-06-15T01:45:16.554Z",
          "wordCount": 658,
          "title": "Cross-Lingual Abstractive Summarization with Limited Parallel Resources. (arXiv:2105.13648v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.04941",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ou_J/0/1/0/all/0/1\">Jiefu Ou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weir_N/0/1/0/all/0/1\">Nathaniel Weir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belyy_A/0/1/0/all/0/1\">Anton Belyy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1\">Felix Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durme_B/0/1/0/all/0/1\">Benjamin Van Durme</a>",
          "description": "We propose a structured extension to bidirectional-context conditional\nlanguage generation, or \"infilling,\" inspired by Frame Semantic theory\n(Fillmore, 1976). Guidance is provided through two approaches: (1) model\nfine-tuning, conditioning directly on observed symbolic frames, and (2) a novel\nextension to disjunctive lexically constrained decoding that leverages frame\nsemantic lexical units. Automatic and human evaluations confirm that\nframe-guided generation allows for explicit manipulation of intended infill\nsemantics, with minimal loss in distinguishability from human-generated text.\nOur methods flexibly apply to a variety of use scenarios, and we provide a\ncodebase and interactive demo available from\nhttps://nlp.jhu.edu/demos/infillmore.",
          "link": "http://arxiv.org/abs/2103.04941",
          "publishedOn": "2021-06-15T01:45:16.461Z",
          "wordCount": 558,
          "title": "InFillmore: Frame-Guided Language Generation with Bidirectional Context. (arXiv:2103.04941v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06965",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fenglin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_C/0/1/0/all/0/1\">Changchang Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_S/0/1/0/all/0/1\">Shen Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Ping Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xu Sun</a>",
          "description": "Recently, chest X-ray report generation, which aims to automatically generate\ndescriptions of given chest X-ray images, has received growing research\ninterests. The key challenge of chest X-ray report generation is to accurately\ncapture and describe the abnormal regions. In most cases, the normal regions\ndominate the entire chest X-ray image, and the corresponding descriptions of\nthese normal regions dominate the final report. Due to such data bias,\nlearning-based models may fail to attend to abnormal regions. In this work, to\neffectively capture and describe abnormal regions, we propose the Contrastive\nAttention (CA) model. Instead of solely focusing on the current input image,\nthe CA model compares the current input image with normal images to distill the\ncontrastive information. The acquired contrastive information can better\nrepresent the visual features of abnormal regions. According to the experiments\non the public IU-X-ray and MIMIC-CXR datasets, incorporating our CA into\nseveral existing models can boost their performance across most metrics. In\naddition, according to the analysis, the CA model can help existing models\nbetter attend to the abnormal regions and provide more accurate descriptions\nwhich are crucial for an interpretable diagnosis. Specifically, we achieve the\nstate-of-the-art results on the two public datasets.",
          "link": "http://arxiv.org/abs/2106.06965",
          "publishedOn": "2021-06-15T01:45:16.418Z",
          "wordCount": 669,
          "title": "Contrastive Attention for Automatic Chest X-ray Report Generation. (arXiv:2106.06965v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2102.02959",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+DAnniballe_V/0/1/0/all/0/1\">Vincent M. D&#x27;Anniballe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tushar_F/0/1/0/all/0/1\">Fakrul I. Tushar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faryna_K/0/1/0/all/0/1\">Khrystyna Faryna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Songyue Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mazurowski_M/0/1/0/all/0/1\">Maciej A. Mazurowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubin_G/0/1/0/all/0/1\">Geoffrey D. Rubin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lo_J/0/1/0/all/0/1\">Joseph Y. Lo</a>",
          "description": "Purpose: To develop high throughput multi-label annotators for body (chest,\nabdomen, and pelvis) Computed Tomography (CT) reports that can be applied\nacross a variety of abnormalities, organs, and disease states.\n\nApproach: We used a dictionary approach to develop rule-based algorithms\n(RBA) for extraction of disease labels from radiology text reports. We targeted\nthree organ systems (lungs/pleura, liver/gallbladder, kidneys/ureters) with\nfour diseases per system based on their prevalence in our dataset. To expand\nthe algorithms beyond pre-defined keywords, attention-guided recurrent neural\nnetworks (RNN) were trained using the RBA-extracted labels to classify reports\nas being positive for one or more diseases or normal for each organ system.\nConfounding effects on model performance were evaluated using random\ninitialization or pre-trained embedding as well as different sizes of training\ndatasets. Performance was evaluated using the receiver operating characteristic\n(ROC) area under the curve (AUC) against 2,158 manually obtained labels.\n\nResults: Our models extracted disease labels from 261,229 radiology reports\nof 112,501 unique subjects. Pre-trained models outperformed random\ninitialization across all diseases. As the training dataset size was reduced,\nperformance was robust except for a few diseases with relatively small number\nof cases. Pre-trained classification AUCs achieved > 0.95 for all five disease\noutcomes across all three organ systems.\n\nConclusions: Our label-extracting pipeline was able to encompass a variety of\ncases and diseases by generalizing beyond strict rules with exceptional\naccuracy. This method can be easily adapted to enable automated labeling of\nhospital-scale medical data sets for training image-based disease classifiers.",
          "link": "http://arxiv.org/abs/2102.02959",
          "publishedOn": "2021-06-15T01:45:15.907Z",
          "wordCount": 748,
          "title": "Multi-Label Annotation of Chest Abdomen Pelvis Computed Tomography Text Reports Using Deep Learning. (arXiv:2102.02959v4 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06811",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pritom_M/0/1/0/all/0/1\">Mir Mehedi A. Pritom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_R/0/1/0/all/0/1\">Rosana Montanez Rodriguez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1\">Asad Ali Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nugroho_S/0/1/0/all/0/1\">Sebastian A. Nugroho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alrashydah_E/0/1/0/all/0/1\">Esra&#x27;a Alrashydah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruiz_B/0/1/0/all/0/1\">Beatrice N. Ruiz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rios_A/0/1/0/all/0/1\">Anthony Rios</a>",
          "description": "COVID-19 pandemic has generated what public health officials called an\ninfodemic of misinformation. As social distancing and stay-at-home orders came\ninto effect, many turned to social media for socializing. This increase in\nsocial media usage has made it a prime vehicle for the spreading of\nmisinformation. This paper presents a mechanism to detect COVID-19\nhealth-related misinformation in social media following an interdisciplinary\napproach. Leveraging social psychology as a foundation and existing\nmisinformation frameworks, we defined misinformation themes and associated\nkeywords incorporated into the misinformation detection mechanism using applied\nmachine learning techniques. Next, using the Twitter dataset, we explored the\nperformance of the proposed methodology using multiple state-of-the-art machine\nlearning classifiers. Our method shows promising results with at most 78%\naccuracy in classifying health-related misinformation versus true information\nusing uni-gram-based NLP feature generations from tweets and the Decision Tree\nclassifier. We also provide suggestions on alternatives for countering\nmisinformation and ethical consideration for the study.",
          "link": "http://arxiv.org/abs/2106.06811",
          "publishedOn": "2021-06-15T01:45:15.849Z",
          "wordCount": 656,
          "title": "Case Study on Detecting COVID-19 Health-Related Misinformation in Social Media. (arXiv:2106.06811v1 [cs.SI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06823",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Paranjape_B/0/1/0/all/0/1\">Bhargavi Paranjape</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Michael_J/0/1/0/all/0/1\">Julian Michael</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghazvininejad_M/0/1/0/all/0/1\">Marjan Ghazvininejad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1\">Luke Zettlemoyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1\">Hannaneh Hajishirzi</a>",
          "description": "Many commonsense reasoning NLP tasks involve choosing between one or more\npossible answers to a question or prompt based on knowledge that is often\nimplicit. Large pretrained language models (PLMs) can achieve near-human\nperformance on such tasks, while providing little human-interpretable evidence\nof the underlying reasoning they use. In this work, we show how to use these\nsame models to generate such evidence: inspired by the contrastive nature of\nhuman explanations, we use PLMs to complete explanation prompts which contrast\nalternatives according to the key attribute(s) required to justify the correct\nanswer (for example, peanuts are usually salty while raisins are sweet).\nConditioning model decisions on these explanations improves performance on two\ncommonsense reasoning benchmarks, as compared to previous non-contrastive\nalternatives. These explanations are also judged by humans to be more relevant\nfor solving the task, and facilitate a novel method to evaluate explanation\nfaithfulfness.",
          "link": "http://arxiv.org/abs/2106.06823",
          "publishedOn": "2021-06-15T01:45:15.842Z",
          "wordCount": 579,
          "title": "Prompting Contrastive Explanations for Commonsense Reasoning Tasks. (arXiv:2106.06823v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2101.06561",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khashabi_D/0/1/0/all/0/1\">Daniel Khashabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stanovsky_G/0/1/0/all/0/1\">Gabriel Stanovsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bragg_J/0/1/0/all/0/1\">Jonathan Bragg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lourie_N/0/1/0/all/0/1\">Nicholas Lourie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kasai_J/0/1/0/all/0/1\">Jungo Kasai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1\">Noah A. Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weld_D/0/1/0/all/0/1\">Daniel S. Weld</a>",
          "description": "Leaderboards have eased model development for many NLP datasets by\nstandardizing their evaluation and delegating it to an independent external\nrepository. Their adoption, however, is so far limited to tasks that can be\nreliably evaluated in an automatic manner. This work introduces GENIE, an\nextensible human evaluation leaderboard, which brings the ease of leaderboards\nto text generation tasks. GENIE automatically posts leaderboard submissions to\ncrowdsourcing platforms asking human annotators to evaluate them on various\naxes (e.g., correctness, conciseness, fluency) and compares their answers to\nvarious automatic metrics. We introduce several datasets in English to GENIE,\nrepresenting four core challenges in text generation: machine translation,\nsummarization, commonsense reasoning, and machine comprehension. We provide\nformal granular evaluation metrics and identify areas for future research. We\nmake GENIE publicly available and hope that it will spur progress in language\ngeneration models as well as their automatic and manual evaluation.",
          "link": "http://arxiv.org/abs/2101.06561",
          "publishedOn": "2021-06-15T01:45:15.806Z",
          "wordCount": 620,
          "title": "GENIE: A Leaderboard for Human-in-the-Loop Evaluation of Text Generation. (arXiv:2101.06561v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06751",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yang Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_S/0/1/0/all/0/1\">Shuhao Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_D/0/1/0/all/0/1\">Dengji Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhengxin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_C/0/1/0/all/0/1\">Chenze Shao</a>",
          "description": "Although teacher forcing has become the main training paradigm for neural\nmachine translation, it usually makes predictions only conditioned on past\ninformation, and hence lacks global planning for the future. To address this\nproblem, we introduce another decoder, called seer decoder, into the\nencoder-decoder framework during training, which involves future information in\ntarget predictions. Meanwhile, we force the conventional decoder to simulate\nthe behaviors of the seer decoder via knowledge distillation. In this way, at\ntest the conventional decoder can perform like the seer decoder without the\nattendance of it. Experiment results on the Chinese-English, English-German and\nEnglish-Romanian translation tasks show our method can outperform competitive\nbaselines significantly and achieves greater improvements on the bigger data\nsets. Besides, the experiments also prove knowledge distillation the best way\nto transfer knowledge from the seer decoder to the conventional decoder\ncompared to adversarial learning and L2 regularization.",
          "link": "http://arxiv.org/abs/2106.06751",
          "publishedOn": "2021-06-15T01:45:15.372Z",
          "wordCount": 583,
          "title": "Guiding Teacher Forcing with Seer Forcing for Neural Machine Translation. (arXiv:2106.06751v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2101.07393",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hanjie_A/0/1/0/all/0/1\">Austin W. Hanjie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_V/0/1/0/all/0/1\">Victor Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narasimhan_K/0/1/0/all/0/1\">Karthik Narasimhan</a>",
          "description": "We investigate the use of natural language to drive the generalization of\ncontrol policies and introduce the new multi-task environment Messenger with\nfree-form text manuals describing the environment dynamics. Unlike previous\nwork, Messenger does not assume prior knowledge connecting text and state\nobservations $-$ the control policy must simultaneously ground the game manual\nto entity symbols and dynamics in the environment. We develop a new model, EMMA\n(Entity Mapper with Multi-modal Attention) which uses an entity-conditioned\nattention module that allows for selective focus over relevant descriptions in\nthe manual for each entity in the environment. EMMA is end-to-end\ndifferentiable and learns a latent grounding of entities and dynamics from text\nto observations using only environment rewards. EMMA achieves successful\nzero-shot generalization to unseen games with new dynamics, obtaining a 40%\nhigher win rate compared to multiple baselines. However, win rate on the\nhardest stage of Messenger remains low (10%), demonstrating the need for\nadditional work in this direction.",
          "link": "http://arxiv.org/abs/2101.07393",
          "publishedOn": "2021-06-15T01:45:15.298Z",
          "wordCount": 638,
          "title": "Grounding Language to Entities and Dynamics for Generalization in Reinforcement Learning. (arXiv:2101.07393v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.06969",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhengyan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_G/0/1/0/all/0/1\">Guangxuan Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yongwei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_T/0/1/0/all/0/1\">Tian Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_F/0/1/0/all/0/1\">Fanchao Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yasheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1\">Xin Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>",
          "description": "Pre-trained models (PTMs) have been widely used in various downstream tasks.\nThe parameters of PTMs are distributed on the Internet and may suffer backdoor\nattacks. In this work, we demonstrate the universal vulnerability of PTMs,\nwhere fine-tuned PTMs can be easily controlled by backdoor attacks in arbitrary\ndownstream tasks. Specifically, attackers can add a simple pre-training task,\nwhich restricts the output representations of trigger instances to pre-defined\nvectors, namely neuron-level backdoor attack (NeuBA). If the backdoor\nfunctionality is not eliminated during fine-tuning, the triggers can make the\nfine-tuned model predict fixed labels by pre-defined vectors. In the\nexperiments of both natural language processing (NLP) and computer vision (CV),\nwe show that NeuBA absolutely controls the predictions for trigger instances\nwithout any knowledge of downstream tasks. Finally, we apply several defense\nmethods to NeuBA and find that model pruning is a promising direction to resist\nNeuBA by excluding backdoored neurons. Our findings sound a red alarm for the\nwide use of PTMs. Our source code and models are available at\n\\url{https://github.com/thunlp/NeuBA}.",
          "link": "http://arxiv.org/abs/2101.06969",
          "publishedOn": "2021-06-15T01:45:15.267Z",
          "wordCount": 660,
          "title": "Red Alarm for Pre-trained Models: Universal Vulnerability to Neuron-Level Backdoor Attacks. (arXiv:2101.06969v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06797",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Sachin Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anastasopoulos_A/0/1/0/all/0/1\">Antonios Anastasopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wintner_S/0/1/0/all/0/1\">Shuly Wintner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsvetkov_Y/0/1/0/all/0/1\">Yulia Tsvetkov</a>",
          "description": "State-of-the-art machine translation (MT) systems are typically trained to\ngenerate the \"standard\" target language; however, many languages have multiple\nvarieties (regional varieties, dialects, sociolects, non-native varieties) that\nare different from the standard language. Such varieties are often\nlow-resource, and hence do not benefit from contemporary NLP solutions, MT\nincluded. We propose a general framework to rapidly adapt MT systems to\ngenerate language varieties that are close to, but different from, the standard\ntarget language, using no parallel (source--variety) data. This also includes\nadaptation of MT systems to low-resource typologically-related target\nlanguages. We experiment with adapting an English--Russian MT system to\ngenerate Ukrainian and Belarusian, an English--Norwegian Bokm{\\aa}l system to\ngenerate Nynorsk, and an English--Arabic system to generate four Arabic\ndialects, obtaining significant improvements over competitive baselines.",
          "link": "http://arxiv.org/abs/2106.06797",
          "publishedOn": "2021-06-15T01:45:15.254Z",
          "wordCount": 575,
          "title": "Machine Translation into Low-resource Language Varieties. (arXiv:2106.06797v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06673",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sayyed_Z/0/1/0/all/0/1\">Zeeshan Ali Sayyed</a>",
          "description": "This work investigates the application of sampling methods for sentiment\nanalysis on two different highly imbalanced datasets. One dataset contains\nonline user reviews from the cooking platform Epicurious and the other contains\ncomments given to the Planned Parenthood organization. In both these datasets,\nthe classes of interest are rare. Word n-grams were used as features from these\ndatasets. A feature selection technique based on information gain is first\napplied to reduce the number of features to a manageable space. A number of\ndifferent sampling methods were then applied to mitigate the class imbalance\nproblem which are then analyzed.",
          "link": "http://arxiv.org/abs/2106.06673",
          "publishedOn": "2021-06-15T01:45:15.220Z",
          "wordCount": 522,
          "title": "Study of sampling methods in sentiment analysis of imbalanced data. (arXiv:2106.06673v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06766",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sachintha_D/0/1/0/all/0/1\">Dilan Sachintha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piyarathna_L/0/1/0/all/0/1\">Lakmali Piyarathna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajitha_C/0/1/0/all/0/1\">Charith Rajitha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranathunga_S/0/1/0/all/0/1\">Surangika Ranathunga</a>",
          "description": "Multilingual sentence representations pose a great advantage for low-resource\nlanguages that do not have enough data to build monolingual models on their\nown. These multilingual sentence representations have been separately exploited\nby few research for document and sentence alignment. However, most of the\nlow-resource languages are under-represented in these pre-trained models. Thus,\nin the context of low-resource languages, these models have to be fine-tuned\nfor the task at hand, using additional data sources. This paper presents a\nweighting mechanism that makes use of available small-scale parallel corpora to\nimprove the performance of multilingual sentence representations on document\nand sentence alignment. Experiments are conducted with respect to two\nlow-resource languages, Sinhala and Tamil. Results on a newly created dataset\nof Sinhala-English, Tamil-English, and Sinhala-Tamil show that this new\nweighting mechanism significantly improves both document and sentence\nalignment. This dataset, as well as the source-code, is publicly released.",
          "link": "http://arxiv.org/abs/2106.06766",
          "publishedOn": "2021-06-15T01:45:15.190Z",
          "wordCount": 585,
          "title": "Exploiting Parallel Corpora to Improve Multilingual Embedding based Document and Sentence Alignment. (arXiv:2106.06766v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06605",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Reddy_S/0/1/0/all/0/1\">Sravana Reddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lazarova_M/0/1/0/all/0/1\">Marina Lazarova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yongze Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jones_R/0/1/0/all/0/1\">Rosie Jones</a>",
          "description": "While there is an abundance of popular writing targeted to podcast creators\non how to speak in ways that engage their listeners, there has been little\ndata-driven analysis of podcasts that relates linguistic style with listener\nengagement. In this paper, we investigate how various factors -- vocabulary\ndiversity, distinctiveness, emotion, and syntax, among others -- correlate with\nengagement, based on analysis of the creators' written descriptions and\ntranscripts of the audio. We build models with different textual\nrepresentations, and show that the identified features are highly predictive of\nengagement. Our analysis tests popular wisdom about stylistic elements in\nhigh-engagement podcasts, corroborating some aspects, and adding new\nperspectives on others.",
          "link": "http://arxiv.org/abs/2106.06605",
          "publishedOn": "2021-06-15T01:45:15.153Z",
          "wordCount": 537,
          "title": "Modeling Language Usage and Listener Engagement in Podcasts. (arXiv:2106.06605v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06963",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fenglin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_S/0/1/0/all/0/1\">Shen Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_W/0/1/0/all/0/1\">Wei Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1\">Yuexian Zou</a>",
          "description": "Automatically generating radiology reports can improve current clinical\npractice in diagnostic radiology. On one hand, it can relieve radiologists from\nthe heavy burden of report writing; On the other hand, it can remind\nradiologists of abnormalities and avoid the misdiagnosis and missed diagnosis.\nYet, this task remains a challenging job for data-driven neural networks, due\nto the serious visual and textual data biases. To this end, we propose a\nPosterior-and-Prior Knowledge Exploring-and-Distilling approach (PPKED) to\nimitate the working patterns of radiologists, who will first examine the\nabnormal regions and assign the disease topic tags to the abnormal regions, and\nthen rely on the years of prior medical knowledge and prior working experience\naccumulations to write reports. Thus, the PPKED includes three modules:\nPosterior Knowledge Explorer (PoKE), Prior Knowledge Explorer (PrKE) and\nMulti-domain Knowledge Distiller (MKD). In detail, PoKE explores the posterior\nknowledge, which provides explicit abnormal visual regions to alleviate visual\ndata bias; PrKE explores the prior knowledge from the prior medical knowledge\ngraph (medical knowledge) and prior radiology reports (working experience) to\nalleviate textual data bias. The explored knowledge is distilled by the MKD to\ngenerate the final reports. Evaluated on MIMIC-CXR and IU-Xray datasets, our\nmethod is able to outperform previous state-of-the-art models on these two\ndatasets.",
          "link": "http://arxiv.org/abs/2106.06963",
          "publishedOn": "2021-06-15T01:45:15.146Z",
          "wordCount": 656,
          "title": "Exploring and Distilling Posterior and Prior Knowledge for Radiology Report Generation. (arXiv:2106.06963v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2010.14318",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Peidong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sainath_T/0/1/0/all/0/1\">Tara N. Sainath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weiss_R/0/1/0/all/0/1\">Ron J. Weiss</a>",
          "description": "We propose a multitask training method for attention-based end-to-end speech\nrecognition models. We regularize the decoder in a listen, attend, and spell\nmodel by multitask training it on both audio-text and text-only data. Trained\non the 100-hour subset of LibriSpeech, the proposed method, without requiring\nan additional language model, leads to an 11% relative performance improvement\nover the baseline and approaches the performance of language model shallow\nfusion on the test-clean evaluation set. We observe a similar trend on the\nwhole 960-hour LibriSpeech training set. Analyses of different types of errors\nand sample output sentences demonstrate that the proposed method can\nincorporate language level information, suggesting its effectiveness in\nreal-world applications.",
          "link": "http://arxiv.org/abs/2010.14318",
          "publishedOn": "2021-06-15T01:45:15.137Z",
          "wordCount": 570,
          "title": "Multitask Training with Text Data for End-to-End Speech Recognition. (arXiv:2010.14318v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.06040",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Herzig_J/0/1/0/all/0/1\">Jonathan Herzig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berant_J/0/1/0/all/0/1\">Jonathan Berant</a>",
          "description": "Despite the success of sequence-to-sequence (seq2seq) models in semantic\nparsing, recent work has shown that they fail in compositional generalization,\ni.e., the ability to generalize to new structures built of components observed\nduring training. In this work, we posit that a span-based parser should lead to\nbetter compositional generalization. we propose SpanBasedSP, a parser that\npredicts a span tree over an input utterance, explicitly encoding how partial\nprograms compose over spans in the input. SpanBasedSP extends Pasupat et al.\n(2019) to be comparable to seq2seq models by (i) training from programs,\nwithout access to gold trees, treating trees as latent variables, (ii) parsing\na class of non-projective trees through an extension to standard CKY. On\nGeoQuery, SCAN and CLOSURE datasets, SpanBasedSP performs similarly to strong\nseq2seq baselines on random splits, but dramatically improves performance\ncompared to baselines on splits that require compositional generalization: from\n$61.0 \\rightarrow 88.9$ average accuracy.",
          "link": "http://arxiv.org/abs/2009.06040",
          "publishedOn": "2021-06-15T01:45:15.086Z",
          "wordCount": 600,
          "title": "Span-based Semantic Parsing for Compositional Generalization. (arXiv:2009.06040v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06937",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1\">Bill Yuchen Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Seyeon Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_X/0/1/0/all/0/1\">Xiaoyang Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>",
          "description": "Commonsense reasoning research has so far been limited to English. We aim to\nevaluate and improve popular multilingual language models (ML-LMs) to help\nadvance commonsense reasoning (CSR) beyond English. We collect the Mickey\nCorpus, consisting of 561k sentences in 11 different languages, which can be\nused for analyzing and improving ML-LMs. We propose Mickey Probe, a\nlanguage-agnostic probing task for fairly evaluating the common sense of\npopular ML-LMs across different languages. In addition, we also create two new\ndatasets, X-CSQA and X-CODAH, by translating their English versions to 15 other\nlanguages, so that we can evaluate popular ML-LMs for cross-lingual commonsense\nreasoning. To improve the performance beyond English, we propose a simple yet\neffective method -- multilingual contrastive pre-training (MCP). It\nsignificantly enhances sentence representations, yielding a large performance\ngain on both benchmarks.",
          "link": "http://arxiv.org/abs/2106.06937",
          "publishedOn": "2021-06-15T01:45:15.080Z",
          "wordCount": 589,
          "title": "Common Sense Beyond English: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning. (arXiv:2106.06937v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06899",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Ankit Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dar_G/0/1/0/all/0/1\">Guy Dar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goodman_S/0/1/0/all/0/1\">Shaya Goodman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ciprut_D/0/1/0/all/0/1\">David Ciprut</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berant_J/0/1/0/all/0/1\">Jonathan Berant</a>",
          "description": "Following the success of dot-product attention in Transformers, numerous\napproximations have been recently proposed to address its quadratic complexity\nwith respect to the input length. While these variants are memory and compute\nefficient, it is not possible to directly use them with popular pre-trained\nlanguage models trained using vanilla attention, without an expensive\ncorrective pre-training stage. In this work, we propose a simple yet highly\naccurate approximation for vanilla attention. We process the queries in chunks,\nand for each query, compute the top-$k$ scores with respect to the keys. Our\napproach offers several advantages: (a) its memory usage is linear in the input\nsize, similar to linear attention variants, such as Performer and RFA (b) it is\na drop-in replacement for vanilla attention that does not require any\ncorrective pre-training, and (c) it can also lead to significant memory savings\nin the feed-forward layers after casting them into the familiar query-key-value\nframework. We evaluate the quality of top-$k$ approximation for multi-head\nattention layers on the Long Range Arena Benchmark, and for feed-forward layers\nof T5 and UnifiedQA on multiple QA datasets. We show our approach leads to\naccuracy that is nearly-identical to vanilla attention in multiple setups\nincluding training from scratch, fine-tuning, and zero-shot inference.",
          "link": "http://arxiv.org/abs/2106.06899",
          "publishedOn": "2021-06-15T01:45:15.055Z",
          "wordCount": 630,
          "title": "Memory-efficient Transformers via Top-$k$ Attention. (arXiv:2106.06899v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06588",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Henn_S/0/1/0/all/0/1\">Sophia Henn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sticha_A/0/1/0/all/0/1\">Abigail Sticha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burley_T/0/1/0/all/0/1\">Timothy Burley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verdeja_E/0/1/0/all/0/1\">Ernesto Verdeja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brenner_P/0/1/0/all/0/1\">Paul Brenner</a>",
          "description": "Robust visualization of complex data is critical for the effective use of NLP\nfor event classification, as the volume of data is large and the\nhigh-dimensional structure of text makes data challenging to summarize\nsuccinctly. In event extraction tasks in particular, visualization can aid in\nunderstanding and illustrating the textual relationships from which machine\nlearning tools produce insights. Through our case study which seeks to identify\npotential triggers of state-led mass killings from news articles using NLP, we\ndemonstrate how visualizations can aid in each stage, from exploratory analysis\nof raw data, to machine learning training analysis, and finally post-inference\nvalidation.",
          "link": "http://arxiv.org/abs/2106.06588",
          "publishedOn": "2021-06-15T01:45:15.040Z",
          "wordCount": 534,
          "title": "Visualization Techniques to Enhance Automated Event Extraction. (arXiv:2106.06588v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06981",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weiss_G/0/1/0/all/0/1\">Gail Weiss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldberg_Y/0/1/0/all/0/1\">Yoav Goldberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yahav_E/0/1/0/all/0/1\">Eran Yahav</a>",
          "description": "What is the computational model behind a Transformer? Where recurrent neural\nnetworks have direct parallels in finite state machines, allowing clear\ndiscussion and thought around architecture variants or trained models,\nTransformers have no such familiar parallel. In this paper we aim to change\nthat, proposing a computational model for the transformer-encoder in the form\nof a programming language. We map the basic components of a transformer-encoder\n-- attention and feed-forward computation -- into simple primitives, around\nwhich we form a programming language: the Restricted Access Sequence Processing\nLanguage (RASP). We show how RASP can be used to program solutions to tasks\nthat could conceivably be learned by a Transformer, and how a Transformer can\nbe trained to mimic a RASP solution. In particular, we provide RASP programs\nfor histograms, sorting, and Dyck-languages. We further use our model to relate\ntheir difficulty in terms of the number of required layers and attention heads:\nanalyzing a RASP program implies a maximum number of heads and layers necessary\nto encode a task in a transformer. Finally, we see how insights gained from our\nabstraction might be used to explain phenomena seen in recent works.",
          "link": "http://arxiv.org/abs/2106.06981",
          "publishedOn": "2021-06-15T01:45:15.033Z",
          "wordCount": 611,
          "title": "Thinking Like Transformers. (arXiv:2106.06981v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2104.14470",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1\">Ha Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Esteve_Y/0/1/0/all/0/1\">Yannick Est&#xe8;ve</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Besacier_L/0/1/0/all/0/1\">Laurent Besacier</a>",
          "description": "Boosted by the simultaneous translation shared task at IWSLT 2020, promising\nend-to-end online speech translation approaches were recently proposed. They\nconsist in incrementally encoding a speech input (in a source language) and\ndecoding the corresponding text (in a target language) with the best possible\ntrade-off between latency and translation quality. This paper investigates two\nkey aspects of end-to-end simultaneous speech translation: (a) how to encode\nefficiently the continuous speech flow, and (b) how to segment the speech flow\nin order to alternate optimally between reading (R: encoding input) and writing\n(W: decoding output) operations. We extend our previously proposed end-to-end\nonline decoding strategy and show that while replacing BLSTM by ULSTM encoding\ndegrades performance in offline mode, it actually improves both efficiency and\nperformance in online mode. We also measure the impact of different methods to\nsegment the speech signal (using fixed interval boundaries, oracle word\nboundaries or randomly set boundaries) and show that our best end-to-end online\ndecoding strategy is surprisingly the one that alternates R/W operations on\nfixed size blocks on our English-German speech translation setup.",
          "link": "http://arxiv.org/abs/2104.14470",
          "publishedOn": "2021-06-15T01:45:14.799Z",
          "wordCount": 653,
          "title": "Impact of Encoding and Segmentation Strategies on End-to-End Simultaneous Speech Translation. (arXiv:2104.14470v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.08620",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rozner_J/0/1/0/all/0/1\">Josh Rozner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potts_C/0/1/0/all/0/1\">Christopher Potts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahowald_K/0/1/0/all/0/1\">Kyle Mahowald</a>",
          "description": "Cryptic crosswords, the dominant English-language crossword variety in the\nUnited Kingdom, can be solved by expert humans using flexible, creative\nintelligence and knowledge of language. Cryptic clues read like fluent natural\nlanguage, but they are adversarially composed of two parts: a definition and a\nwordplay cipher requiring sub-word or character-level manipulations. As such,\nthey are a promising target for evaluating and advancing NLP systems that seek\nto process language in more creative, human-like ways. We present a dataset of\ncryptic crossword clues from a major newspaper that can be used as a benchmark\nand train a sequence-to-sequence model to solve them. We also develop related\nbenchmarks that can guide development of approaches to this challenging task.\nWe show that performance can be substantially improved using a novel curriculum\nlearning approach in which the model is pre-trained on related tasks involving,\ne.g, unscrambling words, before it is trained to solve cryptics. However, even\nthis curricular approach does not generalize to novel clue types in the way\nthat humans can, and so cryptic crosswords remain a challenge for NLP systems\nand a potential source of future innovation.",
          "link": "http://arxiv.org/abs/2104.08620",
          "publishedOn": "2021-06-15T01:45:14.661Z",
          "wordCount": 647,
          "title": "Decrypting Cryptic Crosswords: Semantically Complex Wordplay Puzzles as a Target for NLP. (arXiv:2104.08620v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.05752",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cha_S/0/1/0/all/0/1\">Sujeong Cha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_W/0/1/0/all/0/1\">Wangrui Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_H/0/1/0/all/0/1\">Hyun Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Phung_M/0/1/0/all/0/1\">My Phung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Picheny_M/0/1/0/all/0/1\">Michael Picheny</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuo_H/0/1/0/all/0/1\">Hong-Kwang Kuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thomas_S/0/1/0/all/0/1\">Samuel Thomas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morais_E/0/1/0/all/0/1\">Edmilson Morais</a>",
          "description": "A major focus of recent research in spoken language understanding (SLU) has\nbeen on the end-to-end approach where a single model can predict intents\ndirectly from speech inputs without intermediate transcripts. However, this\napproach presents some challenges. First, since speech can be considered as\npersonally identifiable information, in some cases only automatic speech\nrecognition (ASR) transcripts are accessible. Second, intent-labeled speech\ndata is scarce. To address the first challenge, we propose a novel system that\ncan predict intents from flexible types of inputs: speech, ASR transcripts, or\nboth. We demonstrate strong performance for either modality separately, and\nwhen both speech and ASR transcripts are available, through system combination,\nwe achieve better results than using a single input modality. To address the\nsecond challenge, we leverage a semantically robust pre-trained BERT model and\nadopt a cross-modal system that co-trains text embeddings and acoustic\nembeddings in a shared latent space. We further enhance this system by\nutilizing an acoustic module pre-trained on LibriSpeech and domain-adapting the\ntext module on our target datasets. Our experiments show significant advantages\nfor these pre-training and fine-tuning strategies, resulting in a system that\nachieves competitive intent-classification performance on Snips SLU and Fluent\nSpeech Commands datasets.",
          "link": "http://arxiv.org/abs/2104.05752",
          "publishedOn": "2021-06-15T01:45:14.609Z",
          "wordCount": 689,
          "title": "Speak or Chat with Me: End-to-End Spoken Language Understanding System with Flexible Inputs. (arXiv:2104.05752v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03153",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Min_D/0/1/0/all/0/1\">Dongchan Min</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_D/0/1/0/all/0/1\">Dong Bok Lee</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_E/0/1/0/all/0/1\">Eunho Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hwang_S/0/1/0/all/0/1\">Sung Ju Hwang</a>",
          "description": "With rapid progress in neural text-to-speech (TTS) models, personalized\nspeech generation is now in high demand for many applications. For practical\napplicability, a TTS model should generate high-quality speech with only a few\naudio samples from the given speaker, that are also short in length. However,\nexisting methods either require to fine-tune the model or achieve low\nadaptation quality without fine-tuning. In this work, we propose StyleSpeech, a\nnew TTS model which not only synthesizes high-quality speech but also\neffectively adapts to new speakers. Specifically, we propose Style-Adaptive\nLayer Normalization (SALN) which aligns gain and bias of the text input\naccording to the style extracted from a reference speech audio. With SALN, our\nmodel effectively synthesizes speech in the style of the target speaker even\nfrom single speech audio. Furthermore, to enhance StyleSpeech's adaptation to\nspeech from new speakers, we extend it to Meta-StyleSpeech by introducing two\ndiscriminators trained with style prototypes, and performing episodic training.\nThe experimental results show that our models generate high-quality speech\nwhich accurately follows the speaker's voice with single short-duration (1-3\nsec) speech audio, significantly outperforming baselines.",
          "link": "http://arxiv.org/abs/2106.03153",
          "publishedOn": "2021-06-15T01:45:14.370Z",
          "wordCount": 645,
          "title": "Meta-StyleSpeech : Multi-Speaker Adaptive Text-to-Speech Generation. (arXiv:2106.03153v2 [eess.AS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.03006",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeyer_A/0/1/0/all/0/1\">Albert Zeyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Merboldt_A/0/1/0/all/0/1\">Andr&#xe9; Merboldt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Michel_W/0/1/0/all/0/1\">Wilfried Michel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schluter_R/0/1/0/all/0/1\">Ralf Schl&#xfc;ter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ney_H/0/1/0/all/0/1\">Hermann Ney</a>",
          "description": "We present our transducer model on Librispeech. We study variants to include\nan external language model (LM) with shallow fusion and subtract an estimated\ninternal LM. This is justified by a Bayesian interpretation where the\ntransducer model prior is given by the estimated internal LM. The subtraction\nof the internal LM gives us over 14% relative improvement over normal shallow\nfusion. Our transducer has a separate probability distribution for the\nnon-blank labels which allows for easier combination with the external LM, and\neasier estimation of the internal LM. We additionally take care of including\nthe end-of-sentence (EOS) probability of the external LM in the last blank\nprobability which further improves the performance. All our code and setups are\npublished.",
          "link": "http://arxiv.org/abs/2104.03006",
          "publishedOn": "2021-06-15T01:45:14.323Z",
          "wordCount": 592,
          "title": "Librispeech Transducer Model with Internal Language Model Prior Correction. (arXiv:2104.03006v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.10685",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zou_X/0/1/0/all/0/1\">Xu Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_D/0/1/0/all/0/1\">Da Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_Q/0/1/0/all/0/1\">Qingyang Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1\">Ming Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhilin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jie Tang</a>",
          "description": "Large-scale pre-trained language models have demonstrated strong capabilities\nof generating realistic text. However, it remains challenging to control the\ngeneration results. Previous approaches such as prompting are far from\nsufficient, which limits the usage of language models. To tackle this\nchallenge, we propose an innovative method, inverse prompting, to better\ncontrol text generation. The core idea of inverse prompting is to use generated\ntext to inversely predict the prompt during beam search, which enhances the\nrelevance between the prompt and the generated text and provides better\ncontrollability. Empirically, we pre-train a large-scale Chinese language model\nto perform a systematic study using human evaluation on the tasks of\nopen-domain poem generation and open-domain long-form question answering. Our\nresults show that our proposed method substantially outperforms the baselines\nand that our generation quality is close to human performance on some of the\ntasks.\n\nNarrators can try our poem generation demo at\nhttps://pretrain.aminer.cn/apps/poetry.html, while our QA demo can be found at\nhttps://pretrain.aminer.cn/app/qa. For researchers, the code is provided in\nhttps://github.com/THUDM/InversePrompting.",
          "link": "http://arxiv.org/abs/2103.10685",
          "publishedOn": "2021-06-15T01:45:14.275Z",
          "wordCount": 641,
          "title": "Controllable Generation from Pre-trained Language Models via Inverse Prompting. (arXiv:2103.10685v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03469",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xia_M/0/1/0/all/0/1\">Menglin Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monti_E/0/1/0/all/0/1\">Emilio Monti</a>",
          "description": "Multilingual semantic parsing is a cost-effective method that allows a single\nmodel to understand different languages. However, researchers face a great\nimbalance of availability of training data, with English being resource rich,\nand other languages having much less data. To tackle the data limitation\nproblem, we propose using machine translation to bootstrap multilingual\ntraining data from the more abundant English data. To compensate for the data\nquality of machine translated training data, we utilize transfer learning from\npretrained multilingual encoders to further improve the model. To evaluate our\nmultilingual models on human-written sentences as opposed to machine translated\nones, we introduce a new multilingual semantic parsing dataset in English,\nItalian and Japanese based on the Facebook Task Oriented Parsing (TOP) dataset.\nWe show that joint multilingual training with pretrained encoders substantially\noutperforms our baselines on the TOP dataset and outperforms the\nstate-of-the-art model on the public NLMaps dataset. We also establish a new\nbaseline for zero-shot learning on the TOP dataset. We find that a semantic\nparser trained only on English data achieves a zero-shot performance of 44.9%\nexact-match accuracy on Italian sentences.",
          "link": "http://arxiv.org/abs/2106.03469",
          "publishedOn": "2021-06-15T01:45:14.234Z",
          "wordCount": 623,
          "title": "Multilingual Neural Semantic Parsing for Low-Resourced Languages. (arXiv:2106.03469v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1906.01154",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schmaltz_A/0/1/0/all/0/1\">Allen Schmaltz</a>",
          "description": "We propose a new, more actionable view of neural network interpretability and\ndata analysis by leveraging the remarkable matching effectiveness of\nrepresentations derived from deep networks, guided by an approach for\nclass-conditional feature detection. The decomposition of the filter-ngram\ninteractions of a convolutional neural network and a linear layer over a\npre-trained deep network yields a strong binary sequence labeler, with\nflexibility in producing predictions at -- and defining loss functions for --\nvarying label granularities, from the fully-supervised sequence labeling\nsetting to the challenging zero-shot sequence labeling setting, in which we\nseek token-level predictions but only have document-level labels for training.\nFrom this sequence-labeling layer we derive dense representations of the input\nthat can then be matched to instances from training, or a support set with\nknown labels. Such introspection with inference-time decision rules provides a\nmeans, in some settings, of making local updates to the model by altering the\nlabels or instances in the support set without re-training the full model.\nFinally, we construct a particular K-nearest neighbors (K-NN) model from\nmatched exemplar representations that approximates the original model's\npredictions and is at least as effective a predictor with respect to the\nground-truth labels. This additionally yields interpretable heuristics at the\ntoken level for determining when predictions are less likely to be reliable,\nand for screening input dissimilar to the support set. In effect, we show that\nwe can transform the deep network into a simple weighting over exemplars and\nassociated labels, yielding an introspectable -- and modestly updatable --\nversion of the original model.",
          "link": "http://arxiv.org/abs/1906.01154",
          "publishedOn": "2021-06-15T01:45:14.214Z",
          "wordCount": 760,
          "title": "Detecting Local Insights from Global Labels: Supervised & Zero-Shot Sequence Labeling via a Convolutional Decomposition. (arXiv:1906.01154v6 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.00981",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gusev_I/0/1/0/all/0/1\">Ilya Gusev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smurov_I/0/1/0/all/0/1\">Ivan Smurov</a>",
          "description": "This paper presents the results of the Russian News Clustering and Headline\nSelection shared task. As a part of it, we propose the tasks of Russian news\nevent detection, headline selection, and headline generation. These tasks are\naccompanied by datasets and baselines. The presented datasets for event\ndetection and headline selection are the first public Russian datasets for\ntheir tasks. The headline generation dataset is based on clustering and\nprovides multiple reference headlines for every cluster, unlike the previous\ndatasets. Finally, the approaches proposed by the shared task participants are\nreported and analyzed.",
          "link": "http://arxiv.org/abs/2105.00981",
          "publishedOn": "2021-06-15T01:45:14.144Z",
          "wordCount": 557,
          "title": "Russian News Clustering and Headline Selection Shared Task. (arXiv:2105.00981v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.09261",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1\">Xu Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Boyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Han Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miao_C/0/1/0/all/0/1\">Chunyan Miao</a>",
          "description": "The existence of multiple datasets for sarcasm detection prompts us to apply\ntransfer learning to exploit their commonality. The adversarial neural transfer\n(ANT) framework utilizes multiple loss terms that encourage the source-domain\nand the target-domain feature distributions to be similar while optimizing for\ndomain-specific performance. However, these objectives may be in conflict,\nwhich can lead to optimization difficulties and sometimes diminished transfer.\nWe propose a generalized latent optimization strategy that allows different\nlosses to accommodate each other and improves training dynamics. The proposed\nmethod outperforms transfer learning and meta-learning baselines. In\nparticular, we achieve 10.02% absolute performance gain over the previous state\nof the art on the iSarcasm dataset.",
          "link": "http://arxiv.org/abs/2104.09261",
          "publishedOn": "2021-06-15T01:45:14.126Z",
          "wordCount": 579,
          "title": "Latent-Optimized Adversarial Neural Transfer for Sarcasm Detection. (arXiv:2104.09261v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06944",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yan_H/0/1/0/all/0/1\">Hua Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_W/0/1/0/all/0/1\">Weikang Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_F/0/1/0/all/0/1\">Feng Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jian Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_F/0/1/0/all/0/1\">Furao Shen</a>",
          "description": "Subtext is a kind of deep semantics which can be acquired after one or more\nrounds of expression transformation. As a popular way of expressing one's\nintentions, it is well worth studying. In this paper, we try to make computers\nunderstand whether there is a subtext by means of machine learning. We build a\nChinese dataset whose source data comes from the popular social media (e.g.\nWeibo, Netease Music, Zhihu, and Bilibili). In addition, we also build a\nbaseline model called SASICM to deal with subtext recognition. The F1 score of\nSASICMg, whose pretrained model is GloVe, is as high as 64.37%, which is 3.97%\nhigher than that of BERT based model, 12.7% higher than that of traditional\nmethods on average, including support vector machine, logistic regression\nclassifier, maximum entropy classifier, naive bayes classifier and decision\ntree and 2.39% higher than that of the state-of-the-art, including MARIN and\nBTM. The F1 score of SASICMBERT, whose pretrained model is BERT, is 65.12%,\nwhich is 0.75% higher than that of SASICMg. The accuracy rates of SASICMg and\nSASICMBERT are 71.16% and 70.76%, respectively, which can compete with those of\nother methods which are mentioned before.",
          "link": "http://arxiv.org/abs/2106.06944",
          "publishedOn": "2021-06-15T01:45:14.106Z",
          "wordCount": 647,
          "title": "SASICM A Multi-Task Benchmark For Subtext Recognition. (arXiv:2106.06944v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2003.00330",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lamb_L/0/1/0/all/0/1\">Luis C. Lamb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garcez_A/0/1/0/all/0/1\">Artur Garcez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gori_M/0/1/0/all/0/1\">Marco Gori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prates_M/0/1/0/all/0/1\">Marcelo Prates</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Avelar_P/0/1/0/all/0/1\">Pedro Avelar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vardi_M/0/1/0/all/0/1\">Moshe Vardi</a>",
          "description": "Neural-symbolic computing has now become the subject of interest of both\nacademic and industry research laboratories. Graph Neural Networks (GNN) have\nbeen widely used in relational and symbolic domains, with widespread\napplication of GNNs in combinatorial optimization, constraint satisfaction,\nrelational reasoning and other scientific domains. The need for improved\nexplainability, interpretability and trust of AI systems in general demands\nprincipled methodologies, as suggested by neural-symbolic computing. In this\npaper, we review the state-of-the-art on the use of GNNs as a model of\nneural-symbolic computing. This includes the application of GNNs in several\ndomains as well as its relationship to current developments in neural-symbolic\ncomputing.",
          "link": "http://arxiv.org/abs/2003.00330",
          "publishedOn": "2021-06-15T01:45:14.041Z",
          "wordCount": 645,
          "title": "Graph Neural Networks Meet Neural-Symbolic Computing: A Survey and Perspective. (arXiv:2003.00330v7 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.00151",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Le_H/0/1/0/all/0/1\">Hung Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sankar_C/0/1/0/all/0/1\">Chinnadhurai Sankar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moon_S/0/1/0/all/0/1\">Seungwhan Moon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beirami_A/0/1/0/all/0/1\">Ahmad Beirami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geramifard_A/0/1/0/all/0/1\">Alborz Geramifard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kottur_S/0/1/0/all/0/1\">Satwik Kottur</a>",
          "description": "A video-grounded dialogue system is required to understand both dialogue,\nwhich contains semantic dependencies from turn to turn, and video, which\ncontains visual cues of spatial and temporal scene variations. Building such\ndialogue systems is a challenging problem, involving various reasoning types on\nboth visual and language inputs. Existing benchmarks do not have enough\nannotations to thoroughly analyze dialogue systems and understand their\ncapabilities and limitations in isolation. These benchmarks are also not\nexplicitly designed to minimise biases that models can exploit without actual\nreasoning. To address these limitations, in this paper, we present DVD, a\nDiagnostic Dataset for Video-grounded Dialogues. The dataset is designed to\ncontain minimal biases and has detailed annotations for the different types of\nreasoning over the spatio-temporal space of video. Dialogues are synthesized\nover multiple question turns, each of which is injected with a set of\ncross-turn semantic relationships. We use DVD to analyze existing approaches,\nproviding interesting insights into their abilities and limitations. In total,\nDVD is built from $11k$ CATER synthetic videos and contains $10$ instances of\n$10$-round dialogues for each video, resulting in more than $100k$ dialogues\nand $1M$ question-answer pairs. Our code and dataset are publicly available at\nhttps://github.com/facebookresearch/DVDialogues.",
          "link": "http://arxiv.org/abs/2101.00151",
          "publishedOn": "2021-06-15T01:45:14.016Z",
          "wordCount": 688,
          "title": "DVD: A Diagnostic Dataset for Multi-step Reasoning in Video Grounded Dialogue. (arXiv:2101.00151v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.12919",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pryzant_R/0/1/0/all/0/1\">Reid Pryzant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Card_D/0/1/0/all/0/1\">Dallas Card</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jurafsky_D/0/1/0/all/0/1\">Dan Jurafsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Veitch_V/0/1/0/all/0/1\">Victor Veitch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sridhar_D/0/1/0/all/0/1\">Dhanya Sridhar</a>",
          "description": "We consider the problem of using observational data to estimate the causal\neffects of linguistic properties. For example, does writing a complaint\npolitely lead to a faster response time? How much will a positive product\nreview increase sales? This paper addresses two technical challenges related to\nthe problem before developing a practical method. First, we formalize the\ncausal quantity of interest as the effect of a writer's intent, and establish\nthe assumptions necessary to identify this from observational data. Second, in\npractice, we only have access to noisy proxies for the linguistic properties of\ninterest -- e.g., predictions from classifiers and lexicons. We propose an\nestimator for this setting and prove that its bias is bounded when we perform\nan adjustment for the text. Based on these results, we introduce TextCause, an\nalgorithm for estimating causal effects of linguistic properties. The method\nleverages (1) distant supervision to improve the quality of noisy proxies, and\n(2) a pre-trained language model (BERT) to adjust for the text. We show that\nthe proposed method outperforms related approaches when estimating the effect\nof Amazon review sentiment on semi-simulated sales figures. Finally, we present\nan applied case study investigating the effects of complaint politeness on\nbureaucratic response times.",
          "link": "http://arxiv.org/abs/2010.12919",
          "publishedOn": "2021-06-15T01:45:14.004Z",
          "wordCount": 705,
          "title": "Causal Effects of Linguistic Properties. (arXiv:2010.12919v5 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06849",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Laverghetta_A/0/1/0/all/0/1\">Antonio Laverghetta Jr.</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nighojkar_A/0/1/0/all/0/1\">Animesh Nighojkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mirzakhalov_J/0/1/0/all/0/1\">Jamshidbek Mirzakhalov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Licato_J/0/1/0/all/0/1\">John Licato</a>",
          "description": "Transformer-based language models (LMs) continue to advance state-of-the-art\nperformance on NLP benchmark tasks, including tasks designed to mimic\nhuman-inspired \"commonsense\" competencies. To better understand the degree to\nwhich LMs can be said to have certain linguistic reasoning skills, researchers\nare beginning to adapt the tools and concepts of the field of psychometrics.\nBut to what extent can the benefits flow in the other direction? I.e., can LMs\nbe of use in predicting what the psychometric properties of test items will be\nwhen those items are given to human participants? We gather responses from\nnumerous human participants and LMs (transformer and non-transformer-based) on\na broad diagnostic test of linguistic competencies. We then use the responses\nto calculate standard psychometric properties of the items in the diagnostic\ntest, using the human responses and the LM responses separately. We then\ndetermine how well these two sets of predictions match. We find cases in which\ntransformer-based LMs predict psychometric properties consistently well in\ncertain categories but consistently poorly in others, thus providing new\ninsights into fundamental similarities and differences between human and LM\nreasoning.",
          "link": "http://arxiv.org/abs/2106.06849",
          "publishedOn": "2021-06-15T01:45:13.991Z",
          "wordCount": 619,
          "title": "Can Transformer Language Models Predict Psychometric Properties?. (arXiv:2106.06849v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06905",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1\">Runshi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_P/0/1/0/all/0/1\">Pengda Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuhong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_W/0/1/0/all/0/1\">Weigao Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_K/0/1/0/all/0/1\">Kefeng Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qiang Wu</a>",
          "description": "E-commerce companies have to face abnormal sellers who sell potentially-risky\nproducts. Typically, the risk can be identified by jointly considering product\ncontent (e.g., title and image) and seller behavior. This work focuses on\nbehavior feature extraction as behavior sequences can provide valuable clues\nfor the risk discovery by reflecting the sellers' operation habits. Traditional\nfeature extraction techniques heavily depend on domain experts and adapt poorly\nto new tasks. In this paper, we propose a self-supervised method InfoBehavior\nto automatically extract meaningful representations from ultra-long raw\nbehavior sequences instead of the costly feature selection procedure.\nInfoBehavior utilizes Bidirectional Transformer as feature encoder due to its\nexcellent capability in modeling long-term dependency. However, it is\nintractable for commodity GPUs because the time and memory required by\nTransformer grow quadratically with the increase of sequence length. Thus, we\npropose a hierarchical grouping strategy to aggregate ultra-long raw behavior\nsequences to length-processable high-level embedding sequences. Moreover, we\nintroduce two types of pretext tasks. Sequence-related pretext task defines a\ncontrastive-based training objective to correctly select the masked-out\ncoarse-grained/fine-grained behavior sequences against other \"distractor\"\nbehavior sequences; Domain-related pretext task designs a classification\ntraining objective to correctly predict the domain-specific statistical results\nof anomalous behavior. We show that behavior representations from the\npre-trained InfoBehavior can be directly used or integrated with features from\nother side information to support a wide range of downstream tasks.\nExperimental results demonstrate that InfoBehavior significantly improves the\nperformance of Product Risk Management and Intellectual Property Protection.",
          "link": "http://arxiv.org/abs/2106.06905",
          "publishedOn": "2021-06-15T01:45:13.984Z",
          "wordCount": 682,
          "title": "InfoBehavior: Self-supervised Representation Learning for Ultra-long Behavior Sequence via Hierarchical Grouping. (arXiv:2106.06905v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06697",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ventura_F/0/1/0/all/0/1\">Francesco Ventura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Greco_S/0/1/0/all/0/1\">Salvatore Greco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Apiletti_D/0/1/0/all/0/1\">Daniele Apiletti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cerquitelli_T/0/1/0/all/0/1\">Tania Cerquitelli</a>",
          "description": "Despite the high accuracy offered by state-of-the-art deep natural-language\nmodels (e.g. LSTM, BERT), their application in real-life settings is still\nwidely limited, as they behave like a black-box to the end-user. Hence,\nexplainability is rapidly becoming a fundamental requirement of\nfuture-generation data-driven systems based on deep-learning approaches.\nSeveral attempts to fulfill the existing gap between accuracy and\ninterpretability have been done. However, robust and specialized xAI\n(Explainable Artificial Intelligence) solutions tailored to deep\nnatural-language models are still missing. We propose a new framework, named\nT-EBAnO, which provides innovative prediction-local and class-based\nmodel-global explanation strategies tailored to black-box deep natural-language\nmodels. Given a deep NLP model and the textual input data, T-EBAnO provides an\nobjective, human-readable, domain-specific assessment of the reasons behind the\nautomatic decision-making process. Specifically, the framework extracts sets of\ninterpretable features mining the inner knowledge of the model. Then, it\nquantifies the influence of each feature during the prediction process by\nexploiting the novel normalized Perturbation Influence Relation index at the\nlocal level and the novel Global Absolute Influence and Global Relative\nInfluence indexes at the global level. The effectiveness and the quality of the\nlocal and global explanations obtained with T-EBAnO are proved on (i) a\nsentiment analysis task performed by a fine-tuned BERT model, and (ii) a toxic\ncomment classification task performed by an LSTM model.",
          "link": "http://arxiv.org/abs/2106.06697",
          "publishedOn": "2021-06-15T01:45:13.965Z",
          "wordCount": 655,
          "title": "Explaining the Deep Natural Language Processing by Mining Textual Interpretable Features. (arXiv:2106.06697v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06830",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1\">Anthony Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gudipati_P/0/1/0/all/0/1\">Pallavi Gudipati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Longpre_S/0/1/0/all/0/1\">Shayne Longpre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_X/0/1/0/all/0/1\">Xiao Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Sameer Singh</a>",
          "description": "Retrieval is a core component for open-domain NLP tasks. In open-domain\ntasks, multiple entities can share a name, making disambiguation an inherent\nyet under-explored problem. We propose an evaluation benchmark for assessing\nthe entity disambiguation capabilities of these retrievers, which we call\nAmbiguous Entity Retrieval (AmbER) sets. We define an AmbER set as a collection\nof entities that share a name along with queries about those entities. By\ncovering the set of entities for polysemous names, AmbER sets act as a\nchallenging test of entity disambiguation. We create AmbER sets for three\npopular open-domain tasks: fact checking, slot filling, and question answering,\nand evaluate a diverse set of retrievers. We find that the retrievers exhibit\npopularity bias, significantly under-performing on rarer entities that share a\nname, e.g., they are twice as likely to retrieve erroneous documents on queries\nfor the less popular entity under the same name. These experiments on AmbER\nsets show their utility as an evaluation tool and highlight the weaknesses of\npopular retrieval systems.",
          "link": "http://arxiv.org/abs/2106.06830",
          "publishedOn": "2021-06-15T01:45:13.954Z",
          "wordCount": 604,
          "title": "Evaluating Entity Disambiguation and the Role of Popularity in Retrieval-Based NLP. (arXiv:2106.06830v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2010.05594",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Han_T/0/1/0/all/0/1\">Ting Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Ximing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takanobu_R/0/1/0/all/0/1\">Ryuichi Takanobu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lian_Y/0/1/0/all/0/1\">Yixin Lian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1\">Chongxuan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_D/0/1/0/all/0/1\">Dazhen Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1\">Wei Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Minlie Huang</a>",
          "description": "Task-oriented dialogue systems have made unprecedented progress with multiple\nstate-of-the-art (SOTA) models underpinned by a number of publicly available\nMultiWOZ datasets. Dialogue state annotations are error-prone, leading to\nsub-optimal performance. Various efforts have been put in rectifying the\nannotation errors presented in the original MultiWOZ dataset. In this paper, we\nintroduce MultiWOZ 2.3, in which we differentiate incorrect annotations in\ndialogue acts from dialogue states, identifying a lack of co-reference when\npublishing the updated dataset. To ensure consistency between dialogue acts and\ndialogue states, we implement co-reference features and unify annotations of\ndialogue acts and dialogue states. We update the state of the art performance\nof natural language understanding and dialogue state tracking on MultiWOZ 2.3,\nwhere the results show significant improvements than on previous versions of\nMultiWOZ datasets (2.0-2.2).",
          "link": "http://arxiv.org/abs/2010.05594",
          "publishedOn": "2021-06-15T01:45:13.945Z",
          "wordCount": 615,
          "title": "MultiWOZ 2.3: A multi-domain task-oriented dialogue dataset enhanced with annotation corrections and co-reference annotation. (arXiv:2010.05594v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06636",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Junkun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1\">Mingbo Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_R/0/1/0/all/0/1\">Renjie Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1\">Liang Huang</a>",
          "description": "Simultaneous speech-to-text translation is widely useful in many scenarios.\nThe conventional cascaded approach uses a pipeline of streaming ASR followed by\nsimultaneous MT, but suffers from error propagation and extra latency. To\nalleviate these issues, recent efforts attempt to directly translate the source\nspeech into target text simultaneously, but this is much harder due to the\ncombination of two separate tasks. We instead propose a new paradigm with the\nadvantages of both cascaded and end-to-end approaches. The key idea is to use\ntwo separate, but synchronized, decoders on streaming ASR and direct\nspeech-to-text translation (ST), respectively, and the intermediate results of\nASR guide the decoding policy of (but is not fed as input to) ST. During\ntraining time, we use multitask learning to jointly learn these two tasks with\na shared encoder. En-to-De and En-to-Es experiments on the MuSTC dataset\ndemonstrate that our proposed technique achieves substantially better\ntranslation quality at similar levels of latency.",
          "link": "http://arxiv.org/abs/2106.06636",
          "publishedOn": "2021-06-15T01:45:13.937Z",
          "wordCount": 590,
          "title": "Direct Simultaneous Speech-to-Text Translation Assisted by Synchronized Streaming ASR. (arXiv:2106.06636v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2005.00613",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zeqiu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galley_M/0/1/0/all/0/1\">Michel Galley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brockett_C/0/1/0/all/0/1\">Chris Brockett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yizhe Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1\">Xiang Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quirk_C/0/1/0/all/0/1\">Chris Quirk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koncel_Kedziorski_R/0/1/0/all/0/1\">Rik Koncel-Kedziorski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1\">Hannaneh Hajishirzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ostendorf_M/0/1/0/all/0/1\">Mari Ostendorf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dolan_B/0/1/0/all/0/1\">Bill Dolan</a>",
          "description": "Current end-to-end neural conversation models inherently lack the flexibility\nto impose semantic control in the response generation process, often resulting\nin uninteresting responses. Attempts to boost informativeness alone come at the\nexpense of factual accuracy, as attested by pretrained language models'\npropensity to \"hallucinate\" facts. While this may be mitigated by access to\nbackground knowledge, there is scant guarantee of relevance and informativeness\nin generated responses. We propose a framework that we call controllable\ngrounded response generation (CGRG), in which lexical control phrases are\neither provided by a user or automatically extracted by a control phrase\npredictor from dialogue context and grounding knowledge. Quantitative and\nqualitative results show that, using this framework, a transformer based model\nwith a novel inductive attention mechanism, trained on a conversation-like\nReddit dataset, outperforms strong generation baselines.",
          "link": "http://arxiv.org/abs/2005.00613",
          "publishedOn": "2021-06-15T01:45:13.922Z",
          "wordCount": 604,
          "title": "A Controllable Model of Grounded Response Generation. (arXiv:2005.00613v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06786",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lamb_A/0/1/0/all/0/1\">Alex Lamb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clanuwat_T/0/1/0/all/0/1\">Tarin Clanuwat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Siyu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bober_Irizar_M/0/1/0/all/0/1\">Mikel Bober-Irizar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kitamoto_A/0/1/0/all/0/1\">Asanobu Kitamoto</a>",
          "description": "Japan is a unique country with a distinct cultural heritage, which is\nreflected in billions of historical documents that have been preserved.\nHowever, the change in Japanese writing system in 1900 made these documents\ninaccessible for the general public. A major research project has been to make\nthese historical documents accessible and understandable. An increasing amount\nof research has focused on the character recognition task and the location of\ncharacters on image, yet less research has focused on how to predict the\nsequential ordering of the characters. This is because sequence in classical\nJapanese is very different from modern Japanese. Ordering characters into a\nsequence is important for making the document text easily readable and\nsearchable. Additionally, it is a necessary step for any kind of natural\nlanguage processing on the data (e.g. machine translation, language modeling,\nand word embeddings). We explore a few approaches to the task of predicting the\nsequential ordering of the characters: one using simple hand-crafted rules,\nanother using hand-crafted rules with adaptive thresholds, and another using a\ndeep recurrent sequence model trained with teacher forcing. We provide a\nquantitative and qualitative comparison of these techniques as well as their\ndistinct trade-offs. Our best-performing system has an accuracy of 98.65\\% and\nhas a perfect accuracy on 49\\% of the books in our dataset, suggesting that the\ntechnique is able to predict the order of the characters well enough for many\ntasks.",
          "link": "http://arxiv.org/abs/2106.06786",
          "publishedOn": "2021-06-15T01:45:13.898Z",
          "wordCount": 673,
          "title": "Predicting the Ordering of Characters in Japanese Historical Documents. (arXiv:2106.06786v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2008.05221",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_M/0/1/0/all/0/1\">Manish Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_P/0/1/0/all/0/1\">Puneet Agrawal</a>",
          "description": "In recent years, the fields of natural language processing (NLP) and\ninformation retrieval (IR) have made tremendous progress thanksto deep learning\nmodels like Recurrent Neural Networks (RNNs), Gated Recurrent Units (GRUs) and\nLong Short-Term Memory (LSTMs)networks, and Transformer [120] based models like\nBidirectional Encoder Representations from Transformers (BERT) [24],\nGenerativePre-training Transformer (GPT-2) [94], Multi-task Deep Neural Network\n(MT-DNN) [73], Extra-Long Network (XLNet) [134], Text-to-text transfer\ntransformer (T5) [95], T-NLG [98] and GShard [63]. But these models are\nhumongous in size. On the other hand,real world applications demand small model\nsize, low response times and low computational power wattage. In this survey,\nwediscuss six different types of methods (Pruning, Quantization, Knowledge\nDistillation, Parameter Sharing, Tensor Decomposition, andSub-quadratic\nTransformer based methods) for compression of such models to enable their\ndeployment in real industry NLP projects.Given the critical need of building\napplications with efficient and small models, and the large amount of recently\npublished work inthis area, we believe that this survey organizes the plethora\nof work done by the 'deep learning for NLP' community in the past fewyears and\npresents it as a coherent story.",
          "link": "http://arxiv.org/abs/2008.05221",
          "publishedOn": "2021-06-15T01:45:13.888Z",
          "wordCount": 675,
          "title": "Compression of Deep Learning Models for Text: A Survey. (arXiv:2008.05221v4 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06909",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1\">Guoguo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chai_S/0/1/0/all/0/1\">Shuzhou Chai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Guanbo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_J/0/1/0/all/0/1\">Jiayu Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wei-Qiang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weng_C/0/1/0/all/0/1\">Chao Weng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_D/0/1/0/all/0/1\">Dan Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Povey_D/0/1/0/all/0/1\">Daniel Povey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trmal_J/0/1/0/all/0/1\">Jan Trmal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Junbo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_M/0/1/0/all/0/1\">Mingjie Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khudanpur_S/0/1/0/all/0/1\">Sanjeev Khudanpur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watanabe_S/0/1/0/all/0/1\">Shinji Watanabe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Shuaijiang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_W/0/1/0/all/0/1\">Wei Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiangang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_X/0/1/0/all/0/1\">Xuchen Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yongqing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yujun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_Z/0/1/0/all/0/1\">Zhao You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1\">Zhiyong Yan</a>",
          "description": "This paper introduces GigaSpeech, an evolving, multi-domain English speech\nrecognition corpus with 10,000 hours of high quality labeled audio suitable for\nsupervised training, and 40,000 hours of total audio suitable for\nsemi-supervised and unsupervised training. Around 40,000 hours of transcribed\naudio is first collected from audiobooks, podcasts and YouTube, covering both\nread and spontaneous speaking styles, and a variety of topics, such as arts,\nscience, sports, etc. A new forced alignment and segmentation pipeline is\nproposed to create sentence segments suitable for speech recognition training,\nand to filter out segments with low-quality transcription. For system training,\nGigaSpeech provides five subsets of different sizes, 10h, 250h, 1000h, 2500h,\nand 10000h. For our 10,000-hour XL training subset, we cap the word error rate\nat 4% during the filtering/validation stage, and for all our other smaller\ntraining subsets, we cap it at 0%. The DEV and TEST evaluation sets, on the\nother hand, are re-processed by professional human transcribers to ensure high\ntranscription quality. Baseline systems are provided for popular speech\nrecognition toolkits, namely Athena, ESPnet, Kaldi and Pika.",
          "link": "http://arxiv.org/abs/2106.06909",
          "publishedOn": "2021-06-15T01:45:13.880Z",
          "wordCount": 651,
          "title": "GigaSpeech: An Evolving, Multi-domain ASR Corpus with 10,000 Hours of Transcribed Audio. (arXiv:2106.06909v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06598",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shon_S/0/1/0/all/0/1\">Suwon Shon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brusco_P/0/1/0/all/0/1\">Pablo Brusco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1\">Jing Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_K/0/1/0/all/0/1\">Kyu J. Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watanabe_S/0/1/0/all/0/1\">Shinji Watanabe</a>",
          "description": "In this paper, we explore the use of pre-trained language models to learn\nsentiment information of written texts for speech sentiment analysis. First, we\ninvestigate how useful a pre-trained language model would be in a 2-step\npipeline approach employing Automatic Speech Recognition (ASR) and\ntranscripts-based sentiment analysis separately. Second, we propose a pseudo\nlabel-based semi-supervised training strategy using a language model on an\nend-to-end speech sentiment approach to take advantage of a large, but\nunlabeled speech dataset for training. Although spoken and written texts have\ndifferent linguistic characteristics, they can complement each other in\nunderstanding sentiment. Therefore, the proposed system can not only model\nacoustic characteristics to bear sentiment-specific information in speech\nsignals, but learn latent information to carry sentiments in the text\nrepresentation. In these experiments, we demonstrate the proposed approaches\nimprove F1 scores consistently compared to systems without a language model.\nMoreover, we also show that the proposed framework can reduce 65% of human\nsupervision by leveraging a large amount of data without human sentiment\nannotation and boost performance in a low-resource condition where the human\nsentiment annotation is not available enough.",
          "link": "http://arxiv.org/abs/2106.06598",
          "publishedOn": "2021-06-15T01:45:13.854Z",
          "wordCount": 626,
          "title": "Leveraging Pre-trained Language Model for Speech Sentiment Analysis. (arXiv:2106.06598v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06566",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vaduguru_S/0/1/0/all/0/1\">Saujas Vaduguru</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sathe_A/0/1/0/all/0/1\">Aalok Sathe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choudhury_M/0/1/0/all/0/1\">Monojit Choudhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_D/0/1/0/all/0/1\">Dipti Misra Sharma</a>",
          "description": "Neural models excel at extracting statistical patterns from large amounts of\ndata, but struggle to learn patterns or reason about language from only a few\nexamples. In this paper, we ask: Can we learn explicit rules that generalize\nwell from only a few examples? We explore this question using program\nsynthesis. We develop a synthesis model to learn phonology rules as programs in\na domain-specific language. We test the ability of our models to generalize\nfrom few training examples using our new dataset of problems from the\nLinguistics Olympiad, a challenging set of tasks that require strong linguistic\nreasoning ability. In addition to being highly sample-efficient, our approach\ngenerates human-readable programs, and allows control over the generalizability\nof the learnt programs.",
          "link": "http://arxiv.org/abs/2106.06566",
          "publishedOn": "2021-06-15T01:45:13.785Z",
          "wordCount": 554,
          "title": "Sample-efficient Linguistic Generalizations through Program Synthesis: Experiments with Phonology Problems. (arXiv:2106.06566v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06964",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tikhonov_A/0/1/0/all/0/1\">Alexey Tikhonov</a>",
          "description": "Pre-trained word representations became a key component in many NLP tasks.\nHowever, the global geometry of the word embeddings remains poorly understood.\nIn this paper, we demonstrate that a typical word embeddings cloud is shaped as\na high-dimensional simplex with interpretable vertices and propose a simple yet\neffective method for enumeration of these vertices. We show that the proposed\nmethod can detect and describe vertices of the simplex for GloVe and fasttext\nspaces.",
          "link": "http://arxiv.org/abs/2106.06964",
          "publishedOn": "2021-06-15T01:45:13.760Z",
          "wordCount": 514,
          "title": "Shape of Elephant: Study of Macro Properties of Word Embeddings Spaces. (arXiv:2106.06964v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2009.09162",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zeqiu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koncel_Kedziorski_R/0/1/0/all/0/1\">Rik Koncel-Kedziorski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ostendorf_M/0/1/0/all/0/1\">Mari Ostendorf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1\">Hannaneh Hajishirzi</a>",
          "description": "Knowledge graphs capture entities and relations from long documents and can\nfacilitate reasoning in many downstream applications. Extracting compact\nknowledge graphs containing only salient entities and relations is important\nbut challenging for understanding and summarizing long documents. We introduce\na new text-to-graph task of predicting summarized knowledge graphs from long\ndocuments. We develop a dataset of 200k document/graph pairs using automatic\nand human annotations. We also develop strong baselines for this task based on\ngraph learning and text summarization, and provide quantitative and qualitative\nstudies of their effect.",
          "link": "http://arxiv.org/abs/2009.09162",
          "publishedOn": "2021-06-15T01:45:13.751Z",
          "wordCount": 541,
          "title": "Extracting Summary Knowledge Graphs from Long Documents. (arXiv:2009.09162v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06683",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jialu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Eric Wang</a>",
          "description": "Recently pre-trained multimodal models, such as CLIP, have received a surge\nof attention for their exceptional capabilities towards connecting images and\nnatural language. The textual representations in English can be desirably\ntransferred to multilingualism and support promising downstream multimodal\ntasks for different languages. Nevertheless, previous fairness discourse in\nvision-and-language learning mainly focuses on monolingual representational\nbiases, and rarely scrutinizes the principles of multilingual fairness in this\nmultimodal setting, where one language is equated to a group of individuals and\nimages provide the universal grounding for bridging different languages.\n\nIn this paper, we provide a nuanced understanding of individual fairness and\ngroup fairness by viewing language as the recipient of fairness notions. We\ndefine new fairness notions within multilingual context and analytically\narticulate that, pre-trained vision-and-language representations are\nindividually fair across languages but not guaranteed to group fairness.\nFurthermore, we conduct extensive experiments to explore the prevalent group\ndisparity across languages and protected groups including race, gender and age.",
          "link": "http://arxiv.org/abs/2106.06683",
          "publishedOn": "2021-06-15T01:45:13.490Z",
          "wordCount": 593,
          "title": "Assessing Multilingual Fairness in Pre-trained Multimodal Representations. (arXiv:2106.06683v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06910",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_A/0/1/0/all/0/1\">Arunava Kumar Chakraborty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1\">Sourav Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolya_A/0/1/0/all/0/1\">Anup Kumar Kolya</a>",
          "description": "As the Covid-19 outbreaks rapidly all over the world day by day and also\naffects the lives of million, a number of countries declared complete lock-down\nto check its intensity. During this lockdown period, social media plat-forms\nhave played an important role to spread information about this pandemic across\nthe world, as people used to express their feelings through the social\nnetworks. Considering this catastrophic situation, we developed an experimental\napproach to analyze the reactions of people on Twitter taking into ac-count the\npopular words either directly or indirectly based on this pandemic. This paper\nrepresents the sentiment analysis on collected large number of tweets on\nCoronavirus or Covid-19. At first, we analyze the trend of public sentiment on\nthe topics related to Covid-19 epidemic using an evolutionary classification\nfollowed by the n-gram analysis. Then we calculated the sentiment ratings on\ncollected tweet based on their class. Finally, we trained the long-short term\nnetwork using two types of rated tweets to predict sentiment on Covid-19 data\nand obtained an overall accuracy of 84.46%.",
          "link": "http://arxiv.org/abs/2106.06910",
          "publishedOn": "2021-06-15T01:45:13.433Z",
          "wordCount": 680,
          "title": "Sentiment Analysis of Covid-19 Tweets using Evolutionary Classification-Based LSTM Model. (arXiv:2106.06910v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06600",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yasunaga_M/0/1/0/all/0/1\">Michihiro Yasunaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1\">Percy Liang</a>",
          "description": "We consider repair tasks: given a critic (e.g., compiler) that assesses the\nquality of an input, the goal is to train a fixer that converts a bad example\n(e.g., code with syntax errors) into a good one (e.g., code with no errors).\nExisting works create training data consisting of (bad, good) pairs by\ncorrupting good examples using heuristics (e.g., dropping tokens). However,\nfixers trained on this synthetically-generated data do not extrapolate well to\nthe real distribution of bad inputs. To bridge this gap, we propose a new\ntraining approach, Break-It-Fix-It (BIFI), which has two key ideas: (i) we use\nthe critic to check a fixer's output on real bad inputs and add good (fixed)\noutputs to the training data, and (ii) we train a breaker to generate realistic\nbad code from good code. Based on these ideas, we iteratively update the\nbreaker and the fixer while using them in conjunction to generate more paired\ndata. We evaluate BIFI on two code repair datasets: GitHub-Python, a new\ndataset we introduce where the goal is to repair Python code with AST parse\nerrors; and DeepFix, where the goal is to repair C code with compiler errors.\nBIFI outperforms existing methods, obtaining 90.5% repair accuracy on\nGitHub-Python (+28.5%) and 71.7% on DeepFix (+5.6%). Notably, BIFI does not\nrequire any labeled data; we hope it will be a strong starting point for\nunsupervised learning of various repair tasks.",
          "link": "http://arxiv.org/abs/2106.06600",
          "publishedOn": "2021-06-15T01:45:13.411Z",
          "wordCount": 669,
          "title": "Break-It-Fix-It: Unsupervised Learning for Program Repair. (arXiv:2106.06600v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06689",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhousi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Longtu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Imankulova_A/0/1/0/all/0/1\">Aizhan Imankulova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Komachi_M/0/1/0/all/0/1\">Mamoru Komachi</a>",
          "description": "We propose two fast neural combinatory models for constituency parsing:\nbinary and multi-branching. Our models decompose the bottom-up parsing process\ninto 1) classification of tags, labels, and binary orientations or chunks and\n2) vector composition based on the computed orientations or chunks. These\nmodels have theoretical sub-quadratic complexity and empirical linear\ncomplexity. The binary model achieves an F1 score of 92.54 on Penn Treebank,\nspeeding at 1327.2 sents/sec. Both the models with XLNet provide near\nstate-of-the-art accuracies for English. Syntactic branching tendency and\nheadedness of a language are observed during the training and inference\nprocesses for Penn Treebank, Chinese Treebank, and Keyaki Treebank (Japanese).",
          "link": "http://arxiv.org/abs/2106.06689",
          "publishedOn": "2021-06-15T01:45:13.402Z",
          "wordCount": 528,
          "title": "Neural Combinatory Constituency Parsing. (arXiv:2106.06689v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06739",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Siddharth_L/0/1/0/all/0/1\">L Siddharth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blessing_L/0/1/0/all/0/1\">Lucienne T.M. Blessing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wood_K/0/1/0/all/0/1\">Kristin L. Wood</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1\">Jianxi Luo</a>",
          "description": "We propose a large, scalable engineering knowledge graph, comprising sets of\n(entity, relationship, entity) triples that are real-world engineering facts\nfound in the patent database. We apply a set of rules based on the syntactic\nand lexical properties of claims in a patent document to extract facts. We\naggregate these facts within each patent document and integrate the aggregated\nsets of facts across the patent database to obtain the engineering knowledge\ngraph. Such a knowledge graph is expected to support inference, reasoning, and\nrecalling in various engineering tasks. The knowledge graph has a greater size\nand coverage in comparison with the previously used knowledge graphs and\nsemantic networks in the engineering literature.",
          "link": "http://arxiv.org/abs/2106.06739",
          "publishedOn": "2021-06-15T01:45:13.365Z",
          "wordCount": 544,
          "title": "Engineering Knowledge Graph from Patent Database. (arXiv:2106.06739v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06922",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chiu_S/0/1/0/all/0/1\">Shih-Hsuan Chiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lo_T/0/1/0/all/0/1\">Tien-Hong Lo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Berlin Chen</a>",
          "description": "An important research direction in automatic speech recognition (ASR) has\ncentered around the development of effective methods to rerank the output\nhypotheses of an ASR system with more sophisticated language models (LMs) for\nfurther gains. A current mainstream school of thoughts for ASR N-best\nhypothesis reranking is to employ a recurrent neural network (RNN)-based LM or\nits variants, with performance superiority over the conventional n-gram LMs\nacross a range of ASR tasks. In real scenarios such as a long conversation, a\nsequence of consecutive sentences may jointly contain ample cues of\nconversation-level information such as topical coherence, lexical entrainment\nand adjacency pairs, which however remains to be underexplored. In view of\nthis, we first formulate ASR N-best reranking as a prediction problem, putting\nforward an effective cross-sentence neural LM approach that reranks the ASR\nN-best hypotheses of an upcoming sentence by taking into consideration the word\nusage in its precedent sentences. Furthermore, we also explore to extract\ntask-specific global topical information of the cross-sentence history in an\nunsupervised manner for better ASR performance. Extensive experiments conducted\non the AMI conversational benchmark corpus indicate the effectiveness and\nfeasibility of our methods in comparison to several state-of-the-art reranking\nmethods.",
          "link": "http://arxiv.org/abs/2106.06922",
          "publishedOn": "2021-06-15T01:45:13.356Z",
          "wordCount": 645,
          "title": "Cross-sentence Neural Language Models for Conversational Speech Recognition. (arXiv:2106.06922v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06875",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bhatnagar_R/0/1/0/all/0/1\">Rajat Bhatnagar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganesh_A/0/1/0/all/0/1\">Ananya Ganesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kann_K/0/1/0/all/0/1\">Katharina Kann</a>",
          "description": "High-performing machine translation (MT) systems can help overcome language\nbarriers while making it possible for everyone to communicate and use language\ntechnologies in the language of their choice. However, such systems require\nlarge amounts of parallel sentences for training, and translators can be\ndifficult to find and expensive. Here, we present a data collection strategy\nfor MT which, in contrast, is cheap and simple, as it does not require\nbilingual speakers. Based on the insight that humans pay specific attention to\nmovements, we use graphics interchange formats (GIFs) as a pivot to collect\nparallel sentences from monolingual annotators. We use our strategy to collect\ndata in Hindi, Tamil and English. As a baseline, we also collect data using\nimages as a pivot. We perform an intrinsic evaluation by manually evaluating a\nsubset of the sentence pairs and an extrinsic evaluation by finetuning mBART on\nthe collected data. We find that sentences collected via GIFs are indeed of\nhigher quality.",
          "link": "http://arxiv.org/abs/2106.06875",
          "publishedOn": "2021-06-15T01:45:13.316Z",
          "wordCount": 612,
          "title": "Don't Rule Out Monolingual Speakers: A Method For Crowdsourcing Machine Translation Data. (arXiv:2106.06875v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06758",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bar_Haim_R/0/1/0/all/0/1\">Roy Bar-Haim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eden_L/0/1/0/all/0/1\">Lilach Eden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kantor_Y/0/1/0/all/0/1\">Yoav Kantor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Friedman_R/0/1/0/all/0/1\">Roni Friedman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Slonim_N/0/1/0/all/0/1\">Noam Slonim</a>",
          "description": "Previous work on review summarization focused on measuring the sentiment\ntoward the main aspects of the reviewed product or business, or on creating a\ntextual summary. These approaches provide only a partial view of the data:\naspect-based sentiment summaries lack sufficient explanation or justification\nfor the aspect rating, while textual summaries do not quantify the significance\nof each element, and are not well-suited for representing conflicting views.\nRecently, Key Point Analysis (KPA) has been proposed as a summarization\nframework that provides both textual and quantitative summary of the main\npoints in the data. We adapt KPA to review data by introducing Collective Key\nPoint Mining for better key point extraction; integrating sentiment analysis\ninto KPA; identifying good key point candidates for review summaries; and\nleveraging the massive amount of available reviews and their metadata. We show\nempirically that these novel extensions of KPA substantially improve its\nperformance. We demonstrate that promising results can be achieved without any\ndomain-specific annotation, while human supervision can lead to further\nimprovement.",
          "link": "http://arxiv.org/abs/2106.06758",
          "publishedOn": "2021-06-15T01:45:13.307Z",
          "wordCount": 604,
          "title": "Every Bite Is an Experience: Key Point Analysis of Business Reviews. (arXiv:2106.06758v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06731",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_N/0/1/0/all/0/1\">Ning Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Boxin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jinfeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiangyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhouhan Lin</a>",
          "description": "Punctuation restoration is an important post-processing step in automatic\nspeech recognition. Among other kinds of external information, part-of-speech\n(POS) taggers provide informative tags, suggesting each input token's syntactic\nrole, which has been shown to be beneficial for the punctuation restoration\ntask. In this work, we incorporate an external POS tagger and fuse its\npredicted labels into the existing language model to provide syntactic\ninformation. Besides, we propose sequence boundary sampling (SBS) to learn\npunctuation positions more efficiently as a sequence tagging task. Experimental\nresults show that our methods can consistently obtain performance gains and\nachieve a new state-of-the-art on the common IWSLT benchmark. Further ablation\nstudies illustrate that both large pre-trained language models and the external\nPOS tagger take essential parts to improve the model's performance.",
          "link": "http://arxiv.org/abs/2106.06731",
          "publishedOn": "2021-06-15T01:45:13.271Z",
          "wordCount": 559,
          "title": "Incorporating External POS Tagger for Punctuation Restoration. (arXiv:2106.06731v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06822",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yifan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_M/0/1/0/all/0/1\">Min Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Ying Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Min Li</a>",
          "description": "Automatic International Classification of Diseases (ICD) coding is defined as\na kind of text multi-label classification problem, which is difficult because\nthe number of labels is very large and the distribution of labels is\nunbalanced. The label-wise attention mechanism is widely used in automatic ICD\ncoding because it can assign weights to every word in full Electronic Medical\nRecords (EMR) for different ICD codes. However, the label-wise attention\nmechanism is computational redundant and costly. In this paper, we propose a\npseudo label-wise attention mechanism to tackle the problem. Instead of\ncomputing different attention modes for different ICD codes, the pseudo\nlabel-wise attention mechanism automatically merges similar ICD codes and\ncomputes only one attention mode for the similar ICD codes, which greatly\ncompresses the number of attention modes and improves the predicted accuracy.\nIn addition, we apply a more convenient and effective way to obtain the ICD\nvectors, and thus our model can predict new ICD codes by calculating the\nsimilarities between EMR vectors and ICD vectors. Extensive experiments show\nthe superior performance of our model. On the public MIMIC-III dataset and\nprivate Xiangya dataset, our model achieves micro f1 of 0.575 and 0.796,\nrespectively, which outperforms other competing models. Furthermore, we verify\nthe ability of our model in predicting new ICD codes. The case study shows how\npseudo label-wise attention works, and demonstrates the effectiveness of pseudo\nlabel-wise attention mechanism.",
          "link": "http://arxiv.org/abs/2106.06822",
          "publishedOn": "2021-06-15T01:45:13.259Z",
          "wordCount": 658,
          "title": "A Pseudo Label-wise Attention Network for Automatic ICD Coding. (arXiv:2106.06822v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06719",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xing_L/0/1/0/all/0/1\">Linzi Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carenini_G/0/1/0/all/0/1\">Giuseppe Carenini</a>",
          "description": "Dialogue topic segmentation is critical in several dialogue modeling\nproblems. However, popular unsupervised approaches only exploit surface\nfeatures in assessing topical coherence among utterances. In this work, we\naddress this limitation by leveraging supervisory signals from the\nutterance-pair coherence scoring task. First, we present a simple yet effective\nstrategy to generate a training corpus for utterance-pair coherence scoring.\nThen, we train a BERT-based neural utterance-pair coherence model with the\nobtained training corpus. Finally, such model is used to measure the topical\nrelevance between utterances, acting as the basis of the segmentation\ninference. Experiments on three public datasets in English and Chinese\ndemonstrate that our proposal outperforms the state-of-the-art baselines.",
          "link": "http://arxiv.org/abs/2106.06719",
          "publishedOn": "2021-06-15T01:45:13.245Z",
          "wordCount": 539,
          "title": "Improving Unsupervised Dialogue Topic Segmentation with Utterance-Pair Coherence Scoring. (arXiv:2106.06719v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06738",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jinghui Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henchion_M/0/1/0/all/0/1\">Maeve Henchion</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bacher_I/0/1/0/all/0/1\">Ivan Bacher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Namee_B/0/1/0/all/0/1\">Brian Mac Namee</a>",
          "description": "Training deep learning models with limited labelled data is an attractive\nscenario for many NLP tasks, including document classification. While with the\nrecent emergence of BERT, deep learning language models can achieve reasonably\ngood performance in document classification with few labelled instances, there\nis a lack of evidence in the utility of applying BERT-like models on long\ndocument classification. This work introduces a long-text-specific model -- the\nHierarchical BERT Model (HBM) -- that learns sentence-level features of the\ntext and works well in scenarios with limited labelled data. Various evaluation\nexperiments have demonstrated that HBM can achieve higher performance in\ndocument classification than the previous state-of-the-art methods with only 50\nto 200 labelled instances, especially when documents are long. Also, as an\nextra benefit of HBM, the salient sentences identified by learned HBM are\nuseful as explanations for labelling documents based on a user study.",
          "link": "http://arxiv.org/abs/2106.06738",
          "publishedOn": "2021-06-15T01:45:13.232Z",
          "wordCount": 579,
          "title": "A Sentence-level Hierarchical BERT Model for Document Classification with Limited Labelled Data. (arXiv:2106.06738v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.05596",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qi_Z/0/1/0/all/0/1\">Zhiyuan Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Ziheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiaoyan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_Y/0/1/0/all/0/1\">Yuejia Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yefeng Zheng</a>",
          "description": "Knowledge Graph (KG) alignment is to discover the mappings (i.e., equivalent\nentities, relations, and others) between two KGs. The existing methods can be\ndivided into the embedding-based models, and the conventional reasoning and\nlexical matching based systems. The former compute the similarity of entities\nvia their cross-KG embeddings, but they usually rely on an ideal supervised\nlearning setting for good performance and lack appropriate reasoning to avoid\nlogically wrong mappings; while the latter address the reasoning issue but are\npoor at utilizing the KG graph structures and the entity contexts. In this\nstudy, we aim at combining the above two solutions and thus propose an\niterative framework named PRASE which is based on probabilistic reasoning and\nsemantic embedding. It learns the KG embeddings via entity mappings from a\nprobabilistic reasoning system named PARIS, and feeds the resultant entity\nmappings and embeddings back into PARIS for augmentation. The PRASE framework\nis compatible with different embedding-based models, and our experiments on\nmultiple datasets have demonstrated its state-of-the-art performance.",
          "link": "http://arxiv.org/abs/2105.05596",
          "publishedOn": "2021-06-14T01:38:53.094Z",
          "wordCount": 653,
          "title": "Unsupervised Knowledge Graph Alignment by Probabilistic Reasoning and Semantic Embedding. (arXiv:2105.05596v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09680",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Sungjoon Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moon_J/0/1/0/all/0/1\">Jihyung Moon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sungdong Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_W/0/1/0/all/0/1\">Won Ik Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiyoon Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jangwon Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_C/0/1/0/all/0/1\">Chisung Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Junseong Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yongsook Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_T/0/1/0/all/0/1\">Taehwan Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Joohong Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_J/0/1/0/all/0/1\">Juhyun Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_S/0/1/0/all/0/1\">Sungwon Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeong_Y/0/1/0/all/0/1\">Younghoon Jeong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_I/0/1/0/all/0/1\">Inkwon Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seo_S/0/1/0/all/0/1\">Sangwoo Seo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Dongjun Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyunwoo Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1\">Myeonghwa Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jang_S/0/1/0/all/0/1\">Seongbo Jang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Do_S/0/1/0/all/0/1\">Seungwon Do</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sunkyoung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lim_K/0/1/0/all/0/1\">Kyungtae Lim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jongwon Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_K/0/1/0/all/0/1\">Kyumin Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1\">Jamin Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Seonghyun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_L/0/1/0/all/0/1\">Lucy Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_A/0/1/0/all/0/1\">Alice Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ha_J/0/1/0/all/0/1\">Jung-Woo Ha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1\">Kyunghyun Cho</a>",
          "description": "We introduce Korean Language Understanding Evaluation (KLUE) benchmark. KLUE\nis a collection of 8 Korean natural language understanding (NLU) tasks,\nincluding Topic Classification, SemanticTextual Similarity, Natural Language\nInference, Named Entity Recognition, Relation Extraction, Dependency Parsing,\nMachine Reading Comprehension, and Dialogue State Tracking. We build all of the\ntasks from scratch from diverse source corpora while respecting copyrights, to\nensure accessibility for anyone without any restrictions. With ethical\nconsiderations in mind, we carefully design annotation protocols. Along with\nthe benchmark tasks and data, we provide suitable evaluation metrics and\nfine-tuning recipes for pretrained language models for each task. We\nfurthermore release the pretrained language models (PLM), KLUE-BERT and\nKLUE-RoBERTa, to help reproducing baseline models on KLUE and thereby\nfacilitate future research. We make a few interesting observations from the\npreliminary experiments using the proposed KLUE benchmark suite, already\ndemonstrating the usefulness of this new benchmark suite. First, we find\nKLUE-RoBERTa-large outperforms other baselines, including multilingual PLMs and\nexisting open-source Korean PLMs. Second, we see minimal degradation in\nperformance even when we replace personally identifiable information from the\npretraining corpus, suggesting that privacy and NLU capability are not at odds\nwith each other. Lastly, we find that using BPE tokenization in combination\nwith morpheme-level pre-tokenization is effective in tasks involving\nmorpheme-level tagging, detection and generation. In addition to accelerating\nKorean NLP research, our comprehensive documentation on creating KLUE will\nfacilitate creating similar resources for other languages in the future. KLUE\nis available at https://klue-benchmark.com.",
          "link": "http://arxiv.org/abs/2105.09680",
          "publishedOn": "2021-06-14T01:38:52.938Z",
          "wordCount": 765,
          "title": "KLUE: Korean Language Understanding Evaluation. (arXiv:2105.09680v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06462",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hauer_B/0/1/0/all/0/1\">Bradley Hauer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kondrak_G/0/1/0/all/0/1\">Grzegorz Kondrak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luan_Y/0/1/0/all/0/1\">Yixing Luan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mallik_A/0/1/0/all/0/1\">Arnob Mallik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mou_L/0/1/0/all/0/1\">Lili Mou</a>",
          "description": "Acquisition of multilingual training data continues to be a challenge in word\nsense disambiguation (WSD). To address this problem, unsupervised approaches\nhave been developed in recent years that automatically generate sense\nannotations suitable for training supervised WSD systems. We present three new\nmethods to creating sense-annotated corpora, which leverage translations,\nparallel corpora, lexical resources, and contextual and synset embeddings. Our\nsemi-supervised method applies machine translation to transfer existing sense\nannotations to other languages. Our two unsupervised methods use a\nknowledge-based WSD system to annotate a parallel corpus, and refine the\nresulting sense annotations by identifying lexical translations. We obtain\nstate-of-the-art results on standard WSD benchmarks.",
          "link": "http://arxiv.org/abs/2106.06462",
          "publishedOn": "2021-06-14T01:38:52.571Z",
          "wordCount": 530,
          "title": "Semi-Supervised and Unsupervised Sense Annotation via Translations. (arXiv:2106.06462v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06524",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Serie_E/0/1/0/all/0/1\">Emmanuel S&#xe9;ri&#xe9;</a>",
          "description": "Wax is what you put on a surfboard to avoid slipping. It is an essential tool\nto go surfing... We introduce WAX-ML a research-oriented Python library\nproviding tools to design powerful machine learning algorithms and feedback\nloops working on streaming data. It strives to complement JAX with tools\ndedicated to time series. WAX-ML makes JAX-based programs easy to use for\nend-users working with pandas and xarray for data manipulation. It provides a\nsimple mechanism for implementing feedback loops, allows the implementation of\nonline learning and reinforcement learning algorithms with functions, and makes\nthem easy to integrate by end-users working with the object-oriented\nreinforcement learning framework from the Gym library. It is released with an\nApache open-source license on GitHub at https://github.com/eserie/wax-ml.",
          "link": "http://arxiv.org/abs/2106.06524",
          "publishedOn": "2021-06-14T01:38:52.530Z",
          "wordCount": 560,
          "title": "WAX-ML: A Python library for machine learning and feedback loops on streaming data. (arXiv:2106.06524v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06519",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ganesan_K/0/1/0/all/0/1\">Karthik Ganesan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bamdev_P/0/1/0/all/0/1\">Pakhi Bamdev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+B_J/0/1/0/all/0/1\">Jaivarsan B</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venugopal_A/0/1/0/all/0/1\">Amresh Venugopal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tushar_A/0/1/0/all/0/1\">Abhinav Tushar</a>",
          "description": "Spoken Language Understanding (SLU) systems parse speech into semantic\nstructures like dialog acts and slots. This involves the use of an Automatic\nSpeech Recognizer (ASR) to transcribe speech into multiple text alternatives\n(hypotheses). Transcription errors, common in ASRs, impact downstream SLU\nperformance negatively. Approaches to mitigate such errors involve using richer\ninformation from the ASR, either in form of N-best hypotheses or word-lattices.\nWe hypothesize that transformer models learn better with a simpler utterance\nrepresentation using the concatenation of the N-best ASR alternatives, where\neach alternative is separated by a special delimiter [SEP]. In our work, we\ntest our hypothesis by using concatenated N-best ASR alternatives as the input\nto transformer encoder models, namely BERT and XLM-RoBERTa, and achieve\nperformance equivalent to the prior state-of-the-art model on DSTC2 dataset. We\nalso show that our approach significantly outperforms the prior\nstate-of-the-art when subjected to the low data regime. Additionally, this\nmethodology is accessible to users of third-party ASR APIs which do not provide\nword-lattice information.",
          "link": "http://arxiv.org/abs/2106.06519",
          "publishedOn": "2021-06-14T01:38:52.520Z",
          "wordCount": 623,
          "title": "N-Best ASR Transformer: Enhancing SLU Performance using Multiple ASR Hypotheses. (arXiv:2106.06519v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2101.00010",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sinha_K/0/1/0/all/0/1\">Koustuv Sinha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parthasarathi_P/0/1/0/all/0/1\">Prasanna Parthasarathi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pineau_J/0/1/0/all/0/1\">Joelle Pineau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Williams_A/0/1/0/all/0/1\">Adina Williams</a>",
          "description": "Recent investigations into the inner-workings of state-of-the-art large-scale\npre-trained Transformer-based Natural Language Understanding (NLU) models\nindicate that they appear to know humanlike syntax, at least to some extent. We\nprovide novel evidence that complicates this claim: we find that\nstate-of-the-art Natural Language Inference (NLI) models assign the same labels\nto permuted examples as they do to the original, i.e. they are largely\ninvariant to random word-order permutations. This behavior notably differs from\nthat of humans; we struggle with ungrammatical sentences. To measure the\nseverity of this issue, we propose a suite of metrics and investigate which\nproperties of particular permutations lead models to be word-order invariant.\nIn the MNLI dataset, for example, we find almost all (98.7%) examples contain\nat least one permutation which elicits the gold label. Models are sometimes\neven able to assign gold labels to permutations that they originally failed to\npredict correctly. We provide a comprehensive empirical evaluation of this\nphenomenon, and further show that this issue exists for both Transformers and\npre-Transformer RNN / ConvNet based encoders, as well as across multiple\nlanguages (English and Mandarin Chinese). Our code and data are available at\nhttps://github.com/facebookresearch/unlu.",
          "link": "http://arxiv.org/abs/2101.00010",
          "publishedOn": "2021-06-14T01:38:52.464Z",
          "wordCount": 652,
          "title": "UnNatural Language Inference. (arXiv:2101.00010v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.06304",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Parcalabescu_L/0/1/0/all/0/1\">Letitia Parcalabescu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trost_N/0/1/0/all/0/1\">Nils Trost</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frank_A/0/1/0/all/0/1\">Anette Frank</a>",
          "description": "The last years have shown rapid developments in the field of multimodal\nmachine learning, combining e.g., vision, text or speech. In this position\npaper we explain how the field uses outdated definitions of multimodality that\nprove unfit for the machine learning era. We propose a new task-relative\ndefinition of (multi)modality in the context of multimodal machine learning\nthat focuses on representations and information that are relevant for a given\nmachine learning task. With our new definition of multimodality we aim to\nprovide a missing foundation for multimodal research, an important component of\nlanguage grounding and a crucial milestone towards NLU.",
          "link": "http://arxiv.org/abs/2103.06304",
          "publishedOn": "2021-06-14T01:38:52.425Z",
          "wordCount": 582,
          "title": "What is Multimodality?. (arXiv:2103.06304v3 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.10764",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Huang_L/0/1/0/all/0/1\">Lu Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sun_J/0/1/0/all/0/1\">Jingyu Sun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tang_Y/0/1/0/all/0/1\">Yufeng Tang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hou_J/0/1/0/all/0/1\">Junfeng Hou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_J/0/1/0/all/0/1\">Jinkun Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_J/0/1/0/all/0/1\">Jun Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ma_Z/0/1/0/all/0/1\">Zejun Ma</a>",
          "description": "This work describes an encoder pre-training procedure using frame-wise label\nto improve the training of streaming recurrent neural network transducer\n(RNN-T) model. Streaming RNN-T trained from scratch usually performs worse than\nnon-streaming RNN-T. Although it is common to address this issue through\npre-training components of RNN-T with other criteria or frame-wise alignment\nguidance, the alignment is not easily available in end-to-end manner. In this\nwork, frame-wise alignment, used to pre-train streaming RNN-T's encoder, is\ngenerated without using a HMM-based system. Therefore an all-neural framework\nequipping HMM-free encoder pre-training is constructed. This is achieved by\nexpanding the spikes of CTC model to their left/right blank frames, and two\nexpanding strategies are proposed. To our best knowledge, this is the first\nwork to simulate HMM-based frame-wise label using CTC model for pre-training.\nExperiments conducted on LibriSpeech and MLS English tasks show the proposed\npre-training procedure, compared with random initialization, reduces the WER by\nrelatively 5%~11% and the emission latency by 60 ms. Besides, the method is\nlexicon-free, so it is friendly to new languages without manually designed\nlexicon.",
          "link": "http://arxiv.org/abs/2104.10764",
          "publishedOn": "2021-06-14T01:38:52.361Z",
          "wordCount": 642,
          "title": "HMM-Free Encoder Pre-Training for Streaming RNN Transducer. (arXiv:2104.10764v2 [eess.AS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.12249",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bugert_M/0/1/0/all/0/1\">Michael Bugert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reimers_N/0/1/0/all/0/1\">Nils Reimers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>",
          "description": "Cross-document event coreference resolution (CDCR) is an NLP task in which\nmentions of events need to be identified and clustered throughout a collection\nof documents. CDCR aims to benefit downstream multi-document applications, but\ndespite recent progress on corpora and system development, downstream\nimprovements from applying CDCR have not been shown yet. We make the\nobservation that every CDCR system to date was developed, trained, and tested\nonly on a single respective corpus. This raises strong concerns on their\ngeneralizability -- a must-have for downstream applications where the magnitude\nof domains or event mentions is likely to exceed those found in a curated\ncorpus. To investigate this assumption, we define a uniform evaluation setup\ninvolving three CDCR corpora: ECB+, the Gun Violence Corpus and the Football\nCoreference Corpus (which we reannotate on token level to make our analysis\npossible). We compare a corpus-independent, feature-based system against a\nrecent neural system developed for ECB+. Whilst being inferior in absolute\nnumbers, the feature-based system shows more consistent performance across all\ncorpora whereas the neural system is hit-and-miss. Via model introspection, we\nfind that the importance of event actions, event time, etc. for resolving\ncoreference in practice varies greatly between the corpora. Additional analysis\nshows that several systems overfit on the structure of the ECB+ corpus. We\nconclude with recommendations on how to achieve generally applicable CDCR\nsystems in the future -- the most important being that evaluation on multiple\nCDCR corpora is strongly necessary. To facilitate future research, we release\nour dataset, annotation guidelines, and system implementation to the public.",
          "link": "http://arxiv.org/abs/2011.12249",
          "publishedOn": "2021-06-14T01:38:52.119Z",
          "wordCount": 713,
          "title": "Generalizing Cross-Document Event Coreference Resolution Across Multiple Corpora. (arXiv:2011.12249v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06292",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Santy_S/0/1/0/all/0/1\">Sebastin Santy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharya_P/0/1/0/all/0/1\">Prasanta Bhattacharya</a>",
          "description": "Recent advances in AI and ML applications have benefited from rapid progress\nin NLP research. Leaderboards have emerged as a popular mechanism to track and\naccelerate progress in NLP through competitive model development. While this\nhas increased interest and participation, the over-reliance on single, and\naccuracy-based metrics have shifted focus from other important metrics that\nmight be equally pertinent to consider in real-world contexts. In this paper,\nwe offer a preliminary discussion of the risks associated with focusing\nexclusively on accuracy metrics and draw on recent discussions to highlight\nprescriptive suggestions on how to develop more practical and effective\nleaderboards that can better reflect the real-world utility of models.",
          "link": "http://arxiv.org/abs/2106.06292",
          "publishedOn": "2021-06-14T01:38:52.100Z",
          "wordCount": 545,
          "title": "A Discussion on Building Practical NLP Leaderboards: The Case of Machine Translation. (arXiv:2106.06292v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06297",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hombaiah_S/0/1/0/all/0/1\">Spurthi Amba Hombaiah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mingyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bendersky_M/0/1/0/all/0/1\">Michael Bendersky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Najork_M/0/1/0/all/0/1\">Marc Najork</a>",
          "description": "The content on the web is in a constant state of flux. New entities, issues,\nand ideas continuously emerge, while the semantics of the existing conversation\ntopics gradually shift. In recent years, pre-trained language models like BERT\ngreatly improved the state-of-the-art for a large spectrum of content\nunderstanding tasks. Therefore, in this paper, we aim to study how these\nlanguage models can be adapted to better handle continuously evolving web\ncontent. In our study, we first analyze the evolution of 2013 - 2019 Twitter\ndata, and unequivocally confirm that a BERT model trained on past tweets would\nheavily deteriorate when directly applied to data from later years. Then, we\ninvestigate two possible sources of the deterioration: the semantic shift of\nexisting tokens and the sub-optimal or failed understanding of new tokens. To\nthis end, we both explore two different vocabulary composition methods, as well\nas propose three sampling methods which help in efficient incremental training\nfor BERT-like models. Compared to a new model trained from scratch offline, our\nincremental training (a) reduces the training costs, (b) achieves better\nperformance on evolving content, and (c) is suitable for online deployment. The\nsuperiority of our methods is validated using two downstream tasks. We\ndemonstrate significant improvements when incrementally evolving the model from\na particular base year, on the task of Country Hashtag Prediction, as well as\non the OffensEval 2019 task.",
          "link": "http://arxiv.org/abs/2106.06297",
          "publishedOn": "2021-06-14T01:38:52.068Z",
          "wordCount": 666,
          "title": "Dynamic Language Models for Continuously Evolving Content. (arXiv:2106.06297v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2012.07551",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kamper_H/0/1/0/all/0/1\">Herman Kamper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niekerk_B/0/1/0/all/0/1\">Benjamin van Niekerk</a>",
          "description": "We investigate segmenting and clustering speech into low-bitrate phone-like\nsequences without supervision. We specifically constrain pretrained\nself-supervised vector-quantized (VQ) neural networks so that blocks of\ncontiguous feature vectors are assigned to the same code, thereby giving a\nvariable-rate segmentation of the speech into discrete units. Two segmentation\nmethods are considered. In the first, features are greedily merged until a\nprespecified number of segments are reached. The second uses dynamic\nprogramming to optimize a squared error with a penalty term to encourage fewer\nbut longer segments. We show that these VQ segmentation methods can be used\nwithout alteration across a wide range of tasks: unsupervised phone\nsegmentation, ABX phone discrimination, same-different word discrimination, and\nas inputs to a symbolic word segmentation algorithm. The penalized dynamic\nprogramming method generally performs best. While performance on individual\ntasks is only comparable to the state-of-the-art in some cases, in all tasks a\nreasonable competing approach is outperformed at a substantially lower bitrate.",
          "link": "http://arxiv.org/abs/2012.07551",
          "publishedOn": "2021-06-14T01:38:52.061Z",
          "wordCount": 626,
          "title": "Towards unsupervised phone and word segmentation using self-supervised vector-quantized neural networks. (arXiv:2012.07551v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.05489",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yufan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yanzhe Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiaao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xuezhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Diyi Yang</a>",
          "description": "Continual learning has become increasingly important as it enables NLP models\nto constantly learn and gain knowledge over time. Previous continual learning\nmethods are mainly designed to preserve knowledge from previous tasks, without\nmuch emphasis on how to well generalize models to new tasks. In this work, we\npropose an information disentanglement based regularization method for\ncontinual learning on text classification. Our proposed method first\ndisentangles text hidden spaces into representations that are generic to all\ntasks and representations specific to each individual task, and further\nregularizes these representations differently to better constrain the knowledge\nrequired to generalize. We also introduce two simple auxiliary tasks: next\nsentence prediction and task-id prediction, for learning better generic and\nspecific representation spaces. Experiments conducted on large-scale benchmarks\ndemonstrate the effectiveness of our method in continual text classification\ntasks with various sequences and lengths over state-of-the-art baselines. We\nhave publicly released our code at https://github.com/GT-SALT/IDBR.",
          "link": "http://arxiv.org/abs/2104.05489",
          "publishedOn": "2021-06-14T01:38:52.028Z",
          "wordCount": 620,
          "title": "Continual Learning for Text Classification with Information Disentanglement Based Regularization. (arXiv:2104.05489v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06363",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Scialom_T/0/1/0/all/0/1\">Thomas Scialom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dray_P/0/1/0/all/0/1\">Paul-Alexis Dray</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lamprier_S/0/1/0/all/0/1\">Sylvain Lamprier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piwowarski_B/0/1/0/all/0/1\">Benjamin Piwowarski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Staiano_J/0/1/0/all/0/1\">Jacopo Staiano</a>",
          "description": "Due to the discrete nature of words, language GANs require to be optimized\nfrom rewards provided by discriminator networks, via reinforcement learning\nmethods. This is a much harder setting than for continuous tasks, which enjoy\ngradient flows from discriminators to generators, usually leading to dramatic\nlearning instabilities. However, we claim that this can be solved by making\ndiscriminator and generator networks cooperate to produce output sequences\nduring training. These cooperative outputs, inherently built to obtain higher\ndiscrimination scores, not only provide denser rewards for training, but also\nform a more compact artificial set for discriminator training, hence improving\nits accuracy and stability. In this paper, we show that our SelfGAN framework,\nbuilt on this cooperative principle, outperforms Teacher Forcing and obtains\nstate-of-the-art results on two challenging tasks, Summarization and Question\nGeneration.",
          "link": "http://arxiv.org/abs/2106.06363",
          "publishedOn": "2021-06-14T01:38:52.020Z",
          "wordCount": 577,
          "title": "To Beam Or Not To Beam: That is a Question of Cooperation for Language GANs. (arXiv:2106.06363v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06381",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chi_Z/0/1/0/all/0/1\">Zewen Chi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_L/0/1/0/all/0/1\">Li Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_B/0/1/0/all/0/1\">Bo Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shaohan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_X/0/1/0/all/0/1\">Xian-Ling Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Heyan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>",
          "description": "The cross-lingual language models are typically pretrained with masked\nlanguage modeling on multilingual text or parallel sentences. In this paper, we\nintroduce denoising word alignment as a new cross-lingual pre-training task.\nSpecifically, the model first self-labels word alignments for parallel\nsentences. Then we randomly mask tokens in a bitext pair. Given a masked token,\nthe model uses a pointer network to predict the aligned token in the other\nlanguage. We alternately perform the above two steps in an\nexpectation-maximization manner. Experimental results show that our method\nimproves cross-lingual transferability on various datasets, especially on the\ntoken-level tasks, such as question answering, and structured prediction.\nMoreover, the model can serve as a pretrained word aligner, which achieves\nreasonably low error rates on the alignment benchmarks. The code and pretrained\nparameters are available at https://github.com/CZWin32768/XLM-Align.",
          "link": "http://arxiv.org/abs/2106.06381",
          "publishedOn": "2021-06-14T01:38:51.995Z",
          "wordCount": 571,
          "title": "Improving Pretrained Cross-Lingual Language Models via Self-Labeled Word Alignment. (arXiv:2106.06381v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06471",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xingyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_M/0/1/0/all/0/1\">Muchao Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_Q/0/1/0/all/0/1\">Quanzeng You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_F/0/1/0/all/0/1\">Fenglong Ma</a>",
          "description": "Medical report generation is one of the most challenging tasks in medical\nimage analysis. Although existing approaches have achieved promising results,\nthey either require a predefined template database in order to retrieve\nsentences or ignore the hierarchical nature of medical report generation. To\naddress these issues, we propose MedWriter that incorporates a novel\nhierarchical retrieval mechanism to automatically extract both report and\nsentence-level templates for clinically accurate report generation. MedWriter\nfirst employs the Visual-Language Retrieval~(VLR) module to retrieve the most\nrelevant reports for the given images. To guarantee the logical coherence\nbetween sentences, the Language-Language Retrieval~(LLR) module is introduced\nto retrieve relevant sentences based on the previous generated description. At\nlast, a language decoder fuses image features and features from retrieved\nreports and sentences to generate meaningful medical reports. We verified the\neffectiveness of our model by automatic evaluation and human evaluation on two\ndatasets, i.e., Open-I and MIMIC-CXR.",
          "link": "http://arxiv.org/abs/2106.06471",
          "publishedOn": "2021-06-14T01:38:51.979Z",
          "wordCount": 592,
          "title": "Writing by Memorizing: Hierarchical Retrieval-based Medical Report Generation. (arXiv:2106.06471v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06411",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hazarika_D/0/1/0/all/0/1\">Devamanyu Hazarika</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Namazifar_M/0/1/0/all/0/1\">Mahdi Namazifar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hakkani_Tur_D/0/1/0/all/0/1\">Dilek Hakkani-T&#xfc;r</a>",
          "description": "Controlling neural network-based models for natural language generation (NLG)\nhas broad applications in numerous areas such as machine translation, document\nsummarization, and dialog systems. Approaches that enable such control in a\nzero-shot manner would be of great importance as, among other reasons, they\nremove the need for additional annotated data and training. In this work, we\npropose novel approaches for controlling encoder-decoder transformer-based NLG\nmodels in a zero-shot manner. This is done by introducing three control knobs;\nnamely, attention biasing, decoder mixing, and context augmentation, that are\napplied to these models at generation time. These knobs control the generation\nprocess by directly manipulating trained NLG models (e.g., biasing\ncross-attention layers) to realize the desired attributes in the generated\noutputs. We show that not only are these NLG models robust to such\nmanipulations, but also their behavior could be controlled without an impact on\ntheir generation performance. These results, to the best of our knowledge, are\nthe first of their kind. Through these control knobs, we also investigate the\nrole of transformer decoder's self-attention module and show strong evidence\nthat its primary role is maintaining fluency of sentences generated by these\nmodels. Based on this hypothesis, we show that alternative architectures for\ntransformer decoders could be viable options. We also study how this hypothesis\ncould lead to more efficient ways for training encoder-decoder transformer\nmodels.",
          "link": "http://arxiv.org/abs/2106.06411",
          "publishedOn": "2021-06-14T01:38:51.963Z",
          "wordCount": 648,
          "title": "Zero-Shot Controlled Generation with Encoder-Decoder Transformers. (arXiv:2106.06411v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06528",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tuan_Y/0/1/0/all/0/1\">Yi-Lin Tuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pryor_C/0/1/0/all/0/1\">Connor Pryor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wenhu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Getoor_L/0/1/0/all/0/1\">Lise Getoor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>",
          "description": "In comparison to the interpretation of classification models, the explanation\nof sequence generation models is also an important problem, however it has seen\nlittle attention. In this work, we study model-agnostic explanations of a\nrepresentative text generation task -- dialogue response generation. Dialog\nresponse generation is challenging with its open-ended sentences and multiple\nacceptable responses. To gain insights into the reasoning process of a\ngeneration model, we propose anew method, local explanation of response\ngeneration (LERG) that regards the explanations as the mutual interaction of\nsegments in input and output sentences. LERG views the sequence prediction as\nuncertainty estimation of a human response and then creates explanations by\nperturbing the input and calculating the certainty change over the human\nresponse. We show that LERG adheres to desired properties of explanations for\ntext generation including unbiased approximation, consistency and cause\nidentification. Empirically, our results show that our method consistently\nimproves other widely used methods on proposed automatic- and human- evaluation\nmetrics for this new task by 4.4-12.8%. Our analysis demonstrates that LERG can\nextract both explicit and implicit relations between input and output segments.",
          "link": "http://arxiv.org/abs/2106.06528",
          "publishedOn": "2021-06-14T01:38:51.956Z",
          "wordCount": 613,
          "title": "Local Explanation of Dialogue Response Generation. (arXiv:2106.06528v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06504",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gervits_F/0/1/0/all/0/1\">Felix Gervits</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roque_A/0/1/0/all/0/1\">Antonio Roque</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Briggs_G/0/1/0/all/0/1\">Gordon Briggs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scheutz_M/0/1/0/all/0/1\">Matthias Scheutz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marge_M/0/1/0/all/0/1\">Matthew Marge</a>",
          "description": "Intelligent agents that are confronted with novel concepts in situated\nenvironments will need to ask their human teammates questions to learn about\nthe physical world. To better understand this problem, we need data about\nasking questions in situated task-based interactions. To this end, we present\nthe Human-Robot Dialogue Learning (HuRDL) Corpus - a novel dialogue corpus\ncollected in an online interactive virtual environment in which human\nparticipants play the role of a robot performing a collaborative\ntool-organization task. We describe the corpus data and a corresponding\nannotation scheme to offer insight into the form and content of questions that\nhumans ask to facilitate learning in a situated environment. We provide the\ncorpus as an empirically-grounded resource for improving question generation in\nsituated intelligent agents.",
          "link": "http://arxiv.org/abs/2106.06504",
          "publishedOn": "2021-06-14T01:38:51.937Z",
          "wordCount": 580,
          "title": "How Should Agents Ask Questions For Situated Learning? An Annotated Dialogue Corpus. (arXiv:2106.06504v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2102.05918",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jia_C/0/1/0/all/0/1\">Chao Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yinfei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1\">Ye Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yi-Ting Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parekh_Z/0/1/0/all/0/1\">Zarana Parekh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pham_H/0/1/0/all/0/1\">Hieu Pham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1\">Quoc V. Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sung_Y/0/1/0/all/0/1\">Yunhsuan Sung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duerig_T/0/1/0/all/0/1\">Tom Duerig</a>",
          "description": "Pre-trained representations are becoming crucial for many NLP and perception\ntasks. While representation learning in NLP has transitioned to training on raw\ntext without human annotations, visual and vision-language representations\nstill rely heavily on curated training datasets that are expensive or require\nexpert knowledge. For vision applications, representations are mostly learned\nusing datasets with explicit class labels such as ImageNet or OpenImages. For\nvision-language, popular datasets like Conceptual Captions, MSCOCO, or CLIP all\ninvolve a non-trivial data collection (and cleaning) process. This costly\ncuration process limits the size of datasets and hence hinders the scaling of\ntrained models. In this paper, we leverage a noisy dataset of over one billion\nimage alt-text pairs, obtained without expensive filtering or post-processing\nsteps in the Conceptual Captions dataset. A simple dual-encoder architecture\nlearns to align visual and language representations of the image and text pairs\nusing a contrastive loss. We show that the scale of our corpus can make up for\nits noise and leads to state-of-the-art representations even with such a simple\nlearning scheme. Our visual representation achieves strong performance when\ntransferred to classification tasks such as ImageNet and VTAB. The aligned\nvisual and language representations enables zero-shot image classification and\nalso set new state-of-the-art results on Flickr30K and MSCOCO image-text\nretrieval benchmarks, even when compared with more sophisticated\ncross-attention models. The representations also enable cross-modality search\nwith complex text and text + image queries.",
          "link": "http://arxiv.org/abs/2102.05918",
          "publishedOn": "2021-06-14T01:38:51.931Z",
          "wordCount": 733,
          "title": "Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision. (arXiv:2102.05918v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06233",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jingbei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Y/0/1/0/all/0/1\">Yi Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chenyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhiyong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_H/0/1/0/all/0/1\">Helen Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weng_C/0/1/0/all/0/1\">Chao Weng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_D/0/1/0/all/0/1\">Dan Su</a>",
          "description": "For conversational text-to-speech (TTS) systems, it is vital that the systems\ncan adjust the spoken styles of synthesized speech according to different\ncontent and spoken styles in historical conversations. However, the study about\nlearning spoken styles from historical conversations is still in its infancy.\nOnly the transcripts of the historical conversations are considered, which\nneglects the spoken styles in historical speeches. Moreover, only the\ninteractions of the global aspect between speakers are modeled, missing the\nparty aspect self interactions inside each speaker. In this paper, to achieve\nbetter spoken style learning for conversational TTS, we propose a spoken style\nlearning approach with multi-modal hierarchical context encoding. The textual\ninformation and spoken styles in the historical conversations are processed\nthrough multiple hierarchical recurrent neural networks to learn the spoken\nstyle related features in global and party aspects. The attention mechanism is\nfurther employed to summarize these features into a conversational context\nencoding. Experimental results demonstrate the effectiveness of our proposed\napproach, which outperform a baseline method using context encoding learnt only\nfrom the transcripts in global aspects, with MOS score on the naturalness of\nsynthesized speech increasing from 3.138 to 3.408 and ABX preference rate\nexceeding the baseline method by 36.45%.",
          "link": "http://arxiv.org/abs/2106.06233",
          "publishedOn": "2021-06-14T01:38:51.923Z",
          "wordCount": 647,
          "title": "Spoken Style Learning with Multi-modal Hierarchical Context Encoding for Conversational Text-to-Speech Synthesis. (arXiv:2106.06233v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2102.09690",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tony Z. Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wallace_E/0/1/0/all/0/1\">Eric Wallace</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1\">Shi Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klein_D/0/1/0/all/0/1\">Dan Klein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Sameer Singh</a>",
          "description": "GPT-3 can perform numerous tasks when provided a natural language prompt that\ncontains a few training examples. We show that this type of few-shot learning\ncan be unstable: the choice of prompt format, training examples, and even the\norder of the training examples can cause accuracy to vary from near chance to\nnear state-of-the-art. We demonstrate that this instability arises from the\nbias of language models towards predicting certain answers, e.g., those that\nare placed near the end of the prompt or are common in the pre-training data.\nTo mitigate this, we first estimate the model's bias towards each answer by\nasking for its prediction when given the training prompt and a content-free\ntest input such as \"N/A\". We then fit calibration parameters that cause the\nprediction for this input to be uniform across answers. On a diverse set of\ntasks, this contextual calibration procedure substantially improves GPT-3 and\nGPT-2's average accuracy (up to 30.0% absolute) and reduces variance across\ndifferent choices of the prompt.",
          "link": "http://arxiv.org/abs/2102.09690",
          "publishedOn": "2021-06-14T01:38:51.916Z",
          "wordCount": 632,
          "title": "Calibrate Before Use: Improving Few-Shot Performance of Language Models. (arXiv:2102.09690v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06230",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Peinl_R/0/1/0/all/0/1\">Ren&#xe9; Peinl</a>",
          "description": "Reading text aloud is an important feature for modern computer applications.\nIt not only facilitates access to information for visually impaired people, but\nis also a pleasant convenience for non-impaired users. In this article, the\nstate of the art of speech synthesis is presented separately for\nmel-spectrogram generation and vocoders. It concludes with an overview of\navailable data sets for English and German with a discussion of the\ntransferability of the good speech synthesis results from English to German\nlanguage.",
          "link": "http://arxiv.org/abs/2106.06230",
          "publishedOn": "2021-06-14T01:38:51.907Z",
          "wordCount": 505,
          "title": "Sprachsynthese -- State-of-the-Art in englischer und deutscher Sprache. (arXiv:2106.06230v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06361",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qi_F/0/1/0/all/0/1\">Fanchao Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yuan Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Sophia Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>",
          "description": "Recent studies show that neural natural language processing (NLP) models are\nvulnerable to backdoor attacks. Injected with backdoors, models perform\nnormally on benign examples but produce attacker-specified predictions when the\nbackdoor is activated, presenting serious security threats to real-world\napplications. Since existing textual backdoor attacks pay little attention to\nthe invisibility of backdoors, they can be easily detected and blocked. In this\nwork, we present invisible backdoors that are activated by a learnable\ncombination of word substitution. We show that NLP models can be injected with\nbackdoors that lead to a nearly 100% attack success rate, whereas being highly\ninvisible to existing defense strategies and even human inspections. The\nresults raise a serious alarm to the security of NLP models, which requires\nfurther research to be resolved. All the data and code of this paper are\nreleased at https://github.com/thunlp/BkdAtk-LWS.",
          "link": "http://arxiv.org/abs/2106.06361",
          "publishedOn": "2021-06-14T01:38:51.881Z",
          "wordCount": 593,
          "title": "Turn the Combination Lock: Learnable Textual Backdoor Attacks via Word Substitution. (arXiv:2106.06361v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09043",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Do_P/0/1/0/all/0/1\">Phong Nguyen-Thuan Do</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1\">Nhat Duy Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huynh_T/0/1/0/all/0/1\">Tin Van Huynh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1\">Kiet Van Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1\">Anh Gia-Tuan Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1\">Ngan Luu-Thuy Nguyen</a>",
          "description": "The development of natural language processing (NLP) in general and machine\nreading comprehension in particular has attracted the great attention of the\nresearch community. In recent years, there are a few datasets for machine\nreading comprehension tasks in Vietnamese with large sizes, such as UIT-ViQuAD\nand UIT-ViNewsQA. However, the datasets are not diverse in answers to serve the\nresearch. In this paper, we introduce UIT-ViWikiQA, the first dataset for\nevaluating sentence extraction-based machine reading comprehension in the\nVietnamese language. The UIT-ViWikiQA dataset is converted from the UIT-ViQuAD\ndataset, consisting of comprises 23.074 question-answers based on 5.109\npassages of 174 Wikipedia Vietnamese articles. We propose a conversion\nalgorithm to create the dataset for sentence extraction-based machine reading\ncomprehension and three types of approaches for sentence extraction-based\nmachine reading comprehension in Vietnamese. Our experiments show that the best\nmachine model is XLM-R_Large, which achieves an exact match (EM) of 85.97% and\nan F1-score of 88.77% on our dataset. Besides, we analyze experimental results\nin terms of the question type in Vietnamese and the effect of context on the\nperformance of the MRC models, thereby showing the challenges from the\nUIT-ViWikiQA dataset that we propose to the language processing community.",
          "link": "http://arxiv.org/abs/2105.09043",
          "publishedOn": "2021-06-14T01:38:51.870Z",
          "wordCount": 667,
          "title": "Sentence Extraction-Based Machine Reading Comprehension for Vietnamese. (arXiv:2105.09043v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06247",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jean Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Youn_H/0/1/0/all/0/1\">Hoyoul Luis Youn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stevens_N/0/1/0/all/0/1\">Nicholas Stevens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poon_J/0/1/0/all/0/1\">Josiah Poon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Soyeon Caren Han</a>",
          "description": "The Federal Reserve System (the Fed) plays a significant role in affecting\nmonetary policy and financial conditions worldwide. Although it is important to\nanalyse the Fed's communications to extract useful information, it is generally\nlong-form and complex due to the ambiguous and esoteric nature of content. In\nthis paper, we present FedNLP, an interpretable multi-component Natural\nLanguage Processing system to decode Federal Reserve communications. This\nsystem is designed for end-users to explore how NLP techniques can assist their\nholistic understanding of the Fed's communications with NO coding. Behind the\nscenes, FedNLP uses multiple NLP models from traditional machine learning\nalgorithms to deep neural network architectures in each downstream task. The\ndemonstration shows multiple results at once including sentiment analysis,\nsummary of the document, prediction of the Federal Funds Rate movement and\nvisualization for interpreting the prediction model's result.",
          "link": "http://arxiv.org/abs/2106.06247",
          "publishedOn": "2021-06-14T01:38:51.846Z",
          "wordCount": 583,
          "title": "FedNLP: An interpretable NLP System to Decode Federal Reserve Communications. (arXiv:2106.06247v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06309",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Puchtler_P/0/1/0/all/0/1\">Pascal Puchtler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wirth_J/0/1/0/all/0/1\">Johannes Wirth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peinl_R/0/1/0/all/0/1\">Ren&#xe9; Peinl</a>",
          "description": "The increasing availability of audio data on the internet lead to a multitude\nof datasets for development and training of text to speech applications, based\non neural networks. Highly differing quality of voice, low sampling rates, lack\nof text normalization and disadvantageous alignment of audio samples to\ncorresponding transcript sentences still limit the performance of deep neural\nnetworks trained on this task. Additionally, data resources in languages like\nGerman are still very limited. We introduce the \"HUI-Audio-Corpus-German\", a\nlarge, open-source dataset for TTS engines, created with a processing pipeline,\nwhich produces high quality audio to transcription alignments and decreases\nmanual effort needed for creation.",
          "link": "http://arxiv.org/abs/2106.06309",
          "publishedOn": "2021-06-14T01:38:51.825Z",
          "wordCount": 530,
          "title": "HUI-Audio-Corpus-German: A high quality TTS dataset. (arXiv:2106.06309v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06183",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ray_S/0/1/0/all/0/1\">Swayambhu Nath Ray</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mitra_S/0/1/0/all/0/1\">Soumyajit Mitra</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bilgi_R/0/1/0/all/0/1\">Raghavendra Bilgi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Garimella_S/0/1/0/all/0/1\">Sri Garimella</a>",
          "description": "In this paper, we explore the benefits of incorporating context into a\nRecurrent Neural Network (RNN-T) based Automatic Speech Recognition (ASR) model\nto improve the speech recognition for virtual assistants. Specifically, we use\nmeta information extracted from the time at which the utterance is spoken and\nthe approximate location information to make ASR context aware. We show that\nthese contextual information, when used individually, improves overall\nperformance by as much as 3.48% relative to the baseline and when the contexts\nare combined, the model learns complementary features and the recognition\nimproves by 4.62%. On specific domains, these contextual signals show\nimprovements as high as 11.5%, without any significant degradation on others.\nWe ran experiments with models trained on data of sizes 30K hours and 10K\nhours. We show that the scale of improvement with the 10K hours dataset is much\nhigher than the one obtained with 30K hours dataset. Our results indicate that\nwith limited data to train the ASR model, contextual signals can improve the\nperformance significantly.",
          "link": "http://arxiv.org/abs/2106.06183",
          "publishedOn": "2021-06-14T01:38:51.757Z",
          "wordCount": 619,
          "title": "Improving RNN-T ASR Performance with Date-Time and Location Awareness. (arXiv:2106.06183v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06216",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Waldis_A/0/1/0/all/0/1\">Andreas Waldis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mazzola_L/0/1/0/all/0/1\">Luca Mazzola</a>",
          "description": "Entity Recognition (ER) within a text is a fundamental exercise in Natural\nLanguage Processing, enabling further depending tasks such as Knowledge\nExtraction, Text Summarisation, or Keyphrase Extraction. An entity consists of\nsingle words or of a consecutive sequence of terms, constituting the basic\nbuilding blocks for communication. Mainstream ER approaches are mainly limited\nto flat structures, concentrating on the outermost entities while ignoring the\ninner ones. This paper introduces a partly-layered network architecture that\ndeals with the complexity of overlapping and nested cases. The proposed\narchitecture consists of two parts: (1) a shared Sequence Layer and (2) a\nstacked component with multiple Tagging Layers. The adoption of such an\narchitecture has the advantage of preventing overfit to a specific word-length,\nthus maintaining performance for longer entities despite their lower frequency.\nTo verify the proposed architecture's effectiveness, we train and evaluate this\narchitecture to recognise two kinds of entities - Concepts (CR) and Named\nEntities (NER). Our approach achieves state-of-the-art NER performances, while\nit outperforms previous CR approaches. Considering these promising results, we\nsee the possibility to evolve the architecture for other cases such as the\nextraction of events or the detection of argumentative components.",
          "link": "http://arxiv.org/abs/2106.06216",
          "publishedOn": "2021-06-14T01:38:51.705Z",
          "wordCount": 635,
          "title": "Nested and Balanced Entity Recognition using Multi-Task Learning. (arXiv:2106.06216v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06200",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Huan Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_L/0/1/0/all/0/1\">Liang Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1\">Baosong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1\">Dayiheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Haibo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_W/0/1/0/all/0/1\">Weihua Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1\">Degen Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1\">Jinsong Su</a>",
          "description": "A good translation should not only translate the original content\nsemantically, but also incarnate personal traits of the original text. For a\nreal-world neural machine translation (NMT) system, these user traits (e.g.,\ntopic preference, stylistic characteristics and expression habits) can be\npreserved in user behavior (e.g., historical inputs). However, current NMT\nsystems marginally consider the user behavior due to: 1) the difficulty of\nmodeling user portraits in zero-shot scenarios, and 2) the lack of\nuser-behavior annotated parallel dataset. To fill this gap, we introduce a\nnovel framework called user-driven NMT. Specifically, a cache-based module and\na user-driven contrastive learning method are proposed to offer NMT the ability\nto capture potential user traits from their historical inputs under a zero-shot\nlearning fashion. Furthermore, we contribute the first Chinese-English parallel\ncorpus annotated with user behavior called UDT-Corpus. Experimental results\nconfirm that the proposed user-driven NMT can generate user-specific\ntranslations.",
          "link": "http://arxiv.org/abs/2106.06200",
          "publishedOn": "2021-06-14T01:38:51.697Z",
          "wordCount": 574,
          "title": "Towards User-Driven Neural Machine Translation. (arXiv:2106.06200v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06213",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weld_H/0/1/0/all/0/1\">Henry Weld</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1\">Guanghao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jean Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tongshu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Kunze Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1\">Xinghong Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_S/0/1/0/all/0/1\">Siqu Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poon_J/0/1/0/all/0/1\">Josiah Poon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Soyeon Caren Han</a>",
          "description": "Traditional toxicity detection models have focused on the single utterance\nlevel without deeper understanding of context. We introduce CONDA, a new\ndataset for in-game toxic language detection enabling joint intent\nclassification and slot filling analysis, which is the core task of Natural\nLanguage Understanding (NLU). The dataset consists of 45K utterances from 12K\nconversations from the chat logs of 1.9K completed Dota 2 matches. We propose a\nrobust dual semantic-level toxicity framework, which handles utterance and\ntoken-level patterns, and rich contextual chatting history. Accompanying the\ndataset is a thorough in-game toxicity analysis, which provides comprehensive\nunderstanding of context at utterance, token, and dual levels. Inspired by NLU,\nwe also apply its metrics to the toxicity detection tasks for assessing\ntoxicity and game-specific aspects. We evaluate strong NLU models on CONDA,\nproviding fine-grained results for different intent classes and slot classes.\nFurthermore, we examine the coverage of toxicity nature in our dataset by\ncomparing it with other toxicity datasets.",
          "link": "http://arxiv.org/abs/2106.06213",
          "publishedOn": "2021-06-14T01:38:51.652Z",
          "wordCount": 604,
          "title": "CONDA: a CONtextual Dual-Annotated dataset for in-game toxicity understanding and detection. (arXiv:2106.06213v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06228",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Bo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xin_C/0/1/0/all/0/1\">Chunlei Xin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xianpei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Le Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Weipeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiansong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1\">Fan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_X/0/1/0/all/0/1\">Xunliang Cai</a>",
          "description": "Semantic parsing is challenging due to the structure gap and the semantic gap\nbetween utterances and logical forms. In this paper, we propose an unsupervised\nsemantic parsing method - Synchronous Semantic Decoding (SSD), which can\nsimultaneously resolve the semantic gap and the structure gap by jointly\nleveraging paraphrasing and grammar constrained decoding. Specifically, we\nreformulate semantic parsing as a constrained paraphrasing problem: given an\nutterance, our model synchronously generates its canonical utterance and\nmeaning representation. During synchronous decoding: the utterance paraphrasing\nis constrained by the structure of the logical form, therefore the canonical\nutterance can be paraphrased controlledly; the semantic decoding is guided by\nthe semantics of the canonical utterance, therefore its logical form can be\ngenerated unsupervisedly. Experimental results show that SSD is a promising\napproach and can achieve competitive unsupervised semantic parsing performance\non multiple datasets.",
          "link": "http://arxiv.org/abs/2106.06228",
          "publishedOn": "2021-06-14T01:38:51.627Z",
          "wordCount": 586,
          "title": "From Paraphrasing to Semantic Parsing: Unsupervised Semantic Parsing via Synchronous Semantic Decoding. (arXiv:2106.06228v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06169",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1\">Haoyu Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kaiyan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wei-Nan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Ting Liu</a>",
          "description": "Maintaining consistent personas is essential for dialogue agents. Although\ntremendous advancements have been brought, the limited-scale of annotated\npersona-dense data are still barriers towards training robust and consistent\npersona-based dialogue models. In this work, we show how the challenges can be\naddressed by disentangling persona-based dialogue generation into two sub-tasks\nwith a novel BERT-over-BERT (BoB) model. Specifically, the model consists of a\nBERT-based encoder and two BERT-based decoders, where one decoder is for\nresponse generation, and another is for consistency understanding. In\nparticular, to learn the ability of consistency understanding from large-scale\nnon-dialogue inference data, we train the second decoder in an unlikelihood\nmanner. Under different limited data settings, both automatic and human\nevaluations demonstrate that the proposed model outperforms strong baselines in\nresponse quality and persona consistency.",
          "link": "http://arxiv.org/abs/2106.06169",
          "publishedOn": "2021-06-14T01:38:51.568Z",
          "wordCount": 575,
          "title": "BoB: BERT Over BERT for Training Persona-based Dialogue Models from Limited Personalized Data. (arXiv:2106.06169v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06132",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lal_Y/0/1/0/all/0/1\">Yash Kumar Lal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chambers_N/0/1/0/all/0/1\">Nathanael Chambers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mooney_R/0/1/0/all/0/1\">Raymond Mooney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balasubramanian_N/0/1/0/all/0/1\">Niranjan Balasubramanian</a>",
          "description": "Answering questions about why characters perform certain actions is central\nto understanding and reasoning about narratives. Despite recent progress in QA,\nit is not clear if existing models have the ability to answer \"why\" questions\nthat may require commonsense knowledge external to the input narrative. In this\nwork, we introduce TellMeWhy, a new crowd-sourced dataset that consists of more\nthan 30k questions and free-form answers concerning why characters in short\nnarratives perform the actions described. For a third of this dataset, the\nanswers are not present within the narrative. Given the limitations of\nautomated evaluation for this task, we also present a systematized human\nevaluation interface for this dataset. Our evaluation of state-of-the-art\nmodels show that they are far below human performance on answering such\nquestions. They are especially worse on questions whose answers are external to\nthe narrative, thus providing a challenge for future QA and narrative\nunderstanding research.",
          "link": "http://arxiv.org/abs/2106.06132",
          "publishedOn": "2021-06-14T01:38:51.559Z",
          "wordCount": 590,
          "title": "TellMeWhy: A Dataset for Answering Why-Questions in Narratives. (arXiv:2106.06132v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06160",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ferrand_E/0/1/0/all/0/1\">&#xc9;ric Le Ferrand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bird_S/0/1/0/all/0/1\">Steven Bird</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Besacier_L/0/1/0/all/0/1\">Laurent Besacier</a>",
          "description": "We investigate the efficiency of two very different spoken term detection\napproaches for transcription when the available data is insufficient to train a\nrobust ASR system. This work is grounded in very low-resource language\ndocumentation scenario where only few minutes of recording have been\ntranscribed for a given language so far.Experiments on two oral languages show\nthat a pretrained universal phone recognizer, fine-tuned with only a few\nminutes of target language speech, can be used for spoken term detection with a\nbetter overall performance than a dynamic time warping approach. In addition,\nwe show that representing phoneme recognition ambiguity in a graph structure\ncan further boost the recall while maintaining high precision in the low\nresource spoken term detection task.",
          "link": "http://arxiv.org/abs/2106.06160",
          "publishedOn": "2021-06-14T01:38:51.537Z",
          "wordCount": 561,
          "title": "Spoken Term Detection Methods for Sparse Transcription in Very Low-resource Settings. (arXiv:2106.06160v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06004",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jayanthi_S/0/1/0/all/0/1\">Sai Muralidhar Jayanthi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nerella_K/0/1/0/all/0/1\">Kavya Nerella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandu_K/0/1/0/all/0/1\">Khyathi Raghavi Chandu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Black_A/0/1/0/all/0/1\">Alan W Black</a>",
          "description": "The NLP community has witnessed steep progress in a variety of tasks across\nthe realms of monolingual and multilingual language processing recently. These\nsuccesses, in conjunction with the proliferating mixed language interactions on\nsocial media have boosted interest in modeling code-mixed texts. In this work,\nwe present CodemixedNLP, an open-source library with the goals of bringing\ntogether the advances in code-mixed NLP and opening it up to a wider machine\nlearning community. The library consists of tools to develop and benchmark\nversatile model architectures that are tailored for mixed texts, methods to\nexpand training sets, techniques to quantify mixing styles, and fine-tuned\nstate-of-the-art models for 7 tasks in Hinglish. We believe this work has a\npotential to foster a distributed yet collaborative and sustainable ecosystem\nin an otherwise dispersed space of code-mixing research. The toolkit is\ndesigned to be simple, easily extensible, and resourceful to both researchers\nas well as practitioners.",
          "link": "http://arxiv.org/abs/2106.06004",
          "publishedOn": "2021-06-14T01:38:51.510Z",
          "wordCount": 596,
          "title": "CodemixedNLP: An Extensible and Open NLP Toolkit for Code-Mixing. (arXiv:2106.06004v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06157",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bang_Y/0/1/0/all/0/1\">Yejin Bang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_N/0/1/0/all/0/1\">Nayeon Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ishii_E/0/1/0/all/0/1\">Etsuko Ishii</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madotto_A/0/1/0/all/0/1\">Andrea Madotto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fung_P/0/1/0/all/0/1\">Pascale Fung</a>",
          "description": "Politically sensitive topics are still a challenge for open-domain chatbots.\nHowever, dealing with politically sensitive content in a responsible,\nnon-partisan, and safe behavior way is integral for these chatbots. Currently,\nthe main approach to handling political sensitivity is by simply changing such\na topic when it is detected. This is safe but evasive and results in a chatbot\nthat is less engaging. In this work, as a first step towards a politically safe\nchatbot, we propose a group of metrics for assessing their political prudence.\nWe then conduct political prudence analysis of various chatbots and discuss\ntheir behavior from multiple angles through our automatic metric and human\nevaluation metrics. The testsets and codebase are released to promote research\nin this area.",
          "link": "http://arxiv.org/abs/2106.06157",
          "publishedOn": "2021-06-14T01:38:51.469Z",
          "wordCount": 560,
          "title": "Assessing Political Prudence of Open-domain Chatbots. (arXiv:2106.06157v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06052",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1\">Zhiyi Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ethayarajh_K/0/1/0/all/0/1\">Kawin Ethayarajh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thrush_T/0/1/0/all/0/1\">Tristan Thrush</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1\">Somya Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1\">Ledell Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1\">Robin Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potts_C/0/1/0/all/0/1\">Christopher Potts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Williams_A/0/1/0/all/0/1\">Adina Williams</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiela_D/0/1/0/all/0/1\">Douwe Kiela</a>",
          "description": "We introduce Dynaboard, an evaluation-as-a-service framework for hosting\nbenchmarks and conducting holistic model comparison, integrated with the\nDynabench platform. Our platform evaluates NLP models directly instead of\nrelying on self-reported metrics or predictions on a single dataset. Under this\nparadigm, models are submitted to be evaluated in the cloud, circumventing the\nissues of reproducibility, accessibility, and backwards compatibility that\noften hinder benchmarking in NLP. This allows users to interact with uploaded\nmodels in real time to assess their quality, and permits the collection of\nadditional metrics such as memory use, throughput, and robustness, which --\ndespite their importance to practitioners -- have traditionally been absent\nfrom leaderboards. On each task, models are ranked according to the Dynascore,\na novel utility-based aggregation of these statistics, which users can\ncustomize to better reflect their preferences, placing more/less weight on a\nparticular axis of evaluation or dataset. As state-of-the-art NLP models push\nthe limits of traditional benchmarks, Dynaboard offers a standardized solution\nfor a more diverse and comprehensive evaluation of model quality.",
          "link": "http://arxiv.org/abs/2106.06052",
          "publishedOn": "2021-06-14T01:38:51.458Z",
          "wordCount": 609,
          "title": "Dynaboard: An Evaluation-As-A-Service Platform for Holistic Next-Generation Benchmarking. (arXiv:2106.06052v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06139",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moore_K/0/1/0/all/0/1\">Kristen Moore</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_S/0/1/0/all/0/1\">Shenjun Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1\">Zhen He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rudolf_T/0/1/0/all/0/1\">Torsten Rudolf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fisher_N/0/1/0/all/0/1\">Nils Fisher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Victor_B/0/1/0/all/0/1\">Brandon Victor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jindal_N/0/1/0/all/0/1\">Neha Jindal</a>",
          "description": "In this paper we present the results of our experiments in training and\ndeploying a self-supervised retrieval-based chatbot trained with contrastive\nlearning for assisting customer support agents. In contrast to most existing\nresearch papers in this area where the focus is on solving just one component\nof a deployable chatbot, we present an end-to-end set of solutions to take the\nreader from an unlabelled chatlogs to a deployed chatbot. This set of solutions\nincludes creating a self-supervised dataset and a weakly labelled dataset from\nchatlogs, as well as a systematic approach to selecting a fixed list of canned\nresponses. We present a hierarchical-based RNN architecture for the response\nselection model, chosen for its ability to cache intermediate utterance\nembeddings, which helped to meet deployment inference speed requirements. We\ncompare the performance of this architecture across 3 different learning\nobjectives: self-supervised contrastive learning, binary classification, and\nmulti-class classification. We find that using a self-supervised contrastive\nlearning model outperforms training the binary and multi-class classification\nmodels on a weakly labelled dataset. Our results validate that the\nself-supervised contrastive learning approach can be effectively used for a\nreal-world chatbot scenario.",
          "link": "http://arxiv.org/abs/2106.06139",
          "publishedOn": "2021-06-14T01:38:51.444Z",
          "wordCount": 624,
          "title": "A comprehensive solution to retrieval-based chatbot construction. (arXiv:2106.06139v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06147",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abdelnour_J/0/1/0/all/0/1\">Jerome Abdelnour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rouat_J/0/1/0/all/0/1\">Jean Rouat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salvi_G/0/1/0/all/0/1\">Giampiero Salvi</a>",
          "description": "The goal of the Acoustic Question Answering (AQA) task is to answer a\nfree-form text question about the content of an acoustic scene. It was inspired\nby the Visual Question Answering (VQA) task. In this paper, based on the\npreviously introduced CLEAR dataset, we propose a new benchmark for AQA that\nemphasizes the specific challenges of acoustic inputs, e.g. variable duration\nscenes. We also introduce NAAQA, a neural architecture that leverages specific\nproperties of acoustic inputs. The usage of time and frequency 1D convolutions\nto process 2D spectro-temporal representations of acoustic content shows\npromising results and enables reductions in model complexity. NAAQA achieves\n91.6% of accuracy on the AQA task with about 7 times fewer parameters than the\npreviously explored VQA model. We provide a detailed analysis of the results\nfor the different question types. The effectiveness of coordinate maps in this\nacoustic context was also studied and we show that time coordinate maps augment\ntemporal localization capabilities which enhance performance of the network by\nabout 17 percentage points.",
          "link": "http://arxiv.org/abs/2106.06147",
          "publishedOn": "2021-06-14T01:38:51.433Z",
          "wordCount": 622,
          "title": "NAAQA: A Neural Architecture for Acoustic Question Answering. (arXiv:2106.06147v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06125",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1\">Baosong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1\">Dayiheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Haibo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_W/0/1/0/all/0/1\">Weihua Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Min Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Haiying Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1\">Jinsong Su</a>",
          "description": "A well-known limitation in pretrain-finetune paradigm lies in its\ninflexibility caused by the one-size-fits-all vocabulary. This potentially\nweakens the effect when applying pretrained models into natural language\ngeneration (NLG) tasks, especially for the subword distributions between\nupstream and downstream tasks with significant discrepancy. Towards approaching\nthis problem, we extend the vanilla pretrain-finetune pipeline with an extra\nembedding transfer step. Specifically, a plug-and-play embedding generator is\nintroduced to produce the representation of any input token, according to\npre-trained embeddings of its morphologically similar ones. Thus, embeddings of\nmismatch tokens in downstream tasks can also be efficiently initialized. We\nconduct experiments on a variety of NLG tasks under the pretrain-finetune\nfashion. Experimental results and extensive analyses show that the proposed\nstrategy offers us opportunities to feel free to transfer the vocabulary,\nleading to more efficient and better performed downstream NLG models.",
          "link": "http://arxiv.org/abs/2106.06125",
          "publishedOn": "2021-06-14T01:38:51.408Z",
          "wordCount": 581,
          "title": "Bridging Subword Gaps in Pretrain-Finetune Paradigm for Natural Language Generation. (arXiv:2106.06125v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06090",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1\">Lingfei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_K/0/1/0/all/0/1\">Kai Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1\">Xiaojie Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_H/0/1/0/all/0/1\">Hanning Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shucheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pei_J/0/1/0/all/0/1\">Jian Pei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_B/0/1/0/all/0/1\">Bo Long</a>",
          "description": "Deep learning has become the dominant approach in coping with various tasks\nin Natural LanguageProcessing (NLP). Although text inputs are typically\nrepresented as a sequence of tokens, there isa rich variety of NLP problems\nthat can be best expressed with a graph structure. As a result, thereis a surge\nof interests in developing new deep learning techniques on graphs for a large\nnumberof NLP tasks. In this survey, we present a comprehensive overview onGraph\nNeural Networks(GNNs) for Natural Language Processing. We propose a new\ntaxonomy of GNNs for NLP, whichsystematically organizes existing research of\nGNNs for NLP along three axes: graph construction,graph representation\nlearning, and graph based encoder-decoder models. We further introducea large\nnumber of NLP applications that are exploiting the power of GNNs and summarize\nthecorresponding benchmark datasets, evaluation metrics, and open-source codes.\nFinally, we discussvarious outstanding challenges for making the full use of\nGNNs for NLP as well as future researchdirections. To the best of our\nknowledge, this is the first comprehensive overview of Graph NeuralNetworks for\nNatural Language Processing.",
          "link": "http://arxiv.org/abs/2106.06090",
          "publishedOn": "2021-06-14T01:38:51.397Z",
          "wordCount": 614,
          "title": "Graph Neural Networks for Natural Language Processing: A Survey. (arXiv:2106.06090v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06087",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Finlayson_M/0/1/0/all/0/1\">Matthew Finlayson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mueller_A/0/1/0/all/0/1\">Aaron Mueller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shieber_S/0/1/0/all/0/1\">Stuart Shieber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gehrmann_S/0/1/0/all/0/1\">Sebastian Gehrmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Linzen_T/0/1/0/all/0/1\">Tal Linzen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belinkov_Y/0/1/0/all/0/1\">Yonatan Belinkov</a>",
          "description": "Targeted syntactic evaluations have demonstrated the ability of language\nmodels to perform subject-verb agreement given difficult contexts. To elucidate\nthe mechanisms by which the models accomplish this behavior, this study applies\ncausal mediation analysis to pre-trained neural language models. We investigate\nthe magnitude of models' preferences for grammatical inflections, as well as\nwhether neurons process subject-verb agreement similarly across sentences with\ndifferent syntactic structures. We uncover similarities and differences across\narchitectures and model sizes -- notably, that larger models do not necessarily\nlearn stronger preferences. We also observe two distinct mechanisms for\nproducing subject-verb agreement depending on the syntactic structure of the\ninput sentence. Finally, we find that language models rely on similar sets of\nneurons when given sentences with similar syntactic structure.",
          "link": "http://arxiv.org/abs/2106.06087",
          "publishedOn": "2021-06-14T01:38:51.386Z",
          "wordCount": 572,
          "title": "Causal Analysis of Syntactic Agreement Mechanisms in Neural Language Models. (arXiv:2106.06087v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06017",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hassan_S/0/1/0/all/0/1\">Sabit Hassan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shaar_S/0/1/0/all/0/1\">Shaden Shaar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Darwish_K/0/1/0/all/0/1\">Kareem Darwish</a>",
          "description": "Emotion detection is of great importance for understanding humans.\nConstructing annotated datasets to train automated models can be expensive. We\nexplore the efficacy of cross-lingual approaches that would use data from a\nsource language to build models for emotion detection in a target language. We\ncompare three approaches, namely: i) using inherently multilingual models; ii)\ntranslating training data into the target language; and iii) using an\nautomatically tagged parallel corpus. In our study, we consider English as the\nsource language with Arabic and Spanish as target languages. We study the\neffectiveness of different classification models such as BERT and SVMs trained\nwith different features. Our BERT-based monolingual models that are trained on\ntarget language data surpass state-of-the-art (SOTA) by 4% and 5% absolute\nJaccard score for Arabic and Spanish respectively. Next, we show that using\ncross-lingual approaches with English data alone, we can achieve more than 90%\nand 80% relative effectiveness of the Arabic and Spanish BERT models\nrespectively. Lastly, we use LIME to interpret the differences between models.",
          "link": "http://arxiv.org/abs/2106.06017",
          "publishedOn": "2021-06-14T01:38:51.364Z",
          "wordCount": 582,
          "title": "Cross-lingual Emotion Detection. (arXiv:2106.06017v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06038",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chowdhury_J/0/1/0/all/0/1\">Jishnu Ray Chowdhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caragea_C/0/1/0/all/0/1\">Cornelia Caragea</a>",
          "description": "Recursive Neural Networks (RvNNs), which compose sequences according to their\nunderlying hierarchical syntactic structure, have performed well in several\nnatural language processing tasks compared to similar models without structural\nbiases. However, traditional RvNNs are incapable of inducing the latent\nstructure in a plain text sequence on their own. Several extensions have been\nproposed to overcome this limitation. Nevertheless, these extensions tend to\nrely on surrogate gradients or reinforcement learning at the cost of higher\nbias or variance. In this work, we propose Continuous Recursive Neural Network\n(CRvNN) as a backpropagation-friendly alternative to address the aforementioned\nlimitations. This is done by incorporating a continuous relaxation to the\ninduced structure. We demonstrate that CRvNN achieves strong performance in\nchallenging synthetic tasks such as logical inference and ListOps. We also show\nthat CRvNN performs comparably or better than prior latent structure models on\nreal-world tasks such as sentiment analysis and natural language inference.",
          "link": "http://arxiv.org/abs/2106.06038",
          "publishedOn": "2021-06-14T01:38:51.346Z",
          "wordCount": 589,
          "title": "Modeling Hierarchical Structures with Continuous Recursive Neural Networks. (arXiv:2106.06038v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06082",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hauer_B/0/1/0/all/0/1\">Bradley Hauer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kondrak_G/0/1/0/all/0/1\">Grzegorz Kondrak</a>",
          "description": "The idea of using lexical translations to define sense inventories has a long\nhistory in lexical semantics. We propose a theoretical framework which allows\nus to answer the question of why this apparently reasonable idea failed to\nproduce useful results. We formally prove several propositions on how the\ntranslations of a word relate to its senses, as well as on the relationship\nbetween synonymy and polysemy. We empirically validate our theoretical findings\non BabelNet, and demonstrate how they could be used to perform unsupervised\nword sense disambiguation of a substantial fraction of the lexicon.",
          "link": "http://arxiv.org/abs/2106.06082",
          "publishedOn": "2021-06-14T01:38:51.306Z",
          "wordCount": 508,
          "title": "One Sense Per Translation. (arXiv:2106.06082v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06002",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Blodgett_A/0/1/0/all/0/1\">Austin Blodgett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schneider_N/0/1/0/all/0/1\">Nathan Schneider</a>",
          "description": "We present algorithms for aligning components of Abstract Meaning\nRepresentation (AMR) graphs to spans in English sentences. We leverage\nunsupervised learning in combination with heuristics, taking the best of both\nworlds from previous AMR aligners. Our unsupervised models, however, are more\nsensitive to graph substructures, without requiring a separate syntactic parse.\nOur approach covers a wider variety of AMR substructures than previously\nconsidered, achieves higher coverage of nodes and edges, and does so with\nhigher accuracy. We will release our LEAMR datasets and aligner for use in\nresearch on AMR parsing, generation, and evaluation.",
          "link": "http://arxiv.org/abs/2106.06002",
          "publishedOn": "2021-06-14T01:38:51.293Z",
          "wordCount": 527,
          "title": "Probabilistic, Structure-Aware Algorithms for Improved Variety, Accuracy, and Coverage of AMR Alignments. (arXiv:2106.06002v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05589",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xinnuo Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Guoyin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Young-Bum Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sungjin Lee</a>",
          "description": "Natural Language Generation (NLG) is a key component in a task-oriented\ndialogue system, which converts the structured meaning representation (MR) to\nthe natural language. For large-scale conversational systems, where it is\ncommon to have over hundreds of intents and thousands of slots, neither\ntemplate-based approaches nor model-based approaches are scalable. Recently,\nneural NLGs started leveraging transfer learning and showed promising results\nin few-shot settings. This paper proposes AUGNLG, a novel data augmentation\napproach that combines a self-trained neural retrieval model with a few-shot\nlearned NLU model, to automatically create MR-to-Text data from open-domain\ntexts. The proposed system mostly outperforms the state-of-the-art methods on\nthe FewShotWOZ data in both BLEU and Slot Error Rate. We further confirm\nimproved results on the FewShotSGD data and provide comprehensive analysis\nresults on key components of our system. Our code and data are available at\nhttps://github.com/XinnuoXu/AugNLG.",
          "link": "http://arxiv.org/abs/2106.05589",
          "publishedOn": "2021-06-11T01:42:17.736Z",
          "wordCount": null,
          "title": "AUGNLG: Few-shot Natural Language Generation using Self-trained Data Augmentation. (arXiv:2106.05589v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2010.13105",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Seongbin Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1\">Gyuwan Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_S/0/1/0/all/0/1\">Seongjin Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sangmin Lee</a>",
          "description": "End-to-end approaches open a new way for more accurate and efficient spoken\nlanguage understanding (SLU) systems by alleviating the drawbacks of\ntraditional pipeline systems. Previous works exploit textual information for an\nSLU model via pre-training with automatic speech recognition or fine-tuning\nwith knowledge distillation. To utilize textual information more effectively,\nthis work proposes a two-stage textual knowledge distillation method that\nmatches utterance-level representations and predicted logits of two modalities\nduring pre-training and fine-tuning, sequentially. We use vq-wav2vec BERT as a\nspeech encoder because it captures general and rich features. Furthermore, we\nimprove the performance, especially in a low-resource scenario, with data\naugmentation methods by randomly masking spans of discrete audio tokens and\ncontextualized hidden representations. Consequently, we push the\nstate-of-the-art on the Fluent Speech Commands, achieving 99.7% test accuracy\nin the full dataset setting and 99.5% in the 10% subset setting. Throughout the\nablation studies, we empirically verify that all used methods are crucial to\nthe final performance, providing the best practice for spoken language\nunderstanding. Code is available at https://github.com/clovaai/textual-kd-slu.",
          "link": "http://arxiv.org/abs/2010.13105",
          "publishedOn": "2021-06-11T01:42:17.722Z",
          "wordCount": null,
          "title": "Two-stage Textual Knowledge Distillation for End-to-End Spoken Language Understanding. (arXiv:2010.13105v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05768",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Althammer_S/0/1/0/all/0/1\">Sophia Althammer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buckley_M/0/1/0/all/0/1\">Mark Buckley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hofstatter_S/0/1/0/all/0/1\">Sebastian Hofst&#xe4;tter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hanbury_A/0/1/0/all/0/1\">Allan Hanbury</a>",
          "description": "Domain-specific contextualized language models have demonstrated substantial\neffectiveness gains for domain-specific downstream tasks, like similarity\nmatching, entity recognition or information retrieval. However successfully\napplying such models in highly specific language domains requires domain\nadaptation of the pre-trained models. In this paper we propose the empirically\nmotivated Linguistically Informed Masking (LIM) method to focus\ndomain-adaptative pre-training on the linguistic patterns of patents, which use\na highly technical sublanguage. We quantify the relevant differences between\npatent, scientific and general-purpose language and demonstrate for two\ndifferent language models (BERT and SciBERT) that domain adaptation with LIM\nleads to systematically improved representations by evaluating the performance\nof the domain-adapted representations of patent language on two independent\ndownstream tasks, the IPC classification and similarity matching. We\ndemonstrate the impact of balancing the learning from different information\nsources during domain adaptation for the patent domain. We make the source code\nas well as the domain-adaptive pre-trained patent language models publicly\navailable at https://github.com/sophiaalthammer/patent-lim.",
          "link": "http://arxiv.org/abs/2106.05768",
          "publishedOn": "2021-06-11T01:42:17.721Z",
          "wordCount": null,
          "title": "Linguistically Informed Masking for Representation Learning in the Patent Domain. (arXiv:2106.05768v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05822",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chelombiev_I/0/1/0/all/0/1\">Ivan Chelombiev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Justus_D/0/1/0/all/0/1\">Daniel Justus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Orr_D/0/1/0/all/0/1\">Douglas Orr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dietrich_A/0/1/0/all/0/1\">Anastasia Dietrich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gressmann_F/0/1/0/all/0/1\">Frithjof Gressmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koliousis_A/0/1/0/all/0/1\">Alexandros Koliousis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luschi_C/0/1/0/all/0/1\">Carlo Luschi</a>",
          "description": "Attention based language models have become a critical component in\nstate-of-the-art natural language processing systems. However, these models\nhave significant computational requirements, due to long training times, dense\noperations and large parameter count. In this work we demonstrate a set of\nmodifications to the structure of a Transformer layer, producing a more\nefficient architecture. First, we add a convolutional module to complement the\nself-attention module, decoupling the learning of local and global\ninteractions. Secondly, we rely on grouped transformations to reduce the\ncomputational cost of dense feed-forward layers and convolutions, while\npreserving the expressivity of the model. We apply the resulting architecture\nto language representation learning and demonstrate its superior performance\ncompared to BERT models of different scales. We further highlight its improved\nefficiency, both in terms of floating-point operations (FLOPs) and\ntime-to-train.",
          "link": "http://arxiv.org/abs/2106.05822",
          "publishedOn": "2021-06-11T01:42:17.681Z",
          "wordCount": null,
          "title": "GroupBERT: Enhanced Transformer Architecture with Efficient Grouped Structures. (arXiv:2106.05822v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05546",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ding_L/0/1/0/all/0/1\">Liang Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Longyue Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xuebo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_D/0/1/0/all/0/1\">Derek F. Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1\">Zhaopeng Tu</a>",
          "description": "Non-autoregressive translation (NAT) significantly accelerates the inference\nprocess via predicting the entire target sequence. However, recent studies show\nthat NAT is weak at learning high-mode of knowledge such as one-to-many\ntranslations. We argue that modes can be divided into various granularities\nwhich can be learned from easy to hard. In this study, we empirically show that\nNAT models are prone to learn fine-grained lower-mode knowledge, such as words\nand phrases, compared with sentences. Based on this observation, we propose\nprogressive multi-granularity training for NAT. More specifically, to make the\nmost of the training data, we break down the sentence-level examples into three\ntypes, i.e. words, phrases, sentences, and with the training goes, we\nprogressively increase the granularities. Experiments on Romanian-English,\nEnglish-German, Chinese-English, and Japanese-English demonstrate that our\napproach improves the phrase translation accuracy and model reordering ability,\ntherefore resulting in better translation quality against strong NAT baselines.\nAlso, we show that more deterministic fine-grained knowledge can further\nenhance performance.",
          "link": "http://arxiv.org/abs/2106.05546",
          "publishedOn": "2021-06-11T01:42:17.661Z",
          "wordCount": 590,
          "title": "Progressive Multi-Granularity Training for Non-Autoregressive Translation. (arXiv:2106.05546v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05346",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sachan_D/0/1/0/all/0/1\">Devendra Singh Sachan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reddy_S/0/1/0/all/0/1\">Siva Reddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamilton_W/0/1/0/all/0/1\">William Hamilton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dyer_C/0/1/0/all/0/1\">Chris Dyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yogatama_D/0/1/0/all/0/1\">Dani Yogatama</a>",
          "description": "We present an end-to-end differentiable training method for\nretrieval-augmented open-domain question answering systems that combine\ninformation from multiple retrieved documents when generating answers. We model\nretrieval decisions as latent variables over sets of relevant documents. Since\nmarginalizing over sets of retrieved documents is computationally hard, we\napproximate this using an expectation-maximization algorithm. We iteratively\nestimate the value of our latent variable (the set of relevant documents for a\ngiven question) and then use this estimate to update the retriever and reader\nparameters. We hypothesize that such end-to-end training allows training\nsignals to flow to the reader and then to the retriever better than staged-wise\ntraining. This results in a retriever that is able to select more relevant\ndocuments for a question and a reader that is trained on more accurate\ndocuments to generate an answer. Experiments on three benchmark datasets\ndemonstrate that our proposed method outperforms all existing approaches of\ncomparable size by 2-3% absolute exact match points, achieving new\nstate-of-the-art results. Our results also demonstrate the feasibility of\nlearning to retrieve to improve answer generation without explicit supervision\nof retrieval decisions.",
          "link": "http://arxiv.org/abs/2106.05346",
          "publishedOn": "2021-06-11T01:42:17.624Z",
          "wordCount": null,
          "title": "End-to-End Training of Multi-Document Reader and Retriever for Open-Domain Question Answering. (arXiv:2106.05346v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05387",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Murugesan_K/0/1/0/all/0/1\">Keerthiram Murugesan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhury_S/0/1/0/all/0/1\">Subhajit Chaudhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Talamadupula_K/0/1/0/all/0/1\">Kartik Talamadupula</a>",
          "description": "Text-based games (TBGs) have become a popular proving ground for the\ndemonstration of learning-based agents that make decisions in quasi real-world\nsettings. The crux of the problem for a reinforcement learning agent in such\nTBGs is identifying the objects in the world, and those objects' relations with\nthat world. While the recent use of text-based resources for increasing an\nagent's knowledge and improving its generalization have shown promise, we posit\nin this paper that there is much yet to be learned from visual representations\nof these same worlds. Specifically, we propose to retrieve images that\nrepresent specific instances of text observations from the world and train our\nagents on such images. This improves the agent's overall understanding of the\ngame 'scene' and objects' relationships to the world around them, and the\nvariety of visual representations on offer allow the agent to generate a better\ngeneralization of a relationship. We show that incorporating such images\nimproves the performance of agents in various TBG settings.",
          "link": "http://arxiv.org/abs/2106.05387",
          "publishedOn": "2021-06-11T01:42:17.618Z",
          "wordCount": null,
          "title": "Eye of the Beholder: Improved Relation Generalization for Text-based Reinforcement Learning Agents. (arXiv:2106.05387v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05707",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aly_R/0/1/0/all/0/1\">Rami Aly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1\">Zhijiang Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schlichtkrull_M/0/1/0/all/0/1\">Michael Schlichtkrull</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thorne_J/0/1/0/all/0/1\">James Thorne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vlachos_A/0/1/0/all/0/1\">Andreas Vlachos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Christodoulopoulos_C/0/1/0/all/0/1\">Christos Christodoulopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cocarascu_O/0/1/0/all/0/1\">Oana Cocarascu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mittal_A/0/1/0/all/0/1\">Arpit Mittal</a>",
          "description": "Fact verification has attracted a lot of attention in the machine learning\nand natural language processing communities, as it is one of the key methods\nfor detecting misinformation. Existing large-scale benchmarks for this task\nhave focused mostly on textual sources, i.e. unstructured information, and thus\nignored the wealth of information available in structured formats, such as\ntables. In this paper we introduce a novel dataset and benchmark, Fact\nExtraction and VERification Over Unstructured and Structured information\n(FEVEROUS), which consists of 87,026 verified claims. Each claim is annotated\nwith evidence in the form of sentences and/or cells from tables in Wikipedia,\nas well as a label indicating whether this evidence supports, refutes, or does\nnot provide enough information to reach a verdict. Furthermore, we detail our\nefforts to track and minimize the biases present in the dataset and could be\nexploited by models, e.g. being able to predict the label without using\nevidence. Finally, we develop a baseline for verifying claims against text and\ntables which predicts both the correct evidence and verdict for 18% of the\nclaims.",
          "link": "http://arxiv.org/abs/2106.05707",
          "publishedOn": "2021-06-11T01:42:17.113Z",
          "wordCount": 614,
          "title": "FEVEROUS: Fact Extraction and VERification Over Unstructured and Structured information. (arXiv:2106.05707v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05677",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Murauer_B/0/1/0/all/0/1\">Benjamin Murauer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Specht_G/0/1/0/all/0/1\">G&#xfc;nther Specht</a>",
          "description": "Cross-language authorship attribution problems rely on either translation to\nenable the use of single-language features, or language-independent feature\nextraction methods. Until recently, the lack of datasets for this problem\nhindered the development of the latter, and single-language solutions were\nperformed on machine-translated corpora. In this paper, we present a novel\nlanguage-independent feature for authorship analysis based on dependency graphs\nand universal part of speech tags, called DT-grams (dependency tree grams),\nwhich are constructed by selecting specific sub-parts of the dependency graph\nof sentences. We evaluate DT-grams by performing cross-language authorship\nattribution on untranslated datasets of bilingual authors, showing that, on\naverage, they achieve a macro-averaged F1 score of 0.081 higher than previous\nmethods across five different language pairs. Additionally, by providing\nresults for a diverse set of features for comparison, we provide a baseline on\nthe previously undocumented task of untranslated cross-language authorship\nattribution.",
          "link": "http://arxiv.org/abs/2106.05677",
          "publishedOn": "2021-06-11T01:42:17.006Z",
          "wordCount": 577,
          "title": "DT-grams: Structured Dependency Grammar Stylometry for Cross-Language Authorship Attribution. (arXiv:2106.05677v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2101.07597",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chengyi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1\">Yao Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumatani_K/0/1/0/all/0/1\">Kenichi Kumatani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shujie Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_M/0/1/0/all/0/1\">Michael Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuedong Huang</a>",
          "description": "In this paper, we propose a unified pre-training approach called UniSpeech to\nlearn speech representations with both unlabeled and labeled data, in which\nsupervised phonetic CTC learning and phonetically-aware contrastive\nself-supervised learning are conducted in a multi-task learning manner. The\nresultant representations can capture information more correlated with phonetic\nstructures and improve the generalization across languages and domains. We\nevaluate the effectiveness of UniSpeech for cross-lingual representation\nlearning on public CommonVoice corpus. The results show that UniSpeech\noutperforms self-supervised pretraining and supervised transfer learning for\nspeech recognition by a maximum of 13.4% and 17.8% relative phone error rate\nreductions respectively (averaged over all testing languages). The\ntransferability of UniSpeech is also demonstrated on a domain-shift speech\nrecognition task, i.e., a relative word error rate reduction of 6% against the\nprevious approach.",
          "link": "http://arxiv.org/abs/2101.07597",
          "publishedOn": "2021-06-11T01:42:16.922Z",
          "wordCount": 618,
          "title": "UniSpeech: Unified Speech Representation Learning with Labeled and Unlabeled Data. (arXiv:2101.07597v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05664",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hada_R/0/1/0/all/0/1\">Rishav Hada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sudhir_S/0/1/0/all/0/1\">Sohi Sudhir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_P/0/1/0/all/0/1\">Pushkar Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yannakoudakis_H/0/1/0/all/0/1\">Helen Yannakoudakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohammad_S/0/1/0/all/0/1\">Saif M. Mohammad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shutova_E/0/1/0/all/0/1\">Ekaterina Shutova</a>",
          "description": "On social media platforms, hateful and offensive language negatively impact\nthe mental well-being of users and the participation of people from diverse\nbackgrounds. Automatic methods to detect offensive language have largely relied\non datasets with categorical labels. However, comments can vary in their degree\nof offensiveness. We create the first dataset of English language Reddit\ncomments that has \\textit{fine-grained, real-valued scores} between -1\n(maximally supportive) and 1 (maximally offensive). The dataset was annotated\nusing \\emph{Best--Worst Scaling}, a form of comparative annotation that has\nbeen shown to alleviate known biases of using rating scales. We show that the\nmethod produces highly reliable offensiveness scores. Finally, we evaluate the\nability of widely-used neural models to predict offensiveness scores on this\nnew dataset.",
          "link": "http://arxiv.org/abs/2106.05664",
          "publishedOn": "2021-06-11T01:42:16.764Z",
          "wordCount": 561,
          "title": "Ruddit: Norms of Offensiveness for English Reddit Comments. (arXiv:2106.05664v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05365",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1\">Weijia Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_M/0/1/0/all/0/1\">Mandar Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1\">Luke Zettlemoyer</a>",
          "description": "Short textual descriptions of entities provide summaries of their key\nattributes and have been shown to be useful sources of background knowledge for\ntasks such as entity linking and question answering. However, generating entity\ndescriptions, especially for new and long-tail entities, can be challenging\nsince relevant information is often scattered across multiple sources with\nvaried content and style. We introduce DESCGEN: given mentions spread over\nmultiple documents, the goal is to generate an entity summary description.\nDESCGEN consists of 37K entity descriptions from Wikipedia and Fandom, each\npaired with nine evidence documents on average. The documents were collected\nusing a combination of entity linking and hyperlinks to the Wikipedia and\nFandom entity pages, which together provide high-quality distant supervision.\nThe resulting summaries are more abstractive than those found in existing\ndatasets and provide a better proxy for the challenge of describing new and\nemerging entities. We also propose a two-stage extract-then-generate baseline\nand show that there exists a large gap (19.9% in ROUGE-L) between\nstate-of-the-art models and human performance, suggesting that the data will\nsupport significant future work.",
          "link": "http://arxiv.org/abs/2106.05365",
          "publishedOn": "2021-06-11T01:42:16.695Z",
          "wordCount": 611,
          "title": "DESCGEN: A Distantly Supervised Datasetfor Generating Abstractive Entity Descriptions. (arXiv:2106.05365v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2102.10992",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chacoma_A/0/1/0/all/0/1\">A. Chacoma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zanette_D/0/1/0/all/0/1\">D. H. Zanette</a>",
          "description": "We analyze the frequency-rank relationship in sub-vocabularies corresponding\nto three different grammatical classes (nouns, verbs, and others) in a\ncollection of literary works in English, whose words have been automatically\ntagged according to their grammatical role. Comparing with a null hypothesis\nwhich assumes that words belonging to each class are uniformly distributed\nacross the frequency-ranked vocabulary of the whole work, we disclose\nstatistically significant differences between the three classes. This results\npoint to the fact that frequency-rank relationships may reflect linguistic\nfeatures associated with grammatical function.",
          "link": "http://arxiv.org/abs/2102.10992",
          "publishedOn": "2021-06-11T01:42:16.346Z",
          "wordCount": 536,
          "title": "Word frequency-rank relationship in tagged texts. (arXiv:2102.10992v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05784",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schuster_T/0/1/0/all/0/1\">Tal Schuster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalyan_A/0/1/0/all/0/1\">Ashwin Kalyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Polozov_O/0/1/0/all/0/1\">Oleksandr Polozov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalai_A/0/1/0/all/0/1\">Adam Tauman Kalai</a>",
          "description": "We introduce a new type of programming challenge called programming puzzles,\nas an objective and comprehensive evaluation of program synthesis, and release\nan open-source dataset of Python Programming Puzzles (P3). Each puzzle is\ndefined by a short Python program $f$, and the goal is to find an input $x$\nwhich makes $f$ output \"True\". The puzzles are objective in that each one is\nspecified entirely by the source code of its verifier $f$, so evaluating $f(x)$\nis all that is needed to test a candidate solution $x$. They do not require an\nanswer key or input/output examples, nor do they depend on natural language\nunderstanding. The dataset is comprehensive in that it spans problems of a\nrange of difficulties and domains, ranging from trivial string manipulation\nproblems that are immediately obvious to human programmers (but not necessarily\nto AI), to classic programming puzzles (e.g., Towers of Hanoi), to\ninterview/competitive-programming problems (e.g., dynamic programming), to\nlongstanding open problems in algorithms and mathematics (e.g., factoring). The\nobjective nature of P3 readily supports self-supervised bootstrapping. We\ndevelop baseline enumerative program synthesis and GPT-3 solvers that are\ncapable of solving easy puzzles -- even without access to any reference\nsolutions -- by learning from their own past solutions. Based on a small user\nstudy, we find puzzle difficulty to correlate between human programmers and the\nbaseline AI solvers.",
          "link": "http://arxiv.org/abs/2106.05784",
          "publishedOn": "2021-06-11T01:42:16.254Z",
          "wordCount": 661,
          "title": "Programming Puzzles. (arXiv:2106.05784v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.02692",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Seanie Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_M/0/1/0/all/0/1\">Minki Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Juho Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1\">Sung Ju Hwang</a>",
          "description": "QA models based on pretrained language mod-els have achieved remarkable\nperformance onv arious benchmark datasets.However, QA models do not generalize\nwell to unseen data that falls outside the training distribution, due to\ndistributional shifts.Data augmentation(DA) techniques which drop/replace words\nhave shown to be effective in regularizing the model from overfitting to the\ntraining data.Yet, they may adversely affect the QA tasks since they incur\nsemantic changes that may lead to wrong answers for the QA task. To tackle this\nproblem, we propose a simple yet effective DA method based on a stochastic\nnoise generator, which learns to perturb the word embedding of the input\nquestions and context without changing their semantics. We validate the\nperformance of the QA models trained with our word embedding perturbation on a\nsingle source dataset, on five different target domains.The results show that\nour method significantly outperforms the baselineDA methods. Notably, the model\ntrained with ours outperforms the model trained with more than 240K\nartificially generated QA pairs.",
          "link": "http://arxiv.org/abs/2105.02692",
          "publishedOn": "2021-06-11T01:42:15.298Z",
          "wordCount": 621,
          "title": "Learning to Perturb Word Embeddings for Out-of-distribution QA. (arXiv:2105.02692v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.08399",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liutkus_A/0/1/0/all/0/1\">Antoine Liutkus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cifka_O/0/1/0/all/0/1\">Ond&#x159;ej C&#xed;fka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shih-Lun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simsekli_U/0/1/0/all/0/1\">Umut &#x15e;im&#x15f;ekli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yi-Hsuan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Richard_G/0/1/0/all/0/1\">Ga&#xeb;l Richard</a>",
          "description": "Recent advances in Transformer models allow for unprecedented sequence\nlengths, due to linear space and time complexity. In the meantime, relative\npositional encoding (RPE) was proposed as beneficial for classical Transformers\nand consists in exploiting lags instead of absolute positions for inference.\nStill, RPE is not available for the recent linear-variants of the Transformer,\nbecause it requires the explicit computation of the attention matrix, which is\nprecisely what is avoided by such methods. In this paper, we bridge this gap\nand present Stochastic Positional Encoding as a way to generate PE that can be\nused as a replacement to the classical additive (sinusoidal) PE and provably\nbehaves like RPE. The main theoretical contribution is to make a connection\nbetween positional encoding and cross-covariance structures of correlated\nGaussian processes. We illustrate the performance of our approach on the\nLong-Range Arena benchmark and on music generation.",
          "link": "http://arxiv.org/abs/2105.08399",
          "publishedOn": "2021-06-11T01:42:15.213Z",
          "wordCount": 630,
          "title": "Relative Positional Encoding for Transformers with Linear Complexity. (arXiv:2105.08399v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.00171",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1\">Yao-Fei Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hung-Shin Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hsin-Min Wang</a>",
          "description": "The end-to-end architecture has made promising progress in speech translation\n(ST). However, the ST task is still challenging under low-resource conditions.\nMost ST models have shown unsatisfactory results, especially in the absence of\nword information from the source speech utterance. In this study, we survey\nmethods to improve ST performance without using source transcription, and\npropose a learning framework that utilizes a language-independent universal\nphone recognizer. The framework is based on an attention-based\nsequence-to-sequence model, where the encoder generates the phonetic embeddings\nand phone-aware acoustic representations, and the decoder controls the fusion\nof the two embedding streams to produce the target token sequence. In addition\nto investigating different fusion strategies, we explore the specific usage of\nbyte pair encoding (BPE), which compresses a phone sequence into a\nsyllable-like segmented sequence. Due to the conversion of symbols, a segmented\nsequence represents not only pronunciation but also language-dependent\ninformation lacking in phones. Experiments conducted on the Fisher\nSpanish-English and Taigi-Mandarin drama corpora show that our method\noutperforms the conformer-based baseline, and the performance is close to that\nof the existing best method using source transcription.",
          "link": "http://arxiv.org/abs/2105.00171",
          "publishedOn": "2021-06-11T01:42:15.185Z",
          "wordCount": 634,
          "title": "AlloST: Low-resource Speech Translation without Source Transcription. (arXiv:2105.00171v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01093",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cao_R/0/1/0/all/0/1\">Ruisheng Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yanbin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1\">Su Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_K/0/1/0/all/0/1\">Kai Yu</a>",
          "description": "This work aims to tackle the challenging heterogeneous graph encoding problem\nin the text-to-SQL task. Previous methods are typically node-centric and merely\nutilize different weight matrices to parameterize edge types, which 1) ignore\nthe rich semantics embedded in the topological structure of edges, and 2) fail\nto distinguish local and non-local relations for each node. To this end, we\npropose a Line Graph Enhanced Text-to-SQL (LGESQL) model to mine the underlying\nrelational features without constructing meta-paths. By virtue of the line\ngraph, messages propagate more efficiently through not only connections between\nnodes, but also the topology of directed edges. Furthermore, both local and\nnon-local relations are integrated distinctively during the graph iteration. We\nalso design an auxiliary task called graph pruning to improve the\ndiscriminative capability of the encoder. Our framework achieves\nstate-of-the-art results (62.8% with Glove, 72.0% with Electra) on the\ncross-domain text-to-SQL benchmark Spider at the time of writing.",
          "link": "http://arxiv.org/abs/2106.01093",
          "publishedOn": "2021-06-11T01:42:15.121Z",
          "wordCount": 626,
          "title": "LGESQL: Line Graph Enhanced Text-to-SQL Model with Mixed Local and Non-Local Relations. (arXiv:2106.01093v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03161",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ulinskaite_J/0/1/0/all/0/1\">Jogil&#x117; Ulinskait&#x117;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pukelis_L/0/1/0/all/0/1\">Lukas Pukelis</a>",
          "description": "Abstract: In this paper we present an approach to develop a\ntext-classification model which would be able to identify populist content in\ntext. The developed BERT-based model is largely successful in identifying\npopulist content in text and produces only a negligible amount of False\nNegatives, which makes it well-suited as a content analysis automation tool,\nwhich shortlists potentially relevant content for human validation.",
          "link": "http://arxiv.org/abs/2106.03161",
          "publishedOn": "2021-06-11T01:42:14.310Z",
          "wordCount": 515,
          "title": "Identifying Populist Paragraphs in Text: A machine-learning approach. (arXiv:2106.03161v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.04298",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Vieting_P/0/1/0/all/0/1\">Peter Vieting</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Luscher_C/0/1/0/all/0/1\">Christoph L&#xfc;scher</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Michel_W/0/1/0/all/0/1\">Wilfried Michel</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Schluter_R/0/1/0/all/0/1\">Ralf Schl&#xfc;ter</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ney_H/0/1/0/all/0/1\">Hermann Ney</a>",
          "description": "Acoustic modeling of raw waveform and learning feature extractors as part of\nthe neural network classifier has been the goal of many studies in the area of\nautomatic speech recognition (ASR). Recently, one line of research has focused\non frameworks that can be pre-trained on audio-only data in an unsupervised\nfashion and aim at improving downstream ASR tasks. In this work, we investigate\nthe usefulness of one of these front-end frameworks, namely wav2vec, for hybrid\nASR systems. In addition to deploying a pre-trained feature extractor, we\nexplore how to make use of an existing acoustic model (AM) trained on the same\ntask with different features as well. Another neural front-end which is only\ntrained together with the supervised ASR loss as well as traditional Gammatone\nfeatures are applied for comparison. Moreover, it is shown that the AM can be\nretrofitted with i-vectors for speaker adaptation. Finally, the described\nfeatures are combined in order to further advance the performance. With the\nfinal best system, we obtain a relative improvement of 4% and 6% over our\nprevious best model on the LibriSpeech test-clean and test-other sets.",
          "link": "http://arxiv.org/abs/2104.04298",
          "publishedOn": "2021-06-11T01:42:14.294Z",
          "wordCount": 648,
          "title": "Feature Replacement and Combination for Hybrid ASR Systems. (arXiv:2104.04298v2 [eess.AS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.05379",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rossenbach_N/0/1/0/all/0/1\">Nick Rossenbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeineldeen_M/0/1/0/all/0/1\">Mohammad Zeineldeen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hilmes_B/0/1/0/all/0/1\">Benedikt Hilmes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schluter_R/0/1/0/all/0/1\">Ralf Schl&#xfc;ter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ney_H/0/1/0/all/0/1\">Hermann Ney</a>",
          "description": "Recent publications on automatic-speech-recognition (ASR) have a strong focus\non attention encoder-decoder (AED) architectures which work well for large\ndatasets, but tend to overfit when applied in low resource scenarios. One\nsolution to tackle this issue is to generate synthetic data with a trained\ntext-to-speech system (TTS) if additional text is available. This was\nsuccessfully applied in many publications with AED systems. We present a novel\napproach of silence correction in the data pre-processing for TTS systems which\nincreases the robustness when training on corpora targeted for ASR\napplications. In this work we do not only show the successful application of\nsynthetic data for AED systems, but also test the same method on a highly\noptimized state-of-the-art Hybrid ASR system and a competitive monophone based\nsystem using connectionist-temporal-classification (CTC). We show that for the\nlater systems the addition of synthetic data only has a minor effect, but they\nstill outperform the AED systems by a large margin on LibriSpeech-100h. We\nachieve a final word-error-rate of 3.3%/10.0% with a Hybrid system on the\nclean/noisy test-sets, surpassing any previous state-of-the-art systems that do\nnot include unlabeled audio data.",
          "link": "http://arxiv.org/abs/2104.05379",
          "publishedOn": "2021-06-11T01:42:14.140Z",
          "wordCount": 657,
          "title": "Comparing the Benefit of Synthetic Training Data for Various Automatic Speech Recognition Architectures. (arXiv:2104.05379v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03084",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jinpeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_B/0/1/0/all/0/1\">Baijun Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_N/0/1/0/all/0/1\">Nini Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_X/0/1/0/all/0/1\">Xiangyu Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Min Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yangbin Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_W/0/1/0/all/0/1\">Weihua Luo</a>",
          "description": "Bilingual Lexicon Induction (BLI) aims to map words in one language to their\ntranslations in another, and is typically through learning linear projections\nto align monolingual word representation spaces. Two classes of word\nrepresentations have been explored for BLI: static word embeddings and\ncontextual representations, but there is no studies to combine both. In this\npaper, we propose a simple yet effective mechanism to combine the static word\nembeddings and the contextual representations to utilize the advantages of both\nparadigms. We test the combination mechanism on various language pairs under\nthe supervised and unsupervised BLI benchmark settings. Experiments show that\nour mechanism consistently improves performances over robust BLI baselines on\nall language pairs by averagely improving 3.2 points in the supervised setting,\nand 3.1 points in the unsupervised setting.",
          "link": "http://arxiv.org/abs/2106.03084",
          "publishedOn": "2021-06-11T01:42:14.129Z",
          "wordCount": 589,
          "title": "Combining Static Word Embeddings and Contextual Representations for Bilingual Lexicon Induction. (arXiv:2106.03084v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.11462",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Evain_S/0/1/0/all/0/1\">Solene Evain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1\">Ha Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_H/0/1/0/all/0/1\">Hang Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boito_M/0/1/0/all/0/1\">Marcely Zanon Boito</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mdhaffar_S/0/1/0/all/0/1\">Salima Mdhaffar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alisamir_S/0/1/0/all/0/1\">Sina Alisamir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_Z/0/1/0/all/0/1\">Ziyi Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomashenko_N/0/1/0/all/0/1\">Natalia Tomashenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dinarelli_M/0/1/0/all/0/1\">Marco Dinarelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parcollet_T/0/1/0/all/0/1\">Titouan Parcollet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Allauzen_A/0/1/0/all/0/1\">Alexandre Allauzen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Esteve_Y/0/1/0/all/0/1\">Yannick Esteve</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lecouteux_B/0/1/0/all/0/1\">Benjamin Lecouteux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Portet_F/0/1/0/all/0/1\">Francois Portet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rossato_S/0/1/0/all/0/1\">Solange Rossato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ringeval_F/0/1/0/all/0/1\">Fabien Ringeval</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schwab_D/0/1/0/all/0/1\">Didier Schwab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Besacier_L/0/1/0/all/0/1\">Laurent Besacier</a>",
          "description": "Self-Supervised Learning (SSL) using huge unlabeled data has been\nsuccessfully explored for image and natural language processing. Recent works\nalso investigated SSL from speech. They were notably successful to improve\nperformance on downstream tasks such as automatic speech recognition (ASR).\nWhile these works suggest it is possible to reduce dependence on labeled data\nfor building efficient speech systems, their evaluation was mostly made on ASR\nand using multiple and heterogeneous experimental settings (most of them for\nEnglish). This questions the objective comparison of SSL approaches and the\nevaluation of their impact on building speech systems. In this paper, we\npropose LeBenchmark: a reproducible framework for assessing SSL from speech. It\nnot only includes ASR (high and low resource) tasks but also spoken language\nunderstanding, speech translation and emotion recognition. We also focus on\nspeech technologies in a language different than English: French. SSL models of\ndifferent sizes are trained from carefully sourced and documented datasets.\nExperiments show that SSL is beneficial for most but not all tasks which\nconfirms the need for exhaustive and reliable benchmarks to evaluate its real\nimpact. LeBenchmark is shared with the scientific community for reproducible\nresearch in SSL from speech.",
          "link": "http://arxiv.org/abs/2104.11462",
          "publishedOn": "2021-06-11T01:42:14.107Z",
          "wordCount": 706,
          "title": "LeBenchmark: A Reproducible Framework for Assessing Self-Supervised Representation Learning from Speech. (arXiv:2104.11462v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.15079",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Phan_L/0/1/0/all/0/1\">Luong Luc Phan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pham_P/0/1/0/all/0/1\">Phuc Huynh Pham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1\">Kim Thi-Thanh Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Tham Thi Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huynh_S/0/1/0/all/0/1\">Sieu Khai Huynh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_L/0/1/0/all/0/1\">Luan Thanh Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huynh_T/0/1/0/all/0/1\">Tin Van Huynh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1\">Kiet Van Nguyen</a>",
          "description": "In this paper, we present a process of building a social listening system\nbased on aspect-based sentiment analysis in Vietnamese from creating a dataset\nto building a real application. Firstly, we create UIT-ViSFD, a Vietnamese\nSmartphone Feedback Dataset as a new benchmark corpus built based on a strict\nannotation schemes for evaluating aspect-based sentiment analysis, consisting\nof 11,122 human-annotated comments for mobile e-commerce, which is freely\navailable for research purposes. We also present a proposed approach based on\nthe Bi-LSTM architecture with the fastText word embeddings for the Vietnamese\naspect based sentiment task. Our experiments show that our approach achieves\nthe best performances with the F1-score of 84.48% for the aspect task and\n63.06% for the sentiment task, which performs several conventional machine\nlearning and deep learning systems. Last but not least, we build SA2SL, a\nsocial listening system based on the best performance model on our dataset,\nwhich will inspire more social listening systems in future.",
          "link": "http://arxiv.org/abs/2105.15079",
          "publishedOn": "2021-06-11T01:42:14.079Z",
          "wordCount": 624,
          "title": "SA2SL: From Aspect-Based Sentiment Analysis to Social Listening System for Business Intelligence. (arXiv:2105.15079v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.00259",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Norouzi_S/0/1/0/all/0/1\">Sajad Norouzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_K/0/1/0/all/0/1\">Keyi Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yanshuai Cao</a>",
          "description": "Training datasets for semantic parsing are typically small due to the higher\nexpertise required for annotation than most other NLP tasks. As a result,\nmodels for this application usually need additional prior knowledge to be built\ninto the architecture or algorithm. The increased dependency on human experts\nhinders automation and raises the development and maintenance costs in\npractice. This work investigates whether a generic transformer-based seq2seq\nmodel can achieve competitive performance with minimal code-generation-specific\ninductive bias design. By exploiting a relatively sizeable monolingual corpus\nof the target programming language, which is cheap to mine from the web, we\nachieved 81.03% exact match accuracy on Django and 32.57 BLEU score on CoNaLa.\nBoth are SOTA to the best of our knowledge. This positive evidence highlights a\npotentially easier path toward building accurate semantic parsers in practice.",
          "link": "http://arxiv.org/abs/2101.00259",
          "publishedOn": "2021-06-11T01:42:14.063Z",
          "wordCount": 599,
          "title": "Code Generation from Natural Language with Less Prior and More Monolingual Data. (arXiv:2101.00259v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.09625",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">John Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berlot_Attwell_I/0/1/0/all/0/1\">Ian Berlot-Attwell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hossain_S/0/1/0/all/0/1\">Safwan Hossain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xindi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rudzicz_F/0/1/0/all/0/1\">Frank Rudzicz</a>",
          "description": "Clinical machine learning is increasingly multimodal, collected in both\nstructured tabular formats and unstructured forms such as freetext. We propose\na novel task of exploring fairness on a multimodal clinical dataset, adopting\nequalized odds for the downstream medical prediction tasks. To this end, we\ninvestigate a modality-agnostic fairness algorithm - equalized odds post\nprocessing - and compare it to a text-specific fairness algorithm: debiased\nclinical word embeddings. Despite the fact that debiased word embeddings do not\nexplicitly address equalized odds of protected groups, we show that a\ntext-specific approach to fairness may simultaneously achieve a good balance of\nperformance and classical notions of fairness. We hope that our paper inspires\nfuture contributions at the critical intersection of clinical NLP and fairness.\nThe full source code is available here:\nhttps://github.com/johntiger1/multimodal_fairness",
          "link": "http://arxiv.org/abs/2011.09625",
          "publishedOn": "2021-06-11T01:42:14.056Z",
          "wordCount": 625,
          "title": "Exploring Text Specific and Blackbox Fairness Algorithms in Multimodal Clinical NLP. (arXiv:2011.09625v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.10018",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1\">Chengqi Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mingxuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>",
          "description": "NeurST is an open-source toolkit for neural speech translation. The toolkit\nmainly focuses on end-to-end speech translation, which is easy to use, modify,\nand extend to advanced speech translation research and products. NeurST aims at\nfacilitating the speech translation research for NLP researchers and building\nreliable benchmarks for this field. It provides step-by-step recipes for\nfeature extraction, data preprocessing, distributed training, and evaluation.\nIn this paper, we will introduce the framework design of NeurST and show\nexperimental results for different benchmark datasets, which can be regarded as\nreliable baselines for future research. The toolkit is publicly available at\nhttps://github.com/bytedance/neurst/ and we will continuously update the\nperformance of NeurST with other counterparts and studies at\nhttps://st-benchmark.github.io/.",
          "link": "http://arxiv.org/abs/2012.10018",
          "publishedOn": "2021-06-11T01:42:14.035Z",
          "wordCount": 582,
          "title": "NeurST: Neural Speech Translation Toolkit. (arXiv:2012.10018v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.07144",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1\">Jason Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meister_C/0/1/0/all/0/1\">Clara Meister</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>",
          "description": "The uniform information density (UID) hypothesis, which posits that speakers\nbehaving optimally tend to distribute information uniformly across a linguistic\nsignal, has gained traction in psycholinguistics as an explanation for certain\nsyntactic, morphological, and prosodic choices. In this work, we explore\nwhether the UID hypothesis can be operationalized as an inductive bias for\nstatistical language modeling. Specifically, we augment the canonical MLE\nobjective for training language models with a regularizer that encodes UID. In\nexperiments on ten languages spanning five language families, we find that\nusing UID regularization consistently improves perplexity in language models,\nhaving a larger effect when training data is limited. Moreover, via an analysis\nof generated sequences, we find that UID-regularized language models have other\ndesirable properties, e.g., they generate text that is more lexically diverse.\nOur results not only suggest that UID is a reasonable inductive bias for\nlanguage modeling, but also provide an alternative validation of the UID\nhypothesis using modern-day NLP tools.",
          "link": "http://arxiv.org/abs/2105.07144",
          "publishedOn": "2021-06-11T01:42:14.030Z",
          "wordCount": 623,
          "title": "A Cognitive Regularizer for Language Modeling. (arXiv:2105.07144v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.01393",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lam_T/0/1/0/all/0/1\">Tsz Kin Lam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ohta_M/0/1/0/all/0/1\">Mayumi Ohta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schamoni_S/0/1/0/all/0/1\">Shigehiko Schamoni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riezler_S/0/1/0/all/0/1\">Stefan Riezler</a>",
          "description": "We propose an on-the-fly data augmentation method for automatic speech\nrecognition (ASR) that uses alignment information to generate effective\ntraining samples. Our method, called Aligned Data Augmentation (ADA) for ASR,\nreplaces transcribed tokens and the speech representations in an aligned manner\nto generate previously unseen training pairs. The speech representations are\nsampled from an audio dictionary that has been extracted from the training\ncorpus and inject speaker variations into the training examples. The\ntranscribed tokens are either predicted by a language model such that the\naugmented data pairs are semantically close to the original data, or randomly\nsampled. Both strategies result in training pairs that improve robustness in\nASR training. Our experiments on a Seq-to-Seq architecture show that ADA can be\napplied on top of SpecAugment, and achieves about 9-23% and 4-15% relative\nimprovements in WER over SpecAugment alone on LibriSpeech 100h and LibriSpeech\n960h test datasets, respectively.",
          "link": "http://arxiv.org/abs/2104.01393",
          "publishedOn": "2021-06-11T01:42:14.014Z",
          "wordCount": 614,
          "title": "On-the-Fly Aligned Data Augmentation for Sequence-to-Sequence ASR. (arXiv:2104.01393v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05885",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hussein_A/0/1/0/all/0/1\">Amir Hussein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chowdhury_S/0/1/0/all/0/1\">Shammur Chowdhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ali_A/0/1/0/all/0/1\">Ahmed Ali</a>",
          "description": "In this paper, we present the Kanari/QCRI (KARI) system and the modeling\nstrategies used to participate in the Interspeech 2021 Code-switching (CS)\nchallenge for low-resource Indian languages. The subtask involved developing a\nspeech recognition system for two CS datasets: Hindi-English and\nBengali-English, collected in a real-life scenario. To tackle the CS\nchallenges, we use transfer learning for incorporating the publicly available\nmonolingual Hindi, Bengali, and English speech data. In this work, we study the\neffectiveness of two steps transfer learning protocol for low-resourced CS\ndata: monolingual pretraining, followed by fine-tuning. For acoustic modeling,\nwe develop an end-to-end convolution-augmented transformer (Conformer). We show\nthat selecting the percentage of each monolingual data affects model biases\ntowards using one language character set over the other in a CS scenario. The\nmodels pretrained on well-aligned and accurate monolingual data showed\nrobustness against misalignment between the segments and the transcription.\nFinally, we develop word-level n-gram language models (LM) to rescore ASR\nrecognition.",
          "link": "http://arxiv.org/abs/2106.05885",
          "publishedOn": "2021-06-11T01:42:13.987Z",
          "wordCount": 591,
          "title": "KARI: KAnari/QCRI's End-to-End systems for the INTERSPEECH 2021 Indian Languages Code-Switching Challenge. (arXiv:2106.05885v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05903",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Botelho_A/0/1/0/all/0/1\">Austin Botelho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vidgen_B/0/1/0/all/0/1\">Bertie Vidgen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hale_S/0/1/0/all/0/1\">Scott A. Hale</a>",
          "description": "Accurate detection and classification of online hate is a difficult task.\nImplicit hate is particularly challenging as such content tends to have unusual\nsyntax, polysemic words, and fewer markers of prejudice (e.g., slurs). This\nproblem is heightened with multimodal content, such as memes (combinations of\ntext and images), as they are often harder to decipher than unimodal content\n(e.g., text alone). This paper evaluates the role of semantic and multimodal\ncontext for detecting implicit and explicit hate. We show that both text- and\nvisual- enrichment improves model performance, with the multimodal model\n(0.771) outperforming other models' F1 scores (0.544, 0.737, and 0.754). While\nthe unimodal-text context-aware (transformer) model was the most accurate on\nthe subtask of implicit hate detection, the multimodal model outperformed it\noverall because of a lower propensity towards false positives. We find that all\nmodels perform better on content with full annotator agreement and that\nmultimodal models are best at classifying the content where annotators\ndisagree. To conduct these investigations, we undertook high-quality annotation\nof a sample of 5,000 multimodal entries. Tweets were annotated for primary\ncategory, modality, and strategy. We make this corpus, along with the codebook,\ncode, and final model, freely available.",
          "link": "http://arxiv.org/abs/2106.05903",
          "publishedOn": "2021-06-11T01:42:13.977Z",
          "wordCount": 659,
          "title": "Deciphering Implicit Hate: Evaluating Automated Detection Algorithms for Multimodal Hate. (arXiv:2106.05903v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05852",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Adiga_D/0/1/0/all/0/1\">Devaraja Adiga</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kumar_R/0/1/0/all/0/1\">Rishabh Kumar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Krishna_A/0/1/0/all/0/1\">Amrith Krishna</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jyothi_P/0/1/0/all/0/1\">Preethi Jyothi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ramakrishnan_G/0/1/0/all/0/1\">Ganesh Ramakrishnan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Goyal_P/0/1/0/all/0/1\">Pawan Goyal</a>",
          "description": "Automatic speech recognition (ASR) in Sanskrit is interesting, owing to the\nvarious linguistic peculiarities present in the language. The Sanskrit language\nis lexically productive, undergoes euphonic assimilation of phones at the word\nboundaries and exhibits variations in spelling conventions and in\npronunciations. In this work, we propose the first large scale study of\nautomatic speech recognition (ASR) in Sanskrit, with an emphasis on the impact\nof unit selection in Sanskrit ASR. In this work, we release a 78 hour ASR\ndataset for Sanskrit, which faithfully captures several of the linguistic\ncharacteristics expressed by the language. We investigate the role of different\nacoustic model and language model units in ASR systems for Sanskrit. We also\npropose a new modelling unit, inspired by the syllable level unit selection,\nthat captures character sequences from one vowel in the word to the next vowel.\nWe also highlight the importance of choosing graphemic representations for\nSanskrit and show the impact of this choice on word error rates (WER). Finally,\nwe extend these insights from Sanskrit ASR for building ASR systems in two\nother Indic languages, Gujarati and Telugu. For both these languages, our\nexperimental results show that the use of phonetic based graphemic\nrepresentations in ASR results in performance improvements as compared to ASR\nsystems that use native scripts.",
          "link": "http://arxiv.org/abs/2106.05852",
          "publishedOn": "2021-06-11T01:42:13.967Z",
          "wordCount": 685,
          "title": "Automatic Speech Recognition in Sanskrit: A New Speech Corpus and Modelling Insights. (arXiv:2106.05852v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05970",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">Wanrong Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Eric Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_A/0/1/0/all/0/1\">An Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eckstein_M/0/1/0/all/0/1\">Miguel Eckstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>",
          "description": "Automatic evaluations for natural language generation (NLG) conventionally\nrely on token-level or embedding-level comparisons with the text references.\nThis is different from human language processing, for which visual imaginations\noften improve comprehension. In this work, we propose ImaginE, an\nimagination-based automatic evaluation metric for natural language generation.\nWith the help of CLIP and DALL-E, two cross-modal models pre-trained on\nlarge-scale image-text pairs, we automatically generate an image as the\nembodied imagination for the text snippet and compute the imagination\nsimilarity using contextual embeddings. Experiments spanning several text\ngeneration tasks demonstrate that adding imagination with our ImaginE displays\ngreat potential in introducing multi-modal information into NLG evaluation, and\nimproves existing automatic metrics' correlations with human similarity\njudgments in many circumstances.",
          "link": "http://arxiv.org/abs/2106.05970",
          "publishedOn": "2021-06-11T01:42:13.873Z",
          "wordCount": 564,
          "title": "ImaginE: An Imagination-Based Automatic Evaluation Metric for Natural Language Generation. (arXiv:2106.05970v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05752",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1\">Sourav Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolya_A/0/1/0/all/0/1\">Anup Kumar Kolya</a>",
          "description": "Sarcasm is a sophisticated way of wrapping any immanent truth, mes-sage, or\neven mockery within a hilarious manner. The advent of communications using\nsocial networks has mass-produced new avenues of socialization. It can be\nfurther said that humor, irony, sarcasm, and wit are the four chariots of being\nsocially funny in the modern days. In this paper, we manually extract the\nsarcastic word distribution features of a benchmark pop culture sarcasm corpus,\ncontaining sarcastic dialogues and monologues. We generate input sequences\nformed of the weighted vectors from such words. We further propose an\namalgamation of four parallel deep long-short term networks (pLSTM), each with\ndistinctive activation classifier. These modules are primarily aimed at\nsuccessfully detecting sarcasm from the text corpus. Our proposed model for\ndetecting sarcasm peaks a training accuracy of 98.95% when trained with the\ndiscussed dataset. Consecutively, it obtains the highest of 98.31% overall\nvalidation accuracy on two handpicked Project Gutenberg English humor\nliterature among all the test cases. Our approach transcends previous\nstate-of-the-art works on several sarcasm corpora and results in a new gold\nstandard performance for sarcasm detection.",
          "link": "http://arxiv.org/abs/2106.05752",
          "publishedOn": "2021-06-11T01:42:13.844Z",
          "wordCount": 657,
          "title": "Parallel Deep Learning-Driven Sarcasm Detection from Pop Culture Text and English Humor Literature. (arXiv:2106.05752v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05894",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_P/0/1/0/all/0/1\">Prakhar Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsvetkov_Y/0/1/0/all/0/1\">Yulia Tsvetkov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bigham_J/0/1/0/all/0/1\">Jeffrey P. Bigham</a>",
          "description": "Open-domain neural dialogue models have achieved high performance in response\nranking and evaluation tasks. These tasks are formulated as a binary\nclassification of responses given in a dialogue context, and models generally\nlearn to make predictions based on context-response content similarity.\nHowever, over-reliance on content similarity makes the models less sensitive to\nthe presence of inconsistencies, incorrect time expressions and other factors\nimportant for response appropriateness and coherence. We propose approaches for\nautomatically creating adversarial negative training data to help ranking and\nevaluation models learn features beyond content similarity. We propose\nmask-and-fill and keyword-guided approaches that generate negative examples for\ntraining more robust dialogue systems. These generated adversarial responses\nhave high content similarity with the contexts but are either incoherent,\ninappropriate or not fluent. Our approaches are fully data-driven and can be\neasily incorporated in existing models and datasets. Experiments on\nclassification, ranking and evaluation tasks across multiple datasets\ndemonstrate that our approaches outperform strong baselines in providing\ninformative negative examples for training dialogue systems.",
          "link": "http://arxiv.org/abs/2106.05894",
          "publishedOn": "2021-06-11T01:42:13.837Z",
          "wordCount": 600,
          "title": "Synthesizing Adversarial Negative Responses for Robust Response Ranking and Evaluation. (arXiv:2106.05894v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05691",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yuanxin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_F/0/1/0/all/0/1\">Fandong Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zheng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Weiping Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>",
          "description": "Recently, knowledge distillation (KD) has shown great success in BERT\ncompression. Instead of only learning from the teacher's soft label as in\nconventional KD, researchers find that the rich information contained in the\nhidden layers of BERT is conducive to the student's performance. To better\nexploit the hidden knowledge, a common practice is to force the student to\ndeeply mimic the teacher's hidden states of all the tokens in a layer-wise\nmanner. In this paper, however, we observe that although distilling the\nteacher's hidden state knowledge (HSK) is helpful, the performance gain\n(marginal utility) diminishes quickly as more HSK is distilled. To understand\nthis effect, we conduct a series of analysis. Specifically, we divide the HSK\nof BERT into three dimensions, namely depth, length and width. We first\ninvestigate a variety of strategies to extract crucial knowledge for each\nsingle dimension and then jointly compress the three dimensions. In this way,\nwe show that 1) the student's performance can be improved by extracting and\ndistilling the crucial HSK, and 2) using a tiny fraction of HSK can achieve the\nsame performance as extensive HSK distillation. Based on the second finding, we\nfurther propose an efficient KD paradigm to compress BERT, which does not\nrequire loading the teacher during the training of student. For two kinds of\nstudent models and computing devices, the proposed KD paradigm gives rise to\ntraining speedup of 2.7x ~ 3.4x.",
          "link": "http://arxiv.org/abs/2106.05691",
          "publishedOn": "2021-06-11T01:42:13.832Z",
          "wordCount": 674,
          "title": "Marginal Utility Diminishes: Exploring the Minimum Knowledge for BERT Knowledge Distillation. (arXiv:2106.05691v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05933",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lai_C/0/1/0/all/0/1\">Cheng-I Jeff Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Alexander H. Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1\">Shiyu Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_Y/0/1/0/all/0/1\">Yi-Lun Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chuang_Y/0/1/0/all/0/1\">Yung-Sung Chuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_K/0/1/0/all/0/1\">Kaizhi Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khurana_S/0/1/0/all/0/1\">Sameer Khurana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cox_D/0/1/0/all/0/1\">David Cox</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glass_J/0/1/0/all/0/1\">James Glass</a>",
          "description": "Recent work on speech self-supervised learning (speech SSL) demonstrated the\nbenefits of scale in learning rich and transferable representations for\nAutomatic Speech Recognition (ASR) with limited parallel data. It is then\nnatural to investigate the existence of sparse and transferrable subnetworks in\npre-trained speech SSL models that can achieve even better low-resource ASR\nperformance. However, directly applying widely adopted pruning methods such as\nthe Lottery Ticket Hypothesis (LTH) is suboptimal in the computational cost\nneeded. Moreover, contrary to what LTH predicts, the discovered subnetworks\nyield minimal performance gain compared to the original dense network. In this\nwork, we propose Prune-Adjust- Re-Prune (PARP), which discovers and finetunes\nsubnetworks for much better ASR performance, while only requiring a single\ndownstream finetuning run. PARP is inspired by our surprising observation that\nsubnetworks pruned for pre-training tasks only needed to be slightly adjusted\nto achieve a sizeable performance boost in downstream ASR tasks. Extensive\nexperiments on low-resource English and multi-lingual ASR show (1) sparse\nsubnetworks exist in pre-trained speech SSL, and (2) the computational\nadvantage and performance gain of PARP over baseline pruning methods. On the\n10min Librispeech split without LM decoding, PARP discovers subnetworks from\nwav2vec 2.0 with an absolute 10.9%/12.6% WER decrease compared to the full\nmodel. We demonstrate PARP mitigates performance degradation in cross-lingual\nmask transfer, and investigate the possibility of discovering a single\nsubnetwork for 10 spoken languages in one run.",
          "link": "http://arxiv.org/abs/2106.05933",
          "publishedOn": "2021-06-11T01:42:13.814Z",
          "wordCount": 686,
          "title": "PARP: Prune, Adjust and Re-Prune for Self-Supervised Speech Recognition. (arXiv:2106.05933v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05606",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lv_T/0/1/0/all/0/1\">Tengchao Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1\">Lei Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasilijevic_M/0/1/0/all/0/1\">Momcilo Vasilijevic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>",
          "description": "Video transcript summarization is a fundamental task for video understanding.\nConventional approaches for transcript summarization are usually built upon the\nsummarization data for written language such as news articles, while the domain\ndiscrepancy may degrade the model performance on spoken text. In this paper, we\npresent VT-SSum, a benchmark dataset with spoken language for video transcript\nsegmentation and summarization, which includes 125K transcript-summary pairs\nfrom 9,616 videos. VT-SSum takes advantage of the videos from VideoLectures.NET\nby leveraging the slides content as the weak supervision to generate the\nextractive summary for video transcripts. Experiments with a state-of-the-art\ndeep learning approach show that the model trained with VT-SSum brings a\nsignificant improvement on the AMI spoken text summarization benchmark. VT-SSum\nwill be publicly available to support the future research of video transcript\nsegmentation and summarization tasks.",
          "link": "http://arxiv.org/abs/2106.05606",
          "publishedOn": "2021-06-11T01:42:13.805Z",
          "wordCount": 569,
          "title": "VT-SSum: A Benchmark Dataset for Video Transcript Segmentation and Summarization. (arXiv:2106.05606v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05830",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Dingmin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Ziyao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_W/0/1/0/all/0/1\">Wanwei He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_L/0/1/0/all/0/1\">Li Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_Y/0/1/0/all/0/1\">Yunzhe Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Min Yang</a>",
          "description": "Most existing neural network based task-oriented dialogue systems follow\nencoder-decoder paradigm, where the decoder purely depends on the source texts\nto generate a sequence of words, usually suffering from instability and poor\nreadability. Inspired by the traditional template-based generation approaches,\nwe propose a template-guided hybrid pointer network for the knowledge-based\ntask-oriented dialogue system, which retrieves several potentially relevant\nanswers from a pre-constructed domain-specific conversational repository as\nguidance answers, and incorporates the guidance answers into both the encoding\nand decoding processes. Specifically, we design a memory pointer network model\nwith a gating mechanism to fully exploit the semantic correlation between the\nretrieved answers and the ground-truth response. We evaluate our model on four\nwidely used task-oriented datasets, including one simulated and three manually\ncreated datasets. The experimental results demonstrate that the proposed model\nachieves significantly better performance than the state-of-the-art methods\nover different automatic evaluation metrics.",
          "link": "http://arxiv.org/abs/2106.05830",
          "publishedOn": "2021-06-11T01:42:13.790Z",
          "wordCount": 579,
          "title": "A Template-guided Hybrid Pointer Network for Knowledge-basedTask-oriented Dialogue Systems. (arXiv:2106.05830v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05630",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_M/0/1/0/all/0/1\">Mingliang Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1\">Xu Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ju_Z/0/1/0/all/0/1\">Zeqian Ju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1\">Tao Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tie-Yan Liu</a>",
          "description": "Symbolic music understanding, which refers to the understanding of music from\nthe symbolic data (e.g., MIDI format, but not audio), covers many music\napplications such as genre classification, emotion classification, and music\npieces matching. While good music representations are beneficial for these\napplications, the lack of training data hinders representation learning.\nInspired by the success of pre-training models in natural language processing,\nin this paper, we develop MusicBERT, a large-scale pre-trained model for music\nunderstanding. To this end, we construct a large-scale symbolic music corpus\nthat contains more than 1 million music songs. Since symbolic music contains\nmore structural (e.g., bar, position) and diverse information (e.g., tempo,\ninstrument, and pitch), simply adopting the pre-training techniques from NLP to\nsymbolic music only brings marginal gains. Therefore, we design several\nmechanisms, including OctupleMIDI encoding and bar-level masking strategy, to\nenhance pre-training with symbolic music data. Experiments demonstrate the\nadvantages of MusicBERT on four music understanding tasks, including melody\ncompletion, accompaniment suggestion, genre classification, and style\nclassification. Ablation studies also verify the effectiveness of our designs\nof OctupleMIDI encoding and bar-level masking strategy in MusicBERT.",
          "link": "http://arxiv.org/abs/2106.05630",
          "publishedOn": "2021-06-11T01:42:13.781Z",
          "wordCount": 631,
          "title": "MusicBERT: Symbolic Music Understanding with Large-Scale Pre-Training. (arXiv:2106.05630v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05634",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Baziotis_C/0/1/0/all/0/1\">Christos Baziotis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Titov_I/0/1/0/all/0/1\">Ivan Titov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Birch_A/0/1/0/all/0/1\">Alexandra Birch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haddow_B/0/1/0/all/0/1\">Barry Haddow</a>",
          "description": "Unsupervised cross-lingual pretraining has achieved strong results in neural\nmachine translation (NMT), by drastically reducing the need for large parallel\ndata. Most approaches adapt masked-language modeling (MLM) to\nsequence-to-sequence architectures, by masking parts of the input and\nreconstructing them in the decoder. In this work, we systematically compare\nmasking with alternative objectives that produce inputs resembling real (full)\nsentences, by reordering and replacing words based on their context. We\npretrain models with different methods on English$\\leftrightarrow$German,\nEnglish$\\leftrightarrow$Nepali and English$\\leftrightarrow$Sinhala monolingual\ndata, and evaluate them on NMT. In (semi-) supervised NMT, varying the\npretraining objective leads to surprisingly small differences in the finetuned\nperformance, whereas unsupervised NMT is much more sensitive to it. To\nunderstand these results, we thoroughly study the pretrained models using a\nseries of probes and verify that they encode and use information in different\nways. We conclude that finetuning on parallel data is mostly sensitive to few\nproperties that are shared by most models, such as a strong decoder, in\ncontrast to unsupervised NMT that also requires models with strong\ncross-lingual abilities.",
          "link": "http://arxiv.org/abs/2106.05634",
          "publishedOn": "2021-06-11T01:42:13.758Z",
          "wordCount": 603,
          "title": "Exploring Unsupervised Pretraining Objectives for Machine Translation. (arXiv:2106.05634v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05823",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yaseen_U/0/1/0/all/0/1\">Usama Yaseen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Langer_S/0/1/0/all/0/1\">Stefan Langer</a>",
          "description": "This paper presents our findings from participating in the SMM4H Shared Task\n2021. We addressed Named Entity Recognition (NER) and Text Classification. To\naddress NER we explored BiLSTM-CRF with Stacked Heterogeneous Embeddings and\nlinguistic features. We investigated various machine learning algorithms\n(logistic regression, Support Vector Machine (SVM) and Neural Networks) to\naddress text classification. Our proposed approaches can be generalized to\ndifferent languages and we have shown its effectiveness for English and\nSpanish. Our text classification submissions (team:MIC-NLP) have achieved\ncompetitive performance with F1-score of $0.46$ and $0.90$ on ADE\nClassification (Task 1a) and Profession Classification (Task 7a) respectively.\nIn the case of NER, our submissions scored F1-score of $0.50$ and $0.82$ on ADE\nSpan Detection (Task 1b) and Profession Span detection (Task 7b) respectively.",
          "link": "http://arxiv.org/abs/2106.05823",
          "publishedOn": "2021-06-11T01:42:13.700Z",
          "wordCount": 560,
          "title": "Neural Text Classification and StackedHeterogeneous Embeddings for Named Entity Recognition in SMM4H 2021. (arXiv:2106.05823v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05544",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ren_Y/0/1/0/all/0/1\">Yuqi Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_D/0/1/0/all/0/1\">Deyi Xiong</a>",
          "description": "Most previous studies integrate cognitive language processing signals (e.g.,\neye-tracking or EEG data) into neural models of natural language processing\n(NLP) just by directly concatenating word embeddings with cognitive features,\nignoring the gap between the two modalities (i.e., textual vs. cognitive) and\nnoise in cognitive features. In this paper, we propose a CogAlign approach to\nthese issues, which learns to align textual neural representations to cognitive\nfeatures. In CogAlign, we use a shared encoder equipped with a modality\ndiscriminator to alternatively encode textual and cognitive inputs to capture\ntheir differences and commonalities. Additionally, a text-aware attention\nmechanism is proposed to detect task-related information and to avoid using\nnoise in cognitive features. Experimental results on three NLP tasks, namely\nnamed entity recognition, sentiment analysis and relation extraction, show that\nCogAlign achieves significant improvements with multiple cognitive features\nover state-of-the-art models on public datasets. Moreover, our model is able to\ntransfer cognitive information to other datasets that do not have any cognitive\nprocessing signals.",
          "link": "http://arxiv.org/abs/2106.05544",
          "publishedOn": "2021-06-11T01:42:13.649Z",
          "wordCount": 592,
          "title": "CogAlign: Learning to Align Textual Neural Representations to Cognitive Language Processing Signals. (arXiv:2106.05544v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05762",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Valles_Perez_I/0/1/0/all/0/1\">Iv&#xe1;n Vall&#xe9;s-P&#xe9;rez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_J/0/1/0/all/0/1\">Julian Roth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beringer_G/0/1/0/all/0/1\">Grzegorz Beringer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barra_Chicote_R/0/1/0/all/0/1\">Roberto Barra-Chicote</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Droppo_J/0/1/0/all/0/1\">Jasha Droppo</a>",
          "description": "Text-to-speech systems recently achieved almost indistinguishable quality\nfrom human speech. However, the prosody of those systems is generally flatter\nthan natural speech, producing samples with low expressiveness. Disentanglement\nof speaker id and prosody is crucial in text-to-speech systems to improve on\nnaturalness and produce more variable syntheses. This paper proposes a new\nneural text-to-speech model that approaches the disentanglement problem by\nconditioning a Tacotron2-like architecture on flow-normalized speaker\nembeddings, and by substituting the reference encoder with a new learned latent\ndistribution responsible for modeling the intra-sentence variability due to the\nprosody. By removing the reference encoder dependency, the speaker-leakage\nproblem typically happening in this kind of systems disappears, producing more\ndistinctive syntheses at inference time. The new model achieves significantly\nhigher prosody variance than the baseline in a set of quantitative prosody\nfeatures, as well as higher speaker distinctiveness, without decreasing the\nspeaker intelligibility. Finally, we observe that the normalized speaker\nembeddings enable much richer speaker interpolations, substantially improving\nthe distinctiveness of the new interpolated speakers.",
          "link": "http://arxiv.org/abs/2106.05762",
          "publishedOn": "2021-06-11T01:42:13.638Z",
          "wordCount": 617,
          "title": "Improving multi-speaker TTS prosody variance with a residual encoder and normalizing flows. (arXiv:2106.05762v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05642",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1\">Di Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Binbin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_Z/0/1/0/all/0/1\">Zhendong Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_W/0/1/0/all/0/1\">Wenjing Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiaoyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_X/0/1/0/all/0/1\">Xin Lei</a>",
          "description": "The unified streaming and non-streaming two-pass (U2) end-to-end model for\nspeech recognition has shown great performance in terms of streaming\ncapability, accuracy, real-time factor (RTF), and latency. In this paper, we\npresent U2++, an enhanced version of U2 to further improve the accuracy. The\ncore idea of U2++ is to use the forward and the backward information of the\nlabeling sequences at the same time at training to learn richer information,\nand combine the forward and backward prediction at decoding to give more\naccurate recognition results. We also proposed a new data augmentation method\ncalled SpecSub to help the U2++ model to be more accurate and robust. Our\nexperiments show that, compared with U2, U2++ shows faster convergence at\ntraining, better robustness to the decoding method, as well as consistent 5\\% -\n8\\% word error rate reduction gain over U2. On the experiment of AISHELL-1, we\nachieve a 4.63\\% character error rate (CER) with a non-streaming setup and\n5.05\\% with a streaming setup with 320ms latency by U2++. To the best of our\nknowledge, 5.05\\% is the best-published streaming result on the AISHELL-1 test\nset.",
          "link": "http://arxiv.org/abs/2106.05642",
          "publishedOn": "2021-06-11T01:42:13.612Z",
          "wordCount": 626,
          "title": "U2++: Unified Two-pass Bidirectional End-to-end Model for Speech Recognition. (arXiv:2106.05642v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05723",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jihye Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hye Jin Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_S/0/1/0/all/0/1\">Sungzoon Cho</a>",
          "description": "Increasing attention has been drawn to the sentiment analysis of financial\ndocuments. The most popular examples of such documents include analyst reports\nand economic news, the analysis of which is frequently used to capture the\ntrends in market sentiments. On the other hand, the significance of the role\nsentiment analysis plays in the financial domain has given rise to the efforts\nto construct a financial domain-specific sentiment lexicon. Sentiment lexicons\nlend a hand for solving various text mining tasks, such as unsupervised\nclassification of text data, while alleviating the arduous human labor required\nfor manual labeling. One of the challenges in the construction of an effective\nsentiment lexicon is that the semantic orientation of a word may change\ndepending on the context in which it appears. For instance, the word ``profit\"\nusually conveys positive sentiments; however, when the word is juxtaposed with\nanother word ``decrease,\" the sentiment associated with the phrase ``profit\ndecreases\" now becomes negative. Hence, the sentiment of a given word may shift\nas one begins to consider the context surrounding the word. In this paper, we\naddress this issue by incorporating context when building sentiment lexicon\nfrom a given corpus. Specifically, we construct a lexicon named Senti-DD for\nthe Sentiment lexicon composed of Direction-Dependent words, which expresses\neach term a pair of a directional word and a direction-dependent word.\nExperiment results show that higher classification performance is achieved with\nSenti-DD, proving the effectiveness of our method for automatically\nconstructing a context-aware sentiment lexicon in the financial domain.",
          "link": "http://arxiv.org/abs/2106.05723",
          "publishedOn": "2021-06-11T01:42:13.590Z",
          "wordCount": 685,
          "title": "Automatic Construction of Context-Aware Sentiment Lexicon in the Financial Domain Using Direction-Dependent Words. (arXiv:2106.05723v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05555",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nekvinda_T/0/1/0/all/0/1\">Tom&#xe1;&#x161; Nekvinda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dusek_O/0/1/0/all/0/1\">Ond&#x159;ej Du&#x161;ek</a>",
          "description": "The MultiWOZ dataset (Budzianowski et al.,2018) is frequently used for\nbenchmarking context-to-response abilities of task-oriented dialogue systems.\nIn this work, we identify inconsistencies in data preprocessing and reporting\nof three corpus-based metrics used on this dataset, i.e., BLEU score and Inform\n& Success rates. We point out a few problems of the MultiWOZ benchmark such as\nunsatisfactory preprocessing, insufficient or under-specified evaluation\nmetrics, or rigid database. We re-evaluate 7 end-to-end and 6 policy\noptimization models in as-fair-as-possible setups, and we show that their\nreported scores cannot be directly compared. To facilitate comparison of future\nsystems, we release our stand-alone standardized evaluation scripts. We also\ngive basic recommendations for corpus-based benchmarking in future works.",
          "link": "http://arxiv.org/abs/2106.05555",
          "publishedOn": "2021-06-11T01:42:13.581Z",
          "wordCount": 554,
          "title": "Shades of BLEU, Flavours of Success: The Case of MultiWOZ. (arXiv:2106.05555v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05450",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chousa_K/0/1/0/all/0/1\">Katsuki Chousa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morishita_M/0/1/0/all/0/1\">Makoto Morishita</a>",
          "description": "This paper describes our systems that were submitted to the restricted\ntranslation task at WAT 2021. In this task, the systems are required to output\ntranslated sentences that contain all given word constraints. Our system\ncombined input augmentation and constrained beam search algorithms. Through\nexperiments, we found that this combination significantly improves translation\naccuracy and can save inference time while containing all the constraints in\nthe output. For both En->Ja and Ja->En, our systems obtained the best\nevaluation performances in automatic evaluation.",
          "link": "http://arxiv.org/abs/2106.05450",
          "publishedOn": "2021-06-11T01:42:13.482Z",
          "wordCount": 526,
          "title": "Input Augmentation Improves Constrained Beam Search for Neural Machine Translation: NTT at WAT 2021. (arXiv:2106.05450v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05505",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chang_T/0/1/0/all/0/1\">Tyler A. Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yifan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Weijian Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1\">Zhuowen Tu</a>",
          "description": "In this paper, we detail the relationship between convolutions and\nself-attention in natural language tasks. We show that relative position\nembeddings in self-attention layers are equivalent to recently-proposed dynamic\nlightweight convolutions, and we consider multiple new ways of integrating\nconvolutions into Transformer self-attention. Specifically, we propose\ncomposite attention, which unites previous relative position embedding methods\nunder a convolutional framework. We conduct experiments by training BERT with\ncomposite attention, finding that convolutions consistently improve performance\non multiple downstream tasks, replacing absolute position embeddings. To inform\nfuture work, we present results comparing lightweight convolutions, dynamic\nconvolutions, and depthwise-separable convolutions in language model\npre-training, considering multiple injection points for convolutions in\nself-attention layers.",
          "link": "http://arxiv.org/abs/2106.05505",
          "publishedOn": "2021-06-11T01:42:13.458Z",
          "wordCount": 547,
          "title": "Convolutions and Self-Attention: Re-interpreting Relative Positions in Pre-trained Language Models. (arXiv:2106.05505v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05426",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Antonello_R/0/1/0/all/0/1\">Richard Antonello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turek_J/0/1/0/all/0/1\">Javier Turek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vo_V/0/1/0/all/0/1\">Vy Vo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huth_A/0/1/0/all/0/1\">Alexander Huth</a>",
          "description": "How related are the representations learned by neural language models,\ntranslation models, and language tagging tasks? We answer this question by\nadapting an encoder-decoder transfer learning method from computer vision to\ninvestigate the structure among 100 different feature spaces extracted from\nhidden representations of various networks trained on language tasks. This\nmethod reveals a low-dimensional structure where language models and\ntranslation models smoothly interpolate between word embeddings, syntactic and\nsemantic tasks, and future word embeddings. We call this low-dimensional\nstructure a language representation embedding because it encodes the\nrelationships between representations needed to process language for a variety\nof NLP tasks. We find that this representation embedding can predict how well\neach individual feature space maps to human brain responses to natural language\nstimuli recorded using fMRI. Additionally, we find that the principal dimension\nof this structure can be used to create a metric which highlights the brain's\nnatural language processing hierarchy. This suggests that the embedding\ncaptures some part of the brain's natural language representation structure.",
          "link": "http://arxiv.org/abs/2106.05426",
          "publishedOn": "2021-06-11T01:42:13.432Z",
          "wordCount": 611,
          "title": "Low-Dimensional Structure in the Space of Language Representations is Reflected in Brain Responses. (arXiv:2106.05426v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05580",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xinnuo Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dusek_O/0/1/0/all/0/1\">Ond&#x159;ej Du&#x161;ek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rieser_V/0/1/0/all/0/1\">Verena Rieser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Konstas_I/0/1/0/all/0/1\">Ioannis Konstas</a>",
          "description": "We present AGGGEN (pronounced 'again'), a data-to-text model which\nre-introduces two explicit sentence planning stages into neural data-to-text\nsystems: input ordering and input aggregation. In contrast to previous work\nusing sentence planning, our model is still end-to-end: AGGGEN performs\nsentence planning at the same time as generating text by learning latent\nalignments (via semantic facts) between input representation and target text.\nExperiments on the WebNLG and E2E challenge data show that by using fact-based\nalignments our approach is more interpretable, expressive, robust to noise, and\neasier to control, while retaining the advantages of end-to-end systems in\nterms of fluency. Our code is available at https://github.com/XinnuoXu/AggGen.",
          "link": "http://arxiv.org/abs/2106.05580",
          "publishedOn": "2021-06-11T01:42:13.421Z",
          "wordCount": 543,
          "title": "AGGGEN: Ordering and Aggregating while Generating. (arXiv:2106.05580v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05299",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Correia_A/0/1/0/all/0/1\">A. D. Correia</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Moortgat_M/0/1/0/all/0/1\">M. Moortgat</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Stoof_H/0/1/0/all/0/1\">H. T. C. Stoof</a>",
          "description": "Grover's algorithm, a well-know quantum search algorithm, allows one to find\nthe correct item in a database, with quadratic speedup. In this paper we adapt\nGrover's algorithm to the problem of finding a correct answer to a natural\nlanguage question in English, thus contributing to the growing field of Quantum\nNatural Language Processing. Using a grammar that can be interpreted as tensor\ncontractions, each word is represented as a quantum state that serves as input\nto the quantum circuit. We here introduce a quantum measurement to contract the\nrepresentations of words, resulting in the representation of larger text\nfragments. Using this framework, a representation for the question is found\nthat contains all the possible answers in equal quantum superposition, and\nallows for the building of an oracle that can detect a correct answer, being\nagnostic to the specific question. Furthermore, we show that our construction\ncan deal with certain types of ambiguous phrases by keeping the various\ndifferent meanings in quantum superposition.",
          "link": "http://arxiv.org/abs/2106.05299",
          "publishedOn": "2021-06-11T01:42:13.402Z",
          "wordCount": 593,
          "title": "Grover's Algorithm for Question Answering. (arXiv:2106.05299v1 [quant-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05437",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bujimalla_S/0/1/0/all/0/1\">Shashank Bujimalla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Subedar_M/0/1/0/all/0/1\">Mahesh Subedar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tickoo_O/0/1/0/all/0/1\">Omesh Tickoo</a>",
          "description": "In this paper, we study the impact of motion blur, a common quality flaw in\nreal world images, on a state-of-the-art two-stage image captioning solution,\nand notice a degradation in solution performance as blur intensity increases.\nWe investigate techniques to improve the robustness of the solution to motion\nblur using training data augmentation at each or both stages of the solution,\ni.e., object detection and captioning, and observe improved results. In\nparticular, augmenting both the stages reduces the CIDEr-D degradation for high\nmotion blur intensity from 68.7 to 11.7 on MS COCO dataset, and from 22.4 to\n6.8 on Vizwiz dataset.",
          "link": "http://arxiv.org/abs/2106.05437",
          "publishedOn": "2021-06-11T01:42:13.394Z",
          "wordCount": 539,
          "title": "Data augmentation to improve robustness of image captioning solutions. (arXiv:2106.05437v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05532",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1\">Swaroop Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arunkumar_A/0/1/0/all/0/1\">Anjana Arunkumar</a>",
          "description": "Models that top leaderboards often perform unsatisfactorily when deployed in\nreal world applications; this has necessitated rigorous and expensive\npre-deployment model testing. A hitherto unexplored facet of model performance\nis: Are our leaderboards doing equitable evaluation? In this paper, we\nintroduce a task-agnostic method to probe leaderboards by weighting samples\nbased on their `difficulty' level. We find that leaderboards can be\nadversarially attacked and top performing models may not always be the best\nmodels. We subsequently propose alternate evaluation metrics. Our experiments\non 10 models show changes in model ranking and an overall reduction in\npreviously reported performance -- thus rectifying the overestimation of AI\nsystems' capabilities. Inspired by behavioral testing principles, we further\ndevelop a prototype of a visual analytics tool that enables leaderboard\nrevamping through customization, based on an end user's focus area. This helps\nusers analyze models' strengths and weaknesses, and guides them in the\nselection of a model best suited for their application scenario. In a user\nstudy, members of various commercial product development teams, covering 5\nfocus areas, find that our prototype reduces pre-deployment development and\ntesting effort by 41% on average.",
          "link": "http://arxiv.org/abs/2106.05532",
          "publishedOn": "2021-06-11T01:42:13.322Z",
          "wordCount": 632,
          "title": "How Robust are Model Rankings: A Leaderboard Customization Approach for Equitable Evaluation. (arXiv:2106.05532v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05469",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mahabadi_R/0/1/0/all/0/1\">Rabeeh Karimi Mahabadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belinkov_Y/0/1/0/all/0/1\">Yonatan Belinkov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henderson_J/0/1/0/all/0/1\">James Henderson</a>",
          "description": "While large-scale pretrained language models have obtained impressive results\nwhen fine-tuned on a wide variety of tasks, they still often suffer from\noverfitting in low-resource scenarios. Since such models are general-purpose\nfeature extractors, many of these features are inevitably irrelevant for a\ngiven target task. We propose to use Variational Information Bottleneck (VIB)\nto suppress irrelevant features when fine-tuning on low-resource target tasks,\nand show that our method successfully reduces overfitting. Moreover, we show\nthat our VIB model finds sentence representations that are more robust to\nbiases in natural language inference datasets, and thereby obtains better\ngeneralization to out-of-domain datasets. Evaluation on seven low-resource\ndatasets in different tasks shows that our method significantly improves\ntransfer learning in low-resource scenarios, surpassing prior work. Moreover,\nit improves generalization on 13 out of 15 out-of-domain natural language\ninference benchmarks. Our code is publicly available in\nhttps://github.com/rabeehk/vibert.",
          "link": "http://arxiv.org/abs/2106.05469",
          "publishedOn": "2021-06-11T01:42:13.296Z",
          "wordCount": 572,
          "title": "Variational Information Bottleneck for Effective Low-Resource Fine-Tuning. (arXiv:2106.05469v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01978",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_D/0/1/0/all/0/1\">Dou Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_L/0/1/0/all/0/1\">Lingwei Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huai_X/0/1/0/all/0/1\">Xiaoyong Huai</a>",
          "description": "Emotion Recognition in Conversations (ERC) has gained increasing attention\nfor developing empathetic machines. Recently, many approaches have been devoted\nto perceiving conversational context by deep learning models. However, these\napproaches are insufficient in understanding the context due to lacking the\nability to extract and integrate emotional clues. In this work, we propose\nnovel Contextual Reasoning Networks (DialogueCRN) to fully understand the\nconversational context from a cognitive perspective. Inspired by the Cognitive\nTheory of Emotion, we design multi-turn reasoning modules to extract and\nintegrate emotional clues. The reasoning module iteratively performs an\nintuitive retrieving process and a conscious reasoning process, which imitates\nhuman unique cognitive thinking. Extensive experiments on three public\nbenchmark datasets demonstrate the effectiveness and superiority of the\nproposed model.",
          "link": "http://arxiv.org/abs/2106.01978",
          "publishedOn": "2021-06-10T22:40:40.475Z",
          "wordCount": 575,
          "title": "DialogueCRN: Contextual Reasoning Networks for Emotion Recognition in Conversations. (arXiv:2106.01978v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04831",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chin_N/0/1/0/all/0/1\">Ng Bee Chin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Susanto_Y/0/1/0/all/0/1\">Yosephine Susanto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cambria_E/0/1/0/all/0/1\">Erik Cambria</a>",
          "description": "MICE is a corpus of emotion words in four languages which is currently\nworking progress. There are two sections to this study, Part I: Emotion word\ncorpus and Part II: Emotion word survey. In Part 1, the method of how the\nemotion data is culled for each of the four languages will be described and\nvery preliminary data will be presented. In total, we identified 3,750 emotion\nexpressions in Malay, 6,657 in Indonesian, 3,347 in Mandarin Chinese and 8,683\nin English. We are currently evaluating and double checking the corpus and\ndoing further analysis on the distribution of these emotion expressions. Part\nII Emotion word survey involved an online language survey which collected\ninformation on how speakers assigned the emotion words into basic emotion\ncategories, the rating for valence and intensity as well as biographical\ninformation of all the respondents.",
          "link": "http://arxiv.org/abs/2106.04831",
          "publishedOn": "2021-06-10T01:56:49.602Z",
          "wordCount": 571,
          "title": "MICE: A Crosslinguistic Emotion Corpus in Malay, Indonesian, Chinese and English. (arXiv:2106.04831v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/1811.00606",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1\">Zhiwen Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1\">Grace Hui Yang</a>",
          "description": "Most neural Information Retrieval (Neu-IR) models derive query-to-document\nranking scores based on term-level matching. Inspired by TileBars, a classical\nterm distribution visualization method, in this paper, we propose a novel\nNeu-IR model that handles query-to-document matching at the subtopic and higher\nlevels. Our system first splits the documents into topical segments,\n\"visualizes\" the matchings between the query and the segments, and then feeds\nan interaction matrix into a Neu-IR model, DeepTileBars, to obtain the final\nranking scores. DeepTileBars models the relevance signals occurring at\ndifferent granularities in a document's topic hierarchy. It better captures the\ndiscourse structure of a document and thus the matching patterns. Although its\ndesign and implementation are light-weight, DeepTileBars outperforms other\nstate-of-the-art Neu-IR models on benchmark datasets including the Text\nREtrieval Conference (TREC) 2010-2012 Web Tracks and LETOR 4.0.",
          "link": "http://arxiv.org/abs/1811.00606",
          "publishedOn": "2021-06-10T01:56:49.544Z",
          "wordCount": 612,
          "title": "DeepTileBars: Visualizing Term Distribution for Neural Information Retrieval. (arXiv:1811.00606v3 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05141",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mohiuddin_T/0/1/0/all/0/1\">Tasnim Mohiuddin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bari_M/0/1/0/all/0/1\">M Saiful Bari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joty_S/0/1/0/all/0/1\">Shafiq Joty</a>",
          "description": "The success of Neural Machine Translation (NMT) largely depends on the\navailability of large bitext training corpora. Due to the lack of such large\ncorpora in low-resource language pairs, NMT systems often exhibit poor\nperformance. Extra relevant monolingual data often helps, but acquiring it\ncould be quite expensive, especially for low-resource languages. Moreover,\ndomain mismatch between bitext (train/test) and monolingual data might degrade\nthe performance. To alleviate such issues, we propose AUGVIC, a novel data\naugmentation framework for low-resource NMT which exploits the vicinal samples\nof the given bitext without using any extra monolingual data explicitly. It can\ndiversify the in-domain bitext data with finer level control. Through extensive\nexperiments on four low-resource language pairs comprising data from different\ndomains, we have shown that our method is comparable to the traditional\nback-translation that uses extra in-domain monolingual data. When we combine\nthe synthetic parallel data generated from AUGVIC with the ones from the extra\nmonolingual data, we achieve further improvements. We show that AUGVIC helps to\nattenuate the discrepancies between relevant and distant-domain monolingual\ndata in traditional back-translation. To understand the contributions of\ndifferent components of AUGVIC, we perform an in-depth framework analysis.",
          "link": "http://arxiv.org/abs/2106.05141",
          "publishedOn": "2021-06-10T01:56:49.511Z",
          "wordCount": 619,
          "title": "AUGVIC: Exploiting BiText Vicinity for Low-Resource NMT. (arXiv:2106.05141v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05221",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1\">Shuoran Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qingcai Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1\">Baotian Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lisai Zhang</a>",
          "description": "Graph convolutional network (GCN) has become popular in various natural\nlanguage processing (NLP) tasks with its superiority in long-term and\nnon-consecutive word interactions. However, existing single-hop graph reasoning\nin GCN may miss some important non-consecutive dependencies. In this study, we\ndefine the spectral graph convolutional network with the high-order dynamic\nChebyshev approximation (HDGCN), which augments the multi-hop graph reasoning\nby fusing messages aggregated from direct and long-term dependencies into one\nconvolutional layer. To alleviate the over-smoothing in high-order Chebyshev\napproximation, a multi-vote-based cross-attention (MVCAttn) with linear\ncomputation complexity is also proposed. The empirical results on four\ntransductive and inductive NLP tasks and the ablation study verify the efficacy\nof the proposed model. Our source code is available at\nhttps://github.com/MathIsAll/HDGCN-pytorch.",
          "link": "http://arxiv.org/abs/2106.05221",
          "publishedOn": "2021-06-10T01:56:49.460Z",
          "wordCount": 559,
          "title": "Multi-hop Graph Convolutional Network with High-order Chebyshev Approximation for Text Reasoning. (arXiv:2106.05221v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2012.05628",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vries_W/0/1/0/all/0/1\">Wietse de Vries</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nissim_M/0/1/0/all/0/1\">Malvina Nissim</a>",
          "description": "Large generative language models have been very successful for English, but\nother languages lag behind, in part due to data and computational limitations.\nWe propose a method that may overcome these problems by adapting existing\npre-trained models to new languages. Specifically, we describe the adaptation\nof English GPT-2 to Italian and Dutch by retraining lexical embeddings without\ntuning the Transformer layers. As a result, we obtain lexical embeddings for\nItalian and Dutch that are aligned with the original English lexical\nembeddings. Additionally, we scale up complexity by transforming relearned\nlexical embeddings of GPT-2 small to the GPT-2 medium embedding space. This\nmethod minimises the amount of training and prevents losing information during\nadaptation that was learned by GPT-2. English GPT-2 models with relearned\nlexical embeddings can generate realistic sentences in Italian and Dutch.\nThough on average these sentences are still identifiable as artificial by\nhumans, they are assessed on par with sentences generated by a GPT-2 model\nfully trained from scratch.",
          "link": "http://arxiv.org/abs/2012.05628",
          "publishedOn": "2021-06-10T01:56:49.440Z",
          "wordCount": 642,
          "title": "As Good as New. How to Successfully Recycle English GPT-2 to Make Models for Other Languages. (arXiv:2012.05628v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04995",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Banerjee_T/0/1/0/all/0/1\">Tamali Banerjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+V_R/0/1/0/all/0/1\">Rudra Murthy V</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharyya_P/0/1/0/all/0/1\">Pushpak Bhattacharyya</a>",
          "description": "Recent advances in Unsupervised Neural Machine Translation (UNMT) have\nminimized the gap between supervised and unsupervised machine translation\nperformance for closely related language pairs. However, the situation is very\ndifferent for distant language pairs. Lack of lexical overlap and low syntactic\nsimilarities such as between English and Indo-Aryan languages leads to poor\ntranslation quality in existing UNMT systems. In this paper, we show that\ninitializing the embedding layer of UNMT models with cross-lingual embeddings\nshows significant improvements in BLEU score over existing approaches with\nembeddings randomly initialized. Further, static embeddings (freezing the\nembedding layer weights) lead to better gains compared to updating the\nembedding layer weights during training (non-static). We experimented using\nMasked Sequence to Sequence (MASS) and Denoising Autoencoder (DAE) UNMT\napproaches for three distant language pairs. The proposed cross-lingual\nembedding initialization yields BLEU score improvement of as much as ten times\nover the baseline for English-Hindi, English-Bengali, and English-Gujarati. Our\nanalysis shows the importance of cross-lingual embedding, comparisons between\napproaches, and the scope of improvements in these systems.",
          "link": "http://arxiv.org/abs/2106.04995",
          "publishedOn": "2021-06-10T01:56:49.332Z",
          "wordCount": 613,
          "title": "Crosslingual Embeddings are Essential in UNMT for Distant Languages: An English to IndoAryan Case Study. (arXiv:2106.04995v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05006",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hazoom_M/0/1/0/all/0/1\">Moshe Hazoom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malik_V/0/1/0/all/0/1\">Vibhor Malik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bogin_B/0/1/0/all/0/1\">Ben Bogin</a>",
          "description": "Most available semantic parsing datasets, comprising of pairs of natural\nutterances and logical forms, were collected solely for the purpose of training\nand evaluation of natural language understanding systems. As a result, they do\nnot contain any of the richness and variety of natural-occurring utterances,\nwhere humans ask about data they need or are curious about. In this work, we\nrelease SEDE, a dataset with 12,023 pairs of utterances and SQL queries\ncollected from real usage on the Stack Exchange website. We show that these\npairs contain a variety of real-world challenges which were rarely reflected so\nfar in any other semantic parsing dataset, propose an evaluation metric based\non comparison of partial query clauses that is more suitable for real-world\nqueries, and conduct experiments with strong baselines, showing a large gap\nbetween the performance on SEDE compared to other common datasets.",
          "link": "http://arxiv.org/abs/2106.05006",
          "publishedOn": "2021-06-10T01:56:48.699Z",
          "wordCount": null,
          "title": "Text-to-SQL in the Wild: A Naturally-Occurring Dataset Based on Stack Exchange Data. (arXiv:2106.05006v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04833",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1\">Xingshan Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Liangyou Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qun Liu</a>",
          "description": "End-to-end simultaneous speech translation (SST), which directly translates\nspeech in one language into text in another language in real-time, is useful in\nmany scenarios but has not been fully investigated. In this work, we propose\nRealTranS, an end-to-end model for SST. To bridge the modality gap between\nspeech and text, RealTranS gradually downsamples the input speech with\ninterleaved convolution and unidirectional Transformer layers for acoustic\nmodeling, and then maps speech features into text space with a\nweighted-shrinking operation and a semantic encoder. Besides, to improve the\nmodel performance in simultaneous scenarios, we propose a blank penalty to\nenhance the shrinking quality and a Wait-K-Stride-N strategy to allow local\nreranking during decoding. Experiments on public and widely-used datasets show\nthat RealTranS with the Wait-K-Stride-N strategy outperforms prior end-to-end\nmodels as well as cascaded models in diverse latency settings.",
          "link": "http://arxiv.org/abs/2106.04833",
          "publishedOn": "2021-06-10T01:56:48.084Z",
          "wordCount": 578,
          "title": "RealTranS: End-to-End Simultaneous Speech Translation with Convolutional Weighted-Shrinking Transformer. (arXiv:2106.04833v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2104.11127",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pylkkonen_J/0/1/0/all/0/1\">Janne Pylkk&#xf6;nen</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Ukkonen_A/0/1/0/all/0/1\">Antti Ukkonen</a> (1 and 2), <a href=\"http://arxiv.org/find/cs/1/au:+Kilpikoski_J/0/1/0/all/0/1\">Juho Kilpikoski</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Tamminen_S/0/1/0/all/0/1\">Samu Tamminen</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Heikinheimo_H/0/1/0/all/0/1\">Hannes Heikinheimo</a> (1) ((1) Speechly, (2) Department of Computer Science, University of Helsinki, Finland)",
          "description": "Adaption of end-to-end speech recognition systems to new tasks is known to be\nchallenging. A number of solutions have been proposed which apply external\nlanguage models with various fusion methods, possibly with a combination of\ntwo-pass decoding. Also TTS systems have been used to generate adaptation data\nfor the end-to-end models. In this paper we show that RNN-transducer models can\nbe effectively adapted to new domains using only small amounts of textual data.\nBy taking advantage of model's inherent structure, where the prediction network\nis interpreted as a language model, we can apply fast adaptation to the model.\nAdapting the model avoids the need for complicated decoding time fusions and\nexternal language models. Using appropriate regularization, the prediction\nnetwork can be adapted to new domains while still retaining good generalization\ncapabilities. We show with multiple ASR evaluation tasks how this method can\nprovide relative gains of 10-45% in target task WER. We also share insights how\nRNN-transducer prediction network performs as a language model.",
          "link": "http://arxiv.org/abs/2104.11127",
          "publishedOn": "2021-06-10T01:56:47.204Z",
          "wordCount": 656,
          "title": "Fast Text-Only Domain Adaptation of RNN-Transducer Prediction Network. (arXiv:2104.11127v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.08445",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_L/0/1/0/all/0/1\">Lingwei Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_D/0/1/0/all/0/1\">Dou Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Wei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1\">Xuehai Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaodan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jizhong Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1\">Songlin Hu</a>",
          "description": "Document-level Sentiment Analysis (DSA) is more challenging due to vague\nsemantic links and complicate sentiment information. Recent works have been\ndevoted to leveraging text summarization and have achieved promising results.\nHowever, these summarization-based methods did not take full advantage of the\nsummary including ignoring the inherent interactions between the summary and\ndocument. As a result, they limited the representation to express major points\nin the document, which is highly indicative of the key sentiment. In this\npaper, we study how to effectively generate a discriminative representation\nwith explicit subject patterns and sentiment contexts for DSA. A Hierarchical\nInteraction Networks (HIN) is proposed to explore bidirectional interactions\nbetween the summary and document at multiple granularities and learn\nsubject-oriented document representations for sentiment classification.\nFurthermore, we design a Sentiment-based Rethinking mechanism (SR) by refining\nthe HIN with sentiment label information to learn a more sentiment-aware\ndocument representation. We extensively evaluate our proposed models on three\npublic datasets. The experimental results consistently demonstrate the\neffectiveness of our proposed models and show that HIN-SR outperforms various\nstate-of-the-art methods.",
          "link": "http://arxiv.org/abs/2007.08445",
          "publishedOn": "2021-06-10T01:56:46.022Z",
          "wordCount": 658,
          "title": "Hierarchical Interaction Networks with Rethinking Mechanism for Document-level Sentiment Analysis. (arXiv:2007.08445v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.02021",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dao_M/0/1/0/all/0/1\">Mai Hoang Dao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Truong_T/0/1/0/all/0/1\">Thinh Hung Truong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1\">Dat Quoc Nguyen</a>",
          "description": "Intent detection and slot filling are important tasks in spoken and natural\nlanguage understanding. However, Vietnamese is a low-resource language in these\nresearch topics. In this paper, we present the first public intent detection\nand slot filling dataset for Vietnamese. In addition, we also propose a joint\nmodel for intent detection and slot filling, that extends the recent\nstate-of-the-art JointBERT+CRF model with an intent-slot attention layer to\nexplicitly incorporate intent context information into slot filling via \"soft\"\nintent label embedding. Experimental results on our Vietnamese dataset show\nthat our proposed model significantly outperforms JointBERT+CRF. We publicly\nrelease our dataset and the implementation of our model at:\nhttps://github.com/VinAIResearch/JointIDSF",
          "link": "http://arxiv.org/abs/2104.02021",
          "publishedOn": "2021-06-10T01:56:46.005Z",
          "wordCount": 579,
          "title": "Intent Detection and Slot Filling for Vietnamese. (arXiv:2104.02021v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09632",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dessi_D/0/1/0/all/0/1\">Danilo Dessi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Helaoui_R/0/1/0/all/0/1\">Rim Helaoui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1\">Vivek Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Recupero_D/0/1/0/all/0/1\">Diego Reforgiato Recupero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riboni_D/0/1/0/all/0/1\">Daniele Riboni</a>",
          "description": "Today, we are seeing an ever-increasing number of clinical notes that contain\nclinical results, images, and textual descriptions of patient's health state.\nAll these data can be analyzed and employed to cater novel services that can\nhelp people and domain experts with their common healthcare tasks. However,\nmany technologies such as Deep Learning and tools like Word Embeddings have\nstarted to be investigated only recently, and many challenges remain open when\nit comes to healthcare domain applications. To address these challenges, we\npropose the use of Deep Learning and Word Embeddings for identifying sixteen\nmorbidity types within textual descriptions of clinical records. For this\npurpose, we have used a Deep Learning model based on Bidirectional Long-Short\nTerm Memory (LSTM) layers which can exploit state-of-the-art vector\nrepresentations of data such as Word Embeddings. We have employed pre-trained\nWord Embeddings namely GloVe and Word2Vec, and our own Word Embeddings trained\non the target domain. Furthermore, we have compared the performances of the\ndeep learning approaches against the traditional tf-idf using Support Vector\nMachine and Multilayer perceptron (our baselines). From the obtained results it\nseems that the latter outperforms the combination of Deep Learning approaches\nusing any word embeddings. Our preliminary results indicate that there are\nspecific features that make the dataset biased in favour of traditional machine\nlearning approaches.",
          "link": "http://arxiv.org/abs/2105.09632",
          "publishedOn": "2021-06-10T01:56:45.999Z",
          "wordCount": 711,
          "title": "TF-IDF vs Word Embeddings for Morbidity Identification in Clinical Notes: An Initial Study. (arXiv:2105.09632v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.04339",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tsukagoshi_H/0/1/0/all/0/1\">Hayato Tsukagoshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sasano_R/0/1/0/all/0/1\">Ryohei Sasano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takeda_K/0/1/0/all/0/1\">Koichi Takeda</a>",
          "description": "Sentence embedding methods using natural language inference (NLI) datasets\nhave been successfully applied to various tasks. However, these methods are\nonly available for limited languages due to relying heavily on the large NLI\ndatasets. In this paper, we propose DefSent, a sentence embedding method that\nuses definition sentences from a word dictionary, which performs comparably on\nunsupervised semantics textual similarity (STS) tasks and slightly better on\nSentEval tasks than conventional methods. Since dictionaries are available for\nmany languages, DefSent is more broadly applicable than methods using NLI\ndatasets without constructing additional datasets. We demonstrate that DefSent\nperforms comparably on unsupervised semantics textual similarity (STS) tasks\nand slightly better on SentEval tasks to the methods using large NLI datasets.\nOur code is publicly available at https://github.com/hpprc/defsent .",
          "link": "http://arxiv.org/abs/2105.04339",
          "publishedOn": "2021-06-10T01:56:45.987Z",
          "wordCount": 591,
          "title": "DefSent: Sentence Embeddings using Definition Sentences. (arXiv:2105.04339v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.15671",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jingjing Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Hao Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_C/0/1/0/all/0/1\">Chun Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zaixiang Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>",
          "description": "The choice of token vocabulary affects the performance of machine\ntranslation. This paper aims to figure out what is a good vocabulary and\nwhether one can find the optimal vocabulary without trial training. To answer\nthese questions, we first provide an alternative understanding of the role of\nvocabulary from the perspective of information theory. Motivated by this, we\nformulate the quest of vocabularization -- finding the best token dictionary\nwith a proper size -- as an optimal transport (OT) problem.We We propose VOLT,\na simple and efficient solution without trial training. Empirical results show\nthat VOLT outperforms widely-used vocabularies in diverse scenarios, including\nWMT-14 English-German and TED's 52 translation directions. For example, VOLT\nachieves 70% vocabulary size reduction and 0.5 BLEU gain on English-German\ntranslation. Also, compared to BPE-search, VOLT reduces the search time from\n384 GPU hours to 30 GPU hours on English-German translation. Codes are\navailable at https://github.com/Jingjing-NLP/VOLT .",
          "link": "http://arxiv.org/abs/2012.15671",
          "publishedOn": "2021-06-10T01:56:45.981Z",
          "wordCount": 615,
          "title": "Vocabulary Learning via Optimal Transport for Machine Translation. (arXiv:2012.15671v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05160",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ozan_S/0/1/0/all/0/1\">&#x15e;&#xfc;kr&#xfc; Ozan</a>",
          "description": "How can a text corpus stored in a customer relationship management (CRM)\ndatabase be used for data mining and segmentation? In order to answer this\nquestion we inherited the state of the art methods commonly used in natural\nlanguage processing (NLP) literature, such as word embeddings, and deep\nlearning literature, such as recurrent neural networks (RNN). We used the text\nnotes from a CRM system which are taken by customer representatives of an\ninternet ads consultancy agency between years 2009 and 2020. We trained word\nembeddings by using the corresponding text corpus and showed that these word\nembeddings can not only be used directly for data mining but also be used in\nRNN architectures, which are deep learning frameworks built with long short\nterm memory (LSTM) units, for more comprehensive segmentation objectives. The\nresults prove that structured text data in a CRM can be used to mine out very\nvaluable information and any CRM can be equipped with useful NLP features once\nthe problem definitions are properly built and the solution methods are\nconveniently implemented.",
          "link": "http://arxiv.org/abs/2106.05160",
          "publishedOn": "2021-06-10T01:56:45.974Z",
          "wordCount": 638,
          "title": "Case Studies on using Natural Language Processing Techniques in Customer Relationship Management Software. (arXiv:2106.05160v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2011.02511",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kreutzer_J/0/1/0/all/0/1\">Julia Kreutzer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riezler_S/0/1/0/all/0/1\">Stefan Riezler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lawrence_C/0/1/0/all/0/1\">Carolin Lawrence</a>",
          "description": "Large volumes of interaction logs can be collected from NLP systems that are\ndeployed in the real world. How can this wealth of information be leveraged?\nUsing such interaction logs in an offline reinforcement learning (RL) setting\nis a promising approach. However, due to the nature of NLP tasks and the\nconstraints of production systems, a series of challenges arise. We present a\nconcise overview of these challenges and discuss possible solutions.",
          "link": "http://arxiv.org/abs/2011.02511",
          "publishedOn": "2021-06-10T01:56:45.944Z",
          "wordCount": 577,
          "title": "Offline Reinforcement Learning from Human Feedback in Real-World Sequence-to-Sequence Tasks. (arXiv:2011.02511v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.16809",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1\">Kun Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sisman_B/0/1/0/all/0/1\">Berrak Sisman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haizhou Li</a>",
          "description": "Emotional voice conversion (EVC) aims to change the emotional state of an\nutterance while preserving the linguistic content and speaker identity. In this\npaper, we propose a novel 2-stage training strategy for sequence-to-sequence\nemotional voice conversion with a limited amount of emotional speech data. We\nnote that the proposed EVC framework leverages text-to-speech (TTS) as they\nshare a common goal that is to generate high-quality expressive voice. In stage\n1, we perform style initialization with a multi-speaker TTS corpus, to\ndisentangle speaking style and linguistic content. In stage 2, we perform\nemotion training with a limited amount of emotional speech data, to learn how\nto disentangle emotional style and linguistic information from the speech. The\nproposed framework can perform both spectrum and prosody conversion and\nachieves significant improvement over the state-of-the-art baselines in both\nobjective and subjective evaluation.",
          "link": "http://arxiv.org/abs/2103.16809",
          "publishedOn": "2021-06-10T01:56:45.912Z",
          "wordCount": 598,
          "title": "Limited Data Emotional Voice Conversion Leveraging Text-to-Speech: Two-stage Sequence-to-Sequence Training. (arXiv:2103.16809v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03181",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Inoue_K/0/1/0/all/0/1\">Katsuma Inoue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ohara_S/0/1/0/all/0/1\">Soh Ohara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuniyoshi_Y/0/1/0/all/0/1\">Yasuo Kuniyoshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakajima_K/0/1/0/all/0/1\">Kohei Nakajima</a>",
          "description": "Language is an outcome of our complex and dynamic human-interactions and the\ntechnique of natural language processing (NLP) is hence built on human\nlinguistic activities. Bidirectional Encoder Representations from Transformers\n(BERT) has recently gained its popularity by establishing the state-of-the-art\nscores in several NLP benchmarks. A Lite BERT (ALBERT) is literally\ncharacterized as a lightweight version of BERT, in which the number of BERT\nparameters is reduced by repeatedly applying the same neural network called\nTransformer's encoder layer. By pre-training the parameters with a massive\namount of natural language data, ALBERT can convert input sentences into\nversatile high-dimensional vectors potentially capable of solving multiple NLP\ntasks. In that sense, ALBERT can be regarded as a well-designed\nhigh-dimensional dynamical system whose operator is the Transformer's encoder,\nand essential structures of human language are thus expected to be encapsulated\nin its dynamics. In this study, we investigated the embedded properties of\nALBERT to reveal how NLP tasks are effectively solved by exploiting its\ndynamics. We thereby aimed to explore the nature of human language from the\ndynamical expressions of the NLP model. Our short-term analysis clarified that\nthe pre-trained model stably yields trajectories with higher dimensionality,\nwhich would enhance the expressive capacity required for NLP tasks. Also, our\nlong-term analysis revealed that ALBERT intrinsically shows transient chaos, a\ntypical nonlinear phenomenon showing chaotic dynamics only in its transient,\nand the pre-trained ALBERT model tends to produce the chaotic trajectory for a\nsignificantly longer time period compared to a randomly-initialized one. Our\nresults imply that local chaoticity would contribute to improving NLP\nperformance, uncovering a novel aspect in the role of chaotic dynamics in human\nlanguage behaviors.",
          "link": "http://arxiv.org/abs/2106.03181",
          "publishedOn": "2021-06-10T01:56:45.906Z",
          "wordCount": 731,
          "title": "Transient Chaos in BERT. (arXiv:2106.03181v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.00891",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1\">Zhiwen Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulkarni_H/0/1/0/all/0/1\">Hrishikesh Kulkarni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1\">Grace Hui Yang</a>",
          "description": "Many task-oriented dialogue systems use deep reinforcement learning (DRL) to\nlearn policies that respond to the user appropriately and complete the tasks\nsuccessfully. Training DRL agents with diverse dialogue trajectories prepare\nthem well for rare user requests and unseen situations. One effective\ndiversification method is to let the agent interact with a diverse set of\nlearned user models. However, trajectories created by these artificial user\nmodels may contain generation errors, which can quickly propagate into the\nagent's policy. It is thus important to control the quality of the\ndiversification and resist the noise. In this paper, we propose a novel\ndialogue diversification method for task-oriented dialogue systems trained in\nsimulators. Our method, Intermittent Short Extension Ensemble (I-SEE),\nconstrains the intensity to interact with an ensemble of diverse user models\nand effectively controls the quality of the diversification. Evaluations on the\nMultiwoz dataset show that I-SEE successfully boosts the performance of several\nstate-of-the-art DRL dialogue agents.",
          "link": "http://arxiv.org/abs/2106.00891",
          "publishedOn": "2021-06-10T01:56:45.889Z",
          "wordCount": 605,
          "title": "High-Quality Diversification for Task-Oriented Dialogue Systems. (arXiv:2106.00891v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10042",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Potdar_N/0/1/0/all/0/1\">Nihal Potdar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Avila_A/0/1/0/all/0/1\">Anderson R. Avila</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_C/0/1/0/all/0/1\">Chao Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Dong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yiran Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiao Chen</a>",
          "description": "End-to-end spoken language understanding (SLU) has recently attracted\nincreasing interest. Compared to the conventional tandem-based approach that\ncombines speech recognition and language understanding as separate modules, the\nnew approach extracts users' intentions directly from the speech signals,\nresulting in joint optimization and low latency. Such an approach, however, is\ntypically designed to process one intention at a time, which leads users to\ntake multiple rounds to fulfill their requirements while interacting with a\ndialogue system. In this paper, we propose a streaming end-to-end framework\nthat can process multiple intentions in an online and incremental way. The\nbackbone of our framework is a unidirectional RNN trained with the\nconnectionist temporal classification (CTC) criterion. By this design, an\nintention can be identified when sufficient evidence has been accumulated, and\nmultiple intentions can be identified sequentially. We evaluate our solution on\nthe Fluent Speech Commands (FSC) dataset and the intent detection accuracy is\nabout 97 % on all multi-intent settings. This result is comparable to the\nperformance of the state-of-the-art non-streaming models, but is achieved in an\nonline and incremental way. We also employ our model to a keyword spotting task\nusing the Google Speech Commands dataset and the results are also highly\npromising.",
          "link": "http://arxiv.org/abs/2105.10042",
          "publishedOn": "2021-06-10T01:56:45.884Z",
          "wordCount": 677,
          "title": "A Streaming End-to-End Framework For Spoken Language Understanding. (arXiv:2105.10042v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.14210",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Reimers_N/0/1/0/all/0/1\">Nils Reimers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>",
          "description": "Information Retrieval using dense low-dimensional representations recently\nbecame popular and showed out-performance to traditional sparse-representations\nlike BM25. However, no previous work investigated how dense representations\nperform with large index sizes. We show theoretically and empirically that the\nperformance for dense representations decreases quicker than sparse\nrepresentations for increasing index sizes. In extreme cases, this can even\nlead to a tipping point where at a certain index size sparse representations\noutperform dense representations. We show that this behavior is tightly\nconnected to the number of dimensions of the representations: The lower the\ndimension, the higher the chance for false positives, i.e. returning irrelevant\ndocuments.",
          "link": "http://arxiv.org/abs/2012.14210",
          "publishedOn": "2021-06-10T01:56:45.826Z",
          "wordCount": 565,
          "title": "The Curse of Dense Low-Dimensional Information Retrieval for Large Index Sizes. (arXiv:2012.14210v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.12011",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Herzig_J/0/1/0/all/0/1\">Jonathan Herzig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muller_T/0/1/0/all/0/1\">Thomas M&#xfc;ller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krichene_S/0/1/0/all/0/1\">Syrine Krichene</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eisenschlos_J/0/1/0/all/0/1\">Julian Martin Eisenschlos</a>",
          "description": "Recent advances in open-domain QA have led to strong models based on dense\nretrieval, but only focused on retrieving textual passages. In this work, we\ntackle open-domain QA over tables for the first time, and show that retrieval\ncan be improved by a retriever designed to handle tabular context. We present\nan effective pre-training procedure for our retriever and improve retrieval\nquality with mined hard negatives. As relevant datasets are missing, we extract\na subset of Natural Questions (Kwiatkowski et al., 2019) into a Table QA\ndataset. We find that our retriever improves retrieval results from 72.0 to\n81.1 recall@10 and end-to-end QA results from 33.8 to 37.7 exact match, over a\nBERT based retriever.",
          "link": "http://arxiv.org/abs/2103.12011",
          "publishedOn": "2021-06-10T01:56:45.803Z",
          "wordCount": 577,
          "title": "Open Domain Question Answering over Tables via Dense Retrieval. (arXiv:2103.12011v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05111",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Karita_S/0/1/0/all/0/1\">Shigeki Karita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kubo_Y/0/1/0/all/0/1\">Yotaro Kubo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bacchiani_M/0/1/0/all/0/1\">Michiel Adriaan Unico Bacchiani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jones_L/0/1/0/all/0/1\">Llion Jones</a>",
          "description": "End-to-end (E2E) modeling is advantageous for automatic speech recognition\n(ASR) especially for Japanese since word-based tokenization of Japanese is not\ntrivial, and E2E modeling is able to model character sequences directly. This\npaper focuses on the latest E2E modeling techniques, and investigates their\nperformances on character-based Japanese ASR by conducting comparative\nexperiments. The results are analyzed and discussed in order to understand the\nrelative advantages of long short-term memory (LSTM), and Conformer models in\ncombination with connectionist temporal classification, transducer, and\nattention-based loss functions. Furthermore, the paper investigates on\neffectivity of the recent training techniques such as data augmentation\n(SpecAugment), variational noise injection, and exponential moving average. The\nbest configuration found in the paper achieved the state-of-the-art character\nerror rates of 4.1%, 3.2%, and 3.5% for Corpus of Spontaneous Japanese (CSJ)\neval1, eval2, and eval3 tasks, respectively. The system is also shown to be\ncomputationally efficient thanks to the efficiency of Conformer transducers.",
          "link": "http://arxiv.org/abs/2106.05111",
          "publishedOn": "2021-06-10T01:56:45.785Z",
          "wordCount": 607,
          "title": "A Comparative Study on Neural Architectures and Training Methods for Japanese Speech Recognition. (arXiv:2106.05111v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2008.03130",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Demir_C/0/1/0/all/0/1\">Caglar Demir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ngomo_A/0/1/0/all/0/1\">Axel-Cyrille Ngonga Ngomo</a>",
          "description": "In this paper, we study the problem of learning continuous vector\nrepresentations of knowledge graphs for predicting missing links. We present a\nnew approach called ConEx, which infers missing links by leveraging the\ncomposition of a 2D convolution with a Hermitian inner product of\ncomplex-valued embedding vectors. We evaluate ConEx against state-of-the-art\napproaches on the WN18RR, FB15K-237, KINSHIP and UMLS benchmark datasets. Our\nexperimental results show that ConEx achieves a performance superior to that of\nstate-of-the-art approaches such as RotatE, QuatE and TuckER on the link\nprediction task on all datasets while requiring at least 8 times fewer\nparameters. We ensure the reproducibility of our results by providing an\nopen-source implementation which includes the training, evaluation scripts\nalong with pre-trained models at https://github.com/conex-kge/ConEx.",
          "link": "http://arxiv.org/abs/2008.03130",
          "publishedOn": "2021-06-10T01:56:45.779Z",
          "wordCount": 587,
          "title": "Convolutional Complex Knowledge Graph Embeddings. (arXiv:2008.03130v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.15573",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1\">Mingzhu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moosavi_N/0/1/0/all/0/1\">Nafise Sadat Moosavi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_D/0/1/0/all/0/1\">Dan Roth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>",
          "description": "Coreference resolution is essential for natural language understanding and\nhas been long studied in NLP. In recent years, as the format of Question\nAnswering (QA) became a standard for machine reading comprehension (MRC), there\nhave been data collection efforts, e.g., Dasigi et al. (2019), that attempt to\nevaluate the ability of MRC models to reason about coreference. However, as we\nshow, coreference reasoning in MRC is a greater challenge than earlier thought;\nMRC datasets do not reflect the natural distribution and, consequently, the\nchallenges of coreference reasoning. Specifically, success on these datasets\ndoes not reflect a model's proficiency in coreference reasoning. We propose a\nmethodology for creating MRC datasets that better reflect the challenges of\ncoreference reasoning and use it to create a sample evaluation set. The results\non our dataset show that state-of-the-art models still struggle with these\nphenomena. Furthermore, we develop an effective way to use naturally occurring\ncoreference phenomena from existing coreference resolution datasets when\ntraining MRC models. This allows us to show an improvement in the coreference\nreasoning abilities of state-of-the-art models. The code and the resulting\ndataset are available at https://github.com/UKPLab/coref-reasoning-in-qa.",
          "link": "http://arxiv.org/abs/2012.15573",
          "publishedOn": "2021-06-10T01:56:45.772Z",
          "wordCount": 646,
          "title": "Coreference Reasoning in Machine Reading Comprehension. (arXiv:2012.15573v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04632",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Linjie Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_J/0/1/0/all/0/1\">Jie Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_Z/0/1/0/all/0/1\">Zhe Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1\">Licheng Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yen-Chun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pillai_R/0/1/0/all/0/1\">Rohit Pillai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1\">Yu Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1\">Luowei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Eric Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berg_T/0/1/0/all/0/1\">Tamara Lee Berg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jingjing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lijuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zicheng Liu</a>",
          "description": "Most existing video-and-language (VidL) research focuses on a single dataset,\nor multiple datasets of a single task. In reality, a truly useful VidL system\nis expected to be easily generalizable to diverse tasks, domains, and datasets.\nTo facilitate the evaluation of such systems, we introduce Video-And-Language\nUnderstanding Evaluation (VALUE) benchmark, an assemblage of 11 VidL datasets\nover 3 popular tasks: (i) text-to-video retrieval; (ii) video question\nanswering; and (iii) video captioning. VALUE benchmark aims to cover a broad\nrange of video genres, video lengths, data volumes, and task difficulty levels.\nRather than focusing on single-channel videos with visual information only,\nVALUE promotes models that leverage information from both video frames and\ntheir associated subtitles, as well as models that share knowledge across\nmultiple tasks. We evaluate various baseline methods with and without\nlarge-scale VidL pre-training, and systematically investigate the impact of\nvideo input channels, fusion methods, and different video representations. We\nalso study the transferability between tasks, and conduct multi-task learning\nunder different settings. The significant gap between our best model and human\nperformance calls for future study for advanced VidL models. VALUE is available\nat https://value-leaderboard.github.io/.",
          "link": "http://arxiv.org/abs/2106.04632",
          "publishedOn": "2021-06-10T01:56:45.767Z",
          "wordCount": 656,
          "title": "VALUE: A Multi-Task Benchmark for Video-and-Language Understanding Evaluation. (arXiv:2106.04632v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05251",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shujian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1\">Xinjie Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Bo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1\">Mingyuan Zhou</a>",
          "description": "Attention-based neural networks have achieved state-of-the-art results on a\nwide range of tasks. Most such models use deterministic attention while\nstochastic attention is less explored due to the optimization difficulties or\ncomplicated model design. This paper introduces Bayesian attention belief\nnetworks, which construct a decoder network by modeling unnormalized attention\nweights with a hierarchy of gamma distributions, and an encoder network by\nstacking Weibull distributions with a deterministic-upward-stochastic-downward\nstructure to approximate the posterior. The resulting auto-encoding networks\ncan be optimized in a differentiable way with a variational lower bound. It is\nsimple to convert any models with deterministic attention, including pretrained\nones, to the proposed Bayesian attention belief networks. On a variety of\nlanguage understanding tasks, we show that our method outperforms deterministic\nattention and state-of-the-art stochastic attention in accuracy, uncertainty\nestimation, generalization across domains, and robustness to adversarial\nattacks. We further demonstrate the general applicability of our method on\nneural machine translation and visual question answering, showing great\npotential of incorporating our method into various attention-related tasks.",
          "link": "http://arxiv.org/abs/2106.05251",
          "publishedOn": "2021-06-10T01:56:45.755Z",
          "wordCount": 596,
          "title": "Bayesian Attention Belief Networks. (arXiv:2106.05251v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05249",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ganesh_A/0/1/0/all/0/1\">Ananya Ganesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Palmer_M/0/1/0/all/0/1\">Martha Palmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kann_K/0/1/0/all/0/1\">Katharina Kann</a>",
          "description": "Recent advances in natural language processing (NLP) have the ability to\ntransform how classroom learning takes place. Combined with the increasing\nintegration of technology in today's classrooms, NLP systems leveraging\nquestion answering and dialog processing techniques can serve as private tutors\nor participants in classroom discussions to increase student engagement and\nlearning. To progress towards this goal, we use the classroom discourse\nframework of academically productive talk (APT) to learn strategies that make\nfor the best learning experience. In this paper, we introduce a new task,\ncalled future talk move prediction (FTMP): it consists of predicting the next\ntalk move -- an utterance strategy from APT -- given a conversation history\nwith its corresponding talk moves. We further introduce a neural network model\nfor this task, which outperforms multiple baselines by a large margin. Finally,\nwe compare our model's performance on FTMP to human performance and show\nseveral similarities between the two.",
          "link": "http://arxiv.org/abs/2106.05249",
          "publishedOn": "2021-06-10T01:56:45.738Z",
          "wordCount": 589,
          "title": "What Would a Teacher Do? Predicting Future Talk Moves. (arXiv:2106.05249v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2012.01721",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Si_Q/0/1/0/all/0/1\">Qingyi Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yuanxin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_P/0/1/0/all/0/1\">Peng Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zheng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiangnan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Weiping Wang</a>",
          "description": "Zero-shot intent detection (ZSID) aims to deal with the continuously emerging\nintents without annotated training data. However, existing ZSID systems suffer\nfrom two limitations: 1) They are not good at modeling the relationship between\nseen and unseen intents. 2) They cannot effectively recognize unseen intents\nunder the generalized intent detection (GZSID) setting. A critical problem\nbehind these limitations is that the representations of unseen intents cannot\nbe learned in the training stage. To address this problem, we propose a novel\nframework that utilizes unseen class labels to learn Class-Transductive Intent\nRepresentations (CTIR). Specifically, we allow the model to predict unseen\nintents during training, with the corresponding label names serving as input\nutterances. On this basis, we introduce a multi-task learning objective, which\nencourages the model to learn the distinctions among intents, and a similarity\nscorer, which estimates the connections among intents more accurately. CTIR is\neasy to implement and can be integrated with existing methods. Experiments on\ntwo real-world datasets show that CTIR brings considerable improvement to the\nbaseline systems.",
          "link": "http://arxiv.org/abs/2012.01721",
          "publishedOn": "2021-06-10T01:56:45.732Z",
          "wordCount": 636,
          "title": "Learning Class-Transductive Intent Representations for Zero-shot Intent Detection. (arXiv:2012.01721v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04939",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nikzad_Khasmakhi_N/0/1/0/all/0/1\">Narjes Nikzad-Khasmakhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feizi_Derakhshi_M/0/1/0/all/0/1\">Mohammad-Reza Feizi-Derakhshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asgari_Chenaghlu_M/0/1/0/all/0/1\">Meysam Asgari-Chenaghlu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balafar_M/0/1/0/all/0/1\">Mohammad-Ali Balafar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feizi_Derakhshi_A/0/1/0/all/0/1\">Ali-Reza Feizi-Derakhshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahkar_Farshi_T/0/1/0/all/0/1\">Taymaz Rahkar-Farshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramezani_M/0/1/0/all/0/1\">Majid Ramezani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jahanbakhsh_Nagadeh_Z/0/1/0/all/0/1\">Zoleikha Jahanbakhsh-Nagadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zafarani_Moattar_E/0/1/0/all/0/1\">Elnaz Zafarani-Moattar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranjbar_Khadivi_M/0/1/0/all/0/1\">Mehrdad Ranjbar-Khadivi</a>",
          "description": "Background: Keyword extraction is a popular research topic in the field of\nnatural language processing. Keywords are terms that describe the most relevant\ninformation in a document. The main problem that researchers are facing is how\nto efficiently and accurately extract the core keywords from a document.\nHowever, previous keyword extraction approaches have utilized the text and\ngraph features, there is the lack of models that can properly learn and combine\nthese features in a best way.\n\nMethods: In this paper, we develop a multimodal Key-phrase extraction\napproach, namely Phraseformer, using transformer and graph embedding\ntechniques. In Phraseformer, each keyword candidate is presented by a vector\nwhich is the concatenation of the text and structure learning representations.\nPhraseformer takes the advantages of recent researches such as BERT and ExEm to\npreserve both representations. Also, the Phraseformer treats the key-phrase\nextraction task as a sequence labeling problem solved using classification\ntask.\n\nResults: We analyze the performance of Phraseformer on three datasets\nincluding Inspec, SemEval2010 and SemEval 2017 by F1-score. Also, we\ninvestigate the performance of different classifiers on Phraseformer method\nover Inspec dataset. Experimental results demonstrate the effectiveness of\nPhraseformer method over the three datasets used. Additionally, the Random\nForest classifier gain the highest F1-score among all classifiers.\n\nConclusions: Due to the fact that the combination of BERT and ExEm is more\nmeaningful and can better represent the semantic of words. Hence, Phraseformer\nsignificantly outperforms single-modality methods.",
          "link": "http://arxiv.org/abs/2106.04939",
          "publishedOn": "2021-06-10T01:56:45.726Z",
          "wordCount": 685,
          "title": "Phraseformer: Multimodal Key-phrase Extraction using Transformer and Graph Embedding. (arXiv:2106.04939v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.03928",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wies_N/0/1/0/all/0/1\">Noam Wies</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_Y/0/1/0/all/0/1\">Yoav Levine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jannai_D/0/1/0/all/0/1\">Daniel Jannai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shashua_A/0/1/0/all/0/1\">Amnon Shashua</a>",
          "description": "After their successful debut in natural language processing, Transformer\narchitectures are now becoming the de-facto standard in many domains. An\nobstacle for their deployment over new modalities is the architectural\nconfiguration: the optimal depth-to-width ratio has been shown to dramatically\nvary across data types (e.g., $10$x larger over images than over language). We\ntheoretically predict the existence of an embedding rank bottleneck that limits\nthe contribution of self-attention width to the Transformer expressivity. We\nthus directly tie the input vocabulary size and rank to the optimal\ndepth-to-width ratio, since a small vocabulary size or rank dictates an added\nadvantage of depth over width. We empirically demonstrate the existence of this\nbottleneck and its implications on the depth-to-width interplay of Transformer\narchitectures, linking the architecture variability across domains to the often\nglossed-over usage of different vocabulary sizes or embedding ranks in\ndifferent domains. As an additional benefit, our rank bottlenecking framework\nallows us to identify size redundancies of $25\\%-50\\%$ in leading NLP models\nsuch as ALBERT and T5.",
          "link": "http://arxiv.org/abs/2105.03928",
          "publishedOn": "2021-06-10T01:56:45.720Z",
          "wordCount": 632,
          "title": "Which transformer architecture fits my data? A vocabulary bottleneck in self-attention. (arXiv:2105.03928v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.14465",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bujel_K/0/1/0/all/0/1\">Kamil Bujel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yannakoudakis_H/0/1/0/all/0/1\">Helen Yannakoudakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rei_M/0/1/0/all/0/1\">Marek Rei</a>",
          "description": "We investigate how sentence-level transformers can be modified into effective\nsequence labelers at the token level without any direct supervision. Existing\napproaches to zero-shot sequence labeling do not perform well when applied on\ntransformer-based architectures. As transformers contain multiple layers of\nmulti-head self-attention, information in the sentence gets distributed between\nmany tokens, negatively affecting zero-shot token-level performance. We find\nthat a soft attention module which explicitly encourages sharpness of attention\nweights can significantly outperform existing methods.",
          "link": "http://arxiv.org/abs/2103.14465",
          "publishedOn": "2021-06-10T01:56:45.713Z",
          "wordCount": 529,
          "title": "Zero-shot Sequence Labeling for Transformer-based Sentence Classifiers. (arXiv:2103.14465v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.07463",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_D/0/1/0/all/0/1\">Demi Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rush_A/0/1/0/all/0/1\">Alexander M. Rush</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Yoon Kim</a>",
          "description": "While task-specific finetuning of pretrained networks has led to significant\nempirical advances in NLP, the large size of networks makes finetuning\ndifficult to deploy in multi-task, memory-constrained settings. We propose diff\npruning as a simple approach to enable parameter-efficient transfer learning\nwithin the pretrain-finetune framework. This approach views finetuning as\nlearning a task-specific diff vector that is applied on top of the pretrained\nparameter vector, which remains fixed and is shared across different tasks. The\ndiff vector is adaptively pruned during training with a differentiable\napproximation to the L0-norm penalty to encourage sparsity. Diff pruning\nbecomes parameter-efficient as the number of tasks increases, as it requires\nstoring only the nonzero positions and weights of the diff vector for each\ntask, while the cost of storing the shared pretrained model remains constant.\nIt further does not require access to all tasks during training, which makes it\nattractive in settings where tasks arrive in stream or the set of tasks is\nunknown. We find that models finetuned with diff pruning can match the\nperformance of fully finetuned baselines on the GLUE benchmark while only\nmodifying 0.5% of the pretrained model's parameters per task.",
          "link": "http://arxiv.org/abs/2012.07463",
          "publishedOn": "2021-06-10T01:56:45.695Z",
          "wordCount": 647,
          "title": "Parameter-Efficient Transfer Learning with Diff Pruning. (arXiv:2012.07463v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05166",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yinpeng Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Liangyou Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1\">Xin Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qun Liu</a>",
          "description": "Recently, pre-training multilingual language models has shown great potential\nin learning multilingual representation, a crucial topic of natural language\nprocessing. Prior works generally use a single mixed attention (MA) module,\nfollowing TLM (Conneau and Lample, 2019), for attending to intra-lingual and\ncross-lingual contexts equivalently and simultaneously. In this paper, we\npropose a network named decomposed attention (DA) as a replacement of MA. The\nDA consists of an intra-lingual attention (IA) and a cross-lingual attention\n(CA), which model intralingual and cross-lingual supervisions respectively. In\naddition, we introduce a language-adaptive re-weighting strategy during\ntraining to further boost the model's performance. Experiments on various\ncross-lingual natural language understanding (NLU) tasks show that the proposed\narchitecture and learning strategy significantly improve the model's\ncross-lingual transferability.",
          "link": "http://arxiv.org/abs/2106.05166",
          "publishedOn": "2021-06-10T01:56:45.650Z",
          "wordCount": 553,
          "title": "Learning Multilingual Representation for Natural Language Understanding with Enhanced Cross-Lingual Supervision. (arXiv:2106.05166v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2004.08694",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dhole_K/0/1/0/all/0/1\">Kaustubh D. Dhole</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manning_C/0/1/0/all/0/1\">Christopher D. Manning</a>",
          "description": "Question Generation (QG) is fundamentally a simple syntactic transformation;\nhowever, many aspects of semantics influence what questions are good to form.\nWe implement this observation by developing Syn-QG, a set of transparent\nsyntactic rules leveraging universal dependencies, shallow semantic parsing,\nlexical resources, and custom rules which transform declarative sentences into\nquestion-answer pairs. We utilize PropBank argument descriptions and VerbNet\nstate predicates to incorporate shallow semantic content, which helps generate\nquestions of a descriptive nature and produce inferential and semantically\nricher questions than existing systems. In order to improve syntactic fluency\nand eliminate grammatically incorrect questions, we employ back-translation\nover the output of these syntactic rules. A set of crowd-sourced evaluations\nshows that our system can generate a larger number of highly grammatical and\nrelevant questions than previous QG systems and that back-translation\ndrastically improves grammaticality at a slight cost of generating irrelevant\nquestions.",
          "link": "http://arxiv.org/abs/2004.08694",
          "publishedOn": "2021-06-10T01:56:45.642Z",
          "wordCount": 639,
          "title": "Syn-QG: Syntactic and Shallow Semantic Rules for Question Generation. (arXiv:2004.08694v4 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04935",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meftah_S/0/1/0/all/0/1\">Sara Meftah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Semmar_N/0/1/0/all/0/1\">Nasredine Semmar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tamaazousti_Y/0/1/0/all/0/1\">Youssef Tamaazousti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Essafi_H/0/1/0/all/0/1\">Hassane Essafi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sadat_F/0/1/0/all/0/1\">Fatiha Sadat</a>",
          "description": "Neural Transfer Learning (TL) is becoming ubiquitous in Natural Language\nProcessing (NLP), thanks to its high performance on many tasks, especially in\nlow-resourced scenarios. Notably, TL is widely used for neural domain\nadaptation to transfer valuable knowledge from high-resource to low-resource\ndomains. In the standard fine-tuning scheme of TL, a model is initially\npre-trained on a source domain and subsequently fine-tuned on a target domain\nand, therefore, source and target domains are trained using the same\narchitecture. In this paper, we show through interpretation methods that such\nscheme, despite its efficiency, is suffering from a main limitation. Indeed,\nalthough capable of adapting to new domains, pre-trained neurons struggle with\nlearning certain patterns that are specific to the target domain. Moreover, we\nshed light on the hidden negative transfer occurring despite the high\nrelatedness between source and target domains, which may mitigate the final\ngain brought by transfer learning. To address these problems, we propose to\naugment the pre-trained model with normalised, weighted and randomly\ninitialised units that foster a better adaptation while maintaining the\nvaluable source knowledge. We show that our approach exhibits significant\nimprovements to the standard fine-tuning scheme for neural domain adaptation\nfrom the news domain to the social media domain on four NLP tasks:\npart-of-speech tagging, chunking, named entity recognition and morphosyntactic\ntagging.",
          "link": "http://arxiv.org/abs/2106.04935",
          "publishedOn": "2021-06-10T01:56:45.636Z",
          "wordCount": 657,
          "title": "Neural Supervised Domain Adaptation by Augmenting Pre-trained Models with Random Units. (arXiv:2106.04935v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2101.00379",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Levy_S/0/1/0/all/0/1\">Sharon Levy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saxon_M/0/1/0/all/0/1\">Michael Saxon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>",
          "description": "The adoption of natural language generation (NLG) models can leave\nindividuals vulnerable to the generation of harmful information memorized by\nthe models, such as conspiracy theories. While previous studies examine\nconspiracy theories in the context of social media, they have not evaluated\ntheir presence in the new space of generative language models. In this work, we\ninvestigate the capability of language models to generate conspiracy theory\ntext. Specifically, we aim to answer: can we test pretrained generative\nlanguage models for the memorization and elicitation of conspiracy theories\nwithout access to the model's training data? We highlight the difficulties of\nthis task and discuss it in the context of memorization, generalization, and\nhallucination. Utilizing a new dataset consisting of conspiracy theory topics\nand machine-generated conspiracy theories helps us discover that many\nconspiracy theories are deeply rooted in the pretrained language models. Our\nexperiments demonstrate a relationship between model parameters such as size\nand temperature and their propensity to generate conspiracy theory text. These\nresults indicate the need for a more thorough review of NLG applications before\nrelease and an in-depth discussion of the drawbacks of memorization in\ngenerative language models.",
          "link": "http://arxiv.org/abs/2101.00379",
          "publishedOn": "2021-06-10T01:56:45.630Z",
          "wordCount": 660,
          "title": "Investigating Memorization of Conspiracy Theories in Text Generation. (arXiv:2101.00379v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09501",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1\">Xiao Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mingxuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1\">Liwei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>",
          "description": "Existing multilingual machine translation approaches mainly focus on\nEnglish-centric directions, while the non-English directions still lag behind.\nIn this work, we aim to build a many-to-many translation system with an\nemphasis on the quality of non-English language directions. Our intuition is\nbased on the hypothesis that a universal cross-language representation leads to\nbetter multilingual translation performance. To this end, we propose mRASP2, a\ntraining method to obtain a single unified multilingual translation model.\nmRASP2 is empowered by two techniques: a) a contrastive learning scheme to\nclose the gap among representations of different languages, and b) data\naugmentation on both multiple parallel and monolingual data to further align\ntoken representations. For English-centric directions, mRASP2 outperforms\nexisting best unified model and achieves competitive or even better performance\nthan the pre-trained and fine-tuned model mBART on tens of WMT's translation\ndirections. For non-English directions, mRASP2 achieves an improvement of\naverage 10+ BLEU compared with the multilingual Transformer baseline. Code,\ndata and trained models are available at https://github.com/PANXiao1994/mRASP2.",
          "link": "http://arxiv.org/abs/2105.09501",
          "publishedOn": "2021-06-10T01:56:45.612Z",
          "wordCount": 627,
          "title": "Contrastive Learning for Many-to-many Multilingual Neural Machine Translation. (arXiv:2105.09501v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04631",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zafar_M/0/1/0/all/0/1\">Muhammad Bilal Zafar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Donini_M/0/1/0/all/0/1\">Michele Donini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Slack_D/0/1/0/all/0/1\">Dylan Slack</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Archambeau_C/0/1/0/all/0/1\">C&#xe9;dric Archambeau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1\">Sanjiv Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kenthapadi_K/0/1/0/all/0/1\">Krishnaram Kenthapadi</a>",
          "description": "With the ever-increasing complexity of neural language models, practitioners\nhave turned to methods for understanding the predictions of these models. One\nof the most well-adopted approaches for model interpretability is feature-based\ninterpretability, i.e., ranking the features in terms of their impact on model\npredictions. Several prior studies have focused on assessing the fidelity of\nfeature-based interpretability methods, i.e., measuring the impact of dropping\nthe top-ranked features on the model output. However, relatively little work\nhas been conducted on quantifying the robustness of interpretations. In this\nwork, we assess the robustness of interpretations of neural text classifiers,\nspecifically, those based on pretrained Transformer encoders, using two\nrandomization tests. The first compares the interpretations of two models that\nare identical except for their initializations. The second measures whether the\ninterpretations differ between a model with trained parameters and a model with\nrandom parameters. Both tests show surprising deviations from expected\nbehavior, raising questions about the extent of insights that practitioners may\ndraw from interpretations.",
          "link": "http://arxiv.org/abs/2106.04631",
          "publishedOn": "2021-06-10T01:56:45.596Z",
          "wordCount": 608,
          "title": "On the Lack of Robust Interpretability of Neural Text Classifiers. (arXiv:2106.04631v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04612",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ravfogel_S/0/1/0/all/0/1\">Shauli Ravfogel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taub_Tabib_H/0/1/0/all/0/1\">Hillel Taub-Tabib</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldberg_Y/0/1/0/all/0/1\">Yoav Goldberg</a>",
          "description": "Domain experts often need to extract structured information from large\ncorpora. We advocate for a search paradigm called ``extractive search'', in\nwhich a search query is enriched with capture-slots, to allow for such rapid\nextraction. Such an extractive search system can be built around syntactic\nstructures, resulting in high-precision, low-recall results. We show how the\nrecall can be improved using neural retrieval and alignment. The goals of this\npaper are to concisely introduce the extractive-search paradigm; and to\ndemonstrate a prototype neural retrieval system for extractive search and its\nbenefits and potential. Our prototype is available at\n\\url{https://spike.neural-sim.apps.allenai.org/} and a video demonstration is\navailable at \\url{https://vimeo.com/559586687}.",
          "link": "http://arxiv.org/abs/2106.04612",
          "publishedOn": "2021-06-10T01:56:45.590Z",
          "wordCount": 535,
          "title": "Neural Extractive Search. (arXiv:2106.04612v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2010.02810",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pluss_M/0/1/0/all/0/1\">Michel Pl&#xfc;ss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neukom_L/0/1/0/all/0/1\">Lukas Neukom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scheller_C/0/1/0/all/0/1\">Christian Scheller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogel_M/0/1/0/all/0/1\">Manfred Vogel</a>",
          "description": "We present the Swiss Parliaments Corpus (SPC), an automatically aligned Swiss\nGerman speech to Standard German text corpus. This first version of the corpus\nis based on publicly available data of the Bernese cantonal parliament and\nconsists of 293 hours of data. It was created using a novel forced sentence\nalignment procedure and an alignment quality estimator, which can be used to\ntrade off corpus size and quality. We trained Automatic Speech Recognition\n(ASR) models as baselines on different subsets of the data and achieved a Word\nError Rate (WER) of 0.278 and a BLEU score of 0.586 on the SPC test set. The\ncorpus is freely available for download.",
          "link": "http://arxiv.org/abs/2010.02810",
          "publishedOn": "2021-06-10T01:56:45.584Z",
          "wordCount": 581,
          "title": "Swiss Parliaments Corpus, an Automatically Aligned Swiss German Speech to Standard German Text Corpus. (arXiv:2010.02810v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04970",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xin Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_T/0/1/0/all/0/1\">Tao Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Houfeng Wang</a>",
          "description": "In this paper, we propose Shallow Aggressive Decoding (SAD) to improve the\nonline inference efficiency of the Transformer for instantaneous Grammatical\nError Correction (GEC). SAD optimizes the online inference efficiency for GEC\nby two innovations: 1) it aggressively decodes as many tokens as possible in\nparallel instead of always decoding only one token in each step to improve\ncomputational parallelism; 2) it uses a shallow decoder instead of the\nconventional Transformer architecture with balanced encoder-decoder depth to\nreduce the computational cost during inference. Experiments in both English and\nChinese GEC benchmarks show that aggressive decoding could yield the same\npredictions as greedy decoding but with a significant speedup for online\ninference. Its combination with the shallow decoder could offer an even higher\nonline inference speedup over the powerful Transformer baseline without quality\nloss. Not only does our approach allow a single model to achieve the\nstate-of-the-art results in English GEC benchmarks: 66.4 F0.5 in the CoNLL-14\nand 72.9 F0.5 in the BEA-19 test set with an almost 10x online inference\nspeedup over the Transformer-big model, but also it is easily adapted to other\nlanguages. Our code is available at\nhttps://github.com/AutoTemp/Shallow-Aggressive-Decoding.",
          "link": "http://arxiv.org/abs/2106.04970",
          "publishedOn": "2021-06-10T01:56:45.577Z",
          "wordCount": 627,
          "title": "Instantaneous Grammatical Error Correction with Shallow Aggressive Decoding. (arXiv:2106.04970v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05093",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Du_C/0/1/0/all/0/1\">Cunxiao Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1\">Zhaopeng Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jing Jiang</a>",
          "description": "We propose a new training objective named order-agnostic cross entropy (OaXE)\nfor fully non-autoregressive translation (NAT) models. OaXE improves the\nstandard cross-entropy loss to ameliorate the effect of word reordering, which\nis a common source of the critical multimodality problem in NAT. Concretely,\nOaXE removes the penalty for word order errors, and computes the cross entropy\nloss based on the best possible alignment between model predictions and target\ntokens. Since the log loss is very sensitive to invalid references, we leverage\ncross entropy initialization and loss truncation to ensure the model focuses on\na good part of the search space. Extensive experiments on major WMT benchmarks\nshow that OaXE substantially improves translation performance, setting new\nstate of the art for fully NAT models. Further analyses show that OaXE\nalleviates the multimodality problem by reducing token repetitions and\nincreasing prediction confidence. Our code, data, and trained models are\navailable at https://github.com/tencent-ailab/ICML21_OAXE.",
          "link": "http://arxiv.org/abs/2106.05093",
          "publishedOn": "2021-06-10T01:56:45.570Z",
          "wordCount": 590,
          "title": "Order-Agnostic Cross Entropy for Non-Autoregressive Machine Translation. (arXiv:2106.05093v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04835",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zichuan Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jing Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1\">Bowen Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiaodong He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1\">Tengyu Ma</a>",
          "description": "Recent work (Takanobu et al., 2020) proposed the system-wise evaluation on\ndialog systems and found that improvement on individual components (e.g., NLU,\npolicy) in prior work may not necessarily bring benefit to pipeline systems in\nsystem-wise evaluation. To improve the system-wise performance, in this paper,\nwe propose new joint system-wise optimization techniques for the pipeline\ndialog system. First, we propose a new data augmentation approach which\nautomates the labeling process for NLU training. Second, we propose a novel\nstochastic policy parameterization with Poisson distribution that enables\nbetter exploration and offers a principled way to compute policy gradient.\nThird, we propose a reward bonus to help policy explore successful dialogs. Our\napproaches outperform the competitive pipeline systems from Takanobu et al.\n(2020) by big margins of 12% success rate in automatic system-wise evaluation\nand of 16% success rate in human evaluation on the standard multi-domain\nbenchmark dataset MultiWOZ 2.1, and also outperform the recent state-of-the-art\nend-to-end trained model from DSTC9.",
          "link": "http://arxiv.org/abs/2106.04835",
          "publishedOn": "2021-06-10T01:56:45.553Z",
          "wordCount": 594,
          "title": "Joint System-Wise Optimization for Pipeline Goal-Oriented Dialog System. (arXiv:2106.04835v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04959",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ozan_S/0/1/0/all/0/1\">&#x15e;&#xfc;kr&#xfc; Ozan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tasar_D/0/1/0/all/0/1\">D. Emre Ta&#x15f;ar</a>",
          "description": "In this study, we aim to find a method to auto-tag sentences specific to a\ndomain. Our training data comprises short conversational sentences extracted\nfrom chat conversations between company's customer representatives and web site\nvisitors. We manually tagged approximately 14 thousand visitor inputs into ten\nbasic categories, which will later be used in a transformer-based language\nmodel with attention mechanisms for the ultimate goal of developing a chatbot\napplication that can produce meaningful dialogue. We considered three different\nstate-of-the-art models and reported their auto-tagging capabilities. We\nachieved the best performance with the bidirectional encoder representation\nfrom transformers (BERT) model. Implementation of the models used in these\nexperiments can be cloned from our GitHub repository and tested for similar\nauto-tagging problems without much effort.",
          "link": "http://arxiv.org/abs/2106.04959",
          "publishedOn": "2021-06-10T01:56:45.531Z",
          "wordCount": 554,
          "title": "Auto-tagging of Short Conversational Sentences using Natural Language Processing Methods. (arXiv:2106.04959v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04814",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1\">Yitao Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhe Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_X/0/1/0/all/0/1\">Xiaojun Wan</a>",
          "description": "Abstract Meaning Representation (AMR) is a rooted, labeled, acyclic graph\nrepresenting the semantics of natural language. As previous works show,\nalthough AMR is designed for English at first, it can also represent semantics\nin other languages. However, they find that concepts in their predicted AMR\ngraphs are less specific. We argue that the misprediction of concepts is due to\nthe high relevance between English tokens and AMR concepts. In this work, we\nintroduce bilingual input, namely the translated texts as well as non-English\ntexts, in order to enable the model to predict more accurate concepts. Besides,\nwe also introduce an auxiliary task, requiring the decoder to predict the\nEnglish sequences at the same time. The auxiliary task can help the decoder\nunderstand what exactly the corresponding English tokens are. Our proposed\ncross-lingual AMR parser surpasses previous state-of-the-art parser by 10.6\npoints on Smatch F1 score. The ablation study also demonstrates the efficacy of\nour proposed modules.",
          "link": "http://arxiv.org/abs/2106.04814",
          "publishedOn": "2021-06-10T01:56:45.525Z",
          "wordCount": 588,
          "title": "Making Better Use of Bilingual Information for Cross-Lingual AMR Parsing. (arXiv:2106.04814v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04832",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kurfali_M/0/1/0/all/0/1\">Murathan Kurfal&#x131;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ostling_R/0/1/0/all/0/1\">Robert &#xd6;stling</a>",
          "description": "Pre-trained multilingual language models have become an important building\nblock in multilingual natural language processing. In the present paper, we\ninvestigate a range of such models to find out how well they transfer\ndiscourse-level knowledge across languages. This is done with a systematic\nevaluation on a broader set of discourse-level tasks than has been previously\nbeen assembled. We find that the XLM-RoBERTa family of models consistently show\nthe best performance, by simultaneously being good monolingual models and\ndegrading relatively little in a zero-shot setting. Our results also indicate\nthat model distillation may hurt the ability of cross-lingual transfer of\nsentence representations, while language dissimilarity at most has a modest\neffect. We hope that our test suite, covering 5 tasks with a total of 22\nlanguages in 10 distinct families, will serve as a useful evaluation platform\nfor multilingual performance at and beyond the sentence level.",
          "link": "http://arxiv.org/abs/2106.04832",
          "publishedOn": "2021-06-10T01:56:45.505Z",
          "wordCount": 569,
          "title": "Probing Multilingual Language Models for Discourse. (arXiv:2106.04832v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04963",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1\">Tao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1\">Feifan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_H/0/1/0/all/0/1\">Haolan Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quan_X/0/1/0/all/0/1\">Xiaojun Quan</a>",
          "description": "Most of the recent work on personality detection from online posts adopts\nmultifarious deep neural networks to represent the posts and builds predictive\nmodels in a data-driven manner, without the exploitation of psycholinguistic\nknowledge that may unveil the connections between one's language usage and his\npsychological traits. In this paper, we propose a psycholinguistic\nknowledge-based tripartite graph network, TrigNet, which consists of a\ntripartite graph network and a BERT-based graph initializer. The graph network\ninjects structural psycholinguistic knowledge from LIWC, a computerized\ninstrument for psycholinguistic analysis, by constructing a heterogeneous\ntripartite graph. The graph initializer is employed to provide initial\nembeddings for the graph nodes. To reduce the computational cost in graph\nlearning, we further propose a novel flow graph attention network (GAT) that\nonly transmits messages between neighboring parties in the tripartite graph.\nBenefiting from the tripartite graph, TrigNet can aggregate post information\nfrom a psychological perspective, which is a novel way of exploiting domain\nknowledge. Extensive experiments on two datasets show that TrigNet outperforms\nthe existing state-of-art model by 3.47 and 2.10 points in average F1.\nMoreover, the flow GAT reduces the FLOPS and Memory measures by 38% and 32%,\nrespectively, in comparison to the original GAT in our setting.",
          "link": "http://arxiv.org/abs/2106.04963",
          "publishedOn": "2021-06-10T01:56:45.498Z",
          "wordCount": 631,
          "title": "Psycholinguistic Tripartite Graph Network for Personality Detection. (arXiv:2106.04963v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04905",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_G/0/1/0/all/0/1\">Guangyi Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Meng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_E/0/1/0/all/0/1\">Enhong Chen</a>",
          "description": "Sentence semantic matching requires an agent to determine the semantic\nrelation between two sentences, where much recent progress has been made by the\nadvancement of representation learning techniques and inspiration of human\nbehaviors. Among all these methods, attention mechanism plays an essential role\nby selecting important parts effectively. However, current attention methods\neither focus on all the important parts in a static way or only select one\nimportant part at one attention step dynamically, which leaves a large space\nfor further improvement. To this end, in this paper, we design a novel Dynamic\nGaussian Attention Network (DGA-Net) to combine the advantages of current\nstatic and dynamic attention methods. More specifically, we first leverage\npre-trained language model to encode the input sentences and construct semantic\nrepresentations from a global perspective. Then, we develop a Dynamic Gaussian\nAttention (DGA) to dynamically capture the important parts and corresponding\nlocal contexts from a detailed perspective. Finally, we combine the global\ninformation and detailed local information together to decide the semantic\nrelation of sentences comprehensively and precisely. Extensive experiments on\ntwo popular sentence semantic matching tasks demonstrate that our proposed\nDGA-Net is effective in improving the ability of attention mechanism.",
          "link": "http://arxiv.org/abs/2106.04905",
          "publishedOn": "2021-06-10T01:56:45.477Z",
          "wordCount": 630,
          "title": "DGA-Net Dynamic Gaussian Attention Network for Sentence Semantic Matching. (arXiv:2106.04905v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04897",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aldarmaki_H/0/1/0/all/0/1\">Hanan Aldarmaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ullah_A/0/1/0/all/0/1\">Asad Ullah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaki_N/0/1/0/all/0/1\">Nazar Zaki</a>",
          "description": "Automatic Speech Recognition (ASR) systems can be trained to achieve\nremarkable performance given large amounts of manually transcribed speech, but\nlarge labeled data sets can be difficult or expensive to acquire for all\nlanguages of interest. In this paper, we review the research literature to\nidentify models and ideas that could lead to fully unsupervised ASR, including\nunsupervised segmentation of the speech signal, unsupervised mapping from\nspeech segments to text, and semi-supervised models with nominal amounts of\nlabeled examples. The objective of the study is to identify the limitations of\nwhat can be learned from speech data alone and to understand the minimum\nrequirements for speech recognition. Identifying these limitations would help\noptimize the resources and efforts in ASR development for low-resource\nlanguages.",
          "link": "http://arxiv.org/abs/2106.04897",
          "publishedOn": "2021-06-10T01:56:45.471Z",
          "wordCount": 552,
          "title": "Unsupervised Automatic Speech Recognition: A Review. (arXiv:2106.04897v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04791",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liao_D/0/1/0/all/0/1\">Danqi Liao</a>",
          "description": "Sentence embeddings encode sentences in fixed dense vectors and have played\nan important role in various NLP tasks and systems. Methods for building\nsentence embeddings include unsupervised learning such as Quick-Thoughts and\nsupervised learning such as InferSent. With the success of pretrained NLP\nmodels, recent research shows that fine-tuning pretrained BERT on SNLI and\nMulti-NLI data creates state-of-the-art sentence embeddings, outperforming\nprevious sentence embeddings methods on various evaluation benchmarks. In this\npaper, we propose a new method to build sentence embeddings by doing supervised\ncontrastive learning. Specifically our method fine-tunes pretrained BERT on\nSNLI data, incorporating both supervised crossentropy loss and supervised\ncontrastive loss. Compared with baseline where fine-tuning is only done with\nsupervised cross-entropy loss similar to current state-of-the-art method SBERT,\nour supervised contrastive method improves 2.8% in average on Semantic Textual\nSimilarity (STS) benchmarks and 1.05% in average on various sentence transfer\ntasks.",
          "link": "http://arxiv.org/abs/2106.04791",
          "publishedOn": "2021-06-10T01:56:45.459Z",
          "wordCount": 565,
          "title": "Sentence Embeddings using Supervised Contrastive Learning. (arXiv:2106.04791v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04908",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mina_S/0/1/0/all/0/1\">Sch&#xfc;tz Mina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaqueline_B/0/1/0/all/0/1\">Boeck Jaqueline</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daria_L/0/1/0/all/0/1\">Liakhovets Daria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Djordje_S/0/1/0/all/0/1\">Slijep&#x10d;evi&#x107; Djordje</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Armin_K/0/1/0/all/0/1\">Kirchknopf Armin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manuel_H/0/1/0/all/0/1\">Hecht Manuel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johannes_B/0/1/0/all/0/1\">Bogensperger Johannes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sven_S/0/1/0/all/0/1\">Schlarb Sven</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alexander_S/0/1/0/all/0/1\">Schindler Alexander</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matthias_Z/0/1/0/all/0/1\">Zeppelzauer Matthias</a>",
          "description": "Sexism has become an increasingly major problem on social networks during the\nlast years. The first shared task on sEXism Identification in Social neTworks\n(EXIST) at IberLEF 2021 is an international competition in the field of Natural\nLanguage Processing (NLP) with the aim to automatically identify sexism in\nsocial media content by applying machine learning methods. Thereby sexism\ndetection is formulated as a coarse (binary) classification problem and a\nfine-grained classification task that distinguishes multiple types of sexist\ncontent (e.g., dominance, stereotyping, and objectification). This paper\npresents the contribution of the AIT_FHSTP team at the EXIST2021 benchmark for\nboth tasks. To solve the tasks we applied two multilingual transformer models,\none based on multilingual BERT and one based on XLM-R. Our approach uses two\ndifferent strategies to adapt the transformers to the detection of sexist\ncontent: first, unsupervised pre-training with additional data and second,\nsupervised fine-tuning with additional and augmented data. For both tasks our\nbest model is XLM-R with unsupervised pre-training on the EXIST data and\nadditional datasets and fine-tuning on the provided dataset. The best run for\nthe binary classification (task 1) achieves a macro F1-score of 0.7752 and\nscores 5th rank in the benchmark; for the multiclass classification (task 2)\nour best submission scores 6th rank with a macro F1-score of 0.5589.",
          "link": "http://arxiv.org/abs/2106.04908",
          "publishedOn": "2021-06-10T01:56:45.452Z",
          "wordCount": 670,
          "title": "Automatic Sexism Detection with Multilingual Transformer Models. (arXiv:2106.04908v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04985",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Korbak_T/0/1/0/all/0/1\">Tomasz Korbak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elsahar_H/0/1/0/all/0/1\">Hady Elsahar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dymetman_M/0/1/0/all/0/1\">Marc Dymetman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kruszewski_G/0/1/0/all/0/1\">Germ&#xe1;n Kruszewski</a>",
          "description": "Neural language models can be successfully trained on source code, leading to\napplications such as code completion. However, their versatile autoregressive\nself-supervision objective overlooks important global sequence-level features\nthat are present in the data such as syntactic correctness or compilability. In\nthis work, we pose the problem of learning to generate compilable code as\nconstraint satisfaction. We define an Energy-Based Model (EBM) representing a\npre-trained generative model with an imposed constraint of generating only\ncompilable sequences. We then use the KL-Adaptive Distributional Policy\nGradient algorithm (Khalifa et al., 2021) to train a generative model\napproximating the EBM. We conduct experiments showing that our proposed\napproach is able to improve compilability rates without sacrificing diversity\nand complexity of the generated samples.",
          "link": "http://arxiv.org/abs/2106.04985",
          "publishedOn": "2021-06-10T01:56:45.445Z",
          "wordCount": 578,
          "title": "Energy-Based Models for Code Generation under Compilability Constraints. (arXiv:2106.04985v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04847",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Huanqin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_D/0/1/0/all/0/1\">Dan Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Feng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Di Wang</a>",
          "description": "Keyphrase Prediction (KP) task aims at predicting several keyphrases that can\nsummarize the main idea of the given document. Mainstream KP methods can be\ncategorized into purely generative approaches and integrated models with\nextraction and generation. However, these methods either ignore the diversity\namong keyphrases or only weakly capture the relation across tasks implicitly.\nIn this paper, we propose UniKeyphrase, a novel end-to-end learning framework\nthat jointly learns to extract and generate keyphrases. In UniKeyphrase,\nstacked relation layer and bag-of-words constraint are proposed to fully\nexploit the latent semantic relation between extraction and generation in the\nview of model structure and training process, respectively. Experiments on KP\nbenchmarks demonstrate that our joint approach outperforms mainstream methods\nby a large margin.",
          "link": "http://arxiv.org/abs/2106.04847",
          "publishedOn": "2021-06-10T01:56:45.429Z",
          "wordCount": 568,
          "title": "UniKeyphrase: A Unified Extraction and Generation Framework for Keyphrase Prediction. (arXiv:2106.04847v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04830",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sweed_N/0/1/0/all/0/1\">Nir Sweed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shahaf_D/0/1/0/all/0/1\">Dafna Shahaf</a>",
          "description": "A snowclone is a customizable phrasal template that can be realized in\nmultiple, instantly recognized variants. For example, ``* is the new *\" (Orange\nis the new black, 40 is the new 30). Snowclones are extensively used in social\nmedia. In this paper, we study snowclones originating from pop-culture quotes;\nour goal is to automatically detect cultural references in text. We introduce a\nnew, publicly available data set of pop-culture quotes and their corresponding\nsnowclone usages and train models on them. We publish code for Catchphrase, an\ninternet browser plugin to automatically detect and mark references in\nreal-time, and examine its performance via a user study. Aside from assisting\npeople to better comprehend cultural references, we hope that detecting\nsnowclones can complement work on paraphrasing and help to tackle long-standing\nquestions in social science about the dynamics of information propagation.",
          "link": "http://arxiv.org/abs/2106.04830",
          "publishedOn": "2021-06-10T01:56:45.422Z",
          "wordCount": 557,
          "title": "Catchphrase: Automatic Detection of Cultural References. (arXiv:2106.04830v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04903",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kale_M/0/1/0/all/0/1\">Maija K&#x101;le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rikters_M/0/1/0/all/0/1\">Mat&#x12b;ss Rikters</a>",
          "description": "We analysed sentiment and frequencies related to smell, taste and temperature\nexpressed by food tweets in the Latvian language. To get a better understanding\nof the role of smell, taste and temperature in the mental map of food\nassociations, we looked at such categories as 'tasty' and 'healthy', which\nturned out to be mutually exclusive. By analysing the occurrence frequency of\nwords associated with these categories, we discovered that food discourse\noverall was permeated by `tasty' while the category of 'healthy' was relatively\nsmall. Finally, we used the analysis of temporal dynamics to see if we can\ntrace seasonality or other temporal aspects in smell, taste and temperature as\nreflected in food tweets. Understanding the composition of social media content\nwith relation to smell, taste and temperature in food tweets allows us to\ndevelop our work further - on food culture/seasonality and its relation to\ntemperature, on our limited capacity to express smell-related sentiments, and\nthe lack of the paradigm of taste in discussing food healthiness.",
          "link": "http://arxiv.org/abs/2106.04903",
          "publishedOn": "2021-06-10T01:56:45.416Z",
          "wordCount": 602,
          "title": "Fragmented and Valuable: Following Sentiment Changes in Food Tweets. (arXiv:2106.04903v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04747",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Briakou_E/0/1/0/all/0/1\">Eleftheria Briakou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_S/0/1/0/all/0/1\">Sweta Agrawal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Ke Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tetreault_J/0/1/0/all/0/1\">Joel Tetreault</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carpuat_M/0/1/0/all/0/1\">Marine Carpuat</a>",
          "description": "This paper reviews and summarizes human evaluation practices described in 97\nstyle transfer papers with respect to three main evaluation aspects: style\ntransfer, meaning preservation, and fluency. In principle, evaluations by human\nraters should be the most reliable. However, in style transfer papers, we find\nthat protocols for human evaluations are often underspecified and not\nstandardized, which hampers the reproducibility of research in this field and\nprogress toward better human and automatic evaluation methods.",
          "link": "http://arxiv.org/abs/2106.04747",
          "publishedOn": "2021-06-10T01:56:45.258Z",
          "wordCount": 504,
          "title": "A Review of Human Evaluation for Style Transfer. (arXiv:2106.04747v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04753",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Ziming Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yada Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_G/0/1/0/all/0/1\">Guangnan Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_X/0/1/0/all/0/1\">Xiaodong Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Fan Zhang</a>",
          "description": "In the recent advances of natural language processing, the scale of the\nstate-of-the-art models and datasets is usually extensive, which challenges the\napplication of sample-based explanation methods in many aspects, such as\nexplanation interpretability, efficiency, and faithfulness. In this work, for\nthe first time, we can improve the interpretability of explanations by allowing\narbitrary text sequences as the explanation unit. On top of this, we implement\na hessian-free method with a model faithfulness guarantee. Finally, to compare\nour method with the others, we propose a semantic-based evaluation metric that\ncan better align with humans' judgment of explanations than the widely adopted\ndiagnostic or re-training measures. The empirical results on multiple real data\nsets demonstrate the proposed method's superior performance to popular\nexplanation techniques such as Influence Function or TracIn on semantic\nevaluation.",
          "link": "http://arxiv.org/abs/2106.04753",
          "publishedOn": "2021-06-10T01:56:45.250Z",
          "wordCount": 581,
          "title": "On Sample Based Explanation Methods for NLP:Efficiency, Faithfulness, and Semantic Evaluation. (arXiv:2106.04753v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04681",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Beddiar_D/0/1/0/all/0/1\">Djamila Romaissa Beddiar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jahan_M/0/1/0/all/0/1\">Md Saroar Jahan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oussalah_M/0/1/0/all/0/1\">Mourad Oussalah</a>",
          "description": "With proliferation of user generated contents in social media platforms,\nestablishing mechanisms to automatically identify toxic and abusive content\nbecomes a prime concern for regulators, researchers, and society. Keeping the\nbalance between freedom of speech and respecting each other dignity is a major\nconcern of social media platform regulators. Although, automatic detection of\noffensive content using deep learning approaches seems to provide encouraging\nresults, training deep learning-based models requires large amounts of\nhigh-quality labeled data, which is often missing. In this regard, we present\nin this paper a new deep learning-based method that fuses a Back Translation\nmethod, and a Paraphrasing technique for data augmentation. Our pipeline\ninvestigates different word-embedding-based architectures for classification of\nhate speech. The back translation technique relies on an encoder-decoder\narchitecture pre-trained on a large corpus and mostly used for machine\ntranslation. In addition, paraphrasing exploits the transformer model and the\nmixture of experts to generate diverse paraphrases. Finally, LSTM, and CNN are\ncompared to seek enhanced classification results. We evaluate our proposal on\nfive publicly available datasets; namely, AskFm corpus, Formspring dataset,\nWarner and Waseem dataset, Olid, and Wikipedia toxic comments dataset. The\nperformance of the proposal together with comparison to some related\nstate-of-art results demonstrate the effectiveness and soundness of our\nproposal.",
          "link": "http://arxiv.org/abs/2106.04681",
          "publishedOn": "2021-06-10T01:56:45.226Z",
          "wordCount": 640,
          "title": "Data Expansion using Back Translation and Paraphrasing for Hate Speech Detection. (arXiv:2106.04681v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04853",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chakravarthi_B/0/1/0/all/0/1\">Bharathi Raja Chakravarthi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+K_J/0/1/0/all/0/1\">Jishnu Parameswaran P.K</a>, <a href=\"http://arxiv.org/find/cs/1/au:+B_P/0/1/0/all/0/1\">Premjith B</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soman_K/0/1/0/all/0/1\">K.P Soman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ponnusamy_R/0/1/0/all/0/1\">Rahul Ponnusamy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumaresan_P/0/1/0/all/0/1\">Prasanna Kumar Kumaresan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thamburaj_K/0/1/0/all/0/1\">Kingston Pal Thamburaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McCrae_J/0/1/0/all/0/1\">John P. McCrae</a>",
          "description": "Human communication is inherently multimodal and asynchronous. Analyzing\nhuman emotions and sentiment is an emerging field of artificial intelligence.\nWe are witnessing an increasing amount of multimodal content in local languages\non social media about products and other topics. However, there are not many\nmultimodal resources available for under-resourced Dravidian languages. Our\nstudy aims to create a multimodal sentiment analysis dataset for the\nunder-resourced Tamil and Malayalam languages. First, we downloaded product or\nmovies review videos from YouTube for Tamil and Malayalam. Next, we created\ncaptions for the videos with the help of annotators. Then we labelled the\nvideos for sentiment, and verified the inter-annotator agreement using Fleiss's\nKappa. This is the first multimodal sentiment analysis dataset for Tamil and\nMalayalam by volunteer annotators.",
          "link": "http://arxiv.org/abs/2106.04853",
          "publishedOn": "2021-06-10T01:56:45.214Z",
          "wordCount": 571,
          "title": "DravidianMultiModality: A Dataset for Multi-modal Sentiment Analysis in Tamil and Malayalam. (arXiv:2106.04853v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04718",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1\">Yu Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_F/0/1/0/all/0/1\">Fei Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiusheng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhendawade_N/0/1/0/all/0/1\">Nikhil Bhendawade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_T/0/1/0/all/0/1\">Ting Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1\">Yeyun Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1\">Nan Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_D/0/1/0/all/0/1\">Desheng Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chi_B/0/1/0/all/0/1\">Bingyu Chi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ruifei Zhang</a>",
          "description": "Transformer-based models have made tremendous impacts in natural language\ngeneration. However the inference speed is a bottleneck due to large model size\nand intensive computing involved in auto-regressive decoding process. We\ndevelop FastSeq framework to accelerate sequence generation without accuracy\nloss. The proposed optimization techniques include an attention cache\noptimization, an efficient algorithm for detecting repeated n-grams, and an\nasynchronous generation pipeline with parallel I/O. These optimizations are\ngeneral enough to be applicable to Transformer-based models (e.g., T5, GPT2,\nand UniLM). Our benchmark results on a set of widely used and diverse models\ndemonstrate 4-9x inference speed gain. Additionally, FastSeq is easy to use\nwith a simple one-line code change. The source code is available at\nhttps://github.com/microsoft/fastseq.",
          "link": "http://arxiv.org/abs/2106.04718",
          "publishedOn": "2021-06-10T01:56:45.207Z",
          "wordCount": 560,
          "title": "FastSeq: Make Sequence Generation Faster. (arXiv:2106.04718v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04726",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kazemi_A/0/1/0/all/0/1\">Ashkan Kazemi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garimella_K/0/1/0/all/0/1\">Kiran Garimella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shahi_G/0/1/0/all/0/1\">Gautam Kishore Shahi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaffney_D/0/1/0/all/0/1\">Devin Gaffney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hale_S/0/1/0/all/0/1\">Scott A. Hale</a>",
          "description": "WhatsApp is a popular chat application used by over 2 billion users\nworldwide. However, due to end-to-end encryption, there is currently no easy\nway to fact-check content on WhatsApp at scale. In this paper, we analyze the\nusefulness of a crowd-sourced system on WhatsApp through which users can submit\n\"tips\" containing messages they want fact-checked. We compare the tips sent to\na WhatsApp tipline run during the 2019 Indian national elections with the\nmessages circulating in large, public groups on WhatsApp and other social media\nplatforms during the same period. We find that tiplines are a very useful lens\ninto WhatsApp conversations: a significant fraction of messages and images sent\nto the tipline match with the content being shared on public WhatsApp groups\nand other social media. Our analysis also shows that tiplines cover the most\npopular content well, and a majority of such content is often shared to the\ntipline before appearing in large, public WhatsApp groups. Overall, the\nanalysis suggests tiplines can be an effective source for discovering content\nto fact-check.",
          "link": "http://arxiv.org/abs/2106.04726",
          "publishedOn": "2021-06-10T01:56:45.187Z",
          "wordCount": 635,
          "title": "Tiplines to Combat Misinformation on Encrypted Platforms: A Case Study of the 2019 Indian Election on WhatsApp. (arXiv:2106.04726v1 [cs.SI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04630",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_R/0/1/0/all/0/1\">Rongmei Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jie Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zalmout_N/0/1/0/all/0/1\">Nasser Zalmout</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_L/0/1/0/all/0/1\">Li Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1\">Xin Luna Dong</a>",
          "description": "Understanding product attributes plays an important role in improving online\nshopping experience for customers and serves as an integral part for\nconstructing a product knowledge graph. Most existing methods focus on\nattribute extraction from text description or utilize visual information from\nproduct images such as shape and color. Compared to the inputs considered in\nprior works, a product image in fact contains more information, represented by\na rich mixture of words and visual clues with a layout carefully designed to\nimpress customers. This work proposes a more inclusive framework that fully\nutilizes these different modalities for attribute extraction. Inspired by\nrecent works in visual question answering, we use a transformer based sequence\nto sequence model to fuse representations of product text, Optical Character\nRecognition (OCR) tokens and visual objects detected in the product image. The\nframework is further extended with the capability to extract attribute value\nacross multiple product categories with a single model, by training the decoder\nto predict both product category and attribute value and conditioning its\noutput on product category. The model provides a unified attribute extraction\nsolution desirable at an e-commerce platform that offers numerous product\ncategories with a diverse body of product attributes. We evaluated the model on\ntwo product attributes, one with many possible values and one with a small set\nof possible values, over 14 product categories and found the model could\nachieve 15% gain on the Recall and 10% gain on the F1 score compared to\nexisting methods using text-only features.",
          "link": "http://arxiv.org/abs/2106.04630",
          "publishedOn": "2021-06-10T01:56:45.112Z",
          "wordCount": 704,
          "title": "PAM: Understanding Product Images in Cross Product Category Attribute Extraction. (arXiv:2106.04630v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04641",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pogrebnyakov_N/0/1/0/all/0/1\">Nicolai Pogrebnyakov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shaghaghian_S/0/1/0/all/0/1\">Shohreh Shaghaghian</a>",
          "description": "Transfer learning methods, and in particular domain adaptation, help exploit\nlabeled data in one domain to improve the performance of a certain task in\nanother domain. However, it is still not clear what factors affect the success\nof domain adaptation. This paper models adaptation success and selection of the\nmost suitable source domains among several candidates in text similarity. We\nuse descriptive domain information and cross-domain similarity metrics as\npredictive features. While mostly positive, the results also point to some\ndomains where adaptation success was difficult to predict.",
          "link": "http://arxiv.org/abs/2106.04641",
          "publishedOn": "2021-06-10T01:56:45.067Z",
          "wordCount": 520,
          "title": "Predicting the Success of Domain Adaptation in Text Similarity. (arXiv:2106.04641v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04647",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mahabadi_R/0/1/0/all/0/1\">Rabeeh Karimi Mahabadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henderson_J/0/1/0/all/0/1\">James Henderson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruder_S/0/1/0/all/0/1\">Sebastian Ruder</a>",
          "description": "Adapting large-scale pretrained language models to downstream tasks via\nfine-tuning is the standard method for achieving state-of-the-art performance\non NLP benchmarks. However, fine-tuning all weights of models with millions or\nbillions of parameters is sample-inefficient, unstable in low-resource\nsettings, and wasteful as it requires storing a separate copy of the model for\neach task. Recent work has developed parameter-efficient fine-tuning methods,\nbut these approaches either still require a relatively large number of\nparameters or underperform standard fine-tuning. In this work, we propose\nCompacter, a method for fine-tuning large-scale language models with a better\ntrade-off between task performance and the number of trainable parameters than\nprior work. Compacter accomplishes this by building on top of ideas from\nadapters, low-rank optimization, and parameterized hypercomplex multiplication\nlayers.\n\nSpecifically, Compacter inserts task-specific weight matrices into a\npretrained model's weights, which are computed efficiently as a sum of\nKronecker products between shared ``slow'' weights and ``fast'' rank-one\nmatrices defined per Compacter layer. By only training 0.047% of a pretrained\nmodel's parameters, Compacter performs on par with standard fine-tuning on GLUE\nand outperforms fine-tuning in low-resource settings. Our code is publicly\navailable in https://github.com/rabeehk/compacter/",
          "link": "http://arxiv.org/abs/2106.04647",
          "publishedOn": "2021-06-10T01:56:45.020Z",
          "wordCount": 612,
          "title": "Compacter: Efficient Low-Rank Hypercomplex Adapter Layers. (arXiv:2106.04647v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04660",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yiran Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potdar_N/0/1/0/all/0/1\">Nihal Potdar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Avila_A/0/1/0/all/0/1\">Anderson R. Avila</a>",
          "description": "Human-computer interaction (HCI) is significantly impacted by delayed\nresponses from a spoken dialogue system. Hence, end-to-end (e2e) spoken\nlanguage understanding (SLU) solutions have recently been proposed to decrease\nlatency. Such approaches allow for the extraction of semantic information\ndirectly from the speech signal, thus bypassing the need for a transcript from\nan automatic speech recognition (ASR) system. In this paper, we propose a\ncompact e2e SLU architecture for streaming scenarios, where chunks of the\nspeech signal are processed continuously to predict intent and slot values. Our\nmodel is based on a 3D convolutional neural network (3D-CNN) and a\nunidirectional long short-term memory (LSTM). We compare the performance of two\nalignment-free losses: the connectionist temporal classification (CTC) method\nand its adapted version, namely connectionist temporal localization (CTL). The\nlatter performs not only the classification but also localization of sequential\naudio events. The proposed solution is evaluated on the Fluent Speech Command\ndataset and results show our model ability to process incoming speech signal,\nreaching accuracy as high as 98.97 % for CTC and 98.78 % for CTL on\nsingle-label classification, and as high as 95.69 % for CTC and 95.28 % for CTL\non two-label prediction.",
          "link": "http://arxiv.org/abs/2106.04660",
          "publishedOn": "2021-06-10T01:56:44.974Z",
          "wordCount": 637,
          "title": "Sequential End-to-End Intent and Slot Label Classification and Localization. (arXiv:2106.04660v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04653",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sahu_P/0/1/0/all/0/1\">Pritish Sahu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cogswell_M/0/1/0/all/0/1\">Michael Cogswell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rutherford_Quach_S/0/1/0/all/0/1\">Sara Rutherford-Quach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Divakaran_A/0/1/0/all/0/1\">Ajay Divakaran</a>",
          "description": "Current pre-trained language models have lots of knowledge, but a more\nlimited ability to use that knowledge. Bloom's Taxonomy helps educators teach\nchildren how to use knowledge by categorizing comprehension skills, so we use\nit to analyze and improve the comprehension skills of large pre-trained\nlanguage models. Our experiments focus on zero-shot question answering, using\nthe taxonomy to provide proximal context that helps the model answer questions\nby being relevant to those questions. We show targeting context in this manner\nimproves performance across 4 popular common sense question answer datasets.",
          "link": "http://arxiv.org/abs/2106.04653",
          "publishedOn": "2021-06-10T01:56:44.947Z",
          "wordCount": 513,
          "title": "Comprehension Based Question Answering using Bloom's Taxonomy. (arXiv:2106.04653v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2012.15859",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Goldfarb_Tarrant_S/0/1/0/all/0/1\">Seraphina Goldfarb-Tarrant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marchant_R/0/1/0/all/0/1\">Rebecca Marchant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanchez_R/0/1/0/all/0/1\">Ricardo Mu&#xf1;oz Sanchez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pandya_M/0/1/0/all/0/1\">Mugdha Pandya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lopez_A/0/1/0/all/0/1\">Adam Lopez</a>",
          "description": "Natural Language Processing (NLP) systems learn harmful societal biases that\ncause them to amplify inequality as they are deployed in more and more\nsituations. To guide efforts at debiasing these systems, the NLP community\nrelies on a variety of metrics that quantify bias in models. Some of these\nmetrics are intrinsic, measuring bias in word embedding spaces, and some are\nextrinsic, measuring bias in downstream tasks that the word embeddings enable.\nDo these intrinsic and extrinsic metrics correlate with each other? We compare\nintrinsic and extrinsic metrics across hundreds of trained models covering\ndifferent tasks and experimental conditions. Our results show no reliable\ncorrelation between these metrics that holds in all scenarios across tasks and\nlanguages. We urge researchers working on debiasing to focus on extrinsic\nmeasures of bias, and to make using these measures more feasible via creation\nof new challenge sets and annotated test data. To aid this effort, we release\ncode, a new intrinsic metric, and an annotated test set focused on gender bias\nin hate speech.",
          "link": "http://arxiv.org/abs/2012.15859",
          "publishedOn": "2021-06-09T22:43:50.385Z",
          "wordCount": 662,
          "title": "Intrinsic Bias Metrics Do Not Correlate with Application Bias. (arXiv:2012.15859v5 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.01785",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abdul_Mageed_M/0/1/0/all/0/1\">Muhammad Abdul-Mageed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elmadany_A/0/1/0/all/0/1\">AbdelRahim Elmadany</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nagoudi_E/0/1/0/all/0/1\">El Moatez Billah Nagoudi</a>",
          "description": "Pre-trained language models (LMs) are currently integral to many natural\nlanguage processing systems. Although multilingual LMs were also introduced to\nserve many languages, these have limitations such as being costly at inference\ntime and the size and diversity of non-English data involved in their\npre-training. We remedy these issues for a collection of diverse Arabic\nvarieties by introducing two powerful deep bidirectional transformer-based\nmodels, ARBERT and MARBERT. To evaluate our models, we also introduce ARLUE, a\nnew benchmark for multi-dialectal Arabic language understanding evaluation.\nARLUE is built using 42 datasets targeting six different task clusters,\nallowing us to offer a series of standardized experiments under rich\nconditions. When fine-tuned on ARLUE, our models collectively achieve new\nstate-of-the-art results across the majority of tasks (37 out of 48\nclassification tasks, on the 42 datasets). Our best model acquires the highest\nARLUE score (77.40) across all six task clusters, outperforming all other\nmodels including XLM-R Large (~ 3.4 x larger size). Our models are publicly\navailable at https://github.com/UBC-NLP/marbert and ARLUE will be released\nthrough the same repository.",
          "link": "http://arxiv.org/abs/2101.01785",
          "publishedOn": "2021-06-09T22:43:50.339Z",
          "wordCount": 654,
          "title": "ARBERT & MARBERT: Deep Bidirectional Transformers for Arabic. (arXiv:2101.01785v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01087",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meister_C/0/1/0/all/0/1\">Clara Meister</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lazov_S/0/1/0/all/0/1\">Stefan Lazov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Augenstein_I/0/1/0/all/0/1\">Isabelle Augenstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>",
          "description": "Sparse attention has been claimed to increase model interpretability under\nthe assumption that it highlights influential inputs. Yet the attention\ndistribution is typically over representations internal to the model rather\nthan the inputs themselves, suggesting this assumption may not have merit. We\nbuild on the recent work exploring the interpretability of attention; we design\na set of experiments to help us understand how sparsity affects our ability to\nuse attention as an explainability tool. On three text classification tasks, we\nverify that only a weak relationship between inputs and co-indexed intermediate\nrepresentations exists -- under sparse attention and otherwise. Further, we do\nnot find any plausible mappings from sparse attention distributions to a sparse\nset of influential inputs through other avenues. Rather, we observe in this\nsetting that inducing sparsity may make it less plausible that attention can be\nused as a tool for understanding model behavior.",
          "link": "http://arxiv.org/abs/2106.01087",
          "publishedOn": "2021-06-09T22:43:50.188Z",
          "wordCount": 593,
          "title": "Is Sparse Attention more Interpretable?. (arXiv:2106.01087v2 [cs.CL] UPDATED)"
        }
      ]
    },
    {
      "title": "cs.IR updates on arXiv.org",
      "feedUrl": "http://export.arxiv.org/rss/cs.IR",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2101.06983",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1\">Luyu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yunyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Callan_J/0/1/0/all/0/1\">Jamie Callan</a>",
          "description": "Contrastive learning has been applied successfully to learn vector\nrepresentations of text. Previous research demonstrated that learning\nhigh-quality representations benefits from batch-wise contrastive loss with a\nlarge number of negatives. In practice, the technique of in-batch negative is\nused, where for each example in a batch, other batch examples' positives will\nbe taken as its negatives, avoiding encoding extra negatives. This, however,\nstill conditions each example's loss on all batch examples and requires fitting\nthe entire large batch into GPU memory. This paper introduces a gradient\ncaching technique that decouples backpropagation between contrastive loss and\nthe encoder, removing encoder backward pass data dependency along the batch\ndimension. As a result, gradients can be computed for one subset of the batch\nat a time, leading to almost constant memory usage.",
          "link": "http://arxiv.org/abs/2101.06983",
          "publishedOn": "2021-06-16T00:27:38.497Z",
          "wordCount": 593,
          "title": "Scaling Deep Contrastive Learning Batch Size under Memory Limited Setup. (arXiv:2101.06983v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03954",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pereira_G/0/1/0/all/0/1\">Geand Trindade Pereira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santos_M/0/1/0/all/0/1\">Moises Rocha dos Santos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carvalho_A/0/1/0/all/0/1\">Andre Carlos Ponce de Leon Ferreira de Carvalho</a>",
          "description": "With the popularity of Machine Learning (ML) solutions, algorithms and data\nhave been released faster than the capacity of processing them. In this\ncontext, the problem of Algorithm Recommendation (AR) is receiving a\nsignificant deal of attention recently. This problem has been addressed in the\nliterature as a learning task, often as a Meta-Learning problem where the aim\nis to recommend the best alternative for a specific dataset. For such, datasets\nencoded by meta-features are explored by ML algorithms that try to learn the\nmapping between meta-representations and the best technique to be used. One of\nthe challenges for the successful use of ML is to define which features are the\nmost valuable for a specific dataset since several meta-features can be used,\nwhich increases the meta-feature dimension. This paper presents an empirical\nanalysis of Feature Selection and Feature Extraction in the meta-level for the\nAR problem. The present study was focused on three criteria: predictive\nperformance, dimensionality reduction, and pipeline runtime. As we verified,\napplying Dimensionality Reduction (DR) methods did not improve predictive\nperformances in general. However, DR solutions reduced about 80% of the\nmeta-features, obtaining pretty much the same performance as the original setup\nbut with lower runtimes. The only exception was PCA, which presented about the\nsame runtime as the original meta-features. Experimental results also showed\nthat various datasets have many non-informative meta-features and that it is\npossible to obtain high predictive performance using around 20% of the original\nmeta-features. Therefore, due to their natural trend for high dimensionality,\nDR methods should be used for Meta-Feature Selection and Meta-Feature\nExtraction.",
          "link": "http://arxiv.org/abs/2106.03954",
          "publishedOn": "2021-06-15T22:41:24.942Z",
          "wordCount": 718,
          "title": "Evaluating Meta-Feature Selection for the Algorithm Recommendation Problem. (arXiv:2106.03954v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14188",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_L/0/1/0/all/0/1\">Liyi Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_J/0/1/0/all/0/1\">Junqi Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Haoqi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zhenzhe Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhiye Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_Z/0/1/0/all/0/1\">Zhizhuang Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_F/0/1/0/all/0/1\">Fei Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_L/0/1/0/all/0/1\">Lvyin Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haiyang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1\">Chuan Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yuning Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaoqiang Zhu</a>",
          "description": "Advertising expenditures have become the major source of revenue for\ne-commerce platforms. Providing good advertising experiences for advertisers by\nreducing their costs of trial and error in discovering the optimal advertising\nstrategies is crucial for the long-term prosperity of online advertising. To\nachieve this goal, the advertising platform needs to identify the advertiser's\noptimization objectives, and then recommend the corresponding strategies to\nfulfill the objectives. In this work, we first deploy a prototype of strategy\nrecommender system on Taobao display advertising platform, which indeed\nincreases the advertisers' performance and the platform's revenue, indicating\nthe effectiveness of strategy recommendation for online advertising. We further\naugment this prototype system by explicitly learning the advertisers'\npreferences over various advertising performance indicators and then\noptimization objectives through their adoptions of different recommending\nadvertising strategies. We use contextual bandit algorithms to efficiently\nlearn the advertisers' preferences and maximize the recommendation adoption,\nsimultaneously. Simulation experiments based on Taobao online bidding data show\nthat the designed algorithms can effectively optimize the strategy adoption\nrate of advertisers.",
          "link": "http://arxiv.org/abs/2105.14188",
          "publishedOn": "2021-06-15T22:41:24.921Z",
          "wordCount": 675,
          "title": "We Know What You Want: An Advertising Strategy Recommender System for Online Advertising. (arXiv:2105.14188v3 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03569",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Junliang Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1\">Hongzhi Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_M/0/1/0/all/0/1\">Min Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_X/0/1/0/all/0/1\">Xin Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiangliang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hung_N/0/1/0/all/0/1\">Nguyen Quoc Viet Hung</a>",
          "description": "Self-supervised learning (SSL), which can automatically generate ground-truth\nsamples from raw data, holds vast potential to improve recommender systems.\nMost existing SSL-based methods perturb the raw data graph with uniform\nnode/edge dropout to generate new data views and then conduct the\nself-discrimination based contrastive learning over different views to learn\ngeneralizable representations. Under this scheme, only a bijective mapping is\nbuilt between nodes in two different views, which means that the\nself-supervision signals from other nodes are being neglected. Due to the\nwidely observed homophily in recommender systems, we argue that the supervisory\nsignals from other nodes are also highly likely to benefit the representation\nlearning for recommendation. To capture these signals, a general socially-aware\nSSL framework that integrates tri-training is proposed in this paper.\nTechnically, our framework first augments the user data views with the user\nsocial information. And then under the regime of tri-training for multi-view\nencoding, the framework builds three graph encoders (one for recommendation)\nupon the augmented views and iteratively improves each encoder with\nself-supervision signals from other users, generated by the other two encoders.\nSince the tri-training operates on the augmented views of the same data sources\nfor self-supervision signals, we name it self-supervised tri-training.\nExtensive experiments on multiple real-world datasets consistently validate the\neffectiveness of the self-supervised tri-training framework for improving\nrecommendation. The code is released at https://github.com/Coder-Yu/QRec.",
          "link": "http://arxiv.org/abs/2106.03569",
          "publishedOn": "2021-06-15T01:45:13.457Z",
          "wordCount": 672,
          "title": "Socially-Aware Self-Supervised Tri-Training for Recommendation. (arXiv:2106.03569v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06900",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zefang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_S/0/1/0/all/0/1\">Shuran Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quan_Y/0/1/0/all/0/1\">Yinzhu Quan</a>",
          "description": "Group recommender systems are widely used in current web applications. In\nthis paper, we propose a novel group recommender system based on the deep\nreinforcement learning. We introduce the MovieLens data at first and generate\none random group dataset, MovieLens-Rand, from it. This randomly generated\ndataset is described and analyzed. We also present experimental settings and\ntwo state-of-art baselines, AGREE and GroupIM. The framework of our novel\nmodel, the Deep Reinforcement learning based Group Recommender system (DRGR),\nis proposed. Actor-critic networks are implemented with the deep deterministic\npolicy gradient algorithm. The DRGR model is applied on the MovieLens-Rand\ndataset with two baselines. Compared with baselines, we conclude that DRGR\nperforms better than GroupIM due to long interaction histories but worse than\nAGREE because of the self-attention mechanism. We express advantages and\nshortcomings of DRGR and also give future improvement directions at the end.",
          "link": "http://arxiv.org/abs/2106.06900",
          "publishedOn": "2021-06-15T01:45:13.386Z",
          "wordCount": 563,
          "title": "Deep Reinforcement Learning based Group Recommender System. (arXiv:2106.06900v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06910",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_A/0/1/0/all/0/1\">Arunava Kumar Chakraborty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1\">Sourav Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolya_A/0/1/0/all/0/1\">Anup Kumar Kolya</a>",
          "description": "As the Covid-19 outbreaks rapidly all over the world day by day and also\naffects the lives of million, a number of countries declared complete lock-down\nto check its intensity. During this lockdown period, social media plat-forms\nhave played an important role to spread information about this pandemic across\nthe world, as people used to express their feelings through the social\nnetworks. Considering this catastrophic situation, we developed an experimental\napproach to analyze the reactions of people on Twitter taking into ac-count the\npopular words either directly or indirectly based on this pandemic. This paper\nrepresents the sentiment analysis on collected large number of tweets on\nCoronavirus or Covid-19. At first, we analyze the trend of public sentiment on\nthe topics related to Covid-19 epidemic using an evolutionary classification\nfollowed by the n-gram analysis. Then we calculated the sentiment ratings on\ncollected tweet based on their class. Finally, we trained the long-short term\nnetwork using two types of rated tweets to predict sentiment on Covid-19 data\nand obtained an overall accuracy of 84.46%.",
          "link": "http://arxiv.org/abs/2106.06910",
          "publishedOn": "2021-06-15T01:45:13.169Z",
          "wordCount": 680,
          "title": "Sentiment Analysis of Covid-19 Tweets using Evolutionary Classification-Based LSTM Model. (arXiv:2106.06910v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2010.09029",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chen Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xinyi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zafarani_R/0/1/0/all/0/1\">Reza Zafarani</a>",
          "description": "COVID-19 has impacted all lives. To maintain social distancing and avoiding\nexposure, works and lives have gradually moved online. Under this trend, social\nmedia usage to obtain COVID-19 news has increased. Also, misinformation on\nCOVID-19 is frequently spread on social media. In this work, we develop\nCHECKED, the first Chinese dataset on COVID-19 misinformation. CHECKED provides\na total 2,104 verified microblogs related to COVID-19 from December 2019 to\nAugust 2020, identified by using a specific list of keywords. Correspondingly,\nCHECKED includes 1,868,175 reposts, 1,185,702 comments, and 56,852,736 likes\nthat reveal how these verified microblogs are spread and reacted on Weibo. The\ndataset contains a rich set of multimedia information for each microblog\nincluding ground-truth label, textual, visual, temporal, and network\ninformation. Extensive experiments have been conducted to analyze CHECKED data\nand to provide benchmark results for well-established methods when predicting\nfake news using CHECKED. We hope that CHECKED can facilitate studies that\ntarget misinformation on coronavirus. The dataset is available at\nhttps://github.com/cyang03/CHECKED.",
          "link": "http://arxiv.org/abs/2010.09029",
          "publishedOn": "2021-06-15T01:45:13.134Z",
          "wordCount": 671,
          "title": "CHECKED: Chinese COVID-19 Fake News Dataset. (arXiv:2010.09029v2 [cs.SI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06739",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Siddharth_L/0/1/0/all/0/1\">L Siddharth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blessing_L/0/1/0/all/0/1\">Lucienne T.M. Blessing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wood_K/0/1/0/all/0/1\">Kristin L. Wood</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1\">Jianxi Luo</a>",
          "description": "We propose a large, scalable engineering knowledge graph, comprising sets of\n(entity, relationship, entity) triples that are real-world engineering facts\nfound in the patent database. We apply a set of rules based on the syntactic\nand lexical properties of claims in a patent document to extract facts. We\naggregate these facts within each patent document and integrate the aggregated\nsets of facts across the patent database to obtain the engineering knowledge\ngraph. Such a knowledge graph is expected to support inference, reasoning, and\nrecalling in various engineering tasks. The knowledge graph has a greater size\nand coverage in comparison with the previously used knowledge graphs and\nsemantic networks in the engineering literature.",
          "link": "http://arxiv.org/abs/2106.06739",
          "publishedOn": "2021-06-15T01:45:13.110Z",
          "wordCount": 544,
          "title": "Engineering Knowledge Graph from Patent Database. (arXiv:2106.06739v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06722",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1\">Kun Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wayne Xin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jingyuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Ji-Rong Wen</a>",
          "description": "Due to the flexibility in modelling data heterogeneity, heterogeneous\ninformation network (HIN) has been adopted to characterize complex and\nheterogeneous auxiliary data in top-$N$ recommender systems, called\n\\emph{HIN-based recommendation}. HIN characterizes complex, heterogeneous data\nrelations, containing a variety of information that may not be related to the\nrecommendation task. Therefore, it is challenging to effectively leverage\nuseful information from HINs for improving the recommendation performance. To\naddress the above issue, we propose a Curriculum pre-training based\nHEterogeneous Subgraph Transformer (called \\emph{CHEST}) with new \\emph{data\ncharacterization}, \\emph{representation model} and \\emph{learning algorithm}.\n\nSpecifically, we consider extracting useful information from HIN to compose\nthe interaction-specific heterogeneous subgraph, containing both sufficient and\nrelevant context information for recommendation. Then we capture the rich\nsemantics (\\eg graph structure and path semantics) within the subgraph via a\nheterogeneous subgraph Transformer, where we encode the subgraph with\nmulti-slot sequence representations. Besides, we design a curriculum\npre-training strategy to provide an elementary-to-advanced learning process, by\nwhich we smoothly transfer basic semantics in HIN for modeling user-item\ninteraction relation.\n\nExtensive experiments conducted on three real-world datasets demonstrate the\nsuperiority of our proposed method over a number of competitive baselines,\nespecially when only limited training data is available.",
          "link": "http://arxiv.org/abs/2106.06722",
          "publishedOn": "2021-06-15T01:45:12.267Z",
          "wordCount": 627,
          "title": "Curriculum Pre-Training Heterogeneous Subgraph Transformer for Top-$N$ Recommendation. (arXiv:2106.06722v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06713",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xiangyu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Haochen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_W/0/1/0/all/0/1\">Wenqi Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jiliang Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chong Wang</a>",
          "description": "Designing an effective loss function plays a crucial role in training deep\nrecommender systems. Most existing works often leverage a predefined and fixed\nloss function that could lead to suboptimal recommendation quality and training\nefficiency. Some recent efforts rely on exhaustively or manually searched\nweights to fuse a group of candidate loss functions, which is exceptionally\ncostly in computation and time. They also neglect the various convergence\nbehaviors of different data examples. In this work, we propose an AutoLoss\nframework that can automatically and adaptively search for the appropriate loss\nfunction from a set of candidates. To be specific, we develop a novel\ncontroller network, which can dynamically adjust the loss probabilities in a\ndifferentiable manner. Unlike existing algorithms, the proposed controller can\nadaptively generate the loss probabilities for different data examples\naccording to their varied convergence behaviors. Such design improves the\nmodel's generalizability and transferability between deep recommender systems\nand datasets. We evaluate the proposed framework on two benchmark datasets. The\nresults show that AutoLoss outperforms representative baselines. Further\nexperiments have been conducted to deepen our understandings of AutoLoss,\nincluding its transferability, components and training efficiency.",
          "link": "http://arxiv.org/abs/2106.06713",
          "publishedOn": "2021-06-15T01:45:12.220Z",
          "wordCount": 634,
          "title": "AutoLoss: Automated Loss Function Search in Recommendations. (arXiv:2106.06713v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2104.08976",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mackenzie_J/0/1/0/all/0/1\">Joel Mackenzie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petri_M/0/1/0/all/0/1\">Matthias Petri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moffat_A/0/1/0/all/0/1\">Alistair Moffat</a>",
          "description": "Inverted indexes continue to be a mainstay of text search engines, allowing\nefficient querying of large document collections. While there are a number of\npossible organizations, document-ordered indexes are the most common, since\nthey are amenable to various query types, support index updates, and allow for\nefficient dynamic pruning operations. One disadvantage with document-ordered\nindexes is that high-scoring documents can be distributed across the document\nidentifier space, meaning that index traversal algorithms that terminate early\nmight put search effectiveness at risk. The alternative is impact-ordered\nindexes, which primarily support top-k disjunctions, but also allow for anytime\nquery processing, where the search can be terminated at any time, with search\nquality improving as processing latency increases. Anytime query processing can\nbe used to effectively reduce high-percentile tail latency which is essential\nfor operational scenarios in which a service level agreement (SLA) imposes\nresponse time requirements. In this work, we show how document-ordered indexes\ncan be organized such that they can be queried in an anytime fashion, enabling\nstrict latency control with effective early termination. Our experiments show\nthat processing document-ordered topical segments selected by a simple score\nestimator outperforms existing anytime algorithms, and allows query runtimes to\nbe accurately limited in order to comply with SLA requirements.",
          "link": "http://arxiv.org/abs/2104.08976",
          "publishedOn": "2021-06-14T01:38:51.546Z",
          "wordCount": 659,
          "title": "Anytime Ranking on Document-Ordered Indexes. (arXiv:2104.08976v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06244",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Otto_C/0/1/0/all/0/1\">Christian Otto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_R/0/1/0/all/0/1\">Ran Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pardi_G/0/1/0/all/0/1\">Georg Pardi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoyer_J/0/1/0/all/0/1\">Johannes von Hoyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rokicki_M/0/1/0/all/0/1\">Markus Rokicki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoppe_A/0/1/0/all/0/1\">Anett Hoppe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holtz_P/0/1/0/all/0/1\">Peter Holtz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kammerer_Y/0/1/0/all/0/1\">Yvonne Kammerer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dietze_S/0/1/0/all/0/1\">Stefan Dietze</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ewerth_R/0/1/0/all/0/1\">Ralph Ewerth</a>",
          "description": "In informal learning scenarios the popularity of multimedia content, such as\nvideo tutorials or lectures, has significantly increased. Yet, the users'\ninteractions, navigation behavior, and consequently learning outcome, have not\nbeen researched extensively. Related work in this field, also called search as\nlearning, has focused on behavioral or text resource features to predict\nlearning outcome and knowledge gain. In this paper, we investigate whether we\ncan exploit features representing multimedia resource consumption to predict of\nknowledge gain (KG) during Web search from in-session data, that is without\nprior knowledge about the learner. For this purpose, we suggest a set of\nmultimedia features related to image and video consumption. Our feature\nextraction is evaluated in a lab study with 113 participants where we collected\ndata for a given search as learning task on the formation of thunderstorms and\nlightning. We automatically analyze the monitored log data and utilize\nstate-of-the-art computer vision methods to extract features about the seen\nmultimedia resources. Experimental results demonstrate that multimedia features\ncan improve KG prediction. Finally, we provide an analysis on feature\nimportance (text and multimedia) for KG prediction.",
          "link": "http://arxiv.org/abs/2106.06244",
          "publishedOn": "2021-06-14T01:38:51.500Z",
          "wordCount": 633,
          "title": "Predicting Knowledge Gain during Web Search based on Multimedia Resource Consumption. (arXiv:2106.06244v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06471",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xingyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_M/0/1/0/all/0/1\">Muchao Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_Q/0/1/0/all/0/1\">Quanzeng You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_F/0/1/0/all/0/1\">Fenglong Ma</a>",
          "description": "Medical report generation is one of the most challenging tasks in medical\nimage analysis. Although existing approaches have achieved promising results,\nthey either require a predefined template database in order to retrieve\nsentences or ignore the hierarchical nature of medical report generation. To\naddress these issues, we propose MedWriter that incorporates a novel\nhierarchical retrieval mechanism to automatically extract both report and\nsentence-level templates for clinically accurate report generation. MedWriter\nfirst employs the Visual-Language Retrieval~(VLR) module to retrieve the most\nrelevant reports for the given images. To guarantee the logical coherence\nbetween sentences, the Language-Language Retrieval~(LLR) module is introduced\nto retrieve relevant sentences based on the previous generated description. At\nlast, a language decoder fuses image features and features from retrieved\nreports and sentences to generate meaningful medical reports. We verified the\neffectiveness of our model by automatic evaluation and human evaluation on two\ndatasets, i.e., Open-I and MIMIC-CXR.",
          "link": "http://arxiv.org/abs/2106.06471",
          "publishedOn": "2021-06-14T01:38:51.477Z",
          "wordCount": 592,
          "title": "Writing by Memorizing: Hierarchical Retrieval-based Medical Report Generation. (arXiv:2106.06471v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06467",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hao_B/0/1/0/all/0/1\">Bin Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Min Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1\">Weizhi Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1\">Shaoyun Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1\">Xinxing Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shan_H/0/1/0/all/0/1\">Houzhi Shan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yiqun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1\">Shaoping Ma</a>",
          "description": "Data plays a vital role in machine learning studies. In the research of\nrecommendation, both user behaviors and side information are helpful to model\nusers. So, large-scale real scenario datasets with abundant user behaviors will\ncontribute a lot. However, it is not easy to get such datasets as most of them\nare only hold and protected by companies. In this paper, a new large-scale\ndataset collected from a knowledge-sharing platform is presented, which is\ncomposed of around 100M interactions collected within 10 days, 798K users, 165K\nquestions, 554K answers, 240K authors, 70K topics, and more than 501K user\nquery keywords. There are also descriptions of users, answers, questions,\nauthors, and topics, which are anonymous. Note that each user's latest query\nkeywords have not been included in previous open datasets, which reveal users'\nexplicit information needs.\n\nWe characterize the dataset and demonstrate its potential applications for\nrecommendation study. Multiple experiments show the dataset can be used to\nevaluate algorithms in general top-N recommendation, sequential recommendation,\nand context-aware recommendation. This dataset can also be used to integrate\nsearch and recommendation and recommendation with negative feedback. Besides,\ntasks beyond recommendation, such as user gender prediction, most valuable\nanswerer identification, and high-quality answer recognition, can also use this\ndataset. To the best of our knowledge, this is the largest real-world\ninteraction dataset for personalized recommendation.",
          "link": "http://arxiv.org/abs/2106.06467",
          "publishedOn": "2021-06-14T01:38:51.319Z",
          "wordCount": 662,
          "title": "A Large-Scale Rich Context Query and Recommendation Dataset in Online Knowledge-Sharing. (arXiv:2106.06467v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06420",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Al_Kaabi_K/0/1/0/all/0/1\">Karrar Al-Kaabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monsefi_R/0/1/0/all/0/1\">Reza Monsefi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zabihzadeh_D/0/1/0/all/0/1\">Davood Zabihzadeh</a>",
          "description": "Metric learning algorithms aim to learn a distance function that brings the\nsemantically similar data items together and keeps dissimilar ones at a\ndistance. The traditional Mahalanobis distance learning is equivalent to find a\nlinear projection. In contrast, Deep Metric Learning (DML) methods are proposed\nthat automatically extract features from data and learn a non-linear\ntransformation from input space to a semantically embedding space. Recently,\nmany DML methods are proposed focused to enhance the discrimination power of\nthe learned metric by providing novel sampling strategies or loss functions.\nThis approach is very helpful when both the training and test examples are\ncoming from the same set of categories. However, it is less effective in many\napplications of DML such as image retrieval and person-reidentification. Here,\nthe DML should learn general semantic concepts from observed classes and employ\nthem to rank or identify objects from unseen categories. Neglecting the\ngeneralization ability of the learned representation and just emphasizing to\nlearn a more discriminative embedding on the observed classes may lead to the\noverfitting problem. To address this limitation, we propose a framework to\nenhance the generalization power of existing DML methods in a Zero-Shot\nLearning (ZSL) setting by general yet discriminative representation learning\nand employing a class adversarial neural network. To learn a more general\nrepresentation, we propose to employ feature maps of intermediate layers in a\ndeep neural network and enhance their discrimination power through an attention\nmechanism. Besides, a class adversarial network is utilized to enforce the deep\nmodel to seek class invariant features for the DML task. We evaluate our work\non widely used machine vision datasets in a ZSL setting.",
          "link": "http://arxiv.org/abs/2106.06420",
          "publishedOn": "2021-06-14T01:38:51.279Z",
          "wordCount": 744,
          "title": "A Framework to Enhance Generalization of Deep Metric Learning methods using General Discriminative Feature Learning and Class Adversarial Neural Networks. (arXiv:2106.06420v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06165",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1\">Ziwei Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiwei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1\">Lei Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Philip S. Yu</a>",
          "description": "The sequential patterns within the user interactions are pivotal for\nrepresenting the user's preference and capturing latent relationships among\nitems. The recent advancements of sequence modeling by Transformers advocate\nthe community to devise more effective encoders for the sequential\nrecommendation. Most existing sequential methods assume users are\ndeterministic. However, item-item transitions might fluctuate significantly in\nseveral item aspects and exhibit randomness of user interests. This\n\\textit{stochastic characteristics} brings up a solid demand to include\nuncertainties in representing sequences and items. Additionally, modeling\nsequences and items with uncertainties expands users' and items' interaction\nspaces, thus further alleviating cold-start problems.\n\nIn this work, we propose a Distribution-based Transformer for Sequential\nRecommendation (DT4SR), which injects uncertainties into sequential modeling.\nWe use Elliptical Gaussian distributions to describe items and sequences with\nuncertainty. We describe the uncertainty in items and sequences as Elliptical\nGaussian distribution. And we adopt Wasserstein distance to measure the\nsimilarity between distributions. We devise two novel Trans-formers for\nmodeling mean and covariance, which guarantees the positive-definite property\nof distributions. The proposed method significantly outperforms the\nstate-of-the-art methods. The experiments on three benchmark datasets also\ndemonstrate its effectiveness in alleviating cold-start issues. The code is\navailable inhttps://github.com/DyGRec/DT4SR.",
          "link": "http://arxiv.org/abs/2106.06165",
          "publishedOn": "2021-06-14T01:38:51.217Z",
          "wordCount": 631,
          "title": "Modeling Sequences as Distributions with Uncertainty for Sequential Recommendation. (arXiv:2106.06165v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06216",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Waldis_A/0/1/0/all/0/1\">Andreas Waldis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mazzola_L/0/1/0/all/0/1\">Luca Mazzola</a>",
          "description": "Entity Recognition (ER) within a text is a fundamental exercise in Natural\nLanguage Processing, enabling further depending tasks such as Knowledge\nExtraction, Text Summarisation, or Keyphrase Extraction. An entity consists of\nsingle words or of a consecutive sequence of terms, constituting the basic\nbuilding blocks for communication. Mainstream ER approaches are mainly limited\nto flat structures, concentrating on the outermost entities while ignoring the\ninner ones. This paper introduces a partly-layered network architecture that\ndeals with the complexity of overlapping and nested cases. The proposed\narchitecture consists of two parts: (1) a shared Sequence Layer and (2) a\nstacked component with multiple Tagging Layers. The adoption of such an\narchitecture has the advantage of preventing overfit to a specific word-length,\nthus maintaining performance for longer entities despite their lower frequency.\nTo verify the proposed architecture's effectiveness, we train and evaluate this\narchitecture to recognise two kinds of entities - Concepts (CR) and Named\nEntities (NER). Our approach achieves state-of-the-art NER performances, while\nit outperforms previous CR approaches. Considering these promising results, we\nsee the possibility to evolve the architecture for other cases such as the\nextraction of events or the detection of argumentative components.",
          "link": "http://arxiv.org/abs/2106.06216",
          "publishedOn": "2021-06-14T01:38:51.205Z",
          "wordCount": 635,
          "title": "Nested and Balanced Entity Recognition using Multi-Task Learning. (arXiv:2106.06216v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06258",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chuhan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fangzhao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yongfeng Huang</a>",
          "description": "News recommendation is important for improving news reading experience of\nusers. Users' news click behaviors are widely used for inferring user interests\nand predicting future clicks. However, click behaviors are heavily affected by\nthe biases brought by the positions of news displayed on the webpage. It is\nimportant to eliminate the effect of position biases on the recommendation\nmodel to accurately target user interests. In this paper, we propose a news\nrecommendation method named DebiasGAN that can effectively eliminate the effect\nof position biases via adversarial learning. We use a bias-aware click model to\ncapture the influence of position bias on click behaviors, and we use a\nbias-invariant click model with random candidate news positions to estimate the\nideally unbiased click scores. We apply adversarial learning techniques to the\nhidden representations learned by the two models to help the bias-invariant\nclick model capture the bias-independent interest of users on news.\nExperimental results on two real-world datasets show that DebiasGAN can\neffectively improve the accuracy of news recommendation by eliminating position\nbiases.",
          "link": "http://arxiv.org/abs/2106.06258",
          "publishedOn": "2021-06-14T01:38:51.192Z",
          "wordCount": 596,
          "title": "DebiasGAN: Eliminating Position Bias in News Recommendation with Adversarial Learning. (arXiv:2106.06258v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06022",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bauer_M/0/1/0/all/0/1\">Martin Bauer</a>",
          "description": "For IoT to reach its full potential, the sharing and reuse of information in\ndifferent applications and across verticals is of paramount importance.\nHowever, there are a plethora of IoT platforms using different representations,\nprotocols and interaction patterns. To address this issue, the Fed4IoT project\nhas developed an IoT virtualization platform that, on the one hand, integrates\ninformation from many different source platforms and, on the other hand, makes\nthe information required by the respective users available in the target\nplatform of choice. To enable this, information is translated into a common,\nneutral exchange format. The format of choice is NGSI-LD, which is being\nstandardized by the ETSI Industry Specification Group on Context Information\nManagement (ETSI ISG CIM). Thing Visors are the components that translate the\nsource information to NGSI-LD, which is then delivered to the target platform\nand translated into the target format. ThingVisors can be implemented by hand,\nbut this requires significant human effort, especially considering the\nheterogeneity of low level information produced by a multitude of sensors.\nThus, supporting the human developer and, ideally, fully automating the process\nof extracting and enriching data and translating it to NGSI-LD is a crucial\nstep. Machine learning is a promising approach for this, but it typically\nrequires large amounts of hand-labelled data for training, an effort that makes\nit unrealistic in many IoT scenarios. A programmatic labelling approach called\nknowledge infusion that encodes expert knowledge is used for matching a schema\nor ontology extracted from the data with a target schema or ontology, providing\nthe basis for annotating the data and facilitating the translation to NGSI-LD.",
          "link": "http://arxiv.org/abs/2106.06022",
          "publishedOn": "2021-06-14T01:38:50.756Z",
          "wordCount": 690,
          "title": "IoT Virtualization with ML-based Information Extraction. (arXiv:2106.06022v1 [cs.DC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01300",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qi_T/0/1/0/all/0/1\">Tao Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fangzhao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chuhan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yongfeng Huang</a>",
          "description": "Personalized news recommendation methods are widely used in online news\nservices. These methods usually recommend news based on the matching between\nnews content and user interest inferred from historical behaviors. However,\nthese methods usually have difficulties in making accurate recommendations to\ncold-start users, and tend to recommend similar news with those users have\nread. In general, popular news usually contain important information and can\nattract users with different interests. Besides, they are usually diverse in\ncontent and topic. Thus, in this paper we propose to incorporate news\npopularity information to alleviate the cold-start and diversity problems for\npersonalized news recommendation. In our method, the ranking score for\nrecommending a candidate news to a target user is the combination of a\npersonalized matching score and a news popularity score. The former is used to\ncapture the personalized user interest in news. The latter is used to measure\ntime-aware popularity of candidate news, which is predicted based on news\ncontent, recency, and real-time CTR using a unified framework. Besides, we\npropose a popularity-aware user encoder to eliminate the popularity bias in\nuser behaviors for accurate interest modeling. Experiments on two real-world\ndatasets show our method can effectively improve the accuracy and diversity for\nnews recommendation.",
          "link": "http://arxiv.org/abs/2106.01300",
          "publishedOn": "2021-06-11T01:42:15.104Z",
          "wordCount": 653,
          "title": "PP-Rec: News Recommendation with Personalized User Interest and Time-aware News Popularity. (arXiv:2106.01300v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05482",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jianqiang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_K/0/1/0/all/0/1\">Ke Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_Q/0/1/0/all/0/1\">Qingtao Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Mingjian Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_Y/0/1/0/all/0/1\">Yi Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1\">Jia Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_J/0/1/0/all/0/1\">Jun Lei</a>",
          "description": "Click-through rate (CTR) prediction plays an important role in online\nadvertising and recommender systems. In practice, the training of CTR models\ndepends on click data which is intrinsically biased towards higher positions\nsince higher position has higher CTR by nature. Existing methods such as actual\nposition training with fixed position inference and inverse propensity weighted\ntraining with no position inference alleviate the bias problem to some extend.\nHowever, the different treatment of position information between training and\ninference will inevitably lead to inconsistency and sub-optimal online\nperformance. Meanwhile, the basic assumption of these methods, i.e., the click\nprobability is the product of examination probability and relevance\nprobability, is oversimplified and insufficient to model the rich interaction\nbetween position and other information. In this paper, we propose a Deep\nPosition-wise Interaction Network (DPIN) to efficiently combine all candidate\nitems and positions for estimating CTR at each position, achieving consistency\nbetween offline and online as well as modeling the deep non-linear interaction\namong position, user, context and item under the limit of serving performance.\nFollowing our new treatment to the position bias in CTR prediction, we propose\na new evaluation metrics named PAUC (position-wise AUC) that is suitable for\nmeasuring the ranking quality at a given position. Through extensive\nexperiments on a real world dataset, we show empirically that our method is\nboth effective and efficient in solving position bias problem. We have also\ndeployed our method in production and observed statistically significant\nimprovement over a highly optimized baseline in a rigorous A/B test.",
          "link": "http://arxiv.org/abs/2106.05482",
          "publishedOn": "2021-06-11T01:42:13.961Z",
          "wordCount": 687,
          "title": "Deep Position-wise Interaction Network for CTR Prediction. (arXiv:2106.05482v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2008.09093",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Canjia Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yates_A/0/1/0/all/0/1\">Andrew Yates</a>, <a href=\"http://arxiv.org/find/cs/1/au:+MacAvaney_S/0/1/0/all/0/1\">Sean MacAvaney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_B/0/1/0/all/0/1\">Ben He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yingfei Sun</a>",
          "description": "Pretrained transformer models, such as BERT and T5, have shown to be highly\neffective at ad-hoc passage and document ranking. Due to inherent sequence\nlength limits of these models, they need to be run over a document's passages,\nrather than processing the entire document sequence at once. Although several\napproaches for aggregating passage-level signals have been proposed, there has\nyet to be an extensive comparison of these techniques. In this work, we explore\nstrategies for aggregating relevance signals from a document's passages into a\nfinal ranking score. We find that passage representation aggregation techniques\ncan significantly improve over techniques proposed in prior work, such as\ntaking the maximum passage score. We call this new approach PARADE. In\nparticular, PARADE can significantly improve results on collections with broad\ninformation needs where relevance signals can be spread throughout the document\n(such as TREC Robust04 and GOV2). Meanwhile, less complex aggregation\ntechniques may work better on collections with an information need that can\noften be pinpointed to a single passage (such as TREC DL and TREC Genomics). We\nalso conduct efficiency analyses, and highlight several strategies for\nimproving transformer-based aggregation.",
          "link": "http://arxiv.org/abs/2008.09093",
          "publishedOn": "2021-06-11T01:42:13.629Z",
          "wordCount": 641,
          "title": "PARADE: Passage Representation Aggregation for Document Reranking. (arXiv:2008.09093v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.03654",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yichen Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yanqiao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1\">Feng Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qiang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shu Wu</a>",
          "description": "Click-through rate (CTR) prediction, whose aim is to predict the probability\nof whether a user will click on an item, is an essential task for many online\napplications. Due to the nature of data sparsity and high dimensionality in CTR\nprediction, a key to making effective prediction is to model high-order feature\ninteraction among feature fields. To explicitly model high-order feature\ninteraction, an efficient way is to perform inner product of feature embeddings\nwith self-attentive neural networks. To better model complex feature\ninteraction, in this paper we propose a novel DisentanglEd Self-atTentIve\nNEtwork (DESTINE) framework for CTR prediction that explicitly decouples the\ncomputation of unary importance from pairwise interaction. Specifically, the\nunary term models the general impact of one feature on all other features,\nwhereas the whitened pairwise interaction term contributes to learning the pure\nimportance score for each feature interaction. We conduct extensive experiments\nframework using two real-world benchmark datasets. The results show that\nDESTINE not only maintains computational efficiency but obtains performance\nimprovements over state-of-the-art baselines.",
          "link": "http://arxiv.org/abs/2101.03654",
          "publishedOn": "2021-06-11T01:42:13.345Z",
          "wordCount": 630,
          "title": "Disentangled Self-Attentive Neural Networks for Click-Through Rate Prediction. (arXiv:2101.03654v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05768",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Althammer_S/0/1/0/all/0/1\">Sophia Althammer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buckley_M/0/1/0/all/0/1\">Mark Buckley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hofstatter_S/0/1/0/all/0/1\">Sebastian Hofst&#xe4;tter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hanbury_A/0/1/0/all/0/1\">Allan Hanbury</a>",
          "description": "Domain-specific contextualized language models have demonstrated substantial\neffectiveness gains for domain-specific downstream tasks, like similarity\nmatching, entity recognition or information retrieval. However successfully\napplying such models in highly specific language domains requires domain\nadaptation of the pre-trained models. In this paper we propose the empirically\nmotivated Linguistically Informed Masking (LIM) method to focus\ndomain-adaptative pre-training on the linguistic patterns of patents, which use\na highly technical sublanguage. We quantify the relevant differences between\npatent, scientific and general-purpose language and demonstrate for two\ndifferent language models (BERT and SciBERT) that domain adaptation with LIM\nleads to systematically improved representations by evaluating the performance\nof the domain-adapted representations of patent language on two independent\ndownstream tasks, the IPC classification and similarity matching. We\ndemonstrate the impact of balancing the learning from different information\nsources during domain adaptation for the patent domain. We make the source code\nas well as the domain-adaptive pre-trained patent language models publicly\navailable at https://github.com/sophiaalthammer/patent-lim.",
          "link": "http://arxiv.org/abs/2106.05768",
          "publishedOn": "2021-06-11T01:42:13.250Z",
          "wordCount": 599,
          "title": "Linguistically Informed Masking for Representation Learning in the Patent Domain. (arXiv:2106.05768v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05729",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hermanns_J/0/1/0/all/0/1\">Judith Hermanns</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsitsulin_A/0/1/0/all/0/1\">Anton Tsitsulin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Munkhoeva_M/0/1/0/all/0/1\">Marina Munkhoeva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bronstein_A/0/1/0/all/0/1\">Alex Bronstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mottin_D/0/1/0/all/0/1\">Davide Mottin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karras_P/0/1/0/all/0/1\">Panagiotis Karras</a>",
          "description": "What is the best way to match the nodes of two graphs? This graph alignment\nproblem generalizes graph isomorphism and arises in applications from social\nnetwork analysis to bioinformatics. Some solutions assume that auxiliary\ninformation on known matches or node or edge attributes is available, or\nutilize arbitrary graph features. Such methods fare poorly in the pure form of\nthe problem, in which only graph structures are given. Other proposals\ntranslate the problem to one of aligning node embeddings, yet, by doing so,\nprovide only a single-scale view of the graph.In this paper, we transfer the\nshape-analysis concept of functional maps from the continuous to the discrete\ncase, and treat the graph alignment problem as a special case of the problem of\nfinding a mapping between functions on graphs. We present GRASP, a method that\nfirst establishes a correspondence between functions derived from Laplacian\nmatrix eigenvectors, which capture multiscale structural characteristics,and\nthen exploits this correspondence to align nodes. Our experimental study,\nfeaturing noise levels higher than anything used in previous studies, shows\nthat GRASP outperforms state-of-the-art methods for graph alignment across\nnoise levels and graph types.",
          "link": "http://arxiv.org/abs/2106.05729",
          "publishedOn": "2021-06-11T01:42:13.115Z",
          "wordCount": 617,
          "title": "GRASP: Graph Alignment through Spectral Signatures. (arXiv:2106.05729v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/1909.12425",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1\">Zhiwen Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1\">Grace Hui Yang</a>",
          "description": "This article presents the emerging topic of dynamic search (DS). To position\ndynamic search in a larger research landscape, the article discusses in detail\nits relationship to related research topics and disciplines. The article\nreviews approaches to modeling dynamics during information seeking, with an\nemphasis on Reinforcement Learning (RL)-enabled methods. Details are given for\nhow different approaches are used to model interactions among the human user,\nthe search system, and the environment. The paper ends with a review of\nevaluations of dynamic search systems.",
          "link": "http://arxiv.org/abs/1909.12425",
          "publishedOn": "2021-06-11T01:42:13.101Z",
          "wordCount": 539,
          "title": "Dynamic Search -- Optimizing the Game of Information Seeking. (arXiv:1909.12425v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05633",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brack_A/0/1/0/all/0/1\">Arthur Brack</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoppe_A/0/1/0/all/0/1\">Anett Hoppe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ewerth_R/0/1/0/all/0/1\">Ralph Ewerth</a>",
          "description": "Citation recommendation for research papers is a valuable task that can help\nresearchers improve the quality of their work by suggesting relevant related\nwork. Current approaches for this task rely primarily on the text of the papers\nand the citation network. In this paper, we propose to exploit an additional\nsource of information, namely research knowledge graphs (KG) that interlink\nresearch papers based on mentioned scientific concepts. Our experimental\nresults demonstrate that the combination of information from research KGs with\nexisting state-of-the-art approaches is beneficial. Experimental results are\npresented for the STM-KG (STM: Science, Technology, Medicine), which is an\nautomatically populated knowledge graph based on the scientific concepts\nextracted from papers of ten domains. The proposed approach outperforms the\nstate of the art with a mean average precision of 20.6% (+0.8) for the top-50\nretrieved results.",
          "link": "http://arxiv.org/abs/2106.05633",
          "publishedOn": "2021-06-11T01:42:13.081Z",
          "wordCount": 578,
          "title": "Citation Recommendation for Research Papers via Knowledge Graphs. (arXiv:2106.05633v1 [cs.DL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05764",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meuschke_N/0/1/0/all/0/1\">Norman Meuschke</a>",
          "description": "Identifying academic plagiarism is a pressing problem, among others, for\nresearch institutions, publishers, and funding organizations. Detection\napproaches proposed so far analyze lexical, syntactical, and semantic text\nsimilarity. These approaches find copied, moderately reworded, and literally\ntranslated text. However, reliably detecting disguised plagiarism, such as\nstrong paraphrases, sense-for-sense translations, and the reuse of non-textual\ncontent and ideas, is an open research problem.\n\nThe thesis addresses this problem by proposing plagiarism detection\napproaches that implement a different concept: analyzing non-textual content in\nacademic documents, specifically citations, images, and mathematical content.\n\nTo validate the effectiveness of the proposed detection approaches, the\nthesis presents five evaluations that use real cases of academic plagiarism and\nexploratory searches for unknown cases.\n\nThe evaluation results show that non-textual content elements contain a high\ndegree of semantic information, are language-independent, and largely immutable\nto the alterations that authors typically perform to conceal plagiarism.\nAnalyzing non-textual content complements text-based detection approaches and\nincreases the detection effectiveness, particularly for disguised forms of\nacademic plagiarism.\n\nTo demonstrate the benefit of combining non-textual and text-based detection\nmethods, the thesis describes the first plagiarism detection system that\nintegrates the analysis of citation-based, image-based, math-based, and\ntext-based document similarity. The system's user interface employs\nvisualizations that significantly reduce the effort and time users must invest\nin examining content similarity.",
          "link": "http://arxiv.org/abs/2106.05764",
          "publishedOn": "2021-06-11T01:42:13.057Z",
          "wordCount": 651,
          "title": "Analyzing Non-Textual Content Elements to Detect Academic Plagiarism. (arXiv:2106.05764v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05346",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sachan_D/0/1/0/all/0/1\">Devendra Singh Sachan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reddy_S/0/1/0/all/0/1\">Siva Reddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamilton_W/0/1/0/all/0/1\">William Hamilton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dyer_C/0/1/0/all/0/1\">Chris Dyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yogatama_D/0/1/0/all/0/1\">Dani Yogatama</a>",
          "description": "We present an end-to-end differentiable training method for\nretrieval-augmented open-domain question answering systems that combine\ninformation from multiple retrieved documents when generating answers. We model\nretrieval decisions as latent variables over sets of relevant documents. Since\nmarginalizing over sets of retrieved documents is computationally hard, we\napproximate this using an expectation-maximization algorithm. We iteratively\nestimate the value of our latent variable (the set of relevant documents for a\ngiven question) and then use this estimate to update the retriever and reader\nparameters. We hypothesize that such end-to-end training allows training\nsignals to flow to the reader and then to the retriever better than staged-wise\ntraining. This results in a retriever that is able to select more relevant\ndocuments for a question and a reader that is trained on more accurate\ndocuments to generate an answer. Experiments on three benchmark datasets\ndemonstrate that our proposed method outperforms all existing approaches of\ncomparable size by 2-3% absolute exact match points, achieving new\nstate-of-the-art results. Our results also demonstrate the feasibility of\nlearning to retrieve to improve answer generation without explicit supervision\nof retrieval decisions.",
          "link": "http://arxiv.org/abs/2106.05346",
          "publishedOn": "2021-06-11T01:42:12.824Z",
          "wordCount": 628,
          "title": "End-to-End Training of Multi-Document Reader and Retriever for Open-Domain Question Answering. (arXiv:2106.05346v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05630",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_M/0/1/0/all/0/1\">Mingliang Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1\">Xu Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ju_Z/0/1/0/all/0/1\">Zeqian Ju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1\">Tao Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tie-Yan Liu</a>",
          "description": "Symbolic music understanding, which refers to the understanding of music from\nthe symbolic data (e.g., MIDI format, but not audio), covers many music\napplications such as genre classification, emotion classification, and music\npieces matching. While good music representations are beneficial for these\napplications, the lack of training data hinders representation learning.\nInspired by the success of pre-training models in natural language processing,\nin this paper, we develop MusicBERT, a large-scale pre-trained model for music\nunderstanding. To this end, we construct a large-scale symbolic music corpus\nthat contains more than 1 million music songs. Since symbolic music contains\nmore structural (e.g., bar, position) and diverse information (e.g., tempo,\ninstrument, and pitch), simply adopting the pre-training techniques from NLP to\nsymbolic music only brings marginal gains. Therefore, we design several\nmechanisms, including OctupleMIDI encoding and bar-level masking strategy, to\nenhance pre-training with symbolic music data. Experiments demonstrate the\nadvantages of MusicBERT on four music understanding tasks, including melody\ncompletion, accompaniment suggestion, genre classification, and style\nclassification. Ablation studies also verify the effectiveness of our designs\nof OctupleMIDI encoding and bar-level masking strategy in MusicBERT.",
          "link": "http://arxiv.org/abs/2106.05630",
          "publishedOn": "2021-06-11T01:42:12.798Z",
          "wordCount": 631,
          "title": "MusicBERT: Symbolic Music Understanding with Large-Scale Pre-Training. (arXiv:2106.05630v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2012.14210",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Reimers_N/0/1/0/all/0/1\">Nils Reimers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>",
          "description": "Information Retrieval using dense low-dimensional representations recently\nbecame popular and showed out-performance to traditional sparse-representations\nlike BM25. However, no previous work investigated how dense representations\nperform with large index sizes. We show theoretically and empirically that the\nperformance for dense representations decreases quicker than sparse\nrepresentations for increasing index sizes. In extreme cases, this can even\nlead to a tipping point where at a certain index size sparse representations\noutperform dense representations. We show that this behavior is tightly\nconnected to the number of dimensions of the representations: The lower the\ndimension, the higher the chance for false positives, i.e. returning irrelevant\ndocuments.",
          "link": "http://arxiv.org/abs/2012.14210",
          "publishedOn": "2021-06-10T01:56:45.233Z",
          "wordCount": 565,
          "title": "The Curse of Dense Low-Dimensional Information Retrieval for Large Index Sizes. (arXiv:2012.14210v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.04833",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qitian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hengrui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1\">Xiaofeng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Junchi Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zha_H/0/1/0/all/0/1\">Hongyuan Zha</a>",
          "description": "Recommendation models can effectively estimate underlying user interests and\npredict one's future behaviors by factorizing an observed user-item rating\nmatrix into products of two sets of latent factors. However, the user-specific\nembedding factors can only be learned in a transductive way, making it\ndifficult to handle new users on-the-fly. In this paper, we propose an\ninductive collaborative filtering framework that contains two representation\nmodels. The first model follows conventional matrix factorization which\nfactorizes a group of key users' rating matrix to obtain meta latents. The\nsecond model resorts to attention-based structure learning that estimates\nhidden relations from query to key users and learns to leverage meta latents to\ninductively compute embeddings for query users via neural message passing. Our\nmodel enables inductive representation learning for users and meanwhile\nguarantees equivalent representation capacity as matrix factorization.\nExperiments demonstrate that our model achieves promising results for\nrecommendation on few-shot users with limited training ratings and new unseen\nusers which are commonly encountered in open-world recommender systems.",
          "link": "http://arxiv.org/abs/2007.04833",
          "publishedOn": "2021-06-10T01:56:45.180Z",
          "wordCount": 626,
          "title": "Towards Open-World Recommendation: An Inductive Model-based Collaborative Filtering Approach. (arXiv:2007.04833v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.03185",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Limin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1\">Zhiwen Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1\">Grace Hui Yang</a>",
          "description": "Interactive Information Retrieval (IIR) and Reinforcement Learning (RL) share\nmany commonalities, including an agent who learns while interacts, a long-term\nand complex goal, and an algorithm that explores and adapts. To successfully\napply RL methods to IIR, one challenge is to obtain sufficient relevance labels\nto train the RL agents, which are infamously known as sample inefficient.\nHowever, in a text corpus annotated for a given query, it is not the relevant\ndocuments but the irrelevant documents that predominate. This would cause very\nunbalanced training experiences for the agent and prevent it from learning any\npolicy that is effective. Our paper addresses this issue by using domain\nrandomization to synthesize more relevant documents for the training. Our\nexperimental results on the Text REtrieval Conference (TREC) Dynamic Domain\n(DD) 2017 Track show that the proposed method is able to boost an RL agent's\nlearning effectiveness by 22\\% in dealing with unseen situations.",
          "link": "http://arxiv.org/abs/2006.03185",
          "publishedOn": "2021-06-10T01:56:45.173Z",
          "wordCount": 615,
          "title": "Balancing Reinforcement Learning Training Experiences in Interactive Information Retrieval. (arXiv:2006.03185v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1811.00606",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1\">Zhiwen Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1\">Grace Hui Yang</a>",
          "description": "Most neural Information Retrieval (Neu-IR) models derive query-to-document\nranking scores based on term-level matching. Inspired by TileBars, a classical\nterm distribution visualization method, in this paper, we propose a novel\nNeu-IR model that handles query-to-document matching at the subtopic and higher\nlevels. Our system first splits the documents into topical segments,\n\"visualizes\" the matchings between the query and the segments, and then feeds\nan interaction matrix into a Neu-IR model, DeepTileBars, to obtain the final\nranking scores. DeepTileBars models the relevance signals occurring at\ndifferent granularities in a document's topic hierarchy. It better captures the\ndiscourse structure of a document and thus the matching patterns. Although its\ndesign and implementation are light-weight, DeepTileBars outperforms other\nstate-of-the-art Neu-IR models on benchmark datasets including the Text\nREtrieval Conference (TREC) 2010-2012 Web Tracks and LETOR 4.0.",
          "link": "http://arxiv.org/abs/1811.00606",
          "publishedOn": "2021-06-10T01:56:45.165Z",
          "wordCount": 612,
          "title": "DeepTileBars: Visualizing Term Distribution for Neural Information Retrieval. (arXiv:1811.00606v3 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05081",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Ziyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_W/0/1/0/all/0/1\">Wei Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cong_G/0/1/0/all/0/1\">Gao Cong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiao-Li Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_X/0/1/0/all/0/1\">Xian-Ling Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_M/0/1/0/all/0/1\">Minghui Qiu</a>",
          "description": "Session-based recommendation (SBR) is a challenging task, which aims at\nrecommending items based on anonymous behavior sequences. Almost all the\nexisting solutions for SBR model user preference only based on the current\nsession without exploiting the other sessions, which may contain both relevant\nand irrelevant item-transitions to the current session. This paper proposes a\nnovel approach, called Global Context Enhanced Graph Neural Networks (GCE-GNN)\nto exploit item transitions over all sessions in a more subtle manner for\nbetter inferring the user preference of the current session. Specifically,\nGCE-GNN learns two levels of item embeddings from session graph and global\ngraph, respectively: (i) Session graph, which is to learn the session-level\nitem embedding by modeling pairwise item-transitions within the current\nsession; and (ii) Global graph, which is to learn the global-level item\nembedding by modeling pairwise item-transitions over all sessions. In GCE-GNN,\nwe propose a novel global-level item representation learning layer, which\nemploys a session-aware attention mechanism to recursively incorporate the\nneighbors' embeddings of each node on the global graph. We also design a\nsession-level item representation learning layer, which employs a GNN on the\nsession graph to learn session-level item embeddings within the current\nsession. Moreover, GCE-GNN aggregates the learnt item representations in the\ntwo levels with a soft attention mechanism. Experiments on three benchmark\ndatasets demonstrate that GCE-GNN outperforms the state-of-the-art methods\nconsistently.",
          "link": "http://arxiv.org/abs/2106.05081",
          "publishedOn": "2021-06-10T01:56:45.154Z",
          "wordCount": 669,
          "title": "Global Context Enhanced Graph Neural Networks for Session-based Recommendation. (arXiv:2106.05081v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04873",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiangli Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_R/0/1/0/all/0/1\">Rong Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_R/0/1/0/all/0/1\">Ruiming Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhirong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiuqiang He</a>",
          "description": "Recommender systems are often asked to serve multiple recommendation\nscenarios or domains. Fine-tuning a pre-trained CTR model from source domains\nand adapting it to a target domain allows knowledge transferring. However,\noptimizing all the parameters of the pre-trained network may result in\nover-fitting if the target dataset is small and the number of parameters is\nlarge. This leads us to think of directly reusing parameters in the pre-trained\nmodel which represent more general features learned from multiple domains.\nHowever, the design of freezing or fine-tuning layers of parameters requires\nmuch manual effort since the decision highly depends on the pre-trained model\nand target instances. In this work, we propose an end-to-end transfer learning\nframework, called Automatic Fine-Tuning (AutoFT), for CTR prediction. AutoFT\nconsists of a field-wise transfer policy and a layer-wise transfer policy. The\nfield-wise transfer policy decides how the pre-trained embedding\nrepresentations are frozen or fine-tuned based on the given instance from the\ntarget domain. The layer-wise transfer policy decides how the high?order\nfeature representations are transferred layer by layer. Extensive experiments\non two public benchmark datasets and one private industrial dataset demonstrate\nthat AutoFT can significantly improve the performance of CTR prediction\ncompared with state-of-the-art transferring approaches.",
          "link": "http://arxiv.org/abs/2106.04873",
          "publishedOn": "2021-06-10T01:56:45.129Z",
          "wordCount": 635,
          "title": "AutoFT: Automatic Fine-Tune for Parameters Transfer Learning in Click-Through Rate Prediction. (arXiv:2106.04873v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/1912.00753",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1\">Zhiwen Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1\">Grace Hui Yang</a>",
          "description": "A core interest in building Artificial Intelligence (AI) agents is to let\nthem interact with and assist humans. One example is Dynamic Search (DS), which\nmodels the process that a human works with a search engine agent to accomplish\na complex and goal-oriented task. Early DS agents using Reinforcement Learning\n(RL) have only achieved limited success for (1) their lack of direct control\nover which documents to return and (2) the difficulty to recover from wrong\nsearch trajectories. In this paper, we present a novel corpus-level end-to-end\nexploration (CE3) method to address these issues. In our method, an entire text\ncorpus is compressed into a global low-dimensional representation, which\nenables the agent to gain access to the full state and action spaces, including\nthe under-explored areas. We also propose a new form of retrieval function,\nwhose linear approximation allows end-to-end manipulation of documents.\nExperiments on the Text REtrieval Conference (TREC) Dynamic Domain (DD) Track\nshow that CE3 outperforms the state-of-the-art DS systems.",
          "link": "http://arxiv.org/abs/1912.00753",
          "publishedOn": "2021-06-10T01:56:45.121Z",
          "wordCount": 618,
          "title": "Corpus-Level End-to-End Exploration for Interactive Systems. (arXiv:1912.00753v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05222",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Heidarzadeh_A/0/1/0/all/0/1\">Anoosheh Heidarzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Esmati_N/0/1/0/all/0/1\">Nahid Esmati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sprintson_A/0/1/0/all/0/1\">Alex Sprintson</a>",
          "description": "This paper considers the single-server Private Linear Transformation (PLT)\nproblem with individual privacy guarantees. In this problem, there is a user\nthat wishes to obtain $L$ independent linear combinations of a $D$-subset of\nmessages belonging to a dataset of $K$ messages stored on a single server. The\ngoal is to minimize the download cost while keeping the identity of each\nmessage required for the computation individually private. The individual\nprivacy requirement ensures that the identity of each individual message\nrequired for the computation is kept private. This is in contrast to the\nstricter notion of joint privacy that protects the entire set of identities of\nall messages used for the computation, including the correlations between these\nidentities. The notion of individual privacy captures a broad set of practical\napplications. For example, such notion is relevant when the dataset contains\ninformation about individuals, each of them requires privacy guarantees for\ntheir data access patterns. We focus on the setting in which the required\nlinear transformation is associated with a maximum distance separable (MDS)\nmatrix. In particular, we require that the matrix of coefficients pertaining to\nthe required linear combinations is the generator matrix of an MDS code. We\nestablish lower and upper bounds on the capacity of PLT with individual\nprivacy, where the capacity is defined as the supremum of all achievable\ndownload rates. We show that our bounds are tight under certain conditions.",
          "link": "http://arxiv.org/abs/2106.05222",
          "publishedOn": "2021-06-10T01:56:45.102Z",
          "wordCount": 678,
          "title": "Single-Server Private Linear Transformation: The Individual Privacy Case. (arXiv:2106.05222v1 [cs.IT])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05194",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+He_Y/0/1/0/all/0/1\">Yixuan He</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Reinert_G/0/1/0/all/0/1\">Gesine Reinert</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cucuringu_M/0/1/0/all/0/1\">Mihai Cucuringu</a>",
          "description": "Node clustering is a powerful tool in the analysis of networks. Here, we\nintroduce a graph neural network framework with a novel scalable Directed Mixed\nPath Aggregation(DIMPA) scheme to obtain node embeddings for directed networks\nin a self-supervised manner, including a novel probabilistic imbalance loss.\nThe method is end-to-end in combining embedding generation and clustering\nwithout an intermediate step. In contrast to standard approaches in the\nliterature, in this paper, directionality is not treated as a nuisance, but\nrather contains the main signal. In particular, we leverage the recently\nintroduced cut flow imbalance measure, which is tightly related to\ndirectionality; cut flow imbalance is optimized without resorting to spectral\nmethods or cluster labels. Experimental results on synthetic data, in the form\nof directed stochastic block models and real-world data at different scales,\ndemonstrate that our method attains state-of-the-art results on directed\nclustering, for a wide range of noise and sparsity levels, as well as graph\nstructures.",
          "link": "http://arxiv.org/abs/2106.05194",
          "publishedOn": "2021-06-10T01:56:45.093Z",
          "wordCount": 593,
          "title": "DIGRAC: Digraph Clustering with Flow Imbalance. (arXiv:2106.05194v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05147",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chios_I/0/1/0/all/0/1\">Ioannis Chios</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verberne_S/0/1/0/all/0/1\">Suzan Verberne</a>",
          "description": "In this paper we address the explainability of web search engines. We propose\ntwo explainable elements on the search engine result page: a visualization of\nquery term weights and a visualization of passage relevance. The idea is that\nsearch engines that indicate to the user why results are retrieved are valued\nhigher by users and gain user trust. We deduce the query term weights from the\nterm gating network in the Deep Relevance Matching Model (DRMM) and visualize\nthem as a doughnut chart. In addition, we train a passage-level ranker with\nDRMM that selects the most relevant passage from each document and shows it as\nsnippet on the result page. Next to the snippet we show a document thumbnail\nwith this passage highlighted. We evaluate the proposed interface in an online\nuser study, asking users to judge the explainability and assessability of the\ninterface. We found that users judge our proposed interface significantly more\nexplainable and easier to assess than a regular search engine result page.\nHowever, they are not significantly better in selecting the relevant documents\nfrom the top-5. This indicates that the explainability of the search engine\nresult page leads to a better user experience. Thus, we conclude that the\nproposed explainable elements are promising as visualization for search engine\nusers.",
          "link": "http://arxiv.org/abs/2106.05147",
          "publishedOn": "2021-06-10T01:56:45.056Z",
          "wordCount": 665,
          "title": "Helping results assessment by adding explainable elements to the deep relevance matching model. (arXiv:2106.05147v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05260",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Adams_J/0/1/0/all/0/1\">Jane L. Adams</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Deluca_T/0/1/0/all/0/1\">Todd F. Deluca</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Danforth_C/0/1/0/all/0/1\">Christopher M. Danforth</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dodds_P/0/1/0/all/0/1\">Peter S. Dodds</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zheng_Y/0/1/0/all/0/1\">Yuhang Zheng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Anastasakis_K/0/1/0/all/0/1\">Konstantinos Anastasakis</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Choi_B/0/1/0/all/0/1\">Boyoon Choi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Min_A/0/1/0/all/0/1\">Allison Min</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bessey_M/0/1/0/all/0/1\">Michael M. Bessey</a>",
          "description": "Data scientists across disciplines are increasingly in need of exploratory\nanalysis tools for data sets with a high volume of features. We expand upon\ngraph mining approaches for exploratory analysis of high-dimensional data to\nintroduce Sirius, a visualization package for researchers to explore feature\nrelationships among mixed data types using mutual information and network\nbackbone sparsification. Visualizations of feature relationships aid data\nscientists in finding meaningful dependence among features, which can engender\nfurther analysis for feature selection, feature extraction, projection,\nidentification of proxy variables, or insight into temporal variation at the\nmacro scale. Graph mining approaches for feature analysis exist, such as\nassociation networks of binary features, or correlation networks of\nquantitative features, but mixed data types present a unique challenge for\ndeveloping comprehensive feature networks for exploratory analysis. Using an\ninformation theoretic approach, Sirius supports heterogeneous data sets\nconsisting of binary, continuous quantitative, and discrete categorical data\ntypes, and provides a user interface exploring feature pairs with high mutual\ninformation scores. We leverage a backbone sparsification approach from network\ntheory as a dimensionality reduction technique, which probabilistically trims\nedges according to the local network context. Sirius is an open source Python\npackage and Django web application for exploratory visualization, which can be\ndeployed in data analysis pipelines. The Sirius codebase and exemplary data\nsets can be found at: https://github.com/compstorylab/sirius",
          "link": "http://arxiv.org/abs/2106.05260",
          "publishedOn": "2021-06-10T01:56:45.043Z",
          "wordCount": 677,
          "title": "Sirius: A Mutual Information Tool for Exploratory Visualization of Mixed Data. (arXiv:2106.05260v1 [stat.AP])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05144",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Riba_P/0/1/0/all/0/1\">Pau Riba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Molina_A/0/1/0/all/0/1\">Adri&#xe0; Molina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gomez_L/0/1/0/all/0/1\">Lluis Gomez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramos_Terrades_O/0/1/0/all/0/1\">Oriol Ramos-Terrades</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Llados_J/0/1/0/all/0/1\">Josep Llad&#xf3;s</a>",
          "description": "In this paper, we explore and evaluate the use of ranking-based objective\nfunctions for learning simultaneously a word string and a word image encoder.\nWe consider retrieval frameworks in which the user expects a retrieval list\nranked according to a defined relevance score. In the context of a word\nspotting problem, the relevance score has been set according to the string edit\ndistance from the query string. We experimentally demonstrate the competitive\nperformance of the proposed model on query-by-string word spotting for both,\nhandwritten and real scene word images. We also provide the results for\nquery-by-example word spotting, although it is not the main focus of this work.",
          "link": "http://arxiv.org/abs/2106.05144",
          "publishedOn": "2021-06-10T01:56:44.964Z",
          "wordCount": 552,
          "title": "Learning to Rank Words: Optimizing Ranking Metrics for Word Spotting. (arXiv:2106.05144v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05220",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Heidarzadeh_A/0/1/0/all/0/1\">Anoosheh Heidarzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Esmati_N/0/1/0/all/0/1\">Nahid Esmati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sprintson_A/0/1/0/all/0/1\">Alex Sprintson</a>",
          "description": "This paper introduces the problem of Private Linear Transformation (PLT)\nwhich generalizes the problems of private information retrieval and private\nlinear computation. The PLT problem includes one or more remote server(s)\nstoring (identical copies of) $K$ messages and a user who wants to compute $L$\nindependent linear combinations of a $D$-subset of messages. The objective of\nthe user is to perform the computation by downloading minimum possible amount\nof information from the server(s), while protecting the identities of the $D$\nmessages required for the computation. In this work, we focus on the\nsingle-server setting of the PLT problem when the identities of the $D$\nmessages required for the computation must be protected jointly. We consider\ntwo different models, depending on whether the coefficient matrix of the\nrequired $L$ linear combinations generates a Maximum Distance Separable (MDS)\ncode. We prove that the capacity for both models is given by $L/(K-D+L)$, where\nthe capacity is defined as the supremum of all achievable download rates. Our\nconverse proofs are based on linear-algebraic and information-theoretic\narguments that establish connections between PLT schemes and linear codes. We\nalso present an achievability scheme for each of the models being considered.",
          "link": "http://arxiv.org/abs/2106.05220",
          "publishedOn": "2021-06-10T01:56:44.923Z",
          "wordCount": 638,
          "title": "Single-Server Private Linear Transformation: The Joint Privacy Case. (arXiv:2106.05220v1 [cs.IT])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04612",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ravfogel_S/0/1/0/all/0/1\">Shauli Ravfogel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taub_Tabib_H/0/1/0/all/0/1\">Hillel Taub-Tabib</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldberg_Y/0/1/0/all/0/1\">Yoav Goldberg</a>",
          "description": "Domain experts often need to extract structured information from large\ncorpora. We advocate for a search paradigm called ``extractive search'', in\nwhich a search query is enriched with capture-slots, to allow for such rapid\nextraction. Such an extractive search system can be built around syntactic\nstructures, resulting in high-precision, low-recall results. We show how the\nrecall can be improved using neural retrieval and alignment. The goals of this\npaper are to concisely introduce the extractive-search paradigm; and to\ndemonstrate a prototype neural retrieval system for extractive search and its\nbenefits and potential. Our prototype is available at\n\\url{https://spike.neural-sim.apps.allenai.org/} and a video demonstration is\navailable at \\url{https://vimeo.com/559586687}.",
          "link": "http://arxiv.org/abs/2106.04612",
          "publishedOn": "2021-06-10T01:56:44.908Z",
          "wordCount": 535,
          "title": "Neural Extractive Search. (arXiv:2106.04612v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04993",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yinan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Boyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miao_C/0/1/0/all/0/1\">Chunyan Miao</a>",
          "description": "Proper initialization is crucial to the optimization and the generalization\nof neural networks. However, most existing neural recommendation systems\ninitialize the user and item embeddings randomly. In this work, we propose a\nnew initialization scheme for user and item embeddings called Laplacian\nEigenmaps with Popularity-based Regularization for Isolated Data (LEPORID).\nLEPORID endows the embeddings with information regarding multi-scale\nneighborhood structures on the data manifold and performs adaptive\nregularization to compensate for high embedding variance on the tail of the\ndata distribution. Exploiting matrix sparsity, LEPORID embeddings can be\ncomputed efficiently. We evaluate LEPORID in a wide range of neural\nrecommendation models. In contrast to the recent surprising finding that the\nsimple K-nearest-neighbor (KNN) method often outperforms neural recommendation\nsystems, we show that existing neural systems initialized with LEPORID often\nperform on par or better than KNN. To maximize the effects of the\ninitialization, we propose the Dual-Loss Residual Recommendation (DLR2)\nnetwork, which, when initialized with LEPORID, substantially outperforms both\ntraditional and state-of-the-art neural recommender systems.",
          "link": "http://arxiv.org/abs/2106.04993",
          "publishedOn": "2021-06-10T01:56:44.870Z",
          "wordCount": 597,
          "title": "Initialization Matters: Regularizing Manifold-informed Initialization for Neural Recommendation Systems. (arXiv:2106.04993v1 [cs.IR])"
        }
      ]
    },
    {
      "title": "cs.MM updates on arXiv.org",
      "feedUrl": "http://export.arxiv.org/rss/cs.MM",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2106.06924",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chang_C/0/1/0/all/0/1\">Ching-Chun Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Sisheng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Echizen_I/0/1/0/all/0/1\">Isao Echizen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanchez_V/0/1/0/all/0/1\">Victor Sanchez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chang-Tsun Li</a>",
          "description": "Deep-learning\\textendash{centric} reversible steganography has emerged as a\npromising research paradigm. A direct way of applying deep learning to\nreversible steganography is to construct a pair of encoder and decoder, whose\nparameters are trained jointly, thereby learning the steganographic system as a\nwhole. This end-to-end framework, however, falls short of the reversibility\nrequirement because it is difficult for this kind of monolithic system, as a\nblack box, to create or duplicate intricate reversible mechanisms. In response\nto this issue, a recent approach is to carve up the steganographic system and\nwork on modules independently. In particular, neural networks are deployed in\nan analytics module to learn the data distribution, while an established\nmechanism is called upon to handle the remaining tasks. In this paper, we\ninvestigate the modular framework and deploy deep neural networks in a\nreversible steganographic scheme referred to as prediction-error modulation, in\nwhich an analytics module serves the purpose of pixel intensity prediction. The\nprimary focus of this study is on deep-learning\\textendash{based} context-aware\npixel intensity prediction. We address the unsolved issues reported in related\nliterature, including the impact of pixel initialisation on prediction accuracy\nand the influence of uncertainty propagation in dual-layer embedding.\nFurthermore, we establish a connection between context-aware pixel intensity\nprediction and low-level computer vision and analyse the performance of several\nadvanced neural networks.",
          "link": "http://arxiv.org/abs/2106.06924",
          "publishedOn": "2021-06-15T22:07:48.721Z",
          "wordCount": 658,
          "title": "Deep Learning for Reversible Steganography: Principles and Insights. (arXiv:2106.06924v1 [cs.MM])"
        },
        {
          "id": "http://arxiv.org/abs/2105.13096",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jieni Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_J/0/1/0/all/0/1\">Junren Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_S/0/1/0/all/0/1\">Shanxiang Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_B/0/1/0/all/0/1\">Bingwen Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiabo Wang</a>",
          "description": "Lattices have been conceived as a powerful tool for data hiding. While\nconventional studies and applications focus on achieving the optimal robustness\nversus distortion tradeoff, in some applications such as data hiding in\nmedical/physiological signals, the primary concern is to achieve a minimum\namount of distortion to the cover signal. In this paper, we revisit the\ncelebrated quantization index modulation (QIM) scheme and propose a\nminimum-distortion version of it, referred to as MD-QIM. The crux of MD-QIM is\nto move the data point to only the boundary of the Voronoi region of the\nlattice point indexed by a message, which suffices for subsequent correct\ndecoding. At any fixed code rate, the scheme achieves the minimum amount of\ndistortion by sacrificing the robustness to the additive white Gaussian noise\n(AWGN) attacks. Simulation results confirm that our scheme significantly\noutperforms QIM in terms of mean square error (MSE), peak signal to noise ratio\n(PSNR) and percentage residual difference (PRD).",
          "link": "http://arxiv.org/abs/2105.13096",
          "publishedOn": "2021-06-15T01:45:14.088Z",
          "wordCount": 615,
          "title": "Lattice-Based Minimum-Distortion Data Hiding. (arXiv:2105.13096v2 [cs.IT] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06736",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brousmiche_M/0/1/0/all/0/1\">Mathilde Brousmiche</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rouat_J/0/1/0/all/0/1\">Jean Rouat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dupont_S/0/1/0/all/0/1\">St&#xe9;phane Dupont</a>",
          "description": "Event classification is inherently sequential and multimodal. Therefore, deep\nneural models need to dynamically focus on the most relevant time window and/or\nmodality of a video. In this study, we propose the Multi-level Attention Fusion\nnetwork (MAFnet), an architecture that can dynamically fuse visual and audio\ninformation for event recognition. Inspired by prior studies in neuroscience,\nwe couple both modalities at different levels of visual and audio paths.\nFurthermore, the network dynamically highlights a modality at a given time\nwindow relevant to classify events. Experimental results in AVE (Audio-Visual\nEvent), UCF51, and Kinetics-Sounds datasets show that the approach can\neffectively improve the accuracy in audio-visual event classification. Code is\navailable at: https://github.com/numediart/MAFnet",
          "link": "http://arxiv.org/abs/2106.06736",
          "publishedOn": "2021-06-15T01:45:13.424Z",
          "wordCount": 555,
          "title": "Multi-level Attention Fusion Network for Audio-visual Event Recognition. (arXiv:2106.06736v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2009.00100",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Young-min Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_Y/0/1/0/all/0/1\">Young-chul Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_K/0/1/0/all/0/1\">Kwangjin Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeon_M/0/1/0/all/0/1\">Moongu Jeon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Seong-Whan Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pedrycz_W/0/1/0/all/0/1\">Witold Pedrycz</a>",
          "description": "In this paper, we propose a highly practical fully online multi-object\ntracking and segmentation (MOTS) method that uses instance segmentation results\nas an input. The proposed method is based on the Gaussian mixture probability\nhypothesis density (GMPHD) filter, a hierarchical data association (HDA), and a\nmask-based affinity fusion (MAF) model to achieve high-performance online\ntracking. The HDA consists of two associations: segment-to-track and\ntrack-to-track associations. One affinity, for position and motion, is computed\nby using the GMPHD filter, and the other affinity, for appearance is computed\nby using the responses from a single object tracker such as a kernalized\ncorrelation filter. These two affinities are simply fused by using a\nscore-level fusion method such as min-max normalization referred to as MAF. In\naddition, to reduce the number of false positive segments, we adopt mask\nIoU-based merging (mask merging). The proposed MOTS framework with the key\nmodules: HDA, MAF, and mask merging, is easily extensible to simultaneously\ntrack multiple types of objects with CPU only execution in parallel processing.\nIn addition, the developed framework only requires simple parameter tuning\nunlike many existing MOTS methods that need intensive hyperparameter\noptimization. In the experiments on the two popular MOTS datasets, the key\nmodules show some improvements. For instance, ID-switch decreases by more than\nhalf compared to a baseline method in the training sets. In conclusion, our\ntracker achieves state-of-the-art MOTS performance in the test sets.",
          "link": "http://arxiv.org/abs/2009.00100",
          "publishedOn": "2021-06-14T01:38:50.799Z",
          "wordCount": 708,
          "title": "Online Multi-Object Tracking and Segmentation with GMPHD Filter and Mask-based Affinity Fusion. (arXiv:2009.00100v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.11376",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wilmot_C/0/1/0/all/0/1\">Charles Wilmot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Triesch_J/0/1/0/all/0/1\">Jochen Triesch</a>",
          "description": "A key competence for open-ended learning is the formation of increasingly\nabstract representations useful for driving complex behavior. Abstract\nrepresentations ignore specific details and facilitate generalization. Here we\nconsider the learning of abstract representations in a multi-modal setting with\ntwo or more input modalities. We treat the problem as a lossy compression\nproblem and show that generic lossy compression of multimodal sensory input\nnaturally extracts abstract representations that tend to strip away modalitiy\nspecific details and preferentially retain information that is shared across\nthe different modalities. Furthermore, we propose an architecture to learn\nabstract representations by identifying and retaining only the information that\nis shared across multiple modalities while discarding any modality specific\ninformation.",
          "link": "http://arxiv.org/abs/2101.11376",
          "publishedOn": "2021-06-14T01:38:50.480Z",
          "wordCount": 568,
          "title": "Learning Abstract Representations through Lossy Compression of Multi-Modal Signals. (arXiv:2101.11376v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06489",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liong_G/0/1/0/all/0/1\">Gen-Bing Liong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+See_J/0/1/0/all/0/1\">John See</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_L/0/1/0/all/0/1\">Lai-Kuan Wong</a>",
          "description": "Facial expressions vary from the visible to the subtle. In recent years, the\nanalysis of micro-expressions $-$ a natural occurrence resulting from the\nsuppression of one's true emotions, has drawn the attention of researchers with\na broad range of potential applications. However, spotting microexpressions in\nlong videos becomes increasingly challenging when intertwined with normal or\nmacro-expressions. In this paper, we propose a shallow optical flow\nthree-stream CNN (SOFTNet) model to predict a score that captures the\nlikelihood of a frame being in an expression interval. By fashioning the\nspotting task as a regression problem, we introduce pseudo-labeling to\nfacilitate the learning process. We demonstrate the efficacy and efficiency of\nthe proposed approach on the recent MEGC 2020 benchmark, where state-of-the-art\nperformance is achieved on CAS(ME)$^{2}$ with equally promising results on SAMM\nLong Videos.",
          "link": "http://arxiv.org/abs/2106.06489",
          "publishedOn": "2021-06-14T01:38:50.449Z",
          "wordCount": 591,
          "title": "Shallow Optical Flow Three-Stream CNN for Macro- and Micro-Expression Spotting from Long Videos. (arXiv:2106.06489v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05630",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_M/0/1/0/all/0/1\">Mingliang Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1\">Xu Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ju_Z/0/1/0/all/0/1\">Zeqian Ju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1\">Tao Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tie-Yan Liu</a>",
          "description": "Symbolic music understanding, which refers to the understanding of music from\nthe symbolic data (e.g., MIDI format, but not audio), covers many music\napplications such as genre classification, emotion classification, and music\npieces matching. While good music representations are beneficial for these\napplications, the lack of training data hinders representation learning.\nInspired by the success of pre-training models in natural language processing,\nin this paper, we develop MusicBERT, a large-scale pre-trained model for music\nunderstanding. To this end, we construct a large-scale symbolic music corpus\nthat contains more than 1 million music songs. Since symbolic music contains\nmore structural (e.g., bar, position) and diverse information (e.g., tempo,\ninstrument, and pitch), simply adopting the pre-training techniques from NLP to\nsymbolic music only brings marginal gains. Therefore, we design several\nmechanisms, including OctupleMIDI encoding and bar-level masking strategy, to\nenhance pre-training with symbolic music data. Experiments demonstrate the\nadvantages of MusicBERT on four music understanding tasks, including melody\ncompletion, accompaniment suggestion, genre classification, and style\nclassification. Ablation studies also verify the effectiveness of our designs\nof OctupleMIDI encoding and bar-level masking strategy in MusicBERT.",
          "link": "http://arxiv.org/abs/2106.05630",
          "publishedOn": "2021-06-11T01:42:14.601Z",
          "wordCount": 631,
          "title": "MusicBERT: Symbolic Music Understanding with Large-Scale Pre-Training. (arXiv:2106.05630v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05481",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Man_H/0/1/0/all/0/1\">Hengyu Man</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1\">Xiaopeng Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_R/0/1/0/all/0/1\">Ruiqin Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1\">Debin Zhao</a>",
          "description": "As a crucial part of video compression, intra prediction utilizes local\ninformation of images to eliminate the redundancy in spatial domain. In both\nH.265/HEVC and H.266/VVC, multiple directional prediction modes are employed to\nfind the texture trend of each small block and then the prediction is made\nbased on reference samples in the selected direction. Recently, the intra\nprediction schemes based on neural networks have achieved great success. In\nthese methods, the networks are trained and applied to intra prediction in\naddition to the directional prediction modes. In this paper, we propose a novel\ndata clustering-driven neural network (dubbed DCDNN) for intra prediction,\nwhich can learn deep features of the clustered data. In DCDNN, each network can\nbe split into two networks by adding or subtracting Gaussian random noise. Then\na data clustering-driven training is applied to train all the derived networks\nrecursively. In each iteration, the entire training dataset is partitioned\naccording to the recovery qualities of the derived networks. For the\nexperiment, DCDNN is implemented into HEVC reference software HM-16.9. The\nexperimental results demonstrate that DCDNN can reach an average of 4.2%\nBjontegaard distortion rate (BDrate) improvement (up to 7.0%) over HEVC with\nall intra configuration. Compared with existing fully connected networkbased\nintra prediction methods, the bitrate saving performance is further improved.",
          "link": "http://arxiv.org/abs/2106.05481",
          "publishedOn": "2021-06-11T01:42:13.535Z",
          "wordCount": 633,
          "title": "Data Clustering-Driven Neural Network for Intra Prediction. (arXiv:2106.05481v1 [cs.MM])"
        },
        {
          "id": "http://arxiv.org/abs/1908.01947",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Su_W/0/1/0/all/0/1\">Wenkang Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_J/0/1/0/all/0/1\">Jiangqun Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xianglei Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jiwu Huang</a>",
          "description": "Recently, with the introduction of JPEG phase-aware steganalysis features,\ne.g., GFR, the design of JPEG steganographic distortion cost function turns to\nmaintain not only the statistical undetectability in DCT domain but also in\nspatial domain. To tackle this issue, this paper presents a novel paradigm for\nthe design of JPEG steganographic distortion cost function, which calculates\nthe distortion cost via a generalized Distortion Cost Domain Transformation\n(DCDT) function. The proposed function comprises the decompressed pixel block\nembedding changes and their corresponding embedding distortion costs for unit\nchange, where the pixel embedding distortion costs are represented in a more\ngeneral exponential model, aiming to flexibly allocate the embedding data. In\nthis way, the JPEG steganography could be formulated as the optimization\nproblem of minimizing the overall distortion cost in its decompressed spatial\ndomain, which is equivalent to maximizing its statistical undetectability\nagainst JPEG phase-aware steganalysis features. Experimental results show that\nthe proposed DCDT equipped with HiLL (a spatial steganographic distortion cost\nfunction) is superior to other state-of-the-art JPEG steganographic schemes,\ne.g., UERD, J-UNIWARD, and GUED in resisting the detection of JPEG phase-aware\nfeature-based steganalyzers GFR and SCA-GFR, and rivals BET-HiLL with one order\nof magnitude lower computational complexity, along with the possibility of\nbeing further improved by considering the mutually dependent embedding\ninteractions. In addition, the proposed DCDT is also verified to be effective\nfor different image databases and quality factors.",
          "link": "http://arxiv.org/abs/1908.01947",
          "publishedOn": "2021-06-11T01:42:13.440Z",
          "wordCount": 691,
          "title": "New Design Paradigm of Distortion Cost Function for Efficient JPEG Steganography. (arXiv:1908.01947v3 [cs.MM] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.01404",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Changsheng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shuzheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_F/0/1/0/all/0/1\">Fengbo Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jiwu Huang</a>",
          "description": "Recapturing attack can be employed as a simple but effective anti-forensic\ntool for digital document images. Inspired by the document inspection process\nthat compares a questioned document against a reference sample, we proposed a\ndocument recapture detection scheme by employing Siamese network to compare and\nextract distinct features in a recapture document image. The proposed algorithm\ntakes advantages of both metric learning and image forensic techniques. Instead\nof adopting Euclidean distance-based loss function, we integrate the forensic\nsimilarity function with a triplet loss and a normalized softmax loss. After\ntraining with the proposed triplet selection strategy, the resulting feature\nembedding clusters the genuine samples near the reference while pushes the\nrecaptured samples apart. In the experiment, we consider practical domain\ngeneralization problems, such as the variations in printing/imaging devices,\nsubstrates, recapturing channels, and document types. To evaluate the\nrobustness of different approaches, we benchmark some popular off-the-shelf\nmachine learning-based approaches, a state-of-the-art document image detection\nscheme, and the proposed schemes with different network backbones under various\nexperimental protocols. Experimental results show that the proposed schemes\nwith different network backbones have consistently outperformed the\nstate-of-the-art approaches under different experimental settings.\nSpecifically, under the most challenging scenario in our experiment, i.e.,\nevaluation across different types of documents that produced by different\ndevices, we have achieved less than 5.00% APCER (Attack Presentation\nClassification Error Rate) and 5.56% BPCER (Bona Fide Presentation\nClassification Error Rate) by the proposed network with ResNeXt101 backbone at\n5% BPCER decision threshold.",
          "link": "http://arxiv.org/abs/2101.01404",
          "publishedOn": "2021-06-10T01:56:44.423Z",
          "wordCount": 703,
          "title": "Domain Generalization for Document Authentication against Practical Recapturing Attacks. (arXiv:2101.01404v2 [cs.MM] UPDATED)"
        }
      ]
    },
    {
      "title": "cs.CV updates on arXiv.org",
      "feedUrl": "http://export.arxiv.org/rss/cs.CV",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2106.04067",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shao_R/0/1/0/all/0/1\">Ruizhi Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_G/0/1/0/all/0/1\">Gaochang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yuemei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1\">Ying Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yebin Liu</a>",
          "description": "Cross-resolution image alignment is a key problem in multiscale gigapixel\nphotography, which requires to estimate homography matrix using images with\nlarge resolution gap. Existing deep homography methods concatenate the input\nimages or features, neglecting the explicit formulation of correspondences\nbetween them, which leads to degraded accuracy in cross-resolution challenges.\nIn this paper, we consider the cross-resolution homography estimation as a\nmultimodal problem, and propose a local transformer network embedded within a\nmultiscale structure to explicitly learn correspondences between the multimodal\ninputs, namely, input images with different resolutions. The proposed local\ntransformer adopts a local attention map specifically for each position in the\nfeature. By combining the local transformer with the multiscale structure, the\nnetwork is able to capture long-short range correspondences efficiently and\naccurately. Experiments on both the MS-COCO dataset and the real-captured\ncross-resolution dataset show that the proposed network outperforms existing\nstate-of-the-art feature-based and deep-learning-based homography estimation\nmethods, and is able to accurately align images under $10\\times$ resolution\ngap.",
          "link": "http://arxiv.org/abs/2106.04067",
          "publishedOn": "2021-06-15T22:41:25.275Z",
          "wordCount": 613,
          "title": "LocalTrans: A Multiscale Local Transformer Network for Cross-Resolution Homography Estimation. (arXiv:2106.04067v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06769",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Junfu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bi Wang</a>",
          "description": "Working memory (WM) is a basic part of human cognition, which plays an\nimportant role in the study of human cognitive load. Among various brain\nimaging techniques, electroencephalography has shown its advantage on easy\naccess and reliability. However, one of the critical challenges is that\nindividual difference may cause the ineffective results, especially when the\nestablished model meets an unfamiliar subject. In this work, we propose a\ncross-subject deep adaptation model with spatial attention (CS-DASA) to\ngeneralize the workload classifications across subjects. First, we transform\ntime-series EEG data into multi-frame EEG images incorporating more\nspatio-temporal information. First, the subject-shared module in CS-DASA\nreceives multi-frame EEG image data from both source and target subjects and\nlearns the common feature representations. Then, in subject-specific module,\nthe maximum mean discrepancy is implemented to measure the domain distribution\ndivergence in a reproducing kernel Hilbert space, which can add an effective\npenalty loss for domain adaptation. Additionally, the subject-to-subject\nspatial attention mechanism is employed to focus on the most discriminative\nspatial feature in EEG image data. Experiments conducted on a public WM EEG\ndataset containing 13 subjects show that the proposed model is capable of\nachieve better performance than existing state-of-the art methods.",
          "link": "http://arxiv.org/abs/2106.06769",
          "publishedOn": "2021-06-15T22:07:49.048Z",
          "wordCount": 632,
          "title": "Cross-Subject Domain Adaptation for Multi-Frame EEG Images. (arXiv:2106.06769v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06911",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lo_S/0/1/0/all/0/1\">Shaw-Hwa Lo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1\">Yiqiao Yin</a>",
          "description": "The field of Explainable Artificial Intelligence (XAI) aims to build\nexplainable and interpretable machine learning (or deep learning) methods\nwithout sacrificing prediction performance. Convolutional Neural Networks\n(CNNs) have been successful in making predictions, especially in image\nclassification. However, these famous deep learning models use tens of millions\nof parameters based on a large number of pre-trained filters which have been\nrepurposed from previous data sets. We propose a novel Interaction-based\nConvolutional Neural Network (ICNN) that does not make assumptions about the\nrelevance of local information. Instead, we use a model-free Influence Score\n(I-score) to directly extract the influential information from images to form\nimportant variable modules. We demonstrate that the proposed method produces\nstate-of-the-art prediction performance of 99.8% on a real-world data set\nclassifying COVID-19 Chest X-ray images without sacrificing the explanatory\npower of the model. This proposed design can efficiently screen COVID-19\npatients before human diagnosis, and will be the benchmark for addressing\nfuture XAI problems in large-scale data sets.",
          "link": "http://arxiv.org/abs/2106.06911",
          "publishedOn": "2021-06-15T01:45:20.380Z",
          "wordCount": 641,
          "title": "An Interaction-based Convolutional Neural Network (ICNN) Towards Better Understanding of COVID-19 X-ray Images. (arXiv:2106.06911v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.12924",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiang_J/0/1/0/all/0/1\">Jinxi Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhuowei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenji Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Q/0/1/0/all/0/1\">Qing Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shaoting Zhang</a>",
          "description": "Deep learning has demonstrated significant improvements in medical image\nsegmentation using a sufficiently large amount of training data with manual\nlabels. Acquiring well-representative labels requires expert knowledge and\nexhaustive labors. In this paper, we aim to boost the performance of\nsemi-supervised learning for medical image segmentation with limited labels\nusing a self-ensembling contrastive learning technique. To this end, we propose\nto train an encoder-decoder network at image-level with small amounts of\nlabeled images, and more importantly, we learn latent representations directly\nat feature-level by imposing contrastive loss on unlabeled images. This method\nstrengthens intra-class compactness and inter-class separability, so as to get\na better pixel classifier. Moreover, we devise a student encoder for online\nlearning and an exponential moving average version of it, called teacher\nencoder, to improve the performance iteratively in a self-ensembling manner. To\nconstruct contrastive samples with unlabeled images, two sampling strategies\nthat exploit structure similarity across medical images and utilize\npseudo-labels for construction, termed region-aware and anatomical-aware\ncontrastive sampling, are investigated. We conduct extensive experiments on an\nMRI and a CT segmentation dataset and demonstrate that in a limited label\nsetting, the proposed method achieves state-of-the-art performance. Moreover,\nthe anatomical-aware strategy that prepares contrastive samples on-the-fly\nusing pseudo-labels realizes better contrastive regularization on feature\nrepresentations.",
          "link": "http://arxiv.org/abs/2105.12924",
          "publishedOn": "2021-06-15T01:45:20.286Z",
          "wordCount": 668,
          "title": "Self-Ensembling Contrastive Learning for Semi-Supervised Medical Image Segmentation. (arXiv:2105.12924v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06856",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Quach_K/0/1/0/all/0/1\">Kha Gia Quach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_P/0/1/0/all/0/1\">Pha Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_H/0/1/0/all/0/1\">Huu Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Truong_T/0/1/0/all/0/1\">Thanh-Dat Truong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duong_C/0/1/0/all/0/1\">Chi Nhan Duong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_M/0/1/0/all/0/1\">Minh-Triet Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luu_K/0/1/0/all/0/1\">Khoa Luu</a>",
          "description": "Multi-Camera Multiple Object Tracking (MC-MOT) is a significant computer\nvision problem due to its emerging applicability in several real-world\napplications. Despite a large number of existing works, solving the data\nassociation problem in any MC-MOT pipeline is arguably one of the most\nchallenging tasks. Developing a robust MC-MOT system, however, is still highly\nchallenging due to many practical issues such as inconsistent lighting\nconditions, varying object movement patterns, or the trajectory occlusions of\nthe objects between the cameras. To address these problems, this work,\ntherefore, proposes a new Dynamic Graph Model with Link Prediction (DyGLIP)\napproach to solve the data association task. Compared to existing methods, our\nnew model offers several advantages, including better feature representations\nand the ability to recover from lost tracks during camera transitions.\nMoreover, our model works gracefully regardless of the overlapping ratios\nbetween the cameras. Experimental results show that we outperform existing\nMC-MOT algorithms by a large margin on several practical datasets. Notably, our\nmodel works favorably on online settings but can be extended to an incremental\napproach for large-scale datasets.",
          "link": "http://arxiv.org/abs/2106.06856",
          "publishedOn": "2021-06-15T01:45:20.274Z",
          "wordCount": 632,
          "title": "DyGLIP: A Dynamic Graph Model with Link Prediction for Accurate Multi-Camera Multiple Object Tracking. (arXiv:2106.06856v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06819",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sinha_A/0/1/0/all/0/1\">Abhishek Sinha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1\">Jiaming Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_C/0/1/0/all/0/1\">Chenlin Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ermon_S/0/1/0/all/0/1\">Stefano Ermon</a>",
          "description": "Conditional generative models of high-dimensional images have many\napplications, but supervision signals from conditions to images can be\nexpensive to acquire. This paper describes Diffusion-Decoding models with\nContrastive representations (D2C), a paradigm for training unconditional\nvariational autoencoders (VAEs) for few-shot conditional image generation. D2C\nuses a learned diffusion-based prior over the latent representations to improve\ngeneration and contrastive self-supervised learning to improve representation\nquality. D2C can adapt to novel generation tasks conditioned on labels or\nmanipulation constraints, by learning from as few as 100 labeled examples. On\nconditional generation from new labels, D2C achieves superior performance over\nstate-of-the-art VAEs and diffusion models. On conditional image manipulation,\nD2C generations are two orders of magnitude faster to produce over StyleGAN2\nones and are preferred by 50% - 60% of the human evaluators in a double-blind\nstudy.",
          "link": "http://arxiv.org/abs/2106.06819",
          "publishedOn": "2021-06-15T01:45:19.652Z",
          "wordCount": null,
          "title": "D2C: Diffusion-Denoising Models for Few-shot Conditional Generation. (arXiv:2106.06819v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06654",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Evtimov_I/0/1/0/all/0/1\">Ivan Evtimov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Covert_I/0/1/0/all/0/1\">Ian Covert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kusupati_A/0/1/0/all/0/1\">Aditya Kusupati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kohno_T/0/1/0/all/0/1\">Tadayoshi Kohno</a>",
          "description": "When data is publicly released for human consumption, it is unclear how to\nprevent its unauthorized usage for machine learning purposes. Successful model\ntraining may be preventable with carefully designed dataset modifications, and\nwe present a proof-of-concept approach for the image classification setting. We\npropose methods based on the notion of adversarial shortcuts, which encourage\nmodels to rely on non-robust signals rather than semantic features, and our\nexperiments demonstrate that these measures successfully prevent deep learning\nmodels from achieving high accuracy on real, unmodified data examples.",
          "link": "http://arxiv.org/abs/2106.06654",
          "publishedOn": "2021-06-15T01:45:19.642Z",
          "wordCount": null,
          "title": "Disrupting Model Training with Adversarial Shortcuts. (arXiv:2106.06654v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2104.10414",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1\">Zhong-Qiu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yao Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1\">Yuchen Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_W/0/1/0/all/0/1\">Weidong Tian</a>",
          "description": "Although deep convolution neural networks (DCNN) have achieved excellent\nperformance in human pose estimation, these networks often have a large number\nof parameters and computations, leading to the slow inference speed. For this\nissue, an effective solution is knowledge distillation, which transfers\nknowledge from a large pre-trained network (teacher) to a small network\n(student). However, there are some defects in the existing approaches: (I) Only\na single teacher is adopted, neglecting the potential that a student can learn\nfrom multiple teachers. (II) The human segmentation mask can be regarded as\nadditional prior information to restrict the location of keypoints, which is\nnever utilized. (III) A student with a small number of parameters cannot fully\nimitate heatmaps provided by datasets and teachers. (IV) There exists noise in\nheatmaps generated by teachers, which causes model degradation. To overcome\nthese defects, we propose an orderly dual-teacher knowledge distillation (ODKD)\nframework, which consists of two teachers with different capabilities.\nSpecifically, the weaker one (primary teacher, PT) is used to teach keypoints\ninformation, the stronger one (senior teacher, ST) is utilized to transfer\nsegmentation and keypoints information by adding the human segmentation mask.\nTaking dual-teacher together, an orderly learning strategy is proposed to\npromote knowledge absorbability. Moreover, we employ a binarization operation\nwhich further improves the learning ability of the student and reduces noise in\nheatmaps. Experimental results on COCO and OCHuman keypoints datasets show that\nour proposed ODKD can improve the performance of different lightweight models\nby a large margin, and HRNet-W16 equipped with ODKD achieves state-of-the-art\nperformance for lightweight human pose estimation.",
          "link": "http://arxiv.org/abs/2104.10414",
          "publishedOn": "2021-06-15T01:45:19.636Z",
          "wordCount": null,
          "title": "Orderly Dual-Teacher Knowledge Distillation for Lightweight Human Pose Estimation. (arXiv:2104.10414v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.04648",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_G/0/1/0/all/0/1\">Guihua Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chapman_A/0/1/0/all/0/1\">Adriane Chapman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_P/0/1/0/all/0/1\">Pei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_M/0/1/0/all/0/1\">Mingnan Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yingxue Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_D/0/1/0/all/0/1\">Dan Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hall_W/0/1/0/all/0/1\">Wendy Hall</a>",
          "description": "Zero-shot learning uses semantic attributes to connect the search space of\nunseen objects. In recent years, although the deep convolutional network brings\npowerful visual modeling capabilities to the ZSL task, its visual features have\nsevere pattern inertia and lack of representation of semantic relationships,\nwhich leads to severe bias and ambiguity. In response to this, we propose the\nGraph-based Visual-Semantic Entanglement Network to conduct graph modeling of\nvisual features, which is mapped to semantic attributes by using a knowledge\ngraph, it contains several novel designs: 1. it establishes a multi-path\nentangled network with the convolutional neural network (CNN) and the graph\nconvolutional network (GCN), which input the visual features from CNN to GCN to\nmodel the implicit semantic relations, then GCN feedback the graph modeled\ninformation to CNN features; 2. it uses attribute word vectors as the target\nfor the graph semantic modeling of GCN, which forms a self-consistent\nregression for graph modeling and supervise GCN to learn more personalized\nattribute relations; 3. it fuses and supplements the hierarchical\nvisual-semantic features refined by graph modeling into visual embedding. Our\nmethod outperforms state-of-the-art approaches on multiple representative ZSL\ndatasets: AwA2, CUB, and SUN by promoting the semantic linkage modelling of\nvisual features.",
          "link": "http://arxiv.org/abs/2006.04648",
          "publishedOn": "2021-06-15T01:45:19.617Z",
          "wordCount": null,
          "title": "Graph-based Visual-Semantic Entanglement Network for Zero-shot Image Recognition. (arXiv:2006.04648v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.02703",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1\">Tong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Ziwei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1\">Qingqiu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_D/0/1/0/all/0/1\">Dahua Lin</a>",
          "description": "Adversarial robustness has attracted extensive studies recently by revealing\nthe vulnerability and intrinsic characteristics of deep networks. However,\nexisting works on adversarial robustness mainly focus on balanced datasets,\nwhile real-world data usually exhibits a long-tailed distribution. To push\nadversarial robustness towards more realistic scenarios, in this work we\ninvestigate the adversarial vulnerability as well as defense under long-tailed\ndistributions. In particular, we first reveal the negative impacts induced by\nimbalanced data on both recognition performance and adversarial robustness,\nuncovering the intrinsic challenges of this problem. We then perform a\nsystematic study on existing long-tailed recognition methods in conjunction\nwith the adversarial training framework. Several valuable observations are\nobtained: 1) natural accuracy is relatively easy to improve, 2) fake gain of\nrobust accuracy exists under unreliable evaluation, and 3) boundary error\nlimits the promotion of robustness. Inspired by these observations, we propose\na clean yet effective framework, RoBal, which consists of two dedicated\nmodules, a scale-invariant classifier and data re-balancing via both margin\nengineering at training stage and boundary adjustment during inference.\nExtensive experiments demonstrate the superiority of our approach over other\nstate-of-the-art defense methods. To our best knowledge, we are the first to\ntackle adversarial robustness under long-tailed distributions, which we believe\nwould be a significant step towards real-world robustness. Our code is\navailable at: https://github.com/wutong16/Adversarial_Long-Tail .",
          "link": "http://arxiv.org/abs/2104.02703",
          "publishedOn": "2021-06-15T01:45:19.612Z",
          "wordCount": null,
          "title": "Adversarial Robustness under Long-Tailed Distribution. (arXiv:2104.02703v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1812.03664",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1\">Han-Jia Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Hexiang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_D/0/1/0/all/0/1\">De-Chuan Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sha_F/0/1/0/all/0/1\">Fei Sha</a>",
          "description": "Learning with limited data is a key challenge for visual recognition. Many\nfew-shot learning methods address this challenge by learning an instance\nembedding function from seen classes and apply the function to instances from\nunseen classes with limited labels. This style of transfer learning is\ntask-agnostic: the embedding function is not learned optimally discriminative\nwith respect to the unseen classes, where discerning among them leads to the\ntarget task. In this paper, we propose a novel approach to adapt the instance\nembeddings to the target classification task with a set-to-set function,\nyielding embeddings that are task-specific and are discriminative. We\nempirically investigated various instantiations of such set-to-set functions\nand observed the Transformer is most effective -- as it naturally satisfies key\nproperties of our desired model. We denote this model as FEAT (few-shot\nembedding adaptation w/ Transformer) and validate it on both the standard\nfew-shot classification benchmark and four extended few-shot learning settings\nwith essential use cases, i.e., cross-domain, transductive, generalized\nfew-shot learning, and low-shot learning. It archived consistent improvements\nover baseline models as well as previous methods and established the new\nstate-of-the-art results on two benchmarks.",
          "link": "http://arxiv.org/abs/1812.03664",
          "publishedOn": "2021-06-15T01:45:19.604Z",
          "wordCount": null,
          "title": "Few-Shot Learning via Embedding Adaptation with Set-to-Set Functions. (arXiv:1812.03664v6 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.06192",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hicsonmez_S/0/1/0/all/0/1\">Samet Hicsonmez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samet_N/0/1/0/all/0/1\">Nermin Samet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akbas_E/0/1/0/all/0/1\">Emre Akbas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duygulu_P/0/1/0/all/0/1\">Pinar Duygulu</a>",
          "description": "We introduce a new method for generating color images from sketches or edge\nmaps. Current methods either require some form of additional user-guidance or\nare limited to the \"paired\" translation approach. We argue that segmentation\ninformation could provide valuable guidance for sketch colorization. To this\nend, we propose to leverage semantic image segmentation, as provided by a\ngeneral purpose panoptic segmentation network, to create an additional\nadversarial loss function. Our loss function can be integrated to any baseline\nGAN model. Our method is not limited to datasets that contain segmentation\nlabels, and it can be trained for \"unpaired\" translation tasks. We show the\neffectiveness of our method on four different datasets spanning scene level\nindoor, outdoor, and children book illustration images using qualitative,\nquantitative and user study analysis. Our model improves its baseline up to 35\npoints on the FID metric. Our code and pretrained models can be found at\nhttps://github.com/giddyyupp/AdvSegLoss.",
          "link": "http://arxiv.org/abs/2102.06192",
          "publishedOn": "2021-06-15T01:45:19.589Z",
          "wordCount": null,
          "title": "Adversarial Segmentation Loss for Sketch Colorization. (arXiv:2102.06192v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.06969",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhengyan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_G/0/1/0/all/0/1\">Guangxuan Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yongwei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_T/0/1/0/all/0/1\">Tian Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_F/0/1/0/all/0/1\">Fanchao Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yasheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1\">Xin Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>",
          "description": "Pre-trained models (PTMs) have been widely used in various downstream tasks.\nThe parameters of PTMs are distributed on the Internet and may suffer backdoor\nattacks. In this work, we demonstrate the universal vulnerability of PTMs,\nwhere fine-tuned PTMs can be easily controlled by backdoor attacks in arbitrary\ndownstream tasks. Specifically, attackers can add a simple pre-training task,\nwhich restricts the output representations of trigger instances to pre-defined\nvectors, namely neuron-level backdoor attack (NeuBA). If the backdoor\nfunctionality is not eliminated during fine-tuning, the triggers can make the\nfine-tuned model predict fixed labels by pre-defined vectors. In the\nexperiments of both natural language processing (NLP) and computer vision (CV),\nwe show that NeuBA absolutely controls the predictions for trigger instances\nwithout any knowledge of downstream tasks. Finally, we apply several defense\nmethods to NeuBA and find that model pruning is a promising direction to resist\nNeuBA by excluding backdoored neurons. Our findings sound a red alarm for the\nwide use of PTMs. Our source code and models are available at\n\\url{https://github.com/thunlp/NeuBA}.",
          "link": "http://arxiv.org/abs/2101.06969",
          "publishedOn": "2021-06-15T01:45:19.587Z",
          "wordCount": null,
          "title": "Red Alarm for Pre-trained Models: Universal Vulnerability to Neuron-Level Backdoor Attacks. (arXiv:2101.06969v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06866",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Reddy_P/0/1/0/all/0/1\">Pradyumna Reddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhifei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fisher_M/0/1/0/all/0/1\">Matthew Fisher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_H/0/1/0/all/0/1\">Hailin Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhaowen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitra_N/0/1/0/all/0/1\">Niloy J. Mitra</a>",
          "description": "Fonts are ubiquitous across documents and come in a variety of styles. They\nare either represented in a native vector format or rasterized to produce fixed\nresolution images. In the first case, the non-standard representation prevents\nbenefiting from latest network architectures for neural representations; while,\nin the latter case, the rasterized representation, when encoded via networks,\nresults in loss of data fidelity, as font-specific discontinuities like edges\nand corners are difficult to represent using neural networks. Based on the\nobservation that complex fonts can be represented by a superposition of a set\nof simpler occupancy functions, we introduce \\textit{multi-implicits} to\nrepresent fonts as a permutation-invariant set of learned implict functions,\nwithout losing features (e.g., edges and corners). However, while\nmulti-implicits locally preserve font features, obtaining supervision in the\nform of ground truth multi-channel signals is a problem in itself. Instead, we\npropose how to train such a representation with only local supervision, while\nthe proposed neural architecture directly finds globally consistent\nmulti-implicits for font families. We extensively evaluate the proposed\nrepresentation for various tasks including reconstruction, interpolation, and\nsynthesis to demonstrate clear advantages with existing alternatives.\nAdditionally, the representation naturally enables glyph completion, wherein a\nsingle characteristic font is used to synthesize a whole font family in the\ntarget style.",
          "link": "http://arxiv.org/abs/2106.06866",
          "publishedOn": "2021-06-15T01:45:19.572Z",
          "wordCount": 643,
          "title": "A Multi-Implicit Neural Representation for Fonts. (arXiv:2106.06866v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10620",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yan_S/0/1/0/all/0/1\">Siming Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhenpei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1\">Chongyang Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Haibin Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vouga_E/0/1/0/all/0/1\">Etienne Vouga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1\">Qixing Huang</a>",
          "description": "This paper introduces HPNet, a novel deep-learning approach for segmenting a\n3D shape represented as a point cloud into primitive patches. The key to deep\nprimitive segmentation is learning a feature representation that can separate\npoints of different primitives. Unlike utilizing a single feature\nrepresentation, HPNet leverages hybrid representations that combine one learned\nsemantic descriptor, two spectral descriptors derived from predicted geometric\nparameters, as well as an adjacency matrix that encodes sharp edges. Moreover,\ninstead of merely concatenating the descriptors, HPNet optimally combines\nhybrid representations by learning combination weights. This weighting module\nbuilds on the entropy of input features. The output primitive segmentation is\nobtained from a mean-shift clustering module. Experimental results on benchmark\ndatasets ANSI and ABCParts show that HPNet leads to significant performance\ngains from baseline approaches.",
          "link": "http://arxiv.org/abs/2105.10620",
          "publishedOn": "2021-06-15T01:45:19.463Z",
          "wordCount": null,
          "title": "HPNet: Deep Primitive Segmentation Using Hybrid Representations. (arXiv:2105.10620v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1906.00460",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Malyshkin_V/0/1/0/all/0/1\">Vladislav Gennadievich Malyshkin</a>",
          "description": "Problems of interpolation, classification, and clustering are considered. In\nthe tenets of Radon--Nikodym approach $\\langle f(\\mathbf{x})\\psi^2 \\rangle /\n\\langle\\psi^2\\rangle$, where the $\\psi(\\mathbf{x})$ is a linear function on\ninput attributes, all the answers are obtained from a generalized eigenproblem\n$|f|\\psi^{[i]}\\rangle = \\lambda^{[i]} |\\psi^{[i]}\\rangle$. The solution to the\ninterpolation problem is a regular Radon-Nikodym derivative. The solution to\nthe classification problem requires prior and posterior probabilities that are\nobtained using the Lebesgue quadrature[1] technique. Whereas in a Bayesian\napproach new observations change only outcome probabilities, in the\nRadon-Nikodym approach not only outcome probabilities but also the probability\nspace $|\\psi^{[i]}\\rangle$ change with new observations. This is a remarkable\nfeature of the approach: both the probabilities and the probability space are\nconstructed from the data. The Lebesgue quadrature technique can be also\napplied to the optimal clustering problem. The problem is solved by\nconstructing a Gaussian quadrature on the Lebesgue measure. A distinguishing\nfeature of the Radon-Nikodym approach is the knowledge of the invariant group:\nall the answers are invariant relatively any non-degenerated linear transform\nof input vector $\\mathbf{x}$ components. A software product implementing the\nalgorithms of interpolation, classification, and optimal clustering is\navailable from the authors.",
          "link": "http://arxiv.org/abs/1906.00460",
          "publishedOn": "2021-06-15T01:45:19.457Z",
          "wordCount": null,
          "title": "On The Radon-Nikodym Spectral Approach With Optimal Clustering. (arXiv:1906.00460v16 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06579",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Venkatesha_Y/0/1/0/all/0/1\">Yeshwanth Venkatesha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Youngeun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tassiulas_L/0/1/0/all/0/1\">Leandros Tassiulas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panda_P/0/1/0/all/0/1\">Priyadarshini Panda</a>",
          "description": "As neural networks get widespread adoption in resource-constrained embedded\ndevices, there is a growing need for low-power neural systems. Spiking Neural\nNetworks (SNNs)are emerging to be an energy-efficient alternative to the\ntraditional Artificial Neural Networks (ANNs) which are known to be\ncomputationally intensive. From an application perspective, as federated\nlearning involves multiple energy-constrained devices, there is a huge scope to\nleverage energy efficiency provided by SNNs. Despite its importance, there has\nbeen little attention on training SNNs on a large-scale distributed system like\nfederated learning. In this paper, we bring SNNs to a more realistic federated\nlearning scenario. Specifically, we propose a federated learning framework for\ndecentralized and privacy-preserving training of SNNs. To validate the proposed\nfederated learning framework, we experimentally evaluate the advantages of SNNs\non various aspects of federated learning with CIFAR10 and CIFAR100 benchmarks.\nWe observe that SNNs outperform ANNs in terms of overall accuracy by over 15%\nwhen the data is distributed across a large number of clients in the federation\nwhile providing up to5.3x energy efficiency. In addition to efficiency, we also\nanalyze the sensitivity of the proposed federated SNN framework to data\ndistribution among the clients, stragglers, and gradient noise and perform a\ncomprehensive comparison with ANNs.",
          "link": "http://arxiv.org/abs/2106.06579",
          "publishedOn": "2021-06-15T01:45:19.397Z",
          "wordCount": null,
          "title": "Federated Learning with Spiking Neural Networks. (arXiv:2106.06579v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06847",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1\">Jiezhang Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yawei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1\">Luc Van Gool</a>",
          "description": "Video super-resolution (VSR), with the aim to restore a high-resolution video\nfrom its corresponding low-resolution version, is a spatial-temporal sequence\nprediction problem. Recently, Transformer has been gaining popularity due to\nits parallel computing ability for sequence-to-sequence modeling. Thus, it\nseems to be straightforward to apply the vision Transformer to solve VSR.\nHowever, the typical block design of Transformer with a fully connected\nself-attention layer and a token-wise feed-forward layer does not fit well for\nVSR due to the following two reasons. First, the fully connected self-attention\nlayer neglects to exploit the data locality because this layer relies on linear\nlayers to compute attention maps. Second, the token-wise feed-forward layer\nlacks the feature alignment which is important for VSR since this layer\nindependently processes each of the input token embeddings without any\ninteraction among them. In this paper, we make the first attempt to adapt\nTransformer for VSR. Specifically, to tackle the first issue, we present a\nspatial-temporal convolutional self-attention layer with a theoretical\nunderstanding to exploit the locality information. For the second issue, we\ndesign a bidirectional optical flow-based feed-forward layer to discover the\ncorrelations across different video frames and also align features. Extensive\nexperiments on several benchmark datasets demonstrate the effectiveness of our\nproposed method. The code will be available at\nhttps://github.com/caojiezhang/VSR-Transformer.",
          "link": "http://arxiv.org/abs/2106.06847",
          "publishedOn": "2021-06-15T01:45:19.384Z",
          "wordCount": 636,
          "title": "Video Super-Resolution Transformer. (arXiv:2106.06847v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00305",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ruis_F/0/1/0/all/0/1\">Frank Ruis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burghouts_G/0/1/0/all/0/1\">Gertjan Burghouts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bucur_D/0/1/0/all/0/1\">Doina Bucur</a>",
          "description": "Humans are good at compositional zero-shot reasoning; someone who has never\nseen a zebra before could nevertheless recognize one when we tell them it looks\nlike a horse with black and white stripes. Machine learning systems, on the\nother hand, usually leverage spurious correlations in the training data, and\nwhile such correlations can help recognize objects in context, they hurt\ngeneralization. To be able to deal with underspecified datasets while still\nleveraging contextual clues during classification, we propose ProtoProp, a\nnovel prototype propagation graph method. First we learn prototypical\nrepresentations of objects (e.g., zebra) that are conditionally independent\nw.r.t. their attribute labels (e.g., stripes) and vice versa. Next we propagate\nthe independent prototypes through a compositional graph, to learn\ncompositional prototypes of novel attribute-object combinations that reflect\nthe dependencies of the target distribution. The method does not rely on any\nexternal data, such as class hierarchy graphs or pretrained word embeddings. We\nevaluate our approach on AO-Clever, a synthetic and strongly visual dataset\nwith clean labels, and UT-Zappos, a noisy real-world dataset of fine-grained\nshoe types. We show that in the generalized compositional zero-shot setting we\noutperform state-of-the-art results, and through ablations we show the\nimportance of each part of the method and their contribution to the final\nresults.",
          "link": "http://arxiv.org/abs/2106.00305",
          "publishedOn": "2021-06-15T01:45:19.291Z",
          "wordCount": null,
          "title": "Independent Prototype Propagation for Zero-Shot Compositionality. (arXiv:2106.00305v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.00268",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Lei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xinyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Li Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1\">Minghan Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jun Li</a>",
          "description": "3D object detection with a single image is an essential and challenging task\nfor autonomous driving. Recently, keypoint-based monocular 3D object detection\nhas made tremendous progress and achieved great speed-accuracy trade-off.\nHowever, there still exists a huge gap with LIDAR-based methods in terms of\naccuracy. To improve their performance without sacrificing efficiency, we\npropose a sort of lightweight feature pyramid network called Lite-FPN to\nachieve multi-scale feature fusion in an effective and efficient way, which can\nboost the multi-scale detection capability of keypoint-based detectors.\nBesides, the misalignment between classification score and localization\nprecision is further relieved by introducing a novel regression loss named\nattention loss. With the proposed loss, predictions with high confidence but\npoor localization are treated with more attention during the training phase.\nComparative experiments based on several state-of-the-art keypoint-based\ndetectors on the KITTI dataset show that our proposed methods manage to achieve\nsignificant improvements in both accuracy and frame rate. The code and\npretrained models will be released at\n\\url{https://github.com/yanglei18/Lite-FPN}.",
          "link": "http://arxiv.org/abs/2105.00268",
          "publishedOn": "2021-06-15T01:45:19.277Z",
          "wordCount": 629,
          "title": "Lite-FPN for Keypoint-based Monocular 3D Object Detection. (arXiv:2105.00268v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.11092",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ye_Y/0/1/0/all/0/1\">Yuanxin Ye</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_C/0/1/0/all/0/1\">Chao Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhu_B/0/1/0/all/0/1\">Bai Zhu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+He_Y/0/1/0/all/0/1\">Youquan He</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jia_H/0/1/0/all/0/1\">Huarong Jia</a>",
          "description": "Co-registering the Sentinel-1 SAR and Sentinel-2 optical data of European\nSpace Agency (ESA) is of great importance for many remote sensing applications.\nHowever, we find that there are evident misregistration shifts between the\nSentinel-1 SAR and Sentinel-2 optical images that are directly downloaded from\nthe official website. To address that, this paper presents a fast and effective\nregistration method for the two types of images. In the proposed method, a\nblock-based scheme is first designed to extract evenly distributed interest\npoints. Then the correspondences are detected by using the similarity of\nstructural features between the SAR and optical images, where the three\ndimension (3D) phase correlation (PC) is used as the similarity measure for\naccelerating image matching. Finally, the obtained correspondences are employed\nto measure the misregistration shifts between the images. Moreover, to\neliminate the misregistration, we use some representative geometric\ntransformation models such as polynomial models, projective models, and\nrational function models for the co-registration of the two types of images,\nand compare and analyze their registration accuracy under different numbers of\ncontrol points and different terrains. Six pairs of the Sentinel-1 SAR L1 and\nSentinel-2 optical L1C images covering three different terrains are tested in\nour experiments. Experimental results show that the proposed method can achieve\nprecise correspondences between the images, and the 3rd. Order polynomial\nachieves the most satisfactory registration results. Its registration accuracy\nof the flat areas is less than 1.0 10m pixels, and that of the hilly areas is\nabout 1.5 10m pixels, and that of the mountainous areas is between 1.7 and 2.3\n10m pixels, which significantly improves the co-registration accuracy of the\nSentinel-1 SAR and Sentinel-2 optical images.",
          "link": "http://arxiv.org/abs/2005.11092",
          "publishedOn": "2021-06-15T01:45:19.241Z",
          "wordCount": 734,
          "title": "Improving Co-registration for Sentinel-1 SAR and Sentinel-2 Optical images. (arXiv:2005.11092v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06743",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Varmazyar_H/0/1/0/all/0/1\">Hadi Varmazyar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yousefi_Banaem_H/0/1/0/all/0/1\">Hossein Yousefi-Banaem</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Malekzadeh_S/0/1/0/all/0/1\">Saber Malekzadeh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gharehaghaji_N/0/1/0/all/0/1\">Nahideh Gharehaghaji</a>",
          "description": "Background: Alzheimers disease is a progressive neurodegenerative disorder\nand the main cause of dementia in aging. Hippocampus is prone to changes in the\nearly stages of Alzheimers disease. Detection and observation of the\nhippocampus changes using magnetic resonance imaging (MRI) before the onset of\nAlzheimers disease leads to the faster preventive and therapeutic measures.\nObjective: The aim of this study was the segmentation of the hippocampus in\nmagnetic resonance (MR) images of Alzheimers patients using deep machine\nlearning method. Methods: U-Net architecture of convolutional neural network\nwas proposed to segment the hippocampus in the real MRI data. The MR images of\nthe 100 and 35 patients available in Alzheimers disease Neuroimaging Initiative\n(ADNI) dataset, was used for the train and test of the model, respectively. The\nperformance of the proposed method was compared with manual segmentation by\nmeasuring the similarity metrics. Results: The desired segmentation achieved\nafter 10 iterations. A Dice similarity coefficient (DSC) = 92.3%, sensitivity =\n96.5%, positive predicted value (PPV) = 90.4%, and Intersection over Union\n(IoU) value for the train 92.94 and test 92.93 sets were obtained which are\nacceptable. Conclusion: The proposed approach is promising and can be extended\nin the prognosis of Alzheimers disease by the prediction of the hippocampus\nvolume changes in the early stage of the disease.",
          "link": "http://arxiv.org/abs/2106.06743",
          "publishedOn": "2021-06-15T01:45:19.102Z",
          "wordCount": 674,
          "title": "Hippocampus segmentation in magnetic resonance images of Alzheimer's patients using Deep machine learning. (arXiv:2106.06743v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2101.04230",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singla_S/0/1/0/all/0/1\">Sumedha Singla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pollack_B/0/1/0/all/0/1\">Brian Pollack</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wallace_S/0/1/0/all/0/1\">Stephen Wallace</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Batmanghelich_K/0/1/0/all/0/1\">Kayhan Batmanghelich</a>",
          "description": "We propose a BlackBox \\emph{Counterfactual Explainer} that is explicitly\ndeveloped for medical imaging applications. Classical approaches (e.g. saliency\nmaps) assessing feature importance do not explain \\emph{how} and \\emph{why}\nvariations in a particular anatomical region is relevant to the outcome, which\nis crucial for transparent decision making in healthcare application. Our\nframework explains the outcome by gradually \\emph{exaggerating} the semantic\neffect of the given outcome label. Given a query input to a classifier,\nGenerative Adversarial Networks produce a progressive set of perturbations to\nthe query image that gradually changes the posterior probability from its\noriginal class to its negation. We design the loss function to ensure that\nessential and potentially relevant details, such as support devices, are\npreserved in the counterfactually generated images. We provide an extensive\nevaluation of different classification tasks on the chest X-Ray images. Our\nexperiments show that a counterfactually generated visual explanation is\nconsistent with the disease's clinical relevant measurements, both\nquantitatively and qualitatively.",
          "link": "http://arxiv.org/abs/2101.04230",
          "publishedOn": "2021-06-15T01:45:19.036Z",
          "wordCount": 624,
          "title": "Explaining the Black-box Smoothly- A Counterfactual Approach. (arXiv:2101.04230v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.12854",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Wu_Z/0/1/0/all/0/1\">Zhaolong Wu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhang_S/0/1/0/all/0/1\">Shuwen Zhang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Wang_W/0/1/0/all/0/1\">Wei Li Wang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ma_Y/0/1/0/all/0/1\">Yinping Ma</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Dong_Y/0/1/0/all/0/1\">Yuanchen Dong</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Mao_Y/0/1/0/all/0/1\">Youdong Mao</a>",
          "description": "The 2.5-MDa 26S proteasome maintains proteostasis and regulates myriad\ncellular processes. How polyubiquitylated substrate interactions regulate\nproteasome activity is not understood. Here we introduce a deep manifold\nlearning framework, named AlphaCryo4D, which enables atomic-level cryogenic\nelectron microscopy (cryo-EM) reconstructions of nonequilibrium conformational\ncontinuum and reconstitutes hidden dynamics of proteasome autoregulation in the\nact of substrate degradation. AlphaCryo4D integrates 3D deep residual learning\nwith manifold embedding of free-energy landscapes, which directs 3D clustering\nvia an energy-based particle-voting algorithm. In blind assessments using\nsimulated heterogeneous cryo-EM datasets, AlphaCryo4D achieved 3D\nclassification accuracy three times that of conventional method and\nreconstructed continuous conformational changes of a 130-kDa protein at\nsub-3-angstrom resolution. By using AlphaCryo4D to analyze a single\nexperimental cryo-EM dataset, we identified 64 conformers of the\nsubstrate-bound human 26S proteasome, revealing conformational entanglement of\ntwo regulatory particles in the doubly capped holoenzymes and their energetic\ndifferences with singly capped ones. Novel ubiquitin-binding sites are\ndiscovered on the RPN2, RPN10 and Alpha5 subunits to remodel polyubiquitin\nchains for deubiquitylation and recycle. Importantly, AlphaCryo4D choreographs\nsingle-nucleotide-exchange dynamics of proteasomal AAA-ATPase motor during\ntranslocation initiation, which upregulates proteolytic activity by\nallosterically promoting nucleophilic attack. Our systemic analysis illuminates\na grand hierarchical allostery for proteasome autoregulation.",
          "link": "http://arxiv.org/abs/2012.12854",
          "publishedOn": "2021-06-15T01:45:18.985Z",
          "wordCount": 671,
          "title": "Deep manifold learning reveals hidden dynamics of proteasome autoregulation. (arXiv:2012.12854v2 [q-bio.QM] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06560",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1\">Mingyu Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lian_X/0/1/0/all/0/1\">Xiaochen Lian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Linjie Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Peng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1\">Xiaojie Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1\">Zhiwu Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_P/0/1/0/all/0/1\">Ping Luo</a>",
          "description": "High-resolution representations (HR) are essential for dense prediction tasks\nsuch as segmentation, detection, and pose estimation. Learning HR\nrepresentations is typically ignored in previous Neural Architecture Search\n(NAS) methods that focus on image classification. This work proposes a novel\nNAS method, called HR-NAS, which is able to find efficient and accurate\nnetworks for different tasks, by effectively encoding multiscale contextual\ninformation while maintaining high-resolution representations. In HR-NAS, we\nrenovate the NAS search space as well as its searching strategy. To better\nencode multiscale image contexts in the search space of HR-NAS, we first\ncarefully design a lightweight transformer, whose computational complexity can\nbe dynamically changed with respect to different objective functions and\ncomputation budgets. To maintain high-resolution representations of the learned\nnetworks, HR-NAS adopts a multi-branch architecture that provides convolutional\nencoding of multiple feature resolutions, inspired by HRNet. Last, we proposed\nan efficient fine-grained search strategy to train HR-NAS, which effectively\nexplores the search space, and finds optimal architectures given various tasks\nand computation resources. HR-NAS is capable of achieving state-of-the-art\ntrade-offs between performance and FLOPs for three dense prediction tasks and\nan image classification task, given only small computational budgets. For\nexample, HR-NAS surpasses SqueezeNAS that is specially designed for semantic\nsegmentation while improving efficiency by 45.9%. Code is available at\nhttps://github.com/dingmyu/HR-NAS",
          "link": "http://arxiv.org/abs/2106.06560",
          "publishedOn": "2021-06-15T01:45:18.890Z",
          "wordCount": 659,
          "title": "HR-NAS: Searching Efficient High-Resolution Neural Architectures with Lightweight Transformers. (arXiv:2106.06560v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06817",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1\">Yize Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patney_A/0/1/0/all/0/1\">Anjul Patney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bovik_A/0/1/0/all/0/1\">Alan Bovik</a>",
          "description": "Virtual Reality is regaining attention due to recent advancements in hardware\ntechnology. Immersive images / videos are becoming widely adopted to carry\nomnidirectional visual information. However, due to the requirements for higher\nspatial and temporal resolution of real video data, immersive videos require\nsignificantly larger bandwidth consumption. To reduce stresses on bandwidth,\nfoveated video compression is regaining popularity, whereby the space-variant\nspatial resolution of the retina is exploited. Towards advancing the progress\nof foveated video compression, we propose a full reference (FR) foveated image\nquality assessment algorithm, which we call foveated entropic differencing\n(FED), which employs the natural scene statistics of bandpass responses by\napplying differences of local entropies weighted by a foveation-based error\nsensitivity function. We evaluate the proposed algorithm by measuring the\ncorrelations of the predictions that FED makes against human judgements on the\nnewly created 2D and 3D LIVE-FBT-FCVR databases for Virtual Reality (VR). The\nperformance of the proposed algorithm yields state-of-the-art as compared with\nother existing full reference algorithms. Software for FED has been made\navailable at: this http URL",
          "link": "http://arxiv.org/abs/2106.06817",
          "publishedOn": "2021-06-15T01:45:18.857Z",
          "wordCount": 600,
          "title": "Evaluating Foveated Video Quality Using Entropic Differencing. (arXiv:2106.06817v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2012.03408",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wen_X/0/1/0/all/0/1\">Xin Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_P/0/1/0/all/0/1\">Peng Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1\">Zhizhong Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yan-Pei Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_P/0/1/0/all/0/1\">Pengfei Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_W/0/1/0/all/0/1\">Wen Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yu-Shen Liu</a>",
          "description": "The task of point cloud completion aims to predict the missing part for an\nincomplete 3D shape. A widely used strategy is to generate a complete point\ncloud from the incomplete one. However, the unordered nature of point clouds\nwill degrade the generation of high-quality 3D shapes, as the detailed topology\nand structure of discrete points are hard to be captured by the generative\nprocess only using a latent code. In this paper, we address the above problem\nby reconsidering the completion task from a new perspective, where we formulate\nthe prediction as a point cloud deformation process. Specifically, we design a\nnovel neural network, named PMP-Net, to mimic the behavior of an earth mover.\nIt moves each point of the incomplete input to complete the point cloud, where\nthe total distance of point moving paths (PMP) should be shortest. Therefore,\nPMP-Net predicts a unique point moving path for each point according to the\nconstraint of total point moving distances. As a result, the network learns a\nstrict and unique correspondence on point-level, which can capture the detailed\ntopology and structure relationships between the incomplete shape and the\ncomplete target, and thus improves the quality of the predicted complete shape.\nWe conduct comprehensive experiments on Completion3D and PCN datasets, which\ndemonstrate our advantages over the state-of-the-art point cloud completion\nmethods.",
          "link": "http://arxiv.org/abs/2012.03408",
          "publishedOn": "2021-06-15T01:45:18.828Z",
          "wordCount": 704,
          "title": "PMP-Net: Point Cloud Completion by Learning Multi-step Point Moving Paths. (arXiv:2012.03408v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.09670",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Croce_F/0/1/0/all/0/1\">Francesco Croce</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andriushchenko_M/0/1/0/all/0/1\">Maksym Andriushchenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sehwag_V/0/1/0/all/0/1\">Vikash Sehwag</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Debenedetti_E/0/1/0/all/0/1\">Edoardo Debenedetti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Flammarion_N/0/1/0/all/0/1\">Nicolas Flammarion</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiang_M/0/1/0/all/0/1\">Mung Chiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mittal_P/0/1/0/all/0/1\">Prateek Mittal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hein_M/0/1/0/all/0/1\">Matthias Hein</a>",
          "description": "As a research community, we are still lacking a systematic understanding of\nthe progress on adversarial robustness, which often makes it hard to identify\nthe most promising ideas in training robust models. A key challenge in\nbenchmarking robustness is that its evaluation is often error-prone, leading to\noverestimation of the true robustness of models. While adaptive attacks\ndesigned for a particular defense are a potential solution, they have to be\nhighly customized for particular models, which makes it difficult to compare\ndifferent methods. Our goal is to instead establish a standardized benchmark of\nadversarial robustness, which as accurately as possible reflects the robustness\nof the considered models within a reasonable computational budget. To evaluate\nthe robustness of models for our benchmark, we consider AutoAttack, an ensemble\nof white- and black-box attacks which was recently shown in a large-scale study\nto improve almost all robustness evaluations compared to the original\npublications. We also impose some restrictions on the admitted models to rule\nout defenses that only make gradient-based attacks ineffective without\nimproving actual robustness. Our leaderboard, hosted at\nhttps://robustbench.github.io/, contains evaluations of 90+ models and aims at\nreflecting the current state of the art on a set of well-defined tasks in\n$\\ell_\\infty$- and $\\ell_2$-threat models and on common corruptions, with\npossible extensions in the future. Additionally, we open-source the library\nhttps://github.com/RobustBench/robustbench that provides unified access to 60+\nrobust models to facilitate their downstream applications. Finally, based on\nthe collected models, we analyze the impact of robustness on the performance on\ndistribution shifts, calibration, out-of-distribution detection, fairness,\nprivacy leakage, smoothness, and transferability.",
          "link": "http://arxiv.org/abs/2010.09670",
          "publishedOn": "2021-06-15T01:45:18.388Z",
          "wordCount": 763,
          "title": "RobustBench: a standardized adversarial robustness benchmark. (arXiv:2010.09670v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06742",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Feng_C/0/1/0/all/0/1\">Chun-Mei Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1\">Yunlu Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_H/0/1/0/all/0/1\">Huazhu Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Li Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yong Xu</a>",
          "description": "The core problem of Magnetic Resonance Imaging (MRI) is the trade off between\nacceleration and image quality. Image reconstruction and super-resolution are\ntwo crucial techniques in Magnetic Resonance Imaging (MRI). Current methods are\ndesigned to perform these tasks separately, ignoring the correlations between\nthem. In this work, we propose an end-to-end task transformer network\n(T$^2$Net) for joint MRI reconstruction and super-resolution, which allows\nrepresentations and feature transmission to be shared between multiple task to\nachieve higher-quality, super-resolved and motion-artifacts-free images from\nhighly undersampled and degenerated MRI data. Our framework combines both\nreconstruction and super-resolution, divided into two sub-branches, whose\nfeatures are expressed as queries and keys. Specifically, we encourage joint\nfeature learning between the two tasks, thereby transferring accurate task\ninformation. We first use two separate CNN branches to extract task-specific\nfeatures. Then, a task transformer module is designed to embed and synthesize\nthe relevance between the two tasks. Experimental results show that our\nmulti-task model significantly outperforms advanced sequential methods, both\nquantitatively and qualitatively.",
          "link": "http://arxiv.org/abs/2106.06742",
          "publishedOn": "2021-06-15T01:45:18.279Z",
          "wordCount": 611,
          "title": "Task Transformer Network for Joint MRI Reconstruction and Super-Resolution. (arXiv:2106.06742v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00671",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khazatsky_A/0/1/0/all/0/1\">Alexander Khazatsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nair_A/0/1/0/all/0/1\">Ashvin Nair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jing_D/0/1/0/all/0/1\">Daniel Jing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1\">Sergey Levine</a>",
          "description": "A generalist robot equipped with learned skills must be able to perform many\ntasks in many different environments. However, zero-shot generalization to new\nsettings is not always possible. When the robot encounters a new environment or\nobject, it may need to finetune some of its previously learned skills to\naccommodate this change. But crucially, previously learned behaviors and models\nshould still be suitable to accelerate this relearning. In this paper, we aim\nto study how generative models of possible outcomes can allow a robot to learn\nvisual representations of affordances, so that the robot can sample potentially\npossible outcomes in new situations, and then further train its policy to\nachieve those outcomes. In effect, prior data is used to learn what kinds of\noutcomes may be possible, such that when the robot encounters an unfamiliar\nsetting, it can sample potential outcomes from its model, attempt to reach\nthem, and thereby update both its skills and its outcome model. This approach,\nvisuomotor affordance learning (VAL), can be used to train goal-conditioned\npolicies that operate on raw image inputs, and can rapidly learn to manipulate\nnew objects via our proposed affordance-directed exploration scheme. We show\nthat VAL can utilize prior data to solve real-world tasks such drawer opening,\ngrasping, and placing objects in new scenes with only five minutes of online\nexperience in the new scene.",
          "link": "http://arxiv.org/abs/2106.00671",
          "publishedOn": "2021-06-15T01:45:18.003Z",
          "wordCount": 696,
          "title": "What Can I Do Here? Learning New Skills by Imagining Visual Affordances. (arXiv:2106.00671v2 [cs.RO] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.12100",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Chen_X/0/1/0/all/0/1\">Xiang Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huang_Y/0/1/0/all/0/1\">Yufeng Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_L/0/1/0/all/0/1\">Lei Xu</a>",
          "description": "Rain streaks bring serious blurring and visual quality degradation, which\noften vary in size, direction and density. Current CNN-based methods achieve\nencouraging performance, while are limited to depict rain characteristics and\nrecover image details in the poor visibility environment. To address these\nissues, we present a Multi-scale Hourglass Hierarchical Fusion Network\n(MH2F-Net) in end-to-end manner, to exactly captures rain streak features with\nmulti-scale extraction, hierarchical distillation and information aggregation.\nFor better extracting the features, a novel Multi-scale Hourglass Extraction\nBlock (MHEB) is proposed to get local and global features across different\nscales through down- and up-sample process. Besides, a Hierarchical Attentive\nDistillation Block (HADB) then employs the dual attention feature responses to\nadaptively recalibrate the hierarchical features and eliminate the redundant\nones. Further, we introduce a Residual Projected Feature Fusion (RPFF) strategy\nto progressively discriminate feature learning and aggregate different features\ninstead of directly concatenating or adding. Extensive experiments on both\nsynthetic and real rainy datasets demonstrate the effectiveness of the designed\nMH2F-Net by comparing with recent state-of-the-art deraining algorithms. Our\nsource code will be available on the GitHub:\nhttps://github.com/cxtalk/MH2F-Net.",
          "link": "http://arxiv.org/abs/2104.12100",
          "publishedOn": "2021-06-15T01:45:17.405Z",
          "wordCount": 642,
          "title": "Multi-Scale Hourglass Hierarchical Fusion Network for Single Image Deraining. (arXiv:2104.12100v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2001.06372",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sumbul_G/0/1/0/all/0/1\">Gencer Sumbul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_J/0/1/0/all/0/1\">Jian Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kreuziger_T/0/1/0/all/0/1\">Tristan Kreuziger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marcelino_F/0/1/0/all/0/1\">Filipe Marcelino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Costa_H/0/1/0/all/0/1\">Hugo Costa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benevides_P/0/1/0/all/0/1\">Pedro Benevides</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caetano_M/0/1/0/all/0/1\">Mario Caetano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Demir_B/0/1/0/all/0/1\">Beg&#xfc;m Demir</a>",
          "description": "This paper presents BigEarthNet that is a large-scale Sentinel-2\nmultispectral image dataset with a new class nomenclature to advance deep\nlearning (DL) studies in remote sensing (RS). BigEarthNet is made up of 590,326\nimage patches annotated with multi-labels provided by the CORINE Land Cover\n(CLC) map of 2018 based on its most thematic detailed Level-3 class\nnomenclature. Initial research demonstrates that some CLC classes are\nchallenging to be accurately described by considering only Sentinel-2 images.\nTo increase the effectiveness of BigEarthNet, in this paper we introduce an\nalternative class-nomenclature to allow DL models for better learning and\ndescribing the complex spatial and spectral information content of the\nSentinel-2 images. This is achieved by interpreting and arranging the CLC\nLevel-3 nomenclature based on the properties of Sentinel-2 images in a new\nnomenclature of 19 classes. Then, the new class-nomenclature of BigEarthNet is\nused within state-of-the-art DL models in the context of multi-label\nclassification. Results show that the models trained from scratch on\nBigEarthNet outperform those pre-trained on ImageNet, especially in relation to\nsome complex classes including agriculture, other vegetated and natural\nenvironments. All DL models are made publicly available at\nthis http URL, offering an important resource to guide future\nprogress on RS image analysis.",
          "link": "http://arxiv.org/abs/2001.06372",
          "publishedOn": "2021-06-15T01:45:17.272Z",
          "wordCount": 705,
          "title": "BigEarthNet Dataset with A New Class-Nomenclature for Remote Sensing Image Understanding. (arXiv:2001.06372v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06992",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Feihong_L/0/1/0/all/0/1\">Liu Feihong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Junwei_Y/0/1/0/all/0/1\">Yang Junwei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiaowei_H/0/1/0/all/0/1\">He Xiaowei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luping_Z/0/1/0/all/0/1\">Zhou Luping</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jun_F/0/1/0/all/0/1\">Feng Jun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dinggang_S/0/1/0/all/0/1\">Shen Dinggang</a>",
          "description": "Being complex-valued and low in signal-to-noise ratios, magnitude-based\ndiffusion MRI is confounded by the noise-floor that falsely elevates signal\nmagnitude and incurs bias to the commonly used diffusion indices, such as\nfractional anisotropy (FA). To avoid noise-floor, most existing phase\ncorrection methods explore improving filters to estimate the noise-free\nbackground phase. In this work, after diving into the phase correction\nprocedures, we argue that even a perfect filter is insufficient for phase\ncorrection because the correction procedures are incapable of distinguishing\nsign-symbols of noise, resulting in artifacts (\\textit{i.e.}, arbitrary signal\nloss). With this insight, we generalize the definition of noise-floor to a\ncomplex polar coordinate system and propose a calibration procedure that could\nconveniently distinguish noise sign symbols. The calibration procedure is\nconceptually simple and easy to implement without relying on any external\ntechnique while keeping distinctly effective.",
          "link": "http://arxiv.org/abs/2106.06992",
          "publishedOn": "2021-06-15T01:45:17.265Z",
          "wordCount": 585,
          "title": "Is Perfect Filtering Enough Leading to Perfect Phase Correction for dMRI data?. (arXiv:2106.06992v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2006.09179",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Buzzicotti_M/0/1/0/all/0/1\">M. Buzzicotti</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Bonaccorso_F/0/1/0/all/0/1\">F. Bonaccorso</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Leoni_P/0/1/0/all/0/1\">P. Clark Di Leoni</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Biferale_L/0/1/0/all/0/1\">L. Biferale</a>",
          "description": "We study the applicability of tools developed by the computer vision\ncommunity for features learning and semantic image inpainting to perform data\nreconstruction of fluid turbulence configurations. The aim is twofold. First,\nwe explore on a quantitative basis, the capability of Convolutional Neural\nNetworks embedded in a Deep Generative Adversarial Model (Deep-GAN) to generate\nmissing data in turbulence, a paradigmatic high dimensional chaotic system. In\nparticular, we investigate their use in reconstructing two-dimensional damaged\nsnapshots extracted from a large database of numerical configurations of 3d\nturbulence in the presence of rotation, a case with multi-scale random features\nwhere both large-scale organised structures and small-scale highly intermittent\nand non-Gaussian fluctuations are present. Second, following a reverse\nengineering approach, we aim to rank the input flow properties (features) in\nterms of their qualitative and quantitative importance to obtain a better set\nof reconstructed fields. We present two approaches both based on Context\nEncoders. The first one infers the missing data via a minimization of the L2\npixel-wise reconstruction loss, plus a small adversarial penalisation. The\nsecond searches for the closest encoding of the corrupted flow configuration\nfrom a previously trained generator. Finally, we present a comparison with a\ndifferent data assimilation tool, based on Nudging, an equation-informed\nunbiased protocol, well known in the numerical weather prediction community.\nThe TURB-Rot database, this http URL, of roughly 300K 2d\nturbulent images is released and details on how to download it are given.",
          "link": "http://arxiv.org/abs/2006.09179",
          "publishedOn": "2021-06-15T01:45:17.173Z",
          "wordCount": 723,
          "title": "Reconstruction of turbulent data with deep generative models for semantic inpainting from TURB-Rot database. (arXiv:2006.09179v2 [physics.flu-dyn] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06980",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Panicker_M/0/1/0/all/0/1\">Mahesh Raveendranatha Panicker</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_Y/0/1/0/all/0/1\">Yale Tung Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+M_G/0/1/0/all/0/1\">Gayathri M</a>, <a href=\"http://arxiv.org/find/eess/1/au:+N_M/0/1/0/all/0/1\">Madhavanunni A N</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Narayan_K/0/1/0/all/0/1\">Kiran Vishnu Narayan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kesavadas_C/0/1/0/all/0/1\">C Kesavadas</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Vinod_A/0/1/0/all/0/1\">A P Vinod</a>",
          "description": "Ultrasound is fast becoming an inevitable diagnostic tool for regular and\ncontinuous monitoring of the lung with the recent outbreak of COVID-19. In this\nwork, a novel approach is presented to extract acoustic propagation-based\nfeatures to automatically highlight the region below pleura, which is an\nimportant landmark in lung ultrasound (LUS). Subsequently, a multichannel input\nformed by using the acoustic physics-based feature maps is fused to train a\nneural network, referred to as LUSNet, to classify the LUS images into five\nclasses of varying severity of lung infection to track the progression of\nCOVID-19. In order to ensure that the proposed approach is agnostic to the type\nof acquisition, the LUSNet, which consists of a U-net architecture is trained\nin an unsupervised manner with the acoustic feature maps to ensure that the\nencoder-decoder architecture is learning features in the pleural region of\ninterest. A novel combination of the U-net output and the U-net encoder output\nis employed for the classification of severity of infection in the lung. A\ndetailed analysis of the proposed approach on LUS images over the infection to\nfull recovery period of ten confirmed COVID-19 subjects shows an average\nfive-fold cross-validation accuracy, sensitivity, and specificity of 97%, 93%,\nand 98% respectively over 5000 frames of COVID-19 videos. The analysis also\nshows that, when the input dataset is limited and diverse as in the case of\nCOVID-19 pandemic, an aided effort of combining acoustic propagation-based\nfeatures along with the gray scale images, as proposed in this work, improves\nthe performance of the neural network significantly and also aids the labelling\nand triaging process.",
          "link": "http://arxiv.org/abs/2106.06980",
          "publishedOn": "2021-06-15T01:45:17.157Z",
          "wordCount": 790,
          "title": "An Approach Towards Physics Informed Lung Ultrasound Image Scoring Neural Network for Diagnostic Assistance in COVID-19. (arXiv:2106.06980v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.08949",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Feng_C/0/1/0/all/0/1\">Chun-Mei Feng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fu_H/0/1/0/all/0/1\">Huazhu Fu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yuan_S/0/1/0/all/0/1\">Shuhao Yuan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_Y/0/1/0/all/0/1\">Yong Xu</a>",
          "description": "Super-resolution (SR) plays a crucial role in improving the image quality of\nmagnetic resonance imaging (MRI). MRI produces multi-contrast images and can\nprovide a clear display of soft tissues. However, current super-resolution\nmethods only employ a single contrast, or use a simple multi-contrast fusion\nmechanism, ignoring the rich relations among different contrasts, which are\nvaluable for improving SR. In this work, we propose a multi-stage integration\nnetwork (i.e., MINet) for multi-contrast MRI SR, which explicitly models the\ndependencies between multi-contrast images at different stages to guide image\nSR. In particular, our MINet first learns a hierarchical feature representation\nfrom multiple convolutional stages for each of different-contrast image.\nSubsequently, we introduce a multi-stage integration module to mine the\ncomprehensive relations between the representations of the multi-contrast\nimages. Specifically, the module matches each representation with all other\nfeatures, which are integrated in terms of their similarities to obtain an\nenriched representation. Extensive experiments on fastMRI and real-world\nclinical datasets demonstrate that 1) our MINet outperforms state-of-the-art\nmulti-contrast SR methods in terms of various metrics and 2) our multi-stage\nintegration module is able to excavate complex interactions among\nmulti-contrast features at different stages, leading to improved target-image\nquality.",
          "link": "http://arxiv.org/abs/2105.08949",
          "publishedOn": "2021-06-15T01:45:17.001Z",
          "wordCount": 668,
          "title": "Multi-Contrast MRI Super-Resolution via a Multi-Stage Integration Network. (arXiv:2105.08949v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09356",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rezaei_S/0/1/0/all/0/1\">Seyed Saeed Changiz Rezaei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_F/0/1/0/all/0/1\">Fred X. Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_D/0/1/0/all/0/1\">Di Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salameh_M/0/1/0/all/0/1\">Mohammad Salameh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mills_K/0/1/0/all/0/1\">Keith Mills</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lian_S/0/1/0/all/0/1\">Shuo Lian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1\">Wei Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jui_S/0/1/0/all/0/1\">Shangling Jui</a>",
          "description": "Despite the empirical success of neural architecture search (NAS) in deep\nlearning applications, the optimality, reproducibility and cost of NAS schemes\nremain hard to assess. In this paper, we propose Generative Adversarial NAS\n(GA-NAS) with theoretically provable convergence guarantees, promoting\nstability and reproducibility in neural architecture search. Inspired by\nimportance sampling, GA-NAS iteratively fits a generator to previously\ndiscovered top architectures, thus increasingly focusing on important parts of\na large search space. Furthermore, we propose an efficient adversarial learning\napproach, where the generator is trained by reinforcement learning based on\nrewards provided by a discriminator, thus being able to explore the search\nspace without evaluating a large number of architectures. Extensive experiments\nshow that GA-NAS beats the best published results under several cases on three\npublic NAS benchmarks. In the meantime, GA-NAS can handle ad-hoc search\nconstraints and search spaces. We show that GA-NAS can be used to improve\nalready optimized baselines found by other NAS methods, including EfficientNet\nand ProxylessNAS, in terms of ImageNet accuracy or the number of parameters, in\ntheir original search space.",
          "link": "http://arxiv.org/abs/2105.09356",
          "publishedOn": "2021-06-15T01:45:16.975Z",
          "wordCount": 655,
          "title": "Generative Adversarial Neural Architecture Search. (arXiv:2105.09356v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06726",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1\">Xuan Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1\">Tianshu Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaomin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1\">Jiali Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Minghui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Ming Liu</a>",
          "description": "Regularization and data augmentation methods have been widely used and become\nincreasingly indispensable in deep learning training. Researchers who devote\nthemselves to this have considered various possibilities. But so far, there has\nbeen little discussion about regularizing outputs of the model. This paper\nbegins with empirical observations that better performances are significantly\nassociated with output distributions, that have smaller average values and\nvariances. By audaciously assuming there is causality involved, we propose a\nnovel regularization term, called Output Decay, that enforces the model to\nassign smaller and similar output values on each class. Though being\ncounter-intuitive, such a small modification result in a remarkable improvement\non performance. Extensive experiments demonstrate the wide applicability,\nversatility, and compatibility of Output Decay.",
          "link": "http://arxiv.org/abs/2106.06726",
          "publishedOn": "2021-06-15T01:45:16.943Z",
          "wordCount": 559,
          "title": "Go Small and Similar: A Simple Output Decay Brings Better Performance. (arXiv:2106.06726v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2103.07838",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wen_X/0/1/0/all/0/1\">Xin Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1\">Zhizhong Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yan-Pei Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_P/0/1/0/all/0/1\">Pengfei Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_W/0/1/0/all/0/1\">Wen Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yu-Shen Liu</a>",
          "description": "In this paper, we present a novel unpaired point cloud completion network,\nnamed Cycle4Completion, to infer the complete geometries from a partial 3D\nobject. Previous unpaired completion methods merely focus on the learning of\ngeometric correspondence from incomplete shapes to complete shapes, and ignore\nthe learning in the reverse direction, which makes them suffer from low\ncompletion accuracy due to the limited 3D shape understanding ability. To\naddress this problem, we propose two simultaneous cycle transformations between\nthe latent spaces of complete shapes and incomplete ones. The insight of cycle\ntransformation is to promote networks to understand 3D shapes by learning to\ngenerate complete or incomplete shapes from their complementary ones.\nSpecifically, the first cycle transforms shapes from incomplete domain to\ncomplete domain, and then projects them back to the incomplete domain. This\nprocess learns the geometric characteristic of complete shapes, and maintains\nthe shape consistency between the complete prediction and the incomplete input.\nSimilarly, the inverse cycle transformation starts from complete domain to\nincomplete domain, and goes back to complete domain to learn the characteristic\nof incomplete shapes. We provide a comprehensive evaluation in experiments,\nwhich shows that our model with the learned bidirectional geometry\ncorrespondence outperforms state-of-the-art unpaired completion methods.",
          "link": "http://arxiv.org/abs/2103.07838",
          "publishedOn": "2021-06-15T01:45:16.919Z",
          "wordCount": 679,
          "title": "Cycle4Completion: Unpaired Point Cloud Completion using Cycle Transformation with Missing Region Coding. (arXiv:2103.07838v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1904.01636",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vorontsov_E/0/1/0/all/0/1\">Eugene Vorontsov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Molchanov_P/0/1/0/all/0/1\">Pavlo Molchanov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beckham_C/0/1/0/all/0/1\">Christopher Beckham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kautz_J/0/1/0/all/0/1\">Jan Kautz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kadoury_S/0/1/0/all/0/1\">Samuel Kadoury</a>",
          "description": "Often in medical imaging, it is prohibitively challenging to produce enough\nboundary annotations to train deep neural networks for accurate tumor\nsegmentation. We propose the use of weak labels about whether an image presents\ntumor or whether it is absent to extend training over images that lack these\nannotations. Specifically, we propose a semi-supervised framework that employs\nunpaired image-to-image translation between two domains, presence vs. absence\nof cancer, as the unsupervised objective. We conjecture that translation helps\nsegmentation -- both require the target to be separated from the background. We\nencode images into two codes: one that is common to both domains and one that\nis unique to the presence domain. Decoding from the common code yields healthy\nimages; decoding with the addition of the unique code produces a residual\nchange to this image that adds cancer. Translation proceeds from presence to\nabsence and vice versa. In the first case, the tumor is re-added to the image\nand we successfully exploit the residual decoder to also perform segmentation.\nIn the second case, unique codes are sampled, producing a distribution of\npossible tumors. To validate the method, we created challenging synthetic tasks\nand tumor segmentation datasets from public BRATS (brain, MRI) and LitS (liver,\nCT) datasets. We show a clear improvement (0.83 Dice on brain, 0.74 on liver)\nover baseline semi-supervised training with autoencoding (0.73, 0.66) and a\nmean teacher approach (0.75, 0.69), demonstrating the ability to generalize\nfrom smaller distributions of annotated samples.",
          "link": "http://arxiv.org/abs/1904.01636",
          "publishedOn": "2021-06-15T01:45:16.892Z",
          "wordCount": 721,
          "title": "Towards annotation-efficient segmentation via image-to-image translation. (arXiv:1904.01636v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.06810",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yuandong Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xinlei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganguli_S/0/1/0/all/0/1\">Surya Ganguli</a>",
          "description": "While contrastive approaches of self-supervised learning (SSL) learn\nrepresentations by minimizing the distance between two augmented views of the\nsame data point (positive pairs) and maximizing views from different data\npoints (negative pairs), recent \\emph{non-contrastive} SSL (e.g., BYOL and\nSimSiam) show remarkable performance {\\it without} negative pairs, with an\nextra learnable predictor and a stop-gradient operation. A fundamental question\narises: why do these methods not collapse into trivial representations? We\nanswer this question via a simple theoretical study and propose a novel\napproach, DirectPred, that \\emph{directly} sets the linear predictor based on\nthe statistics of its inputs, without gradient training. On ImageNet, it\nperforms comparably with more complex two-layer non-linear predictors that\nemploy BatchNorm and outperforms a linear predictor by $2.5\\%$ in 300-epoch\ntraining (and $5\\%$ in 60-epoch). DirectPred is motivated by our theoretical\nstudy of the nonlinear learning dynamics of non-contrastive SSL in simple\nlinear networks. Our study yields conceptual insights into how non-contrastive\nSSL methods learn, how they avoid representational collapse, and how multiple\nfactors, like predictor networks, stop-gradients, exponential moving averages,\nand weight decay all come into play. Our simple theory recapitulates the\nresults of real-world ablation studies in both STL-10 and ImageNet. Code is\nreleased\\footnote{\\url{https://github.com/facebookresearch/luckmatters/tree/master/ssl}}.",
          "link": "http://arxiv.org/abs/2102.06810",
          "publishedOn": "2021-06-15T01:45:16.878Z",
          "wordCount": 664,
          "title": "Understanding self-supervised Learning Dynamics without Contrastive Pairs. (arXiv:2102.06810v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06716",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_A/0/1/0/all/0/1\">Ailiang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Bingzhi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jiayu Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_G/0/1/0/all/0/1\">Guangming Lu</a>",
          "description": "Automatic medical image segmentation has made great progress benefit from the\ndevelopment of deep learning. However, most existing methods are based on\nconvolutional neural networks (CNNs), which fail to build long-range\ndependencies and global context connections due to the limitation of receptive\nfield in convolution operation. Inspired by the success of Transformer in\nmodeling the long-range contextual information, some researchers have expended\nconsiderable efforts in designing the robust variants of Transformer-based\nU-Net. Moreover, the patch division used in vision transformers usually ignores\nthe pixel-level intrinsic structural features inside each patch. To alleviate\nthese problems, we propose a novel deep medical image segmentation framework\ncalled Dual Swin Transformer U-Net (DS-TransUNet), which might be the first\nattempt to concurrently incorporate the advantages of hierarchical Swin\nTransformer into both encoder and decoder of the standard U-shaped architecture\nto enhance the semantic segmentation quality of varying medical images. Unlike\nmany prior Transformer-based solutions, the proposed DS-TransUNet first adopts\ndual-scale encoder subnetworks based on Swin Transformer to extract the coarse\nand fine-grained feature representations of different semantic scales. As the\ncore component for our DS-TransUNet, a well-designed Transformer Interactive\nFusion (TIF) module is proposed to effectively establish global dependencies\nbetween features of different scales through the self-attention mechanism.\nFurthermore, we also introduce the Swin Transformer block into decoder to\nfurther explore the long-range contextual information during the up-sampling\nprocess. Extensive experiments across four typical tasks for medical image\nsegmentation demonstrate the effectiveness of DS-TransUNet, and show that our\napproach significantly outperforms the state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2106.06716",
          "publishedOn": "2021-06-15T01:45:16.856Z",
          "wordCount": 681,
          "title": "DS-TransUNet:Dual Swin Transformer U-Net for Medical Image Segmentation. (arXiv:2106.06716v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2101.12242",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Adis_P/0/1/0/all/0/1\">Philipp Adis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Horst_N/0/1/0/all/0/1\">Nicolas Horst</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wien_M/0/1/0/all/0/1\">Mathias Wien</a>",
          "description": "LiDAR odometry (LO) describes the task of finding an alignment of subsequent\nLiDAR point clouds. This alignment can be used to estimate the motion of the\nplatform where the LiDAR sensor is mounted on. Currently, on the well-known\nKITTI Vision Benchmark Suite state-of-the-art algorithms are non-learning\napproaches. We propose a network architecture that learns LO by directly\nprocessing 3D point clouds. It is trained on the KITTI dataset in an end-to-end\nmanner without the necessity of pre-defining corresponding pairs of points. An\nevaluation on the KITTI Vision Benchmark Suite shows similar performance to a\npreviously published work, DeepCLR [1], even though our model uses only around\n3.56% of the number of network parameters thereof. Furthermore, a plane point\nextraction is applied which leads to a marginal performance decrease while\nsimultaneously reducing the input size by up to 50%.",
          "link": "http://arxiv.org/abs/2101.12242",
          "publishedOn": "2021-06-15T01:45:16.786Z",
          "wordCount": 594,
          "title": "D3DLO: Deep 3D LiDAR Odometry. (arXiv:2101.12242v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.14372",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hering_A/0/1/0/all/0/1\">Alessa Hering</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hager_S/0/1/0/all/0/1\">Stephanie H&#xe4;ger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moltz_J/0/1/0/all/0/1\">Jan Moltz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lessmann_N/0/1/0/all/0/1\">Nikolas Lessmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heldmann_S/0/1/0/all/0/1\">Stefan Heldmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ginneken_B/0/1/0/all/0/1\">Bram van Ginneken</a>",
          "description": "Deep-learning-based registration methods emerged as a fast alternative to\nconventional registration methods. However, these methods often still cannot\nachieve the same performance as conventional registration methods because they\nare either limited to small deformation or they fail to handle a superposition\nof large and small deformations without producing implausible deformation\nfields with foldings inside.\n\nIn this paper, we identify important strategies of conventional registration\nmethods for lung registration and successfully developed the deep-learning\ncounterpart. We employ a Gaussian-pyramid-based multilevel framework that can\nsolve the image registration optimization in a coarse-to-fine fashion.\nFurthermore, we prevent foldings of the deformation field and restrict the\ndeterminant of the Jacobian to physiologically meaningful values by combining a\nvolume change penalty with a curvature regularizer in the loss function.\nKeypoint correspondences are integrated to focus on the alignment of smaller\nstructures.\n\nWe perform an extensive evaluation to assess the accuracy, the robustness,\nthe plausibility of the estimated deformation fields, and the transferability\nof our registration approach. We show that it achieves state-of-the-art results\non the COPDGene dataset compared to conventional registration method with much\nshorter execution time. In our experiments on the DIRLab exhale to inhale lung\nregistration, we demonstrate substantial improvements (TRE below $1.2$ mm) over\nother deep learning methods. Our algorithm is publicly available at\nhttps://grand-challenge.org/algorithms/deep-learning-based-ct-lung-registration/.",
          "link": "http://arxiv.org/abs/2011.14372",
          "publishedOn": "2021-06-15T01:45:16.771Z",
          "wordCount": 680,
          "title": "CNN-based Lung CT Registration with Multiple Anatomical Constraints. (arXiv:2011.14372v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06684",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mazumder_J/0/1/0/all/0/1\">Joy Mazumder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zand_M/0/1/0/all/0/1\">Mohsen Zand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Greenspan_M/0/1/0/all/0/1\">Michael Greenspan</a>",
          "description": "This work presents a novel approach to improve the results of pose estimation\nby detecting and distinguishing between the occurrence of True and False\nPositive results. It achieves this by training a binary classifier on the\noutput of an arbitrary pose estimation algorithm, and returns a binary label\nindicating the validity of the result. We demonstrate that our approach\nimproves upon a state-of-the-art pose estimation result on the Sil\\'eane\ndataset, outperforming a variation of the alternative CullNet method by 4.15%\nin average class accuracy and 0.73% in overall accuracy at validation. Applying\nour method can also improve the pose estimation average precision results of\nOp-Net by 6.06% on average.",
          "link": "http://arxiv.org/abs/2106.06684",
          "publishedOn": "2021-06-15T01:45:16.750Z",
          "wordCount": 573,
          "title": "Multistream ValidNet: Improving 6D Object Pose Estimation by Automatic Multistream Validation. (arXiv:2106.06684v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06924",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chang_C/0/1/0/all/0/1\">Ching-Chun Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Sisheng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Echizen_I/0/1/0/all/0/1\">Isao Echizen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanchez_V/0/1/0/all/0/1\">Victor Sanchez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chang-Tsun Li</a>",
          "description": "Deep-learning\\textendash{centric} reversible steganography has emerged as a\npromising research paradigm. A direct way of applying deep learning to\nreversible steganography is to construct a pair of encoder and decoder, whose\nparameters are trained jointly, thereby learning the steganographic system as a\nwhole. This end-to-end framework, however, falls short of the reversibility\nrequirement because it is difficult for this kind of monolithic system, as a\nblack box, to create or duplicate intricate reversible mechanisms. In response\nto this issue, a recent approach is to carve up the steganographic system and\nwork on modules independently. In particular, neural networks are deployed in\nan analytics module to learn the data distribution, while an established\nmechanism is called upon to handle the remaining tasks. In this paper, we\ninvestigate the modular framework and deploy deep neural networks in a\nreversible steganographic scheme referred to as prediction-error modulation, in\nwhich an analytics module serves the purpose of pixel intensity prediction. The\nprimary focus of this study is on deep-learning\\textendash{based} context-aware\npixel intensity prediction. We address the unsolved issues reported in related\nliterature, including the impact of pixel initialisation on prediction accuracy\nand the influence of uncertainty propagation in dual-layer embedding.\nFurthermore, we establish a connection between context-aware pixel intensity\nprediction and low-level computer vision and analyse the performance of several\nadvanced neural networks.",
          "link": "http://arxiv.org/abs/2106.06924",
          "publishedOn": "2021-06-15T01:45:16.735Z",
          "wordCount": 652,
          "title": "Deep Learning for Reversible Steganography: Principles and Insights. (arXiv:2106.06924v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2004.00202",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Choi_C/0/1/0/all/0/1\">Chiho Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1\">Joon Hee Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malla_S/0/1/0/all/0/1\">Srikanth Malla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiachen Li</a>",
          "description": "Predicting future trajectories of traffic agents in highly interactive\nenvironments is an essential and challenging problem for the safe operation of\nautonomous driving systems. On the basis of the fact that self-driving vehicles\nare equipped with various types of sensors (e.g., LiDAR scanner, RGB camera,\nradar, etc.), we propose a Cross-Modal Embedding framework that aims to benefit\nfrom the use of multiple input modalities. At training time, our model learns\nto embed a set of complementary features in a shared latent space by jointly\noptimizing the objective functions across different types of input data. At\ntest time, a single input modality (e.g., LiDAR data) is required to generate\npredictions from the input perspective (i.e., in the LiDAR space), while taking\nadvantages from the model trained with multiple sensor modalities. An extensive\nevaluation is conducted to show the efficacy of the proposed framework using\ntwo benchmark driving datasets.",
          "link": "http://arxiv.org/abs/2004.00202",
          "publishedOn": "2021-06-15T01:45:16.697Z",
          "wordCount": 629,
          "title": "Shared Cross-Modal Trajectory Prediction for Autonomous Driving. (arXiv:2004.00202v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.08175",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xuanhong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1\">Xirui Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1\">Naiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_T/0/1/0/all/0/1\">Ting Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_B/0/1/0/all/0/1\">Bingbing Ni</a>",
          "description": "Though significant progress has been made in artistic style transfer,\nsemantic information is usually difficult to be preserved in a fine-grained\nlocally consistent manner by most existing methods, especially when multiple\nartists styles are required to transfer within one single model. To circumvent\nthis issue, we propose a Stroke Control Multi-Artist Style Transfer framework.\nOn the one hand, we develop a multi-condition single-generator structure which\nfirst performs multi-artist style transfer. On the one hand, we design an\nAnisotropic Stroke Module (ASM) which realizes the dynamic adjustment of\nstyle-stroke between the non-trivial and the trivial regions. ASM endows the\nnetwork with the ability of adaptive semantic-consistency among various styles.\nOn the other hand, we present an novel Multi-Scale Projection Discriminator} to\nrealize the texture-level conditional generation. In contrast to the\nsingle-scale conditional discriminator, our discriminator is able to capture\nmulti-scale texture clue to effectively distinguish a wide range of artistic\nstyles. Extensive experimental results well demonstrate the feasibility and\neffectiveness of our approach. Our framework can transform a photograph into\ndifferent artistic style oil painting via only ONE single model. Furthermore,\nthe results are with distinctive artistic style and retain the anisotropic\nsemantic information. The code is already available on github:\nhttps://github.com/neuralchen/ASMAGAN.",
          "link": "http://arxiv.org/abs/2010.08175",
          "publishedOn": "2021-06-15T01:45:16.677Z",
          "wordCount": 673,
          "title": "Anisotropic Stroke Control for Multiple Artists Style Transfer. (arXiv:2010.08175v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.01750",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singla_S/0/1/0/all/0/1\">Sahil Singla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nushi_B/0/1/0/all/0/1\">Besmira Nushi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_S/0/1/0/all/0/1\">Shital Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamar_E/0/1/0/all/0/1\">Ece Kamar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Horvitz_E/0/1/0/all/0/1\">Eric Horvitz</a>",
          "description": "Traditional evaluation metrics for learned models that report aggregate\nscores over a test set are insufficient for surfacing important and informative\npatterns of failure over features and instances. We introduce and study a\nmethod aimed at characterizing and explaining failures by identifying visual\nattributes whose presence or absence results in poor performance. In\ndistinction to previous work that relies upon crowdsourced labels for visual\nattributes, we leverage the representation of a separate robust model to\nextract interpretable features and then harness these features to identify\nfailure modes. We further propose a visualization method aimed at enabling\nhumans to understand the meaning encoded in such features and we test the\ncomprehensibility of the features. An evaluation of the methods on the ImageNet\ndataset demonstrates that: (i) the proposed workflow is effective for\ndiscovering important failure modes, (ii) the visualization techniques help\nhumans to understand the extracted features, and (iii) the extracted insights\ncan assist engineers with error analysis and debugging.",
          "link": "http://arxiv.org/abs/2012.01750",
          "publishedOn": "2021-06-15T01:45:16.660Z",
          "wordCount": 636,
          "title": "Understanding Failures of Deep Networks via Robust Feature Extraction. (arXiv:2012.01750v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06583",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Speth_J/0/1/0/all/0/1\">Jeremy Speth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vance_N/0/1/0/all/0/1\">Nathan Vance</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Czajka_A/0/1/0/all/0/1\">Adam Czajka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bowyer_K/0/1/0/all/0/1\">Kevin W. Bowyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wright_D/0/1/0/all/0/1\">Diane Wright</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Flynn_P/0/1/0/all/0/1\">Patrick Flynn</a>",
          "description": "We present the Deception Detection and Physiological Monitoring (DDPM)\ndataset and initial baseline results on this dataset. Our application context\nis an interview scenario in which the interviewee attempts to deceive the\ninterviewer on selected responses. The interviewee is recorded in RGB,\nnear-infrared, and long-wave infrared, along with cardiac pulse, blood\noxygenation, and audio. After collection, data were annotated for\ninterviewer/interviewee, curated, ground-truthed, and organized into train /\ntest parts for a set of canonical deception detection experiments. Baseline\nexperiments found random accuracy for micro-expressions as an indicator of\ndeception, but that saccades can give a statistically significant response. We\nalso estimated subject heart rates from face videos (remotely) with a mean\nabsolute error as low as 3.16 bpm. The database contains almost 13 hours of\nrecordings of 70 subjects, and over 8 million visible-light, near-infrared, and\nthermal video frames, along with appropriate meta, audio and pulse oximeter\ndata. To our knowledge, this is the only collection offering recordings of five\nmodalities in an interview scenario that can be used in both deception\ndetection and remote photoplethysmography research.",
          "link": "http://arxiv.org/abs/2106.06583",
          "publishedOn": "2021-06-15T01:45:16.646Z",
          "wordCount": 633,
          "title": "Deception Detection and Remote Physiological Monitoring: A Dataset and Baseline Experimental Results. (arXiv:2106.06583v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06778",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ye_L/0/1/0/all/0/1\">Longqing Ye</a>",
          "description": "Convolutional networks (ConvNets) have shown impressive capability to solve\nvarious vision tasks. Nevertheless, the trade-off between performance and\nefficiency is still a challenge for a feasible model deployment on\nresource-constrained platforms. In this paper, we introduce a novel concept\ntermed multi-path fully connected pattern (MPFC) to rethink the\ninterdependencies of topology pattern, accuracy and efficiency for ConvNets.\nInspired by MPFC, we further propose a dual-branch module named dynamic clone\ntransformer (DCT) where one branch generates multiple replicas from inputs and\nanother branch reforms those clones through a series of difference vectors\nconditional on inputs itself to produce more variants. This operation allows\nthe self-expansion of channel-wise information in a data-driven way with little\ncomputational cost while providing sufficient learning capacity, which is a\npotential unit to replace computationally expensive pointwise convolution as an\nexpansion layer in the bottleneck structure.",
          "link": "http://arxiv.org/abs/2106.06778",
          "publishedOn": "2021-06-15T01:45:16.602Z",
          "wordCount": 567,
          "title": "Dynamic Clone Transformer for Efficient Convolutional Neural Netwoks. (arXiv:2106.06778v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06703",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gadd_M/0/1/0/all/0/1\">Matthew Gadd</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martini_D/0/1/0/all/0/1\">Daniele De Martini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Newman_P/0/1/0/all/0/1\">Paul Newman</a>",
          "description": "We learn, in an unsupervised way, an embedding from sequences of radar images\nthat is suitable for solving place recognition problem using complex radar\ndata. We experiment on 280 km of data and show performance exceeding\nstate-of-the-art supervised approaches, localising correctly 98.38% of the time\nwhen using just the nearest database candidate.",
          "link": "http://arxiv.org/abs/2106.06703",
          "publishedOn": "2021-06-15T01:45:16.596Z",
          "wordCount": 512,
          "title": "Unsupervised Place Recognition with Deep Embedding Learning over Radar Videos. (arXiv:2106.06703v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2102.07074",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yifan Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1\">Shiyu Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhangyang Wang</a>",
          "description": "The recent explosive interest on transformers has suggested their potential\nto become powerful ``universal\" models for computer vision tasks, such as\nclassification, detection, and segmentation. While those attempts mainly study\nthe discriminative models, we explore transformers on some more notoriously\ndifficult vision tasks, e.g., generative adversarial networks (GANs). Our goal\nis to conduct the first pilot study in building a GAN completely free of\nconvolutions, using only pure transformer-based architectures. Our vanilla GAN\narchitecture, dubbed TransGAN, consists of a memory-friendly transformer-based\ngenerator that progressively increases feature resolution, and correspondingly\na multi-scale discriminator to capture simultaneously semantic contexts and\nlow-level textures. On top of them, we introduce the new module of grid\nself-attention for alleviating the memory bottleneck further, in order to scale\nup TransGAN to high-resolution generation. We also develop a unique training\nrecipe including a series of techniques that can mitigate the training\ninstability issues of TransGAN, such as data augmentation, modified\nnormalization, and relative position encoding. Our best architecture achieves\nhighly competitive performance compared to current state-of-the-art GANs using\nconvolutional backbones. Specifically, TransGAN sets new state-of-the-art\ninception score of 10.43 and FID of 18.28 on STL-10, outperforming StyleGAN-V2.\nWhen it comes to higher-resolution (e.g. 256 x 256) generation tasks, such as\non CelebA-HQ and LSUN-Church, TransGAN continues to produce diverse visual\nexamples with high fidelity and impressive texture details. In addition, we\ndive deep into the transformer-based generation models to understand how their\nbehaviors differ from convolutional ones, by visualizing training dynamics. The\ncode is available at https://github.com/VITA-Group/TransGAN.",
          "link": "http://arxiv.org/abs/2102.07074",
          "publishedOn": "2021-06-15T01:45:16.538Z",
          "wordCount": 729,
          "title": "TransGAN: Two Pure Transformers Can Make One Strong GAN, and That Can Scale Up. (arXiv:2102.07074v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.14512",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liang_K/0/1/0/all/0/1\">Kaizhao Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jacky Y. Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koyejo_O/0/1/0/all/0/1\">Oluwasanmi Koyejo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>",
          "description": "Knowledge transferability, or transfer learning, has been widely adopted to\nallow a pre-trained model in the source domain to be effectively adapted to\ndownstream tasks in the target domain. It is thus important to explore and\nunderstand the factors affecting knowledge transferability. In this paper, as\nthe first work, we analyze and demonstrate the connections between knowledge\ntransferability and another important phenomenon--adversarial transferability,\n\\emph{i.e.}, adversarial examples generated against one model can be\ntransferred to attack other models. Our theoretical studies show that\nadversarial transferability indicates knowledge transferability and vice versa.\nMoreover, based on the theoretical insights, we propose two practical\nadversarial transferability metrics to characterize this process, serving as\nbidirectional indicators between adversarial and knowledge transferability. We\nconduct extensive experiments for different scenarios on diverse datasets,\nshowing a positive correlation between adversarial transferability and\nknowledge transferability. Our findings will shed light on future research\nabout effective knowledge transfer learning and adversarial transferability\nanalyses.",
          "link": "http://arxiv.org/abs/2006.14512",
          "publishedOn": "2021-06-15T01:45:16.524Z",
          "wordCount": 628,
          "title": "Uncovering the Connections Between Adversarial Transferability and Knowledge Transferability. (arXiv:2006.14512v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06971",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hao_H/0/1/0/all/0/1\">Hou Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yingkun_H/0/1/0/all/0/1\">Hou Yingkun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuxuan_S/0/1/0/all/0/1\">Shi Yuxuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benzheng_W/0/1/0/all/0/1\">Wei Benzheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jun_X/0/1/0/all/0/1\">Xu Jun</a>",
          "description": "Retinex model has been applied to low-light image enhancement in many\nexisting methods. More appropriate decomposition of a low-light image can help\nachieve better image enhancement. In this paper, we propose a new pixel-level\nnon-local Haar transform based illumination and reflectance decomposition\nmethod (NLHD). The unique low-frequency coefficient of Haar transform on each\nsimilar pixel group is used to reconstruct the illumination component, and the\nrest of all high-frequency coefficients are employed to reconstruct the\nreflectance component. The complete similarity of pixels in a matched similar\npixel group and the simple separable Haar transform help to obtain more\nappropriate image decomposition; thus, the image is hardly sharpened in the\nimage brightness enhancement procedure. The exponential transform and\nlogarithmic transform are respectively implemented on the illumination\ncomponent. Then a minimum fusion strategy on the results of these two\ntransforms is utilized to achieve more natural illumination component\nenhancement. It can alleviate the mosaic artifacts produced in the darker\nregions by the exponential transform with a gamma value less than 1 and reduce\ninformation loss caused by excessive enhancement of the brighter regions due to\nthe logarithmic transform. Finally, the Retinex model is applied to the\nenhanced illumination and reflectance to achieve image enhancement. We also\ndevelop a local noise level estimation based noise suppression method and a\nnon-local saturation reduction based color deviation correction method. These\ntwo methods can respectively attenuate noise or color deviation usually\npresented in the enhanced results of the extremely dark low-light images.\nExperiments on benchmark datasets show that the proposed method can achieve\nbetter low-light image enhancement results on subjective and objective\nevaluations than most existing methods.",
          "link": "http://arxiv.org/abs/2106.06971",
          "publishedOn": "2021-06-15T01:45:16.448Z",
          "wordCount": 712,
          "title": "NLHD: A Pixel-Level Non-Local Retinex Model for Low-Light Image Enhancement. (arXiv:2106.06971v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06887",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gu_C/0/1/0/all/0/1\">Cheng Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Learned_Miller_E/0/1/0/all/0/1\">Erik Learned-Miller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheldon_D/0/1/0/all/0/1\">Daniel Sheldon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gallego_G/0/1/0/all/0/1\">Guillermo Gallego</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bideau_P/0/1/0/all/0/1\">Pia Bideau</a>",
          "description": "Event cameras, inspired by biological vision systems, provide a natural and\ndata efficient representation of visual information. Visual information is\nacquired in the form of events that are triggered by local brightness changes.\nEach pixel location of the camera's sensor records events asynchronously and\nindependently with very high temporal resolution. However, because most\nbrightness changes are triggered by relative motion of the camera and the\nscene, the events recorded at a single sensor location seldom correspond to the\nsame world point. To extract meaningful information from event cameras, it is\nhelpful to register events that were triggered by the same underlying world\npoint. In this work we propose a new model of event data that captures its\nnatural spatio-temporal structure. We start by developing a model for aligned\nevent data. That is, we develop a model for the data as though it has been\nperfectly registered already. In particular, we model the aligned data as a\nspatio-temporal Poisson point process. Based on this model, we develop a\nmaximum likelihood approach to registering events that are not yet aligned.\nThat is, we find transformations of the observed events that make them as\nlikely as possible under our model. In particular we extract the camera\nrotation that leads to the best event alignment. We show new state of the art\naccuracy for rotational velocity estimation on the DAVIS 240C dataset. In\naddition, our method is also faster and has lower computational complexity than\nseveral competing methods.",
          "link": "http://arxiv.org/abs/2106.06887",
          "publishedOn": "2021-06-15T01:45:16.386Z",
          "wordCount": 689,
          "title": "The Spatio-Temporal Poisson Point Process: A Simple Model for the Alignment of Event Camera Data. (arXiv:2106.06887v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06733",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yi Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yanfei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jingguang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Guocai Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_K/0/1/0/all/0/1\">Kai Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yefeng Zheng</a>",
          "description": "Radiation therapy treatment planning is a complex process, as the target dose\nprescription and normal tissue sparing are conflicting objectives. Automated\nand accurate dose prediction for radiation therapy planning is in high demand.\nIn this study, we propose a novel learning-based ensemble approach, named\nLE-NAS, which integrates neural architecture search (NAS) with knowledge\ndistillation for 3D radiotherapy dose prediction. Specifically, the prediction\nnetwork first exhaustively searches each block from enormous architecture\nspace. Then, multiple architectures are selected with promising performance and\ndiversity. To reduce the inference time, we adopt the teacher-student paradigm\nby treating the combination of diverse outputs from multiple searched networks\nas supervisions to guide the student network training. In addition, we apply\nadversarial learning to optimize the student network to recover the knowledge\nin teacher networks. To the best of our knowledge, we are the first to\ninvestigate the combination of NAS and knowledge distillation. The proposed\nmethod has been evaluated on the public OpenKBP dataset, and experimental\nresults demonstrate the effectiveness of our method and its superior\nperformance to the state-of-the-art method.",
          "link": "http://arxiv.org/abs/2106.06733",
          "publishedOn": "2021-06-15T01:45:16.362Z",
          "wordCount": 613,
          "title": "LE-NAS: Learning-based Ensenble with NAS for Dose Prediction. (arXiv:2106.06733v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06804",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Barbiero_P/0/1/0/all/0/1\">Pietro Barbiero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ciravegna_G/0/1/0/all/0/1\">Gabriele Ciravegna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giannini_F/0/1/0/all/0/1\">Francesco Giannini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lio_P/0/1/0/all/0/1\">Pietro Li&#xf3;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gori_M/0/1/0/all/0/1\">Marco Gori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Melacci_S/0/1/0/all/0/1\">Stefano Melacci</a>",
          "description": "Explainable artificial intelligence has rapidly emerged since lawmakers have\nstarted requiring interpretable models for safety-critical domains.\nConcept-based neural networks have arisen as explainable-by-design methods as\nthey leverage human-understandable symbols (i.e. concepts) to predict class\nmemberships. However, most of these approaches focus on the identification of\nthe most relevant concepts but do not provide concise, formal explanations of\nhow such concepts are leveraged by the classifier to make predictions. In this\npaper, we propose a novel end-to-end differentiable approach enabling the\nextraction of logic explanations from neural networks using the formalism of\nFirst-Order Logic. The method relies on an entropy-based criterion which\nautomatically identifies the most relevant concepts. We consider four different\ncase studies to demonstrate that: (i) this entropy-based criterion enables the\ndistillation of concise logic explanations in safety-critical domains from\nclinical data to computer vision; (ii) the proposed approach outperforms\nstate-of-the-art white-box models in terms of classification accuracy.",
          "link": "http://arxiv.org/abs/2106.06804",
          "publishedOn": "2021-06-15T01:45:16.341Z",
          "wordCount": 591,
          "title": "Entropy-based Logic Explanations of Neural Networks. (arXiv:2106.06804v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2008.06910",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zanfir_A/0/1/0/all/0/1\">Andrei Zanfir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bazavan_E/0/1/0/all/0/1\">Eduard Gabriel Bazavan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zanfir_M/0/1/0/all/0/1\">Mihai Zanfir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freeman_W/0/1/0/all/0/1\">William T. Freeman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sukthankar_R/0/1/0/all/0/1\">Rahul Sukthankar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sminchisescu_C/0/1/0/all/0/1\">Cristian Sminchisescu</a>",
          "description": "We present deep neural network methodology to reconstruct the 3d pose and\nshape of people, given an input RGB image. We rely on a recently introduced,\nexpressivefull body statistical 3d human model, GHUM, trained end-to-end, and\nlearn to reconstruct its pose and shape state in a self-supervised regime.\nCentral to our methodology, is a learning to learn and optimize approach,\nreferred to as HUmanNeural Descent (HUND), which avoids both second-order\ndifferentiation when training the model parameters,and expensive state gradient\ndescent in order to accurately minimize a semantic differentiable rendering\nloss at test time. Instead, we rely on novel recurrent stages to update the\npose and shape parameters such that not only losses are minimized effectively,\nbut the process is meta-regularized in order to ensure end-progress. HUND's\nsymmetry between training and testing makes it the first 3d human sensing\narchitecture to natively support different operating regimes including\nself-supervised ones. In diverse tests, we show that HUND achieves very\ncompetitive results in datasets like H3.6M and 3DPW, aswell as good quality 3d\nreconstructions for complex imagery collected in-the-wild.",
          "link": "http://arxiv.org/abs/2008.06910",
          "publishedOn": "2021-06-15T01:45:16.329Z",
          "wordCount": 649,
          "title": "Neural Descent for Visual 3D Human Pose and Shape. (arXiv:2008.06910v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06637",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1\">Yan Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ravikumar_N/0/1/0/all/0/1\">Nishant Ravikumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frangi_A/0/1/0/all/0/1\">Alejandro F Frangi</a>",
          "description": "Image registration is a fundamental building block for various applications\nin medical image analysis. To better explore the correlation between the fixed\nand moving images and improve registration performance, we propose a novel deep\nlearning network, Co-Attention guided Registration Network (CAR-Net). CAR-Net\nemploys a co-attention block to learn a new representation of the inputs, which\ndrives the registration of the fixed and moving images. Experiments on UK\nBiobank cardiac cine-magnetic resonance image data demonstrate that CAR-Net\nobtains higher registration accuracy and smoother deformation fields than\nstate-of-the-art unsupervised registration methods, while achieving comparable\nor better registration performance than corresponding weakly-supervised\nvariants. In addition, our approach can provide critical structural information\nof the input fixed and moving images simultaneously in a completely\nunsupervised manner.",
          "link": "http://arxiv.org/abs/2106.06637",
          "publishedOn": "2021-06-15T01:45:16.323Z",
          "wordCount": 561,
          "title": "CAR-Net: Unsupervised Co-Attention Guided Registration Network for Joint Registration and Structure Learning. (arXiv:2106.06637v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06882",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vedder_K/0/1/0/all/0/1\">Kyle Vedder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eaton_E/0/1/0/all/0/1\">Eric Eaton</a>",
          "description": "Bird's Eye View (BEV) is a popular representation for processing 3D point\nclouds, and by its nature is fundamentally sparse. Motivated by the\ncomputational limitations of mobile robot platforms, we take a fast\nhigh-performance BEV 3D object detector - PointPillars - and modify its\nbackbone to exploit this sparsity, leading to decreased runtimes. We present\npreliminary results demonstrating decreased runtimes with either the same\nperformance or a modest decrease in performance, which we anticipate will be\nremedied by model specific hyperparameter tuning. Our work is a first step\ntowards a new class of 3D object detectors that exploit sparsity throughout\ntheir entire pipeline in order to reduce runtime and resource usage while\nmaintaining good detection performance.",
          "link": "http://arxiv.org/abs/2106.06882",
          "publishedOn": "2021-06-15T01:45:16.254Z",
          "wordCount": 546,
          "title": "Sparse PointPillars: Exploiting Sparsity in Birds-Eye-View Object Detection. (arXiv:2106.06882v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06650",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vo_H/0/1/0/all/0/1\">Huy V. Vo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sizikova_E/0/1/0/all/0/1\">Elena Sizikova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmid_C/0/1/0/all/0/1\">Cordelia Schmid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perez_P/0/1/0/all/0/1\">Patrick P&#xe9;rez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ponce_J/0/1/0/all/0/1\">Jean Ponce</a>",
          "description": "Existing approaches to unsupervised object discovery (UOD) do not scale up to\nlarge datasets without approximations which compromise their performance. We\npropose a novel formulation of UOD as a ranking problem, amenable to the\narsenal of distributed methods available for eigenvalue problems and link\nanalysis. Extensive experiments with COCO and OpenImages demonstrate that, in\nthe single-object discovery setting where a single prominent object is sought\nin each image, the proposed LOD (Large-scale Object Discovery) approach is on\npar with, or better than the state of the art for medium-scale datasets (up to\n120K images), and over 37% better than the only other algorithms capable of\nscaling up to 1.7M images. In the multi-object discovery setting where multiple\nobjects are sought in each image, the proposed LOD is over 14% better in\naverage precision (AP) than all other methods for datasets ranging from 20K to\n1.7M images.",
          "link": "http://arxiv.org/abs/2106.06650",
          "publishedOn": "2021-06-15T01:45:16.226Z",
          "wordCount": 574,
          "title": "Large-Scale Unsupervised Object Discovery. (arXiv:2106.06650v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2103.10626",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sharma_Y/0/1/0/all/0/1\">Yash Sharma</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shrivastava_A/0/1/0/all/0/1\">Aman Shrivastava</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ehsan_L/0/1/0/all/0/1\">Lubaina Ehsan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Moskaluk_C/0/1/0/all/0/1\">Christopher A. Moskaluk</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Syed_S/0/1/0/all/0/1\">Sana Syed</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Brown_D/0/1/0/all/0/1\">Donald E. Brown</a>",
          "description": "In recent years, the availability of digitized Whole Slide Images (WSIs) has\nenabled the use of deep learning-based computer vision techniques for automated\ndisease diagnosis. However, WSIs present unique computational and algorithmic\nchallenges. WSIs are gigapixel-sized ($\\sim$100K pixels), making them\ninfeasible to be used directly for training deep neural networks. Also, often\nonly slide-level labels are available for training as detailed annotations are\ntedious and can be time-consuming for experts. Approaches using\nmultiple-instance learning (MIL) frameworks have been shown to overcome these\nchallenges. Current state-of-the-art approaches divide the learning framework\ninto two decoupled parts: a convolutional neural network (CNN) for encoding the\npatches followed by an independent aggregation approach for slide-level\nprediction. In this approach, the aggregation step has no bearing on the\nrepresentations learned by the CNN encoder. We have proposed an end-to-end\nframework that clusters the patches from a WSI into ${k}$-groups, samples\n${k}'$ patches from each group for training, and uses an adaptive attention\nmechanism for slide level prediction; Cluster-to-Conquer (C2C). We have\ndemonstrated that dividing a WSI into clusters can improve the model training\nby exposing it to diverse discriminative features extracted from the patches.\nWe regularized the clustering mechanism by introducing a KL-divergence loss\nbetween the attention weights of patches in a cluster and the uniform\ndistribution. The framework is optimized end-to-end on slide-level\ncross-entropy, patch-level cross-entropy, and KL-divergence loss\n(Implementation: https://github.com/YashSharma/C2C).",
          "link": "http://arxiv.org/abs/2103.10626",
          "publishedOn": "2021-06-15T01:45:15.952Z",
          "wordCount": 711,
          "title": "Cluster-to-Conquer: A Framework for End-to-End Multi-Instance Learning for Whole Slide Image Classification. (arXiv:2103.10626v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03210",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yaman_D/0/1/0/all/0/1\">Dogucan Yaman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ekenel_H/0/1/0/all/0/1\">Haz&#x131;m Kemal Ekenel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Waibel_A/0/1/0/all/0/1\">Alexander Waibel</a>",
          "description": "Portrait matting is an important research problem with a wide range of\napplications, such as video conference app, image/video editing, and\npost-production. The goal is to predict an alpha matte that identifies the\neffect of each pixel on the foreground subject. Traditional approaches and most\nof the existing works utilized an additional input, e.g., trimap, background\nimage, to predict alpha matte. However, providing additional input is not\nalways practical. Besides, models are too sensitive to these additional inputs.\nIn this paper, we introduce an additional input-free approach to perform\nportrait matting using Generative Adversarial Nets (GANs). We divide the main\ntask into two subtasks. For this, we propose a segmentation network for the\nperson segmentation and the alpha generation network for alpha matte\nprediction. While the segmentation network takes an input image and produces a\ncoarse segmentation map, the alpha generation network utilizes the same input\nimage as well as a coarse segmentation map that is produced by the segmentation\nnetwork to predict the alpha matte. Besides, we present a segmentation encoding\nblock to downsample the coarse segmentation map and provide feature\nrepresentation to the residual block. Furthermore, we propose border loss to\npenalize only the borders of the subject separately which is more likely to be\nchallenging and we also adapt perceptual loss for portrait matting. To train\nthe proposed system, we combine two different popular training datasets to\nimprove the amount of data as well as diversity to address domain shift\nproblems in the inference time. We tested our model on three different\nbenchmark datasets, namely Adobe Image Matting dataset, Portrait Matting\ndataset, and Distinctions dataset. The proposed method outperformed the MODNet\nmethod that also takes a single input.",
          "link": "http://arxiv.org/abs/2106.03210",
          "publishedOn": "2021-06-15T01:45:15.916Z",
          "wordCount": 729,
          "title": "Alpha Matte Generation from Single Input for Portrait Matting. (arXiv:2106.03210v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.03230",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zbontar_J/0/1/0/all/0/1\">Jure Zbontar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jing_L/0/1/0/all/0/1\">Li Jing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Misra_I/0/1/0/all/0/1\">Ishan Misra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+LeCun_Y/0/1/0/all/0/1\">Yann LeCun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deny_S/0/1/0/all/0/1\">St&#xe9;phane Deny</a>",
          "description": "Self-supervised learning (SSL) is rapidly closing the gap with supervised\nmethods on large computer vision benchmarks. A successful approach to SSL is to\nlearn embeddings which are invariant to distortions of the input sample.\nHowever, a recurring issue with this approach is the existence of trivial\nconstant solutions. Most current methods avoid such solutions by careful\nimplementation details. We propose an objective function that naturally avoids\ncollapse by measuring the cross-correlation matrix between the outputs of two\nidentical networks fed with distorted versions of a sample, and making it as\nclose to the identity matrix as possible. This causes the embedding vectors of\ndistorted versions of a sample to be similar, while minimizing the redundancy\nbetween the components of these vectors. The method is called Barlow Twins,\nowing to neuroscientist H. Barlow's redundancy-reduction principle applied to a\npair of identical networks. Barlow Twins does not require large batches nor\nasymmetry between the network twins such as a predictor network, gradient\nstopping, or a moving average on the weight updates. Intriguingly it benefits\nfrom very high-dimensional output vectors. Barlow Twins outperforms previous\nmethods on ImageNet for semi-supervised classification in the low-data regime,\nand is on par with current state of the art for ImageNet classification with a\nlinear classifier head, and for transfer tasks of classification and object\ndetection.",
          "link": "http://arxiv.org/abs/2103.03230",
          "publishedOn": "2021-06-15T01:45:15.887Z",
          "wordCount": 717,
          "title": "Barlow Twins: Self-Supervised Learning via Redundancy Reduction. (arXiv:2103.03230v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.05068",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chun_S/0/1/0/all/0/1\">Sanghyuk Chun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_S/0/1/0/all/0/1\">Seong Joon Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rezende_R/0/1/0/all/0/1\">Rafael Sampaio de Rezende</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalantidis_Y/0/1/0/all/0/1\">Yannis Kalantidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Larlus_D/0/1/0/all/0/1\">Diane Larlus</a>",
          "description": "Cross-modal retrieval methods build a common representation space for samples\nfrom multiple modalities, typically from the vision and the language domains.\nFor images and their captions, the multiplicity of the correspondences makes\nthe task particularly challenging. Given an image (respectively a caption),\nthere are multiple captions (respectively images) that equally make sense. In\nthis paper, we argue that deterministic functions are not sufficiently powerful\nto capture such one-to-many correspondences. Instead, we propose to use\nProbabilistic Cross-Modal Embedding (PCME), where samples from the different\nmodalities are represented as probabilistic distributions in the common\nembedding space. Since common benchmarks such as COCO suffer from\nnon-exhaustive annotations for cross-modal matches, we propose to additionally\nevaluate retrieval on the CUB dataset, a smaller yet clean database where all\npossible image-caption pairs are annotated. We extensively ablate PCME and\ndemonstrate that it not only improves the retrieval performance over its\ndeterministic counterpart but also provides uncertainty estimates that render\nthe embeddings more interpretable. Code is available at\nhttps://github.com/naver-ai/pcme",
          "link": "http://arxiv.org/abs/2101.05068",
          "publishedOn": "2021-06-15T01:45:15.867Z",
          "wordCount": 639,
          "title": "Probabilistic Embeddings for Cross-Modal Retrieval. (arXiv:2101.05068v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.05980",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Feng_C/0/1/0/all/0/1\">Chun-Mei Feng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_Z/0/1/0/all/0/1\">Zhanyuan Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fu_H/0/1/0/all/0/1\">Huazhu Fu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_Y/0/1/0/all/0/1\">Yong Xu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_J/0/1/0/all/0/1\">Jian Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shao_L/0/1/0/all/0/1\">Ling Shao</a>",
          "description": "Magnetic resonance (MR) image acquisition is an inherently prolonged process,\nwhose acceleration has long been the subject of research. This is commonly\nachieved by obtaining multiple undersampled images, simultaneously, through\nparallel imaging. In this paper, we propose the Dual-Octave Network (DONet),\nwhich is capable of learning multi-scale spatial-frequency features from both\nthe real and imaginary components of MR data, for fast parallel MR image\nreconstruction. More specifically, our DONet consists of a series of\nDual-Octave convolutions (Dual-OctConv), which are connected in a dense manner\nfor better reuse of features. In each Dual-OctConv, the input feature maps and\nconvolutional kernels are first split into two components (ie, real and\nimaginary), and then divided into four groups according to their spatial\nfrequencies. Then, our Dual-OctConv conducts intra-group information updating\nand inter-group information exchange to aggregate the contextual information\nacross different groups. Our framework provides three appealing benefits: (i)\nIt encourages information interaction and fusion between the real and imaginary\ncomponents at various spatial frequencies to achieve richer representational\ncapacity. (ii) The dense connections between the real and imaginary groups in\neach Dual-OctConv make the propagation of features more efficient by feature\nreuse. (iii) DONet enlarges the receptive field by learning multiple\nspatial-frequency features of both the real and imaginary components. Extensive\nexperiments on two popular datasets (ie, clinical knee and fastMRI), under\ndifferent undersampling patterns and acceleration factors, demonstrate the\nsuperiority of our model in accelerated parallel MR image reconstruction.",
          "link": "http://arxiv.org/abs/2105.05980",
          "publishedOn": "2021-06-15T01:45:15.761Z",
          "wordCount": 717,
          "title": "DONet: Dual-Octave Network for Fast MR Image Reconstruction. (arXiv:2105.05980v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06988",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhangy_W/0/1/0/all/0/1\">Weichuan Zhangy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liuy_X/0/1/0/all/0/1\">Xuefang Liuy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_Z/0/1/0/all/0/1\">Zhe Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yongsheng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1\">Changming Sun</a>",
          "description": "Metric-based few-shot fine-grained image classification (FSFGIC) aims to\nlearn a transferable feature embedding network by estimating the similarities\nbetween query images and support classes from very few examples. In this work,\nwe propose, for the first time, to introduce the non-linear data projection\nconcept into the design of FSFGIC architecture in order to address the limited\nsample problem in few-shot learning and at the same time to increase the\ndiscriminability of the model for fine-grained image classification.\nSpecifically, we first design a feature re-abstraction embedding network that\nhas the ability to not only obtain the required semantic features for effective\nmetric learning but also re-enhance such features with finer details from input\nimages. Then the descriptors of the query images and the support classes are\nprojected into different non-linear spaces in our proposed similarity metric\nlearning network to learn discriminative projection factors. This design can\neffectively operate in the challenging and restricted condition of a FSFGIC\ntask for making the distance between the samples within the same class smaller\nand the distance between samples from different classes larger and for reducing\nthe coupling relationship between samples from different categories.\nFurthermore, a novel similarity measure based on the proposed non-linear data\nproject is presented for evaluating the relationships of feature information\nbetween a query image and a support set. It is worth to note that our proposed\narchitecture can be easily embedded into any episodic training mechanisms for\nend-to-end training from scratch. Extensive experiments on FSFGIC tasks\ndemonstrate the superiority of the proposed methods over the state-of-the-art\nbenchmarks.",
          "link": "http://arxiv.org/abs/2106.06988",
          "publishedOn": "2021-06-15T01:45:15.709Z",
          "wordCount": 701,
          "title": "NDPNet: A novel non-linear data projection network for few-shot fine-gained image classification. (arXiv:2106.06988v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.15134",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wen_Z/0/1/0/all/0/1\">Zixin Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuanzhi Li</a>",
          "description": "How can neural networks trained by contrastive learning extract features from\nthe unlabeled data? Why does contrastive learning usually need much stronger\ndata augmentations than supervised learning to ensure good representations?\nThese questions involve both the optimization and statistical aspects of deep\nlearning, but can hardly be answered by analyzing supervised learning, where\nthe target functions are the highest pursuit. Indeed, in self-supervised\nlearning, it is inevitable to relate to the optimization/generalization of\nneural networks to how they can encode the latent structures in the data, which\nwe refer to as the feature learning process.\n\nIn this work, we formally study how contrastive learning learns the feature\nrepresentations for neural networks by analyzing its feature learning process.\nWe consider the case where our data are comprised of two types of features: the\nmore semantically aligned sparse features which we want to learn from, and the\nother dense features we want to avoid. Theoretically, we prove that contrastive\nlearning using $\\mathbf{ReLU}$ networks provably learns the desired sparse\nfeatures if proper augmentations are adopted. We present an underlying\nprinciple called $\\textbf{feature decoupling}$ to explain the effects of\naugmentations, where we theoretically characterize how augmentations can reduce\nthe correlations of dense features between positive samples while keeping the\ncorrelations of sparse features intact, thereby forcing the neural networks to\nlearn from the self-supervision of sparse features. Empirically, we verified\nthat the feature decoupling principle matches the underlying mechanism of\ncontrastive learning in practice.",
          "link": "http://arxiv.org/abs/2105.15134",
          "publishedOn": "2021-06-15T01:45:15.691Z",
          "wordCount": 703,
          "title": "Toward Understanding the Feature Learning Process of Self-supervised Contrastive Learning. (arXiv:2105.15134v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1906.06514",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongsong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1\">Jian Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_B/0/1/0/all/0/1\">Bin Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jiashi Feng</a>",
          "description": "Human motion prediction, which aims to predict future human poses given past\nposes, has recently seen increased interest. Many recent approaches are based\non Recurrent Neural Networks (RNN) which model human poses with exponential\nmaps. These approaches neglect the pose velocity as well as temporal relation\nof different poses, and tend to converge to the mean pose or fail to generate\nnatural-looking poses. We therefore propose a novel Position-Velocity Recurrent\nEncoder-Decoder (PVRED) for human motion prediction, which makes full use of\npose velocities and temporal positional information. A temporal position\nembedding method is presented and a Position-Velocity RNN (PVRNN) is proposed.\nWe also emphasize the benefits of quaternion parameterization of poses and\ndesign a novel trainable Quaternion Transformation (QT) layer, which is\ncombined with a robust loss function during training. We provide quantitative\nresults for both short-term prediction in the future 0.5 seconds and long-term\nprediction in the future 0.5 to 1 seconds. Experiments on several benchmarks\nshow that our approach considerably outperforms the state-of-the-art methods.\nIn addition, qualitative visualizations in the future 4 seconds show that our\napproach could predict future human-like and meaningful poses in very long time\nhorizons. Code is publicly available on GitHub:\n\\textcolor{red}{https://github.com/hongsong-wang/PVRNN}.",
          "link": "http://arxiv.org/abs/1906.06514",
          "publishedOn": "2021-06-15T01:45:15.508Z",
          "wordCount": 659,
          "title": "PVRED: A Position-Velocity Recurrent Encoder-Decoder for Human Motion Prediction. (arXiv:1906.06514v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03743",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Labatie_A/0/1/0/all/0/1\">Antoine Labatie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Masters_D/0/1/0/all/0/1\">Dominic Masters</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eaton_Rosen_Z/0/1/0/all/0/1\">Zach Eaton-Rosen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luschi_C/0/1/0/all/0/1\">Carlo Luschi</a>",
          "description": "We investigate the reasons for the performance degradation incurred with\nbatch-independent normalization. We find that the prototypical techniques of\nlayer normalization and instance normalization both induce the appearance of\nfailure modes in the neural network's pre-activations: (i) layer normalization\ninduces a collapse towards channel-wise constant functions; (ii) instance\nnormalization induces a lack of variability in instance statistics, symptomatic\nof an alteration of the expressivity. To alleviate failure mode (i) without\naggravating failure mode (ii), we introduce the technique \"Proxy Normalization\"\nthat normalizes post-activations using a proxy distribution. When combined with\nlayer normalization or group normalization, this batch-independent\nnormalization emulates batch normalization's behavior and consistently matches\nor exceeds its performance.",
          "link": "http://arxiv.org/abs/2106.03743",
          "publishedOn": "2021-06-15T01:45:15.459Z",
          "wordCount": 565,
          "title": "Proxy-Normalizing Activations to Match Batch Normalization while Removing Batch Dependence. (arXiv:2106.03743v2 [cs.LG] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.02523",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ochal_M/0/1/0/all/0/1\">Mateusz Ochal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patacchiola_M/0/1/0/all/0/1\">Massimiliano Patacchiola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Storkey_A/0/1/0/all/0/1\">Amos Storkey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vazquez_J/0/1/0/all/0/1\">Jose Vazquez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Sen Wang</a>",
          "description": "Few-Shot Learning (FSL) algorithms are commonly trained through Meta-Learning\n(ML), which exposes models to batches of tasks sampled from a meta-dataset to\nmimic tasks seen during evaluation. However, the standard training procedures\noverlook the real-world dynamics where classes commonly occur at different\nfrequencies. While it is generally understood that class imbalance harms the\nperformance of supervised methods, limited research examines the impact of\nimbalance on the FSL evaluation task. Our analysis compares 10 state-of-the-art\nmeta-learning and FSL methods on different imbalance distributions and\nrebalancing techniques. Our results reveal that 1) some FSL methods display a\nnatural disposition against imbalance while most other approaches produce a\nperformance drop by up to 17\\% compared to the balanced task without the\nappropriate mitigation; 2) contrary to popular belief, many meta-learning\nalgorithms will not automatically learn to balance from exposure to imbalanced\ntraining tasks; 3) classical rebalancing strategies, such as random\noversampling, can still be very effective, leading to state-of-the-art\nperformances and should not be overlooked; 4) FSL methods are more robust\nagainst meta-dataset imbalance than imbalance at the task-level with a similar\nimbalance ratio ($\\rho<20$), with the effect holding even in long-tail datasets\nunder a larger imbalance ($\\rho=65$).",
          "link": "http://arxiv.org/abs/2101.02523",
          "publishedOn": "2021-06-15T01:45:15.417Z",
          "wordCount": 677,
          "title": "Few-Shot Learning with Class Imbalance. (arXiv:2101.02523v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.13504",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liao_P/0/1/0/all/0/1\">Peiyuan Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Han Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1\">Keyulu Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaakkola_T/0/1/0/all/0/1\">Tommi Jaakkola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gordon_G/0/1/0/all/0/1\">Geoffrey Gordon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jegelka_S/0/1/0/all/0/1\">Stefanie Jegelka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1\">Ruslan Salakhutdinov</a>",
          "description": "While the advent of Graph Neural Networks (GNNs) has greatly improved node\nand graph representation learning in many applications, the neighborhood\naggregation scheme exposes additional vulnerabilities to adversaries seeking to\nextract node-level information about sensitive attributes. In this paper, we\nstudy the problem of protecting sensitive attributes by information obfuscation\nwhen learning with graph structured data. We propose a framework to locally\nfilter out pre-determined sensitive attributes via adversarial training with\nthe total variation and the Wasserstein distance. Our method creates a strong\ndefense against inference attacks, while only suffering small loss in task\nperformance. Theoretically, we analyze the effectiveness of our framework\nagainst a worst-case adversary, and characterize an inherent trade-off between\nmaximizing predictive accuracy and minimizing information leakage. Experiments\nacross multiple datasets from recommender systems, knowledge graphs and quantum\nchemistry demonstrate that the proposed approach provides a robust defense\nacross various graph structures and tasks, while producing competitive GNN\nencoders for downstream tasks.",
          "link": "http://arxiv.org/abs/2009.13504",
          "publishedOn": "2021-06-15T01:45:15.403Z",
          "wordCount": 667,
          "title": "Information Obfuscation of Graph Neural Networks. (arXiv:2009.13504v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.12672",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lo_S/0/1/0/all/0/1\">Shaw-Hwa Lo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1\">Yiqiao Yin</a>",
          "description": "In the field of eXplainable AI (XAI), robust ``blackbox'' algorithms such as\nConvolutional Neural Networks (CNNs) are known for making high prediction\nperformance. However, the ability to explain and interpret these algorithms\nstill require innovation in the understanding of influential and, more\nimportantly, explainable features that directly or indirectly impact the\nperformance of predictivity. A number of methods existing in literature focus\non visualization techniques but the concepts of explainability and\ninterpretability still require rigorous definition. In view of the above needs,\nthis paper proposes an interaction-based methodology -- Influence Score\n(I-score) -- to screen out the noisy and non-informative variables in the\nimages hence it nourishes an environment with explainable and interpretable\nfeatures that are directly associated to feature predictivity. We apply the\nproposed method on a real world application in Pneumonia Chest X-ray Image data\nset and produced state-of-the-art results. We demonstrate how to apply the\nproposed approach for more general big data problems by improving the\nexplainability and interpretability without sacrificing the prediction\nperformance. The contribution of this paper opens a novel angle that moves the\ncommunity closer to the future pipelines of XAI problems.",
          "link": "http://arxiv.org/abs/2104.12672",
          "publishedOn": "2021-06-15T01:45:15.383Z",
          "wordCount": 656,
          "title": "A Novel Interaction-based Methodology Towards Explainable AI with Better Understanding of Pneumonia Chest X-ray Images. (arXiv:2104.12672v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.05077",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chrysos_G/0/1/0/all/0/1\">Grigorios G Chrysos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Georgopoulos_M/0/1/0/all/0/1\">Markos Georgopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panagakis_Y/0/1/0/all/0/1\">Yannis Panagakis</a>",
          "description": "Generative modeling has evolved to a notable field of machine learning. Deep\npolynomial neural networks (PNNs) have demonstrated impressive results in\nunsupervised image generation, where the task is to map an input vector (i.e.,\nnoise) to a synthesized image. However, the success of PNNs has not been\nreplicated in conditional generation tasks, such as super-resolution. Existing\nPNNs focus on single-variable polynomial expansions which do not fare well to\ntwo-variable inputs, i.e., the noise variable and the conditional variable. In\nthis work, we introduce a general framework, called CoPE, that enables a\npolynomial expansion of two input variables and captures their auto- and\ncross-correlations. We exhibit how CoPE can be trivially augmented to accept an\narbitrary number of input variables. CoPE is evaluated in five tasks\n(class-conditional generation, inverse problems, edges-to-image translation,\nimage-to-image translation, attribute-guided generation) involving eight\ndatasets. The thorough evaluation suggests that CoPE can be useful for tackling\ndiverse conditional generation tasks.",
          "link": "http://arxiv.org/abs/2104.05077",
          "publishedOn": "2021-06-15T01:45:15.327Z",
          "wordCount": 612,
          "title": "CoPE: Conditional image generation using Polynomial Expansions. (arXiv:2104.05077v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.10884",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cai_H/0/1/0/all/0/1\">Hongxiang Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jun Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1\">Yichao Xiong</a>",
          "description": "The prevalent perspectives of scene text recognition are from sequence to\nsequence (seq2seq) and segmentation. Nevertheless, the former is composed of\nmany components which makes implementation and deployment complicated, while\nthe latter requires character level annotations that is expensive. In this\npaper, we revisit classification perspective that models scene text recognition\nas an image classification problem. Classification perspective has a simple\npipeline and only needs word level annotations. We revive classification\nperspective by devising a scene text recognition model named as CSTR, which\nperforms as well as methods from other perspectives. The CSTR model consists of\nCPNet (classification perspective network) and SPPN (separated conv with global\naverage pooling prediction network). CSTR is as simple as image classification\nmodel like ResNet \\cite{he2016deep} which makes it easy to implement and\ndeploy. We demonstrate the effectiveness of the classification perspective on\nscene text recognition with extensive experiments. Futhermore, CSTR achieves\nnearly state-of-the-art performance on six public benchmarks including regular\ntext, irregular text. The code will be available at\nhttps://github.com/Media-Smart/vedastr.",
          "link": "http://arxiv.org/abs/2102.10884",
          "publishedOn": "2021-06-15T01:45:15.321Z",
          "wordCount": 635,
          "title": "Revisiting Classification Perspective on Scene Text Recognition. (arXiv:2102.10884v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.03716",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_W/0/1/0/all/0/1\">Wuxinlin Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_C/0/1/0/all/0/1\">Chenhui Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1\">Zhiqiang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1\">Yaohui Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhiru Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1\">Zhuo Feng</a>",
          "description": "A black-box spectral method is introduced for evaluating the adversarial\nrobustness of a given machine learning (ML) model. Our approach, named SPADE,\nexploits bijective distance mapping between the input/output graphs constructed\nfor approximating the manifolds corresponding to the input/output data. By\nleveraging the generalized Courant-Fischer theorem, we propose a SPADE score\nfor evaluating the adversarial robustness of a given model, which is proved to\nbe an upper bound of the best Lipschitz constant under the manifold setting. To\nreveal the most non-robust data samples highly vulnerable to adversarial\nattacks, we develop a spectral graph embedding procedure leveraging dominant\ngeneralized eigenvectors. This embedding step allows assigning each data sample\na robustness score that can be further harnessed for more effective adversarial\ntraining. Our experiments show the proposed SPADE method leads to promising\nempirical results for neural network models that are adversarially trained with\nthe MNIST and CIFAR-10 data sets.",
          "link": "http://arxiv.org/abs/2102.03716",
          "publishedOn": "2021-06-15T01:45:15.281Z",
          "wordCount": 635,
          "title": "SPADE: A Spectral Method for Black-Box Adversarial Robustness Evaluation. (arXiv:2102.03716v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.05522",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiashun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Huazhe Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jingwei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Sifei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaolong Wang</a>",
          "description": "Synthesizing 3D human motion plays an important role in many graphics\napplications as well as understanding human activity. While many efforts have\nbeen made on generating realistic and natural human motion, most approaches\nneglect the importance of modeling human-scene interactions and affordance. On\nthe other hand, affordance reasoning (e.g., standing on the floor or sitting on\nthe chair) has mainly been studied with static human pose and gestures, and it\nhas rarely been addressed with human motion. In this paper, we propose to\nbridge human motion synthesis and scene affordance reasoning. We present a\nhierarchical generative framework to synthesize long-term 3D human motion\nconditioning on the 3D scene structure. Building on this framework, we further\nenforce multiple geometry constraints between the human mesh and scene point\nclouds via optimization to improve realistic synthesis. Our experiments show\nsignificant improvements over previous approaches on generating natural and\nphysically plausible human motion in a scene.",
          "link": "http://arxiv.org/abs/2012.05522",
          "publishedOn": "2021-06-15T01:45:15.214Z",
          "wordCount": 617,
          "title": "Synthesizing Long-Term 3D Human Motion and Interaction in 3D Scenes. (arXiv:2012.05522v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.08524",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Garcia_Salguero_M/0/1/0/all/0/1\">Mercedes Garcia-Salguero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_Jimenez_J/0/1/0/all/0/1\">Javier Gonzalez-Jimenez</a>",
          "description": "This work contributes an efficient algorithm to compute the Relative Pose\nproblem (RPp) between calibrated cameras and certify the optimality of the\nsolution, given a set of pair-wise feature correspondences affected by noise\nand probably corrupted by wrong matches. We propose a family of certifiers that\nis shown to increase the ratio of detected optimal solutions. This set of\ncertifiers is incorporated into a fast essential matrix estimation pipeline\nthat, given any initial guess for the RPp, refines it iteratively on the\nproduct space of 3D rotations and 2-sphere. In addition, this fast certifiable\npipeline is integrated into a robust framework that combines Graduated\nNon-convexity and the Black-Rangarajan duality between robust functions and\nline processes.\n\nWe proved through extensive experiments on synthetic and real data that the\nproposed framework provides a fast and robust relative pose estimation. We make\nthe code publicly available\n\\url{https://github.com/mergarsal/FastCertRelPose.git}.",
          "link": "http://arxiv.org/abs/2101.08524",
          "publishedOn": "2021-06-15T01:45:15.205Z",
          "wordCount": 609,
          "title": "Fast and Robust Certifiable Estimation of the Relative Pose Between Two Calibrated Cameras. (arXiv:2101.08524v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.01158",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tushar_F/0/1/0/all/0/1\">Fakrul Islam Tushar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DAnniballe_V/0/1/0/all/0/1\">Vincent M. D&#x27;Anniballe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_R/0/1/0/all/0/1\">Rui Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mazurowski_M/0/1/0/all/0/1\">Maciej A. Mazurowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_W/0/1/0/all/0/1\">Wanyi Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samei_E/0/1/0/all/0/1\">Ehsan Samei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubin_G/0/1/0/all/0/1\">Geoffrey D. Rubin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lo_J/0/1/0/all/0/1\">Joseph Y. Lo</a>",
          "description": "Background: Training deep learning classifiers typically requires massive\namounts of manual annotation. Weak supervision may leverage existing medical\ndata to classify multiple diseases and organ systems. Purpose: To design\nmulti-disease classifiers for body computed tomography (CT) scans using\nautomatically extracted labels from radiology text reports. Materials &\nMethods: This retrospective study deployed rule-based algorithms to extract\n19,255 disease labels from reports of 13,667 body CT scans of 12,092 subjects\nfor training. Using a 3D DenseVNet, three organ systems were segmented:\nlungs/pleura, liver/gallbladder, and kidneys/ureters. For each organ, a 3D\nconvolutional neural network classified normality versus four common diseases.\nTesting was performed on an additional 2,158 CT volumes relative to 2,875\nmanually derived reference labels. Results: Manual validation of the extracted\nlabels confirmed 91 to 99% accuracy. Performance using the receiver operating\ncharacteristic area under the curve (AUC) for lungs/pleura labels were as\nfollows: atelectasis 0.77 (95% CI: 0.74 to 0.81), nodule 0.65 (0.61 to 0.69),\nemphysema 0.89 (0.86 to 0.92), effusion 0.97 (0.96 to 0.98), and normal 0.89\n(0.87 to 0.91). For liver/gallbladder: stone 0.62 (0.56 to 0.67), lesion 0.73\n(0.69 to 0.77), dilation 0.87 (0.84 to 0.90), fatty 0.89 (0.86 to 0.92), and\nnormal 0.82 (0.78 to 0.85). For kidneys/ureters: stone 0.83 (0.79 to 0.87),\natrophy 0.92 (0.89 to 0.94), lesion 0.68 (0.64 to 0.72), cyst 0.70 (0.66 to\n0.73), and normal 0.79 (0.75 to 0.83). Conclusion: Weakly supervised deep\nlearning classifiers leveraged massive amounts of unannotated body CT data to\nclassify multiple organ systems and diverse diseases.",
          "link": "http://arxiv.org/abs/2008.01158",
          "publishedOn": "2021-06-15T01:45:15.197Z",
          "wordCount": 749,
          "title": "Multi-Disease Classification of 13,667 Body CT Scans Using Weakly Supervised Deep Learning. (arXiv:2008.01158v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.01458",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1\">Shitong Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1\">Wei Hu</a>",
          "description": "We present a probabilistic model for point cloud generation, which is\nfundamental for various 3D vision tasks such as shape completion, upsampling,\nsynthesis and data augmentation. Inspired by the diffusion process in\nnon-equilibrium thermodynamics, we view points in point clouds as particles in\na thermodynamic system in contact with a heat bath, which diffuse from the\noriginal distribution to a noise distribution. Point cloud generation thus\namounts to learning the reverse diffusion process that transforms the noise\ndistribution to the distribution of a desired shape. Specifically, we propose\nto model the reverse diffusion process for point clouds as a Markov chain\nconditioned on certain shape latent. We derive the variational bound in closed\nform for training and provide implementations of the model. Experimental\nresults demonstrate that our model achieves competitive performance in point\ncloud generation and auto-encoding. The code is available at\n\\url{https://github.com/luost26/diffusion-point-cloud}.",
          "link": "http://arxiv.org/abs/2103.01458",
          "publishedOn": "2021-06-15T01:45:15.162Z",
          "wordCount": 602,
          "title": "Diffusion Probabilistic Models for 3D Point Cloud Generation. (arXiv:2103.01458v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06965",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fenglin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_C/0/1/0/all/0/1\">Changchang Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_S/0/1/0/all/0/1\">Shen Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Ping Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xu Sun</a>",
          "description": "Recently, chest X-ray report generation, which aims to automatically generate\ndescriptions of given chest X-ray images, has received growing research\ninterests. The key challenge of chest X-ray report generation is to accurately\ncapture and describe the abnormal regions. In most cases, the normal regions\ndominate the entire chest X-ray image, and the corresponding descriptions of\nthese normal regions dominate the final report. Due to such data bias,\nlearning-based models may fail to attend to abnormal regions. In this work, to\neffectively capture and describe abnormal regions, we propose the Contrastive\nAttention (CA) model. Instead of solely focusing on the current input image,\nthe CA model compares the current input image with normal images to distill the\ncontrastive information. The acquired contrastive information can better\nrepresent the visual features of abnormal regions. According to the experiments\non the public IU-X-ray and MIMIC-CXR datasets, incorporating our CA into\nseveral existing models can boost their performance across most metrics. In\naddition, according to the analysis, the CA model can help existing models\nbetter attend to the abnormal regions and provide more accurate descriptions\nwhich are crucial for an interpretable diagnosis. Specifically, we achieve the\nstate-of-the-art results on the two public datasets.",
          "link": "http://arxiv.org/abs/2106.06965",
          "publishedOn": "2021-06-15T01:45:15.131Z",
          "wordCount": 669,
          "title": "Contrastive Attention for Automatic Chest X-ray Report Generation. (arXiv:2106.06965v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2008.13305",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhijian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xin_J/0/1/0/all/0/1\">Jack Xin</a>",
          "description": "Deep Neural Networks (DNNs) needs to be both efficient and robust for\npractical uses. Quantization and structure simplification are promising ways to\nadapt DNNs to mobile devices, and adversarial training is the most popular\nmethod to make DNNs robust. In this work, we try to obtain both features by\napplying a convergent relaxation quantization algorithm, Binary-Relax (BR), to\na robust adversarial-trained model, ResNets Ensemble via Feynman-Kac Formalism\n(EnResNet). We also discover that high precision, such as ternary (tnn) and\n4-bit, quantization will produce sparse DNNs. However, this sparsity is\nunstructured under advarsarial training. To solve the problems that adversarial\ntraining jeopardizes DNNs' accuracy on clean images and the struture of\nsparsity, we design a trade-off loss function that helps DNNs preserve their\nnatural accuracy and improve the channel sparsity. With our trade-off loss\nfunction, we achieve both goals with no reduction of resistance under weak\nattacks and very minor reduction of resistance under strong attcks. Together\nwith quantized EnResNet with trade-off loss function, we provide robust models\nthat have high efficiency.",
          "link": "http://arxiv.org/abs/2008.13305",
          "publishedOn": "2021-06-15T01:45:15.114Z",
          "wordCount": 637,
          "title": "An Integrated Approach to Produce Robust Models with High Efficiency. (arXiv:2008.13305v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.13052",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chu_Z/0/1/0/all/0/1\">Zhendong Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jing Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongning Wang</a>",
          "description": "Crowdsourcing provides a practical way to obtain large amounts of labeled\ndata at a low cost. However, the annotation quality of annotators varies\nconsiderably, which imposes new challenges in learning a high-quality model\nfrom the crowdsourced annotations. In this work, we provide a new perspective\nto decompose annotation noise into common noise and individual noise and\ndifferentiate the source of confusion based on instance difficulty and\nannotator expertise on a per-instance-annotator basis. We realize this new\ncrowdsourcing model by an end-to-end learning solution with two types of noise\nadaptation layers: one is shared across annotators to capture their commonly\nshared confusions, and the other one is pertaining to each annotator to realize\nindividual confusion. To recognize the source of noise in each annotation, we\nuse an auxiliary network to choose the two noise adaptation layers with respect\nto both instances and annotators. Extensive experiments on both synthesized and\nreal-world benchmarks demonstrate the effectiveness of our proposed common\nnoise adaptation solution.",
          "link": "http://arxiv.org/abs/2012.13052",
          "publishedOn": "2021-06-15T01:45:15.093Z",
          "wordCount": 624,
          "title": "Learning from Crowds by Modeling Common Confusions. (arXiv:2012.13052v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06987",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Tripathi_A/0/1/0/all/0/1\">Arpan Tripathi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Panicker_M/0/1/0/all/0/1\">Mahesh Raveendranatha Panicker</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hareendranathan_A/0/1/0/all/0/1\">Abhilash R Hareendranathan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_Y/0/1/0/all/0/1\">Yale Tung Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jaremko_J/0/1/0/all/0/1\">Jacob L Jaremko</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Narayan_K/0/1/0/all/0/1\">Kiran Vishnu Narayan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+C_K/0/1/0/all/0/1\">Kesavadas C</a>",
          "description": "Lung ultrasound (LUS) is an increasingly popular diagnostic imaging modality\nfor continuous and periodic monitoring of lung infection, given its advantages\nof non-invasiveness, non-ionizing nature, portability and easy disinfection.\nThe major landmarks assessed by clinicians for triaging using LUS are pleura, A\nand B lines. There have been many efforts for the automatic detection of these\nlandmarks. However, restricting to a few pre-defined landmarks may not reveal\nthe actual imaging biomarkers particularly in case of new pathologies like\nCOVID-19. Rather, the identification of key landmarks should be driven by data\ngiven the availability of a plethora of neural network algorithms. This work is\na first of its kind attempt towards unsupervised detection of the key LUS\nlandmarks in LUS videos of COVID-19 subjects during various stages of\ninfection. We adapted the relatively newer approach of transporter neural\nnetworks to automatically mark and track pleura, A and B lines based on their\nperiodic motion and relatively stable appearance in the videos. Initial results\non unsupervised pleura detection show an accuracy of 91.8% employing 1081 LUS\nvideo frames.",
          "link": "http://arxiv.org/abs/2106.06987",
          "publishedOn": "2021-06-15T01:45:15.073Z",
          "wordCount": 688,
          "title": "Learning the Imaging Landmarks: Unsupervised Key point Detection in Lung Ultrasound Videos. (arXiv:2106.06987v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2008.05221",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_M/0/1/0/all/0/1\">Manish Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_P/0/1/0/all/0/1\">Puneet Agrawal</a>",
          "description": "In recent years, the fields of natural language processing (NLP) and\ninformation retrieval (IR) have made tremendous progress thanksto deep learning\nmodels like Recurrent Neural Networks (RNNs), Gated Recurrent Units (GRUs) and\nLong Short-Term Memory (LSTMs)networks, and Transformer [120] based models like\nBidirectional Encoder Representations from Transformers (BERT) [24],\nGenerativePre-training Transformer (GPT-2) [94], Multi-task Deep Neural Network\n(MT-DNN) [73], Extra-Long Network (XLNet) [134], Text-to-text transfer\ntransformer (T5) [95], T-NLG [98] and GShard [63]. But these models are\nhumongous in size. On the other hand,real world applications demand small model\nsize, low response times and low computational power wattage. In this survey,\nwediscuss six different types of methods (Pruning, Quantization, Knowledge\nDistillation, Parameter Sharing, Tensor Decomposition, andSub-quadratic\nTransformer based methods) for compression of such models to enable their\ndeployment in real industry NLP projects.Given the critical need of building\napplications with efficient and small models, and the large amount of recently\npublished work inthis area, we believe that this survey organizes the plethora\nof work done by the 'deep learning for NLP' community in the past fewyears and\npresents it as a coherent story.",
          "link": "http://arxiv.org/abs/2008.05221",
          "publishedOn": "2021-06-15T01:45:15.047Z",
          "wordCount": 675,
          "title": "Compression of Deep Learning Models for Text: A Survey. (arXiv:2008.05221v4 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1912.07812",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1\">Guangyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Etemad_A/0/1/0/all/0/1\">Ali Etemad</a>",
          "description": "Driver vigilance estimation is an important task for transportation safety.\nWearable and portable brain-computer interface devices provide a powerful means\nfor real-time monitoring of the vigilance level of drivers to help with\navoiding distracted or impaired driving. In this paper, we propose a novel\nmultimodal architecture for in-vehicle vigilance estimation from\nElectroencephalogram and Electrooculogram. To enable the system to focus on the\nmost salient parts of the learned multimodal representations, we propose an\narchitecture composed of a capsule attention mechanism following a deep Long\nShort-Term Memory (LSTM) network. Our model learns hierarchical dependencies in\nthe data through the LSTM and capsule feature representation layers. To better\nexplore the discriminative ability of the learned representations, we study the\neffect of the proposed capsule attention mechanism including the number of\ndynamic routing iterations as well as other parameters. Experiments show the\nrobustness of our method by outperforming other solutions and baseline\ntechniques, setting a new state-of-the-art. We then provide an analysis on\ndifferent frequency bands and brain regions to evaluate their suitability for\ndriver vigilance estimation. Lastly, an analysis on the role of capsule\nattention, multimodality, and robustness to noise is performed, highlighting\nthe advantages of our approach.",
          "link": "http://arxiv.org/abs/1912.07812",
          "publishedOn": "2021-06-15T01:45:15.006Z",
          "wordCount": 700,
          "title": "Capsule Attention for Multimodal EEG-EOG Representation Learning with Application to Driver Vigilance Estimation. (arXiv:1912.07812v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.09453",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hossain_M/0/1/0/all/0/1\">Md Tahmid Hossain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teng_S/0/1/0/all/0/1\">Shyh Wei Teng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sohel_F/0/1/0/all/0/1\">Ferdous Sohel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_G/0/1/0/all/0/1\">Guojun Lu</a>",
          "description": "Convolutional Neural Network's (CNN's) performance disparity on clean and\ncorrupted datasets has recently come under scrutiny. In this work, we analyse\ncommon corruptions in the frequency domain, i.e., High Frequency corruptions\n(HFc, e.g., noise) and Low Frequency corruptions (LFc, e.g., blur). Although a\nsimple solution to HFc is low-pass filtering, ReLU -- a widely used Activation\nFunction (AF), does not have any filtering mechanism. In this work, we instill\nlow-pass filtering into the AF (LP-ReLU) to improve robustness against HFc. To\ndeal with LFc, we complement LP-ReLU with Discrete Cosine Transform based\naugmentation. LP-ReLU, coupled with DCT augmentation, enables a deep network to\ntackle the entire spectrum of corruption. We use CIFAR-10-C and Tiny ImageNet-C\nfor evaluation and demonstrate improvements of 5% and 7.3% in accuracy\nrespectively, compared to the State-Of-The-Art (SOTA). We further evaluate our\nmethod's stability on a variety of perturbations in CIFAR-10-P and Tiny\nImageNet-P, achieving new SOTA in these experiments as well. To further\nstrengthen our understanding regarding CNN's lack of robustness, a decision\nspace visualisation process is proposed and presented in this work.",
          "link": "http://arxiv.org/abs/2007.09453",
          "publishedOn": "2021-06-15T01:45:14.986Z",
          "wordCount": 647,
          "title": "Robust Image Classification Using A Low-Pass Activation Function and DCT Augmentation. (arXiv:2007.09453v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06963",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fenglin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_S/0/1/0/all/0/1\">Shen Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_W/0/1/0/all/0/1\">Wei Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1\">Yuexian Zou</a>",
          "description": "Automatically generating radiology reports can improve current clinical\npractice in diagnostic radiology. On one hand, it can relieve radiologists from\nthe heavy burden of report writing; On the other hand, it can remind\nradiologists of abnormalities and avoid the misdiagnosis and missed diagnosis.\nYet, this task remains a challenging job for data-driven neural networks, due\nto the serious visual and textual data biases. To this end, we propose a\nPosterior-and-Prior Knowledge Exploring-and-Distilling approach (PPKED) to\nimitate the working patterns of radiologists, who will first examine the\nabnormal regions and assign the disease topic tags to the abnormal regions, and\nthen rely on the years of prior medical knowledge and prior working experience\naccumulations to write reports. Thus, the PPKED includes three modules:\nPosterior Knowledge Explorer (PoKE), Prior Knowledge Explorer (PrKE) and\nMulti-domain Knowledge Distiller (MKD). In detail, PoKE explores the posterior\nknowledge, which provides explicit abnormal visual regions to alleviate visual\ndata bias; PrKE explores the prior knowledge from the prior medical knowledge\ngraph (medical knowledge) and prior radiology reports (working experience) to\nalleviate textual data bias. The explored knowledge is distilled by the MKD to\ngenerate the final reports. Evaluated on MIMIC-CXR and IU-Xray datasets, our\nmethod is able to outperform previous state-of-the-art models on these two\ndatasets.",
          "link": "http://arxiv.org/abs/2106.06963",
          "publishedOn": "2021-06-15T01:45:14.960Z",
          "wordCount": 656,
          "title": "Exploring and Distilling Posterior and Prior Knowledge for Radiology Report Generation. (arXiv:2106.06963v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06966",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Huapeng Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gui_J/0/1/0/all/0/1\">Jie Gui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwok_J/0/1/0/all/0/1\">James T. Kwok</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1\">Zhihui Wei</a>",
          "description": "Recently, convolutional neural network (CNN) based image super-resolution\n(SR) methods have achieved significant performance improvement. However, most\nCNN-based methods mainly focus on feed-forward architecture design and neglect\nto explore the feedback mechanism, which usually exists in the human visual\nsystem. In this paper, we propose feedback pyramid attention networks (FPAN) to\nfully exploit the mutual dependencies of features. Specifically, a novel\nfeedback connection structure is developed to enhance low-level feature\nexpression with high-level information. In our method, the output of each layer\nin the first stage is also used as the input of the corresponding layer in the\nnext state to re-update the previous low-level filters. Moreover, we introduce\na pyramid non-local structure to model global contextual information in\ndifferent scales and improve the discriminative representation of the network.\nExtensive experimental results on various datasets demonstrate the superiority\nof our FPAN in comparison with the state-of-the-art SR methods.",
          "link": "http://arxiv.org/abs/2106.06966",
          "publishedOn": "2021-06-15T01:45:14.927Z",
          "wordCount": 581,
          "title": "Feedback Pyramid Attention Networks for Single Image Super-Resolution. (arXiv:2106.06966v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06744",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yujiao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jie Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xiaoshui Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_S/0/1/0/all/0/1\">Sai Ho Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_S/0/1/0/all/0/1\">Steven Weidong Su</a>",
          "description": "Lung cancer is the leading cause of cancer death worldwide. The critical\nreason for the deaths is delayed diagnosis and poor prognosis. With the\naccelerated development of deep learning techniques, it has been successfully\napplied extensively in many real-world applications, including health sectors\nsuch as medical image interpretation and disease diagnosis. By combining more\nmodalities that being engaged in the processing of information, multimodal\nlearning can extract better features and improve predictive ability. The\nconventional methods for lung cancer survival analysis normally utilize\nclinical data and only provide a statistical probability. To improve the\nsurvival prediction accuracy and help prognostic decision-making in clinical\npractice for medical experts, we for the first time propose a multimodal deep\nlearning method for non-small cell lung cancer (NSCLC) survival analysis, named\nDeepMMSA. This method leverages CT images in combination with clinical data,\nenabling the abundant information hold within medical images to be associate\nwith lung cancer survival information. We validate our method on the data of\n422 NSCLC patients from The Cancer Imaging Archive (TCIA). Experimental results\nsupport our hypothesis that there is an underlying relationship between\nprognostic information and radiomic images. Besides, quantitative results\nshowing that the established multimodal model can be applied to traditional\nmethod and has the potential to break bottleneck of existing methods and\nincrease the the percentage of concordant pairs(right predicted pairs) in\noverall population by 4%.",
          "link": "http://arxiv.org/abs/2106.06744",
          "publishedOn": "2021-06-15T01:45:14.921Z",
          "wordCount": 679,
          "title": "DeepMMSA: A Novel Multimodal Deep Learning Method for Non-small Cell Lung Cancer Survival Analysis. (arXiv:2106.06744v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06921",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1\">Sixing Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_P/0/1/0/all/0/1\">Phuong Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anwar_A/0/1/0/all/0/1\">Ali Anwar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jannesari_A/0/1/0/all/0/1\">Ali Jannesari</a>",
          "description": "Federated Learning~(FL) has emerged as a new paradigm of training machine\nlearning models without sacrificing data security and privacy. Learning models\nat edge devices such as cell phones is one of the most common use case of FL.\nHowever, the limited computing power and energy constraints of edge devices\nhinder the adoption of FL for both model training and deployment, especially\nfor the resource-hungry Deep Neural Networks~(DNNs). To this end, many model\ncompression methods have been proposed and network pruning is among the most\nwell-known. However, a pruning policy for a given model is highly\ndataset-dependent, which is not suitable for non-Independent and Identically\nDistributed~(Non-IID) FL edge devices. In this paper, we present an adaptive\npruning scheme for edge devices in an FL system, which applies dataset-aware\ndynamic pruning for inference acceleration on Non-IID datasets. Our evaluation\nshows that the proposed method accelerates inference by $2\\times$~($50\\%$ FLOPs\nreduction) while maintaining the model's quality on edge devices.",
          "link": "http://arxiv.org/abs/2106.06921",
          "publishedOn": "2021-06-15T01:45:14.914Z",
          "wordCount": 585,
          "title": "Adaptive Dynamic Pruning for Non-IID Federated Learning. (arXiv:2106.06921v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2009.06701",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sato_T/0/1/0/all/0/1\">Takami Sato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1\">Junjie Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_N/0/1/0/all/0/1\">Ningfei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1\">Yunhan Jack Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1\">Xue Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qi Alfred Chen</a>",
          "description": "Automated Lane Centering (ALC) systems are convenient and widely deployed\ntoday, but also highly security and safety critical. In this work, we are the\nfirst to systematically study the security of state-of-the-art deep learning\nbased ALC systems in their designed operational domains under physical-world\nadversarial attacks. We formulate the problem with a safety-critical attack\ngoal, and a novel and domain-specific attack vector: dirty road patches. To\nsystematically generate the attack, we adopt an optimization-based approach and\novercome domain-specific design challenges such as camera frame\ninter-dependencies due to attack-influenced vehicle control, and the lack of\nobjective function design for lane detection models.\n\nWe evaluate our attack on a production ALC using 80 scenarios from real-world\ndriving traces. The results show that our attack is highly effective with over\n97.5% success rates and less than 0.903 sec average success time, which is\nsubstantially lower than the average driver reaction time. This attack is also\nfound (1) robust to various real-world factors such as lighting conditions and\nview angles, (2) general to different model designs, and (3) stealthy from the\ndriver's view. To understand the safety impacts, we conduct experiments using\nsoftware-in-the-loop simulation and attack trace injection in a real vehicle.\nThe results show that our attack can cause a 100% collision rate in different\nscenarios, including when tested with common safety features such as automatic\nemergency braking. We also evaluate and discuss defenses.",
          "link": "http://arxiv.org/abs/2009.06701",
          "publishedOn": "2021-06-15T01:45:14.895Z",
          "wordCount": 726,
          "title": "Dirty Road Can Attack: Security of Deep Learning based Automated Lane Centering under Physical-World Attack. (arXiv:2009.06701v2 [cs.CR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06649",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Thuy C. Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_T/0/1/0/all/0/1\">Tuan N. Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Phan_N/0/1/0/all/0/1\">Nam LH. Phan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_C/0/1/0/all/0/1\">Chuong H. Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamazaki_M/0/1/0/all/0/1\">Masayuki Yamazaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamanaka_M/0/1/0/all/0/1\">Masao Yamanaka</a>",
          "description": "Video Instance Segmentation (VIS) is a multi-task problem performing\ndetection, segmentation, and tracking simultaneously. Extended from image set\napplications, video data additionally induces the temporal information, which,\nif handled appropriately, is very useful to identify and predict object\nmotions. In this work, we design a unified model to mutually learn these tasks.\nSpecifically, we propose two modules, named Temporally Correlated Instance\nSegmentation (TCIS) and Bidirectional Tracking (BiTrack), to take the benefit\nof the temporal correlation between the object's instance masks across adjacent\nframes. On the other hand, video data is often redundant due to the frame's\noverlap. Our analysis shows that this problem is particularly severe for the\nYoutubeVOS-VIS2021 data. Therefore, we propose a Multi-Source Data (MSD)\ntraining mechanism to compensate for the data deficiency. By combining these\ntechniques with a bag of tricks, the network performance is significantly\nboosted compared to the baseline, and outperforms other methods by a\nconsiderable margin on the YoutubeVOS-VIS 2019 and 2021 datasets.",
          "link": "http://arxiv.org/abs/2106.06649",
          "publishedOn": "2021-06-15T01:45:14.875Z",
          "wordCount": 604,
          "title": "1st Place Solution for YouTubeVOS Challenge 2021:Video Instance Segmentation. (arXiv:2106.06649v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06896",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yunhao Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mengmeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianbu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1\">Weiwei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_R/0/1/0/all/0/1\">Ran Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_Q/0/1/0/all/0/1\">Qian Du</a>",
          "description": "The monitoring of coastal wetlands is of great importance to the protection\nof marine and terrestrial ecosystems. However, due to the complex environment,\nsevere vegetation mixture, and difficulty of access, it is impossible to\naccurately classify coastal wetlands and identify their species with\ntraditional classifiers. Despite the integration of multisource remote sensing\ndata for performance enhancement, there are still challenges with acquiring and\nexploiting the complementary merits from multisource data. In this paper, the\nDeepwise Feature Interaction Network (DFINet) is proposed for wetland\nclassification. A depthwise cross attention module is designed to extract\nself-correlation and cross-correlation from multisource feature pairs. In this\nway, meaningful complementary information is emphasized for classification.\nDFINet is optimized by coordinating consistency loss, discrimination loss, and\nclassification loss. Accordingly, DFINet reaches the standard solution-space\nunder the regularity of loss functions, while the spatial consistency and\nfeature discrimination are preserved. Comprehensive experimental results on two\nhyperspectral and multispectral wetland datasets demonstrate that the proposed\nDFINet outperforms other competitive methods in terms of overall accuracy.",
          "link": "http://arxiv.org/abs/2106.06896",
          "publishedOn": "2021-06-15T01:45:14.837Z",
          "wordCount": 621,
          "title": "Hyperspectral and Multispectral Classification for Coastal Wetland Using Depthwise Feature Interaction Network. (arXiv:2106.06896v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06718",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Vago_N/0/1/0/all/0/1\">Nicol&#xf2; Oreste Pinciroli Vago</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Hameed_I/0/1/0/all/0/1\">Ibrahim A. Hameed</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Kachelriess_M/0/1/0/all/0/1\">Michael Kachelriess</a>",
          "description": "The presence of non-zero helicity in intergalactic magnetic fields is a\nsmoking gun for their primordial origin since they have to be generated by\nprocesses that break CP invariance. As an experimental signature for the\npresence of helical magnetic fields, an estimator $Q$ based on the triple\nscalar product of the wave-vectors of photons generated in electromagnetic\ncascades from, e.g., TeV blazars, has been suggested previously. We propose to\napply deep learning to helicity classification employing Convolutional Neural\nNetworks and show that this method outperforms the $Q$ estimator.",
          "link": "http://arxiv.org/abs/2106.06718",
          "publishedOn": "2021-06-15T01:45:14.776Z",
          "wordCount": 567,
          "title": "Using Convolutional Neural Networks for the Helicity Classification of Magnetic Fields. (arXiv:2106.06718v1 [astro-ph.HE])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06927",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rojas_Gomez_R/0/1/0/all/0/1\">Renan A. Rojas-Gomez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeh_R/0/1/0/all/0/1\">Raymond A. Yeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Do_M/0/1/0/all/0/1\">Minh N. Do</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1\">Anh Nguyen</a>",
          "description": "Recent research in adversarially robust classifiers suggests their\nrepresentations tend to be aligned with human perception, which makes them\nattractive for image synthesis and restoration applications. Despite favorable\nempirical results on a few downstream tasks, their advantages are limited to\nslow and sensitive optimization-based techniques. Moreover, their use on\ngenerative models remains unexplored. This work proposes the use of robust\nrepresentations as a perceptual primitive for feature inversion models, and\nshow its benefits with respect to standard non-robust image features. We\nempirically show that adopting robust representations as an image prior\nsignificantly improves the reconstruction accuracy of CNN-based feature\ninversion models. Furthermore, it allows reconstructing images at multiple\nscales out-of-the-box. Following these findings, we propose an\nencoding-decoding network based on robust representations and show its\nadvantages for applications such as anomaly detection, style transfer and image\ndenoising.",
          "link": "http://arxiv.org/abs/2106.06927",
          "publishedOn": "2021-06-15T01:45:14.712Z",
          "wordCount": 577,
          "title": "Inverting Adversarially Robust Networks for Image Synthesis. (arXiv:2106.06927v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06801",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pandey_P/0/1/0/all/0/1\">Prashant Pandey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pai_A/0/1/0/all/0/1\">Ajey Pai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhatt_N/0/1/0/all/0/1\">Nisarg Bhatt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_P/0/1/0/all/0/1\">Prasenjit Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Makharia_G/0/1/0/all/0/1\">Govind Makharia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+AP_P/0/1/0/all/0/1\">Prathosh AP</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mausam/0/1/0/all/0/1\">Mausam</a>",
          "description": "Contrastive Learning (CL) is a recent representation learning approach, which\nachieves promising results by encouraging inter-class separability and\nintra-class compactness in learned image representations. Because medical\nimages often contain multiple classes of interest per image, a standard\nimage-level CL for these images is not applicable. In this work, we present a\nnovel semi-supervised 2D medical segmentation solution that applies CL on image\npatches, instead of full images. These patches are meaningfully constructed\nusing the semantic information of different classes obtained via pseudo\nlabeling. We also propose a novel consistency regularization scheme, which\nworks in synergy with contrastive learning. It addresses the problem of\nconfirmation bias often observed in semi-supervised settings, and encourages\nbetter clustering in the feature space. We evaluate our method on four public\nmedical segmentation datasets along with a novel histopathology dataset that we\nintroduce. Our method obtains consistent improvements over the state-of-the-art\nsemi-supervised segmentation approaches for all datasets.",
          "link": "http://arxiv.org/abs/2106.06801",
          "publishedOn": "2021-06-15T01:45:14.702Z",
          "wordCount": 588,
          "title": "Contrastive Semi-Supervised Learning for 2D Medical Image Segmentation. (arXiv:2106.06801v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06946",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Horvath_M/0/1/0/all/0/1\">Mikl&#xf3;s Z. Horv&#xe1;th</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muller_M/0/1/0/all/0/1\">Mark Niklas M&#xfc;ller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fischer_M/0/1/0/all/0/1\">Marc Fischer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vechev_M/0/1/0/all/0/1\">Martin Vechev</a>",
          "description": "Randomized Smoothing (RS) is a promising method for obtaining robustness\ncertificates by evaluating a base model under noise. In this work we: (i)\ntheoretically motivate why ensembles are a particularly suitable choice as base\nmodels for RS, and (ii) empirically confirm this choice, obtaining state of the\nart results in multiple settings. The key insight of our work is that the\nreduced variance of ensembles over the perturbations introduced in RS leads to\nsignificantly more consistent classifications for a given input, in turn\nleading to substantially increased certifiable radii for difficult samples. We\nalso introduce key optimizations which enable an up to 50-fold decrease in\nsample complexity of RS, thus drastically reducing its computational overhead.\nExperimentally, we show that ensembles of only 3 to 10 classifiers consistently\nimprove on the strongest single model with respect to their average certified\nradius (ACR) by 5% to 21% on both CIFAR-10 and ImageNet. On the latter, we\nachieve a state-of-the-art ACR of 1.11. We release all code and models required\nto reproduce our results upon publication.",
          "link": "http://arxiv.org/abs/2106.06946",
          "publishedOn": "2021-06-15T01:45:14.670Z",
          "wordCount": 608,
          "title": "Boosting Randomized Smoothing with Variance Reduced Classifiers. (arXiv:2106.06946v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06792",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gu_L/0/1/0/all/0/1\">Lingyun Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhaokui Wang</a>",
          "description": "Visual surface inspection is a challenging task owing to the highly diverse\nappearance of target surfaces and defective regions. Previous attempts heavily\nrely on vast quantities of training examples with manual annotation. However,\nin some practical cases, it is difficult to obtain a large number of samples\nfor inspection. To combat it, we propose a hierarchical texture-perceiving\ngenerative adversarial network (HTP-GAN) that is learned from the one-shot\nnormal image in an unsupervised scheme. Specifically, the HTP-GAN contains a\npyramid of convolutional GANs that can capture the global structure and\nfine-grained representation of an image simultaneously. This innovation helps\ndistinguishing defective surface regions from normal ones. In addition, in the\ndiscriminator, a texture-perceiving module is devised to capture the spatially\ninvariant representation of normal image via directional convolutions, making\nit more sensitive to defective areas. Experiments on a variety of datasets\nconsistently demonstrate the effectiveness of our method.",
          "link": "http://arxiv.org/abs/2106.06792",
          "publishedOn": "2021-06-15T01:45:14.642Z",
          "wordCount": 584,
          "title": "A One-Shot Texture-Perceiving Generative Adversarial Network for Unsupervised Surface Inspection. (arXiv:2106.06792v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06942",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qing_Z/0/1/0/all/0/1\">Zhiwu Qing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Ziyuan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yutong Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shiwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jianwen Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_M/0/1/0/all/0/1\">Mingqian Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1\">Changxin Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ang_M/0/1/0/all/0/1\">Marcelo H. Ang Jr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sang_N/0/1/0/all/0/1\">Nong Sang</a>,",
          "description": "This technical report analyzes an egocentric video action detection method we\nused in the 2021 EPIC-KITCHENS-100 competition hosted in CVPR2021 Workshop. The\ngoal of our task is to locate the start time and the end time of the action in\nthe long untrimmed video, and predict action category. We adopt sliding window\nstrategy to generate proposals, which can better adapt to short-duration\nactions. In addition, we show that classification and proposals are conflict in\nthe same network. The separation of the two tasks boost the detection\nperformance with high efficiency. By simply employing these strategy, we\nachieved 16.10\\% performance on the test set of EPIC-KITCHENS-100 Action\nDetection challenge using a single model, surpassing the baseline method by\n11.7\\% in terms of average mAP.",
          "link": "http://arxiv.org/abs/2106.06942",
          "publishedOn": "2021-06-15T01:45:14.636Z",
          "wordCount": 570,
          "title": "A Stronger Baseline for Ego-Centric Action Detection. (arXiv:2106.06942v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06672",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shenao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Li Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhifeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wei Liu</a>",
          "description": "Capturing contextual dependencies has proven useful to improve the\nrepresentational power of deep neural networks. Recent approaches that focus on\nmodeling global context, such as self-attention and non-local operation,\nachieve this goal by enabling unconstrained pairwise interactions between\nelements. In this work, we consider learning representations for deformable\nobjects which can benefit from context exploitation by modeling the structural\ndependencies that the data intrinsically possesses. To this end, we provide a\nnovel structure-regularized attention mechanism, which formalizes feature\ninteraction as structural factorization through the use of a pair of\nlight-weight operations. The instantiated building blocks can be directly\nincorporated into modern convolutional neural networks, to boost the\nrepresentational power in an efficient manner. Comprehensive studies on\nmultiple tasks and empirical comparisons with modern attention mechanisms\ndemonstrate the gains brought by our method in terms of both performance and\nmodel complexity. We further investigate its effect on feature representations,\nshowing that our trained models can capture diversified representations\ncharacterizing object parts without resorting to extra supervision.",
          "link": "http://arxiv.org/abs/2106.06672",
          "publishedOn": "2021-06-15T01:45:14.628Z",
          "wordCount": 611,
          "title": "Structure-Regularized Attention for Deformable Object Representation. (arXiv:2106.06672v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06736",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brousmiche_M/0/1/0/all/0/1\">Mathilde Brousmiche</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rouat_J/0/1/0/all/0/1\">Jean Rouat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dupont_S/0/1/0/all/0/1\">St&#xe9;phane Dupont</a>",
          "description": "Event classification is inherently sequential and multimodal. Therefore, deep\nneural models need to dynamically focus on the most relevant time window and/or\nmodality of a video. In this study, we propose the Multi-level Attention Fusion\nnetwork (MAFnet), an architecture that can dynamically fuse visual and audio\ninformation for event recognition. Inspired by prior studies in neuroscience,\nwe couple both modalities at different levels of visual and audio paths.\nFurthermore, the network dynamically highlights a modality at a given time\nwindow relevant to classify events. Experimental results in AVE (Audio-Visual\nEvent), UCF51, and Kinetics-Sounds datasets show that the approach can\neffectively improve the accuracy in audio-visual event classification. Code is\navailable at: https://github.com/numediart/MAFnet",
          "link": "http://arxiv.org/abs/2106.06736",
          "publishedOn": "2021-06-15T01:45:14.617Z",
          "wordCount": 555,
          "title": "Multi-level Attention Fusion Network for Audio-visual Event Recognition. (arXiv:2106.06736v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06620",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Taghanaki_S/0/1/0/all/0/1\">Saeid Asgari Taghanaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_K/0/1/0/all/0/1\">Kristy Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khasahmadi_A/0/1/0/all/0/1\">Amir Khasahmadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_A/0/1/0/all/0/1\">Anirudh Goyal</a>",
          "description": "A fundamental challenge in artificial intelligence is learning useful\nrepresentations of data that yield good performance on a downstream task,\nwithout overfitting to spurious input features. Extracting such task-relevant\npredictive information is particularly difficult for real-world datasets. In\nthis work, we propose Contrastive Input Morphing (CIM), a representation\nlearning framework that learns input-space transformations of the data to\nmitigate the effect of irrelevant input features on downstream performance. Our\nmethod leverages a perceptual similarity metric via a triplet loss to ensure\nthat the transformation preserves task-relevant information.Empirically, we\ndemonstrate the efficacy of our approach on tasks which typically suffer from\nthe presence of spurious correlations: classification with nuisance\ninformation, out-of-distribution generalization, and preservation of subgroup\naccuracies. We additionally show that CIM is complementary to other mutual\ninformation-based representation learning techniques, and demonstrate that it\nimproves the performance of variational information bottleneck (VIB) when used\ntogether.",
          "link": "http://arxiv.org/abs/2106.06620",
          "publishedOn": "2021-06-15T01:45:14.594Z",
          "wordCount": 580,
          "title": "Robust Representation Learning via Perceptual Similarity Metrics. (arXiv:2106.06620v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06960",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cui_M/0/1/0/all/0/1\">Mengmeng Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jinjin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Liang Wang</a>",
          "description": "Attention-based encoder-decoder framework is widely used in the scene text\nrecognition task. However, for the current state-of-the-art(SOTA) methods,\nthere is room for improvement in terms of the efficient usage of local visual\nand global context information of the input text image, as well as the robust\ncorrelation between the scene processing module(encoder) and the text\nprocessing module(decoder). In this paper, we propose a Representation and\nCorrelation Enhanced Encoder-Decoder Framework(RCEED) to address these\ndeficiencies and break performance bottleneck. In the encoder module, local\nvisual feature, global context feature, and position information are aligned\nand fused to generate a small-size comprehensive feature map. In the decoder\nmodule, two methods are utilized to enhance the correlation between scene and\ntext feature space. 1) The decoder initialization is guided by the holistic\nfeature and global glimpse vector exported from the encoder. 2) The feature\nenriched glimpse vector produced by the Multi-Head General Attention is used to\nassist the RNN iteration and the character prediction at each time step.\nMeanwhile, we also design a Layernorm-Dropout LSTM cell to improve model's\ngeneralization towards changeable texts. Extensive experiments on the\nbenchmarks demonstrate the advantageous performance of RCEED in scene text\nrecognition tasks, especially the irregular ones.",
          "link": "http://arxiv.org/abs/2106.06960",
          "publishedOn": "2021-06-15T01:45:14.574Z",
          "wordCount": 639,
          "title": "Representation and Correlation Enhanced Encoder-Decoder Framework for Scene Text Recognition. (arXiv:2106.06960v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06593",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1\">Kedan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chong_M/0/1/0/all/0/1\">Min jin Chong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jeffrey Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jingen Liu</a>",
          "description": "Virtual try-on methods aim to generate images of fashion models wearing\narbitrary combinations of garments. This is a challenging task because the\ngenerated image must appear realistic and accurately display the interaction\nbetween garments. Prior works produce images that are filled with artifacts and\nfail to capture important visual details necessary for commercial applications.\nWe propose Outfit Visualization Net (OVNet) to capture these important details\n(e.g. buttons, shading, textures, realistic hemlines, and interactions between\ngarments) and produce high quality multiple-garment virtual try-on images.\nOVNet consists of 1) a semantic layout generator and 2) an image generation\npipeline using multiple coordinated warps. We train the warper to output\nmultiple warps using a cascade loss, which refines each successive warp to\nfocus on poorly generated regions of a previous warp and yields consistent\nimprovements in detail. In addition, we introduce a method for matching outfits\nwith the most suitable model and produce significant improvements for both our\nand other previous try-on methods. Through quantitative and qualitative\nanalysis, we demonstrate our method generates substantially higher-quality\nstudio images compared to prior works for multi-garment outfits. An interactive\ninterface powered by this method has been deployed on fashion e-commerce\nwebsites and received overwhelmingly positive feedback.",
          "link": "http://arxiv.org/abs/2106.06593",
          "publishedOn": "2021-06-15T01:45:14.568Z",
          "wordCount": 653,
          "title": "Toward Accurate and Realistic Outfits Visualization with Attention to Details. (arXiv:2106.06593v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06685",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Picot_M/0/1/0/all/0/1\">Marine Picot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Messina_F/0/1/0/all/0/1\">Francisco Messina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boudiaf_M/0/1/0/all/0/1\">Malik Boudiaf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Labeau_F/0/1/0/all/0/1\">Fabrice Labeau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ayed_I/0/1/0/all/0/1\">Ismail Ben Ayed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piantanida_P/0/1/0/all/0/1\">Pablo Piantanida</a>",
          "description": "Adversarial robustness has become a topic of growing interest in machine\nlearning since it was observed that neural networks tend to be brittle. We\npropose an information-geometric formulation of adversarial defense and\nintroduce FIRE, a new Fisher-Rao regularization for the categorical\ncross-entropy loss, which is based on the geodesic distance between natural and\nperturbed input features. Based on the information-geometric properties of the\nclass of softmax distributions, we derive an explicit characterization of the\nFisher-Rao Distance (FRD) for the binary and multiclass cases, and draw some\ninteresting properties as well as connections with standard regularization\nmetrics. Furthermore, for a simple linear and Gaussian model, we show that all\nPareto-optimal points in the accuracy-robustness region can be reached by FIRE\nwhile other state-of-the-art methods fail. Empirically, we evaluate the\nperformance of various classifiers trained with the proposed loss on standard\ndatasets, showing up to 2\\% of improvements in terms of robustness while\nreducing the training time by 20\\% over the best-performing methods.",
          "link": "http://arxiv.org/abs/2106.06685",
          "publishedOn": "2021-06-15T01:45:14.557Z",
          "wordCount": 595,
          "title": "Adversarial Robustness via Fisher-Rao Regularization. (arXiv:2106.06685v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06959",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1\">Jaewoong Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_C/0/1/0/all/0/1\">Changyeon Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Junho Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jung Ho Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_G/0/1/0/all/0/1\">Geonho Hwang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_M/0/1/0/all/0/1\">Myungjoo Kang</a>",
          "description": "In this paper, we propose a method to find local-geometry-aware traversal\ndirections on the intermediate latent space of Generative Adversarial Networks\n(GANs). These directions are defined as an ordered basis of tangent space at a\nlatent code. Motivated by the intrinsic sparsity of the latent space, the basis\nis discovered by solving the low-rank approximation problem of the differential\nof the partial network. Moreover, the local traversal basis leads to a natural\niterative traversal on the latent space. Iterative Curve-Traversal shows stable\ntraversal on images, since the trajectory of latent code stays close to the\nlatent space even under the strong perturbations compared to the linear\ntraversal. This stability provides far more diverse variations of the given\nimage. Although the proposed method can be applied to various GAN models, we\nfocus on the W-space of the StyleGAN2, which is renowned for showing the better\ndisentanglement of the latent factors of variation. Our quantitative and\nqualitative analysis provides evidence showing that the W-space is still\nglobally warped while showing a certain degree of global consistency of\ninterpretable variation. In particular, we introduce some metrics on the\nGrassmannian manifolds to quantify the global warpage of the W-space and the\nsubspace traversal to test the stability of traversal directions.",
          "link": "http://arxiv.org/abs/2106.06959",
          "publishedOn": "2021-06-15T01:45:14.537Z",
          "wordCount": 662,
          "title": "Do Not Escape From the Manifold: Discovering the Local Coordinates on the Latent Space of GANs. (arXiv:2106.06959v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06623",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kalra_S/0/1/0/all/0/1\">Shivam Kalra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adnan_M/0/1/0/all/0/1\">Mohammed Adnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hemati_S/0/1/0/all/0/1\">Sobhan Hemati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dehkharghanian_T/0/1/0/all/0/1\">Taher Dehkharghanian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahnamayan_S/0/1/0/all/0/1\">Shahryar Rahnamayan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tizhoosh_H/0/1/0/all/0/1\">Hamid Tizhoosh</a>",
          "description": "Deep learning methods such as convolutional neural networks (CNNs) are\ndifficult to directly utilize to analyze whole slide images (WSIs) due to the\nlarge image dimensions. We overcome this limitation by proposing a novel\ntwo-stage approach. First, we extract a set of representative patches (called\nmosaic) from a WSI. Each patch of a mosaic is encoded to a feature vector using\na deep network. The feature extractor model is fine-tuned using hierarchical\ntarget labels of WSIs, i.e., anatomic site and primary diagnosis. In the second\nstage, a set of encoded patch-level features from a WSI is used to compute the\nprimary diagnosis probability through the proposed Pay Attention with Focus\nscheme, an attention-weighted averaging of predicted probabilities for all\npatches of a mosaic modulated by a trainable focal factor. Experimental results\nshow that the proposed model can be robust, and effective for the\nclassification of WSIs.",
          "link": "http://arxiv.org/abs/2106.06623",
          "publishedOn": "2021-06-15T01:45:14.510Z",
          "wordCount": 596,
          "title": "Pay Attention with Focus: A Novel Learning Scheme for Classification of Whole Slide Images. (arXiv:2106.06623v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06664",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Fu_Y/0/1/0/all/0/1\">Yanwei Fu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhao_L/0/1/0/all/0/1\">Lei Zhao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zheng_H/0/1/0/all/0/1\">Haojie Zheng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sun_Q/0/1/0/all/0/1\">Qiang Sun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_L/0/1/0/all/0/1\">Li Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_H/0/1/0/all/0/1\">Hong Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xie_J/0/1/0/all/0/1\">Jiao Xie</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xue_X/0/1/0/all/0/1\">Xiangyang Xue</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_F/0/1/0/all/0/1\">Feng Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1\">Yuan Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pei_Y/0/1/0/all/0/1\">Yantao Pei</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_J/0/1/0/all/0/1\">Jianmin Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_X/0/1/0/all/0/1\">Xiuqi Wu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zheng_Y/0/1/0/all/0/1\">Yanhua Zheng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gu1_H/0/1/0/all/0/1\">Hongxia Tian Mengwei Gu1</a>",
          "description": "It is still nontrivial to develop a new fast COVID-19 screening method with\nthe easier access and lower cost, due to the technical and cost limitations of\nthe current testing methods in the medical resource-poor districts. On the\nother hand, there are more and more ocular manifestations that have been\nreported in the COVID-19 patients as growing clinical evidence[1]. This\ninspired this project. We have conducted the joint clinical research since\nJanuary 2021 at the ShiJiaZhuang City, Heibei province, China, which approved\nby the ethics committee of The fifth hospital of ShiJiaZhuang of Hebei Medical\nUniversity. We undertake several blind tests of COVID-19 patients by Union\nHospital, Tongji Medical College, Huazhong University of Science and\nTechnology, Wuhan, China. Meantime as an important part of the ongoing globally\nCOVID-19 eye test program by AIMOMICS since February 2020, we propose a new\nfast screening method of analyzing the eye-region images, captured by common\nCCD and CMOS cameras. This could reliably make a rapid risk screening of\nCOVID-19 with the sustainable stable high performance in different countries\nand races. Our model for COVID-19 rapid prescreening have the merits of the\nlower cost, fully self-performed, non-invasive, importantly real-time, and thus\nenables the continuous health surveillance. We further implement it as the open\naccessible APIs, and provide public service to the world. Our pilot experiments\nshow that our model is ready to be usable to all kinds of surveillance\nscenarios, such as infrared temperature measurement device at airports and\nstations, or directly pushing to the target people groups smartphones as a\npackaged application.",
          "link": "http://arxiv.org/abs/2106.06664",
          "publishedOn": "2021-06-15T01:45:14.491Z",
          "wordCount": 764,
          "title": "Rapid COVID-19 Risk Screening by Eye-region Manifestations. (arXiv:2106.06664v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06592",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Munoz_I/0/1/0/all/0/1\">Ignacio Mu&#xf1;oz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bolt_A/0/1/0/all/0/1\">Alfredo Bolt</a>",
          "description": "Introduction: Mobile apps, through artificial vision, are capable of\nrecognizing vegetable species in real time. However, the existing species\nrecognition apps do not take in consideration the wide variety of endemic and\nnative (Chilean) species, which leads to wrong species predictions. This study\nintroduces the development of a chilean species dataset and an optimized\nclassification model implemented to a mobile app. Method: the data set was\nbuilt by putting together pictures of several species captured on the field and\nby selecting some pictures available from other datasets available online.\nConvolutional neural networks were used in order to develop the images\nprediction models. The networks were trained by performing a sensitivity\nanalysis, validating with k-fold cross validation and performing tests with\ndifferent hyper-parameters, optimizers, convolutional layers, and learning\nrates in order to identify and choose the best models and then put them\ntogether in one classification model. Results: The final data set was\ncompounded by 46 species, including native species, endemic and exotic from\nChile, with 6120 training pictures and 655 testing pictures. The best models\nwere implemented on a mobile app, obtaining a 95% correct prediction rate with\nrespect to the set of tests. Conclusion: The app developed in this study is\ncapable of classifying species with a high level of accuracy, depending on the\nstate of the art of the artificial vision and it can also show relevant\ninformation related to the classified species.",
          "link": "http://arxiv.org/abs/2106.06592",
          "publishedOn": "2021-06-15T01:45:14.465Z",
          "wordCount": 680,
          "title": "Dise\\~no y desarrollo de aplicaci\\'on m\\'ovil para la clasificaci\\'on de flora nativa chilena utilizando redes neuronales convolucionales. (arXiv:2106.06592v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06939",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Min_S/0/1/0/all/0/1\">Shaobo Min</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_Q/0/1/0/all/0/1\">Qi Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_H/0/1/0/all/0/1\">Hongtao Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_C/0/1/0/all/0/1\">Chuang Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongdong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jingdong Wang</a>",
          "description": "Cross-modal correlation provides an inherent supervision for video\nunsupervised representation learning. Existing methods focus on distinguishing\ndifferent video clips by visual and audio representations. We human visual\nperception could attend to regions where sounds are made, and our auditory\nperception could also ground their frequencies of sounding objects, which we\ncall bidirectional local correspondence. Such supervision is intuitive but not\nwell explored in the contrastive learning framework. This paper introduces a\npretext task, Cross-Modal Attention Consistency (CMAC), for exploring the\nbidirectional local correspondence property. The CMAC approach aims to align\nthe regional attention generated purely from the visual signal with the target\nattention generated under the guidance of acoustic signal, and do a similar\nalignment for frequency grounding on the acoustic attention. Accompanied by a\nremoulded cross-modal contrastive loss where we consider additional\nwithin-modal interactions, the CMAC approach works effectively for enforcing\nthe bidirectional alignment. Extensive experiments on six downstream benchmarks\ndemonstrate that CMAC can improve the state-of-the-art performance on both\nvisual and audio modalities.",
          "link": "http://arxiv.org/abs/2106.06939",
          "publishedOn": "2021-06-15T01:45:14.438Z",
          "wordCount": 596,
          "title": "Cross-Modal Attention Consistency for Video-Audio Unsupervised Learning. (arXiv:2106.06939v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06561",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chong_M/0/1/0/all/0/1\">Min Jin Chong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Forsyth_D/0/1/0/all/0/1\">David Forsyth</a>",
          "description": "We show how to learn a map that takes a content code, derived from a face\nimage, and a randomly chosen style code to an anime image. We derive an\nadversarial loss from our simple and effective definitions of style and\ncontent. This adversarial loss guarantees the map is diverse -- a very wide\nrange of anime can be produced from a single content code. Under plausible\nassumptions, the map is not just diverse, but also correctly represents the\nprobability of an anime, conditioned on an input face. In contrast, current\nmultimodal generation procedures cannot capture the complex styles that appear\nin anime. Extensive quantitative experiments support the idea the map is\ncorrect. Extensive qualitative results show that the method can generate a much\nmore diverse range of styles than SOTA comparisons. Finally, we show that our\nformalization of content and style allows us to perform video to video\ntranslation without ever training on videos.",
          "link": "http://arxiv.org/abs/2106.06561",
          "publishedOn": "2021-06-15T01:45:14.431Z",
          "wordCount": 609,
          "title": "GANs N' Roses: Stable, Controllable, Diverse Image to Image Translation (works for videos too!). (arXiv:2106.06561v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06629",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tan_J/0/1/0/all/0/1\">Jiaqi Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1\">Weijie Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_A/0/1/0/all/0/1\">Angel X. Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Savva_M/0/1/0/all/0/1\">Manolis Savva</a>",
          "description": "Despite recent progress in depth sensing and 3D reconstruction, mirror\nsurfaces are a significant source of errors. To address this problem, we create\nthe Mirror3D dataset: a 3D mirror plane dataset based on three RGBD datasets\n(Matterport3D, NYUv2 and ScanNet) containing 7,011 mirror instance masks and 3D\nplanes. We then develop Mirror3DNet: a module that refines raw sensor depth or\nestimated depth to correct errors on mirror surfaces. Our key idea is to\nestimate the 3D mirror plane based on RGB input and surrounding depth context,\nand use this estimate to directly regress mirror surface depth. Our experiments\nshow that Mirror3DNet significantly mitigates errors from a variety of input\ndepth data, including raw sensor depth and depth estimation or completion\nmethods.",
          "link": "http://arxiv.org/abs/2106.06629",
          "publishedOn": "2021-06-15T01:45:14.389Z",
          "wordCount": 564,
          "title": "Mirror3D: Depth Refinement for Mirror Surfaces. (arXiv:2106.06629v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06694",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tsutsui_S/0/1/0/all/0/1\">Satoshi Tsutsui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crandall_D/0/1/0/all/0/1\">David Crandall</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1\">Chen Yu</a>",
          "description": "We analyze egocentric views of attended objects from infants. This paper\nshows 1) empirical evidence that children's egocentric views have more diverse\ndistributions compared to adults' views, 2) we can computationally simulate the\ninfants' distribution, and 3) the distribution is beneficial for training more\ngeneralized image classifiers not only for infant egocentric vision but for\nthird-person computer vision.",
          "link": "http://arxiv.org/abs/2106.06694",
          "publishedOn": "2021-06-15T01:45:14.222Z",
          "wordCount": 509,
          "title": "Reverse-engineer the Distributional Structure of Infant Egocentric Views for Training Generalizable Image Classifiers. (arXiv:2106.06694v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06908",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chenxin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_Q/0/1/0/all/0/1\">Qi Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_X/0/1/0/all/0/1\">Xinghao Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yue Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_D/0/1/0/all/0/1\">Dong Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yizhou Yu</a>",
          "description": "Medical imaging datasets usually exhibit domain shift due to the variations\nof scanner vendors, imaging protocols, etc. This raises the concern about the\ngeneralization capacity of machine learning models. Domain generalization (DG),\nwhich aims to learn a model from multiple source domains such that it can be\ndirectly generalized to unseen test domains, seems particularly promising to\nmedical imaging community. To address DG, recent model-agnostic meta-learning\n(MAML) has been introduced, which transfers the knowledge from previous\ntraining tasks to facilitate the learning of novel testing tasks. However, in\nclinical practice, there are usually only a few annotated source domains\navailable, which decreases the capacity of training task generation and thus\nincreases the risk of overfitting to training tasks in the paradigm. In this\npaper, we propose a novel DG scheme of episodic training with task augmentation\non medical imaging classification. Based on meta-learning, we develop the\nparadigm of episodic training to construct the knowledge transfer from episodic\ntraining-task simulation to the real testing task of DG. Motivated by the\nlimited number of source domains in real-world medical deployment, we consider\nthe unique task-level overfitting and we propose task augmentation to enhance\nthe variety during training task generation to alleviate it. With the\nestablished learning framework, we further exploit a novel meta-objective to\nregularize the deep embedding of training domains. To validate the\neffectiveness of the proposed method, we perform experiments on\nhistopathological images and abdominal CT images.",
          "link": "http://arxiv.org/abs/2106.06908",
          "publishedOn": "2021-06-15T01:45:14.157Z",
          "wordCount": 682,
          "title": "Domain Generalization on Medical Imaging Classification using Episodic Training with Task Augmentation. (arXiv:2106.06908v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06795",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Karim_M/0/1/0/all/0/1\">Mohammed Asad Karim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verma_V/0/1/0/all/0/1\">Vinay Kumar Verma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_P/0/1/0/all/0/1\">Pravendra Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Namboodiri_V/0/1/0/all/0/1\">Vinay Namboodiri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rai_P/0/1/0/all/0/1\">Piyush Rai</a>",
          "description": "We propose a novel approach for class incremental online learning in a\nlimited data setting. This problem setting is challenging because of the\nfollowing constraints: (1) Classes are given incrementally, which necessitates\na class incremental learning approach; (2) Data for each class is given in an\nonline fashion, i.e., each training example is seen only once during training;\n(3) Each class has very few training examples; and (4) We do not use or assume\naccess to any replay/memory to store data from previous classes. Therefore, in\nthis setting, we have to handle twofold problems of catastrophic forgetting and\noverfitting. In our approach, we learn robust representations that are\ngeneralizable across tasks without suffering from the problems of catastrophic\nforgetting and overfitting to accommodate future classes with limited samples.\nOur proposed method leverages the meta-learning framework with knowledge\nconsolidation. The meta-learning framework helps the model for rapid learning\nwhen samples appear in an online fashion. Simultaneously, knowledge\nconsolidation helps to learn a robust representation against forgetting under\nonline updates to facilitate future learning. Our approach significantly\noutperforms other methods on several benchmarks.",
          "link": "http://arxiv.org/abs/2106.06795",
          "publishedOn": "2021-06-15T01:45:14.118Z",
          "wordCount": 631,
          "title": "Knowledge Consolidation based Class Incremental Online Learning with Limited Data. (arXiv:2106.06795v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2010.05690",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+B_L/0/1/0/all/0/1\">Lalith Bharadwaj B</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boddeda_R/0/1/0/all/0/1\">Rohit Boddeda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+K_S/0/1/0/all/0/1\">Sai Vardhan K</a>, <a href=\"http://arxiv.org/find/cs/1/au:+G_M/0/1/0/all/0/1\">Madhu G</a>",
          "description": "The issue of COVID-19, increasing with a massive mortality rate. This led to\nthe WHO declaring it as a pandemic. In this situation, it is crucial to perform\nefficient and fast diagnosis. The reverse transcript polymerase chain reaction\n(RTPCR) test is conducted to detect the presence of SARS-CoV-2. This test is\ntime-consuming and instead chest CT (or Chest X-ray) can be used for a fast and\naccurate diagnosis. Automated diagnosis is considered to be important as it\nreduces human effort and provides accurate and low-cost tests. The\ncontributions of our research are three-fold. First, it is aimed to analyse the\nbehaviour and performance of variant vision models ranging from Inception to\nNAS networks with the appropriate fine-tuning procedure. Second, the behaviour\nof these models is visually analysed by plotting CAMs for individual networks\nand determining classification performance with AUCROC curves. Thirdly, stacked\nensembles techniques are imparted to provide higher generalisation on combining\nthe fine-tuned models, in which six ensemble neural networks are designed by\ncombining the existing fine-tuned networks. Implying these stacked ensembles\nprovides a great generalization to the models. The ensemble model designed by\ncombining all the fine-tuned networks obtained a state-of-the-art accuracy\nscore of 99.17%. The precision and recall for the COVID-19 class are 99.99% and\n89.79% respectively, which resembles the robustness of the stacked ensembles.",
          "link": "http://arxiv.org/abs/2010.05690",
          "publishedOn": "2021-06-14T01:38:53.136Z",
          "wordCount": 741,
          "title": "COVID-19 Classification Using Staked Ensembles: A Comprehensive Analysis. (arXiv:2010.05690v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1904.03116",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Souri_Y/0/1/0/all/0/1\">Yaser Souri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fayyaz_M/0/1/0/all/0/1\">Mohsen Fayyaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Minciullo_L/0/1/0/all/0/1\">Luca Minciullo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Francesca_G/0/1/0/all/0/1\">Gianpiero Francesca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gall_J/0/1/0/all/0/1\">Juergen Gall</a>",
          "description": "Action segmentation is the task of predicting the actions for each frame of a\nvideo. As obtaining the full annotation of videos for action segmentation is\nexpensive, weakly supervised approaches that can learn only from transcripts\nare appealing. In this paper, we propose a novel end-to-end approach for weakly\nsupervised action segmentation based on a two-branch neural network. The two\nbranches of our network predict two redundant but different representations for\naction segmentation and we propose a novel mutual consistency (MuCon) loss that\nenforces the consistency of the two redundant representations. Using the MuCon\nloss together with a loss for transcript prediction, our proposed approach\nachieves the accuracy of state-of-the-art approaches while being $14$ times\nfaster to train and $20$ times faster during inference. The MuCon loss proves\nbeneficial even in the fully supervised setting.",
          "link": "http://arxiv.org/abs/1904.03116",
          "publishedOn": "2021-06-14T01:38:53.101Z",
          "wordCount": 638,
          "title": "Fast Weakly Supervised Action Segmentation Using Mutual Consistency. (arXiv:1904.03116v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06485",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Weichen Chen</a> (1) <a href=\"http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1\">Xinyi Yu</a> (1) <a href=\"http://arxiv.org/find/cs/1/au:+Ou_L/0/1/0/all/0/1\">Linlin Ou</a> (1) ((1) Collage of Information Engineering, Zhejiang University of Technology, Hangzhou, China)",
          "description": "Pedestrian attribute recognition in surveillance scenarios is still a\nchallenging task due to inaccurate localization of specific attributes. In this\npaper, we propose a novel view-attribute localization method based on attention\n(VALA), which relies on the strong relevance between attributes and views to\ncapture specific view-attributes and to localize attribute-corresponding areas\nby attention mechanism. A specific view-attribute is composed by the extracted\nattribute feature and four view scores which are predicted by view predictor as\nthe confidences for attribute from different views. View-attribute is then\ndelivered back to shallow network layers for supervising deep feature\nextraction. To explore the location of a view-attribute, regional attention is\nintroduced to aggregate spatial information of the input attribute feature in\nheight and width direction for constraining the image into a narrow range.\nMoreover, the inter-channel dependency of view-feature is embedded in the above\ntwo spatial directions. An attention attribute-specific region is gained after\nfining the narrow range by balancing the ratio of channel dependencies between\nheight and width branches. The final view-attribute recognition outcome is\nobtained by combining the output of regional attention with the view scores\nfrom view predictor. Experiments on three wide datasets (RAP, RAPv2, PETA, and\nPA-100K) demonstrate the effectiveness of our approach compared with\nstate-of-the-art methods.",
          "link": "http://arxiv.org/abs/2106.06485",
          "publishedOn": "2021-06-14T01:38:53.070Z",
          "wordCount": 654,
          "title": "Pedestrian Attribute Recognition in Video Surveillance Scenarios Based on View-attribute Attention Localization. (arXiv:2106.06485v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2102.04906",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1\">Yizeng Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1\">Gao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1\">Shiji Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Le Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Honghui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yulin Wang</a>",
          "description": "Dynamic neural network is an emerging research topic in deep learning.\nCompared to static models which have fixed computational graphs and parameters\nat the inference stage, dynamic networks can adapt their structures or\nparameters to different inputs, leading to notable advantages in terms of\naccuracy, computational efficiency, adaptiveness, etc. In this survey, we\ncomprehensively review this rapidly developing area by dividing dynamic\nnetworks into three main categories: 1) instance-wise dynamic models that\nprocess each instance with data-dependent architectures or parameters; 2)\nspatial-wise dynamic networks that conduct adaptive computation with respect to\ndifferent spatial locations of image data and 3) temporal-wise dynamic models\nthat perform adaptive inference along the temporal dimension for sequential\ndata such as videos and texts. The important research problems of dynamic\nnetworks, e.g., architecture design, decision making scheme, optimization\ntechnique and applications, are reviewed systematically. Finally, we discuss\nthe open problems in this field together with interesting future research\ndirections.",
          "link": "http://arxiv.org/abs/2102.04906",
          "publishedOn": "2021-06-14T01:38:53.062Z",
          "wordCount": 618,
          "title": "Dynamic Neural Networks: A Survey. (arXiv:2102.04906v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06321",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bana_T/0/1/0/all/0/1\">Tejas Bana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Loya_J/0/1/0/all/0/1\">Jatan Loya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulkarni_S/0/1/0/all/0/1\">Siddhant Kulkarni</a>",
          "description": "Studies involving colourising images has been garnering researchers' keen\nattention over time, assisted by significant advances in various Machine\nLearning techniques and compute power availability. Traditionally, colourising\nimages have been an intricate task that gave a substantial degree of freedom\nduring the assignment of chromatic information. In our proposed method, we\nattempt to colourise images using Vision Transformer - Inception - Generative\nAdversarial Network (ViT-I-GAN), which has an Inception-v3 fusion embedding in\nthe generator. For a stable and robust network, we have used Vision Transformer\n(ViT) as the discriminator. We trained the model on the Unsplash and the COCO\ndataset for demonstrating the improvement made by the Inception-v3 embedding.\nWe have compared the results between ViT-GANs with and without Inception-v3\nembedding.",
          "link": "http://arxiv.org/abs/2106.06321",
          "publishedOn": "2021-06-14T01:38:53.052Z",
          "wordCount": 547,
          "title": "ViT-Inception-GAN for Image Colourising. (arXiv:2106.06321v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2010.15560",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Wei_J/0/1/0/all/0/1\">Jiahong Wei</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fan_Z/0/1/0/all/0/1\">Zhun Fan</a>",
          "description": "Recently, many methods based on hand-designed convolutional neural networks\n(CNNs) have achieved promising results in automatic retinal vessel\nsegmentation. However, these CNNs remain constrained in capturing retinal\nvessels in complex fundus images. To improve their segmentation performance,\nthese CNNs tend to have many parameters, which may lead to overfitting and high\ncomputational complexity. Moreover, the manual design of competitive CNNs is\ntime-consuming and requires extensive empirical knowledge. Herein, a novel\nautomated design method, called Genetic U-Net, is proposed to generate a\nU-shaped CNN that can achieve better retinal vessel segmentation but with fewer\narchitecture-based parameters, thereby addressing the above issues. First, we\ndevised a condensed but flexible search space based on a U-shaped\nencoder-decoder. Then, we used an improved genetic algorithm to identify\nbetter-performing architectures in the search space and investigated the\npossibility of finding a superior network architecture with fewer parameters.\nThe experimental results show that the architecture obtained using the proposed\nmethod offered a superior performance with less than 1% of the number of the\noriginal U-Net parameters in particular and with significantly fewer parameters\nthan other state-of-the-art models. Furthermore, through in-depth investigation\nof the experimental results, several effective operations and patterns of\nnetworks to generate superior retinal vessel segmentations were identified.",
          "link": "http://arxiv.org/abs/2010.15560",
          "publishedOn": "2021-06-14T01:38:53.045Z",
          "wordCount": 686,
          "title": "Genetic U-Net: Automatically Designed Deep Networks for Retinal Vessel Segmentation Using a Genetic Algorithm. (arXiv:2010.15560v4 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02078",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sridhar_K/0/1/0/all/0/1\">Kaustubh Sridhar</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sokolsky_O/0/1/0/all/0/1\">Oleg Sokolsky</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lee_I/0/1/0/all/0/1\">Insup Lee</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Weimer_J/0/1/0/all/0/1\">James Weimer</a>",
          "description": "Improving adversarial robustness of neural networks remains a major\nchallenge. Fundamentally, training a network is a parameter estimation problem.\nIn adaptive control theory, maintaining persistency of excitation (PoE) is\nintegral to ensuring convergence of parameter estimates in dynamical systems to\ntheir robust optima. In this work, we show that network training using gradient\ndescent is equivalent to a dynamical system parameter estimation problem.\nLeveraging this relationship, we prove a sufficient condition for PoE of\ngradient descent is achieved when the learning rate is less than the inverse of\nthe Lipschitz constant of the gradient of loss function. We provide an\nefficient technique for estimating the corresponding Lipschitz constant using\nextreme value theory and demonstrate that by only scaling the learning rate\nschedule we can increase adversarial accuracy by up to 15% points on benchmark\ndatasets. Our approach also universally increases the adversarial accuracy by\n0.1% to 0.3% points in various state-of-the-art adversarially trained models on\nthe AutoAttack benchmark, where every small margin of improvement is\nsignificant.",
          "link": "http://arxiv.org/abs/2106.02078",
          "publishedOn": "2021-06-14T01:38:53.036Z",
          "wordCount": 630,
          "title": "Robust Learning via Persistency of Excitation. (arXiv:2106.02078v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06133",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1\">Yixiao Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1\">Yu Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hongsheng Li</a>",
          "description": "Unsupervised object re-identification targets at learning discriminative\nrepresentations for object retrieval without any annotations. Clustering-based\nmethods conduct training with the generated pseudo labels and currently\ndominate this research direction. However, they still suffer from the issue of\npseudo label noise. To tackle the challenge, we propose to properly estimate\npseudo label similarities between consecutive training generations with\nclustering consensus and refine pseudo labels with temporally propagated and\nensembled pseudo labels. To the best of our knowledge, this is the first\nattempt to leverage the spirit of temporal ensembling to improve classification\nwith dynamically changing classes over generations. The proposed pseudo label\nrefinery strategy is simple yet effective and can be seamlessly integrated into\nexisting clustering-based unsupervised re-identification methods. With our\nproposed approach, state-of-the-art method can be further boosted with up to\n8.8% mAP improvements on the challenging MSMT17 dataset.",
          "link": "http://arxiv.org/abs/2106.06133",
          "publishedOn": "2021-06-14T01:38:53.018Z",
          "wordCount": 581,
          "title": "Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification. (arXiv:2106.06133v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2006.04988",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Voynov_A/0/1/0/all/0/1\">Andrey Voynov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morozov_S/0/1/0/all/0/1\">Stanislav Morozov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Babenko_A/0/1/0/all/0/1\">Artem Babenko</a>",
          "description": "The recent rise of unsupervised and self-supervised learning has dramatically\nreduced the dependency on labeled data, providing effective image\nrepresentations for transfer to downstream vision tasks. Furthermore, recent\nworks employed these representations in a fully unsupervised setup for image\nclassification, reducing the need for human labels on the fine-tuning stage as\nwell. This work demonstrates that large-scale unsupervised models can also\nperform a more challenging object segmentation task, requiring neither\npixel-level nor image-level labeling. Namely, we show that recent unsupervised\nGANs allow to differentiate between foreground/background pixels, providing\nhigh-quality saliency masks. By extensive comparison on standard benchmarks, we\noutperform existing unsupervised alternatives for object segmentation,\nachieving new state-of-the-art.",
          "link": "http://arxiv.org/abs/2006.04988",
          "publishedOn": "2021-06-14T01:38:53.010Z",
          "wordCount": 568,
          "title": "Object Segmentation Without Labels with Large-Scale Generative Models. (arXiv:2006.04988v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2002.11318",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kamath_S/0/1/0/all/0/1\">Sandesh Kamath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deshpande_A/0/1/0/all/0/1\">Amit Deshpande</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Subrahmanyam_K/0/1/0/all/0/1\">K V Subrahmanyam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balasubramanian_V/0/1/0/all/0/1\">Vineeth N Balasubramanian</a>",
          "description": "(Non-)robustness of neural networks to small, adversarial pixel-wise\nperturbations, and as more recently shown, to even random spatial\ntransformations (e.g., translations, rotations) entreats both theoretical and\nempirical understanding. Spatial robustness to random translations and\nrotations is commonly attained via equivariant models (e.g., StdCNNs, GCNNs)\nand training augmentation, whereas adversarial robustness is typically achieved\nby adversarial training. In this paper, we prove a quantitative trade-off\nbetween spatial and adversarial robustness in a simple statistical setting. We\ncomplement this empirically by showing that: (a) as the spatial robustness of\nequivariant models improves by training augmentation with progressively larger\ntransformations, their adversarial robustness worsens progressively, and (b) as\nthe state-of-the-art robust models are adversarially trained with progressively\nlarger pixel-wise perturbations, their spatial robustness drops progressively.\nTowards achieving pareto-optimality in this trade-off, we propose a method\nbased on curriculum learning that trains gradually on more difficult\nperturbations (both spatial and adversarial) to improve spatial and adversarial\nrobustness simultaneously.",
          "link": "http://arxiv.org/abs/2002.11318",
          "publishedOn": "2021-06-14T01:38:53.003Z",
          "wordCount": 689,
          "title": "Can we have it all? On the Trade-off between Spatial and Adversarial Robustness of Neural Networks. (arXiv:2002.11318v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06442",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Su_X/0/1/0/all/0/1\">Xiu Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_S/0/1/0/all/0/1\">Shan You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_M/0/1/0/all/0/1\">Mingkai Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Fei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_C/0/1/0/all/0/1\">Chen Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Changshui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chang Xu</a>",
          "description": "In one-shot weight sharing for NAS, the weights of each operation (at each\nlayer) are supposed to be identical for all architectures (paths) in the\nsupernet. However, this rules out the possibility of adjusting operation\nweights to cater for different paths, which limits the reliability of the\nevaluation results. In this paper, instead of counting on a single supernet, we\nintroduce $K$-shot supernets and take their weights for each operation as a\ndictionary. The operation weight for each path is represented as a convex\ncombination of items in a dictionary with a simplex code. This enables a matrix\napproximation of the stand-alone weight matrix with a higher rank ($K>1$). A\n\\textit{simplex-net} is introduced to produce architecture-customized code for\neach path. As a result, all paths can adaptively learn how to share weights in\nthe $K$-shot supernets and acquire corresponding weights for better evaluation.\n$K$-shot supernets and simplex-net can be iteratively trained, and we further\nextend the search to the channel dimension. Extensive experiments on benchmark\ndatasets validate that K-shot NAS significantly improves the evaluation\naccuracy of paths and thus brings in impressive performance improvements.",
          "link": "http://arxiv.org/abs/2106.06442",
          "publishedOn": "2021-06-14T01:38:52.995Z",
          "wordCount": 631,
          "title": "K-shot NAS: Learnable Weight-Sharing for NAS with K-shot Supernets. (arXiv:2106.06442v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03640",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Masters_D/0/1/0/all/0/1\">Dominic Masters</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Labatie_A/0/1/0/all/0/1\">Antoine Labatie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eaton_Rosen_Z/0/1/0/all/0/1\">Zach Eaton-Rosen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luschi_C/0/1/0/all/0/1\">Carlo Luschi</a>",
          "description": "Much recent research has been dedicated to improving the efficiency of\ntraining and inference for image classification. This effort has commonly\nfocused on explicitly improving theoretical efficiency, often measured as\nImageNet validation accuracy per FLOP. These theoretical savings have, however,\nproven challenging to achieve in practice, particularly on high-performance\ntraining accelerators.\n\nIn this work, we focus on improving the practical efficiency of the\nstate-of-the-art EfficientNet models on a new class of accelerator, the\nGraphcore IPU. We do this by extending this family of models in the following\nways: (i) generalising depthwise convolutions to group convolutions; (ii)\nadding proxy-normalized activations to match batch normalization performance\nwith batch-independent statistics; (iii) reducing compute by lowering the\ntraining resolution and inexpensively fine-tuning at higher resolution. We find\nthat these three methods improve the practical efficiency for both training and\ninference. Our code will be made available online.",
          "link": "http://arxiv.org/abs/2106.03640",
          "publishedOn": "2021-06-14T01:38:52.986Z",
          "wordCount": 605,
          "title": "Making EfficientNet More Efficient: Exploring Batch-Independent Normalization, Group Convolutions and Reduced Resolution Training. (arXiv:2106.03640v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06181",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Anisimov_Y/0/1/0/all/0/1\">Yuriy Anisimov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reis_G/0/1/0/all/0/1\">Gerd Reis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stricker_D/0/1/0/all/0/1\">Didier Stricker</a>",
          "description": "The ability to create an accurate three-dimensional reconstruction of a\ncaptured scene draws attention to the principles of light fields. This paper\npresents an approach for light field camera calibration and rectification,\nbased on pairwise pattern-based parameters extraction. It is followed by a\ncorrespondence-based algorithm for camera parameters refinement from arbitrary\nscenes using the triangulation filter and nonlinear optimization. The\neffectiveness of our approach is validated on both real and synthetic data.",
          "link": "http://arxiv.org/abs/2106.06181",
          "publishedOn": "2021-06-14T01:38:52.979Z",
          "wordCount": 513,
          "title": "Calibration and Auto-Refinement for Light Field Cameras. (arXiv:2106.06181v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2009.00100",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Young-min Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_Y/0/1/0/all/0/1\">Young-chul Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_K/0/1/0/all/0/1\">Kwangjin Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeon_M/0/1/0/all/0/1\">Moongu Jeon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Seong-Whan Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pedrycz_W/0/1/0/all/0/1\">Witold Pedrycz</a>",
          "description": "In this paper, we propose a highly practical fully online multi-object\ntracking and segmentation (MOTS) method that uses instance segmentation results\nas an input. The proposed method is based on the Gaussian mixture probability\nhypothesis density (GMPHD) filter, a hierarchical data association (HDA), and a\nmask-based affinity fusion (MAF) model to achieve high-performance online\ntracking. The HDA consists of two associations: segment-to-track and\ntrack-to-track associations. One affinity, for position and motion, is computed\nby using the GMPHD filter, and the other affinity, for appearance is computed\nby using the responses from a single object tracker such as a kernalized\ncorrelation filter. These two affinities are simply fused by using a\nscore-level fusion method such as min-max normalization referred to as MAF. In\naddition, to reduce the number of false positive segments, we adopt mask\nIoU-based merging (mask merging). The proposed MOTS framework with the key\nmodules: HDA, MAF, and mask merging, is easily extensible to simultaneously\ntrack multiple types of objects with CPU only execution in parallel processing.\nIn addition, the developed framework only requires simple parameter tuning\nunlike many existing MOTS methods that need intensive hyperparameter\noptimization. In the experiments on the two popular MOTS datasets, the key\nmodules show some improvements. For instance, ID-switch decreases by more than\nhalf compared to a baseline method in the training sets. In conclusion, our\ntracker achieves state-of-the-art MOTS performance in the test sets.",
          "link": "http://arxiv.org/abs/2009.00100",
          "publishedOn": "2021-06-14T01:38:52.960Z",
          "wordCount": 708,
          "title": "Online Multi-Object Tracking and Segmentation with GMPHD Filter and Mask-based Affinity Fusion. (arXiv:2009.00100v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06250",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Mingxiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_Z/0/1/0/all/0/1\">Zhanguo Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1\">Haonan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1\">Bitao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhuang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_L/0/1/0/all/0/1\">Liufang Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhecheng Wang</a>",
          "description": "Most of the achievements in artificial intelligence so far were accomplished\nby supervised learning which requires numerous annotated training data and thus\ncosts innumerable manpower for labeling. Unsupervised learning is one of the\neffective solutions to overcome such difficulties. In our work, we propose\nAugNet, a new deep learning training paradigm to learn image features from a\ncollection of unlabeled pictures. We develop a method to construct the\nsimilarities between pictures as distance metrics in the embedding space by\nleveraging the inter-correlation between augmented versions of samples. Our\nexperiments demonstrate that the method is able to represent the image in low\ndimensional space and performs competitively in downstream tasks such as image\nclassification and image similarity comparison. Specifically, we achieved over\n60% and 27% accuracy on the STL10 and CIFAR100 datasets with unsupervised\nclustering, respectively. Moreover, unlike many deep-learning-based image\nretrieval algorithms, our approach does not require access to external\nannotated datasets to train the feature extractor, but still shows comparable\nor even better feature representation ability and easy-to-use characteristics.\nIn our evaluations, the method outperforms all the state-of-the-art image\nretrieval algorithms on some out-of-domain image datasets. The code for the\nmodel implementation is available at\nhttps://github.com/chenmingxiang110/AugNet.",
          "link": "http://arxiv.org/abs/2106.06250",
          "publishedOn": "2021-06-14T01:38:52.951Z",
          "wordCount": 637,
          "title": "AugNet: End-to-End Unsupervised Visual Representation Learning with Image Augmentation. (arXiv:2106.06250v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06439",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singh_D/0/1/0/all/0/1\">Divakar Singh</a>",
          "description": "The unprecedented growth in the easy availability of photo-editing tools has\nendangered the power of digital images.An image was supposed to be worth more\nthan a thousand words,but now this can be said only if it can be authenticated\northe integrity of the image can be proved to be intact. In thispaper, we\npropose a digital image forensic technique for JPEG images. It can detect any\nforgery in the image if the forged portion called a ghost image is having a\ncompression quality different from that of the cover image. It is based on\nresaving the JPEG image at different JPEG qualities, and the detection of the\nforged portion is maximum when it is saved at the same JPEG quality as the\ncover image. Also, we can precisely predictthe JPEG quality of the cover image\nby analyzing the similarity using Structural Similarity Index Measure (SSIM) or\nthe energyof the images. The first maxima in SSIM or the first minima inenergy\ncorrespond to the cover image JPEG quality. We created adataset for varying\nJPEG compression qualities of the ghost and the cover images and validated the\nscalability of the experimental results.We also, experimented with varied\nattack scenarios, e.g. high-quality ghost image embedded in low quality of\ncover image,low-quality ghost image embedded in high-quality of cover image,and\nghost image and cover image both at the same quality.The proposed method is\nable to localize the tampered portions accurately even for forgeries as small\nas 10x10 sized pixel blocks.Our technique is also robust against other attack\nscenarios like copy-move forgery, inserting text into image, rescaling\n(zoom-out/zoom-in) ghost image and then pasting on cover image.",
          "link": "http://arxiv.org/abs/2106.06439",
          "publishedOn": "2021-06-14T01:38:52.944Z",
          "wordCount": 709,
          "title": "An Image Forensic Technique Based on JPEG Ghosts. (arXiv:2106.06439v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06489",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liong_G/0/1/0/all/0/1\">Gen-Bing Liong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+See_J/0/1/0/all/0/1\">John See</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_L/0/1/0/all/0/1\">Lai-Kuan Wong</a>",
          "description": "Facial expressions vary from the visible to the subtle. In recent years, the\nanalysis of micro-expressions $-$ a natural occurrence resulting from the\nsuppression of one's true emotions, has drawn the attention of researchers with\na broad range of potential applications. However, spotting microexpressions in\nlong videos becomes increasingly challenging when intertwined with normal or\nmacro-expressions. In this paper, we propose a shallow optical flow\nthree-stream CNN (SOFTNet) model to predict a score that captures the\nlikelihood of a frame being in an expression interval. By fashioning the\nspotting task as a regression problem, we introduce pseudo-labeling to\nfacilitate the learning process. We demonstrate the efficacy and efficiency of\nthe proposed approach on the recent MEGC 2020 benchmark, where state-of-the-art\nperformance is achieved on CAS(ME)$^{2}$ with equally promising results on SAMM\nLong Videos.",
          "link": "http://arxiv.org/abs/2106.06489",
          "publishedOn": "2021-06-14T01:38:52.930Z",
          "wordCount": 591,
          "title": "Shallow Optical Flow Three-Stream CNN for Macro- and Micro-Expression Spotting from Long Videos. (arXiv:2106.06489v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06129",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vasu_P/0/1/0/all/0/1\">Pavan Kumar Anasosalu Vasu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saxena_S/0/1/0/all/0/1\">Shreyas Saxena</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuzel_O/0/1/0/all/0/1\">Oncel Tuzel</a>",
          "description": "Recent works have shown that deep neural networks benefit from multi-task\nlearning by learning a shared representation across several related tasks.\nHowever, performance of such systems depend on relative weighting between\nvarious losses involved during training. Prior works on loss weighting schemes\nassume that instances are equally easy or hard for all tasks. In order to break\nthis assumption, we let the training process dictate the optimal weighting of\ntasks for every instance in the dataset. More specifically, we equip every\ninstance in the dataset with a set of learnable parameters (instance-level task\nparameters) where the cardinality is equal to the number of tasks learned by\nthe model. These parameters model the weighting of each task for an instance.\nThey are updated by gradient descent and do not require hand-crafted rules. We\nconduct extensive experiments on SURREAL and CityScapes datasets, for human\nshape and pose estimation, depth estimation and semantic segmentation tasks. In\nthese tasks, our approach outperforms recent dynamic loss weighting approaches,\ne.g. reducing surface estimation errors by 8.97% on SURREAL. When applied to\ndatasets where one or more tasks can have noisy annotations, the proposed\nmethod learns to prioritize learning from clean labels for a given task, e.g.\nreducing surface estimation errors by up to 60%. We also show that we can\nreliably detect corrupt labels for a given task as a by-product from learned\ninstance-level task parameters.",
          "link": "http://arxiv.org/abs/2106.06129",
          "publishedOn": "2021-06-14T01:38:52.911Z",
          "wordCount": 665,
          "title": "Instance-Level Task Parameters: A Robust Multi-task Weighting Framework. (arXiv:2106.06129v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2102.09808",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Iuzzolino_M/0/1/0/all/0/1\">Michael L. Iuzzolino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mozer_M/0/1/0/all/0/1\">Michael C. Mozer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_S/0/1/0/all/0/1\">Samy Bengio</a>",
          "description": "Although deep feedforward neural networks share some characteristics with the\nprimate visual system, a key distinction is their dynamics. Deep nets typically\noperate in serial stages wherein each layer completes its computation before\nprocessing begins in subsequent layers. In contrast, biological systems have\ncascaded dynamics: information propagates from neurons at all layers in\nparallel but transmission occurs gradually over time, leading to speed-accuracy\ntrade offs even in feedforward architectures. We explore the consequences of\nbiologically inspired parallel hardware by constructing cascaded ResNets in\nwhich each residual block has propagation delays but all blocks update in\nparallel in a stateful manner. Because information transmitted through skip\nconnections avoids delays, the functional depth of the architecture increases\nover time, yielding anytime predictions that improve with internal-processing\ntime. We introduce a temporal-difference training loss that achieves a strictly\nsuperior speed-accuracy profile over standard losses and enables the cascaded\narchitecture to outperform state-of-the-art anytime-prediction methods. The\ncascaded architecture has intriguing properties, including: it classifies\ntypical instances more rapidly than atypical instances; it is more robust to\nboth persistent and transient noise than is a conventional ResNet; and its\ntime-varying output trace provides a signal that can be exploited to improve\ninformation processing and inference.",
          "link": "http://arxiv.org/abs/2102.09808",
          "publishedOn": "2021-06-14T01:38:52.905Z",
          "wordCount": 676,
          "title": "Improving Anytime Prediction with Parallel Cascaded Networks and a Temporal-Difference Loss. (arXiv:2102.09808v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06440",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Michalkiewicz_M/0/1/0/all/0/1\">Mateusz Michalkiewicz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsogkas_S/0/1/0/all/0/1\">Stavros Tsogkas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parisot_S/0/1/0/all/0/1\">Sarah Parisot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baktashmotlagh_M/0/1/0/all/0/1\">Mahsa Baktashmotlagh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eriksson_A/0/1/0/all/0/1\">Anders Eriksson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belilovsky_E/0/1/0/all/0/1\">Eugene Belilovsky</a>",
          "description": "The impressive performance of deep convolutional neural networks in\nsingle-view 3D reconstruction suggests that these models perform non-trivial\nreasoning about the 3D structure of the output space. Recent work has\nchallenged this belief, showing that, on standard benchmarks, complex\nencoder-decoder architectures perform similarly to nearest-neighbor baselines\nor simple linear decoder models that exploit large amounts of per-category\ndata. However, building large collections of 3D shapes for supervised training\nis a laborious process; a more realistic and less constraining task is\ninferring 3D shapes for categories with few available training examples,\ncalling for a model that can successfully generalize to novel object classes.\nIn this work we experimentally demonstrate that naive baselines fail in this\nfew-shot learning setting, in which the network must learn informative shape\npriors for inference of new categories. We propose three ways to learn a\nclass-specific global shape prior, directly from data. Using these techniques,\nwe are able to capture multi-scale information about the 3D shape, and account\nfor intra-class variability by virtue of an implicit compositional structure.\nExperiments on the popular ShapeNet dataset show that our method outperforms a\nzero-shot baseline by over 40%, and the current state-of-the-art by over 10%,\nin terms of relative performance, in the few-shot setting.12",
          "link": "http://arxiv.org/abs/2106.06440",
          "publishedOn": "2021-06-14T01:38:52.898Z",
          "wordCount": 655,
          "title": "Learning Compositional Shape Priors for Few-Shot 3D Reconstruction. (arXiv:2106.06440v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06471",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xingyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_M/0/1/0/all/0/1\">Muchao Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_Q/0/1/0/all/0/1\">Quanzeng You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_F/0/1/0/all/0/1\">Fenglong Ma</a>",
          "description": "Medical report generation is one of the most challenging tasks in medical\nimage analysis. Although existing approaches have achieved promising results,\nthey either require a predefined template database in order to retrieve\nsentences or ignore the hierarchical nature of medical report generation. To\naddress these issues, we propose MedWriter that incorporates a novel\nhierarchical retrieval mechanism to automatically extract both report and\nsentence-level templates for clinically accurate report generation. MedWriter\nfirst employs the Visual-Language Retrieval~(VLR) module to retrieve the most\nrelevant reports for the given images. To guarantee the logical coherence\nbetween sentences, the Language-Language Retrieval~(LLR) module is introduced\nto retrieve relevant sentences based on the previous generated description. At\nlast, a language decoder fuses image features and features from retrieved\nreports and sentences to generate meaningful medical reports. We verified the\neffectiveness of our model by automatic evaluation and human evaluation on two\ndatasets, i.e., Open-I and MIMIC-CXR.",
          "link": "http://arxiv.org/abs/2106.06471",
          "publishedOn": "2021-06-14T01:38:52.891Z",
          "wordCount": 592,
          "title": "Writing by Memorizing: Hierarchical Retrieval-based Medical Report Generation. (arXiv:2106.06471v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2103.06304",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Parcalabescu_L/0/1/0/all/0/1\">Letitia Parcalabescu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trost_N/0/1/0/all/0/1\">Nils Trost</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frank_A/0/1/0/all/0/1\">Anette Frank</a>",
          "description": "The last years have shown rapid developments in the field of multimodal\nmachine learning, combining e.g., vision, text or speech. In this position\npaper we explain how the field uses outdated definitions of multimodality that\nprove unfit for the machine learning era. We propose a new task-relative\ndefinition of (multi)modality in the context of multimodal machine learning\nthat focuses on representations and information that are relevant for a given\nmachine learning task. With our new definition of multimodality we aim to\nprovide a missing foundation for multimodal research, an important component of\nlanguage grounding and a crucial milestone towards NLU.",
          "link": "http://arxiv.org/abs/2103.06304",
          "publishedOn": "2021-06-14T01:38:52.885Z",
          "wordCount": 582,
          "title": "What is Multimodality?. (arXiv:2103.06304v3 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.05918",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jia_C/0/1/0/all/0/1\">Chao Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yinfei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1\">Ye Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yi-Ting Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parekh_Z/0/1/0/all/0/1\">Zarana Parekh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pham_H/0/1/0/all/0/1\">Hieu Pham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1\">Quoc V. Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sung_Y/0/1/0/all/0/1\">Yunhsuan Sung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duerig_T/0/1/0/all/0/1\">Tom Duerig</a>",
          "description": "Pre-trained representations are becoming crucial for many NLP and perception\ntasks. While representation learning in NLP has transitioned to training on raw\ntext without human annotations, visual and vision-language representations\nstill rely heavily on curated training datasets that are expensive or require\nexpert knowledge. For vision applications, representations are mostly learned\nusing datasets with explicit class labels such as ImageNet or OpenImages. For\nvision-language, popular datasets like Conceptual Captions, MSCOCO, or CLIP all\ninvolve a non-trivial data collection (and cleaning) process. This costly\ncuration process limits the size of datasets and hence hinders the scaling of\ntrained models. In this paper, we leverage a noisy dataset of over one billion\nimage alt-text pairs, obtained without expensive filtering or post-processing\nsteps in the Conceptual Captions dataset. A simple dual-encoder architecture\nlearns to align visual and language representations of the image and text pairs\nusing a contrastive loss. We show that the scale of our corpus can make up for\nits noise and leads to state-of-the-art representations even with such a simple\nlearning scheme. Our visual representation achieves strong performance when\ntransferred to classification tasks such as ImageNet and VTAB. The aligned\nvisual and language representations enables zero-shot image classification and\nalso set new state-of-the-art results on Flickr30K and MSCOCO image-text\nretrieval benchmarks, even when compared with more sophisticated\ncross-attention models. The representations also enable cross-modality search\nwith complex text and text + image queries.",
          "link": "http://arxiv.org/abs/2102.05918",
          "publishedOn": "2021-06-14T01:38:52.868Z",
          "wordCount": 733,
          "title": "Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision. (arXiv:2102.05918v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06420",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Al_Kaabi_K/0/1/0/all/0/1\">Karrar Al-Kaabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monsefi_R/0/1/0/all/0/1\">Reza Monsefi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zabihzadeh_D/0/1/0/all/0/1\">Davood Zabihzadeh</a>",
          "description": "Metric learning algorithms aim to learn a distance function that brings the\nsemantically similar data items together and keeps dissimilar ones at a\ndistance. The traditional Mahalanobis distance learning is equivalent to find a\nlinear projection. In contrast, Deep Metric Learning (DML) methods are proposed\nthat automatically extract features from data and learn a non-linear\ntransformation from input space to a semantically embedding space. Recently,\nmany DML methods are proposed focused to enhance the discrimination power of\nthe learned metric by providing novel sampling strategies or loss functions.\nThis approach is very helpful when both the training and test examples are\ncoming from the same set of categories. However, it is less effective in many\napplications of DML such as image retrieval and person-reidentification. Here,\nthe DML should learn general semantic concepts from observed classes and employ\nthem to rank or identify objects from unseen categories. Neglecting the\ngeneralization ability of the learned representation and just emphasizing to\nlearn a more discriminative embedding on the observed classes may lead to the\noverfitting problem. To address this limitation, we propose a framework to\nenhance the generalization power of existing DML methods in a Zero-Shot\nLearning (ZSL) setting by general yet discriminative representation learning\nand employing a class adversarial neural network. To learn a more general\nrepresentation, we propose to employ feature maps of intermediate layers in a\ndeep neural network and enhance their discrimination power through an attention\nmechanism. Besides, a class adversarial network is utilized to enforce the deep\nmodel to seek class invariant features for the DML task. We evaluate our work\non widely used machine vision datasets in a ZSL setting.",
          "link": "http://arxiv.org/abs/2106.06420",
          "publishedOn": "2021-06-14T01:38:52.861Z",
          "wordCount": 744,
          "title": "A Framework to Enhance Generalization of Deep Metric Learning methods using General Discriminative Feature Learning and Class Adversarial Neural Networks. (arXiv:2106.06420v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06047",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qu_L/0/1/0/all/0/1\">Liangqiong Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yuyin Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1\">Paul Pu Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1\">Yingda Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Feifei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1\">Li Fei-Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adeli_E/0/1/0/all/0/1\">Ehsan Adeli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubin_D/0/1/0/all/0/1\">Daniel Rubin</a>",
          "description": "Federated learning is an emerging research paradigm enabling collaborative\ntraining of machine learning models among different organizations while keeping\ndata private at each institution. Despite recent progress, there remain\nfundamental challenges such as lack of convergence and potential for\ncatastrophic forgetting in federated learning across real-world heterogeneous\ndevices. In this paper, we demonstrate that attention-based architectures\n(e.g., Transformers) are fairly robust to distribution shifts and hence improve\nfederated learning over heterogeneous data. Concretely, we conduct the first\nrigorous empirical investigation of different neural architectures across a\nrange of federated algorithms, real-world benchmarks, and heterogeneous data\nsplits. Our experiments show that simply replacing convolutional networks with\nTransformers can greatly reduce catastrophic forgetting of previous devices,\naccelerate convergence, and reach a better global model, especially when\ndealing with heterogeneous data. We will release our code and pretrained models\nat https://github.com/Liangqiong/ViT-FL-main to encourage future exploration in\nrobust architectures as an alternative to current research efforts on the\noptimization front.",
          "link": "http://arxiv.org/abs/2106.06047",
          "publishedOn": "2021-06-14T01:38:52.854Z",
          "wordCount": 602,
          "title": "Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning. (arXiv:2106.06047v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2006.03204",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Petsiuk_V/0/1/0/all/0/1\">Vitali Petsiuk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_R/0/1/0/all/0/1\">Rajiv Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manjunatha_V/0/1/0/all/0/1\">Varun Manjunatha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morariu_V/0/1/0/all/0/1\">Vlad I. Morariu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehra_A/0/1/0/all/0/1\">Ashutosh Mehra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ordonez_V/0/1/0/all/0/1\">Vicente Ordonez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saenko_K/0/1/0/all/0/1\">Kate Saenko</a>",
          "description": "We propose D-RISE, a method for generating visual explanations for the\npredictions of object detectors. Utilizing the proposed similarity metric that\naccounts for both localization and categorization aspects of object detection\nallows our method to produce saliency maps that show image areas that most\naffect the prediction. D-RISE can be considered \"black-box\" in the software\ntesting sense, as it only needs access to the inputs and outputs of an object\ndetector. Compared to gradient-based methods, D-RISE is more general and\nagnostic to the particular type of object detector being tested, and does not\nneed knowledge of the inner workings of the model. We show that D-RISE can be\neasily applied to different object detectors including one-stage detectors such\nas YOLOv3 and two-stage detectors such as Faster-RCNN. We present a detailed\nanalysis of the generated visual explanations to highlight the utilization of\ncontext and possible biases learned by object detectors.",
          "link": "http://arxiv.org/abs/2006.03204",
          "publishedOn": "2021-06-14T01:38:52.847Z",
          "wordCount": 633,
          "title": "Black-box Explanation of Object Detectors via Saliency Maps. (arXiv:2006.03204v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06415",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hormann_S/0/1/0/all/0/1\">Stefan H&#xf6;rmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zeyuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Knoche_M/0/1/0/all/0/1\">Martin Knoche</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teepe_T/0/1/0/all/0/1\">Torben Teepe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rigoll_G/0/1/0/all/0/1\">Gerhard Rigoll</a>",
          "description": "Photos of faces captured in unconstrained environments, such as large crowds,\nstill constitute challenges for current face recognition approaches as often\nfaces are occluded by objects or people in the foreground. However, few studies\nhave addressed the task of recognizing partial faces. In this paper, we propose\na novel approach to partial face recognition capable of recognizing faces with\ndifferent occluded areas. We achieve this by combining attentional pooling of a\nResNet's intermediate feature maps with a separate aggregation module. We\nfurther adapt common losses to partial faces in order to ensure that the\nattention maps are diverse and handle occluded parts. Our thorough analysis\ndemonstrates that we outperform all baselines under multiple benchmark\nprotocols, including naturally and synthetically occluded partial faces. This\nsuggests that our method successfully focuses on the relevant parts of the\noccluded face.",
          "link": "http://arxiv.org/abs/2106.06415",
          "publishedOn": "2021-06-14T01:38:52.839Z",
          "wordCount": 570,
          "title": "Attention-based Partial Face Recognition. (arXiv:2106.06415v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2104.13840",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chu_X/0/1/0/all/0/1\">Xiangxiang Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Z/0/1/0/all/0/1\">Zhi Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuqing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Bo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_H/0/1/0/all/0/1\">Haibing Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1\">Xiaolin Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_H/0/1/0/all/0/1\">Huaxia Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1\">Chunhua Shen</a>",
          "description": "Very recently, a variety of vision transformer architectures for dense\nprediction tasks have been proposed and they show that the design of spatial\nattention is critical to their success in these tasks. In this work, we revisit\nthe design of the spatial attention and demonstrate that a carefully-devised\nyet simple spatial attention mechanism performs favourably against the\nstate-of-the-art schemes. As a result, we propose two vision transformer\narchitectures, namely, Twins-PCPVT and Twins-SVT. Our proposed architectures\nare highly-efficient and easy to implement, only involving matrix\nmultiplications that are highly optimized in modern deep learning frameworks.\nMore importantly, the proposed architectures achieve excellent performance on a\nwide range of visual tasks including imagelevel classification as well as dense\ndetection and segmentation. The simplicity and strong performance suggest that\nour proposed architectures may serve as stronger backbones for many vision\ntasks. Our code will be released soon at\nhttps://github.com/Meituan-AutoML/Twins .",
          "link": "http://arxiv.org/abs/2104.13840",
          "publishedOn": "2021-06-14T01:38:52.820Z",
          "wordCount": 656,
          "title": "Twins: Revisiting the Design of Spatial Attention in Vision Transformers. (arXiv:2104.13840v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06056",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiawei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Linyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Huichen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaolu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shuang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>",
          "description": "Boundary based blackbox attack has been recognized as practical and\neffective, given that an attacker only needs to access the final model\nprediction. However, the query efficiency of it is in general high especially\nfor high dimensional image data. In this paper, we show that such efficiency\nhighly depends on the scale at which the attack is applied, and attacking at\nthe optimal scale significantly improves the efficiency. In particular, we\npropose a theoretical framework to analyze and show three key characteristics\nto improve the query efficiency. We prove that there exists an optimal scale\nfor projective gradient estimation. Our framework also explains the\nsatisfactory performance achieved by existing boundary black-box attacks. Based\non our theoretical framework, we propose Progressive-Scale enabled projective\nBoundary Attack (PSBA) to improve the query efficiency via progressive scaling\ntechniques. In particular, we employ Progressive-GAN to optimize the scale of\nprojections, which we call PSBA-PGAN. We evaluate our approach on both spatial\nand frequency scales. Extensive experiments on MNIST, CIFAR-10, CelebA, and\nImageNet against different models including a real-world face recognition API\nshow that PSBA-PGAN significantly outperforms existing baseline attacks in\nterms of query efficiency and attack success rate. We also observe relatively\nstable optimal scales for different models and datasets. The code is publicly\navailable at https://github.com/AI-secure/PSBA.",
          "link": "http://arxiv.org/abs/2106.06056",
          "publishedOn": "2021-06-14T01:38:52.811Z",
          "wordCount": 656,
          "title": "Progressive-Scale Boundary Blackbox Attack via Projective Gradient Estimation. (arXiv:2106.06056v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2011.09065",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Nettekoven_A/0/1/0/all/0/1\">Alexander Nettekoven</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fish_S/0/1/0/all/0/1\">Scott Fish</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Beaman_J/0/1/0/all/0/1\">Joseph Beaman</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Topcu_U/0/1/0/all/0/1\">Ufuk Topcu</a>",
          "description": "An increasing number of laser powder bed fusion machines use off-axis\ninfrared cameras to improve online monitoring and data-driven control\ncapabilities. However, there is still a severe lack of algorithmic solutions to\nproperly process the infrared images from these cameras that has led to several\nkey limitations: a lack of online monitoring capabilities for the laser tracks,\ninsufficient pre-processing of the infrared images for data-driven methods, and\nlarge memory requirements for storing the infrared images. To address these\nlimitations, we study over 30 segmentation algorithms that segment each\ninfrared image into a foreground and background. By evaluating each algorithm\nbased on its segmentation accuracy, computational speed, and spatter detection\ncharacteristics, we identify promising algorithmic solutions. The identified\nalgorithms can be readily applied to the laser powder bed fusion machines to\naddress each of the above limitations and thus, significantly improve process\ncontrol.",
          "link": "http://arxiv.org/abs/2011.09065",
          "publishedOn": "2021-06-14T01:38:52.804Z",
          "wordCount": 617,
          "title": "Towards Online Monitoring and Data-driven Control: A Study of Segmentation Algorithms for Laser Powder Bed Fusion Processes. (arXiv:2011.09065v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10446",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chan_K/0/1/0/all/0/1\">Kwan Ho Ryan Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yaodong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1\">Chong You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_H/0/1/0/all/0/1\">Haozhi Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wright_J/0/1/0/all/0/1\">John Wright</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yi Ma</a>",
          "description": "This work attempts to provide a plausible theoretical framework that aims to\ninterpret modern deep (convolutional) networks from the principles of data\ncompression and discriminative representation. We argue that for\nhigh-dimensional multi-class data, the optimal linear discriminative\nrepresentation maximizes the coding rate difference between the whole dataset\nand the average of all the subsets. We show that the basic iterative gradient\nascent scheme for optimizing the rate reduction objective naturally leads to a\nmulti-layer deep network, named ReduNet, which shares common characteristics of\nmodern deep networks. The deep layered architectures, linear and nonlinear\noperators, and even parameters of the network are all explicitly constructed\nlayer-by-layer via forward propagation, although they are amenable to\nfine-tuning via back propagation. All components of so-obtained ``white-box''\nnetwork have precise optimization, statistical, and geometric interpretation.\nMoreover, all linear operators of the so-derived network naturally become\nmulti-channel convolutions when we enforce classification to be rigorously\nshift-invariant. The derivation in the invariant setting suggests a trade-off\nbetween sparsity and invariance, and also indicates that such a deep\nconvolution network is significantly more efficient to construct and learn in\nthe spectral domain. Our preliminary simulations and experiments clearly verify\nthe effectiveness of both the rate reduction objective and the associated\nReduNet. All code and data are available at https://github.com/Ma-Lab-Berkeley.",
          "link": "http://arxiv.org/abs/2105.10446",
          "publishedOn": "2021-06-14T01:38:52.796Z",
          "wordCount": 723,
          "title": "ReduNet: A White-box Deep Network from the Principle of Maximizing Rate Reduction. (arXiv:2105.10446v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06482",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kaya_E/0/1/0/all/0/1\">Emre Can Kaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tabus_I/0/1/0/all/0/1\">Ioan Tabus</a>",
          "description": "This paper describes a novel lossless point cloud compression algorithm that\nuses a neural network for estimating the coding probabilities for the occupancy\nstatus of voxels, depending on wide three dimensional contexts around the voxel\nto be encoded. The point cloud is represented as an octree, with each\nresolution layer being sequentially encoded and decoded using arithmetic\ncoding, starting from the lowest resolution, until the final resolution is\nreached. The occupancy probability of each voxel of the splitting pattern at\neach node of the octree is modeled by a neural network, having at its input the\nalready encoded occupancy status of several octree nodes (belonging to the past\nand current resolutions), corresponding to a 3D context surrounding the node to\nbe encoded. The algorithm has a fast and a slow version, the fast version\nselecting differently several voxels of the context, which allows an increased\nparallelization by sending larger batches of templates to be estimated by the\nneural network, at both encoder and decoder. The proposed algorithms yield\nstate-of-the-art results on benchmark datasets. The implementation will be made\navailable at https://github.com/marmus12/nnctx",
          "link": "http://arxiv.org/abs/2106.06482",
          "publishedOn": "2021-06-14T01:38:52.789Z",
          "wordCount": 637,
          "title": "Neural Network Modeling of Probabilities for Coding the Octree Representation of Point Clouds. (arXiv:2106.06482v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06340",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1\">Renwang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xuanhong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_B/0/1/0/all/0/1\">Bingbing Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1\">Yanhao Ge</a>",
          "description": "We propose an efficient framework, called Simple Swap (SimSwap), aiming for\ngeneralized and high fidelity face swapping. In contrast to previous approaches\nthat either lack the ability to generalize to arbitrary identity or fail to\npreserve attributes like facial expression and gaze direction, our framework is\ncapable of transferring the identity of an arbitrary source face into an\narbitrary target face while preserving the attributes of the target face. We\novercome the above defects in the following two ways. First, we present the ID\nInjection Module (IIM) which transfers the identity information of the source\nface into the target face at feature level. By using this module, we extend the\narchitecture of an identity-specific face swapping algorithm to a framework for\narbitrary face swapping. Second, we propose the Weak Feature Matching Loss\nwhich efficiently helps our framework to preserve the facial attributes in an\nimplicit way. Extensive experiments on wild faces demonstrate that our SimSwap\nis able to achieve competitive identity performance while preserving attributes\nbetter than previous state-of-the-art methods. The code is already available on\ngithub: https://github.com/neuralchen/SimSwap.",
          "link": "http://arxiv.org/abs/2106.06340",
          "publishedOn": "2021-06-14T01:38:52.769Z",
          "wordCount": 630,
          "title": "SimSwap: An Efficient Framework For High Fidelity Face Swapping. (arXiv:2106.06340v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2006.04647",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mellor_J/0/1/0/all/0/1\">Joseph Mellor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turner_J/0/1/0/all/0/1\">Jack Turner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Storkey_A/0/1/0/all/0/1\">Amos Storkey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crowley_E/0/1/0/all/0/1\">Elliot J. Crowley</a>",
          "description": "The time and effort involved in hand-designing deep neural networks is\nimmense. This has prompted the development of Neural Architecture Search (NAS)\ntechniques to automate this design. However, NAS algorithms tend to be slow and\nexpensive; they need to train vast numbers of candidate networks to inform the\nsearch process. This could be alleviated if we could partially predict a\nnetwork's trained accuracy from its initial state. In this work, we examine the\noverlap of activations between datapoints in untrained networks and motivate\nhow this can give a measure which is usefully indicative of a network's trained\nperformance. We incorporate this measure into a simple algorithm that allows us\nto search for powerful networks without any training in a matter of seconds on\na single GPU, and verify its effectiveness on NAS-Bench-101, NAS-Bench-201,\nNATS-Bench, and Network Design Spaces. Our approach can be readily combined\nwith more expensive search methods; we examine a simple adaptation of\nregularised evolutionary search. Code for reproducing our experiments is\navailable at https://github.com/BayesWatch/nas-without-training.",
          "link": "http://arxiv.org/abs/2006.04647",
          "publishedOn": "2021-06-14T01:38:52.761Z",
          "wordCount": 649,
          "title": "Neural Architecture Search without Training. (arXiv:2006.04647v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06237",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zhou_C/0/1/0/all/0/1\">Chenhong Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_F/0/1/0/all/0/1\">Feng Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gong_C/0/1/0/all/0/1\">Chen Gong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_T/0/1/0/all/0/1\">Tongliang Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Han_B/0/1/0/all/0/1\">Bo Han</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cheung_W/0/1/0/all/0/1\">William Cheung</a>",
          "description": "In semantic segmentation, we aim to train a pixel-level classifier to assign\ncategory labels to all pixels in an image, where labeled training images and\nunlabeled test images are from the same distribution and share the same label\nset. However, in an open world, the unlabeled test images probably contain\nunknown categories and have different distributions from the labeled images.\nHence, in this paper, we consider a new, more realistic, and more challenging\nproblem setting where the pixel-level classifier has to be trained with labeled\nimages and unlabeled open-world images -- we name it open world semantic\nsegmentation (OSS). In OSS, the trained classifier is expected to identify\nunknown-class pixels and classify known-class pixels well. To solve OSS, we\nfirst investigate which distribution that unknown-class pixels obey. Then,\nmotivated by the goodness-of-fit test, we use statistical measurements to show\nhow a pixel fits the distribution of an unknown class and select highly-fitted\npixels to form the unknown region in each image. Eventually, we propose an\nend-to-end learning framework, known-region-aware domain alignment (KRADA), to\ndistinguish unknown classes while aligning distributions of known classes in\nlabeled and unlabeled open-world images. The effectiveness of KRADA has been\nverified on two synthetic tasks and one COVID-19 segmentation task.",
          "link": "http://arxiv.org/abs/2106.06237",
          "publishedOn": "2021-06-14T01:38:52.734Z",
          "wordCount": 698,
          "title": "KRADA: Known-region-aware Domain Alignment for Open World Semantic Segmentation. (arXiv:2106.06237v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06523",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Citron_R/0/1/0/all/0/1\">Robert I. Citron</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Jenniskens_P/0/1/0/all/0/1\">Peter Jenniskens</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Watkins_C/0/1/0/all/0/1\">Christopher Watkins</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Sinha_S/0/1/0/all/0/1\">Sravanthi Sinha</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Shah_A/0/1/0/all/0/1\">Amar Shah</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Raissi_C/0/1/0/all/0/1\">Chedy Raissi</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Devillepoix_H/0/1/0/all/0/1\">Hadrien Devillepoix</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Albers_J/0/1/0/all/0/1\">Jim Albers</a>",
          "description": "The recovery of freshly fallen meteorites from tracked and triangulated\nmeteors is critical to determining their source asteroid families. However,\nlocating meteorite fragments in strewn fields remains a challenge with very few\nmeteorites being recovered from the meteors triangulated in past and ongoing\nmeteor camera networks. We examined if locating meteorites can be automated\nusing machine learning and an autonomous drone. Drones can be programmed to fly\na grid search pattern and take systematic pictures of the ground over a large\nsurvey area. Those images can be analyzed using a machine learning classifier\nto identify meteorites in the field among many other features. Here, we\ndescribe a proof-of-concept meteorite classifier that deploys off-line a\ncombination of different convolution neural networks to recognize meteorites\nfrom images taken by drones in the field. The system was implemented in a\nconceptual drone setup and tested in the suspected strewn field of a recent\nmeteorite fall near Walker Lake, Nevada.",
          "link": "http://arxiv.org/abs/2106.06523",
          "publishedOn": "2021-06-14T01:38:52.579Z",
          "wordCount": 620,
          "title": "Recovery of Meteorites Using an Autonomous Drone and Machine Learning. (arXiv:2106.06523v1 [astro-ph.EP])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06073",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roth_N/0/1/0/all/0/1\">Nicolas Roth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bideau_P/0/1/0/all/0/1\">Pia Bideau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hellwich_O/0/1/0/all/0/1\">Olaf Hellwich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rolfs_M/0/1/0/all/0/1\">Martin Rolfs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Obermayer_K/0/1/0/all/0/1\">Klaus Obermayer</a>",
          "description": "Visually exploring the world around us is not a passive process. Instead, we\nactively explore the world and acquire visual information over time. Here, we\npresent a new model for simulating human eye-movement behavior in dynamic\nreal-world scenes. We model this active scene exploration as a sequential\ndecision making process. We adapt the popular drift-diffusion model (DDM) for\nperceptual decision making and extend it towards multiple options, defined by\nobjects present in the scene. For each possible choice, the model integrates\nevidence over time and a decision (saccadic eye movement) is triggered as soon\nas evidence crosses a decision threshold. Drawing this explicit connection\nbetween decision making and object-based scene perception is highly relevant in\nthe context of active viewing, where decisions are made continuously while\ninteracting with an external environment. We validate our model with a\ncarefully designed ablation study and explore influences of our model\nparameters. A comparison on the VidCom dataset supports the plausibility of the\nproposed approach.",
          "link": "http://arxiv.org/abs/2106.06073",
          "publishedOn": "2021-06-14T01:38:52.552Z",
          "wordCount": 608,
          "title": "A modular framework for object-based saccadic decisions in dynamic scenes. (arXiv:2106.06073v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06072",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Llerena_J/0/1/0/all/0/1\">Jeffri M. Llerena</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeni_L/0/1/0/all/0/1\">Luis Felipe Zeni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kristen_L/0/1/0/all/0/1\">Lucas N. Kristen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_C/0/1/0/all/0/1\">Claudio Jung</a>",
          "description": "Most object detection methods use bounding boxes to encode and represent the\nobject shape and location. In this work, we explore a fuzzy representation of\nobject regions using Gaussian distributions, which provides an implicit binary\nrepresentation as (potentially rotated) ellipses. We also present a similarity\nmeasure for the Gaussian distributions based on the Hellinger Distance, which\ncan be viewed as a Probabilistic Intersection-over-Union (ProbIoU). Our\nexperimental results show that the proposed Gaussian representations are closer\nto annotated segmentation masks in publicly available datasets, and that loss\nfunctions based on ProbIoU can be successfully used to regress the parameters\nof the Gaussian representation. Furthermore, we present a simple mapping scheme\nfrom traditional (or rotated) bounding boxes to Gaussian representations,\nallowing the proposed ProbIoU-based losses to be seamlessly integrated into any\nobject detector.",
          "link": "http://arxiv.org/abs/2106.06072",
          "publishedOn": "2021-06-14T01:38:52.544Z",
          "wordCount": 567,
          "title": "Gaussian Bounding Boxes and Probabilistic Intersection-over-Union for Object Detection. (arXiv:2106.06072v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06007",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ba_Y/0/1/0/all/0/1\">Yunhao Ba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karinca_K/0/1/0/all/0/1\">Kerim Doruk Karinca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bozkurt_O/0/1/0/all/0/1\">Oyku Deniz Bozkurt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kadambi_A/0/1/0/all/0/1\">Achuta Kadambi</a>",
          "description": "Camera-based remote photoplethysmography (rPPG) provides a non-contact way to\nmeasure physiological signals (e.g., heart rate) using facial videos. Recent\ndeep learning architectures have improved the accuracy of such physiological\nmeasurement significantly, yet they are restricted by the diversity of the\nannotated videos. The existing datasets MMSE-HR, AFRL, and UBFC-RPPG contain\nroughly 10%, 0%, and 5% of dark-skinned subjects respectively. The unbalanced\ntraining sets result in a poor generalization capability to unseen subjects and\nlead to unwanted bias toward different demographic groups. In Western academia,\nit is regrettably difficult in a university setting to collect data on these\ndark-skinned subjects. Here we show a first attempt to overcome the lack of\ndark-skinned subjects by synthetic augmentation. A joint optimization framework\nis utilized to translate real videos from light-skinned subjects to dark skin\ntones while retaining their pulsatile signals. In the experiment, our method\nexhibits around 31% reduction in mean absolute error for the dark-skinned group\nand 46% improvement on bias mitigation for all the groups, as compared with the\nprevious work trained with just real samples.",
          "link": "http://arxiv.org/abs/2106.06007",
          "publishedOn": "2021-06-14T01:38:52.510Z",
          "wordCount": 615,
          "title": "Overcoming Difficulty in Obtaining Dark-skinned Subjects for Remote-PPG by Synthetic Augmentation. (arXiv:2106.06007v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06112",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jingyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jiaxing Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1\">Shijian Lu</a>",
          "description": "Unsupervised domain adaptation (UDA) aims to learn a well-performed model in\nan unlabeled target domain by leveraging labeled data from one or multiple\nrelated source domains. It remains a great challenge due to 1) the lack of\nannotations in the target domain and 2) the rich discrepancy between the\ndistributions of source and target data. We propose Spectral UDA (SUDA), an\nefficient yet effective UDA technique that works in the spectral space and is\ngeneric across different visual recognition tasks in detection, classification\nand segmentation. SUDA addresses UDA challenges from two perspectives. First,\nit mitigates inter-domain discrepancies by a spectrum transformer (ST) that\nmaps source and target images into spectral space and learns to enhance\ndomain-invariant spectra while suppressing domain-variant spectra\nsimultaneously. To this end, we design novel adversarial multi-head spectrum\nattention that leverages contextual information to identify domain-variant and\ndomain-invariant spectra effectively. Second, it mitigates the lack of\nannotations in target domain by introducing multi-view spectral learning which\naims to learn comprehensive yet confident target representations by maximizing\nthe mutual information among multiple ST augmentations capturing different\nspectral views of each target sample. Extensive experiments over different\nvisual tasks (e.g., detection, classification and segmentation) show that SUDA\nachieves superior accuracy and it is also complementary with state-of-the-art\nUDA methods with consistent performance boosts but little extra computation.",
          "link": "http://arxiv.org/abs/2106.06112",
          "publishedOn": "2021-06-14T01:38:52.493Z",
          "wordCount": 642,
          "title": "Spectral Unsupervised Domain Adaptation for Visual Recognition. (arXiv:2106.06112v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06351",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Geus_D/0/1/0/all/0/1\">Daan de Geus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meletis_P/0/1/0/all/0/1\">Panagiotis Meletis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1\">Chenyang Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_X/0/1/0/all/0/1\">Xiaoxiao Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dubbelman_G/0/1/0/all/0/1\">Gijs Dubbelman</a>",
          "description": "In this work, we introduce the new scene understanding task of Part-aware\nPanoptic Segmentation (PPS), which aims to understand a scene at multiple\nlevels of abstraction, and unifies the tasks of scene parsing and part parsing.\nFor this novel task, we provide consistent annotations on two commonly used\ndatasets: Cityscapes and Pascal VOC. Moreover, we present a single metric to\nevaluate PPS, called Part-aware Panoptic Quality (PartPQ). For this new task,\nusing the metric and annotations, we set multiple baselines by merging results\nof existing state-of-the-art methods for panoptic segmentation and part\nsegmentation. Finally, we conduct several experiments that evaluate the\nimportance of the different levels of abstraction in this single task.",
          "link": "http://arxiv.org/abs/2106.06351",
          "publishedOn": "2021-06-14T01:38:52.486Z",
          "wordCount": 545,
          "title": "Part-aware Panoptic Segmentation. (arXiv:2106.06351v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06158",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gad_A/0/1/0/all/0/1\">Ahmed Fawzy Gad</a>",
          "description": "This paper introduces PyGAD, an open-source easy-to-use Python library for\nbuilding the genetic algorithm. PyGAD supports a wide range of parameters to\ngive the user control over everything in its life cycle. This includes, but is\nnot limited to, population, gene value range, gene data type, parent selection,\ncrossover, and mutation. PyGAD is designed as a general-purpose optimization\nlibrary that allows the user to customize the fitness function. Its usage\nconsists of 3 main steps: build the fitness function, create an instance of the\npygad.GA class, and calling the pygad.GA.run() method. The library supports\ntraining deep learning models created either with PyGAD itself or with\nframeworks like Keras and PyTorch. Given its stable state, PyGAD is also in\nactive development to respond to the user's requested features and enhancement\nreceived on GitHub https://github.com/ahmedfgad/GeneticAlgorithmPython. PyGAD\ncomes with documentation https://pygad.readthedocs.io for further details and\nexamples.",
          "link": "http://arxiv.org/abs/2106.06158",
          "publishedOn": "2021-06-14T01:38:52.479Z",
          "wordCount": 587,
          "title": "PyGAD: An Intuitive Genetic Algorithm Python Library. (arXiv:2106.06158v1 [cs.NE])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06505",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Garcia_R/0/1/0/all/0/1\">R. Gallardo Garc&#xed;a</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_S/0/1/0/all/0/1\">S. Jarqu&#xed;n Rodr&#xed;guez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martinez_B/0/1/0/all/0/1\">B. Beltr&#xe1;n Mart&#xed;nez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gracidas_C/0/1/0/all/0/1\">C. Hern&#xe1;ndez Gracidas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torres_R/0/1/0/all/0/1\">R. Mart&#xed;nez Torres</a>",
          "description": "This work presents twelve fine-tuned deep learning architectures to solve the\nbacterial classification problem over the Digital Image of Bacterial Species\nDataset. The base architectures were mainly published as mobile or efficient\nsolutions to the ImageNet challenge, and all experiments presented in this work\nconsisted of making several modifications to the original designs, in order to\nmake them able to solve the bacterial classification problem by using\nfine-tuning and transfer learning techniques. This work also proposes a novel\ndata augmentation technique for this dataset, which is based on the idea of\nartificial zooming, strongly increasing the performance of every tested\narchitecture, even doubling it in some cases. In order to get robust and\ncomplete evaluations, all experiments were performed with 10-fold\ncross-validation and evaluated with five different metrics: top-1 and top-5\naccuracy, precision, recall, and F1 score. This paper presents a complete\ncomparison of the twelve different architectures, cross-validated with the\noriginal and the augmented version of the dataset, the results are also\ncompared with several literature methods. Overall, eight of the eleven\narchitectures surpassed the 0.95 scores in top-1 accuracy with our data\naugmentation method, being 0.9738 the highest top-1 accuracy. The impact of the\ndata augmentation technique is reported with relative improvement scores.",
          "link": "http://arxiv.org/abs/2106.06505",
          "publishedOn": "2021-06-14T01:38:52.472Z",
          "wordCount": 688,
          "title": "Efficient Deep Learning Architectures for Fast Identification of Bacterial Strains in Resource-Constrained Devices. (arXiv:2106.06505v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2006.15327",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bar_A/0/1/0/all/0/1\">Amir Bar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Herzig_R/0/1/0/all/0/1\">Roei Herzig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaolong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rohrbach_A/0/1/0/all/0/1\">Anna Rohrbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chechik_G/0/1/0/all/0/1\">Gal Chechik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Darrell_T/0/1/0/all/0/1\">Trevor Darrell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Globerson_A/0/1/0/all/0/1\">Amir Globerson</a>",
          "description": "Videos of actions are complex signals containing rich compositional structure\nin space and time. Current video generation methods lack the ability to\ncondition the generation on multiple coordinated and potentially simultaneous\ntimed actions. To address this challenge, we propose to represent the actions\nin a graph structure called Action Graph and present the new ``Action Graph To\nVideo'' synthesis task. Our generative model for this task (AG2Vid)\ndisentangles motion and appearance features, and by incorporating a scheduling\nmechanism for actions facilitates a timely and coordinated video generation. We\ntrain and evaluate AG2Vid on the CATER and Something-Something V2 datasets, and\nshow that the resulting videos have better visual quality and semantic\nconsistency compared to baselines. Finally, our model demonstrates zero-shot\nabilities by synthesizing novel compositions of the learned actions. For code\nand pretrained models, see the project page https://roeiherz.github.io/AG2Video",
          "link": "http://arxiv.org/abs/2006.15327",
          "publishedOn": "2021-06-14T01:38:52.447Z",
          "wordCount": 631,
          "title": "Compositional Video Synthesis with Action Graphs. (arXiv:2006.15327v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.07466",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roldao_L/0/1/0/all/0/1\">Luis Roldao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Charette_R/0/1/0/all/0/1\">Raoul de Charette</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verroust_Blondet_A/0/1/0/all/0/1\">Anne Verroust-Blondet</a>",
          "description": "Semantic Scene Completion (SSC) aims to jointly estimate the complete\ngeometry and semantics of a scene, assuming partial sparse input. In the last\nyears following the multiplication of large-scale 3D datasets, SSC has gained\nsignificant momentum in the research community because it holds unresolved\nchallenges. Specifically, SSC lies in the ambiguous completion of large\nunobserved areas and the weak supervision signal of the ground truth. This led\nto a substantially increasing number of papers on the matter. This survey aims\nto identify, compare and analyze the techniques providing a critical analysis\nof the SSC literature on both methods and datasets. Throughout the paper, we\nprovide an in-depth analysis of the existing works covering all choices made by\nthe authors while highlighting the remaining avenues of research. SSC\nperformance of the SoA on the most popular datasets is also evaluated and\nanalyzed.",
          "link": "http://arxiv.org/abs/2103.07466",
          "publishedOn": "2021-06-14T01:38:52.440Z",
          "wordCount": 600,
          "title": "3D Semantic Scene Completion: a Survey. (arXiv:2103.07466v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.08844",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jinghan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boloor_A/0/1/0/all/0/1\">Adith Boloor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakrabarti_A/0/1/0/all/0/1\">Ayan Chakrabarti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vorobeychik_Y/0/1/0/all/0/1\">Yevgeniy Vorobeychik</a>",
          "description": "There is considerable evidence that deep neural networks are vulnerable to\nadversarial perturbations applied directly to their digital inputs. However, it\nremains an open question whether this translates to vulnerabilities in real\nsystems. For example, an attack on self-driving cars would in practice entail\nmodifying the driving environment, which then impacts the video inputs to the\ncar's controller, thereby indirectly leading to incorrect driving decisions.\nSuch attacks require accounting for system dynamics and tracking viewpoint\nchanges. We propose a scalable approach for finding adversarial modifications\nof a simulated autonomous driving environment using a differentiable\napproximation for the mapping from environmental modifications (rectangles on\nthe road) to the corresponding video inputs to the controller neural network.\nGiven the parameters of the rectangles, our proposed differentiable mapping\ncomposites them onto pre-recorded video streams of the original environment,\naccounting for geometric and color variations. Moreover, we propose a multiple\ntrajectory sampling approach that enables our attacks to be robust to a car's\nself-correcting behavior. When combined with a neural network-based controller,\nour approach allows the design of adversarial modifications through end-to-end\ngradient-based optimization. Using the Carla autonomous driving simulator, we\nshow that our approach is significantly more scalable and far more effective at\nidentifying autonomous vehicle vulnerabilities in simulation experiments than a\nstate-of-the-art approach based on Bayesian Optimization.",
          "link": "http://arxiv.org/abs/2010.08844",
          "publishedOn": "2021-06-14T01:38:52.433Z",
          "wordCount": 694,
          "title": "Finding Physical Adversarial Examples for Autonomous Driving with Fast and Differentiable Image Compositing. (arXiv:2010.08844v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.06868",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Quenum_J/0/1/0/all/0/1\">Jerome Quenum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Kehan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zakhor_A/0/1/0/all/0/1\">Avideh Zakhor</a>",
          "description": "Object detection in Ultra High-Resolution (UHR) images has long been a\nchallenging problem in computer vision due to the varying scales of the\ntargeted objects. When it comes to barcode detection, resizing UHR input images\nto smaller sizes often leads to the loss of pertinent information, while\nprocessing them directly is highly inefficient and computationally expensive.\nIn this paper, we propose using semantic segmentation to achieve a fast and\naccurate detection of barcodes of various scales in UHR images. Our pipeline\ninvolves a modified Region Proposal Network (RPN) on images of size greater\nthan 10k$\\times$10k and a newly proposed Y-Net segmentation network, followed\nby a post-processing workflow for fitting a bounding box around each segmented\nbarcode mask. The end-to-end system has a latency of 16 milliseconds, which is\n$2.5\\times$ faster than YOLOv4 and $5.9\\times$ faster than Mask R-CNN. In terms\nof accuracy, our method outperforms YOLOv4 and Mask R-CNN by a $mAP$ of 5.5%\nand 47.1% respectively, on a synthetic dataset. We have made available the\ngenerated synthetic barcode dataset and its code at\nthis http URL",
          "link": "http://arxiv.org/abs/2102.06868",
          "publishedOn": "2021-06-14T01:38:52.419Z",
          "wordCount": 656,
          "title": "Fast, Accurate Barcode Detection in Ultra High-Resolution Images. (arXiv:2102.06868v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.04061",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xintao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Honglun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shan_Y/0/1/0/all/0/1\">Ying Shan</a>",
          "description": "Blind face restoration usually relies on facial priors, such as facial\ngeometry prior or reference prior, to restore realistic and faithful details.\nHowever, very low-quality inputs cannot offer accurate geometric prior while\nhigh-quality references are inaccessible, limiting the applicability in\nreal-world scenarios. In this work, we propose GFP-GAN that leverages rich and\ndiverse priors encapsulated in a pretrained face GAN for blind face\nrestoration. This Generative Facial Prior (GFP) is incorporated into the face\nrestoration process via novel channel-split spatial feature transform layers,\nwhich allow our method to achieve a good balance of realness and fidelity.\nThanks to the powerful generative facial prior and delicate designs, our\nGFP-GAN could jointly restore facial details and enhance colors with just a\nsingle forward pass, while GAN inversion methods require expensive\nimage-specific optimization at inference. Extensive experiments show that our\nmethod achieves superior performance to prior art on both synthetic and\nreal-world datasets.",
          "link": "http://arxiv.org/abs/2101.04061",
          "publishedOn": "2021-06-14T01:38:52.402Z",
          "wordCount": 618,
          "title": "Towards Real-World Blind Face Restoration with Generative Facial Prior. (arXiv:2101.04061v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06313",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1\">Lixiang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jianke Zhu</a>",
          "description": "It is challenging to directly estimate the geometry of human from a single\nimage due to the high diversity and complexity of body shapes with the various\nclothing styles. Most of model-based approaches are limited to predict the\nshape and pose of a minimally clothed body with over-smoothing surface.\nAlthough capturing the fine detailed geometries, the model-free methods are\nlack of the fixed mesh topology. To address these issues, we propose a novel\ntopology-preserved human reconstruction approach by bridging the gap between\nmodel-based and model-free human reconstruction. We present an end-to-end\nneural network that simultaneously predicts the pixel-aligned implicit surface\nand the explicit mesh model built by graph convolutional neural network.\nMoreover, an extra graph convolutional neural network is employed to estimate\nthe vertex offsets between the implicit surface and parametric mesh model.\nFinally, we suggest an efficient implicit registration method to refine the\nneural network output in implicit space. Experiments on DeepHuman dataset\nshowed that our approach is effective.",
          "link": "http://arxiv.org/abs/2106.06313",
          "publishedOn": "2021-06-14T01:38:52.395Z",
          "wordCount": 588,
          "title": "Bridge the Gap Between Model-based and Model-free Human Reconstruction. (arXiv:2106.06313v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2104.02710",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jennifer J. Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karigo_T/0/1/0/all/0/1\">Tomomi Karigo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_D/0/1/0/all/0/1\">Dipam Chakraborty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohanty_S/0/1/0/all/0/1\">Sharada P. Mohanty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wild_B/0/1/0/all/0/1\">Benjamin Wild</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Q/0/1/0/all/0/1\">Quan Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anderson_D/0/1/0/all/0/1\">David J. Anderson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perona_P/0/1/0/all/0/1\">Pietro Perona</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yue_Y/0/1/0/all/0/1\">Yisong Yue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kennedy_A/0/1/0/all/0/1\">Ann Kennedy</a>",
          "description": "Multi-agent behavior modeling aims to understand the interactions that occur\nbetween agents. We present a multi-agent dataset from behavioral neuroscience,\nthe Caltech Mouse Social Interactions (CalMS21) Dataset. Our dataset consists\nof trajectory data of social interactions, recorded from videos of freely\nbehaving mice in a standard resident-intruder assay. To help accelerate\nbehavioral studies, the CalMS21 dataset provides benchmarks to evaluate the\nperformance of automated behavior classification methods in three settings: (1)\nfor training on large behavioral datasets all annotated by a single annotator,\n(2) for style transfer to learn inter-annotator differences in behavior\ndefinitions, and (3) for learning of new behaviors of interest given limited\ntraining data. The dataset consists of 6 million frames of unlabeled tracked\nposes of interacting mice, as well as over 1 million frames with tracked poses\nand corresponding frame-level behavior annotations. The challenge of our\ndataset is to be able to classify behaviors accurately using both labeled and\nunlabeled tracking data, as well as being able to generalize to new settings.",
          "link": "http://arxiv.org/abs/2104.02710",
          "publishedOn": "2021-06-14T01:38:52.388Z",
          "wordCount": 662,
          "title": "The Multi-Agent Behavior Dataset: Mouse Dyadic Social Interactions. (arXiv:2104.02710v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06307",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nazir_U/0/1/0/all/0/1\">Usman Nazir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">He Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taj_M/0/1/0/all/0/1\">Murtaza Taj</a>",
          "description": "In this survey paper, we analyze image based graph neural networks and\npropose a three-step classification approach. We first convert the image into\nsuperpixels using the Quickshift algorithm so as to reduce 30% of the input\ndata. The superpixels are subsequently used to generate a region adjacency\ngraph. Finally, the graph is passed through a state-of-art graph convolutional\nneural network to get classification scores. We also analyze the spatial and\nspectral convolution filtering techniques in graph neural networks.\nSpectral-based models perform better than spatial-based models and classical\nCNN with lesser compute cost.",
          "link": "http://arxiv.org/abs/2106.06307",
          "publishedOn": "2021-06-14T01:38:52.381Z",
          "wordCount": 522,
          "title": "Survey of Image Based Graph Neural Networks. (arXiv:2106.06307v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06533",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bhattad_A/0/1/0/all/0/1\">Anand Bhattad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dundar_A/0/1/0/all/0/1\">Aysegul Dundar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Guilin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_A/0/1/0/all/0/1\">Andrew Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Catanzaro_B/0/1/0/all/0/1\">Bryan Catanzaro</a>",
          "description": "Humans can easily infer the underlying 3D geometry and texture of an object\nonly from a single 2D image. Current computer vision methods can do this, too,\nbut suffer from view generalization problems - the models inferred tend to make\npoor predictions of appearance in novel views. As for generalization problems\nin machine learning, the difficulty is balancing single-view accuracy (cf.\ntraining error; bias) with novel view accuracy (cf. test error; variance). We\ndescribe a class of models whose geometric rigidity is easily controlled to\nmanage this tradeoff. We describe a cycle consistency loss that improves view\ngeneralization (roughly, a model from a generated view should predict the\noriginal view well). View generalization of textures requires that models share\ntexture information, so a car seen from the back still has headlights because\nother cars have headlights. We describe a cycle consistency loss that\nencourages model textures to be aligned, so as to encourage sharing. We compare\nour method against the state-of-the-art method and show both qualitative and\nquantitative improvements.",
          "link": "http://arxiv.org/abs/2106.06533",
          "publishedOn": "2021-06-14T01:38:52.374Z",
          "wordCount": 620,
          "title": "View Generalization for Single Image Textured 3D Models. (arXiv:2106.06533v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06418",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jansson_Y/0/1/0/all/0/1\">Ylva Jansson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lindeberg_T/0/1/0/all/0/1\">Tony Lindeberg</a>",
          "description": "The ability to handle large scale variations is crucial for many real world\nvisual tasks. A straightforward approach for handling scale in a deep network\nis to process an image at several scales simultaneously in a set of scale\nchannels. Scale invariance can then, in principle, be achieved by using weight\nsharing between the scale channels together with max or average pooling over\nthe outputs from the scale channels. The ability of such scale channel networks\nto generalise to scales not present in the training set over significant scale\nranges has, however, not previously been explored.\n\nIn this paper, we present a systematic study of this methodology by\nimplementing different types of scale channel networks and evaluating their\nability to generalise to previously unseen scales. We develop a formalism for\nanalysing the covariance and invariance properties of scale channel networks,\nand explore how different design choices, unique to scaling transformations,\naffect the overall performance of scale channel networks. We first show that\ntwo previously proposed scale channel network designs do not generalise well to\nscales not present in the training set. We explain theoretically and\ndemonstrate experimentally why generalisation fails in these cases.\n\nWe then propose a new type of foveated scale channel architecture}, where the\nscale channels process increasingly larger parts of the image with decreasing\nresolution. This new type of scale channel network is shown to generalise\nextremely well, provided sufficient image resolution and the absence of\nboundary effects. Our proposed FovMax and FovAvg networks perform almost\nidentically over a scale range of 8, also when training on single scale\ntraining data, and do also give improved performance when learning from\ndatasets with large scale variations in the small sample regime.",
          "link": "http://arxiv.org/abs/2106.06418",
          "publishedOn": "2021-06-14T01:38:52.368Z",
          "wordCount": 734,
          "title": "Scale-invariant scale-channel networks: Deep networks that generalise to previously unseen scales. (arXiv:2106.06418v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2102.07753",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Seidenschwarz_J/0/1/0/all/0/1\">Jenny Seidenschwarz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elezi_I/0/1/0/all/0/1\">Ismail Elezi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leal_Taixe_L/0/1/0/all/0/1\">Laura Leal-Taix&#xe9;</a>",
          "description": "The goal of metric learning is to learn a function that maps samples to a\nlower-dimensional space where similar samples lie closer than dissimilar ones.\nParticularly, deep metric learning utilizes neural networks to learn such a\nmapping. Most approaches rely on losses that only take the relations between\npairs or triplets of samples into account, which either belong to the same\nclass or two different classes. However, these methods do not explore the\nembedding space in its entirety. To this end, we propose an approach based on\nmessage passing networks that takes all the relations in a mini-batch into\naccount. We refine embedding vectors by exchanging messages among all samples\nin a given batch allowing the training process to be aware of its overall\nstructure. Since not all samples are equally important to predict a decision\nboundary, we use an attention mechanism during message passing to allow samples\nto weigh the importance of each neighbor accordingly. We achieve\nstate-of-the-art results on clustering and image retrieval on the CUB-200-2011,\nCars196, Stanford Online Products, and In-Shop Clothes datasets. To facilitate\nfurther research, we make available the code and the models at\nhttps://github.com/dvl-tum/intra_batch_connections.",
          "link": "http://arxiv.org/abs/2102.07753",
          "publishedOn": "2021-06-14T01:38:52.339Z",
          "wordCount": 667,
          "title": "Learning Intra-Batch Connections for Deep Metric Learning. (arXiv:2102.07753v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06234",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Castellano_G/0/1/0/all/0/1\">Giovanna Castellano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vessio_G/0/1/0/all/0/1\">Gennaro Vessio</a>",
          "description": "Clustering artworks is difficult for several reasons. On the one hand,\nrecognizing meaningful patterns based on domain knowledge and visual perception\nis extremely hard. On the other hand, applying traditional clustering and\nfeature reduction techniques to the highly dimensional pixel space can be\nineffective. To address these issues, in this paper we propose DELIUS: a DEep\nlearning approach to cLustering vIsUal artS. The method uses a pre-trained\nconvolutional network to extract features and then feeds these features into a\ndeep embedded clustering model, where the task of mapping the raw input data to\na latent space is jointly optimized with the task of finding a set of cluster\ncentroids in this latent space. Quantitative and qualitative experimental\nresults show the effectiveness of the proposed method. DELIUS can be useful for\nseveral tasks related to art analysis, in particular visual link retrieval and\nhistorical knowledge discovery in painting datasets.",
          "link": "http://arxiv.org/abs/2106.06234",
          "publishedOn": "2021-06-14T01:38:52.333Z",
          "wordCount": 578,
          "title": "A deep learning approach to clustering visual arts. (arXiv:2106.06234v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06011",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yibo Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haidi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1\">Yiming Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shunyao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1\">Mingliang Xu</a>",
          "description": "With the development of deep learning, the single super-resolution image\nreconstruction network models are becoming more and more complex. Small changes\nin hyperparameters of the models have a greater impact on model performance. In\nthe existing works, experts have gradually explored a set of optimal model\nparameters based on empirical values or performing brute-force search. In this\npaper, we introduce a new super-resolution image reconstruction generative\nadversarial network framework, and a Bayesian optimization method used to\noptimizing the hyperparameters of the generator and discriminator. The\ngenerator is made by self-calibrated convolution, and discriminator is made by\nconvolution lays. We have defined the hyperparameters such as the number of\nnetwork layers and the number of neurons. Our method adopts Bayesian\noptimization as a optimization policy of GAN in our model. Not only can find\nthe optimal hyperparameter solution automatically, but also can construct a\nsuper-resolution image reconstruction network, reducing the manual workload.\nExperiments show that Bayesian optimization can search the optimal solution\nearlier than the other two optimization algorithms.",
          "link": "http://arxiv.org/abs/2106.06011",
          "publishedOn": "2021-06-14T01:38:52.326Z",
          "wordCount": 619,
          "title": "A self-adapting super-resolution structures framework for automatic design of GAN. (arXiv:2106.06011v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/1909.04810",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kumra_S/0/1/0/all/0/1\">Sulabh Kumra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_S/0/1/0/all/0/1\">Shirin Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sahin_F/0/1/0/all/0/1\">Ferat Sahin</a>",
          "description": "In this paper, we present a modular robotic system to tackle the problem of\ngenerating and performing antipodal robotic grasps for unknown objects from\nn-channel image of the scene. We propose a novel Generative Residual\nConvolutional Neural Network (GR-ConvNet) model that can generate robust\nantipodal grasps from n-channel input at real-time speeds (~20ms). We evaluate\nthe proposed model architecture on standard datasets and a diverse set of\nhousehold objects. We achieved state-of-the-art accuracy of 97.7% and 94.6% on\nCornell and Jacquard grasping datasets respectively. We also demonstrate a\ngrasp success rate of 95.4% and 93% on household and adversarial objects\nrespectively using a 7 DoF robotic arm.",
          "link": "http://arxiv.org/abs/1909.04810",
          "publishedOn": "2021-06-14T01:38:52.310Z",
          "wordCount": 596,
          "title": "Antipodal Robotic Grasping using Generative Residual Convolutional Neural Network. (arXiv:1909.04810v4 [cs.RO] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.05501",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qin_H/0/1/0/all/0/1\">Haotong Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_Z/0/1/0/all/0/1\">Zhongang Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mingyuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1\">Yifu Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Haiyu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_S/0/1/0/all/0/1\">Shuai Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xianglong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1\">Hao Su</a>",
          "description": "To alleviate the resource constraint for real-time point cloud applications\nthat run on edge devices, in this paper we present BiPointNet, the first model\nbinarization approach for efficient deep learning on point clouds. We discover\nthat the immense performance drop of binarized models for point clouds mainly\nstems from two challenges: aggregation-induced feature homogenization that\nleads to a degradation of information entropy, and scale distortion that\nhinders optimization and invalidates scale-sensitive structures. With\ntheoretical justifications and in-depth analysis, our BiPointNet introduces\nEntropy-Maximizing Aggregation (EMA) to modulate the distribution before\naggregation for the maximum information entropy, and Layer-wise Scale Recovery\n(LSR) to efficiently restore feature representation capacity. Extensive\nexperiments show that BiPointNet outperforms existing binarization methods by\nconvincing margins, at the level even comparable with the full precision\ncounterpart. We highlight that our techniques are generic, guaranteeing\nsignificant improvements on various fundamental tasks and mainstream backbones.\nMoreover, BiPointNet gives an impressive 14.7x speedup and 18.9x storage saving\non real-world resource-constrained devices.",
          "link": "http://arxiv.org/abs/2010.05501",
          "publishedOn": "2021-06-14T01:38:52.303Z",
          "wordCount": 645,
          "title": "BiPointNet: Binary Neural Network for Point Clouds. (arXiv:2010.05501v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1908.01961",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meka_A/0/1/0/all/0/1\">Abhimitra Meka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shafiei_M/0/1/0/all/0/1\">Mohammad Shafiei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zollhoefer_M/0/1/0/all/0/1\">Michael Zollhoefer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Richardt_C/0/1/0/all/0/1\">Christian Richardt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Theobalt_C/0/1/0/all/0/1\">Christian Theobalt</a>",
          "description": "We propose the first approach for the decomposition of a monocular color\nvideo into direct and indirect illumination components in real time. We\nretrieve, in separate layers, the contribution made to the scene appearance by\nthe scene reflectance, the light sources and the reflections from various\ncoherent scene regions to one another. Existing techniques that invert global\nlight transport require image capture under multiplexed controlled lighting, or\nonly enable the decomposition of a single image at slow off-line frame rates.\nIn contrast, our approach works for regular videos and produces temporally\ncoherent decomposition layers at real-time frame rates. At the core of our\napproach are several sparsity priors that enable the estimation of the\nper-pixel direct and indirect illumination layers based on a small set of\njointly estimated base reflectance colors. The resulting variational\ndecomposition problem uses a new formulation based on sparse and dense sets of\nnon-linear equations that we solve efficiently using a novel alternating\ndata-parallel optimization strategy. We evaluate our approach qualitatively and\nquantitatively, and show improvements over the state of the art in this field,\nin both quality and runtime. In addition, we demonstrate various real-time\nappearance editing applications for videos with consistent illumination.",
          "link": "http://arxiv.org/abs/1908.01961",
          "publishedOn": "2021-06-14T01:38:52.296Z",
          "wordCount": 655,
          "title": "Real-Time Global Illumination Decomposition of Videos. (arXiv:1908.01961v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06360",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shen_F/0/1/0/all/0/1\">Feihong Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_P/0/1/0/all/0/1\">Ping Hu</a>",
          "description": "zero-shot learning is an essential part of computer vision. As a classical\ndownstream task, zero-shot semantic segmentation has been studied because of\nits applicant value. One of the popular zero-shot semantic segmentation methods\nis based on the generative model Most new proposed works added structures on\nthe same architecture to enhance this model. However, we found that, from the\nview of causal inference, the result of the original model has been influenced\nby spurious statistical relationships. Thus the performance of the prediction\nshows severe bias. In this work, we consider counterfactual methods to avoid\nthe confounder in the original model. Based on this method, we proposed a new\nframework for zero-shot semantic segmentation. Our model is compared with\nbaseline models on two real-world datasets, Pascal-VOC and Pascal-Context. The\nexperiment results show proposed models can surpass previous confounded models\nand can still make use of additional structures to improve the performance. We\nalso design a simple structure based on Graph Convolutional Networks (GCN) in\nthis work.",
          "link": "http://arxiv.org/abs/2106.06360",
          "publishedOn": "2021-06-14T01:38:52.289Z",
          "wordCount": 598,
          "title": "Conterfactual Generative Zero-Shot Semantic Segmentation. (arXiv:2106.06360v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2101.12690",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Costain_T/0/1/0/all/0/1\">Theo W. Costain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prisacariu_V/0/1/0/all/0/1\">Victor Adrian Prisacariu</a>",
          "description": "Neural implicit representations have shown substantial improvements in\nefficiently storing 3D data, when compared to conventional formats. However,\nthe focus of existing work has mainly been on storage and subsequent\nreconstruction. In this work, we show that training neural representations for\nreconstruction tasks alongside conventional tasks can produce more general\nencodings that admit equal quality reconstructions to single task training,\nwhilst improving results on conventional tasks when compared to single task\nencodings. We reformulate the semantic segmentation task, creating a more\nrepresentative task for implicit representation contexts, and through\nmulti-task experiments on reconstruction, classification, and segmentation,\nshow our approach learns feature rich encodings that admit equal performance\nfor each task.",
          "link": "http://arxiv.org/abs/2101.12690",
          "publishedOn": "2021-06-14T01:38:52.283Z",
          "wordCount": 559,
          "title": "Towards Generalising Neural Implicit Representations. (arXiv:2101.12690v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.11456",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_J/0/1/0/all/0/1\">Jiahong Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adeli_E/0/1/0/all/0/1\">Ehsan Adeli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pohl_K/0/1/0/all/0/1\">Kilian M. Pohl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1\">Qingyu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaharchuk_G/0/1/0/all/0/1\">Greg Zaharchuk</a>",
          "description": "Multi-modal MRIs are widely used in neuroimaging applications since different\nMR sequences provide complementary information about brain structures. Recent\nworks have suggested that multi-modal deep learning analysis can benefit from\nexplicitly disentangling anatomical (shape) and modality (appearance)\ninformation into separate image presentations. In this work, we challenge\nmainstream strategies by showing that they do not naturally lead to\nrepresentation disentanglement both in theory and in practice. To address this\nissue, we propose a margin loss that regularizes the similarity in\nrelationships of the representations across subjects and modalities. To enable\nrobust training, we further use a conditional convolution to design a single\nmodel for encoding images of all modalities. Lastly, we propose a fusion\nfunction to combine the disentangled anatomical representations as a set of\nmodality-invariant features for downstream tasks. We evaluate the proposed\nmethod on three multi-modal neuroimaging datasets. Experiments show that our\nproposed method can achieve superior disentangled representations compared to\nexisting disentanglement strategies. Results also indicate that the fused\nanatomical representation has potential in the downstream task of zero-dose PET\nreconstruction and brain tumor segmentation. The code is available at\n\\url{https://github.com/ouyangjiahong/representation-disentanglement}.",
          "link": "http://arxiv.org/abs/2102.11456",
          "publishedOn": "2021-06-14T01:38:52.242Z",
          "wordCount": 658,
          "title": "Representation Disentanglement for Multi-modal brain MR Analysis. (arXiv:2102.11456v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06059",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roy_P/0/1/0/all/0/1\">Pankaj Raj Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bilodeau_G/0/1/0/all/0/1\">Guillaume-Alexandre Bilodeau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seoud_L/0/1/0/all/0/1\">Lama Seoud</a>",
          "description": "We present a local anomaly detection method in videos. As opposed to most\nexisting methods that are computationally expensive and are not very\ngeneralizable across different video scenes, we propose an adversarial\nframework that learns the temporal local appearance variations by predicting\nthe appearance of a normally behaving object in the next frame of a scene by\nonly relying on its current and past appearances. In the presence of an\nabnormally behaving object, the reconstruction error between the real and the\npredicted next appearance of that object indicates the likelihood of an\nanomaly. Our method is competitive with the existing state-of-the-art while\nbeing significantly faster for both training and inference and being better at\ngeneralizing to unseen video scenes.",
          "link": "http://arxiv.org/abs/2106.06059",
          "publishedOn": "2021-06-14T01:38:52.219Z",
          "wordCount": 556,
          "title": "Predicting Next Local Appearance for Video Anomaly Detection. (arXiv:2106.06059v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06509",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ji_Z/0/1/0/all/0/1\">Zhong Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1\">Kexin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haoran Wang</a>",
          "description": "Image-text matching plays a central role in bridging the semantic gap between\nvision and language. The key point to achieve precise visual-semantic alignment\nlies in capturing the fine-grained cross-modal correspondence between image and\ntext. Most previous methods rely on single-step reasoning to discover the\nvisual-semantic interactions, which lacks the ability of exploiting the\nmulti-level information to locate the hierarchical fine-grained relevance.\nDifferent from them, in this work, we propose a step-wise hierarchical\nalignment network (SHAN) that decomposes image-text matching into multi-step\ncross-modal reasoning process. Specifically, we first achieve local-to-local\nalignment at fragment level, following by performing global-to-local and\nglobal-to-global alignment at context level sequentially. This progressive\nalignment strategy supplies our model with more complementary and sufficient\nsemantic clues to understand the hierarchical correlations between image and\ntext. The experimental results on two benchmark datasets demonstrate the\nsuperiority of our proposed method.",
          "link": "http://arxiv.org/abs/2106.06509",
          "publishedOn": "2021-06-14T01:38:52.171Z",
          "wordCount": 572,
          "title": "Step-Wise Hierarchical Alignment Network for Image-Text Matching. (arXiv:2106.06509v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06403",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tavakoli_H/0/1/0/all/0/1\">Hooman Tavakoli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walunj_S/0/1/0/all/0/1\">Snehal Walunj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pahlevannejad_P/0/1/0/all/0/1\">Parsha Pahlevannejad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plociennik_C/0/1/0/all/0/1\">Christiane Plociennik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruskowski_M/0/1/0/all/0/1\">Martin Ruskowski</a>",
          "description": "Detecting small objects in video streams of head-worn augmented reality\ndevices in near real-time is a huge challenge: training data is typically\nscarce, the input video stream can be of limited quality, and small objects are\nnotoriously hard to detect. In industrial scenarios, however, it is often\npossible to leverage contextual knowledge for the detection of small objects.\nFurthermore, CAD data of objects are typically available and can be used to\ngenerate synthetic training data. We describe a near real-time small object\ndetection pipeline for egocentric perception in a manual assembly scenario: We\ngenerate a training data set based on CAD data and realistic backgrounds in\nUnity. We then train a YOLOv4 model for a two-stage detection process: First,\nthe context is recognized, then the small object of interest is detected. We\nevaluate our pipeline on the augmented reality device Microsoft Hololens 2.",
          "link": "http://arxiv.org/abs/2106.06403",
          "publishedOn": "2021-06-14T01:38:52.139Z",
          "wordCount": 600,
          "title": "Small Object Detection for Near Real-Time Egocentric Perception in a Manual Assembly Scenario. (arXiv:2106.06403v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06195",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1\">Xing Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Hezheng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xiangyu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1\">Fan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_D/0/1/0/all/0/1\">Dong Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhongyuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_N/0/1/0/all/0/1\">Nian Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Honglin Liu</a>",
          "description": "The task of multi-label image classification is to recognize all the object\nlabels presented in an image. Though advancing for years, small objects,\nsimilar objects and objects with high conditional probability are still the\nmain bottlenecks of previous convolutional neural network(CNN) based models,\nlimited by convolutional kernels' representational capacity. Recent vision\ntransformer networks utilize the self-attention mechanism to extract the\nfeature of pixel granularity, which expresses richer local semantic\ninformation, while is insufficient for mining global spatial dependence. In\nthis paper, we point out the three crucial problems that CNN-based methods\nencounter and explore the possibility of conducting specific transformer\nmodules to settle them. We put forward a Multi-label Transformer\narchitecture(MlTr) constructed with windows partitioning, in-window pixel\nattention, cross-window attention, particularly improving the performance of\nmulti-label image classification tasks. The proposed MlTr shows\nstate-of-the-art results on various prevalent multi-label datasets such as\nMS-COCO, Pascal-VOC, and NUS-WIDE with 88.5%, 95.8%, and 65.5% respectively.\nThe code will be available soon at https://github.com/starmemda/MlTr/",
          "link": "http://arxiv.org/abs/2106.06195",
          "publishedOn": "2021-06-14T01:38:52.084Z",
          "wordCount": 594,
          "title": "MlTr: Multi-label Classification with Transformer. (arXiv:2106.06195v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06138",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ruan_L/0/1/0/all/0/1\">Ludan Ruan</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jieting Chen</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yuqing Song</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Shizhe Chen</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Q/0/1/0/all/0/1\">Qin Jin</a> (1) ((1) Renmin University of China, (2) INRIA)",
          "description": "Entities Object Localization (EOL) aims to evaluate how grounded or faithful\na description is, which consists of caption generation and object grounding.\nPrevious works tackle this problem by jointly training the two modules in a\nframework, which limits the complexity of each module. Therefore, in this work,\nwe propose to divide these two modules into two stages and improve them\nrespectively to boost the whole system performance. For the caption generation,\nwe propose a Unified Multi-modal Pre-training Model (UMPM) to generate event\ndescriptions with rich objects for better localization. For the object\ngrounding, we fine-tune the state-of-the-art detection model MDETR and design a\npost processing method to make the grounding results more faithful. Our overall\nsystem achieves the state-of-the-art performances on both sub-tasks in Entities\nObject Localization challenge at Activitynet 2021, with 72.57 localization\naccuracy on the testing set of sub-task I and 0.2477 F1_all_per_sent on the\nhidden testing set of sub-task II.",
          "link": "http://arxiv.org/abs/2106.06138",
          "publishedOn": "2021-06-14T01:38:52.076Z",
          "wordCount": 606,
          "title": "Team RUC_AIM3 Technical Report at ActivityNet 2021: Entities Object Localization. (arXiv:2106.06138v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06027",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1\">Mingkang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tianlong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhangyang Wang</a>",
          "description": "Sparse adversarial attacks can fool deep neural networks (DNNs) by only\nperturbing a few pixels (regularized by l_0 norm). Recent efforts combine it\nwith another l_infty imperceptible on the perturbation magnitudes. The\nresultant sparse and imperceptible attacks are practically relevant, and\nindicate an even higher vulnerability of DNNs that we usually imagined.\nHowever, such attacks are more challenging to generate due to the optimization\ndifficulty by coupling the l_0 regularizer and box constraints with a\nnon-convex objective. In this paper, we address this challenge by proposing a\nhomotopy algorithm, to jointly tackle the sparsity and the perturbation bound\nin one unified framework. Each iteration, the main step of our algorithm is to\noptimize an l_0-regularized adversarial loss, by leveraging the nonmonotone\nAccelerated Proximal Gradient Method (nmAPG) for nonconvex programming; it is\nfollowed by an l_0 change control step, and an optional post-attack step\ndesigned to escape bad local minima. We also extend the algorithm to handling\nthe structural sparsity regularizer. We extensively examine the effectiveness\nof our proposed homotopy attack for both targeted and non-targeted attack\nscenarios, on CIFAR-10 and ImageNet datasets. Compared to state-of-the-art\nmethods, our homotopy attack leads to significantly fewer perturbations, e.g.,\nreducing 42.91% on CIFAR-10 and 75.03% on ImageNet (average case, targeted\nattack), at similar maximal perturbation magnitudes, when still achieving 100%\nattack success rates. Our codes are available at:\nhttps://github.com/VITA-Group/SparseADV_Homotopy.",
          "link": "http://arxiv.org/abs/2106.06027",
          "publishedOn": "2021-06-14T01:38:52.042Z",
          "wordCount": 662,
          "title": "Sparse and Imperceptible Adversarial Attack via a Homotopy Algorithm. (arXiv:2106.06027v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06012",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Laakom_F/0/1/0/all/0/1\">Firas Laakom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raitoharju_J/0/1/0/all/0/1\">Jenni Raitoharju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iosifidis_A/0/1/0/all/0/1\">Alexandros Iosifidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gabbouj_M/0/1/0/all/0/1\">Moncef Gabbouj</a>",
          "description": "Neural networks are composed of multiple layers arranged in a hierarchical\nstructure jointly trained with a gradient-based optimization, where the errors\nare back-propagated from the last layer back to the first one. At each\noptimization step, neurons at a given layer receive feedback from neurons\nbelonging to higher layers of the hierarchy. In this paper, we propose to\ncomplement this traditional 'between-layer' feedback with additional\n'within-layer' feedback to encourage diversity of the activations within the\nsame layer. To this end, we measure the pairwise similarity between the outputs\nof the neurons and use it to model the layer's overall diversity. By penalizing\nsimilarities and promoting diversity, we encourage each neuron to learn a\ndistinctive representation and, thus, to enrich the data representation learned\nwithin the layer and to increase the total capacity of the model. We\ntheoretically study how the within-layer activation diversity affects the\ngeneralization performance of a neural network and prove that increasing the\ndiversity of hidden activations reduces the estimation error. In addition to\nthe theoretical guarantees, we present an empirical study on three datasets\nconfirming that the proposed approach enhances the performance of\nstate-of-the-art neural network models and decreases the generalization gap.",
          "link": "http://arxiv.org/abs/2106.06012",
          "publishedOn": "2021-06-14T01:38:52.035Z",
          "wordCount": 628,
          "title": "Within-layer Diversity Reduces Generalization Gap. (arXiv:2106.06012v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06159",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gan_Y/0/1/0/all/0/1\">Yanhai Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1\">Xinghui Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Huiyu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_F/0/1/0/all/0/1\">Feng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1\">Junyu Dong</a>",
          "description": "Clustering is one of the fundamental tasks in computer vision and pattern\nrecognition. Recently, deep clustering methods (algorithms based on deep\nlearning) have attracted wide attention with their impressive performance. Most\nof these algorithms combine deep unsupervised representation learning and\nstandard clustering together. However, the separation of representation\nlearning and clustering will lead to suboptimal solutions because the two-stage\nstrategy prevents representation learning from adapting to subsequent tasks\n(e.g., clustering according to specific cues). To overcome this issue, efforts\nhave been made in the dynamic adaption of representation and cluster\nassignment, whereas current state-of-the-art methods suffer from heuristically\nconstructed objectives with representation and cluster assignment alternatively\noptimized. To further standardize the clustering problem, we audaciously\nformulate the objective of clustering as finding a precise feature as the cue\nfor cluster assignment. Based on this, we propose a general-purpose deep\nclustering framework which radically integrates representation learning and\nclustering into a single pipeline for the first time. The proposed framework\nexploits the powerful ability of recently developed generative models for\nlearning intrinsic features, and imposes an entropy minimization on the\ndistribution of the cluster assignment by a dedicated variational algorithm.\nExperimental results show that the performance of the proposed method is\nsuperior, or at least comparable to, the state-of-the-art methods on the\nhandwritten digit recognition, fashion recognition, face recognition and object\nrecognition benchmark datasets.",
          "link": "http://arxiv.org/abs/2106.06159",
          "publishedOn": "2021-06-14T01:38:52.014Z",
          "wordCount": 659,
          "title": "Learning the Precise Feature for Cluster Assignment. (arXiv:2106.06159v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05974",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Riquelme_C/0/1/0/all/0/1\">Carlos Riquelme</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Puigcerver_J/0/1/0/all/0/1\">Joan Puigcerver</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mustafa_B/0/1/0/all/0/1\">Basil Mustafa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neumann_M/0/1/0/all/0/1\">Maxim Neumann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jenatton_R/0/1/0/all/0/1\">Rodolphe Jenatton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pinto_A/0/1/0/all/0/1\">Andr&#xe9; Susano Pinto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keysers_D/0/1/0/all/0/1\">Daniel Keysers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Houlsby_N/0/1/0/all/0/1\">Neil Houlsby</a>",
          "description": "Sparsely-gated Mixture of Experts networks (MoEs) have demonstrated excellent\nscalability in Natural Language Processing. In Computer Vision, however, almost\nall performant networks are \"dense\", that is, every input is processed by every\nparameter. We present a Vision MoE (V-MoE), a sparse version of the Vision\nTransformer, that is scalable and competitive with the largest dense networks.\nWhen applied to image recognition, V-MoE matches the performance of\nstate-of-the-art networks, while requiring as little as half of the compute at\ninference time. Further, we propose an extension to the routing algorithm that\ncan prioritize subsets of each input across the entire batch, leading to\nadaptive per-image compute. This allows V-MoE to trade-off performance and\ncompute smoothly at test-time. Finally, we demonstrate the potential of V-MoE\nto scale vision models, and train a 15B parameter model that attains 90.35% on\nImageNet.",
          "link": "http://arxiv.org/abs/2106.05974",
          "publishedOn": "2021-06-14T01:38:51.987Z",
          "wordCount": 589,
          "title": "Scaling Vision with Sparse Mixture of Experts. (arXiv:2106.05974v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06020",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weiler_M/0/1/0/all/0/1\">Maurice Weiler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Forre_P/0/1/0/all/0/1\">Patrick Forr&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verlinde_E/0/1/0/all/0/1\">Erik Verlinde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1\">Max Welling</a>",
          "description": "Motivated by the vast success of deep convolutional networks, there is a\ngreat interest in generalizing convolutions to non-Euclidean manifolds. A major\ncomplication in comparison to flat spaces is that it is unclear in which\nalignment a convolution kernel should be applied on a manifold. The underlying\nreason for this ambiguity is that general manifolds do not come with a\ncanonical choice of reference frames (gauge). Kernels and features therefore\nhave to be expressed relative to arbitrary coordinates. We argue that the\nparticular choice of coordinatization should not affect a network's inference\n-- it should be coordinate independent. A simultaneous demand for coordinate\nindependence and weight sharing is shown to result in a requirement on the\nnetwork to be equivariant under local gauge transformations (changes of local\nreference frames). The ambiguity of reference frames depends thereby on the\nG-structure of the manifold, such that the necessary level of gauge\nequivariance is prescribed by the corresponding structure group G. Coordinate\nindependent convolutions are proven to be equivariant w.r.t. those isometries\nthat are symmetries of the G-structure. The resulting theory is formulated in a\ncoordinate free fashion in terms of fiber bundles. To exemplify the design of\ncoordinate independent convolutions, we implement a convolutional network on\nthe M\\\"obius strip. The generality of our differential geometric formulation of\nconvolutional networks is demonstrated by an extensive literature review which\nexplains a large number of Euclidean CNNs, spherical CNNs and CNNs on general\nsurfaces as specific instances of coordinate independent convolutions.",
          "link": "http://arxiv.org/abs/2106.06020",
          "publishedOn": "2021-06-14T01:38:51.971Z",
          "wordCount": 710,
          "title": "Coordinate Independent Convolutional Networks -- Isometry and Gauge Equivariant Convolutions on Riemannian Manifolds. (arXiv:2106.06020v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05611",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yoshihashi_R/0/1/0/all/0/1\">Ryota Yoshihashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tanaka_T/0/1/0/all/0/1\">Tomohiro Tanaka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doi_K/0/1/0/all/0/1\">Kenji Doi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fujino_T/0/1/0/all/0/1\">Takumi Fujino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamashita_N/0/1/0/all/0/1\">Naoaki Yamashita</a>",
          "description": "In the deployment of scene-text spotting systems on mobile platforms,\nlightweight models with low computation are preferable. In concept, end-to-end\n(E2E) text spotting is suitable for such purposes because it performs text\ndetection and recognition in a single model. However, current state-of-the-art\nE2E methods rely on heavy feature extractors, recurrent sequence modellings,\nand complex shape aligners to pursue accuracy, which means their computations\nare still heavy. We explore the opposite direction: How far can we go without\nbells and whistles in E2E text spotting? To this end, we propose a\ntext-spotting method that consists of simple convolutions and a few\npost-processes, named Context-Free TextSpotter. Experiments using standard\nbenchmarks show that Context-Free TextSpotter achieves real-time text spotting\non a GPU with only three million parameters, which is the smallest and fastest\namong existing deep text spotters, with an acceptable transcription quality\ndegradation compared to heavier ones. Further, we demonstrate that our text\nspotter can run on a smartphone with affordable latency, which is valuable for\nbuilding stand-alone OCR applications.",
          "link": "http://arxiv.org/abs/2106.05611",
          "publishedOn": "2021-06-11T01:42:17.890Z",
          "wordCount": 610,
          "title": "Context-Free TextSpotter for Real-Time and Mobile End-to-End Text Detection and Recognition. (arXiv:2106.05611v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05965",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Murphy_K/0/1/0/all/0/1\">Kieran Murphy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Esteves_C/0/1/0/all/0/1\">Carlos Esteves</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jampani_V/0/1/0/all/0/1\">Varun Jampani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramalingam_S/0/1/0/all/0/1\">Srikumar Ramalingam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Makadia_A/0/1/0/all/0/1\">Ameesh Makadia</a>",
          "description": "Single image pose estimation is a fundamental problem in many vision and\nrobotics tasks, and existing deep learning approaches suffer by not completely\nmodeling and handling: i) uncertainty about the predictions, and ii) symmetric\nobjects with multiple (sometimes infinite) correct poses. To this end, we\nintroduce a method to estimate arbitrary, non-parametric distributions on\nSO(3). Our key idea is to represent the distributions implicitly, with a neural\nnetwork that estimates the probability given the input image and a candidate\npose. Grid sampling or gradient ascent can be used to find the most likely\npose, but it is also possible to evaluate the probability at any pose, enabling\nreasoning about symmetries and uncertainty. This is the most general way of\nrepresenting distributions on manifolds, and to showcase the rich expressive\npower, we introduce a dataset of challenging symmetric and nearly-symmetric\nobjects. We require no supervision on pose uncertainty -- the model trains only\nwith a single pose per example. Nonetheless, our implicit model is highly\nexpressive to handle complex distributions over 3D poses, while still obtaining\naccurate pose estimation on standard non-ambiguous environments, achieving\nstate-of-the-art performance on Pascal3D+ and ModelNet10-SO(3) benchmarks.",
          "link": "http://arxiv.org/abs/2106.05965",
          "publishedOn": "2021-06-11T01:42:17.763Z",
          "wordCount": 625,
          "title": "Implicit-PDF: Non-Parametric Representation of Probability Distributions on the Rotation Manifold. (arXiv:2106.05965v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.14202",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hanting Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yunhe Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chao Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chunjing Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tong Zhang</a>",
          "description": "Compared with cheap addition operation, multiplication operation is of much\nhigher computation complexity. The widely-used convolutions in deep neural\nnetworks are exactly cross-correlation to measure the similarity between input\nfeature and convolution filters, which involves massive multiplications between\nfloat values. In this paper, we present adder networks (AdderNets) to trade\nthese massive multiplications in deep neural networks, especially convolutional\nneural networks (CNNs), for much cheaper additions to reduce computation costs.\nIn AdderNets, we take the $\\ell_1$-norm distance between filters and input\nfeature as the output response. The influence of this new similarity measure on\nthe optimization of neural network have been thoroughly analyzed. To achieve a\nbetter performance, we develop a special training approach for AdderNets by\ninvestigating the $\\ell_p$-norm. We then propose an adaptive learning rate\nstrategy to enhance the training procedure of AdderNets according to the\nmagnitude of each neuron's gradient. As a result, the proposed AdderNets can\nachieve 75.7% Top-1 accuracy 92.3% Top-5 accuracy using ResNet-50 on the\nImageNet dataset without any multiplication in convolutional layer. Moreover,\nwe develop a theoretical foundation for AdderNets, by showing that both the\nsingle hidden layer AdderNet and the width-bounded deep AdderNet with ReLU\nactivation functions are universal function approximators. These results match\nthose of the traditional neural networks using the more complex multiplication\nunits. An approximation bound for AdderNets with a single hidden layer is also\npresented.",
          "link": "http://arxiv.org/abs/2105.14202",
          "publishedOn": "2021-06-11T01:42:17.733Z",
          "wordCount": null,
          "title": "Universal Adder Neural Networks. (arXiv:2105.14202v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05861",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Das_D/0/1/0/all/0/1\">Debanjan Das</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Samal_C/0/1/0/all/0/1\">Chirag Samal</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ukey_D/0/1/0/all/0/1\">Deewanshu Ukey</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chowdhary_G/0/1/0/all/0/1\">Gourav Chowdhary</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mohanty_S/0/1/0/all/0/1\">Saraju P. Mohanty</a>",
          "description": "The pandemic of novel Coronavirus Disease 2019 (COVID-19) is widespread all\nover the world causing serious health problems as well as serious impact on the\nglobal economy. Reliable and fast testing of the COVID-19 has been a challenge\nfor researchers and healthcare practitioners. In this work we present a novel\nmachine learning (ML) integrated X-ray device in Healthcare Cyber-Physical\nSystem (H-CPS) or smart healthcare framework (called CoviLearn) to allow\nhealthcare practitioners to perform automatic initial screening of COVID-19\npatients. We propose convolutional neural network (CNN) models of X-ray images\nintegrated into an X-ray device for automatic COVID-19 detection. The proposed\nCoviLearn device will be useful in detecting if a person is COVID-19 positive\nor negative by considering the chest X-ray image of individuals. CoviLearn will\nbe useful tool doctors to detect potential COVID-19 infections instantaneously\nwithout taking more intrusive healthcare data samples, such as saliva and\nblood. COVID-19 attacks the endothelium tissues that support respiratory tract,\nX-rays images can be used to analyze the health of a patient lungs. As all\nhealthcare centers have X-ray machines, it could be possible to use proposed\nCoviLearn X-rays to test for COVID-19 without the especial test kits. Our\nproposed automated analysis system CoviLearn which has 99% accuracy will be\nable to save valuable time of medical professionals as the X-ray machines come\nwith a drawback as it needed a radiology expert.",
          "link": "http://arxiv.org/abs/2106.05861",
          "publishedOn": "2021-06-11T01:42:17.721Z",
          "wordCount": 735,
          "title": "CoviLearn: A Machine Learning Integrated Smart X-Ray Device in Healthcare Cyber-Physical System for Automatic Initial Screening of COVID-19. (arXiv:2106.05861v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.06340",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yap_C/0/1/0/all/0/1\">Chuin Hong Yap</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yap_M/0/1/0/all/0/1\">Moi Hoon Yap</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Davison_A/0/1/0/all/0/1\">Adrian K. Davison</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cunningham_R/0/1/0/all/0/1\">Ryan Cunningham</a>",
          "description": "Facial expression spotting is the preliminary step for micro- and\nmacro-expression analysis. The task of reliably spotting such expressions in\nvideo sequences is currently unsolved. The current best systems depend upon\noptical flow methods to extract regional motion features, before categorisation\nof that motion into a specific class of facial movement. Optical flow is\nsusceptible to drift error, which introduces a serious problem for motions with\nlong-term dependencies, such as high frame-rate macro-expression. We propose a\npurely deep learning solution which, rather than track frame differential\nmotion, compares via a convolutional model, each frame with two temporally\nlocal reference frames. Reference frames are sampled according to calculated\nmicro- and macro-expression durations. We show that our solution achieves\nstate-of-the-art performance (F1-score of 0.126) in a dataset of high\nframe-rate (200 fps) long video sequences (SAMM-LV) and is competitive in a low\nframe-rate (30 fps) dataset (CAS(ME)2). In this paper, we document our deep\nlearning model and parameters, including how we use local contrast\nnormalisation, which we show is critical for optimal results. We surpass a\nlimitation in existing methods, and advance the state of deep learning in the\ndomain of facial expression spotting.",
          "link": "http://arxiv.org/abs/2105.06340",
          "publishedOn": "2021-06-11T01:42:17.680Z",
          "wordCount": null,
          "title": "3D-CNN for Facial Micro- and Macro-expression Spotting on Long Video Sequences using Temporal Oriented Reference Frame. (arXiv:2105.06340v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.01243",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Forcen_J/0/1/0/all/0/1\">J.I.Forcen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pagola_M/0/1/0/all/0/1\">Miguel Pagola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barrenechea_E/0/1/0/all/0/1\">Edurne Barrenechea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bustince_H/0/1/0/all/0/1\">Humberto Bustince</a>",
          "description": "Spatial pooling is an important step in computer vision systems like\nConvolutional Neural Networks or the Bag-of-Words method. The spatial pooling\npurpose is to combine neighbouring descriptors to obtain a single descriptor\nfor a given region (local or global). The resultant combined vector must be as\ndiscriminant as possible, in other words, must contain relevant information,\nwhile removing irrelevant and confusing details. Maximum and average are the\nmost common aggregation functions used in the pooling step. To improve the\naggregation of relevant information without degrading their discriminative\npower for image classification, we introduce a simple but effective scheme\nbased on Ordered Weighted Average (OWA) aggregation operators. We present a\nmethod to learn the weights of the OWA aggregation operator in a Bag-of-Words\nframework and in Convolutional Neural Networks, and provide an extensive\nevaluation showing that OWA based pooling outperforms classical aggregation\noperators.",
          "link": "http://arxiv.org/abs/2007.01243",
          "publishedOn": "2021-06-11T01:42:17.678Z",
          "wordCount": null,
          "title": "Learning ordered pooling weights in image classification. (arXiv:2007.01243v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05748",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ren_C/0/1/0/all/0/1\">Chao Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dulay_J/0/1/0/all/0/1\">Justin Dulay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rolwes_G/0/1/0/all/0/1\">Gregory Rolwes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pauli_D/0/1/0/all/0/1\">Duke Pauli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shakoor_N/0/1/0/all/0/1\">Nadia Shakoor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stylianou_A/0/1/0/all/0/1\">Abby Stylianou</a>",
          "description": "Automated high throughput plant phenotyping involves leveraging sensors, such\nas RGB, thermal and hyperspectral cameras (among others), to make large scale\nand rapid measurements of the physical properties of plants for the purpose of\nbetter understanding the difference between crops and facilitating rapid plant\nbreeding programs. One of the most basic phenotyping tasks is to determine the\ncultivar, or species, in a particular sensor product. This simple phenotype can\nbe used to detect errors in planting and to learn the most differentiating\nfeatures between cultivars. It is also a challenging visual recognition task,\nas a large number of highly related crops are grown simultaneously, leading to\na classification problem with low inter-class variance. In this paper, we\nintroduce the Sorghum-100 dataset, a large dataset of RGB imagery of sorghum\ncaptured by a state-of-the-art gantry system, a multi-resolution network\narchitecture that learns both global and fine-grained features on the crops,\nand a new global pooling strategy called Dynamic Outlier Pooling which\noutperforms standard global pooling strategies on this task.",
          "link": "http://arxiv.org/abs/2106.05748",
          "publishedOn": "2021-06-11T01:42:17.653Z",
          "wordCount": 607,
          "title": "Multi-resolution Outlier Pooling for Sorghum Classification. (arXiv:2106.05748v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2102.08259",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_B/0/1/0/all/0/1\">Bo Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bilen_H/0/1/0/all/0/1\">Hakan Bilen</a>",
          "description": "In many machine learning problems, large-scale datasets have become the\nde-facto standard to train state-of-the-art deep networks at the price of heavy\ncomputation load. In this paper, we focus on condensing large training sets\ninto significantly smaller synthetic sets which can be used to train deep\nneural networks from scratch with minimum drop in performance. Inspired from\nthe recent training set synthesis methods, we propose Differentiable Siamese\nAugmentation that enables effective use of data augmentation to synthesize more\ninformative synthetic images and thus achieves better performance when training\nnetworks with augmentations. Experiments on multiple image classification\nbenchmarks demonstrate that the proposed method obtains substantial gains over\nthe state-of-the-art, 7% improvements on CIFAR10 and CIFAR100 datasets. We show\nwith only less than 1% data that our method achieves 99.6%, 94.9%, 88.5%, 71.5%\nrelative performance on MNIST, FashionMNIST, SVHN, CIFAR10 respectively. We\nalso explore the use of our method in continual learning and neural\narchitecture search, and show promising results.",
          "link": "http://arxiv.org/abs/2102.08259",
          "publishedOn": "2021-06-11T01:42:17.642Z",
          "wordCount": 615,
          "title": "Dataset Condensation with Differentiable Siamese Augmentation. (arXiv:2102.08259v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.10729",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chongyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_C/0/1/0/all/0/1\">Chunle Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_L/0/1/0/all/0/1\">Linghao Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jun Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_M/0/1/0/all/0/1\">Ming-Ming Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jinwei Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Loy_C/0/1/0/all/0/1\">Chen Change Loy</a>",
          "description": "Low-light image enhancement (LLIE) aims at improving the perception or\ninterpretability of an image captured in an environment with poor illumination.\nRecent advances in this area are dominated by deep learning-based solutions,\nwhere many learning strategies, network structures, loss functions, training\ndata, etc. have been employed. In this paper, we provide a comprehensive survey\nto cover various aspects ranging from algorithm taxonomy to unsolved open\nissues. To examine the generalization of existing methods, we propose a\nlarge-scale low-light image and video dataset, in which the images and videos\nare taken by different mobile phones' cameras under diverse illumination\nconditions. Besides, for the first time, we provide a unified online platform\nthat covers many popular LLIE methods, of which the results can be produced\nthrough a user-friendly web interface. In addition to qualitative and\nquantitative evaluation of existing methods on publicly available and our\nproposed datasets, we also validate their performance in face detection in the\ndark. This survey together with the proposed dataset and online platform could\nserve as a reference source for future study and promote the development of\nthis research field. The proposed platform and the collected methods, datasets,\nand evaluation metrics are publicly available and will be regularly updated at\nhttps://github.com/Li-Chongyi/Lighting-the-Darkness-in-the-Deep-Learning-Era-Open.\nOur low-light image and video dataset is also available.",
          "link": "http://arxiv.org/abs/2104.10729",
          "publishedOn": "2021-06-11T01:42:17.624Z",
          "wordCount": null,
          "title": "Low-Light Image and Video Enhancement Using Deep Learning: A Survey. (arXiv:2104.10729v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05662",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kokkinos_F/0/1/0/all/0/1\">Filippos Kokkinos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kokkinos_I/0/1/0/all/0/1\">Iasonas Kokkinos</a>",
          "description": "We present To The Point (TTP), a method for reconstructing 3D objects from a\nsingle image using 2D to 3D correspondences learned from weak supervision. We\nrecover a 3D shape from a 2D image by first regressing the 2D positions\ncorresponding to the 3D template vertices and then jointly estimating a rigid\ncamera transform and non-rigid template deformation that optimally explain the\n2D positions through the 3D shape projection. By relying on 3D-2D\ncorrespondences we use a simple per-sample optimization problem to replace\nCNN-based regression of camera pose and non-rigid deformation and thereby\nobtain substantially more accurate 3D reconstructions. We treat this\noptimization as a differentiable layer and train the whole system in an\nend-to-end manner. We report systematic quantitative improvements on multiple\ncategories and provide qualitative results comprising diverse shape, pose and\ntexture prediction examples. Project website:\nhttps://fkokkinos.github.io/to_the_point/.",
          "link": "http://arxiv.org/abs/2106.05662",
          "publishedOn": "2021-06-11T01:42:17.623Z",
          "wordCount": null,
          "title": "To The Point: Correspondence-driven monocular 3D category reconstruction. (arXiv:2106.05662v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2003.13827",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Forcen_J/0/1/0/all/0/1\">J.I.Forcen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pagola_M/0/1/0/all/0/1\">Miguel Pagola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barrenechea_E/0/1/0/all/0/1\">Edurne Barrenechea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bustince_H/0/1/0/all/0/1\">Humberto Bustince</a>",
          "description": "Image search can be tackled using deep features from pre-trained\nConvolutional Neural Networks (CNN). The feature map from the last\nconvolutional layer of a CNN encodes descriptive information from which a\ndiscriminative global descriptor can be obtained. We propose a new\nrepresentation of co-occurrences from deep convolutional features to extract\nadditional relevant information from this last convolutional layer. Combining\nthis co-occurrence map with the feature map, we achieve an improved image\nrepresentation. We present two different methods to get the co-occurrence\nrepresentation, the first one based on direct aggregation of activations, and\nthe second one, based on a trainable co-occurrence representation. The image\ndescriptors derived from our methodology improve the performance in very\nwell-known image retrieval datasets as we prove in the experiments.",
          "link": "http://arxiv.org/abs/2003.13827",
          "publishedOn": "2021-06-11T01:42:17.623Z",
          "wordCount": null,
          "title": "Co-occurrence of deep convolutional features for image search. (arXiv:2003.13827v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.12102",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moon_C/0/1/0/all/0/1\">Chul Moon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qiwei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_G/0/1/0/all/0/1\">Guanghua Xiao</a>",
          "description": "Tumor shape is a key factor that affects tumor growth and metastasis. This\npaper proposes a topological feature computed by persistent homology to\ncharacterize tumor progression from digital pathology and radiology images and\nexamines its effect on the time-to-event data. The proposed topological\nfeatures are invariant to scale-preserving transformation and can summarize\nvarious tumor shape patterns. The topological features are represented in\nfunctional space and used as functional predictors in a functional Cox\nproportional hazards model. The proposed model enables interpretable inference\nabout the association between topological shape features and survival risks.\nTwo case studies are conducted using consecutive 143 lung cancer and 77 brain\ntumor patients. The results of both studies show that the topological features\npredict survival prognosis after adjusting clinical variables, and the\npredicted high-risk groups have significantly (at the level of 0.01) worse\nsurvival outcomes than the low-risk groups. Also, the topological shape\nfeatures found to be positively associated with survival hazards are irregular\nand heterogeneous shape patterns, which are known to be related to tumor\nprogression.",
          "link": "http://arxiv.org/abs/2012.12102",
          "publishedOn": "2021-06-11T01:42:17.622Z",
          "wordCount": null,
          "title": "Using Persistent Homology Topological Features to Characterize Medical Images: Case Studies on Lung and Brain Cancers. (arXiv:2012.12102v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05519",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xingkun Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yuge Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_P/0/1/0/all/0/1\">Pengcheng Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shaoxin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jilin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Feiyue Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_Z/0/1/0/all/0/1\">Zhen Cui</a>",
          "description": "Demographic bias is a significant challenge in practical face recognition\nsystems. Existing methods heavily rely on accurate demographic annotations.\nHowever, such annotations are usually unavailable in real scenarios. Moreover,\nthese methods are typically designed for a specific demographic group and are\nnot general enough. In this paper, we propose a false positive rate penalty\nloss, which mitigates face recognition bias by increasing the consistency of\ninstance False Positive Rate (FPR). Specifically, we first define the instance\nFPR as the ratio between the number of the non-target similarities above a\nunified threshold and the total number of the non-target similarities. The\nunified threshold is estimated for a given total FPR. Then, an additional\npenalty term, which is in proportion to the ratio of instance FPR overall FPR,\nis introduced into the denominator of the softmax-based loss. The larger the\ninstance FPR, the larger the penalty. By such unequal penalties, the instance\nFPRs are supposed to be consistent. Compared with the previous debiasing\nmethods, our method requires no demographic annotations. Thus, it can mitigate\nthe bias among demographic groups divided by various attributes, and these\nattributes are not needed to be previously predefined during training.\nExtensive experimental results on popular benchmarks demonstrate the\nsuperiority of our method over state-of-the-art competitors. Code and trained\nmodels are available at https://github.com/Tencent/TFace.",
          "link": "http://arxiv.org/abs/2106.05519",
          "publishedOn": "2021-06-11T01:42:17.056Z",
          "wordCount": 660,
          "title": "Consistent Instance False Positive Improves Fairness in Face Recognition. (arXiv:2106.05519v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05616",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1\">Yicheng Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yongqi Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jiahui Zhu</a>",
          "description": "Recovering 3D human pose from 2D joints is a highly unconstrained problem,\nespecially without any video or multi-view information. We present an\nunsupervised GAN-based model to recover 3D human pose from 2D joint locations\nextracted from a single image. Our model uses a GAN to learn the mapping of\ndistribution from 2D poses to 3D poses, not the simple 2D-3D correspondence.\nConsidering the reprojection constraint, our model can estimate the camera so\nthat we can reproject the estimated 3D pose to the original 2D pose. Based on\nthis reprojection method, we can rotate and reproject the generated pose to get\nour \"new\" 2D pose and then use a weight sharing generator to estimate the \"new\"\n3D pose and a \"new\" camera. Through the above estimation process, we can define\nthe single-view-multi-angle consistency loss during training to simulate\nmulti-view consistency, which means the 3D poses and cameras estimated from two\nangles of a single view should be able to be mixed to generate rich 2D\nreprojections, and the 2D reprojections reprojected from the same 3D pose\nshould be consistent. The experimental results on Human3.6M show that our\nmethod outperforms all the state-of-the-art methods, and results on\nMPI-INF-3DHP show that our method outperforms state-of-the-art by approximately\n15.0%.",
          "link": "http://arxiv.org/abs/2106.05616",
          "publishedOn": "2021-06-11T01:42:16.945Z",
          "wordCount": 636,
          "title": "SVMA: A GAN-based model for Monocular 3D Human Pose Estimation. (arXiv:2106.05616v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05517",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Weifeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_C/0/1/0/all/0/1\">Chao Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_T/0/1/0/all/0/1\">Tu Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_D/0/1/0/all/0/1\">Deng Cai</a>",
          "description": "Few-shot learning (FSL) aims to learn a classifier that can be easily adapted\nto accommodate new tasks not seen during training, given only a few examples.\nTo handle the limited-data problem in few-shot regimes, recent methods tend to\ncollectively use a set of local features to densely represent an image instead\nof using a mixed global feature. They generally explore a unidirectional\nquery-to-support paradigm in FSL, e.g., find the nearest/optimal support\nfeature for each query feature and aggregate these local matches for a joint\nclassification. In this paper, we propose a new method Mutual Centralized\nLearning (MCL) to fully affiliate the two disjoint sets of dense features in a\nbidirectional paradigm. We associate each local feature with a particle that\ncan bidirectionally random walk in a discrete feature space by the\naffiliations. To estimate the class probability, we propose the features'\naccessibility that measures the expected number of visits to the support\nfeatures of that class in a Markov process. We relate our method to learning a\ncentrality on an affiliation network and demonstrate its capability to be\nplugged in existing methods by highlighting centralized local features.\nExperiments show that our method achieves the state-of-the-art on both\nminiImageNet and tieredImageNet.",
          "link": "http://arxiv.org/abs/2106.05517",
          "publishedOn": "2021-06-11T01:42:16.846Z",
          "wordCount": 637,
          "title": "Learning to Affiliate: Mutual Centralized Learning for Few-shot Classification. (arXiv:2106.05517v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05953",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Spurr_A/0/1/0/all/0/1\">Adrian Spurr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dahiya_A/0/1/0/all/0/1\">Aneesh Dahiya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xucong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hilliges_O/0/1/0/all/0/1\">Otmar Hilliges</a>",
          "description": "Acquiring accurate 3D annotated data for hand pose estimation is a\nnotoriously difficult problem. This typically requires complex multi-camera\nsetups and controlled conditions, which in turn creates a domain gap that is\nhard to bridge to fully unconstrained settings. Encouraged by the success of\ncontrastive learning on image classification tasks, we propose a new\nself-supervised method for the structured regression task of 3D hand pose\nestimation. Contrastive learning makes use of unlabeled data for the purpose of\nrepresentation learning via a loss formulation that encourages the learned\nfeature representations to be invariant under any image transformation. For 3D\nhand pose estimation, it too is desirable to have invariance to appearance\ntransformation such as color jitter. However, the task requires equivariance\nunder affine transformations, such as rotation and translation. To address this\nissue, we propose an equivariant contrastive objective and demonstrate its\neffectiveness in the context of 3D hand pose estimation. We experimentally\ninvestigate the impact of invariant and equivariant contrastive objectives and\nshow that learning equivariant features leads to better representations for the\ntask of 3D hand pose estimation. Furthermore, we show that a standard\nResNet-152, trained on additional unlabeled data, attains an improvement of\n$7.6\\%$ in PA-EPE on FreiHAND and thus achieves state-of-the-art performance\nwithout any task specific, specialized architectures.",
          "link": "http://arxiv.org/abs/2106.05953",
          "publishedOn": "2021-06-11T01:42:16.834Z",
          "wordCount": 648,
          "title": "Self-Supervised 3D Hand Pose Estimation from monocular RGB via Contrastive Learning. (arXiv:2106.05953v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2102.07954",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Dilin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_C/0/1/0/all/0/1\">Chengyue Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Meng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qiang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandra_V/0/1/0/all/0/1\">Vikas Chandra</a>",
          "description": "Weight-sharing neural architecture search (NAS) is an effective technique for\nautomating efficient neural architecture design. Weight-sharing NAS builds a\nsupernet that assembles all the architectures as its sub-networks and jointly\ntrains the supernet with the sub-networks. The success of weight-sharing NAS\nheavily relies on distilling the knowledge of the supernet to the sub-networks.\nHowever, we find that the widely used distillation divergence, i.e., KL\ndivergence, may lead to student sub-networks that over-estimate or\nunder-estimate the uncertainty of the teacher supernet, leading to inferior\nperformance of the sub-networks. In this work, we propose to improve the\nsupernet training with a more generalized alpha-divergence. By adaptively\nselecting the alpha-divergence, we simultaneously prevent the over-estimation\nor under-estimation of the uncertainty of the teacher model. We apply the\nproposed alpha-divergence based supernets training to both slimmable neural\nnetworks and weight-sharing NAS, and demonstrate significant improvements.\nSpecifically, our discovered model family, AlphaNet, outperforms prior-art\nmodels on a wide range of FLOPs regimes, including BigNAS, Once-for-All\nnetworks, and AttentiveNAS. We achieve ImageNet top-1 accuracy of 80.0% with\nonly 444M FLOPs. Our code and pretrained models are available at\nhttps://github.com/facebookresearch/AlphaNet.",
          "link": "http://arxiv.org/abs/2102.07954",
          "publishedOn": "2021-06-11T01:42:16.230Z",
          "wordCount": 661,
          "title": "AlphaNet: Improved Training of Supernets with Alpha-Divergence. (arXiv:2102.07954v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.02177",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Duzceker_A/0/1/0/all/0/1\">Arda D&#xfc;z&#xe7;eker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galliani_S/0/1/0/all/0/1\">Silvano Galliani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogel_C/0/1/0/all/0/1\">Christoph Vogel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Speciale_P/0/1/0/all/0/1\">Pablo Speciale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dusmanu_M/0/1/0/all/0/1\">Mihai Dusmanu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pollefeys_M/0/1/0/all/0/1\">Marc Pollefeys</a>",
          "description": "We propose an online multi-view depth prediction approach on posed video\nstreams, where the scene geometry information computed in the previous time\nsteps is propagated to the current time step in an efficient and geometrically\nplausible way. The backbone of our approach is a real-time capable, lightweight\nencoder-decoder that relies on cost volumes computed from pairs of images. We\nextend it by placing a ConvLSTM cell at the bottleneck layer, which compresses\nan arbitrary amount of past information in its states. The novelty lies in\npropagating the hidden state of the cell by accounting for the viewpoint\nchanges between time steps. At a given time step, we warp the previous hidden\nstate into the current camera plane using the previous depth prediction. Our\nextension brings only a small overhead of computation time and memory\nconsumption, while improving the depth predictions significantly. As a result,\nwe outperform the existing state-of-the-art multi-view stereo methods on most\nof the evaluated metrics in hundreds of indoor scenes while maintaining a\nreal-time performance. Code available:\nhttps://github.com/ardaduz/deep-video-mvs",
          "link": "http://arxiv.org/abs/2012.02177",
          "publishedOn": "2021-06-11T01:42:16.059Z",
          "wordCount": 645,
          "title": "DeepVideoMVS: Multi-View Stereo on Video with Recurrent Spatio-Temporal Fusion. (arXiv:2012.02177v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05969",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1\">Zhengyi Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hachiuma_R/0/1/0/all/0/1\">Ryo Hachiuma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1\">Ye Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kitani_K/0/1/0/all/0/1\">Kris Kitani</a>",
          "description": "We propose a method for object-aware 3D egocentric pose estimation that\ntightly integrates kinematics modeling, dynamics modeling, and scene object\ninformation. Unlike prior kinematics or dynamics-based approaches where the two\ncomponents are used disjointly, we synergize the two approaches via\ndynamics-regulated training. At each timestep, a kinematic model is used to\nprovide a target pose using video evidence and simulation state. Then, a\nprelearned dynamics model attempts to mimic the kinematic pose in a physics\nsimulator. By comparing the pose instructed by the kinematic model against the\npose generated by the dynamics model, we can use their misalignment to further\nimprove the kinematic model. By factoring in the 6DoF pose of objects (e.g.,\nchairs, boxes) in the scene, we demonstrate for the first time, the ability to\nestimate physically-plausible 3D human-object interactions using a single\nwearable camera. We evaluate our egocentric pose estimation method in both\ncontrolled laboratory settings and real-world scenarios.",
          "link": "http://arxiv.org/abs/2106.05969",
          "publishedOn": "2021-06-11T01:42:16.023Z",
          "wordCount": 596,
          "title": "Dynamics-Regulated Kinematic Policy for Egocentric Pose Estimation. (arXiv:2106.05969v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05963",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Baradad_M/0/1/0/all/0/1\">Manel Baradad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wulff_J/0/1/0/all/0/1\">Jonas Wulff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tongzhou Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Isola_P/0/1/0/all/0/1\">Phillip Isola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torralba_A/0/1/0/all/0/1\">Antonio Torralba</a>",
          "description": "Current vision systems are trained on huge datasets, and these datasets come\nwith costs: curation is expensive, they inherit human biases, and there are\nconcerns over privacy and usage rights. To counter these costs, interest has\nsurged in learning from cheaper data sources, such as unlabeled images. In this\npaper we go a step further and ask if we can do away with real image datasets\nentirely, instead learning from noise processes. We investigate a suite of\nimage generation models that produce images from simple random processes. These\nare then used as training data for a visual representation learner with a\ncontrastive loss. We study two types of noise processes, statistical image\nmodels and deep generative models under different random initializations. Our\nfindings show that it is important for the noise to capture certain structural\nproperties of real data but that good performance can be achieved even with\nprocesses that are far from realistic. We also find that diversity is a key\nproperty to learn good representations. Datasets, models, and code are\navailable at https://mbaradad.github.io/learning_with_noise.",
          "link": "http://arxiv.org/abs/2106.05963",
          "publishedOn": "2021-06-11T01:42:16.014Z",
          "wordCount": 611,
          "title": "Learning to See by Looking at Noise. (arXiv:2106.05963v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2006.11652",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bauer_M/0/1/0/all/0/1\">Martin Bauer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Charon_N/0/1/0/all/0/1\">Nicolas Charon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harms_P/0/1/0/all/0/1\">Philipp Harms</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsieh_H/0/1/0/all/0/1\">Hsi-Wei Hsieh</a>",
          "description": "Surface comparison and matching is a challenging problem in computer vision.\nWhile reparametrization-invariant Sobolev metrics provide meaningful elastic\ndistances and point correspondences via the geodesic boundary value problem,\nsolving this problem numerically tends to be difficult. Square root normal\nfields (SRNF) considerably simplify the computation of certain elastic\ndistances between parametrized surfaces. Yet they leave open the issue of\nfinding optimal reparametrizations, which induce elastic distances between\nunparametrized surfaces. This issue has concentrated much effort in recent\nyears and led to the development of several numerical frameworks. In this\npaper, we take an alternative approach which bypasses the direct estimation of\nreparametrizations: we relax the geodesic boundary constraint using an\nauxiliary parametrization-blind varifold fidelity metric. This reformulation\nhas several notable benefits. By avoiding altogether the need for\nreparametrizations, it provides the flexibility to deal with simplicial meshes\nof arbitrary topologies and sampling patterns. Moreover, the problem lends\nitself to a coarse-to-fine multi-resolution implementation, which makes the\nalgorithm scalable to large meshes. Furthermore, this approach extends readily\nto higher-order feature maps such as square root curvature fields and is also\nable to include surface textures in the matching problem. We demonstrate these\nadvantages on several examples, synthetic and real.",
          "link": "http://arxiv.org/abs/2006.11652",
          "publishedOn": "2021-06-11T01:42:15.987Z",
          "wordCount": 688,
          "title": "A numerical framework for elastic surface matching, comparison, and interpolation. (arXiv:2006.11652v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05682",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Oh_Y/0/1/0/all/0/1\">Youngtaek Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1\">Dong-Jin Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kweon_I/0/1/0/all/0/1\">In So Kweon</a>",
          "description": "The capability of the traditional semi-supervised learning (SSL) methods is\nfar from real-world application since they do not consider (1) class imbalance\nand (2) class distribution mismatch between labeled and unlabeled data. This\npaper addresses such a relatively under-explored problem, imbalanced\nsemi-supervised learning, where heavily biased pseudo-labels can harm the model\nperformance. Interestingly, we find that the semantic pseudo-labels from a\nsimilarity-based classifier in feature space and the traditional pseudo-labels\nfrom the linear classifier show the complementary property. To this end, we\npropose a general pseudo-labeling framework to address the bias motivated by\nthis observation. The key idea is to class-adaptively blend the semantic\npseudo-label to the linear one, depending on the current pseudo-label\ndistribution. Thereby, the increased semantic pseudo-label component suppresses\nthe false positives in the majority classes and vice versa. We term the novel\npseudo-labeling framework for imbalanced SSL as Distribution-Aware\nSemantics-Oriented (DASO) Pseudo-label. Extensive evaluation on CIFAR10/100-LT\nand STL10-LT shows that DASO consistently outperforms both recently proposed\nre-balancing methods for label and pseudo-label. Moreover, we demonstrate that\ntypical SSL algorithms can effectively benefit from unlabeled data with DASO,\nespecially when (1) class imbalance and (2) class distribution mismatch exist\nand even on recent real-world Semi-Aves benchmark.",
          "link": "http://arxiv.org/abs/2106.05682",
          "publishedOn": "2021-06-11T01:42:15.906Z",
          "wordCount": 638,
          "title": "Distribution-Aware Semantics-Oriented Pseudo-label for Imbalanced Semi-Supervised Learning. (arXiv:2106.05682v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05607",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tianyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ng_K/0/1/0/all/0/1\">Kee Siong Ng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Miaomiao Liu</a>",
          "description": "In this paper, we tackle the problem of unsupervised 3D object segmentation\nfrom a point cloud without RGB information. In particular, we propose a\nframework,~{\\bf SPAIR3D}, to model a point cloud as a spatial mixture model and\njointly learn the multiple-object representation and segmentation in 3D via\nVariational Autoencoders (VAE). Inspired by SPAIR, we adopt an\nobject-specification scheme that describes each object's location relative to\nits local voxel grid cell rather than the point cloud as a whole. To model the\nspatial mixture model on point clouds, we derive the~\\emph{Chamfer Likelihood},\nwhich fits naturally into the variational training pipeline. We further design\na new spatially invariant graph neural network to generate a varying number of\n3D points as a decoder within our VAE.~Experimental results demonstrate\nthat~{\\bf SPAIR3D} is capable of detecting and segmenting variable number of\nobjects without appearance information across diverse scenes.",
          "link": "http://arxiv.org/abs/2106.05607",
          "publishedOn": "2021-06-11T01:42:15.889Z",
          "wordCount": 575,
          "title": "Spatially Invariant Unsupervised 3D Object Segmentation with Graph Neural Networks. (arXiv:2106.05607v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05658",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Xu_T/0/1/0/all/0/1\">Tianlin Xu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Acciaio_B/0/1/0/all/0/1\">Beatrice Acciaio</a>",
          "description": "Causal Optimal Transport (COT) results from imposing a temporal causality\nconstraint on classic optimal transport problems, which naturally generates a\nnew concept of distances between distributions on path spaces. The first\napplication of the COT theory for sequential learning was given in Xu et al.\n(2020), where COT-GAN was introduced as an adversarial algorithm to train\nimplicit generative models optimized for producing sequential data. Relying on\nXu et al. (2020), the contribution of the present paper is twofold. First, we\ndevelop a conditional version of COT-GAN suitable for sequence prediction. This\nmeans that the dataset is now used in order to learn how a sequence will evolve\ngiven the observation of its past evolution. Second, we improve on the\nconvergence results by working with modifications of the empirical measures via\na specific type of quantization due to Backhoff et al. (2020). The resulting\nquantized conditional COT-GAN algorithm is illustrated with an application for\nvideo prediction.",
          "link": "http://arxiv.org/abs/2106.05658",
          "publishedOn": "2021-06-11T01:42:15.839Z",
          "wordCount": 585,
          "title": "Quantized Conditional COT-GAN for Video Prediction. (arXiv:2106.05658v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05438",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Alexander H. Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_S/0/1/0/all/0/1\">SouYoung Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_C/0/1/0/all/0/1\">Cheng-I Jeff Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rouditchenko_A/0/1/0/all/0/1\">Andrew Rouditchenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oliva_A/0/1/0/all/0/1\">Aude Oliva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glass_J/0/1/0/all/0/1\">James Glass</a>",
          "description": "Recent advances in representation learning have demonstrated an ability to\nrepresent information from different modalities such as video, text, and audio\nin a single high-level embedding vector. In this work we present a\nself-supervised learning framework that is able to learn a representation that\ncaptures finer levels of granularity across different modalities such as\nconcepts or events represented by visual objects or spoken words. Our framework\nrelies on a discretized embedding space created via vector quantization that is\nshared across different modalities. Beyond the shared embedding space, we\npropose a Cross-Modal Code Matching objective that forces the representations\nfrom different views (modalities) to have a similar distribution over the\ndiscrete embedding space such that cross-modal objects/actions localization can\nbe performed without direct supervision. In our experiments we show that the\nproposed discretized multi-modal fine-grained representation (e.g.,\npixel/word/frame) can complement high-level summary representations (e.g.,\nvideo/sentence/waveform) for improved performance on cross-modal retrieval\ntasks. We also observe that the discretized representation uses individual\nclusters to represent the same semantic concept across modalities.",
          "link": "http://arxiv.org/abs/2106.05438",
          "publishedOn": "2021-06-11T01:42:15.814Z",
          "wordCount": 599,
          "title": "Cross-Modal Discrete Representation Learning. (arXiv:2106.05438v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05350",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Thandiackal_K/0/1/0/all/0/1\">Kevin Thandiackal</a> (1 and 2), <a href=\"http://arxiv.org/find/cs/1/au:+Portenier_T/0/1/0/all/0/1\">Tiziano Portenier</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Giovannini_A/0/1/0/all/0/1\">Andrea Giovannini</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Gabrani_M/0/1/0/all/0/1\">Maria Gabrani</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Goksel_O/0/1/0/all/0/1\">Orcun Goksel</a> (2 and 3) ((1) IBM Research Europe, (2) ETH Zurich, (3) Uppsala University)",
          "description": "Neural networks are prone to catastrophic forgetting when trained\nincrementally on different tasks. In order to prevent forgetting, most existing\nmethods retain a small subset of previously seen samples, which in turn can be\nused for joint training with new tasks. While this is indeed effective, it may\nnot always be possible to store such samples, e.g., due to data protection\nregulations. In these cases, one can instead employ generative models to create\nartificial samples or features representing memories from previous tasks.\nFollowing a similar direction, we propose GenIFeR (Generative Implicit Feature\nReplay) for class-incremental learning. The main idea is to train a generative\nadversarial network (GAN) to generate images that contain realistic features.\nWhile the generator creates images at full resolution, the discriminator only\nsees the corresponding features extracted by the continually trained\nclassifier. Since the classifier compresses raw images into features that are\nactually relevant for classification, the GAN can match this target\ndistribution more accurately. On the other hand, allowing the generator to\ncreate full resolution images has several benefits: In contrast to previous\napproaches, the feature extractor of the classifier does not have to be frozen.\nIn addition, we can employ augmentations on generated images, which not only\nboosts classification performance, but also mitigates discriminator overfitting\nduring GAN training. We empirically show that GenIFeR is superior to both\nconventional generative image and feature replay. In particular, we\nsignificantly outperform the state-of-the-art in generative replay for various\nsettings on the CIFAR-100 and CUB-200 datasets.",
          "link": "http://arxiv.org/abs/2106.05350",
          "publishedOn": "2021-06-11T01:42:15.684Z",
          "wordCount": 702,
          "title": "Match What Matters: Generative Implicit Feature Replay for Continual Learning. (arXiv:2106.05350v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/1906.11667",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kotyan_S/0/1/0/all/0/1\">Shashank Kotyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vargas_D/0/1/0/all/0/1\">Danilo Vasconcellos Vargas</a>",
          "description": "Neural networks are prone to misclassify slightly modified input images.\nRecently, many defences have been proposed, but none have improved the\nrobustness of neural networks consistently. Here, we propose to use adversarial\nattacks as a function evaluation to search for neural architectures that can\nresist such attacks automatically. Experiments on neural architecture search\nalgorithms from the literature show that although accurate, they are not able\nto find robust architectures. A significant reason for this lies in their\nlimited search space. By creating a novel neural architecture search with\noptions for dense layers to connect with convolution layers and vice-versa as\nwell as the addition of concatenation layers in the search, we were able to\nevolve an architecture that is inherently accurate on adversarial samples.\nInterestingly, this inherent robustness of the evolved architecture rivals\nstate-of-the-art defences such as adversarial training while being trained only\non the non-adversarial samples. Moreover, the evolved architecture makes use of\nsome peculiar traits which might be useful for developing even more robust\nones. Thus, the results here confirm that more robust architectures exist as\nwell as opens up a new realm of feasibilities for the development and\nexploration of neural networks.\n\nCode available at this http URL",
          "link": "http://arxiv.org/abs/1906.11667",
          "publishedOn": "2021-06-11T01:42:15.455Z",
          "wordCount": 722,
          "title": "Evolving Robust Neural Architectures to Defend from Adversarial Attacks. (arXiv:1906.11667v3 [cs.NE] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.03404",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Touvron_H/0/1/0/all/0/1\">Hugo Touvron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bojanowski_P/0/1/0/all/0/1\">Piotr Bojanowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caron_M/0/1/0/all/0/1\">Mathilde Caron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cord_M/0/1/0/all/0/1\">Matthieu Cord</a>, <a href=\"http://arxiv.org/find/cs/1/au:+El_Nouby_A/0/1/0/all/0/1\">Alaaeldin El-Nouby</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grave_E/0/1/0/all/0/1\">Edouard Grave</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Izacard_G/0/1/0/all/0/1\">Gautier Izacard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joulin_A/0/1/0/all/0/1\">Armand Joulin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Synnaeve_G/0/1/0/all/0/1\">Gabriel Synnaeve</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verbeek_J/0/1/0/all/0/1\">Jakob Verbeek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jegou_H/0/1/0/all/0/1\">Herv&#xe9; J&#xe9;gou</a>",
          "description": "We present ResMLP, an architecture built entirely upon multi-layer\nperceptrons for image classification. It is a simple residual network that\nalternates (i) a linear layer in which image patches interact, independently\nand identically across channels, and (ii) a two-layer feed-forward network in\nwhich channels interact independently per patch. When trained with a modern\ntraining strategy using heavy data-augmentation and optionally distillation, it\nattains surprisingly good accuracy/complexity trade-offs on ImageNet. We also\ntrain ResMLP models in a self-supervised setup, to further remove priors from\nemploying a labelled dataset. Finally, by adapting our model to machine\ntranslation we achieve surprisingly good results.\n\nWe share pre-trained models and our code based on the Timm library.",
          "link": "http://arxiv.org/abs/2105.03404",
          "publishedOn": "2021-06-11T01:42:15.412Z",
          "wordCount": 589,
          "title": "ResMLP: Feedforward networks for image classification with data-efficient training. (arXiv:2105.03404v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05954",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Spurr_A/0/1/0/all/0/1\">Adrian Spurr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Molchanov_P/0/1/0/all/0/1\">Pavlo Molchanov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iqbal_U/0/1/0/all/0/1\">Umar Iqbal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kautz_J/0/1/0/all/0/1\">Jan Kautz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hilliges_O/0/1/0/all/0/1\">Otmar Hilliges</a>",
          "description": "Hand pose estimation is difficult due to different environmental conditions,\nobject- and self-occlusion as well as diversity in hand shape and appearance.\nExhaustively covering this wide range of factors in fully annotated datasets\nhas remained impractical, posing significant challenges for generalization of\nsupervised methods. Embracing this challenge, we propose to combine ideas from\nadversarial training and motion modelling to tap into unlabeled videos. To this\nend we propose what to the best of our knowledge is the first motion model for\nhands and show that an adversarial formulation leads to better generalization\nproperties of the hand pose estimator via semi-supervised training on unlabeled\nvideo sequences. In this setting, the pose predictor must produce a valid\nsequence of hand poses, as determined by a discriminative adversary. This\nadversary reasons both on the structural as well as temporal domain,\neffectively exploiting the spatio-temporal structure in the task. The main\nadvantage of our approach is that we can make use of unpaired videos and joint\nsequence data both of which are much easier to attain than paired training\ndata. We perform extensive evaluation, investigating essential components\nneeded for the proposed framework and empirically demonstrate in two\nchallenging settings that the proposed approach leads to significant\nimprovements in pose estimation accuracy. In the lowest label setting, we\nattain an improvement of $40\\%$ in absolute mean joint error.",
          "link": "http://arxiv.org/abs/2106.05954",
          "publishedOn": "2021-06-11T01:42:15.406Z",
          "wordCount": 654,
          "title": "Adversarial Motion Modelling helps Semi-supervised Hand Pose Estimation. (arXiv:2106.05954v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2102.10274",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_D/0/1/0/all/0/1\">Deng-Ping Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_G/0/1/0/all/0/1\">Ge-Peng Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_M/0/1/0/all/0/1\">Ming-Ming Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_L/0/1/0/all/0/1\">Ling Shao</a>",
          "description": "We present the first systematic study on concealed object detection (COD),\nwhich aims to identify objects that are \"perfectly\" embedded in their\nbackground. The high intrinsic similarities between the concealed objects and\ntheir background make COD far more challenging than traditional object\ndetection/segmentation. To better understand this task, we collect a\nlarge-scale dataset, called COD10K, which consists of 10,000 images covering\nconcealed objects in diverse real-world scenarios from 78 object categories.\nFurther, we provide rich annotations including object categories, object\nboundaries, challenging attributes, object-level labels, and instance-level\nannotations. Our COD10K is the largest COD dataset to date, with the richest\nannotations, which enables comprehensive concealed object understanding and can\neven be used to help progress several other vision tasks, such as detection,\nsegmentation, classification, etc. Motivated by how animals hunt in the wild,\nwe also design a simple but strong baseline for COD, termed the Search\nIdentification Network (SINet). Without any bells and whistles, SINet\noutperforms 12 cutting-edge baselines on all datasets tested, making them\nrobust, general architectures that could serve as catalysts for future research\nin COD. Finally, we provide some interesting findings and highlight several\npotential applications and future directions. To spark research in this new\nfield, our code, dataset, and online demo are available on our project page:\nthis http URL",
          "link": "http://arxiv.org/abs/2102.10274",
          "publishedOn": "2021-06-11T01:42:15.401Z",
          "wordCount": 674,
          "title": "Concealed Object Detection. (arXiv:2102.10274v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05844",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jadon_S/0/1/0/all/0/1\">Shruti Jadon</a>",
          "description": "Image Segmentation has been an active field of research as it has a wide\nrange of applications, ranging from automated disease detection to self-driving\ncars. In recent years, various research papers proposed different loss\nfunctions used in case of biased data, sparse segmentation, and unbalanced\ndataset. In this paper, we introduce SemSegLoss, a python package consisting of\nsome of the well-known loss functions widely used for image segmentation. It is\ndeveloped with the intent to help researchers in the development of novel loss\nfunctions and perform an extensive set of experiments on model architectures\nfor various applications. The ease-of-use and flexibility of the presented\npackage have allowed reducing the development time and increased evaluation\nstrategies of machine learning models for semantic segmentation. Furthermore,\ndifferent applications that use image segmentation can use SemSegLoss because\nof the generality of its functions. This wide range of applications will lead\nto the development and growth of AI across all industries.",
          "link": "http://arxiv.org/abs/2106.05844",
          "publishedOn": "2021-06-11T01:42:15.316Z",
          "wordCount": 605,
          "title": "SemSegLoss: A python package of loss functions for semantic segmentation. (arXiv:2106.05844v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05531",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Dhondea_A/0/1/0/all/0/1\">Ashiv Dhondea</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cohen_R/0/1/0/all/0/1\">Robert A. Cohen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bajic_I/0/1/0/all/0/1\">Ivan V. Baji&#x107;</a>",
          "description": "In collaborative intelligence, an artificial intelligence (AI) model is\ntypically split between an edge device and the cloud. Feature tensors produced\nby the edge sub-model are sent to the cloud via an imperfect communication\nchannel. At the cloud side, parts of the feature tensor may be missing due to\npacket loss. In this paper we propose a method called Content-Adaptive Linear\nTensor Completion (CALTeC) to recover the missing feature data. The proposed\nmethod is fast, data-adaptive, does not require pre-training, and produces\nbetter results than existing methods for tensor data recovery in collaborative\nintelligence.",
          "link": "http://arxiv.org/abs/2106.05531",
          "publishedOn": "2021-06-11T01:42:15.242Z",
          "wordCount": 544,
          "title": "CALTeC: Content-Adaptive Linear Tensor Completion for Collaborative Intelligence. (arXiv:2106.05531v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05458",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xindi Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Limin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_W/0/1/0/all/0/1\">Wufeng Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yan Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shengfeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yuhao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1\">Shuangping Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shang_N/0/1/0/all/0/1\">Ning Shang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_D/0/1/0/all/0/1\">Dong Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_N/0/1/0/all/0/1\">Ning Gu</a>",
          "description": "The ultrasound (US) screening of the infant hip is vital for the early\ndiagnosis of developmental dysplasia of the hip (DDH). The US diagnosis of DDH\nrefers to measuring alpha and beta angles that quantify hip joint development.\nThese two angles are calculated from key anatomical landmarks and structures of\nthe hip. However, this measurement process is not trivial for sonographers and\nusually requires a thorough understanding of complex anatomical structures. In\nthis study, we propose a multi-task framework to learn the relationships among\nlandmarks and structures jointly and automatically evaluate DDH. Our multi-task\nnetworks are equipped with three novel modules. Firstly, we adopt Mask R-CNN as\nthe basic framework to detect and segment key anatomical structures and add one\nlandmark detection branch to form a new multi-task framework. Secondly, we\npropose a novel shape similarity loss to refine the incomplete anatomical\nstructure prediction robustly and accurately. Thirdly, we further incorporate\nthe landmark-structure consistent prior to ensure the consistency of the bony\nrim estimated from the segmented structure and the detected landmark. In our\nexperiments, 1,231 US images of the infant hip from 632 patients are collected,\nof which 247 images from 126 patients are tested. The average errors in alpha\nand beta angles are 2.221 degrees and 2.899 degrees. About 93% and 85%\nestimates of alpha and beta angles have errors less than 5 degrees,\nrespectively. Experimental results demonstrate that the proposed method can\naccurately and robustly realize the automatic evaluation of DDH, showing great\npotential for clinical application.",
          "link": "http://arxiv.org/abs/2106.05458",
          "publishedOn": "2021-06-11T01:42:15.136Z",
          "wordCount": 733,
          "title": "Joint Landmark and Structure Learning for Automatic Evaluation of Developmental Dysplasia of the Hip. (arXiv:2106.05458v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05436",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fang_M/0/1/0/all/0/1\">Mengyuan Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_L/0/1/0/all/0/1\">Luliang Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kan_Z/0/1/0/all/0/1\">Zihan Kan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xue Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pei_T/0/1/0/all/0/1\">Tao Pei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qingquan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chaokui Li</a>",
          "description": "Origin-Destination (OD) flow, as an abstract representation of the object`s\nmovement or interaction, has been used to reveal the urban mobility and\nhuman-land interaction pattern. As an important spatial analysis approach, the\nclustering methods of point events have been extended to OD flows to identify\nthe dominant trends and spatial structures of urban mobility. However, the\nexisting methods for OD flow cluster-detecting are limited both in specific\nspatial scale and the uncertain result due to different parameters setting,\nwhich is difficult for complicated OD flows clustering under spatial\nheterogeneity. To address these limitations, in this paper, we proposed a novel\nOD flows cluster-detecting method based on the OPTICS algorithm which can\nidentify OD flow clusters with various aggregation scales. The method can\nadaptively determine parameter value from the dataset without prior knowledge\nand artificial intervention. Experiments indicated that our method outperformed\nthree state-of-the-art methods with more accurate and complete of clusters and\nless noise. As a case study, our method is applied to identify the potential\nroutes for public transport service settings by detecting OD flow clusters\nwithin urban travel data.",
          "link": "http://arxiv.org/abs/2106.05436",
          "publishedOn": "2021-06-11T01:42:15.115Z",
          "wordCount": 623,
          "title": "An adaptive Origin-Destination flows cluster-detecting method to identify urban mobility trends. (arXiv:2106.05436v1 [cs.CG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05392",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Patrick_M/0/1/0/all/0/1\">Mandela Patrick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Campbell_D/0/1/0/all/0/1\">Dylan Campbell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asano_Y/0/1/0/all/0/1\">Yuki M. Asano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Metze_I/0/1/0/all/0/1\">Ishan Misra Florian Metze</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feichtenhofer_C/0/1/0/all/0/1\">Christoph Feichtenhofer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vedaldi_A/0/1/0/all/0/1\">Andrea Vedaldi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henriques_J/0/1/0/all/0/1\">Jo\\&#xe3;o F. Henriques</a>",
          "description": "In video transformers, the time dimension is often treated in the same way as\nthe two spatial dimensions. However, in a scene where objects or the camera may\nmove, a physical point imaged at one location in frame $t$ may be entirely\nunrelated to what is found at that location in frame $t+k$. These temporal\ncorrespondences should be modeled to facilitate learning about dynamic scenes.\nTo this end, we propose a new drop-in block for video transformers --\ntrajectory attention -- that aggregates information along implicitly determined\nmotion paths. We additionally propose a new method to address the quadratic\ndependence of computation and memory on the input size, which is particularly\nimportant for high resolution or long videos. While these ideas are useful in a\nrange of settings, we apply them to the specific task of video action\nrecognition with a transformer model and obtain state-of-the-art results on the\nKinetics, Something--Something V2, and Epic-Kitchens datasets. Code and models\nare available at: https://github.com/facebookresearch/Motionformer",
          "link": "http://arxiv.org/abs/2106.05392",
          "publishedOn": "2021-06-11T01:42:15.110Z",
          "wordCount": 616,
          "title": "Keeping Your Eye on the Ball: Trajectory Attention in Video Transformers. (arXiv:2106.05392v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05970",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">Wanrong Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Eric Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_A/0/1/0/all/0/1\">An Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eckstein_M/0/1/0/all/0/1\">Miguel Eckstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>",
          "description": "Automatic evaluations for natural language generation (NLG) conventionally\nrely on token-level or embedding-level comparisons with the text references.\nThis is different from human language processing, for which visual imaginations\noften improve comprehension. In this work, we propose ImaginE, an\nimagination-based automatic evaluation metric for natural language generation.\nWith the help of CLIP and DALL-E, two cross-modal models pre-trained on\nlarge-scale image-text pairs, we automatically generate an image as the\nembodied imagination for the text snippet and compute the imagination\nsimilarity using contextual embeddings. Experiments spanning several text\ngeneration tasks demonstrate that adding imagination with our ImaginE displays\ngreat potential in introducing multi-modal information into NLG evaluation, and\nimproves existing automatic metrics' correlations with human similarity\njudgments in many circumstances.",
          "link": "http://arxiv.org/abs/2106.05970",
          "publishedOn": "2021-06-11T01:42:15.099Z",
          "wordCount": 564,
          "title": "ImaginE: An Imagination-Based Automatic Evaluation Metric for Natural Language Generation. (arXiv:2106.05970v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.05003",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lizhe Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiaohao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1\">Siyu Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_P/0/1/0/all/0/1\">Ping Tan</a>",
          "description": "Modern deep-learning-based lane detection methods are successful in most\nscenarios but struggling for lane lines with complex topologies. In this work,\nwe propose CondLaneNet, a novel top-to-down lane detection framework that\ndetects the lane instances first and then dynamically predicts the line shape\nfor each instance. Aiming to resolve lane instance-level discrimination\nproblem, we introduce a conditional lane detection strategy based on\nconditional convolution and row-wise formulation. Further, we design the\nRecurrent Instance Module(RIM) to overcome the problem of detecting lane lines\nwith complex topologies such as dense lines and fork lines. Benefit from the\nend-to-end pipeline which requires little post-process, our method has\nreal-time efficiency. We extensively evaluate our method on three benchmarks of\nlane detection. Results show that our method achieves state-of-the-art\nperformance on all three benchmark datasets. Moreover, our method has the\ncoexistence of accuracy and efficiency, e.g. a 78.14 F1 score and 220 FPS on\nCULane. Our code is available at\nhttps://github.com/aliyun/conditional-lane-detection.",
          "link": "http://arxiv.org/abs/2105.05003",
          "publishedOn": "2021-06-11T01:42:15.082Z",
          "wordCount": 620,
          "title": "CondLaneNet: a Top-to-down Lane Detection Framework Based on Conditional Convolution. (arXiv:2105.05003v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.12753",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gong_C/0/1/0/all/0/1\">Chengyue Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Dilin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Meng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandra_V/0/1/0/all/0/1\">Vikas Chandra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qiang Liu</a>",
          "description": "Vision transformer has demonstrated promising performance on challenging\ncomputer vision tasks. However, directly training the vision transformers may\nyield unstable and sub-optimal results. Recent works propose to improve the\nperformance of the vision transformers by modifying the transformer structures,\ne.g., incorporating convolution layers. In contrast, we investigate an\northogonal approach to stabilize the vision transformer training without\nmodifying the networks. We observe the instability of the training can be\nattributed to the significant similarity across the extracted patch\nrepresentations. More specifically, for deep vision transformers, the\nself-attention blocks tend to map different patches into similar latent\nrepresentations, yielding information loss and performance degradation. To\nalleviate this problem, in this work, we introduce novel loss functions in\nvision transformer training to explicitly encourage diversity across patch\nrepresentations for more discriminative feature extraction. We empirically show\nthat our proposed techniques stabilize the training and allow us to train wider\nand deeper vision transformers. We further show the diversified features\nsignificantly benefit the downstream tasks in transfer learning. For semantic\nsegmentation, we enhance the state-of-the-art (SOTA) results on Cityscapes and\nADE20k. Our code will be made publicly available soon.",
          "link": "http://arxiv.org/abs/2104.12753",
          "publishedOn": "2021-06-11T01:42:15.034Z",
          "wordCount": 648,
          "title": "Vision Transformers with Patch Diversification. (arXiv:2104.12753v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05923",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bano_S/0/1/0/all/0/1\">Sophia Bano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Casella_A/0/1/0/all/0/1\">Alessandro Casella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasconcelos_F/0/1/0/all/0/1\">Francisco Vasconcelos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moccia_S/0/1/0/all/0/1\">Sara Moccia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Attilakos_G/0/1/0/all/0/1\">George Attilakos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wimalasundera_R/0/1/0/all/0/1\">Ruwan Wimalasundera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+David_A/0/1/0/all/0/1\">Anna L. David</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paladini_D/0/1/0/all/0/1\">Dario Paladini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deprest_J/0/1/0/all/0/1\">Jan Deprest</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mattos_L/0/1/0/all/0/1\">Leonardo S. Mattos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stoyanov_D/0/1/0/all/0/1\">Danail Stoyanov</a>",
          "description": "Fetoscopy laser photocoagulation is a widely used procedure for the treatment\nof Twin-to-Twin Transfusion Syndrome (TTTS), that occur in mono-chorionic\nmultiple pregnancies due to placental vascular anastomoses. This procedure is\nparticularly challenging due to limited field of view, poor manoeuvrability of\nthe fetoscope, poor visibility due to fluid turbidity, variability in light\nsource, and unusual position of the placenta. This may lead to increased\nprocedural time and incomplete ablation, resulting in persistent TTTS.\nComputer-assisted intervention may help overcome these challenges by expanding\nthe fetoscopic field of view through video mosaicking and providing better\nvisualization of the vessel network. However, the research and development in\nthis domain remain limited due to unavailability of high-quality data to encode\nthe intra- and inter-procedure variability. Through the Fetoscopic Placental\nVessel Segmentation and Registration (FetReg) challenge, we present a\nlarge-scale multi-centre dataset for the development of generalized and robust\nsemantic segmentation and video mosaicking algorithms for the fetal environment\nwith a focus on creating drift-free mosaics from long duration fetoscopy\nvideos. In this paper, we provide an overview of the FetReg dataset, challenge\ntasks, evaluation metrics and baseline methods for both segmentation and\nregistration. Baseline methods results on the FetReg dataset shows that our\ndataset poses interesting challenges, which can be modelled and competed for\nthrough our crowd-sourcing initiative of the FetReg challenge.",
          "link": "http://arxiv.org/abs/2106.05923",
          "publishedOn": "2021-06-11T01:42:15.029Z",
          "wordCount": 682,
          "title": "FetReg: Placental Vessel Segmentation and Registration in Fetoscopy Challenge Dataset. (arXiv:2106.05923v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.14711",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Deng_Y/0/1/0/all/0/1\">Yang Deng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_C/0/1/0/all/0/1\">Ce Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hui_Y/0/1/0/all/0/1\">Yuan Hui</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_Q/0/1/0/all/0/1\">Qian Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_J/0/1/0/all/0/1\">Jun Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Luo_S/0/1/0/all/0/1\">Shiwei Luo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sun_M/0/1/0/all/0/1\">Mengke Sun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Quan_Q/0/1/0/all/0/1\">Quan Quan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_S/0/1/0/all/0/1\">Shuxin Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hao_Y/0/1/0/all/0/1\">You Hao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_P/0/1/0/all/0/1\">Pengbo Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xiao_H/0/1/0/all/0/1\">Honghu Xiao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhao_C/0/1/0/all/0/1\">Chunpeng Zhao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_X/0/1/0/all/0/1\">Xinbao Wu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhou_S/0/1/0/all/0/1\">S. Kevin Zhou</a>",
          "description": "Spine-related diseases have high morbidity and cause a huge burden of social\ncost. Spine imaging is an essential tool for noninvasively visualizing and\nassessing spinal pathology. Segmenting vertebrae in computed tomography (CT)\nimages is the basis of quantitative medical image analysis for clinical\ndiagnosis and surgery planning of spine diseases. Current publicly available\nannotated datasets on spinal vertebrae are small in size. Due to the lack of a\nlarge-scale annotated spine image dataset, the mainstream deep learning-based\nsegmentation methods, which are data-driven, are heavily restricted. In this\npaper, we introduce a large-scale spine CT dataset, called CTSpine1K, curated\nfrom multiple sources for vertebra segmentation, which contains 1,005 CT\nvolumes with over 11,100 labeled vertebrae belonging to different spinal\nconditions. Based on this dataset, we conduct several spinal vertebrae\nsegmentation experiments to set the first benchmark. We believe that this\nlarge-scale dataset will facilitate further research in many spine-related\nimage analysis tasks, including but not limited to vertebrae segmentation,\nlabeling, 3D spine reconstruction from biplanar radiographs, image\nsuper-resolution, and enhancement.",
          "link": "http://arxiv.org/abs/2105.14711",
          "publishedOn": "2021-06-11T01:42:15.013Z",
          "wordCount": 653,
          "title": "CTSpine1K: A Large-Scale Dataset for Spinal Vertebrae Segmentation in Computed Tomography. (arXiv:2105.14711v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.05403",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1\">Jinming Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Ke Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1\">Junfeng Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1\">Xiaoming Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1\">Xiaolin Wei</a>",
          "description": "Recently, lane detection has made great progress with the rapid development\nof deep neural networks and autonomous driving. However, there exist three\nmainly problems including characterizing lanes, modeling the structural\nrelationship between scenes and lanes, and supporting more attributes (e.g.,\ninstance and type) of lanes. In this paper, we propose a novel structure guided\nframework to solve these problems simultaneously. In the framework, we first\nintroduce a new lane representation to characterize each instance. Then a\ntopdown vanishing point guided anchoring mechanism is proposed to produce\nintensive anchors, which efficiently capture various lanes. Next, multi-level\nstructural constraints are used to improve the perception of lanes. In the\nprocess, pixel-level perception with binary segmentation is introduced to\npromote features around anchors and restore lane details from bottom up, a\nlane-level relation is put forward to model structures (i.e., parallel) around\nlanes, and an image-level attention is used to adaptively attend different\nregions of the image from the perspective of scenes. With the help of\nstructural guidance, anchors are effectively classified and regressed to obtain\nprecise locations and shapes. Extensive experiments on public benchmark\ndatasets show that the proposed approach outperforms state-of-the-art methods\nwith 117 FPS on a single GPU.",
          "link": "http://arxiv.org/abs/2105.05403",
          "publishedOn": "2021-06-11T01:42:15.001Z",
          "wordCount": 657,
          "title": "Structure Guided Lane Detection. (arXiv:2105.05403v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.10697",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+dAscoli_S/0/1/0/all/0/1\">St&#xe9;phane d&#x27;Ascoli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Touvron_H/0/1/0/all/0/1\">Hugo Touvron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leavitt_M/0/1/0/all/0/1\">Matthew Leavitt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morcos_A/0/1/0/all/0/1\">Ari Morcos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biroli_G/0/1/0/all/0/1\">Giulio Biroli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sagun_L/0/1/0/all/0/1\">Levent Sagun</a>",
          "description": "Convolutional architectures have proven extremely successful for vision\ntasks. Their hard inductive biases enable sample-efficient learning, but come\nat the cost of a potentially lower performance ceiling. Vision Transformers\n(ViTs) rely on more flexible self-attention layers, and have recently\noutperformed CNNs for image classification. However, they require costly\npre-training on large external datasets or distillation from pre-trained\nconvolutional networks. In this paper, we ask the following question: is it\npossible to combine the strengths of these two architectures while avoiding\ntheir respective limitations? To this end, we introduce gated positional\nself-attention (GPSA), a form of positional self-attention which can be\nequipped with a ``soft\" convolutional inductive bias. We initialise the GPSA\nlayers to mimic the locality of convolutional layers, then give each attention\nhead the freedom to escape locality by adjusting a gating parameter regulating\nthe attention paid to position versus content information. The resulting\nconvolutional-like ViT architecture, ConViT, outperforms the DeiT on ImageNet,\nwhile offering a much improved sample efficiency. We further investigate the\nrole of locality in learning by first quantifying how it is encouraged in\nvanilla self-attention layers, then analysing how it is escaped in GPSA layers.\nWe conclude by presenting various ablations to better understand the success of\nthe ConViT. Our code and models are released publicly at\nhttps://github.com/facebookresearch/convit.",
          "link": "http://arxiv.org/abs/2103.10697",
          "publishedOn": "2021-06-11T01:42:14.995Z",
          "wordCount": 691,
          "title": "ConViT: Improving Vision Transformers with Soft Convolutional Inductive Biases. (arXiv:2103.10697v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.11014",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hong_M/0/1/0/all/0/1\">Min-Fong Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hao-Yun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Min-Hung Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yu-Syuan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuo_H/0/1/0/all/0/1\">Hsien-Kai Kuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsai_Y/0/1/0/all/0/1\">Yi-Min Tsai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hung-Jen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jou_K/0/1/0/all/0/1\">Kevin Jou</a>",
          "description": "Network spaces have been known as a critical factor in both handcrafted\nnetwork designs or defining search spaces for Neural Architecture Search (NAS).\nHowever, an effective space involves tremendous prior knowledge and/or manual\neffort, and additional constraints are required to discover efficiency-aware\narchitectures. In this paper, we define a new problem, Network Space Search\n(NSS), as searching for favorable network spaces instead of a single\narchitecture. We propose an NSS method to directly search for efficient-aware\nnetwork spaces automatically, reducing the manual effort and immense cost in\ndiscovering satisfactory ones. The resultant network spaces, named Elite\nSpaces, are discovered from Expanded Search Space with minimal human expertise\nimposed. The Pareto-efficient Elite Spaces are aligned with the Pareto front\nunder various complexity constraints and can be further served as NAS search\nspaces, benefiting differentiable NAS approaches (e.g. In CIFAR-100, an\naveragely 2.3% lower error rate and 3.7% closer to target constraint than the\nbaseline with around 90% fewer samples required to find satisfactory networks).\nMoreover, our NSS approach is capable of searching for superior spaces in\nfuture unexplored spaces, revealing great potential in searching for network\nspaces automatically.",
          "link": "http://arxiv.org/abs/2104.11014",
          "publishedOn": "2021-06-11T01:42:14.989Z",
          "wordCount": 668,
          "title": "Network Space Search for Pareto-Efficient Spaces. (arXiv:2104.11014v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.01601",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tolstikhin_I/0/1/0/all/0/1\">Ilya Tolstikhin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Houlsby_N/0/1/0/all/0/1\">Neil Houlsby</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolesnikov_A/0/1/0/all/0/1\">Alexander Kolesnikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beyer_L/0/1/0/all/0/1\">Lucas Beyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_X/0/1/0/all/0/1\">Xiaohua Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Unterthiner_T/0/1/0/all/0/1\">Thomas Unterthiner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yung_J/0/1/0/all/0/1\">Jessica Yung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steiner_A/0/1/0/all/0/1\">Andreas Steiner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keysers_D/0/1/0/all/0/1\">Daniel Keysers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uszkoreit_J/0/1/0/all/0/1\">Jakob Uszkoreit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lucic_M/0/1/0/all/0/1\">Mario Lucic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dosovitskiy_A/0/1/0/all/0/1\">Alexey Dosovitskiy</a>",
          "description": "Convolutional Neural Networks (CNNs) are the go-to model for computer vision.\nRecently, attention-based networks, such as the Vision Transformer, have also\nbecome popular. In this paper we show that while convolutions and attention are\nboth sufficient for good performance, neither of them are necessary. We present\nMLP-Mixer, an architecture based exclusively on multi-layer perceptrons (MLPs).\nMLP-Mixer contains two types of layers: one with MLPs applied independently to\nimage patches (i.e. \"mixing\" the per-location features), and one with MLPs\napplied across patches (i.e. \"mixing\" spatial information). When trained on\nlarge datasets, or with modern regularization schemes, MLP-Mixer attains\ncompetitive scores on image classification benchmarks, with pre-training and\ninference cost comparable to state-of-the-art models. We hope that these\nresults spark further research beyond the realms of well established CNNs and\nTransformers.",
          "link": "http://arxiv.org/abs/2105.01601",
          "publishedOn": "2021-06-11T01:42:14.969Z",
          "wordCount": 641,
          "title": "MLP-Mixer: An all-MLP Architecture for Vision. (arXiv:2105.01601v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.04584",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_D/0/1/0/all/0/1\">Dazhen Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yihong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shu_X/0/1/0/all/0/1\">Xinhuan Shu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jiang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1\">Mengye Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_S/0/1/0/all/0/1\">Siwei Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_W/0/1/0/all/0/1\">Weiwei Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yingcai Wu</a>",
          "description": "Images in visualization publications contain rich information, e.g., novel\nvisualization designs and common combinations of visualizations. A systematic\ncollection of these images can contribute to the community in many aspects,\nsuch as literature analysis and automated tasks for visualization. In this\npaper, we build and make public a dataset, VisImages, which collects 12,267\nimages with captions from 1,397 papers in IEEE InfoVis and VAST. Based on a\nrefined taxonomy for visualizations in publications, the dataset includes\n35,096 annotated visualizations, as well as their positions. We demonstrate the\nusefulness of VisImages through three use cases: 1) exploring and analyzing the\nevolution of visualizations with VisImages Explorer, 2) training and\nbenchmarking models for visualization classification, and 3) localizing and\nrecognizing visualizations in the images automatically.",
          "link": "http://arxiv.org/abs/2007.04584",
          "publishedOn": "2021-06-11T01:42:14.964Z",
          "wordCount": 613,
          "title": "VisImages: a Corpus of Visualizations in the Images of Visualization Publications. (arXiv:2007.04584v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.03310",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ciszewski_M/0/1/0/all/0/1\">Micha&#x142; Ciszewski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sohl_J/0/1/0/all/0/1\">Jakob S&#xf6;hl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jongbloed_G/0/1/0/all/0/1\">Geurt Jongbloed</a>",
          "description": "The past decade has seen an increased interest in human activity recognition.\nMost commonly, the raw data coming from sensors attached to body parts are\nunannotated, which creates a need for fast labelling method. Part of the\nprocedure is choosing or designing an appropriate performance measure. We\npropose a new performance measure, the Locally Time-Shifted Measure, which\naddresses the issue of timing uncertainty of state transitions in the\nclassification result. Our main contribution is a novel post-processing method\nfor binary activity recognition. It improves the accuracy of the classification\nmethods, by correcting for unrealistically short activities in the estimate.",
          "link": "http://arxiv.org/abs/2102.03310",
          "publishedOn": "2021-06-11T01:42:14.958Z",
          "wordCount": 561,
          "title": "Improving state estimation through projection post-processing for activity recognition in football. (arXiv:2102.03310v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1811.11606",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Henzler_P/0/1/0/all/0/1\">Philipp Henzler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitra_N/0/1/0/all/0/1\">Niloy Mitra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ritschel_T/0/1/0/all/0/1\">Tobias Ritschel</a>",
          "description": "We introduce PlatonicGAN to discover the 3D structure of an object class from\nan unstructured collection of 2D images, i.e., where no relation between photos\nis known, except that they are showing instances of the same category. The key\nidea is to train a deep neural network to generate 3D shapes which, when\nrendered to images, are indistinguishable from ground truth images (for a\ndiscriminator) under various camera poses. Discriminating 2D images instead of\n3D shapes allows tapping into unstructured 2D photo collections instead of\nrelying on curated (e.g., aligned, annotated, etc.) 3D data sets. To establish\nconstraints between 2D image observation and their 3D interpretation, we\nsuggest a family of rendering layers that are effectively differentiable. This\nfamily includes visual hull, absorption-only (akin to x-ray), and\nemission-absorption. We can successfully reconstruct 3D shapes from\nunstructured 2D images and extensively evaluate PlatonicGAN on a range of\nsynthetic and real data sets achieving consistent improvements over baseline\nmethods. We further show that PlatonicGAN can be combined with 3D supervision\nto improve on and in some cases even surpass the quality of 3D-supervised\nmethods.",
          "link": "http://arxiv.org/abs/1811.11606",
          "publishedOn": "2021-06-11T01:42:14.952Z",
          "wordCount": 660,
          "title": "Escaping Plato's Cave: 3D Shape From Adversarial Rendering. (arXiv:1811.11606v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.06847",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pang_G/0/1/0/all/0/1\">Guansong Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hengel_A/0/1/0/all/0/1\">Anton van den Hengel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1\">Chunhua Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_L/0/1/0/all/0/1\">Longbing Cao</a>",
          "description": "We consider the problem of anomaly detection with a small set of partially\nlabeled anomaly examples and a large-scale unlabeled dataset. This is a common\nscenario in many important applications. Existing related methods either\nexclusively fit the limited anomaly examples that typically do not span the\nentire set of anomalies, or proceed with unsupervised learning from the\nunlabeled data. We propose here instead a deep reinforcement learning-based\napproach that enables an end-to-end optimization of the detection of both\nlabeled and unlabeled anomalies. This approach learns the known abnormality by\nautomatically interacting with an anomaly-biased simulation environment, while\ncontinuously extending the learned abnormality to novel classes of anomaly\n(i.e., unknown anomalies) by actively exploring possible anomalies in the\nunlabeled data. This is achieved by jointly optimizing the exploitation of the\nsmall labeled anomaly data and the exploration of the rare unlabeled anomalies.\nExtensive experiments on 48 real-world datasets show that our model\nsignificantly outperforms five state-of-the-art competing methods.",
          "link": "http://arxiv.org/abs/2009.06847",
          "publishedOn": "2021-06-11T01:42:14.946Z",
          "wordCount": 650,
          "title": "Toward Deep Supervised Anomaly Detection: Reinforcement Learning from Partially Labeled Anomaly Data. (arXiv:2009.06847v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.03931",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Fu_X/0/1/0/all/0/1\">Xiaohang Fu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bi_L/0/1/0/all/0/1\">Lei Bi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kumar_A/0/1/0/all/0/1\">Ashnil Kumar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fulham_M/0/1/0/all/0/1\">Michael Fulham</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kim_J/0/1/0/all/0/1\">Jinman Kim</a>",
          "description": "Accurate characterisation of visual attributes such as spiculation,\nlobulation, and calcification of lung nodules is critical in cancer management.\nThe characterisation of these attributes is often subjective, which may lead to\nhigh inter- and intra-observer variability. Furthermore, lung nodules are often\nheterogeneous in the cross-sectional image slices of a 3D volume. Current\nstate-of-the-art methods that score multiple attributes rely on deep\nlearning-based multi-task learning (MTL) schemes. These methods, however,\nextract shared visual features across attributes and then examine each\nattribute without explicitly leveraging their inherent intercorrelations.\nFurthermore, current methods either treat each slice with equal importance\nwithout considering their relevance or heterogeneity, which limits performance.\nIn this study, we address these challenges with a new convolutional neural\nnetwork (CNN)-based MTL model that incorporates multiple attention-based\nlearning modules to simultaneously score 9 visual attributes of lung nodules in\ncomputed tomography (CT) image volumes. Our model processes entire nodule\nvolumes of arbitrary depth and uses a slice attention module to filter out\nirrelevant slices. We also introduce cross-attribute and attribute\nspecialisation attention modules that learn an optimal amalgamation of\nmeaningful representations to leverage relationships between attributes. We\ndemonstrate that our model outperforms previous state-of-the-art methods at\nscoring attributes using the well-known public LIDC-IDRI dataset of pulmonary\nnodules from over 1,000 patients. Our model also performs competitively when\nrepurposed for benign-malignant classification. Our attention modules also\nprovide easy-to-interpret weights that offer insights into the predictions of\nthe model.",
          "link": "http://arxiv.org/abs/2103.03931",
          "publishedOn": "2021-06-11T01:42:14.928Z",
          "wordCount": 700,
          "title": "Attention-Enhanced Cross-Task Network for Analysing Multiple Attributes of Lung Nodules in CT. (arXiv:2103.03931v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03686",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Thanthrige_U/0/1/0/all/0/1\">Udaya S.K.P. Miriya Thanthrige</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jung_P/0/1/0/all/0/1\">Peter Jung</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sezgin_A/0/1/0/all/0/1\">Aydin Sezgin</a>",
          "description": "We address the detection of material defects, which are inside a layered\nmaterial structure using compressive sensing based multiple-output (MIMO)\nwireless radar. Here, the strong clutter due to the reflection of the layered\nstructure's surface often makes the detection of the defects challenging. Thus,\nsophisticated signal separation methods are required for improved defect\ndetection. In many scenarios, the number of defects that we are interested in\nis limited and the signaling response of the layered structure can be modeled\nas a low-rank structure. Therefore, we propose joint rank and sparsity\nminimization for defect detection. In particular, we propose a non-convex\napproach based on the iteratively reweighted nuclear and $\\ell_1-$norm (a\ndouble-reweighted approach) to obtain a higher accuracy compared to the\nconventional nuclear norm and $\\ell_1-$norm minimization. To this end, an\niterative algorithm is designed to estimate the low-rank and sparse\ncontributions. Further, we propose deep learning to learn the parameters of the\nalgorithm (i.e., algorithm unfolding) to improve the accuracy and the speed of\nconvergence of the algorithm. Our numerical results show that the proposed\napproach outperforms the conventional approaches in terms of mean square errors\nof the recovered low-rank and sparse components and the speed of convergence.",
          "link": "http://arxiv.org/abs/2106.03686",
          "publishedOn": "2021-06-11T01:42:14.922Z",
          "wordCount": 656,
          "title": "Deep Unfolding of Iteratively Reweighted ADMM for Wireless RF Sensing. (arXiv:2106.03686v1 [eess.SP] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.14535",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sukthanker_R/0/1/0/all/0/1\">Rhea Sanjay Sukthanker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhiwu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Suryansh Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Endsjo_E/0/1/0/all/0/1\">Erik Goron Endsjo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1\">Luc Van Gool</a>",
          "description": "In this paper, we propose a new neural architecture search (NAS) problem of\nSymmetric Positive Definite (SPD) manifold networks, aiming to automate the\ndesign of SPD neural architectures. To address this problem, we first introduce\na geometrically rich and diverse SPD neural architecture search space for an\nefficient SPD cell design. Further, we model our new NAS problem with a\none-shot training process of a single supernet. Based on the supernet modeling,\nwe exploit a differentiable NAS algorithm on our relaxed continuous search\nspace for SPD neural architecture search. Statistical evaluation of our method\non drone, action, and emotion recognition tasks mostly provides better results\nthan the state-of-the-art SPD networks and traditional NAS algorithms.\nEmpirical results show that our algorithm excels in discovering better\nperforming SPD network design and provides models that are more than three\ntimes lighter than searched by the state-of-the-art NAS algorithms.",
          "link": "http://arxiv.org/abs/2010.14535",
          "publishedOn": "2021-06-11T01:42:14.884Z",
          "wordCount": 637,
          "title": "Neural Architecture Search of SPD Manifold Networks. (arXiv:2010.14535v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.10803",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sangho Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chung_J/0/1/0/all/0/1\">Jiwan Chung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Youngjae Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1\">Gunhee Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Breuel_T/0/1/0/all/0/1\">Thomas Breuel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chechik_G/0/1/0/all/0/1\">Gal Chechik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yale Song</a>",
          "description": "Large-scale datasets are the cornerstone of representation learning. Existing\nself-supervised approaches extract learning signals by making certain\nassumptions about the data, e.g., spatio-temporal continuity and multimodal\ncorrespondence. However, finding large amounts of data that satisfy such\nassumptions is not straightforward, and this restricts the community to rely on\ndatasets collected through laborious annotation and/or manual filtering\nprocesses. In this paper, we propose a subset optimization approach for\nautomatic dataset curation. Focusing on audio-visual representation learning,\nwe find a subset that provides the maximum mutual information between audio and\nvisual channels in videos. We show that self-supervised models trained on our\ndata, despite being automatically constructed, achieve competitive downstream\nperformances compared to existing datasets that require annotation and/or\nmanual filtering. The most significant benefit of our approach is scalability.\nWe release a dataset of 100M videos with high audio-visual correspondence.",
          "link": "http://arxiv.org/abs/2101.10803",
          "publishedOn": "2021-06-11T01:42:14.874Z",
          "wordCount": 607,
          "title": "Automatic Curation of Large-Scale Datasets for Audio-Visual Representation Learning. (arXiv:2101.10803v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.08435",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Youwei Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1\">Dong Huang</a>",
          "description": "Since the Lipschitz properties of CNN are widely considered to be related to\nadversarial robustness, we theoretically characterize the $\\ell_1$ norm and\n$\\ell_\\infty$ norm of 2D multi-channel convolutional layers and provide\nefficient methods to compute the exact $\\ell_1$ norm and $\\ell_\\infty$ norm.\nBased on our theorem, we propose a novel regularization method termed norm\ndecay, which can effectively reduce the norms of convolutional layers and\nfully-connected layers. Experiments show that norm-regularization methods,\nincluding norm decay, weight decay, and singular value clipping, can improve\ngeneralization of CNNs. However, they can slightly hurt adversarial robustness.\nObserving this unexpected phenomenon, we compute the norms of layers in the\nCNNs trained with three different adversarial training frameworks and\nsurprisingly find that adversarially robust CNNs have comparable or even larger\nlayer norms than their non-adversarially robust counterparts. Furthermore, we\nprove that under a mild assumption, adversarially robust classifiers can be\nachieved, and can have an arbitrarily large Lipschitz constant. For this\nreason, enforcing small norms on CNN layers may be neither necessary nor\neffective in achieving adversarial robustness. The code is available at\nhttps://github.com/youweiliang/norm_robustness.",
          "link": "http://arxiv.org/abs/2009.08435",
          "publishedOn": "2021-06-11T01:42:14.868Z",
          "wordCount": 683,
          "title": "Large Norms of CNN Layers Do Not Hurt Adversarial Robustness. (arXiv:2009.08435v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2003.09671",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Geiger_B/0/1/0/all/0/1\">Bernhard C. Geiger</a>",
          "description": "We review the current literature concerned with information plane analyses of\nneural network classifiers. While the underlying information bottleneck theory\nand the claim that information-theoretic compression is causally linked to\ngeneralization are plausible, empirical evidence was found to be both\nsupporting and conflicting. We review this evidence together with a detailed\nanalysis of how the respective information quantities were estimated. Our\nsurvey suggests that compression visualized in information planes is not\nnecessarily information-theoretic, but is rather often compatible with\ngeometric compression of the latent representations. This insight gives the\ninformation plane a renewed justification.\n\nAside from this, we shed light on the problem of estimating mutual\ninformation in deterministic neural networks and its consequences.\nSpecifically, we argue that even in feed-forward neural networks the data\nprocessing inequality need not hold for estimates of mutual information.\nSimilarly, while a fitting phase, in which the mutual information between the\nlatent representation and the target increases, is necessary (but not\nsufficient) for good classification performance, depending on the specifics of\nmutual information estimation such a fitting phase need not be visible in the\ninformation plane.",
          "link": "http://arxiv.org/abs/2003.09671",
          "publishedOn": "2021-06-11T01:42:14.852Z",
          "wordCount": 682,
          "title": "On Information Plane Analyses of Neural Network Classifiers -- A Review. (arXiv:2003.09671v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.09753",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yi-Si Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xi-Le Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_T/0/1/0/all/0/1\">Tai-Xiang Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yu-Bang Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1\">Yi Chang</a>",
          "description": "Recently, convolutional neural network (CNN)-based methods are proposed for\nhyperspectral images (HSIs) denoising. Among them, unsupervised methods such as\nthe deep image prior (DIP) have received much attention because these methods\ndo not require any training data. However, DIP suffers from the\nsemi-convergence behavior, i.e., the iteration of DIP needs to terminate by\nreferring to the ground-truth image at the optimal iteration point. In this\npaper, we propose the spatial-spectral constrained deep image prior (S2DIP) for\nHSI mixed noise removal. Specifically, we incorporate DIP with a\nspatial-spectral total variation (SSTV) term to fully preserve the\nspatial-spectral local smoothness of the HSI and an $\\ell_1$-norm term to\ncapture the complex sparse noise. The proposed S2DIP jointly leverages the\nexpressive power brought from the deep CNN without any training data and\nexploits the HSI and noise structures via hand-crafted priors. Thus, our method\navoids the semi-convergence behavior, showing higher stabilities than DIP.\nMeanwhile, our method largely enhances the HSI denoising ability of DIP. To\ntackle the proposed denoising model, we develop an alternating direction\nmultiplier method algorithm. Extensive experiments demonstrate that the\nproposed S2DIP outperforms optimization-based and supervised CNN-based\nstate-of-the-art HSI denoising methods.",
          "link": "http://arxiv.org/abs/2008.09753",
          "publishedOn": "2021-06-11T01:42:14.839Z",
          "wordCount": 657,
          "title": "Unsupervised Hyperspectral Mixed Noise Removal Via Spatial-Spectral Constrained Deep Image Prior. (arXiv:2008.09753v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.03240",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Murphy_K/0/1/0/all/0/1\">Kieran A. Murphy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jampani_V/0/1/0/all/0/1\">Varun Jampani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramalingam_S/0/1/0/all/0/1\">Srikumar Ramalingam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Makadia_A/0/1/0/all/0/1\">Ameesh Makadia</a>",
          "description": "Representational learning forms the backbone of most deep learning\napplications, and the value of a learned representation is intimately tied to\nits information content regarding different factors of variation. Finding good\nrepresentations depends on the nature of supervision and the learning\nalgorithm. We propose a novel algorithm that relies on a weak form of\nsupervision where the data is partitioned into sets according to certain\ninactive factors of variation. Our key insight is that by seeking approximate\ncorrespondence between elements of different sets, we learn strong\nrepresentations that exclude the inactive factors of variation and isolate the\nactive factors which vary within all sets. We demonstrate that the method can\nwork in a semi-supervised scenario, and that a portion of the unsupervised data\ncan belong to a different domain entirely. Further control over the content of\nthe learned representations is possible by folding in data augmentation to\nsuppress nuisance factors. We outperform competing baselines on the challenging\nproblem of synthetic-to-real object pose transfer.",
          "link": "http://arxiv.org/abs/2103.03240",
          "publishedOn": "2021-06-11T01:42:14.833Z",
          "wordCount": 628,
          "title": "Learn your ABCs: Approximate Bijective Correspondence for isolating factors of variation. (arXiv:2103.03240v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.01385",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1\">Litao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qiang Wu</a>",
          "description": "Generating natural sentences from images is a fundamental learning task for\nvisual-semantic understanding in multimedia. In this paper, we propose to apply\ndual attention on pyramid image feature maps to fully explore the\nvisual-semantic correlations and improve the quality of generated sentences.\nSpecifically, with the full consideration of the contextual information\nprovided by the hidden state of the RNN controller, the pyramid attention can\nbetter localize the visually indicative and semantically consistent regions in\nimages. On the other hand, the contextual information can help re-calibrate the\nimportance of feature components by learning the channel-wise dependencies, to\nimprove the discriminative power of visual features for better content\ndescription. We conducted comprehensive experiments on three well-known\ndatasets: Flickr8K, Flickr30K and MS COCO, which achieved impressive results in\ngenerating descriptive and smooth natural sentences from images. Using either\nconvolution visual features or more informative bottom-up attention features,\nour composite captioning model achieves very promising performance in a\nsingle-model mode. The proposed pyramid attention and dual attention methods\nare highly modular, which can be inserted into various image captioning modules\nto further improve the performance.",
          "link": "http://arxiv.org/abs/2011.01385",
          "publishedOn": "2021-06-11T01:42:14.826Z",
          "wordCount": 648,
          "title": "Dual Attention on Pyramid Feature Maps for Image Captioning. (arXiv:2011.01385v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05946",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Becker_S/0/1/0/all/0/1\">S&#xf6;ren Becker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wiegand_T/0/1/0/all/0/1\">Thomas Wiegand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bosse_S/0/1/0/all/0/1\">Sebastian Bosse</a>",
          "description": "The performance of visual quality prediction models is commonly assumed to be\nclosely tied to their ability to capture perceptually relevant image aspects.\nModels are thus either based on sophisticated feature extractors carefully\ndesigned from extensive domain knowledge or optimized through feature learning.\nIn contrast to this, we find feature extractors constructed from random noise\nto be sufficient to learn a linear regression model whose quality predictions\nreach high correlations with human visual quality ratings, on par with a model\nwith learned features. We analyze this curious result and show that besides the\nquality of feature extractors also their quantity plays a crucial role - with\ntop performances only being achieved in highly overparameterized models.",
          "link": "http://arxiv.org/abs/2106.05946",
          "publishedOn": "2021-06-11T01:42:14.820Z",
          "wordCount": 548,
          "title": "Curiously Effective Features for Image Quality Prediction. (arXiv:2106.05946v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05915",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kamal_U/0/1/0/all/0/1\">Uday Kamal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zunaed_M/0/1/0/all/0/1\">Mohammad Zunaed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nizam_N/0/1/0/all/0/1\">Nusrat Binta Nizam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasan_T/0/1/0/all/0/1\">Taufiq Hasan</a>",
          "description": "Thoracic disease detection from chest radiographs using deep learning methods\nhas been an active area of research in the last decade. Most previous methods\nattempt to focus on the diseased organs of the image by identifying spatial\nregions responsible for significant contributions to the model's prediction. In\ncontrast, expert radiologists first locate the prominent anatomical structures\nbefore determining if those regions are anomalous. Therefore, integrating\nanatomical knowledge within deep learning models could bring substantial\nimprovement in automatic disease classification. This work proposes an\nanatomy-aware attention-based architecture named Anatomy X-Net, that\nprioritizes the spatial features guided by the pre-identified anatomy regions.\nWe leverage a semi-supervised learning method using the JSRT dataset containing\norgan-level annotation to obtain the anatomical segmentation masks (for lungs\nand heart) for the NIH and CheXpert datasets. The proposed Anatomy X-Net uses\nthe pre-trained DenseNet-121 as the backbone network with two corresponding\nstructured modules, the Anatomy Aware Attention (AAA) and Probabilistic\nWeighted Average Pooling (PWAP), in a cohesive framework for anatomical\nattention learning. Our proposed method sets new state-of-the-art performance\non the official NIH test set with an AUC score of 0.8439, proving the efficacy\nof utilizing the anatomy segmentation knowledge to improve the thoracic disease\nclassification. Furthermore, the Anatomy X-Net yields an averaged AUC of 0.9020\non the Stanford CheXpert dataset, improving on existing methods that\ndemonstrate the generalizability of the proposed framework.",
          "link": "http://arxiv.org/abs/2106.05915",
          "publishedOn": "2021-06-11T01:42:14.802Z",
          "wordCount": 670,
          "title": "Anatomy X-Net: A Semi-Supervised Anatomy Aware Convolutional Neural Network for Thoracic Disease Classification. (arXiv:2106.05915v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2008.03718",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jeong-Kyun Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baik_Y/0/1/0/all/0/1\">Young-Ki Baik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_H/0/1/0/all/0/1\">Hankyu Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1\">Kang Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1\">Duck Hoon Kim</a>",
          "description": "Solving Perspective-n-Point (PnP) problems is a traditional way of estimating\nobject poses. Given outlier-contaminated data, a pose of an object is\ncalculated with PnP algorithms of n = {3, 4} in the RANSAC-based scheme.\nHowever, the computational complexity considerably increases along with n and\nthe high complexity imposes a severe strain on devices which should estimate\nmultiple object poses in real time. In this paper, we propose an efficient\nmethod based on 1-point RANSAC for estimating a pose of an object on the\nground. In the proposed method, a pose is calculated with 1-DoF\nparameterization by using a ground object assumption and a 2D object bounding\nbox as an additional observation, thereby achieving the fastest performance\namong the RANSAC-based methods. In addition, since the method suffers from the\nerrors of the additional information, we propose a hierarchical robust\nestimation method for polishing a rough pose estimate and discovering more\ninliers in a coarse-to-fine manner. The experiments in synthetic and real-world\ndatasets demonstrate the superiority of the proposed method.",
          "link": "http://arxiv.org/abs/2008.03718",
          "publishedOn": "2021-06-11T01:42:14.795Z",
          "wordCount": 645,
          "title": "1-Point RANSAC-Based Method for Ground Object Pose Estimation. (arXiv:2008.03718v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.03841",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Massiceti_D/0/1/0/all/0/1\">Daniela Massiceti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zintgraf_L/0/1/0/all/0/1\">Luisa Zintgraf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bronskill_J/0/1/0/all/0/1\">John Bronskill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Theodorou_L/0/1/0/all/0/1\">Lida Theodorou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harris_M/0/1/0/all/0/1\">Matthew Tobias Harris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cutrell_E/0/1/0/all/0/1\">Edward Cutrell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morrison_C/0/1/0/all/0/1\">Cecily Morrison</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hofmann_K/0/1/0/all/0/1\">Katja Hofmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stumpf_S/0/1/0/all/0/1\">Simone Stumpf</a>",
          "description": "Object recognition has made great advances in the last decade, but\npredominately still relies on many high-quality training examples per object\ncategory. In contrast, learning new objects from only a few examples could\nenable many impactful applications from robotics to user personalization. Most\nfew-shot learning research, however, has been driven by benchmark datasets that\nlack the high variation that these applications will face when deployed in the\nreal-world. To close this gap, we present the ORBIT dataset and benchmark,\ngrounded in a real-world application of teachable object recognizers for people\nwho are blind/low-vision. The dataset contains 3,822 videos of 486 objects\nrecorded by people who are blind/low-vision on their mobile phones, and the\nbenchmark reflects a realistic, highly challenging recognition problem,\nproviding a rich playground to drive research in robustness to few-shot,\nhigh-variation conditions. We set the first state-of-the-art on the benchmark\nand show that there is massive scope for further innovation, holding the\npotential to impact a broad range of real-world vision applications including\ntools for the blind/low-vision community. The dataset is available at\nhttps://bit.ly/2OyElCj and the code to run the benchmark at\nhttps://bit.ly/39YgiUW.",
          "link": "http://arxiv.org/abs/2104.03841",
          "publishedOn": "2021-06-11T01:42:14.788Z",
          "wordCount": 673,
          "title": "ORBIT: A Real-World Few-Shot Dataset for Teachable Object Recognition. (arXiv:2104.03841v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1908.06401",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shah_S/0/1/0/all/0/1\">Sahil Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_N/0/1/0/all/0/1\">Naman Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Abhishek Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1\">Arjun Jain</a>",
          "description": "This paper provides a comprehensive and exhaustive study of adversarial\nattacks on human pose estimation models and the evaluation of their robustness.\nBesides highlighting the important differences between well-studied\nclassification and human pose-estimation systems w.r.t. adversarial attacks, we\nalso provide deep insights into the design choices of pose-estimation systems\nto shape future work. We benchmark the robustness of several 2D single person\npose-estimation architectures trained on multiple datasets, MPII and COCO. In\ndoing so, we also explore the problem of attacking non-classification networks\nincluding regression based networks, which has been virtually unexplored in the\npast.\n\n\\par We find that compared to classification and semantic segmentation, human\npose estimation architectures are relatively robust to adversarial attacks with\nthe single-step attacks being surprisingly ineffective. Our study shows that\nthe heatmap-based pose-estimation models are notably robust than their direct\nregression-based systems and that the systems which explicitly model\nanthropomorphic semantics of human body fare better than their other\ncounterparts. Besides, targeted attacks are more difficult to obtain than\nun-targeted ones and some body-joints are easier to fool than the others. We\npresent visualizations of universal perturbations to facilitate unprecedented\ninsights into their workings on pose-estimation. Additionally, we show them to\ngeneralize well across different networks. Finally we perform a user study\nabout perceptibility of these examples.",
          "link": "http://arxiv.org/abs/1908.06401",
          "publishedOn": "2021-06-11T01:42:14.782Z",
          "wordCount": 672,
          "title": "On the Robustness of Human Pose Estimation. (arXiv:1908.06401v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05966",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jimuyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ohn_Bar_E/0/1/0/all/0/1\">Eshed Ohn-Bar</a>",
          "description": "When in a new situation or geographical location, human drivers have an\nextraordinary ability to watch others and learn maneuvers that they themselves\nmay have never performed. In contrast, existing techniques for learning to\ndrive preclude such a possibility as they assume direct access to an\ninstrumented ego-vehicle with fully known observations and expert driver\nactions. However, such measurements cannot be directly accessed for the non-ego\nvehicles when learning by watching others. Therefore, in an application where\ndata is regarded as a highly valuable asset, current approaches completely\ndiscard the vast portion of the training data that can be potentially obtained\nthrough indirect observation of surrounding vehicles. Motivated by this key\ninsight, we propose the Learning by Watching (LbW) framework which enables\nlearning a driving policy without requiring full knowledge of neither the state\nnor expert actions. To increase its data, i.e., with new perspectives and\nmaneuvers, LbW makes use of the demonstrations of other vehicles in a given\nscene by (1) transforming the ego-vehicle's observations to their points of\nview, and (2) inferring their expert actions. Our LbW agent learns more robust\ndriving policies while enabling data-efficient learning, including quick\nadaptation of the policy to rare and novel scenarios. In particular, LbW drives\nrobustly even with a fraction of available driving data required by existing\nmethods, achieving an average success rate of 92% on the original CARLA\nbenchmark with only 30 minutes of total driving data and 82% with only 10\nminutes.",
          "link": "http://arxiv.org/abs/2106.05966",
          "publishedOn": "2021-06-11T01:42:14.772Z",
          "wordCount": 673,
          "title": "Learning by Watching. (arXiv:2106.05966v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05920",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tianwei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yuanzhi Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_L/0/1/0/all/0/1\">Lianwen Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_D/0/1/0/all/0/1\">Dezhi Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhe Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_M/0/1/0/all/0/1\">Mengchao He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yongpan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_C/0/1/0/all/0/1\">Canjie Luo</a>",
          "description": "Text recognition is a popular research subject with many associated\nchallenges. Despite the considerable progress made in recent years, the text\nrecognition task itself is still constrained to solve the problem of reading\ncropped line text images and serves as a subtask of optical character\nrecognition (OCR) systems. As a result, the final text recognition result is\nlimited by the performance of the text detector. In this paper, we propose a\nsimple, elegant and effective paradigm called Implicit Feature Alignment (IFA),\nwhich can be easily integrated into current text recognizers, resulting in a\nnovel inference mechanism called IFAinference. This enables an ordinary text\nrecognizer to process multi-line text such that text detection can be\ncompletely freed. Specifically, we integrate IFA into the two most prevailing\ntext recognition streams (attention-based and CTC-based) and propose\nattention-guided dense prediction (ADP) and Extended CTC (ExCTC). Furthermore,\nthe Wasserstein-based Hollow Aggregation Cross-Entropy (WH-ACE) is proposed to\nsuppress negative predictions to assist in training ADP and ExCTC. We\nexperimentally demonstrate that IFA achieves state-of-the-art performance on\nend-to-end document recognition tasks while maintaining the fastest speed, and\nADP and ExCTC complement each other on the perspective of different application\nscenarios. Code will be available at\nhttps://github.com/WangTianwei/Implicit-feature-alignment.",
          "link": "http://arxiv.org/abs/2106.05920",
          "publishedOn": "2021-06-11T01:42:14.755Z",
          "wordCount": 650,
          "title": "Implicit Feature Alignment: Learn to Convert Text Recognizer to Text Spotter. (arXiv:2106.05920v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05968",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bulat_A/0/1/0/all/0/1\">Adrian Bulat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perez_Rua_J/0/1/0/all/0/1\">Juan-Manuel Perez-Rua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sudhakaran_S/0/1/0/all/0/1\">Swathikiran Sudhakaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martinez_B/0/1/0/all/0/1\">Brais Martinez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tzimiropoulos_G/0/1/0/all/0/1\">Georgios Tzimiropoulos</a>",
          "description": "This paper is on video recognition using Transformers. Very recent attempts\nin this area have demonstrated promising results in terms of recognition\naccuracy, yet they have been also shown to induce, in many cases, significant\ncomputational overheads due to the additional modelling of the temporal\ninformation. In this work, we propose a Video Transformer model the complexity\nof which scales linearly with the number of frames in the video sequence and\nhence induces \\textit{no overhead} compared to an image-based Transformer\nmodel. To achieve this, our model makes two approximations to the full\nspace-time attention used in Video Transformers: (a) It restricts time\nattention to a local temporal window and capitalizes on the Transformer's depth\nto obtain full temporal coverage of the video sequence. (b) It uses efficient\nspace-time mixing to attend \\textit{jointly} spatial and temporal locations\nwithout inducing any additional cost on top of a spatial-only attention model.\nWe also show how to integrate 2 very lightweight mechanisms for global\ntemporal-only attention which provide additional accuracy improvements at\nminimal computational cost. We demonstrate that our model produces very high\nrecognition accuracy on the most popular video recognition datasets while at\nthe same time being significantly more efficient than other Video Transformer\nmodels. Code will be made available.",
          "link": "http://arxiv.org/abs/2106.05968",
          "publishedOn": "2021-06-11T01:42:14.746Z",
          "wordCount": 643,
          "title": "Space-time Mixing Attention for Video Transformer. (arXiv:2106.05968v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05786",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Hezheng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1\">Xing Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xiangyu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1\">Fan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_D/0/1/0/all/0/1\">Dong Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhongyuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Q/0/1/0/all/0/1\">Qing Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_W/0/1/0/all/0/1\">Wei Yuan</a>",
          "description": "Since Transformer has found widespread use in NLP, the potential of\nTransformer in CV has been realized and has inspired many new approaches.\nHowever, the computation required for replacing word tokens with image patches\nfor Transformer after the tokenization of the image is vast(e.g., ViT), which\nbottlenecks model training and inference. In this paper, we propose a new\nattention mechanism in Transformer termed Cross Attention, which alternates\nattention inner the image patch instead of the whole image to capture local\ninformation and apply attention between image patches which are divided from\nsingle-channel feature maps capture global information. Both operations have\nless computation than standard self-attention in Transformer. By alternately\napplying attention inner patch and between patches, we implement cross\nattention to maintain the performance with lower computational cost and build a\nhierarchical network called Cross Attention Transformer(CAT) for other vision\ntasks. Our base model achieves state-of-the-arts on ImageNet-1K, and improves\nthe performance of other methods on COCO and ADE20K, illustrating that our\nnetwork has the potential to serve as general backbones. The code and models\nare available at \\url{https://github.com/linhezheng19/CAT}.",
          "link": "http://arxiv.org/abs/2106.05786",
          "publishedOn": "2021-06-11T01:42:14.740Z",
          "wordCount": 624,
          "title": "CAT: Cross Attention in Vision Transformer. (arXiv:2106.05786v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05961",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_W/0/1/0/all/0/1\">Weijian Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gould_S/0/1/0/all/0/1\">Stephen Gould</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1\">Liang Zheng</a>",
          "description": "Understanding classifier decision under novel environments is central to the\ncommunity, and a common practice is evaluating it on labeled test sets.\nHowever, in real-world testing, image annotations are difficult and expensive\nto obtain, especially when the test environment is changing. A natural question\nthen arises: given a trained classifier, can we evaluate its accuracy on\nvarying unlabeled test sets? In this work, we train semantic classification and\nrotation prediction in a multi-task way. On a series of datasets, we report an\ninteresting finding, i.e., the semantic classification accuracy exhibits a\nstrong linear relationship with the accuracy of the rotation prediction task\n(Pearson's Correlation r > 0.88). This finding allows us to utilize linear\nregression to estimate classifier performance from the accuracy of rotation\nprediction which can be obtained on the test set through the freely generated\nrotation labels.",
          "link": "http://arxiv.org/abs/2106.05961",
          "publishedOn": "2021-06-11T01:42:14.734Z",
          "wordCount": 586,
          "title": "What Does Rotation Prediction Tell Us about Classifier Accuracy under Varying Testing Environments?. (arXiv:2106.05961v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05956",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lubana_E/0/1/0/all/0/1\">Ekdeep Singh Lubana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dick_R/0/1/0/all/0/1\">Robert P. Dick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tanaka_H/0/1/0/all/0/1\">Hidenori Tanaka</a>",
          "description": "Inspired by BatchNorm, there has been an explosion of normalization layers in\ndeep learning. Recent works have identified a multitude of beneficial\nproperties in BatchNorm to explain its success. However, given the pursuit of\nalternative normalization techniques, these properties need to be generalized\nso that any given layer's success/failure can be accurately predicted. In this\nwork, we take a first step towards this goal by extending known properties of\nBatchNorm in randomly initialized deep neural networks (DNNs) to nine recently\nproposed normalization layers. Our primary findings follow: (i) Similar to\nBatchNorm, activations-based normalization layers can avoid exploding\nactivations in ResNets; (ii) Use of GroupNorm ensures rank of activations is at\nleast $\\Omega(\\sqrt{\\frac{\\text{width}}{\\text{Group Size}}})$, thus explaining\nwhy LayerNorm witnesses slow optimization speed; (iii) Small group sizes result\nin large gradient norm in earlier layers, hence justifying training instability\nissues in Instance Normalization and illustrating a speed-stability tradeoff in\nGroupNorm. Overall, our analysis reveals several general mechanisms that\nexplain the success of normalization techniques in deep learning, providing us\nwith a compass to systematically explore the vast design space of DNN\nnormalization layers.",
          "link": "http://arxiv.org/abs/2106.05956",
          "publishedOn": "2021-06-11T01:42:14.728Z",
          "wordCount": 619,
          "title": "Beyond BatchNorm: Towards a General Understanding of Normalization in Deep Learning. (arXiv:2106.05956v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05843",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zamora_Cardenas_W/0/1/0/all/0/1\">Willard Zamora-Cardenas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mendez_M/0/1/0/all/0/1\">Mauro Mendez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Calderon_Ramirez_S/0/1/0/all/0/1\">Saul Calderon-Ramirez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vargas_M/0/1/0/all/0/1\">Martin Vargas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monge_G/0/1/0/all/0/1\">Gerardo Monge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quiros_S/0/1/0/all/0/1\">Steve Quiros</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elizondo_D/0/1/0/all/0/1\">David Elizondo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elizondo_D/0/1/0/all/0/1\">David Elizondo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Molina_Cabello_M/0/1/0/all/0/1\">Miguel A. Molina-Cabello</a>",
          "description": "Cell instance segmentation in fluorescence microscopy images is becoming\nessential for cancer dynamics and prognosis. Data extracted from cancer\ndynamics allows to understand and accurately model different metabolic\nprocesses such as proliferation. This enables customized and more precise\ncancer treatments. However, accurate cell instance segmentation, necessary for\nfurther cell tracking and behavior analysis, is still challenging in scenarios\nwith high cell concentration and overlapping edges. Within this framework, we\npropose a novel cell instance segmentation approach based on the well-known\nU-Net architecture. To enforce the learning of morphological information per\npixel, a deep distance transformer (DDT) acts as a back-bone model. The DDT\noutput is subsequently used to train a top-model. The following top-models are\nconsidered: a three-class (\\emph{e.g.,} foreground, background and cell border)\nU-net, and a watershed transform. The obtained results suggest a performance\nboost over traditional U-Net architectures. This opens an interesting research\nline around the idea of injecting morphological information into a fully\nconvolutional model.",
          "link": "http://arxiv.org/abs/2106.05843",
          "publishedOn": "2021-06-11T01:42:14.711Z",
          "wordCount": 629,
          "title": "Enforcing Morphological Information in Fully Convolutional Networks to Improve Cell Instance Segmentation in Fluorescence Microscopy Images. (arXiv:2106.05843v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05967",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gansbeke_W/0/1/0/all/0/1\">Wouter Van Gansbeke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vandenhende_S/0/1/0/all/0/1\">Simon Vandenhende</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Georgoulis_S/0/1/0/all/0/1\">Stamatios Georgoulis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1\">Luc Van Gool</a>",
          "description": "Contrastive self-supervised learning has outperformed supervised pretraining\non many downstream tasks like segmentation and object detection. However,\ncurrent methods are still primarily applied to curated datasets like ImageNet.\nIn this paper, we first study how biases in the dataset affect existing\nmethods. Our results show that current contrastive approaches work surprisingly\nwell across: (i) object- versus scene-centric, (ii) uniform versus long-tailed\nand (iii) general versus domain-specific datasets. Second, given the generality\nof the approach, we try to realize further gains with minor modifications. We\nshow that learning additional invariances -- through the use of multi-scale\ncropping, stronger augmentations and nearest neighbors -- improves the\nrepresentations. Finally, we observe that MoCo learns spatially structured\nrepresentations when trained with a multi-crop strategy. The representations\ncan be used for semantic segment retrieval and video instance segmentation\nwithout finetuning. Moreover, the results are on par with specialized models.\nWe hope this work will serve as a useful study for other researchers. The code\nand models will be available at\nhttps://github.com/wvangansbeke/Revisiting-Contrastive-SSL.",
          "link": "http://arxiv.org/abs/2106.05967",
          "publishedOn": "2021-06-11T01:42:14.705Z",
          "wordCount": 617,
          "title": "Revisiting Contrastive Methods for Unsupervised Learning of Visual Representations. (arXiv:2106.05967v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05903",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Botelho_A/0/1/0/all/0/1\">Austin Botelho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vidgen_B/0/1/0/all/0/1\">Bertie Vidgen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hale_S/0/1/0/all/0/1\">Scott A. Hale</a>",
          "description": "Accurate detection and classification of online hate is a difficult task.\nImplicit hate is particularly challenging as such content tends to have unusual\nsyntax, polysemic words, and fewer markers of prejudice (e.g., slurs). This\nproblem is heightened with multimodal content, such as memes (combinations of\ntext and images), as they are often harder to decipher than unimodal content\n(e.g., text alone). This paper evaluates the role of semantic and multimodal\ncontext for detecting implicit and explicit hate. We show that both text- and\nvisual- enrichment improves model performance, with the multimodal model\n(0.771) outperforming other models' F1 scores (0.544, 0.737, and 0.754). While\nthe unimodal-text context-aware (transformer) model was the most accurate on\nthe subtask of implicit hate detection, the multimodal model outperformed it\noverall because of a lower propensity towards false positives. We find that all\nmodels perform better on content with full annotator agreement and that\nmultimodal models are best at classifying the content where annotators\ndisagree. To conduct these investigations, we undertook high-quality annotation\nof a sample of 5,000 multimodal entries. Tweets were annotated for primary\ncategory, modality, and strategy. We make this corpus, along with the codebook,\ncode, and final model, freely available.",
          "link": "http://arxiv.org/abs/2106.05903",
          "publishedOn": "2021-06-11T01:42:14.696Z",
          "wordCount": 659,
          "title": "Deciphering Implicit Hate: Evaluating Automated Detection Algorithms for Multimodal Hate. (arXiv:2106.05903v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05744",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roich_D/0/1/0/all/0/1\">Daniel Roich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mokady_R/0/1/0/all/0/1\">Ron Mokady</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bermano_A/0/1/0/all/0/1\">Amit H. Bermano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_Or_D/0/1/0/all/0/1\">Daniel Cohen-Or</a>",
          "description": "Recently, a surge of advanced facial editing techniques have been proposed\nthat leverage the generative power of a pre-trained StyleGAN. To successfully\nedit an image this way, one must first project (or invert) the image into the\npre-trained generator's domain. As it turns out, however, StyleGAN's latent\nspace induces an inherent tradeoff between distortion and editability, i.e.\nbetween maintaining the original appearance and convincingly altering some of\nits attributes. Practically, this means it is still challenging to apply\nID-preserving facial latent-space editing to faces which are out of the\ngenerator's domain. In this paper, we present an approach to bridge this gap.\nOur technique slightly alters the generator, so that an out-of-domain image is\nfaithfully mapped into an in-domain latent code. The key idea is pivotal tuning\n- a brief training process that preserves the editing quality of an in-domain\nlatent region, while changing its portrayed identity and appearance. In Pivotal\nTuning Inversion (PTI), an initial inverted latent code serves as a pivot,\naround which the generator is fined-tuned. At the same time, a regularization\nterm keeps nearby identities intact, to locally contain the effect. This\nsurgical training process ends up altering appearance features that represent\nmostly identity, without affecting editing capabilities. We validate our\ntechnique through inversion and editing metrics, and show preferable scores to\nstate-of-the-art methods. We further qualitatively demonstrate our technique by\napplying advanced edits (such as pose, age, or expression) to numerous images\nof well-known and recognizable identities. Finally, we demonstrate resilience\nto harder cases, including heavy make-up, elaborate hairstyles and/or headwear,\nwhich otherwise could not have been successfully inverted and edited by\nstate-of-the-art methods.",
          "link": "http://arxiv.org/abs/2106.05744",
          "publishedOn": "2021-06-11T01:42:14.690Z",
          "wordCount": 699,
          "title": "Pivotal Tuning for Latent-based Editing of Real Images. (arXiv:2106.05744v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05746",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kamath_R/0/1/0/all/0/1\">Rashmi Kamath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rolwes_G/0/1/0/all/0/1\">Greg Rolwes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Black_S/0/1/0/all/0/1\">Samuel Black</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stylianou_A/0/1/0/all/0/1\">Abby Stylianou</a>",
          "description": "Hotel recognition is an important task for human trafficking investigations\nsince victims are often photographed in hotel rooms. Identifying these hotels\nis vital to trafficking investigations since they can help track down current\nand future victims who might be taken to the same places. Hotel recognition is\na challenging fine grained visual classification task as there can be little\nsimilarity between different rooms within the same hotel, and high similarity\nbetween rooms from different hotels (especially if they are from the same\nchain). Hotel recognition to combat human trafficking poses additional\nchallenges as investigative images are often low quality, contain uncommon\ncamera angles and are highly occluded. Here, we present the 2021 Hotel-ID\ndataset to help raise awareness for this problem and generate novel approaches.\nThe dataset consists of hotel room images that have been crowd-sourced and\nuploaded through the TraffickCam mobile application. The quality of these\nimages is similar to investigative images and hence models trained on these\nimages have good chances of accurately narrowing down on the correct hotel.",
          "link": "http://arxiv.org/abs/2106.05746",
          "publishedOn": "2021-06-11T01:42:14.670Z",
          "wordCount": 612,
          "title": "The 2021 Hotel-ID to Combat Human Trafficking Competition Dataset. (arXiv:2106.05746v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05735",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Antonelli_M/0/1/0/all/0/1\">Michela Antonelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reinke_A/0/1/0/all/0/1\">Annika Reinke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bakas_S/0/1/0/all/0/1\">Spyridon Bakas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farahani_K/0/1/0/all/0/1\">Keyvan Farahani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+AnnetteKopp-Schneider/0/1/0/all/0/1\">AnnetteKopp-Schneider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Landman_B/0/1/0/all/0/1\">Bennett A. Landman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Litjens_G/0/1/0/all/0/1\">Geert Litjens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Menze_B/0/1/0/all/0/1\">Bjoern Menze</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ronneberger_O/0/1/0/all/0/1\">Olaf Ronneberger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Summers_R/0/1/0/all/0/1\">Ronald M.Summers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ginneken_B/0/1/0/all/0/1\">Bram van Ginneken</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bilello_M/0/1/0/all/0/1\">Michel Bilello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bilic_P/0/1/0/all/0/1\">Patrick Bilic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Christ_P/0/1/0/all/0/1\">Patrick F. Christ</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Do_R/0/1/0/all/0/1\">Richard K. G. Do</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gollub_M/0/1/0/all/0/1\">Marc J. Gollub</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heckers_S/0/1/0/all/0/1\">Stephan H. Heckers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huisman_H/0/1/0/all/0/1\">Henkjan Huisman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jarnagin_W/0/1/0/all/0/1\">William R. Jarnagin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McHugo_M/0/1/0/all/0/1\">Maureen K. McHugo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Napel_S/0/1/0/all/0/1\">Sandy Napel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pernicka_J/0/1/0/all/0/1\">Jennifer S. Goli Pernicka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rhode_K/0/1/0/all/0/1\">Kawal Rhode</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tobon_Gomez_C/0/1/0/all/0/1\">Catalina Tobon-Gomez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vorontsov_E/0/1/0/all/0/1\">Eugene Vorontsov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huisman_H/0/1/0/all/0/1\">Henkjan Huisman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meakin_J/0/1/0/all/0/1\">James A. Meakin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ourselin_S/0/1/0/all/0/1\">Sebastien Ourselin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wiesenfarth_M/0/1/0/all/0/1\">Manuel Wiesenfarth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arbelaez_P/0/1/0/all/0/1\">Pablo Arbelaez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bae_B/0/1/0/all/0/1\">Byeonguk Bae</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Sihong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daza_L/0/1/0/all/0/1\">Laura Daza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jianjiang Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_B/0/1/0/all/0/1\">Baochun He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Isensee_F/0/1/0/all/0/1\">Fabian Isensee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_Y/0/1/0/all/0/1\">Yuanfeng Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_F/0/1/0/all/0/1\">Fucang Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_N/0/1/0/all/0/1\">Namkug Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_I/0/1/0/all/0/1\">Ildoo Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Merhof_D/0/1/0/all/0/1\">Dorit Merhof</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pai_A/0/1/0/all/0/1\">Akshay Pai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_B/0/1/0/all/0/1\">Beomhee Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perslev_M/0/1/0/all/0/1\">Mathias Perslev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rezaiifar_R/0/1/0/all/0/1\">Ramin Rezaiifar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rippel_O/0/1/0/all/0/1\">Oliver Rippel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarasua_I/0/1/0/all/0/1\">Ignacio Sarasua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_W/0/1/0/all/0/1\">Wei Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Son_J/0/1/0/all/0/1\">Jaemin Son</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wachinger_C/0/1/0/all/0/1\">Christian Wachinger</a>, et al. (9 additional authors not shown)",
          "description": "International challenges have become the de facto standard for comparative\nassessment of image analysis algorithms given a specific task. Segmentation is\nso far the most widely investigated medical image processing task, but the\nvarious segmentation challenges have typically been organized in isolation,\nsuch that algorithm development was driven by the need to tackle a single\nspecific clinical problem. We hypothesized that a method capable of performing\nwell on multiple tasks will generalize well to a previously unseen task and\npotentially outperform a custom-designed solution. To investigate the\nhypothesis, we organized the Medical Segmentation Decathlon (MSD) - a\nbiomedical image analysis challenge, in which algorithms compete in a multitude\nof both tasks and modalities. The underlying data set was designed to explore\nthe axis of difficulties typically encountered when dealing with medical\nimages, such as small data sets, unbalanced labels, multi-site data and small\nobjects. The MSD challenge confirmed that algorithms with a consistent good\nperformance on a set of tasks preserved their good average performance on a\ndifferent set of previously unseen tasks. Moreover, by monitoring the MSD\nwinner for two years, we found that this algorithm continued generalizing well\nto a wide range of other clinical problems, further confirming our hypothesis.\nThree main conclusions can be drawn from this study: (1) state-of-the-art image\nsegmentation algorithms are mature, accurate, and generalize well when\nretrained on unseen tasks; (2) consistent algorithmic performance across\nmultiple tasks is a strong surrogate of algorithmic generalizability; (3) the\ntraining of accurate AI segmentation models is now commoditized to non AI\nexperts.",
          "link": "http://arxiv.org/abs/2106.05735",
          "publishedOn": "2021-06-11T01:42:14.655Z",
          "wordCount": 811,
          "title": "The Medical Segmentation Decathlon. (arXiv:2106.05735v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05779",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Venkatesh_R/0/1/0/all/0/1\">Rahul Venkatesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karmali_T/0/1/0/all/0/1\">Tejan Karmali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1\">Sarthak Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_A/0/1/0/all/0/1\">Aurobrata Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeni_L/0/1/0/all/0/1\">L&#xe1;szl&#xf3; A. Jeni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Babu_R/0/1/0/all/0/1\">R. Venkatesh Babu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_M/0/1/0/all/0/1\">Maneesh Singh</a>",
          "description": "Deep neural representations of 3D shapes as implicit functions have been\nshown to produce high fidelity models surpassing the resolution-memory\ntrade-off faced by the explicit representations using meshes and point clouds.\nHowever, most such approaches focus on representing closed shapes. Unsigned\ndistance function (UDF) based approaches have been proposed recently as a\npromising alternative to represent both open and closed shapes. However, since\nthe gradients of UDFs vanish on the surface, it is challenging to estimate\nlocal (differential) geometric properties like the normals and tangent planes\nwhich are needed for many downstream applications in vision and graphics. There\nare additional challenges in computing these properties efficiently with a\nlow-memory footprint. This paper presents a novel approach that models such\nsurfaces using a new class of implicit representations called the closest\nsurface-point (CSP) representation. We show that CSP allows us to represent\ncomplex surfaces of any topology (open or closed) with high fidelity. It also\nallows for accurate and efficient computation of local geometric properties. We\nfurther demonstrate that it leads to efficient implementation of downstream\nalgorithms like sphere-tracing for rendering the 3D surface as well as to\ncreate explicit mesh-based representations. Extensive experimental evaluation\non the ShapeNet dataset validate the above contributions with results\nsurpassing the state-of-the-art.",
          "link": "http://arxiv.org/abs/2106.05779",
          "publishedOn": "2021-06-11T01:42:14.647Z",
          "wordCount": 653,
          "title": "Deep Implicit Surface Point Prediction Networks. (arXiv:2106.05779v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05897",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_Q/0/1/0/all/0/1\">Qingzhe Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Libin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Baoquan Chen</a>",
          "description": "Co-part segmentation is an important problem in computer vision for its rich\napplications. We propose an unsupervised learning approach for co-part\nsegmentation from images. For the training stage, we leverage motion\ninformation embedded in videos and explicitly extract latent representations to\nsegment meaningful object parts. More importantly, we introduce a dual\nprocedure of part-assembly to form a closed loop with part-segmentation,\nenabling an effective self-supervision. We demonstrate the effectiveness of our\napproach with a host of extensive experiments, ranging from human bodies,\nhands, quadruped, and robot arms. We show that our approach can achieve\nmeaningful and compact part segmentation, outperforming state-of-the-art\napproaches on diverse benchmarks.",
          "link": "http://arxiv.org/abs/2106.05897",
          "publishedOn": "2021-06-11T01:42:14.627Z",
          "wordCount": 529,
          "title": "Unsupervised Co-part Segmentation through Assembly. (arXiv:2106.05897v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05665",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_A/0/1/0/all/0/1\">Anurag Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nambi_A/0/1/0/all/0/1\">Akshay Nambi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1\">Aditya Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+YVS_H/0/1/0/all/0/1\">Harish YVS</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganu_T/0/1/0/all/0/1\">Tanuja Ganu</a>",
          "description": "Executing computer vision models on streaming visual data, or streaming\nperception is an emerging problem, with applications in self-driving, embodied\nagents, and augmented/virtual reality. The development of such systems is\nlargely governed by the accuracy and latency of the processing pipeline. While\npast work has proposed numerous approximate execution frameworks, their\ndecision functions solely focus on optimizing latency, accuracy, or energy,\netc. This results in sub-optimum decisions, affecting the overall system\nperformance. We argue that the streaming perception systems should holistically\nmaximize the overall system performance (i.e., considering both accuracy and\nlatency simultaneously). To this end, we describe a new approach based on deep\nreinforcement learning to learn these tradeoffs at runtime for streaming\nperception. This tradeoff optimization is formulated as a novel deep contextual\nbandit problem and we design a new reward function that holistically integrates\nlatency and accuracy into a single metric. We show that our agent can learn a\ncompetitive policy across multiple decision dimensions, which outperforms\nstate-of-the-art policies on public datasets.",
          "link": "http://arxiv.org/abs/2106.05665",
          "publishedOn": "2021-06-11T01:42:14.595Z",
          "wordCount": 604,
          "title": "Adaptive Streaming Perception using Deep Reinforcement Learning. (arXiv:2106.05665v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05741",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Drokin_I/0/1/0/all/0/1\">Ivan Drokin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ericheva_E/0/1/0/all/0/1\">Elena Ericheva</a>",
          "description": "This paper proposes novel end-to-end framework for detecting suspicious\npulmonary nodules in chest CT scans. The method core idea is a new nodule\nsegmentation architecture with a model-based feature projection block on\nthree-dimensional convolutions. This block acts as a preliminary feature\nextractor for a two-dimensional U-Net-like convolutional network. Using the\nproposed approach along with an axial, coronal, and sagittal projection\nanalysis makes it possible to abandon the widely used false positives reduction\nstep. The proposed method achieves SOTA on LUNA2016 with 0.959 average\nsensitivity, and 0.936 sensitivity if the false-positive level per scan is\n0.25. The paper describes the proposed approach and represents the experimental\nresults on LUNA2016 as well as ablation studies.",
          "link": "http://arxiv.org/abs/2106.05741",
          "publishedOn": "2021-06-11T01:42:14.579Z",
          "wordCount": 557,
          "title": "End-to-end lung nodule detection framework with model-based feature projection block. (arXiv:2106.05741v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05657",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kotyan_S/0/1/0/all/0/1\">Shashank Kotyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vargas_D/0/1/0/all/0/1\">Danilo Vasconcellos Vargas</a>",
          "description": "Adversarial algorithms have shown to be effective against neural networks for\na variety of tasks. Some adversarial algorithms perturb all the pixels in the\nimage minimally for the image classification task in image classification. In\ncontrast, some algorithms perturb few pixels strongly. However, very little\ninformation is available regarding why these adversarial samples so diverse\nfrom each other exist. Recently, Vargas et al. showed that the existence of\nthese adversarial samples might be due to conflicting saliency within the\nneural network. We test this hypothesis of conflicting saliency by analysing\nthe Saliency Maps (SM) and Gradient-weighted Class Activation Maps (Grad-CAM)\nof original and few different types of adversarial samples. We also analyse how\ndifferent adversarial samples distort the attention of the neural network\ncompared to original samples. We show that in the case of Pixel Attack,\nperturbed pixels either calls the network attention to themselves or divert the\nattention from them. Simultaneously, the Projected Gradient Descent Attack\nperturbs pixels so that intermediate layers inside the neural network lose\nattention for the correct class. We also show that both attacks affect the\nsaliency map and activation maps differently. Thus, shedding light on why some\ndefences successful against some attacks remain vulnerable against other\nattacks. We hope that this analysis will improve understanding of the existence\nand the effect of adversarial samples and enable the community to develop more\nrobust neural networks.",
          "link": "http://arxiv.org/abs/2106.05657",
          "publishedOn": "2021-06-11T01:42:14.564Z",
          "wordCount": 675,
          "title": "Deep neural network loses attention to adversarial images. (arXiv:2106.05657v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05601",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Terhorst_P/0/1/0/all/0/1\">Philipp Terh&#xf6;rst</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boller_A/0/1/0/all/0/1\">Andr&#xe9; Boller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Damer_N/0/1/0/all/0/1\">Naser Damer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kirchbuchner_F/0/1/0/all/0/1\">Florian Kirchbuchner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuijper_A/0/1/0/all/0/1\">Arjan Kuijper</a>",
          "description": "An essential factor to achieve high accuracies in fingerprint recognition\nsystems is the quality of its samples. Previous works mainly proposed\nsupervised solutions based on image properties that neglects the minutiae\nextraction process, despite that most fingerprint recognition techniques are\nbased on detected minutiae. Consequently, a fingerprint image might be assigned\na high quality even if the utilized minutia extractor produces unreliable\ninformation. In this work, we propose a novel concept of assessing minutia and\nfingerprint quality based on minutia detection confidence (MiDeCon). MiDeCon\ncan be applied to an arbitrary deep learning based minutia extractor and does\nnot require quality labels for learning. We propose using the detection\nreliability of the extracted minutia as its quality indicator. By combining the\nhighest minutia qualities, MiDeCon also accurately determines the quality of a\nfull fingerprint. Experiments are conducted on the publicly available databases\nof the FVC 2006 and compared against several baselines, such as NIST's\nwidely-used fingerprint image quality software NFIQ1 and NFIQ2. The results\ndemonstrate a significantly stronger quality assessment performance of the\nproposed MiDeCon-qualities as related works on both, minutia- and\nfingerprint-level. The implementation is publicly available.",
          "link": "http://arxiv.org/abs/2106.05601",
          "publishedOn": "2021-06-11T01:42:14.558Z",
          "wordCount": 635,
          "title": "MiDeCon: Unsupervised and Accurate Fingerprint and Minutia Quality Assessment based on Minutia Detection Confidence. (arXiv:2106.05601v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05681",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chongwei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haojie Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuchang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1\">Ming Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Dong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1\">Xin Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhihui Wang</a>",
          "description": "Underwater object detection for robot picking has attracted a lot of\ninterest. However, it is still an unsolved problem due to several challenges.\nWe take steps towards making it more realistic by addressing the following\nchallenges. Firstly, the currently available datasets basically lack the test\nset annotations, causing researchers must compare their method with other SOTAs\non a self-divided test set (from the training set). Training other methods lead\nto an increase in workload and different researchers divide different datasets,\nresulting there is no unified benchmark to compare the performance of different\nalgorithms. Secondly, these datasets also have other shortcomings, e.g., too\nmany similar images or incomplete labels. Towards these challenges we introduce\na dataset, Detecting Underwater Objects (DUO), and a corresponding benchmark,\nbased on the collection and re-annotation of all relevant datasets. DUO\ncontains a collection of diverse underwater images with more rational\nannotations. The corresponding benchmark provides indicators of both efficiency\nand accuracy of SOTAs (under the MMDtection framework) for academic research\nand industrial applications, where JETSON AGX XAVIER is used to assess detector\nspeed to simulate the robot-embedded environment.",
          "link": "http://arxiv.org/abs/2106.05681",
          "publishedOn": "2021-06-11T01:42:14.548Z",
          "wordCount": 623,
          "title": "A Dataset And Benchmark Of Underwater Object Detection For Robot Picking. (arXiv:2106.05681v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05610",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dhulipala_L/0/1/0/all/0/1\">Laxman Dhulipala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eisenstat_D/0/1/0/all/0/1\">David Eisenstat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lacki_J/0/1/0/all/0/1\">Jakub &#x141;&#x105;cki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mirrokni_V/0/1/0/all/0/1\">Vahab Mirrokni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1\">Jessica Shi</a>",
          "description": "We study the widely used hierarchical agglomerative clustering (HAC)\nalgorithm on edge-weighted graphs. We define an algorithmic framework for\nhierarchical agglomerative graph clustering that provides the first efficient\n$\\tilde{O}(m)$ time exact algorithms for classic linkage measures, such as\ncomplete- and WPGMA-linkage, as well as other measures. Furthermore, for\naverage-linkage, arguably the most popular variant of HAC, we provide an\nalgorithm that runs in $\\tilde{O}(n\\sqrt{m})$ time. For this variant, this is\nthe first exact algorithm that runs in subquadratic time, as long as\n$m=n^{2-\\epsilon}$ for some constant $\\epsilon > 0$. We complement this result\nwith a simple $\\epsilon$-close approximation algorithm for average-linkage in\nour framework that runs in $\\tilde{O}(m)$ time. As an application of our\nalgorithms, we consider clustering points in a metric space by first using\n$k$-NN to generate a graph from the point set, and then running our algorithms\non the resulting weighted graph. We validate the performance of our algorithms\non publicly available datasets, and show that our approach can speed up\nclustering of point datasets by a factor of 20.7--76.5x.",
          "link": "http://arxiv.org/abs/2106.05610",
          "publishedOn": "2021-06-11T01:42:14.529Z",
          "wordCount": 628,
          "title": "Hierarchical Agglomerative Graph Clustering in Nearly-Linear Time. (arXiv:2106.05610v1 [cs.DS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05656",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhaowen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhiyang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1\">Fan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yousong Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1\">Chaoyang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_R/0/1/0/all/0/1\">Rui Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1\">Liwei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_R/0/1/0/all/0/1\">Rui Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_M/0/1/0/all/0/1\">Ming Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jinqiao Wang</a>",
          "description": "Transformer has been widely used for self-supervised pre-training in Natural\nLanguage Processing (NLP) and achieved great success. However, it has not been\nfully explored in visual self-supervised learning. Meanwhile, previous methods\nonly consider the high-level feature and learning representation from a global\nperspective, which may fail to transfer to the downstream dense prediction\ntasks focusing on local features. In this paper, we present a novel Masked\nSelf-supervised Transformer approach named MST, which can explicitly capture\nthe local context of an image while preserving the global semantic information.\nSpecifically, inspired by the Masked Language Modeling (MLM) in NLP, we propose\na masked token strategy based on the multi-head self-attention map, which\ndynamically masks some tokens of local patches without damaging the crucial\nstructure for self-supervised learning. More importantly, the masked tokens\ntogether with the remaining tokens are further recovered by a global image\ndecoder, which preserves the spatial information of the image and is more\nfriendly to the downstream dense prediction tasks. The experiments on multiple\ndatasets demonstrate the effectiveness and generality of the proposed method.\nFor instance, MST achieves Top-1 accuracy of 76.9% with DeiT-S only using\n300-epoch pre-training by linear evaluation, which outperforms supervised\nmethods with the same epoch by 0.4% and its comparable variant DINO by 1.0\\%.\nFor dense prediction tasks, MST also achieves 42.7% mAP on MS COCO object\ndetection and 74.04% mIoU on Cityscapes segmentation only with 100-epoch\npre-training.",
          "link": "http://arxiv.org/abs/2106.05656",
          "publishedOn": "2021-06-11T01:42:14.518Z",
          "wordCount": 674,
          "title": "MST: Masked Self-Supervised Transformer for Visual Representation. (arXiv:2106.05656v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05728",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shah_R/0/1/0/all/0/1\">Riya Shah Rutva Shah</a>",
          "description": "In the recent times, the Coronaviruses that are a big family of different\nviruses have become very common, contagious and dangerous to the whole human\nkind. It spreads human to human by exhaling the infection breath, which leaves\ndroplets of the virus on different surface which is then inhaled by other\nperson and catches the infection too. So it has become very important to\nprotect ourselves and the people around us from this situation. We can take\nprecautions such as social distancing, washing hands every two hours, using\nsanitizer, maintaining social distance and the most important wearing a mask.\nPublic use of wearing a masks has become very common everywhere in the whole\nworld now. From that the most affected and devastating condition is of India\ndue to its extreme population in small area. This paper proposes a method to\ndetect the face mask is put on or not for offices, or any other work place with\na lot of people coming to work. We have used convolutional neural network for\nthe same. The model is trained on a real world dataset and tested with live\nvideo streaming with a good accuracy. Further the accuracy of the model with\ndifferent hyper parameters and multiple people at different distance and\nlocation of the frame is done.",
          "link": "http://arxiv.org/abs/2106.05728",
          "publishedOn": "2021-06-11T01:42:14.511Z",
          "wordCount": 696,
          "title": "Face mask detection using convolution neural network. (arXiv:2106.05728v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05618",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Molina_A/0/1/0/all/0/1\">Adri&#xe0; Molina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riba_P/0/1/0/all/0/1\">Pau Riba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gomez_L/0/1/0/all/0/1\">Lluis Gomez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramos_Terrades_O/0/1/0/all/0/1\">Oriol Ramos-Terrades</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Llados_J/0/1/0/all/0/1\">Josep Llad&#xf3;s</a>",
          "description": "This paper presents a novel method for date estimation of historical\nphotographs from archival sources. The main contribution is to formulate the\ndate estimation as a retrieval task, where given a query, the retrieved images\nare ranked in terms of the estimated date similarity. The closer are their\nembedded representations the closer are their dates. Contrary to the\ntraditional models that design a neural network that learns a classifier or a\nregressor, we propose a learning objective based on the nDCG ranking metric. We\nhave experimentally evaluated the performance of the method in two different\ntasks: date estimation and date-sensitive image retrieval, using the DEW public\ndatabase, overcoming the baseline methods.",
          "link": "http://arxiv.org/abs/2106.05618",
          "publishedOn": "2021-06-11T01:42:14.488Z",
          "wordCount": 558,
          "title": "Date Estimation in the Wild of Scanned Historical Photos: An Image Retrieval Approach. (arXiv:2106.05618v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05597",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kervadec_C/0/1/0/all/0/1\">Corentin Kervadec</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolf_C/0/1/0/all/0/1\">Christian Wolf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Antipov_G/0/1/0/all/0/1\">Grigory Antipov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baccouche_M/0/1/0/all/0/1\">Moez Baccouche</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nadri_M/0/1/0/all/0/1\">Madiha Nadri</a>",
          "description": "Methods for Visual Question Anwering (VQA) are notorious for leveraging\ndataset biases rather than performing reasoning, hindering generalization. It\nhas been recently shown that better reasoning patterns emerge in attention\nlayers of a state-of-the-art VQA model when they are trained on perfect\n(oracle) visual inputs. This provides evidence that deep neural networks can\nlearn to reason when training conditions are favorable enough. However,\ntransferring this learned knowledge to deployable models is a challenge, as\nmuch of it is lost during the transfer. We propose a method for knowledge\ntransfer based on a regularization term in our loss function, supervising the\nsequence of required reasoning operations. We provide a theoretical analysis\nbased on PAC-learning, showing that such program prediction can lead to\ndecreased sample complexity under mild hypotheses. We also demonstrate the\neffectiveness of this approach experimentally on the GQA dataset and show its\ncomplementarity to BERT-like self-supervised pre-training.",
          "link": "http://arxiv.org/abs/2106.05597",
          "publishedOn": "2021-06-11T01:42:14.482Z",
          "wordCount": 584,
          "title": "Supervising the Transfer of Reasoning Patterns in VQA. (arXiv:2106.05597v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05596",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Seneviratne_S/0/1/0/all/0/1\">Sachith Seneviratne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kasthuriaarachchi_N/0/1/0/all/0/1\">Nuran Kasthuriaarachchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rasnayaka_S/0/1/0/all/0/1\">Sanka Rasnayaka</a>",
          "description": "The COVID-19 pandemic has drastically changed accepted norms globally. Within\nthe past year, masks have been used as a public health response to limit the\nspread of the virus. This sudden change has rendered many face recognition\nbased access control, authentication and surveillance systems ineffective.\nOfficial documents such as passports, driving license and national identity\ncards are enrolled with fully uncovered face images. However, in the current\nglobal situation, face matching systems should be able to match these reference\nimages with masked face images. As an example, in an airport or security\ncheckpoint it is safer to match the unmasked image of the identifying document\nto the masked person rather than asking them to remove the mask. We find that\ncurrent facial recognition techniques are not robust to this form of occlusion.\n\nTo address this unique requirement presented due to the current circumstance,\nwe propose a set of re-purposed datasets and a benchmark for researchers to\nuse. We also propose a contrastive visual representation learning based\npre-training workflow which is specialized to masked vs unmasked face matching.\nWe ensure that our method learns robust features to differentiate people across\nvarying data collection scenarios. We achieve this by training over many\ndifferent datasets and validating our result by testing on various holdout\ndatasets. The specialized weights trained by our method outperform standard\nface recognition features for masked to unmasked face matching. We believe the\nprovided synthetic mask generating code, our novel training approach and the\ntrained weights from the masked face models will help in adopting existing face\nrecognition systems to operate in the current global environment. We\nopen-source all contributions for broader use by the research community.",
          "link": "http://arxiv.org/abs/2106.05596",
          "publishedOn": "2021-06-11T01:42:14.477Z",
          "wordCount": 758,
          "title": "Multi-Dataset Benchmarks for Masked Identification using Contrastive Representation Learning. (arXiv:2106.05596v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05554",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zefan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chenxi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuille_A/0/1/0/all/0/1\">Alan Yuille</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_B/0/1/0/all/0/1\">Bingbing Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenjun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1\">Wen Gao</a>",
          "description": "Unsupervised learning methods have recently shown their competitiveness\nagainst supervised training. Typically, these methods use a single objective to\ntrain the entire network. But one distinct advantage of unsupervised over\nsupervised learning is that the former possesses more variety and freedom in\ndesigning the objective. In this work, we explore new dimensions of\nunsupervised learning by proposing the Progressive Stage-wise Learning (PSL)\nframework. For a given unsupervised task, we design multilevel tasks and define\ndifferent learning stages for the deep network. Early learning stages are\nforced to focus on lowlevel tasks while late stages are guided to extract\ndeeper information through harder tasks. We discover that by progressive\nstage-wise learning, unsupervised feature representation can be effectively\nenhanced. Our extensive experiments show that PSL consistently improves results\nfor the leading unsupervised learning methods.",
          "link": "http://arxiv.org/abs/2106.05554",
          "publishedOn": "2021-06-11T01:42:14.444Z",
          "wordCount": 579,
          "title": "Progressive Stage-wise Learning for Unsupervised Feature Representation Enhancement. (arXiv:2106.05554v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05549",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rosenzweig_J/0/1/0/all/0/1\">Julia Rosenzweig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brito_E/0/1/0/all/0/1\">Eduardo Brito</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kobialka_H/0/1/0/all/0/1\">Hans-Ulrich Kobialka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akila_M/0/1/0/all/0/1\">Maram Akila</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidt_N/0/1/0/all/0/1\">Nico M. Schmidt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schlicht_P/0/1/0/all/0/1\">Peter Schlicht</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schneider_J/0/1/0/all/0/1\">Jan David Schneider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huger_F/0/1/0/all/0/1\">Fabian H&#xfc;ger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rottmann_M/0/1/0/all/0/1\">Matthias Rottmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Houben_S/0/1/0/all/0/1\">Sebastian Houben</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wirtz_T/0/1/0/all/0/1\">Tim Wirtz</a>",
          "description": "Many machine learning applications can benefit from simulated data for\nsystematic validation - in particular if real-life data is difficult to obtain\nor annotate. However, since simulations are prone to domain shift w.r.t.\nreal-life data, it is crucial to verify the transferability of the obtained\nresults. We propose a novel framework consisting of a generative label-to-image\nsynthesis model together with different transferability measures to inspect to\nwhat extent we can transfer testing results of semantic segmentation models\nfrom synthetic data to equivalent real-life data. With slight modifications,\nour approach is extendable to, e.g., general multi-class classification tasks.\nGrounded on the transferability analysis, our approach additionally allows for\nextensive testing by incorporating controlled simulations. We validate our\napproach empirically on a semantic segmentation task on driving scenes.\nTransferability is tested using correlation analysis of IoU and a learned\ndiscriminator. Although the latter can distinguish between real-life and\nsynthetic tests, in the former we observe surprisingly strong correlations of\n0.7 for both cars and pedestrians.",
          "link": "http://arxiv.org/abs/2106.05549",
          "publishedOn": "2021-06-11T01:42:14.438Z",
          "wordCount": 642,
          "title": "Validation of Simulation-Based Testing: Bypassing Domain Shift with Label-to-Image Synthesis. (arXiv:2106.05549v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05321",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lazarou_M/0/1/0/all/0/1\">Michalis Lazarou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Avrithis_Y/0/1/0/all/0/1\">Yannis Avrithis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stathaki_T/0/1/0/all/0/1\">Tania Stathaki</a>",
          "description": "Few-shot classification addresses the challenge of classifying examples given\nnot just limited supervision but limited data as well. An attractive solution\nis synthetic data generation. However, most such methods are overly\nsophisticated, focusing on high-quality, realistic data in the input space. It\nis unclear whether adapting them to the few-shot regime and using them for the\ndownstream task of classification is the right approach. Previous works on\nsynthetic data generation for few-shot classification focus on exploiting\ncomplex models, e.g. a Wasserstein GAN with multiple regularizers or a network\nthat transfers latent diversities from known to novel classes.\n\nWe follow a different approach and investigate how a simple and\nstraightforward synthetic data generation method can be used effectively. We\nmake two contributions, namely we show that: (1) using a simple loss function\nis more than enough for training a feature generator in the few-shot setting;\nand (2) learning to generate tensor features instead of vector features is\nsuperior. Extensive experiments on miniImagenet, CUB and CIFAR-FS datasets show\nthat our method sets a new state of the art, outperforming more sophisticated\nfew-shot data augmentation methods.",
          "link": "http://arxiv.org/abs/2106.05321",
          "publishedOn": "2021-06-11T01:42:14.411Z",
          "wordCount": 626,
          "title": "Tensor feature hallucination for few-shot learning. (arXiv:2106.05321v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05499",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongsong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_S/0/1/0/all/0/1\">Shengcai Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_L/0/1/0/all/0/1\">Ling Shao</a>",
          "description": "Unsupervised domain adaptation for object detection is a challenging problem\nwith many real-world applications. Unfortunately, it has received much less\nattention than supervised object detection. Models that try to address this\ntask tend to suffer from a shortage of annotated training samples. Moreover,\nexisting methods of feature alignments are not sufficient to learn\ndomain-invariant representations. To address these limitations, we propose a\nnovel augmented feature alignment network (AFAN) which integrates intermediate\ndomain image generation and domain-adversarial training into a unified\nframework. An intermediate domain image generator is proposed to enhance\nfeature alignments by domain-adversarial training with automatically generated\nsoft domain labels. The synthetic intermediate domain images progressively\nbridge the domain divergence and augment the annotated source domain training\ndata. A feature pyramid alignment is designed and the corresponding feature\ndiscriminator is used to align multi-scale convolutional features of different\nsemantic levels. Last but not least, we introduce a region feature alignment\nand an instance discriminator to learn domain-invariant features for object\nproposals. Our approach significantly outperforms the state-of-the-art methods\non standard benchmarks for both similar and dissimilar domain adaptations.\nFurther extensive experiments verify the effectiveness of each component and\ndemonstrate that the proposed network can learn domain-invariant\nrepresentations.",
          "link": "http://arxiv.org/abs/2106.05499",
          "publishedOn": "2021-06-11T01:42:14.405Z",
          "wordCount": 628,
          "title": "AFAN: Augmented Feature Alignment Network for Cross-Domain Object Detection. (arXiv:2106.05499v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05545",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yibo Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haidi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1\">Yiming Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shunyao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1\">Mingliang Xu</a>",
          "description": "With the effective application of deep learning in computer vision,\nbreakthroughs have been made in the research of super-resolution images\nreconstruction. However, many researches have pointed out that the\ninsufficiency of the neural network extraction on image features may bring the\ndeteriorating of newly reconstructed image. On the other hand, the generated\npictures are sometimes too artificial because of over-smoothing. In order to\nsolve the above problems, we propose a novel self-calibrated convolutional\ngenerative adversarial networks. The generator consists of feature extraction\nand image reconstruction. Feature extraction uses self-calibrated convolutions,\nwhich contains four portions, and each portion has specific functions. It can\nnot only expand the range of receptive fields, but also obtain long-range\nspatial and inter-channel dependencies. Then image reconstruction is performed,\nand finally a super-resolution image is reconstructed. We have conducted\nthorough experiments on different datasets including set5, set14 and BSD100\nunder the SSIM evaluation method. The experimental results prove the\neffectiveness of the proposed network.",
          "link": "http://arxiv.org/abs/2106.05545",
          "publishedOn": "2021-06-11T01:42:14.391Z",
          "wordCount": 598,
          "title": "Super-Resolution Image Reconstruction Based on Self-Calibrated Convolutional GAN. (arXiv:2106.05545v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05453",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1\">Dawei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_N/0/1/0/all/0/1\">Nannan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1\">Xinbo Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1\">Bo Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Jun Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaoyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tongliang Liu</a>",
          "description": "Deep neural networks (DNNs) are vulnerable to adversarial noise. A range of\nadversarial defense techniques have been proposed to mitigate the interference\nof adversarial noise, among which the input pre-processing methods are scalable\nand show great potential to safeguard DNNs. However, pre-processing methods may\nsuffer from the robustness degradation effect, in which the defense reduces\nrather than improving the adversarial robustness of a target model in a\nwhite-box setting. A potential cause of this negative effect is that\nadversarial training examples are static and independent to the pre-processing\nmodel. To solve this problem, we investigate the influence of full adversarial\nexamples which are crafted against the full model, and find they indeed have a\npositive impact on the robustness of defenses. Furthermore, we find that simply\nchanging the adversarial training examples in pre-processing methods does not\ncompletely alleviate the robustness degradation effect. This is due to the\nadversarial risk of the pre-processed model being neglected, which is another\ncause of the robustness degradation effect. Motivated by above analyses, we\npropose a method called Joint Adversarial Training based Pre-processing (JATP)\ndefense. Specifically, we formulate a feature similarity based adversarial risk\nfor the pre-processing model by using full adversarial examples found in a\nfeature space. Unlike standard adversarial training, we only update the\npre-processing model, which prompts us to introduce a pixel-wise loss to\nimprove its cross-model transferability. We then conduct a joint adversarial\ntraining on the pre-processing model to minimize this overall risk. Empirical\nresults show that our method could effectively mitigate the robustness\ndegradation effect across different target models in comparison to previous\nstate-of-the-art approaches.",
          "link": "http://arxiv.org/abs/2106.05453",
          "publishedOn": "2021-06-11T01:42:14.385Z",
          "wordCount": 705,
          "title": "Improving White-box Robustness of Pre-processing Defenses via Joint Adversarial Training. (arXiv:2106.05453v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05390",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hurtado_J/0/1/0/all/0/1\">Julio Hurtado</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raymond_Saez_A/0/1/0/all/0/1\">Alain Raymond-Saez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soto_A/0/1/0/all/0/1\">Alvaro Soto</a>",
          "description": "When learning tasks over time, artificial neural networks suffer from a\nproblem known as Catastrophic Forgetting (CF). This happens when the weights of\na network are overwritten during the training of a new task causing forgetting\nof old information. To address this issue, we propose MetA Reusable Knowledge\nor MARK, a new method that fosters weight reusability instead of overwriting\nwhen learning a new task. Specifically, MARK keeps a set of shared weights\namong tasks. We envision these shared weights as a common Knowledge Base (KB)\nthat is not only used to learn new tasks, but also enriched with new knowledge\nas the model learns new tasks. Key components behind MARK are two-fold. On the\none hand, a metalearning approach provides the key mechanism to incrementally\nenrich the KB with new knowledge and to foster weight reusability among tasks.\nOn the other hand, a set of trainable masks provides the key mechanism to\nselectively choose from the KB relevant weights to solve each task. By using\nMARK, we achieve state of the art results in several popular benchmarks,\nsurpassing the best performing methods in terms of average accuracy by over 10%\non the 20-Split-MiniImageNet dataset, while achieving almost zero forgetfulness\nusing 55% of the number of parameters. Furthermore, an ablation study provides\nevidence that, indeed, MARK is learning reusable knowledge that is selectively\nused by each task.",
          "link": "http://arxiv.org/abs/2106.05390",
          "publishedOn": "2021-06-11T01:42:14.378Z",
          "wordCount": 655,
          "title": "Optimizing Reusable Knowledge for Continual Learning via Metalearning. (arXiv:2106.05390v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05304",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Goyal_A/0/1/0/all/0/1\">Ankit Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Law_H/0/1/0/all/0/1\">Hei Law</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bowei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Newell_A/0/1/0/all/0/1\">Alejandro Newell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1\">Jia Deng</a>",
          "description": "Processing point cloud data is an important component of many real-world\nsystems. As such, a wide variety of point-based approaches have been proposed,\nreporting steady benchmark improvements over time. We study the key ingredients\nof this progress and uncover two critical results. First, we find that\nauxiliary factors like different evaluation schemes, data augmentation\nstrategies, and loss functions, which are independent of the model\narchitecture, make a large difference in performance. The differences are large\nenough that they obscure the effect of architecture. When these factors are\ncontrolled for, PointNet++, a relatively older network, performs competitively\nwith recent methods. Second, a very simple projection-based method, which we\nrefer to as SimpleView, performs surprisingly well. It achieves on par or\nbetter results than sophisticated state-of-the-art methods on ModelNet40 while\nbeing half the size of PointNet++. It also outperforms state-of-the-art methods\non ScanObjectNN, a real-world point cloud benchmark, and demonstrates better\ncross-dataset generalization. Code is available at\nhttps://github.com/princeton-vl/SimpleView.",
          "link": "http://arxiv.org/abs/2106.05304",
          "publishedOn": "2021-06-11T01:42:14.372Z",
          "wordCount": 605,
          "title": "Revisiting Point Cloud Shape Classification with a Simple and Effective Baseline. (arXiv:2106.05304v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05528",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zuxuan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weng_Z/0/1/0/all/0/1\">Zejia Weng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jingjing Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_G/0/1/0/all/0/1\">Guo-Jun Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yu-Gang Jiang</a>",
          "description": "Unsupervised domain adaptation (UDA) aims to transfer knowledge learned from\na fully-labeled source domain to a different unlabeled target domain. Most\nexisting UDA methods learn domain-invariant feature representations by\nminimizing feature distances across domains. In this work, we build upon\ncontrastive self-supervised learning to align features so as to reduce the\ndomain discrepancy between training and testing sets. Exploring the same set of\ncategories shared by both domains, we introduce a simple yet effective\nframework CDCL, for domain alignment. In particular, given an anchor image from\none domain, we minimize its distances to cross-domain samples from the same\nclass relative to those from different categories. Since target labels are\nunavailable, we use a clustering-based approach with carefully initialized\ncenters to produce pseudo labels. In addition, we demonstrate that CDCL is a\ngeneral framework and can be adapted to the data-free setting, where the source\ndata are unavailable during training, with minimal modification. We conduct\nexperiments on two widely used domain adaptation benchmarks, i.e., Office-31\nand VisDA-2017, and demonstrate that CDCL achieves state-of-the-art performance\non both datasets.",
          "link": "http://arxiv.org/abs/2106.05528",
          "publishedOn": "2021-06-11T01:42:14.361Z",
          "wordCount": 615,
          "title": "Cross-domain Contrastive Learning for Unsupervised Domain Adaptation. (arXiv:2106.05528v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05375",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vidanapathirana_M/0/1/0/all/0/1\">Madhawa Vidanapathirana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qirui Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Furukawa_Y/0/1/0/all/0/1\">Yasutaka Furukawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_A/0/1/0/all/0/1\">Angel X. Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Savva_M/0/1/0/all/0/1\">Manolis Savva</a>",
          "description": "We address the task of converting a floorplan and a set of associated photos\nof a residence into a textured 3D mesh model, a task which we call Plan2Scene.\nOur system 1) lifts a floorplan image to a 3D mesh model; 2) synthesizes\nsurface textures based on the input photos; and 3) infers textures for\nunobserved surfaces using a graph neural network architecture. To train and\nevaluate our system we create indoor surface texture datasets, and augment a\ndataset of floorplans and photos from prior work with rectified surface crops\nand additional annotations. Our approach handles the challenge of producing\ntileable textures for dominant surfaces such as floors, walls, and ceilings\nfrom a sparse set of unaligned photos that only partially cover the residence.\nQualitative and quantitative evaluations show that our system produces\nrealistic 3D interior models, outperforming baseline approaches on a suite of\ntexture quality metrics and as measured by a holistic user study.",
          "link": "http://arxiv.org/abs/2106.05375",
          "publishedOn": "2021-06-11T01:42:14.352Z",
          "wordCount": 605,
          "title": "Plan2Scene: Converting Floorplans to 3D Scenes. (arXiv:2106.05375v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05316",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mozaffari_M/0/1/0/all/0/1\">M. Hamed Mozaffari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tay_L/0/1/0/all/0/1\">Li-Lin Tay</a>",
          "description": "Recently, the combination of robust one-dimensional convolutional neural\nnetworks (1-D CNNs) and Raman spectroscopy has shown great promise in rapid\nidentification of unknown substances with good accuracy. Using this technique,\nresearchers can recognize a pure compound and distinguish it from unknown\nsubstances in a mixture. The novelty of this approach is that the trained\nneural network operates automatically without any pre- or post-processing of\ndata. Some studies have attempted to extend this technique to the\nclassification of pure compounds in an unknown mixture. However, the\napplication of 1-D CNNs has typically been restricted to binary classifications\nof pure compounds. Here we will highlight a new approach in spectral\nrecognition and quantification of chemical components in a multicomponent\nmixture. Two 1-D CNN models, RaMixNet I and II, have been developed for this\npurpose. The former is for rapid classification of components in a mixture\nwhile the latter is for quantitative determination of those constituents. In\nthe proposed method, there is no limit to the number of compounds in a mixture.\nA data augmentation method is also introduced by adding random baselines to the\nRaman spectra. The experimental results revealed that the classification\naccuracy of RaMixNet I and II is 100% for analysis of unknown test mixtures; at\nthe same time, the RaMixNet II model may achieve a regression accuracy of 88%\nfor the quantification of each component.",
          "link": "http://arxiv.org/abs/2106.05316",
          "publishedOn": "2021-06-11T01:42:14.343Z",
          "wordCount": 683,
          "title": "Raman spectral analysis of mixtures with one-dimensional convolutional neural network. (arXiv:2106.05316v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05542",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jung_E/0/1/0/all/0/1\">Eun-Soo Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Son_H/0/1/0/all/0/1\">HyeongGwan Son</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_K/0/1/0/all/0/1\">Kyusam Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yun_Y/0/1/0/all/0/1\">Yongkeun Yun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwon_S/0/1/0/all/0/1\">Soonhwan Kwon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Min Soo Kim</a>",
          "description": "We present a novel deep neural model for text detection in document images.\nFor robust text detection in noisy scanned documents, the advantages of\nmulti-task learning are adopted by adding an auxiliary task of text\nenhancement. Namely, our proposed model is designed to perform noise reduction\nand text region enhancement as well as text detection. Moreover, we enrich the\ntraining data for the model with synthesized document images that are fully\nlabeled for text detection and enhancement, thus overcome the insufficiency of\nlabeled document image data. For the effective exploitation of the synthetic\nand real data, the training process is separated in two phases. The first phase\nis training only synthetic data in a fully-supervised manner. Then real data\nwith only detection labels are added in the second phase. The enhancement task\nfor the real data is weakly-supervised with information from their detection\nlabels. Our methods are demonstrated in a real document dataset with\nperformances exceeding those of other text detection methods. Moreover,\nablations are conducted and the results confirm the effectiveness of the\nsynthetic data, auxiliary task, and weak-supervision. Whereas the existing text\ndetection studies mostly focus on the text in scenes, our proposed method is\noptimized to the applications for the text in scanned documents.",
          "link": "http://arxiv.org/abs/2106.05542",
          "publishedOn": "2021-06-11T01:42:14.317Z",
          "wordCount": 668,
          "title": "DUET: Detection Utilizing Enhancement for Text in Scanned or Captured Documents. (arXiv:2106.05542v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05525",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jonmohamadi_Y/0/1/0/all/0/1\">Yaqub Jonmohamadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ali_S/0/1/0/all/0/1\">Shahnewaz Ali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fengbei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roberts_J/0/1/0/all/0/1\">Jonathan Roberts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crawford_R/0/1/0/all/0/1\">Ross Crawford</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carneiro_G/0/1/0/all/0/1\">Gustavo Carneiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pandey_A/0/1/0/all/0/1\">Ajay K. Pandey</a>",
          "description": "Minimally invasive surgery (MIS) has many documented advantages, but the\nsurgeon's limited visual contact with the scene can be problematic. Hence,\nsystems that can help surgeons navigate, such as a method that can produce a 3D\nsemantic map, can compensate for the limitation above. In theory, we can borrow\n3D semantic mapping techniques developed for robotics, but this requires\nfinding solutions to the following challenges in MIS: 1) semantic segmentation,\n2) depth estimation, and 3) pose estimation. In this paper, we propose the\nfirst 3D semantic mapping system from knee arthroscopy that solves the three\nchallenges above. Using out-of-distribution non-human datasets, where pose\ncould be labeled, we jointly train depth+pose estimators using selfsupervised\nand supervised losses. Using an in-distribution human knee dataset, we train a\nfully-supervised semantic segmentation system to label arthroscopic image\npixels into femur, ACL, and meniscus. Taking testing images from human knees,\nwe combine the results from these two systems to automatically create 3D\nsemantic maps of the human knee. The result of this work opens the pathway to\nthe generation of intraoperative 3D semantic mapping, registration with\npre-operative data, and robotic-assisted arthroscopy",
          "link": "http://arxiv.org/abs/2106.05525",
          "publishedOn": "2021-06-11T01:42:14.270Z",
          "wordCount": 634,
          "title": "3D Semantic Mapping from Arthroscopy using Out-of-distribution Pose and Depth and In-distribution Segmentation Training. (arXiv:2106.05525v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05430",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xin Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_W/0/1/0/all/0/1\">Won Hwa Kim</a>",
          "description": "Clustering algorithms have significantly improved along with Deep Neural\nNetworks which provide effective representation of data. Existing methods are\nbuilt upon deep autoencoder and self-training process that leverages the\ndistribution of cluster assignments of samples. However, as the fundamental\nobjective of the autoencoder is focused on efficient data reconstruction, the\nlearnt space may be sub-optimal for clustering. Moreover, it requires highly\neffective codes (i.e., representation) of data, otherwise the initial cluster\ncenters often cause stability issues during self-training. Many\nstate-of-the-art clustering algorithms use convolution operation to extract\nefficient codes but their applications are limited to image data. In this\nregard, we propose an end-to-end deep clustering algorithm, i.e., Very Compact\nClusters (VCC), for the general datasets, which takes advantage of\ndistributions of local relationships of samples near the boundary of clusters,\nso that they can be properly separated and pulled to cluster centers to form\ncompact clusters. Experimental results on various datasets illustrate that our\nproposed approach achieves better clustering performance over most of the\nstate-of-the-art clustering methods, and the data embeddings learned by VCC\nwithout convolution for image data are even comparable with specialized\nconvolutional methods.",
          "link": "http://arxiv.org/abs/2106.05430",
          "publishedOn": "2021-06-11T01:42:14.242Z",
          "wordCount": 637,
          "title": "Very Compact Clusters with Structural Regularization via Similarity and Connectivity. (arXiv:2106.05430v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05308",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Arnold_E/0/1/0/all/0/1\">Eduardo Arnold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mozaffari_S/0/1/0/all/0/1\">Sajjad Mozaffari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dianati_M/0/1/0/all/0/1\">Mehrdad Dianati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jennings_P/0/1/0/all/0/1\">Paul Jennings</a>",
          "description": "Visual Sensor Networks can be used in a variety of perception applications\nsuch as infrastructure support for autonomous driving in complex road segments.\nThe pose of the sensors in such networks directly determines the coverage of\nthe environment and objects therein, which impacts the performance of\napplications such as object detection and tracking. Existing sensor pose\noptimisation methods in the literature either maximise the coverage of ground\nsurfaces, or consider the visibility of the target objects as binary variables,\nwhich cannot represent various degrees of visibility. Such formulations cannot\nguarantee the visibility of the target objects as they fail to consider\nocclusions. This paper proposes two novel sensor pose optimisation methods,\nbased on gradient-ascent and Integer Programming techniques, which maximise the\nvisibility of multiple target objects in cluttered environments. Both methods\nconsider a realistic visibility model based on a rendering engine that provides\npixel-level visibility information about the target objects. The proposed\nmethods are evaluated in a complex environment and compared to existing methods\nin the literature. The evaluation results indicate that explicitly modelling\nthe visibility of target objects is critical to avoid occlusions in cluttered\nenvironments. Furthermore, both methods significantly outperform existing\nmethods in terms of object visibility.",
          "link": "http://arxiv.org/abs/2106.05308",
          "publishedOn": "2021-06-11T01:42:14.235Z",
          "wordCount": 647,
          "title": "Visual Sensor Pose Optimisation Using Rendering-based Visibility Models for Robust Cooperative Perception. (arXiv:2106.05308v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05441",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_P/0/1/0/all/0/1\">Pengyu Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamasaki_T/0/1/0/all/0/1\">Toshihiko Yamasaki</a>",
          "description": "Unsupervised video-based person re-identification (re-ID) methods extract\nricher features from video tracklets than image-based ones. The\nstate-of-the-art methods utilize clustering to obtain pseudo-labels and train\nthe models iteratively. However, they underestimate the influence of two kinds\nof frames in the tracklet: 1) noise frames caused by detection errors or heavy\nocclusions exist in the tracklet, which may be allocated with unreliable labels\nduring clustering; 2) the tracklet also contains hard frames caused by pose\nchanges or partial occlusions, which are difficult to distinguish but\ninformative. This paper proposes a Noise and Hard frame Aware Clustering (NHAC)\nmethod. NHAC consists of a graph trimming module and a node re-sampling module.\nThe graph trimming module obtains stable graphs by removing noise frame nodes\nto improve the clustering accuracy. The node re-sampling module enhances the\ntraining of hard frame nodes to learn rich tracklet information. Experiments\nconducted on two video-based datasets demonstrate the effectiveness of the\nproposed NHAC under the unsupervised re-ID setting.",
          "link": "http://arxiv.org/abs/2106.05441",
          "publishedOn": "2021-06-11T01:42:14.230Z",
          "wordCount": 600,
          "title": "Unsupervised Video Person Re-identification via Noise and Hard frame Aware Clustering. (arXiv:2106.05441v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05487",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1\">Khoa Tuan Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jang_G/0/1/0/all/0/1\">Ganghee Jang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeong_W/0/1/0/all/0/1\">Won-ki Jeong</a>",
          "description": "The segmentation of nanoscale electron microscopy (EM) images is crucial but\nchallenging in connectomics. Recent advances in deep learning have demonstrated\nthe significant potential of automatic segmentation for tera-scale EM images.\nHowever, none of the existing segmentation methods are error-free, and they\nrequire proofreading, which is typically implemented as an interactive,\nsemi-automatic process via manual intervention. Herein, we propose a fully\nautomatic proofreading method based on reinforcement learning. The main idea is\nto model the human decision process in proofreading using a reinforcement agent\nto achieve fully automatic proofreading. We systematically design the proposed\nsystem by combining multiple reinforcement learning agents in a hierarchical\nmanner, where each agent focuses only on a specific task while preserving\ndependency between agents. Furthermore, we also demonstrate that the episodic\ntask setting of reinforcement learning can efficiently manage a combination of\nmerge and split errors concurrently presented in the input. We demonstrate the\nefficacy of the proposed system by comparing it with state-of-the-art\nproofreading methods using various testing examples.",
          "link": "http://arxiv.org/abs/2106.05487",
          "publishedOn": "2021-06-11T01:42:14.186Z",
          "wordCount": 597,
          "title": "RLCorrector: Reinforced Proofreading for Connectomics Image Segmentation. (arXiv:2106.05487v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05437",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bujimalla_S/0/1/0/all/0/1\">Shashank Bujimalla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Subedar_M/0/1/0/all/0/1\">Mahesh Subedar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tickoo_O/0/1/0/all/0/1\">Omesh Tickoo</a>",
          "description": "In this paper, we study the impact of motion blur, a common quality flaw in\nreal world images, on a state-of-the-art two-stage image captioning solution,\nand notice a degradation in solution performance as blur intensity increases.\nWe investigate techniques to improve the robustness of the solution to motion\nblur using training data augmentation at each or both stages of the solution,\ni.e., object detection and captioning, and observe improved results. In\nparticular, augmenting both the stages reduces the CIDEr-D degradation for high\nmotion blur intensity from 68.7 to 11.7 on MS COCO dataset, and from 22.4 to\n6.8 on Vizwiz dataset.",
          "link": "http://arxiv.org/abs/2106.05437",
          "publishedOn": "2021-06-11T01:42:14.147Z",
          "wordCount": 539,
          "title": "Data augmentation to improve robustness of image captioning solutions. (arXiv:2106.05437v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01981",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Oreshkin_B/0/1/0/all/0/1\">Boris N. Oreshkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bocquelet_F/0/1/0/all/0/1\">Florent Bocquelet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harvey_F/0/1/0/all/0/1\">F&#xe9;lix G. Harvey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raitt_B/0/1/0/all/0/1\">Bay Raitt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laflamme_D/0/1/0/all/0/1\">Dominic Laflamme</a>",
          "description": "Our work focuses on the development of a learnable neural representation of\nhuman pose for advanced AI assisted animation tooling. Specifically, we tackle\nthe problem of constructing a full static human pose based on sparse and\nvariable user inputs (e.g. locations and/or orientations of a subset of body\njoints). To solve this problem, we propose a novel neural architecture that\ncombines residual connections with prototype encoding of a partially specified\npose to create a new complete pose from the learned latent space. We show that\nour architecture outperforms a baseline based on Transformer, both in terms of\naccuracy and computational efficiency. Additionally, we develop a user\ninterface to integrate our neural model in Unity, a real-time 3D development\nplatform. Furthermore, we introduce two new datasets representing the static\nhuman pose modeling problem, based on high-quality human motion capture data,\nwhich will be released publicly along with model code.",
          "link": "http://arxiv.org/abs/2106.01981",
          "publishedOn": "2021-06-10T22:40:40.536Z",
          "wordCount": 609,
          "title": "ProtoRes: Proto-Residual Architecture for Deep Modeling of Human Pose. (arXiv:2106.01981v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01927",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1\">Ao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Haoyuan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hechen Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1\">Peng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1\">Weiming Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wanli Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_S/0/1/0/all/0/1\">Shuojia Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grzegorzek_M/0/1/0/all/0/1\">Marcin Grzegorzek</a>",
          "description": "Image classification has achieved unprecedented advance with the the rapid\ndevelopment of deep learning. However, the classification of tiny object images\nis still not well investigated. In this paper, we first briefly review the\ndevelopment of Convolutional Neural Network and Visual Transformer in deep\nlearning, and introduce the sources and development of conventional noises and\nadversarial attacks. Then we use various models of Convolutional Neural Network\nand Visual Transformer to conduct a series of experiments on the image dataset\nof tiny objects (sperms and impurities), and compare various evaluation metrics\nin the experimental results to obtain a model with stable performance. Finally,\nwe discuss the problems in the classification of tiny objects and make a\nprospect for the classification of tiny objects in the future.",
          "link": "http://arxiv.org/abs/2106.01927",
          "publishedOn": "2021-06-10T22:40:40.506Z",
          "wordCount": 616,
          "title": "A Comparison for Anti-noise Robustness of Deep Learning Classification Methods on a Tiny Object Image Dataset: from Convolutional Neural Network to Visual Transformer and Performer. (arXiv:2106.01927v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04619",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kugelgen_J/0/1/0/all/0/1\">Julius von K&#xfc;gelgen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sharma_Y/0/1/0/all/0/1\">Yash Sharma</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gresele_L/0/1/0/all/0/1\">Luigi Gresele</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Brendel_W/0/1/0/all/0/1\">Wieland Brendel</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Scholkopf_B/0/1/0/all/0/1\">Bernhard Sch&#xf6;lkopf</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Besserve_M/0/1/0/all/0/1\">Michel Besserve</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Locatello_F/0/1/0/all/0/1\">Francesco Locatello</a>",
          "description": "Self-supervised representation learning has shown remarkable success in a\nnumber of domains. A common practice is to perform data augmentation via\nhand-crafted transformations intended to leave the semantics of the data\ninvariant. We seek to understand the empirical success of this approach from a\ntheoretical perspective. We formulate the augmentation process as a latent\nvariable model by postulating a partition of the latent representation into a\ncontent component, which is assumed invariant to augmentation, and a style\ncomponent, which is allowed to change. Unlike prior work on disentanglement and\nindependent component analysis, we allow for both nontrivial statistical and\ncausal dependencies in the latent space. We study the identifiability of the\nlatent representation based on pairs of views of the observations and prove\nsufficient conditions that allow us to identify the invariant content partition\nup to an invertible mapping in both generative and discriminative settings. We\nfind numerical simulations with dependent latent variables are consistent with\nour theory. Lastly, we introduce Causal3DIdent, a dataset of high-dimensional,\nvisually complex images with rich causal dependencies, which we use to study\nthe effect of data augmentations performed in practice.",
          "link": "http://arxiv.org/abs/2106.04619",
          "publishedOn": "2021-06-10T01:56:49.433Z",
          "wordCount": 637,
          "title": "Self-Supervised Learning with Data Augmentations Provably Isolates Content from Style. (arXiv:2106.04619v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04630",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_R/0/1/0/all/0/1\">Rongmei Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jie Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zalmout_N/0/1/0/all/0/1\">Nasser Zalmout</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_L/0/1/0/all/0/1\">Li Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1\">Xin Luna Dong</a>",
          "description": "Understanding product attributes plays an important role in improving online\nshopping experience for customers and serves as an integral part for\nconstructing a product knowledge graph. Most existing methods focus on\nattribute extraction from text description or utilize visual information from\nproduct images such as shape and color. Compared to the inputs considered in\nprior works, a product image in fact contains more information, represented by\na rich mixture of words and visual clues with a layout carefully designed to\nimpress customers. This work proposes a more inclusive framework that fully\nutilizes these different modalities for attribute extraction. Inspired by\nrecent works in visual question answering, we use a transformer based sequence\nto sequence model to fuse representations of product text, Optical Character\nRecognition (OCR) tokens and visual objects detected in the product image. The\nframework is further extended with the capability to extract attribute value\nacross multiple product categories with a single model, by training the decoder\nto predict both product category and attribute value and conditioning its\noutput on product category. The model provides a unified attribute extraction\nsolution desirable at an e-commerce platform that offers numerous product\ncategories with a diverse body of product attributes. We evaluated the model on\ntwo product attributes, one with many possible values and one with a small set\nof possible values, over 14 product categories and found the model could\nachieve 15% gain on the Recall and 10% gain on the F1 score compared to\nexisting methods using text-only features.",
          "link": "http://arxiv.org/abs/2106.04630",
          "publishedOn": "2021-06-10T01:56:48.964Z",
          "wordCount": null,
          "title": "PAM: Understanding Product Images in Cross Product Category Attribute Extraction. (arXiv:2106.04630v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04632",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Linjie Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_J/0/1/0/all/0/1\">Jie Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_Z/0/1/0/all/0/1\">Zhe Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1\">Licheng Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yen-Chun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pillai_R/0/1/0/all/0/1\">Rohit Pillai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1\">Yu Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1\">Luowei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Eric Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berg_T/0/1/0/all/0/1\">Tamara Lee Berg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jingjing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lijuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zicheng Liu</a>",
          "description": "Most existing video-and-language (VidL) research focuses on a single dataset,\nor multiple datasets of a single task. In reality, a truly useful VidL system\nis expected to be easily generalizable to diverse tasks, domains, and datasets.\nTo facilitate the evaluation of such systems, we introduce Video-And-Language\nUnderstanding Evaluation (VALUE) benchmark, an assemblage of 11 VidL datasets\nover 3 popular tasks: (i) text-to-video retrieval; (ii) video question\nanswering; and (iii) video captioning. VALUE benchmark aims to cover a broad\nrange of video genres, video lengths, data volumes, and task difficulty levels.\nRather than focusing on single-channel videos with visual information only,\nVALUE promotes models that leverage information from both video frames and\ntheir associated subtitles, as well as models that share knowledge across\nmultiple tasks. We evaluate various baseline methods with and without\nlarge-scale VidL pre-training, and systematically investigate the impact of\nvideo input channels, fusion methods, and different video representations. We\nalso study the transferability between tasks, and conduct multi-task learning\nunder different settings. The significant gap between our best model and human\nperformance calls for future study for advanced VidL models. VALUE is available\nat https://value-leaderboard.github.io/.",
          "link": "http://arxiv.org/abs/2106.04632",
          "publishedOn": "2021-06-10T01:56:48.467Z",
          "wordCount": 656,
          "title": "VALUE: A Multi-Task Benchmark for Video-and-Language Understanding Evaluation. (arXiv:2106.04632v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2102.05095",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bertasius_G/0/1/0/all/0/1\">Gedas Bertasius</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Heng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torresani_L/0/1/0/all/0/1\">Lorenzo Torresani</a>",
          "description": "We present a convolution-free approach to video classification built\nexclusively on self-attention over space and time. Our method, named\n\"TimeSformer,\" adapts the standard Transformer architecture to video by\nenabling spatiotemporal feature learning directly from a sequence of\nframe-level patches. Our experimental study compares different self-attention\nschemes and suggests that \"divided attention,\" where temporal attention and\nspatial attention are separately applied within each block, leads to the best\nvideo classification accuracy among the design choices considered. Despite the\nradically new design, TimeSformer achieves state-of-the-art results on several\naction recognition benchmarks, including the best reported accuracy on\nKinetics-400 and Kinetics-600. Finally, compared to 3D convolutional networks,\nour model is faster to train, it can achieve dramatically higher test\nefficiency (at a small drop in accuracy), and it can also be applied to much\nlonger video clips (over one minute long). Code and models are available at:\nhttps://github.com/facebookresearch/TimeSformer.",
          "link": "http://arxiv.org/abs/2102.05095",
          "publishedOn": "2021-06-10T01:56:47.382Z",
          "wordCount": 628,
          "title": "Is Space-Time Attention All You Need for Video Understanding?. (arXiv:2102.05095v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.10472",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wortsman_M/0/1/0/all/0/1\">Mitchell Wortsman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Horton_M/0/1/0/all/0/1\">Maxwell Horton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guestrin_C/0/1/0/all/0/1\">Carlos Guestrin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farhadi_A/0/1/0/all/0/1\">Ali Farhadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rastegari_M/0/1/0/all/0/1\">Mohammad Rastegari</a>",
          "description": "Recent observations have advanced our understanding of the neural network\noptimization landscape, revealing the existence of (1) paths of high accuracy\ncontaining diverse solutions and (2) wider minima offering improved\nperformance. Previous methods observing diverse paths require multiple training\nruns. In contrast we aim to leverage both property (1) and (2) with a single\nmethod and in a single training run. With a similar computational cost as\ntraining one model, we learn lines, curves, and simplexes of high-accuracy\nneural networks. These neural network subspaces contain diverse solutions that\ncan be ensembled, approaching the ensemble performance of independently trained\nnetworks without the training cost. Moreover, using the subspace midpoint\nboosts accuracy, calibration, and robustness to label noise, outperforming\nStochastic Weight Averaging.",
          "link": "http://arxiv.org/abs/2102.10472",
          "publishedOn": "2021-06-10T01:56:47.325Z",
          "wordCount": 575,
          "title": "Learning Neural Network Subspaces. (arXiv:2102.10472v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.12109",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xia_M/0/1/0/all/0/1\">Menghan Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1\">Chu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_T/0/1/0/all/0/1\">Tien-Tsin Wong</a>",
          "description": "As a generic modeling tool, Convolutional Neural Networks (CNNs) have been\nwidely employed in image generation and translation tasks. However, when fed\nwith a flat input, current CNN models may fail to generate vivid results due to\nthe spatially shared convolution kernels. We call it the flatness degradation\nof CNNs. Unfortunately, such degradation is the greatest obstacles to generate\na spatially-variant output from a flat input, which has been barely discussed\nin the previous literature. To tackle this problem, we propose a model agnostic\nsolution, i.e. Noise Incentive Block (NIB), which serves as a generic plug-in\nfor any CNN generation model. The key idea is to break the flat input condition\nwhile keeping the intactness of the original information. Specifically, the NIB\nperturbs the input data symmetrically with a noise map and reassembles them in\nthe feature domain as driven by the objective function. Extensive experiments\nshow that existing CNN models equipped with NIB survive from the flatness\ndegradation and are able to generate visually better results with richer\ndetails in some specific image generation tasks given flat inputs, e.g.\nsemantic image synthesis, data-hidden image generation, and deep neural\ndithering.",
          "link": "http://arxiv.org/abs/2012.12109",
          "publishedOn": "2021-06-10T01:56:47.319Z",
          "wordCount": 650,
          "title": "Enhance Convolutional Neural Networks with Noise Incentive Block. (arXiv:2012.12109v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04922",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ding_Z/0/1/0/all/0/1\">Zilin Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yuhang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1\">Xuan Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaomin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Ming Liu</a>",
          "description": "Self-supervised learning, which benefits from automatically constructing\nlabels through pre-designed pretext task, has recently been applied for\nstrengthen supervised learning. Since previous self-supervised pretext tasks\nare based on input, they may incur huge additional training overhead. In this\npaper we find that features in CNNs can be also used for self-supervision. Thus\nwe creatively design the \\emph{feature-based pretext task} which requires only\na small amount of additional training overhead. In our task we discard\ndifferent particular regions of features, and then train the model to\ndistinguish these different features. In order to fully apply our feature-based\npretext task in supervised learning, we also propose a novel learning framework\ncontaining multi-classifiers for further improvement. Original labels will be\nexpanded to joint labels via self-supervision of feature transformations. With\nmore semantic information provided by our self-supervised tasks, this approach\ncan train CNNs more effectively. Extensive experiments on various supervised\nlearning tasks demonstrate the accuracy improvement and wide applicability of\nour method.",
          "link": "http://arxiv.org/abs/2106.04922",
          "publishedOn": "2021-06-10T01:56:47.312Z",
          "wordCount": 598,
          "title": "Self-supervision of Feature Transformation for Further Improving Supervised Learning. (arXiv:2106.04922v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05238",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Willetts_M/0/1/0/all/0/1\">Matthew Willetts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paige_B/0/1/0/all/0/1\">Brooks Paige</a>",
          "description": "In this work we introduce a new approach for identifiable non-linear ICA\nmodels. Recently there has been a renaissance in identifiability results in\ndeep generative models, not least for non-linear ICA. These prior works,\nhowever, have assumed access to a sufficiently-informative auxiliary set of\nobservations, denoted $\\mathbf{u}$. We show here how identifiability can be\nobtained in the absence of this side-information, rendering possible\nfully-unsupervised identifiable non-linear ICA. While previous theoretical\nresults have established the impossibility of identifiable non-linear ICA in\nthe presence of infinitely-flexible universal function approximators, here we\nrely on the intrinsically-finite modelling capacity of any particular chosen\nparameterisation of a deep generative model. In particular, we focus on\ngenerative models which perform clustering in their latent space -- a model\nstructure which matches previous identifiable models, but with the learnt\nclustering providing a synthetic form of auxiliary information. We evaluate our\nproposals using VAEs, on synthetic and image datasets, and find that the\nlearned clusterings function effectively: deep generative models with latent\nclusterings are empirically identifiable, to the same degree as models which\nrely on side information.",
          "link": "http://arxiv.org/abs/2106.05238",
          "publishedOn": "2021-06-10T01:56:47.306Z",
          "wordCount": 620,
          "title": "I Don't Need $\\mathbf{u}$: Identifiable Non-Linear ICA Without Side Information. (arXiv:2106.05238v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2101.11228",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Teepe_T/0/1/0/all/0/1\">Torben Teepe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1\">Ali Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gilg_J/0/1/0/all/0/1\">Johannes Gilg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Herzog_F/0/1/0/all/0/1\">Fabian Herzog</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hormann_S/0/1/0/all/0/1\">Stefan H&#xf6;rmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rigoll_G/0/1/0/all/0/1\">Gerhard Rigoll</a>",
          "description": "Gait recognition is a promising video-based biometric for identifying\nindividual walking patterns from a long distance. At present, most gait\nrecognition methods use silhouette images to represent a person in each frame.\nHowever, silhouette images can lose fine-grained spatial information, and most\npapers do not regard how to obtain these silhouettes in complex scenes.\nFurthermore, silhouette images contain not only gait features but also other\nvisual clues that can be recognized. Hence these approaches can not be\nconsidered as strict gait recognition.\n\nWe leverage recent advances in human pose estimation to estimate robust\nskeleton poses directly from RGB images to bring back model-based gait\nrecognition with a cleaner representation of gait. Thus, we propose GaitGraph\nthat combines skeleton poses with Graph Convolutional Network (GCN) to obtain a\nmodern model-based approach for gait recognition. The main advantages are a\ncleaner, more elegant extraction of the gait features and the ability to\nincorporate powerful spatio-temporal modeling using GCN. Experiments on the\npopular CASIA-B gait dataset show that our method archives state-of-the-art\nperformance in model-based gait recognition.\n\nThe code and models are publicly available.",
          "link": "http://arxiv.org/abs/2101.11228",
          "publishedOn": "2021-06-10T01:56:47.287Z",
          "wordCount": 648,
          "title": "GaitGraph: Graph Convolutional Network for Skeleton-Based Gait Recognition. (arXiv:2101.11228v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05214",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Marimont_S/0/1/0/all/0/1\">Sergio Naval Marimont</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tarroni_G/0/1/0/all/0/1\">Giacomo Tarroni</a>",
          "description": "We propose a novel unsupervised out-of-distribution detection method for\nmedical images based on implicit fields image representations. In our approach,\nan auto-decoder feed-forward neural network learns the distribution of healthy\nimages in the form of a mapping between spatial coordinates and probabilities\nover a proxy for tissue types. At inference time, the learnt distribution is\nused to retrieve, from a given test image, a restoration, i.e. an image\nmaximally consistent with the input one but belonging to the healthy\ndistribution. Anomalies are localized using the voxel-wise probability\npredicted by our model for the restored image. We tested our approach in the\ntask of unsupervised localization of gliomas on brain MR images and compared it\nto several other VAE-based anomaly detection methods. Results show that the\nproposed technique substantially outperforms them (average DICE 0.640 vs 0.518\nfor the best performing VAE-based alternative) while also requiring\nconsiderably less computing time.",
          "link": "http://arxiv.org/abs/2106.05214",
          "publishedOn": "2021-06-10T01:56:47.280Z",
          "wordCount": 603,
          "title": "Implicit field learning for unsupervised anomaly detection in medical images. (arXiv:2106.05214v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05187",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yifan_W/0/1/0/all/0/1\">Wang Yifan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahmann_L/0/1/0/all/0/1\">Lukas Rahmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sorkine_Hornung_O/0/1/0/all/0/1\">Olga Sorkine-Hornung</a>",
          "description": "We present implicit displacement fields, a novel representation for detailed\n3D geometry. Inspired by a classic surface deformation technique, displacement\nmapping, our method represents a complex surface as a smooth base surface plus\na displacement along the base's normal directions, resulting in a\nfrequency-based shape decomposition, where the high frequency signal is\nconstrained geometrically by the low frequency signal. Importantly, this\ndisentanglement is unsupervised thanks to a tailored architectural design that\nhas an innate frequency hierarchy by construction. We explore implicit\ndisplacement field surface reconstruction and detail transfer and demonstrate\nsuperior representational power, training stability and generalizability.",
          "link": "http://arxiv.org/abs/2106.05187",
          "publishedOn": "2021-06-10T01:56:47.266Z",
          "wordCount": 539,
          "title": "Geometry-Consistent Neural Shape Representation with Implicit Displacement Fields. (arXiv:2106.05187v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05124",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cao_S/0/1/0/all/0/1\">Si-Yuan Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1\">Hui-Liang Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_L/0/1/0/all/0/1\">Lun Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Shu-Jie Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chunguang Li</a>",
          "description": "Multispectral and multimodal image processing is important in the community\nof computer vision and computational photography. As the acquired multispectral\nand multimodal data are generally misaligned due to the alternation or movement\nof the image device, the image registration procedure is necessary. The\nregistration of multispectral or multimodal image is challenging due to the\nnon-linear intensity and gradient variation. To cope with this challenge, we\npropose the phase congruency network (PCNet), which is able to enhance the\nstructure similarity and alleviate the non-linear intensity and gradient\nvariation. The images can then be aligned using the similarity enhanced\nfeatures produced by the network. PCNet is constructed under the guidance of\nthe phase congruency prior. The network contains three trainable layers\naccompany with the modified learnable Gabor kernels according to the phase\ncongruency theory. Thanks to the prior knowledge, PCNet is extremely\nlight-weight and can be trained on quite a small amount of multispectral data.\nPCNet can be viewed to be fully convolutional and hence can take input of\narbitrary sizes. Once trained, PCNet is applicable on a variety of\nmultispectral and multimodal data such as RGB/NIR and flash/no-flash images\nwithout additional further tuning. Experimental results validate that PCNet\noutperforms current state-of-the-art registration algorithms, including the\ndeep-learning based ones that have the number of parameters hundreds times\ncompared to PCNet. Thanks to the similarity enhancement training, PCNet\noutperforms the original phase congruency algorithm with two-thirds less\nfeature channels.",
          "link": "http://arxiv.org/abs/2106.05124",
          "publishedOn": "2021-06-10T01:56:47.260Z",
          "wordCount": 682,
          "title": "PCNet: A Structure Similarity Enhancement Method for Multispectral and Multimodal Image Registration. (arXiv:2106.05124v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04919",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Basak_H/0/1/0/all/0/1\">Hritam Basak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kundu_R/0/1/0/all/0/1\">Rohit Kundu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_S/0/1/0/all/0/1\">Sukanta Chakraborty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_N/0/1/0/all/0/1\">Nibaran Das</a>",
          "description": "Cervical cancer is one of the most deadly and common diseases among women\nworldwide. It is completely curable if diagnosed in an early stage, but the\ntedious and costly detection procedure makes it unviable to conduct\npopulation-wise screening. Thus, to augment the effort of the clinicians, in\nthis paper, we propose a fully automated framework that utilizes Deep Learning\nand feature selection using evolutionary optimization for cytology image\nclassification. The proposed framework extracts Deep feature from several\nConvolution Neural Network models and uses a two-step feature reduction\napproach to ensure reduction in computation cost and faster convergence. The\nfeatures extracted from the CNN models form a large feature space whose\ndimensionality is reduced using Principal Component Analysis while preserving\n99% of the variance. A non-redundant, optimal feature subset is selected from\nthis feature space using an evolutionary optimization algorithm, the Grey Wolf\nOptimizer, thus improving the classification performance. Finally, the selected\nfeature subset is used to train an SVM classifier for generating the final\npredictions. The proposed framework is evaluated on three publicly available\nbenchmark datasets: Mendeley Liquid Based Cytology (4-class) dataset, Herlev\nPap Smear (7-class) dataset, and the SIPaKMeD Pap Smear (5-class) dataset\nachieving classification accuracies of 99.47%, 98.32% and 97.87% respectively,\nthus justifying the reliability of the approach. The relevant codes for the\nproposed approach can be found in:\nhttps://github.com/DVLP-CMATERJU/Two-Step-Feature-Enhancement",
          "link": "http://arxiv.org/abs/2106.04919",
          "publishedOn": "2021-06-10T01:56:47.230Z",
          "wordCount": 666,
          "title": "Cervical Cytology Classification Using PCA & GWO Enhanced Deep Features Selection. (arXiv:2106.04919v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04966",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+McCay_K/0/1/0/all/0/1\">Kevin D. McCay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ho_E/0/1/0/all/0/1\">Edmond S. L. Ho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sakkos_D/0/1/0/all/0/1\">Dimitrios Sakkos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woo_W/0/1/0/all/0/1\">Wai Lok Woo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marcroft_C/0/1/0/all/0/1\">Claire Marcroft</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dulson_P/0/1/0/all/0/1\">Patricia Dulson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Embleton_N/0/1/0/all/0/1\">Nicholas D. Embleton</a>",
          "description": "Providing early diagnosis of cerebral palsy (CP) is key to enhancing the\ndevelopmental outcomes for those affected. Diagnostic tools such as the General\nMovements Assessment (GMA), have produced promising results in early diagnosis,\nhowever these manual methods can be laborious.\n\nIn this paper, we propose a new framework for the automated classification of\ninfant body movements, based upon the GMA, which unlike previous methods, also\nincorporates a visualization framework to aid with interpretability. Our\nproposed framework segments extracted features to detect the presence of\nFidgety Movements (FMs) associated with the GMA spatiotemporally. These\nfeatures are then used to identify the body-parts with the greatest\ncontribution towards a classification decision and highlight the related\nbody-part segment providing visual feedback to the user.\n\nWe quantitatively compare the proposed framework's classification performance\nwith several other methods from the literature and qualitatively evaluate the\nvisualization's veracity. Our experimental results show that the proposed\nmethod performs more robustly than comparable techniques in this setting whilst\nsimultaneously providing relevant visual interpretability.",
          "link": "http://arxiv.org/abs/2106.04966",
          "publishedOn": "2021-06-10T01:56:47.164Z",
          "wordCount": 645,
          "title": "Towards Explainable Abnormal Infant Movements Identification: A Body-part Based Prediction and Visualisation Framework. (arXiv:2106.04966v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04989",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lo_Y/0/1/0/all/0/1\">Yi-Chen Lo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_C/0/1/0/all/0/1\">Chia-Che Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiu_H/0/1/0/all/0/1\">Hsuan-Chao Chiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yu-Hao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chia-Ping Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1\">Yu-Lin Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jou_K/0/1/0/all/0/1\">Kevin Jou</a>",
          "description": "In this paper, we present CLCC, a novel contrastive learning framework for\ncolor constancy. Contrastive learning has been applied for learning\nhigh-quality visual representations for image classification. One key aspect to\nyield useful representations for image classification is to design illuminant\ninvariant augmentations. However, the illuminant invariant assumption conflicts\nwith the nature of the color constancy task, which aims to estimate the\nilluminant given a raw image. Therefore, we construct effective contrastive\npairs for learning better illuminant-dependent features via a novel raw-domain\ncolor augmentation. On the NUS-8 dataset, our method provides $17.5\\%$ relative\nimprovements over a strong baseline, reaching state-of-the-art performance\nwithout increasing model complexity. Furthermore, our method achieves\ncompetitive performance on the Gehler dataset with $3\\times$ fewer parameters\ncompared to top-ranking deep learning methods. More importantly, we show that\nour model is more robust to different scenes under close proximity of\nilluminants, significantly reducing $28.7\\%$ worst-case error in data-sparse\nregions.",
          "link": "http://arxiv.org/abs/2106.04989",
          "publishedOn": "2021-06-10T01:56:47.032Z",
          "wordCount": 595,
          "title": "CLCC: Contrastive Learning for Color Constancy. (arXiv:2106.04989v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2012.04830",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaoqing Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hu_Y/0/1/0/all/0/1\">Yan Hu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fang_J/0/1/0/all/0/1\">Jiansheng Fang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_Y/0/1/0/all/0/1\">Yanwu Xu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Higashita_R/0/1/0/all/0/1\">Risa Higashita</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_J/0/1/0/all/0/1\">Jiang Liu</a>",
          "description": "Cataract is one of the leading causes of reversible visual impairment and\nblindness globally. Over the years, researchers have achieved significant\nprogress in developing state-of-the-art artificial intelligence techniques for\nautomatic cataract classification and grading, helping clinicians prevent and\ntreat cataract in time. This paper provides a comprehensive survey of recent\nadvances in machine learning for cataract classification and grading based on\nophthalmic images. We summarize existing literature from two research\ndirections: conventional machine learning techniques and deep learning\ntechniques. This paper also provides insights into existing works of both\nmerits and limitations. In addition, we discuss several challenges of automatic\ncataract classification and grading based on machine learning techniques and\npresent possible solutions to these challenges for future research.",
          "link": "http://arxiv.org/abs/2012.04830",
          "publishedOn": "2021-06-10T01:56:46.805Z",
          "wordCount": 597,
          "title": "Machine Learning for Cataract Classification and Grading on Ophthalmic Imaging Modalities: A Survey. (arXiv:2012.04830v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05109",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Frisch_D/0/1/0/all/0/1\">Daniel Frisch</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hanebeck_U/0/1/0/all/0/1\">Uwe D. Hanebeck</a>",
          "description": "We consider estimating the parameters of a Gaussian mixture density with a\ngiven number of components best representing a given set of weighted samples.\nWe adopt a density interpretation of the samples by viewing them as a discrete\nDirac mixture density over a continuous domain with weighted components. Hence,\nGaussian mixture fitting is viewed as density re-approximation. In order to\nspeed up computation, an expectation-maximization method is proposed that\nproperly considers not only the sample locations, but also the corresponding\nweights. It is shown that methods from literature do not treat the weights\ncorrectly, resulting in wrong estimates. This is demonstrated with simple\ncounterexamples. The proposed method works in any number of dimensions with the\nsame computational load as standard Gaussian mixture estimators for unweighted\nsamples.",
          "link": "http://arxiv.org/abs/2106.05109",
          "publishedOn": "2021-06-10T01:56:46.754Z",
          "wordCount": 566,
          "title": "Gaussian Mixture Estimation from Weighted Samples. (arXiv:2106.05109v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05264",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Arandjelovic_R/0/1/0/all/0/1\">Relja Arandjelovi&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zisserman_A/0/1/0/all/0/1\">Andrew Zisserman</a>",
          "description": "Neural radiance fields (NeRF) methods have demonstrated impressive novel view\nsynthesis performance. The core approach is to render individual rays by\nquerying a neural network at points sampled along the ray to obtain the density\nand colour of the sampled points, and integrating this information using the\nrendering equation. Since dense sampling is computationally prohibitive, a\ncommon solution is to perform coarse-to-fine sampling.\n\nIn this work we address a clear limitation of the vanilla coarse-to-fine\napproach -- that it is based on a heuristic and not trained end-to-end for the\ntask at hand. We introduce a differentiable module that learns to propose\nsamples and their importance for the fine network, and consider and compare\nmultiple alternatives for its neural architecture. Training the proposal module\nfrom scratch can be unstable due to lack of supervision, so an effective\npre-training strategy is also put forward. The approach, named `NeRF in detail'\n(NeRF-ID), achieves superior view synthesis quality over NeRF and the\nstate-of-the-art on the synthetic Blender benchmark and on par or better\nperformance on the real LLFF-NeRF scenes. Furthermore, by leveraging the\npredicted sample importance, a 25% saving in computation can be achieved\nwithout significantly sacrificing the rendering quality.",
          "link": "http://arxiv.org/abs/2106.05264",
          "publishedOn": "2021-06-10T01:56:46.723Z",
          "wordCount": 632,
          "title": "NeRF in detail: Learning to sample for view synthesis. (arXiv:2106.05264v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2011.11844",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Takahashi_N/0/1/0/all/0/1\">Naoya Takahashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitsufuji_Y/0/1/0/all/0/1\">Yuki Mitsufuji</a>",
          "description": "Tasks that involve high-resolution dense prediction require a modeling of\nboth local and global patterns in a large input field. Although the local and\nglobal structures often depend on each other and their simultaneous modeling is\nimportant, many convolutional neural network (CNN)-based approaches interchange\nrepresentations in different resolutions only a few times. In this paper, we\nclaim the importance of a dense simultaneous modeling of multiresolution\nrepresentation and propose a novel CNN architecture called densely connected\nmultidilated DenseNet (D3Net). D3Net involves a novel multidilated convolution\nthat has different dilation factors in a single layer to model different\nresolutions simultaneously. By combining the multidilated convolution with the\nDenseNet architecture, D3Net incorporates multiresolution learning with an\nexponentially growing receptive field in almost all layers, while avoiding the\naliasing problem that occurs when we naively incorporate the dilated\nconvolution in DenseNet. Experiments on the image semantic segmentation task\nusing Cityscapes and the audio source separation task using MUSDB18 show that\nthe proposed method has superior performance over state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2011.11844",
          "publishedOn": "2021-06-10T01:56:46.711Z",
          "wordCount": 636,
          "title": "Densely connected multidilated convolutional networks for dense prediction tasks. (arXiv:2011.11844v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2001.03919",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongguang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koniusz_P/0/1/0/all/0/1\">Piotr Koniusz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jian_S/0/1/0/all/0/1\">Songlei Jian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hongdong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1\">Philip H. S. Torr</a>",
          "description": "The majority of existing few-shot learning methods describe image relations\nwith binary labels. However, such binary relations are insufficient to teach\nthe network complicated real-world relations, due to the lack of decision\nsmoothness. Furthermore, current few-shot learning models capture only the\nsimilarity via relation labels, but they are not exposed to class concepts\nassociated with objects, which is likely detrimental to the classification\nperformance due to underutilization of the available class labels. To\nparaphrase, children learn the concept of tiger from a few of actual examples\nas well as from comparisons of tiger to other animals. Thus, we hypothesize\nthat in fact both similarity and class concept learning must be occurring\nsimultaneously. With these observations at hand, we study the fundamental\nproblem of simplistic class modeling in current few-shot learning methods. We\nrethink the relations between class concepts, and propose a novel\nAbsolute-relative Learning paradigm to fully take advantage of label\ninformation to refine the image representations and correct the relation\nunderstanding in both supervised and unsupervised scenarios. Our proposed\nparadigm improves the performance of several the state-of-the-art models on\npublicly available datasets.",
          "link": "http://arxiv.org/abs/2001.03919",
          "publishedOn": "2021-06-10T01:56:46.697Z",
          "wordCount": 677,
          "title": "Rethinking Class Relations: Absolute-relative Supervised and Unsupervised Few-shot Learning. (arXiv:2001.03919v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.01755",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_B/0/1/0/all/0/1\">Bin-Bin Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Hong-Yu Zhou</a>",
          "description": "Multi-label image recognition is a practical and challenging task compared to\nsingle-label image classification. However, previous works may be suboptimal\nbecause of a great number of object proposals or complex attentional region\ngeneration modules. In this paper, we propose a simple but efficient two-stream\nframework to recognize multi-category objects from global image to local\nregions, similar to how human beings perceive objects. To bridge the gap\nbetween global and local streams, we propose a multi-class attentional region\nmodule which aims to make the number of attentional regions as small as\npossible and keep the diversity of these regions as high as possible. Our\nmethod can efficiently and effectively recognize multi-class objects with an\naffordable computation cost and a parameter-free region localization module.\nOver three benchmarks on multi-label image classification, we create new\nstate-of-the-art results with a single model only using image semantics without\nlabel dependency. In addition, the effectiveness of the proposed method is\nextensively demonstrated under different factors such as global pooling\nstrategy, input size and network architecture. Code has been made available\nat~\\url{https://github.com/gaobb/MCAR}.",
          "link": "http://arxiv.org/abs/2007.01755",
          "publishedOn": "2021-06-10T01:56:46.691Z",
          "wordCount": 651,
          "title": "Learning to Discover Multi-Class Attentional Regions for Multi-Label Image Recognition. (arXiv:2007.01755v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05058",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Ziyuan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qing_Z/0/1/0/all/0/1\">Zhiwu Qing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yutong Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shiwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jianwen Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Z/0/1/0/all/0/1\">Zhurong Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_M/0/1/0/all/0/1\">Mingqian Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sang_N/0/1/0/all/0/1\">Nong Sang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ang_M/0/1/0/all/0/1\">Marcelo H. Ang Jr</a>",
          "description": "With the recent surge in the research of vision transformers, they have\ndemonstrated remarkable potential for various challenging computer vision\napplications, such as image recognition, point cloud classification as well as\nvideo understanding. In this paper, we present empirical results for training a\nstronger video vision transformer on the EPIC-KITCHENS-100 Action Recognition\ndataset. Specifically, we explore training techniques for video vision\ntransformers, such as augmentations, resolutions as well as initialization,\netc. With our training recipe, a single ViViT model achieves the performance of\n47.4\\% on the validation set of EPIC-KITCHENS-100 dataset, outperforming what\nis reported in the original paper by 3.4%. We found that video transformers are\nespecially good at predicting the noun in the verb-noun action prediction task.\nThis makes the overall action prediction accuracy of video transformers notably\nhigher than convolutional ones. Surprisingly, even the best video transformers\nunderperform the convolutional networks on the verb prediction. Therefore, we\ncombine the video vision transformers and some of the convolutional video\nnetworks and present our solution to the EPIC-KITCHENS-100 Action Recognition\ncompetition.",
          "link": "http://arxiv.org/abs/2106.05058",
          "publishedOn": "2021-06-10T01:56:46.685Z",
          "wordCount": 627,
          "title": "Towards Training Stronger Video Vision Transformers for EPIC-KITCHENS-100 Action Recognition. (arXiv:2106.05058v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2104.02867",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hou_Z/0/1/0/all/0/1\">Zhi Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1\">Baosheng Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1\">Yu Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_X/0/1/0/all/0/1\">Xiaojiang Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>",
          "description": "Reasoning the human-object interactions (HOI) is essential for deeper scene\nunderstanding, while object affordances (or functionalities) are of great\nimportance for human to discover unseen HOIs with novel objects. Inspired by\nthis, we introduce an affordance transfer learning approach to jointly detect\nHOIs with novel objects and recognize affordances. Specifically, HOI\nrepresentations can be decoupled into a combination of affordance and object\nrepresentations, making it possible to compose novel interactions by combining\naffordance representations and novel object representations from additional\nimages, i.e. transferring the affordance to novel objects. With the proposed\naffordance transfer learning, the model is also capable of inferring the\naffordances of novel objects from known affordance representations. The\nproposed method can thus be used to 1) improve the performance of HOI\ndetection, especially for the HOIs with unseen objects; and 2) infer the\naffordances of novel objects. Experimental results on two datasets, HICO-DET\nand HOI-COCO (from V-COCO), demonstrate significant improvements over recent\nstate-of-the-art methods for HOI detection and object affordance detection.\nCode is available at https://github.com/zhihou7/HOI-CL",
          "link": "http://arxiv.org/abs/2104.02867",
          "publishedOn": "2021-06-10T01:56:46.666Z",
          "wordCount": 646,
          "title": "Affordance Transfer Learning for Human-Object Interaction Detection. (arXiv:2104.02867v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.16483",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Horn_G/0/1/0/all/0/1\">Grant Van Horn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cole_E/0/1/0/all/0/1\">Elijah Cole</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beery_S/0/1/0/all/0/1\">Sara Beery</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilber_K/0/1/0/all/0/1\">Kimberly Wilber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belongie_S/0/1/0/all/0/1\">Serge Belongie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aodha_O/0/1/0/all/0/1\">Oisin Mac Aodha</a>",
          "description": "Recent progress in self-supervised learning has resulted in models that are\ncapable of extracting rich representations from image collections without\nrequiring any explicit label supervision. However, to date the vast majority of\nthese approaches have restricted themselves to training on standard benchmark\ndatasets such as ImageNet. We argue that fine-grained visual categorization\nproblems, such as plant and animal species classification, provide an\ninformative testbed for self-supervised learning. In order to facilitate\nprogress in this area we present two new natural world visual classification\ndatasets, iNat2021 and NeWT. The former consists of 2.7M images from 10k\ndifferent species uploaded by users of the citizen science application\niNaturalist. We designed the latter, NeWT, in collaboration with domain experts\nwith the aim of benchmarking the performance of representation learning\nalgorithms on a suite of challenging natural world binary classification tasks\nthat go beyond standard species classification. These two new datasets allow us\nto explore questions related to large-scale representation and transfer\nlearning in the context of fine-grained categories. We provide a comprehensive\nanalysis of feature extractors trained with and without supervision on ImageNet\nand iNat2021, shedding light on the strengths and weaknesses of different\nlearned features across a diverse set of tasks. We find that features produced\nby standard supervised methods still outperform those produced by\nself-supervised approaches such as SimCLR. However, improved self-supervised\nlearning methods are constantly being released and the iNat2021 and NeWT\ndatasets are a valuable resource for tracking their progress.",
          "link": "http://arxiv.org/abs/2103.16483",
          "publishedOn": "2021-06-10T01:56:46.660Z",
          "wordCount": 714,
          "title": "Benchmarking Representation Learning for Natural World Image Collections. (arXiv:2103.16483v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.10851",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hadjiivanov_A/0/1/0/all/0/1\">Alexander Hadjiivanov</a>",
          "description": "Most classical (non-spiking) neural network models disregard internal neuron\ndynamics and treat neurons as simple input integrators. However, biological\nneurons have an internal state governed by complex dynamics that plays a\ncrucial role in learning, adaptation and the overall network activity and\nbehaviour. This paper presents the Membrane Potential and Activation Threshold\nHomeostasis (MPATH) neuron model, which combines several biologically inspired\nmechanisms to efficiently simulate internal neuron dynamics with a single\nparameter analogous to the membrane time constant in biological neurons. The\nmodel allows neurons to maintain a form of dynamic equilibrium by automatically\nregulating their activity when presented with fluctuating input. One\nconsequence of the MPATH model is that it imbues neurons with a sense of time\nwithout recurrent connections, paving the way for modelling processes that\ndepend on temporal aspects of neuron activity. Experiments demonstrate the\nmodel's ability to adapt to and continually learn from its input.",
          "link": "http://arxiv.org/abs/2104.10851",
          "publishedOn": "2021-06-10T01:56:46.654Z",
          "wordCount": 619,
          "title": "Continuous Learning and Adaptation with Membrane Potential and Activation Threshold Homeostasis. (arXiv:2104.10851v3 [cs.NE] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.05509",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cygert_S/0/1/0/all/0/1\">Sebastian Cygert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Czyzewski_A/0/1/0/all/0/1\">Andrzej Czy&#x17c;ewski</a>",
          "description": "Model compression techniques allow to significantly reduce the computational\ncost associated with data processing by deep neural networks with only a minor\ndecrease in average accuracy. Simultaneously, reducing the model size may have\na large effect on noisy cases or objects belonging to less frequent classes. It\nis a crucial problem from the perspective of the models' safety, especially for\nobject detection in the autonomous driving setting, which is considered in this\nwork. It was shown in the paper that the sensitivity of compressed models to\ndifferent distortion types is nuanced, and some of the corruptions are heavily\nimpacted by the compression methods (i.e., additive noise), while others (blur\neffect) are only slightly affected. A common way to improve the robustness of\nmodels is to use data augmentation, which was confirmed to positively affect\nmodels' robustness, also for highly compressed models. It was further shown\nthat while data imbalance methods brought only a slight increase in accuracy\nfor the baseline model (without compression), the impact was more striking at\nhigher compression rates for the structured pruning. Finally, methods for\nhandling data imbalance brought a significant improvement of the pruned models'\nworst-detected class accuracy.",
          "link": "http://arxiv.org/abs/2102.05509",
          "publishedOn": "2021-06-10T01:56:46.649Z",
          "wordCount": 647,
          "title": "Robustness in Compressed Neural Networks for Object Detection. (arXiv:2102.05509v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.12663",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Warburg_F/0/1/0/all/0/1\">Frederik Warburg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jorgensen_M/0/1/0/all/0/1\">Martin J&#xf8;rgensen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Civera_J/0/1/0/all/0/1\">Javier Civera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hauberg_S/0/1/0/all/0/1\">S&#xf8;ren Hauberg</a>",
          "description": "Uncertainty quantification in image retrieval is crucial for downstream\ndecisions, yet it remains a challenging and largely unexplored problem. Current\nmethods for estimating uncertainties are poorly calibrated, computationally\nexpensive, or based on heuristics. We present a new method that views image\nembeddings as stochastic features rather than deterministic features. Our two\nmain contributions are (1) a likelihood that matches the triplet constraint and\nthat evaluates the probability of an anchor being closer to a positive than a\nnegative; and (2) a prior over the feature space that justifies the\nconventional l2 normalization. To ensure computational efficiency, we derive a\nvariational approximation of the posterior, called the Bayesian triplet loss,\nthat produces state-of-the-art uncertainty estimates and matches the predictive\nperformance of current state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2011.12663",
          "publishedOn": "2021-06-10T01:56:46.641Z",
          "wordCount": 581,
          "title": "Bayesian Triplet Loss: Uncertainty Quantification in Image Retrieval. (arXiv:2011.12663v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2002.01619",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1\">Yingjie Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Buyu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_Z/0/1/0/all/0/1\">Zeyu Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hongsheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1\">Xingyu Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaogang Wang</a>",
          "description": "Monocular 3D object detection task aims to predict the 3D bounding boxes of\nobjects based on monocular RGB images. Since the location recovery in 3D space\nis quite difficult on account of absence of depth information, this paper\nproposes a novel unified framework which decomposes the detection problem into\na structured polygon prediction task and a depth recovery task. Different from\nthe widely studied 2D bounding boxes, the proposed novel structured polygon in\nthe 2D image consists of several projected surfaces of the target object.\nCompared to the widely-used 3D bounding box proposals, it is shown to be a\nbetter representation for 3D detection. In order to inversely project the\npredicted 2D structured polygon to a cuboid in the 3D physical world, the\nfollowing depth recovery task uses the object height prior to complete the\ninverse projection transformation with the given camera projection matrix.\nMoreover, a fine-grained 3D box refinement scheme is proposed to further\nrectify the 3D detection results. Experiments are conducted on the challenging\nKITTI benchmark, in which our method achieves state-of-the-art detection\naccuracy.",
          "link": "http://arxiv.org/abs/2002.01619",
          "publishedOn": "2021-06-10T01:56:46.624Z",
          "wordCount": 655,
          "title": "Monocular 3D Object Detection with Decoupled Structured Polygon Estimation and Height-Guided Depth Estimation. (arXiv:2002.01619v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05241",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Falck_F/0/1/0/all/0/1\">Fabian Falck</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_H/0/1/0/all/0/1\">Haoting Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Willetts_M/0/1/0/all/0/1\">Matthew Willetts</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nicholson_G/0/1/0/all/0/1\">George Nicholson</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yau_C/0/1/0/all/0/1\">Christopher Yau</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Holmes_C/0/1/0/all/0/1\">Christopher C Holmes</a>",
          "description": "Work in deep clustering focuses on finding a single partition of data.\nHowever, high-dimensional data, such as images, typically feature multiple\ninteresting characteristics one could cluster over. For example, images of\nobjects against a background could be clustered over the shape of the object\nand separately by the colour of the background. In this paper, we introduce\nMulti-Facet Clustering Variational Autoencoders (MFCVAE), a novel class of\nvariational autoencoders with a hierarchy of latent variables, each with a\nMixture-of-Gaussians prior, that learns multiple clusterings simultaneously,\nand is trained fully unsupervised and end-to-end. MFCVAE uses a\nprogressively-trained ladder architecture which leads to highly stable\nperformance. We provide novel theoretical results for optimising the ELBO\nanalytically with respect to the categorical variational posterior\ndistribution, and corrects earlier influential theoretical work. On image\nbenchmarks, we demonstrate that our approach separates out and clusters over\ndifferent aspects of the data in a disentangled manner. We also show other\nadvantages of our model: the compositionality of its latent space and that it\nprovides controlled generation of samples.",
          "link": "http://arxiv.org/abs/2106.05241",
          "publishedOn": "2021-06-10T01:56:46.618Z",
          "wordCount": 616,
          "title": "Multi-Facet Clustering Variational Autoencoders. (arXiv:2106.05241v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2006.12135",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Madaan_D/0/1/0/all/0/1\">Divyam Madaan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1\">Jinwoo Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1\">Sung Ju Hwang</a>",
          "description": "Adversarial learning has emerged as one of the successful techniques to\ncircumvent the susceptibility of existing methods against adversarial\nperturbations. However, the majority of existing defense methods are tailored\nto defend against a single category of adversarial perturbation (e.g.\n$\\ell_\\infty$-attack). In safety-critical applications, this makes these\nmethods extraneous as the attacker can adopt diverse adversaries to deceive the\nsystem. Moreover, training on multiple perturbations simultaneously\nsignificantly increases the computational overhead during training. To address\nthese challenges, we propose a novel meta-learning framework that explicitly\nlearns to generate noise to improve the model's robustness against multiple\ntypes of attacks. Its key component is Meta Noise Generator (MNG) that outputs\noptimal noise to stochastically perturb a given sample, such that it helps\nlower the error on diverse adversarial perturbations. By utilizing samples\ngenerated by MNG, we train a model by enforcing the label consistency across\nmultiple perturbations. We validate the robustness of models trained by our\nscheme on various datasets and against a wide variety of perturbations,\ndemonstrating that it significantly outperforms the baselines across multiple\nperturbations with a marginal computational cost.",
          "link": "http://arxiv.org/abs/2006.12135",
          "publishedOn": "2021-06-10T01:56:46.613Z",
          "wordCount": 657,
          "title": "Learning to Generate Noise for Multi-Attack Robustness. (arXiv:2006.12135v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05261",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liang_B/0/1/0/all/0/1\">Bin Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiachun Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jianjun Huang</a>",
          "description": "Recently, the object detection based on deep learning has proven to be\nvulnerable to adversarial patch attacks. The attackers holding a specially\ncrafted patch can hide themselves from the state-of-the-art person detectors,\ne.g., YOLO, even in the physical world. This kind of attack can bring serious\nsecurity threats, such as escaping from surveillance cameras. In this paper, we\ndeeply explore the detection problems about the adversarial patch attacks to\nthe object detection. First, we identify a leverageable signature of existing\nadversarial patches from the point of the visualization explanation. A fast\nsignature-based defense method is proposed and demonstrated to be effective.\nSecond, we design an improved patch generation algorithm to reveal the risk\nthat the signature-based way may be bypassed by the techniques emerging in the\nfuture. The newly generated adversarial patches can successfully evade the\nproposed signature-based defense. Finally, we present a novel\nsignature-independent detection method based on the internal content semantics\nconsistency rather than any attack-specific prior knowledge. The fundamental\nintuition is that the adversarial object can appear locally but disappear\nglobally in an input image. The experiments demonstrate that the\nsignature-independent method can effectively detect the existing and improved\nattacks. It has also proven to be a general method by detecting unforeseen and\neven other types of attacks without any attack-specific prior knowledge. The\ntwo proposed detection methods can be adopted in different scenarios, and we\nbelieve that combining them can offer a comprehensive protection.",
          "link": "http://arxiv.org/abs/2106.05261",
          "publishedOn": "2021-06-10T01:56:46.606Z",
          "wordCount": 681,
          "title": "We Can Always Catch You: Detecting Adversarial Patched Objects WITH or WITHOUT Signature. (arXiv:2106.05261v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2005.12469",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mendieta_M/0/1/0/all/0/1\">Mat&#xed;as Mendieta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tabkhi_H/0/1/0/all/0/1\">Hamed Tabkhi</a>",
          "description": "Pedestrian path prediction is an essential topic in computer vision and video\nunderstanding. Having insight into the movement of pedestrians is crucial for\nensuring safe operation in a variety of applications including autonomous\nvehicles, social robots, and environmental monitoring. Current works in this\narea utilize complex generative or recurrent methods to capture many possible\nfutures. However, despite the inherent real-time nature of predicting future\npaths, little work has been done to explore accurate and computationally\nefficient approaches for this task. To this end, we propose a convolutional\napproach for real-time pedestrian path prediction, CARPe. It utilizes a\nvariation of Graph Isomorphism Networks in combination with an agile\nconvolutional neural network design to form a fast and accurate path prediction\napproach. Notable results in both inference speed and prediction accuracy are\nachieved, improving FPS considerably in comparison to current state-of-the-art\nmethods while delivering competitive accuracy on well-known path prediction\ndatasets.",
          "link": "http://arxiv.org/abs/2005.12469",
          "publishedOn": "2021-06-10T01:56:46.601Z",
          "wordCount": 616,
          "title": "CARPe Posterum: A Convolutional Approach for Real-time Pedestrian Path Prediction. (arXiv:2005.12469v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.09108",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tuggener_L/0/1/0/all/0/1\">Lukas Tuggener</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidhuber_J/0/1/0/all/0/1\">J&#xfc;rgen Schmidhuber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stadelmann_T/0/1/0/all/0/1\">Thilo Stadelmann</a>",
          "description": "An implicit but pervasive hypothesis of modern computer vision research is\nthat convolutional neural network (CNN) architectures that perform better on\nImageNet will also perform better on other vision datasets. We challenge this\nhypothesis through an extensive empirical study for which we train 500 sampled\nCNN architectures on ImageNet as well as 8 other image classification datasets\nfrom a wide array of application domains. The relationship between architecture\nand performance varies wildly, depending on the datasets. For some of them, the\nperformance correlation with ImageNet is even negative. Clearly, it is not\nenough to optimize architectures solely for ImageNet when aiming for progress\nthat is relevant for all applications. Therefore, we identify two\ndataset-specific performance indicators: the cumulative width across layers as\nwell as the total depth of the network. Lastly, we show that the range of\ndataset variability covered by ImageNet can be significantly extended by adding\nImageNet subsets restricted to few classes.",
          "link": "http://arxiv.org/abs/2103.09108",
          "publishedOn": "2021-06-10T01:56:46.594Z",
          "wordCount": 615,
          "title": "Is it Enough to Optimize CNN Architectures on ImageNet?. (arXiv:2103.09108v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.00567",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1\">Heng Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hengwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jindong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dou_R/0/1/0/all/0/1\">Ruiyu Dou</a>",
          "description": "Convolutional neural networks have outperformed humans in image recognition\ntasks, but they remain vulnerable to attacks from adversarial examples. Since\nthese data are crafted by adding imperceptible noise to normal images, their\nexistence poses potential security threats to deep learning systems.\nSophisticated adversarial examples with strong attack performance can also be\nused as a tool to evaluate the robustness of a model. However, the success rate\nof adversarial attacks can be further improved in black-box environments.\nTherefore, this study combines a modified Adam gradient descent algorithm with\nthe iterative gradient-based attack method. The proposed Adam Iterative Fast\nGradient Method is then used to improve the transferability of adversarial\nexamples. Extensive experiments on ImageNet showed that the proposed method\noffers a higher attack success rate than existing iterative methods. By\nextending our method, we achieved a state-of-the-art attack success rate of\n95.0% on defense models.",
          "link": "http://arxiv.org/abs/2012.00567",
          "publishedOn": "2021-06-10T01:56:46.577Z",
          "wordCount": 604,
          "title": "Boosting Adversarial Attacks on Neural Networks with Better Optimizer. (arXiv:2012.00567v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05266",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shaowei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Hanwen Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jiarui Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Sifei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaolong Wang</a>",
          "description": "Estimating 3D hand and object pose from a single image is an extremely\nchallenging problem: hands and objects are often self-occluded during\ninteractions, and the 3D annotations are scarce as even humans cannot directly\nlabel the ground-truths from a single image perfectly. To tackle these\nchallenges, we propose a unified framework for estimating the 3D hand and\nobject poses with semi-supervised learning. We build a joint learning framework\nwhere we perform explicit contextual reasoning between hand and object\nrepresentations by a Transformer. Going beyond limited 3D annotations in a\nsingle image, we leverage the spatial-temporal consistency in large-scale\nhand-object videos as a constraint for generating pseudo labels in\nsemi-supervised learning. Our method not only improves hand pose estimation in\nchallenging real-world dataset, but also substantially improve the object pose\nwhich has fewer ground-truths per instance. By training with large-scale\ndiverse videos, our model also generalizes better across multiple out-of-domain\ndatasets. Project page and code: https://stevenlsw.github.io/Semi-Hand-Object",
          "link": "http://arxiv.org/abs/2106.05266",
          "publishedOn": "2021-06-10T01:56:46.570Z",
          "wordCount": 599,
          "title": "Semi-Supervised 3D Hand-Object Poses Estimation with Interactions in Time. (arXiv:2106.05266v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05258",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jahanian_A/0/1/0/all/0/1\">Ali Jahanian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Puig_X/0/1/0/all/0/1\">Xavier Puig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yonglong Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Isola_P/0/1/0/all/0/1\">Phillip Isola</a>",
          "description": "Generative models are now capable of producing highly realistic images that\nlook nearly indistinguishable from the data on which they are trained. This\nraises the question: if we have good enough generative models, do we still need\ndatasets? We investigate this question in the setting of learning\ngeneral-purpose visual representations from a black-box generative model rather\nthan directly from data. Given an off-the-shelf image generator without any\naccess to its training data, we train representations from the samples output\nby this generator. We compare several representation learning methods that can\nbe applied to this setting, using the latent space of the generator to generate\nmultiple \"views\" of the same semantic content. We show that for contrastive\nmethods, this multiview data can naturally be used to identify positive pairs\n(nearby in latent space) and negative pairs (far apart in latent space). We\nfind that the resulting representations rival those learned directly from real\ndata, but that good performance requires care in the sampling strategy applied\nand the training method. Generative models can be viewed as a compressed and\norganized copy of a dataset, and we envision a future where more and more\n\"model zoos\" proliferate while datasets become increasingly unwieldy, missing,\nor private. This paper suggests several techniques for dealing with visual\nrepresentation learning in such a future. Code is released on our project page:\nhttps://ali-design.github.io/GenRep/",
          "link": "http://arxiv.org/abs/2106.05258",
          "publishedOn": "2021-06-10T01:56:46.564Z",
          "wordCount": 660,
          "title": "Generative Models as a Data Source for Multiview Representation Learning. (arXiv:2106.05258v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2011.12902",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Evtimov_I/0/1/0/all/0/1\">Ivan Evtimov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Howes_R/0/1/0/all/0/1\">Russel Howes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dolhansky_B/0/1/0/all/0/1\">Brian Dolhansky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Firooz_H/0/1/0/all/0/1\">Hamed Firooz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferrer_C/0/1/0/all/0/1\">Cristian Canton Ferrer</a>",
          "description": "This work examines the vulnerability of multimodal (image + text) models to\nadversarial threats similar to those discussed in previous literature on\nunimodal (image- or text-only) models. We introduce realistic assumptions of\npartial model knowledge and access, and discuss how these assumptions differ\nfrom the standard \"black-box\"/\"white-box\" dichotomy common in current\nliterature on adversarial attacks. Working under various levels of these\n\"gray-box\" assumptions, we develop new attack methodologies unique to\nmultimodal classification and evaluate them on the Hateful Memes Challenge\nclassification task. We find that attacking multiple modalities yields stronger\nattacks than unimodal attacks alone (inducing errors in up to 73% of cases),\nand that the unimodal image attacks on multimodal classifiers we explored were\nstronger than character-based text augmentation attacks (inducing errors on\naverage in 45% and 30% of cases, respectively).",
          "link": "http://arxiv.org/abs/2011.12902",
          "publishedOn": "2021-06-10T01:56:46.559Z",
          "wordCount": 616,
          "title": "Adversarial Evaluation of Multimodal Models under Realistic Gray Box Assumption. (arXiv:2011.12902v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05106",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sahay_A/0/1/0/all/0/1\">Atul Sahay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_I/0/1/0/all/0/1\">Imon Mukherjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arya_K/0/1/0/all/0/1\">Kavi Arya</a>",
          "description": "A user's eyes provide means for Human Computer Interaction (HCI) research as\nan important modal. The time to time scientific explorations of the eye has\nalready seen an upsurge of the benefits in HCI applications from gaze\nestimation to the measure of attentiveness of a user looking at a screen for a\ngiven time period. The eye tracking system as an assisting, interactive tool\ncan be incorporated by physically disabled individuals, fitted best for those\nwho have eyes as only a limited set of communication. The threefold objective\nof this paper is - 1. To introduce a neural network based architecture to\npredict users' gaze at 9 positions displayed in the 11.31{\\deg} visual range on\nthe screen, through a low resolution based system such as a webcam in real time\nby learning various aspects of eyes as an ocular feature set. 2.A collection of\ncoarsely supervised feature set obtained in real time which is also validated\nthrough the user case study presented in the paper for 21 individuals ( 17 men\nand 4 women ) from whom a 35k set of instances was derived with an accuracy\nscore of 82.36% and f1_score of 82.2% and 3.A detailed study over applicability\nand underlying challenges of such systems. The experimental results verify the\nfeasibility and validity of the proposed eye gaze tracking model.",
          "link": "http://arxiv.org/abs/2106.05106",
          "publishedOn": "2021-06-10T01:56:46.553Z",
          "wordCount": 674,
          "title": "An Efficient Point of Gaze Estimator for Low-Resolution Imaging Systems Using Extracted Ocular Features Based Neural Architecture. (arXiv:2106.05106v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/1804.06679",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Amjad_R/0/1/0/all/0/1\">Rana Ali Amjad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1\">Kairen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geiger_B/0/1/0/all/0/1\">Bernhard C. Geiger</a>",
          "description": "In this work, we investigate the use of three information-theoretic\nquantities -- entropy, mutual information with the class variable, and a class\nselectivity measure based on Kullback-Leibler divergence -- to understand and\nstudy the behavior of already trained fully-connected feed-forward neural\nnetworks. We analyze the connection between these information-theoretic\nquantities and classification performance on the test set by cumulatively\nablating neurons in networks trained on MNIST, FashionMNIST, and CIFAR-10. Our\nresults parallel those recently published by Morcos et al., indicating that\nclass selectivity is not a good indicator for classification performance.\nHowever, looking at individual layers separately, both mutual information and\nclass selectivity are positively correlated with classification performance, at\nleast for networks with ReLU activation functions. We provide explanations for\nthis phenomenon and conclude that it is ill-advised to compare the proposed\ninformation-theoretic quantities across layers. Furthermore, we show that\ncumulative ablation of neurons with ascending or descending\ninformation-theoretic quantities can be used to formulate hypotheses regarding\nthe joint behavior of multiple neurons, such as redundancy and synergy, with\ncomparably low computational cost. We also draw connections to the information\nbottleneck theory for neural networks.",
          "link": "http://arxiv.org/abs/1804.06679",
          "publishedOn": "2021-06-10T01:56:46.536Z",
          "wordCount": 698,
          "title": "Understanding Neural Networks and Individual Neuron Importance via Information-Ordered Cumulative Ablation. (arXiv:1804.06679v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.00116",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cherti_M/0/1/0/all/0/1\">Mehdi Cherti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jitsev_J/0/1/0/all/0/1\">Jenia Jitsev</a>",
          "description": "Transfer learning aims to exploit pre-trained models for more efficient\nfollow-up training on wide range of downstream tasks and datasets, enabling\nsuccessful training also on small data. Recent line of work posits strong\nbenefits for model generalization and transfer when model size, data size, and\ncompute budget are increased for the pre-training. It remains however still\nlargely unclear whether the observed transfer improvement due to increase in\nscale also holds when source and target data distributions are far apart from\neach other. In this work we conduct large-scale pre-training on large source\ndatasets of either natural (ImageNet-21k/1k) or medical chest X-Ray images and\ncompare full and few-shot transfer using different target datasets from both\nnatural and medical imaging domains. Our observations provide evidence that\nwhile pre-training and transfer on closely related datasets do show clear\nbenefit of increasing model and data size during pre-training, such benefits\nare not clearly visible when source and target datasets are further apart.\nThese observations hold across both full and few-shot transfer and indicate\nthat scaling laws pointing to improvement of generalization and transfer with\nincreasing model and data size are incomplete and should be revised by taking\ninto account the type and proximity of the source and target data, to correctly\npredict the effect of model and data scale during pre-training on transfer.\nRemarkably, in full shot transfer to a large X-Ray chest imaging target\n(PadChest), the largest model pre-trained on ImageNet-21k slightly outperforms\nbest models pre-trained on large X-Ray chest imaging data. This indicates\npossibility to obtain high quality models for domain-specific transfer even\nwithout access to large domain-specific data, by pre-training instead on\ncomparably very large, generic source data.",
          "link": "http://arxiv.org/abs/2106.00116",
          "publishedOn": "2021-06-10T01:56:46.530Z",
          "wordCount": 742,
          "title": "Effect of large-scale pre-training on full and few-shot transfer learning for natural and medical images. (arXiv:2106.00116v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1905.13308",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Livezey_J/0/1/0/all/0/1\">Jesse A. Livezey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_A/0/1/0/all/0/1\">Ahyeon Hwang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeung_J/0/1/0/all/0/1\">Jacob Yeung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bouchard_K/0/1/0/all/0/1\">Kristofer E. Bouchard</a>",
          "description": "Hierarchy and compositionality are common latent properties in many natural\nand scientific datasets. Determining when a deep network's hidden activations\nrepresent hierarchy and compositionality is important both for understanding\ndeep representation learning and for applying deep networks in domains where\ninterpretability is crucial. However, current benchmark machine learning\ndatasets either have little hierarchical or compositional structure, or the\nstructure is not known. This gap impedes precise analysis of a network's\nrepresentations and thus hinders development of new methods that can learn such\nproperties. To address this gap, we developed a new benchmark dataset with\nknown hierarchical and compositional structure. The Hangul Fonts Dataset (HFD)\nis comprised of 35 fonts from the Korean writing system (Hangul), each with\n11,172 blocks (syllables) composed from the product of initial consonant,\nmedial vowel, and final consonant glyphs. All blocks can be grouped into a few\ngeometric types which induces a hierarchy across blocks. In addition, each\nblock is composed of individual glyphs with rotations, translations, scalings,\nand naturalistic style variation across fonts. We find that both shallow and\ndeep unsupervised methods only show modest evidence of hierarchy and\ncompositionality in their representations of the HFD compared to supervised\ndeep networks. Supervised deep network representations contain structure\nrelated to the geometrical hierarchy of the characters, but the compositional\nstructure of the data is not evident. Thus, HFD enables the identification of\nshortcomings in existing methods, a critical first step toward developing new\nmachine learning algorithms to extract hierarchical and compositional structure\nin the context of naturalistic variability.",
          "link": "http://arxiv.org/abs/1905.13308",
          "publishedOn": "2021-06-10T01:56:46.523Z",
          "wordCount": 732,
          "title": "Hangul Fonts Dataset: a Hierarchical and Compositional Dataset for Investigating Learned Representations. (arXiv:1905.13308v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05210",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1\">Ho Kei Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tai_Y/0/1/0/all/0/1\">Yu-Wing Tai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_C/0/1/0/all/0/1\">Chi-Keung Tang</a>",
          "description": "This paper presents a simple yet effective approach to modeling space-time\ncorrespondences in the context of video object segmentation. Unlike most\nexisting approaches, we establish correspondences directly between frames\nwithout re-encoding the mask features for every object, leading to a highly\nefficient and robust framework. With the correspondences, every node in the\ncurrent query frame is inferred by aggregating features from the past in an\nassociative fashion. We cast the aggregation process as a voting problem and\nfind that the existing inner-product affinity leads to poor use of memory with\na small (fixed) subset of memory nodes dominating the votes, regardless of the\nquery. In light of this phenomenon, we propose using the negative squared\nEuclidean distance instead to compute the affinities. We validated that every\nmemory node now has a chance to contribute, and experimentally showed that such\ndiversified voting is beneficial to both memory efficiency and inference\naccuracy. The synergy of correspondence networks and diversified voting works\nexceedingly well, achieves new state-of-the-art results on both DAVIS and\nYouTubeVOS datasets while running significantly faster at 20+ FPS for multiple\nobjects without bells and whistles.",
          "link": "http://arxiv.org/abs/2106.05210",
          "publishedOn": "2021-06-10T01:56:46.517Z",
          "wordCount": 628,
          "title": "Rethinking Space-Time Networks with Improved Memory Coverage for Efficient Video Object Segmentation. (arXiv:2106.05210v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2104.10858",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1\">Zihang Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_Q/0/1/0/all/0/1\">Qibin Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1\">Li Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1\">Daquan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yujun Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1\">Xiaojie Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_A/0/1/0/all/0/1\">Anran Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jiashi Feng</a>",
          "description": "In this paper, we present token labeling -- a new training objective for\ntraining high-performance vision transformers (ViTs). Different from the\nstandard training objective of ViTs that computes the classification loss on an\nadditional trainable class token, our proposed one takes advantage of all the\nimage patch tokens to compute the training loss in a dense manner.\nSpecifically, token labeling reformulates the image classification problem into\nmultiple token-level recognition problems and assigns each patch token with an\nindividual location-specific supervision generated by a machine annotator.\nExperiments show that token labeling can clearly and consistently improve the\nperformance of various ViT models across a wide spectrum. For a vision\ntransformer with 26M learnable parameters serving as an example, with token\nlabeling, the model can achieve 84.4% Top-1 accuracy on ImageNet. The result\ncan be further increased to 86.4% by slightly scaling the model size up to\n150M, delivering the minimal-sized model among previous models (250M+) reaching\n86%. We also show that token labeling can clearly improve the generalization\ncapability of the pre-trained models on downstream tasks with dense prediction,\nsuch as semantic segmentation. Our code and all the training details will be\nmade publicly available at https://github.com/zihangJiang/TokenLabeling.",
          "link": "http://arxiv.org/abs/2104.10858",
          "publishedOn": "2021-06-10T01:56:46.511Z",
          "wordCount": 679,
          "title": "All Tokens Matter: Token Labeling for Training Better Vision Transformers. (arXiv:2104.10858v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05113",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gaziv_G/0/1/0/all/0/1\">Guy Gaziv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Irani_M/0/1/0/all/0/1\">Michal Irani</a>",
          "description": "In the past few years, significant advancements were made in reconstruction\nof observed natural images from fMRI brain recordings using deep-learning\ntools. Here, for the first time, we show that dense 3D depth maps of observed\n2D natural images can also be recovered directly from fMRI brain recordings. We\nuse an off-the-shelf method to estimate the unknown depth maps of natural\nimages. This is applied to both: (i) the small number of images presented to\nsubjects in an fMRI scanner (images for which we have fMRI recordings -\nreferred to as \"paired\" data), and (ii) a very large number of natural images\nwith no fMRI recordings (\"unpaired data\"). The estimated depth maps are then\nused as an auxiliary reconstruction criterion to train for depth reconstruction\ndirectly from fMRI. We propose two main approaches: Depth-only recovery and\njoint image-depth RGBD recovery. Because the number of available \"paired\"\ntraining data (images with fMRI) is small, we enrich the training data via\nself-supervised cycle-consistent training on many \"unpaired\" data (natural\nimages & depth maps without fMRI). This is achieved using our newly defined and\ntrained Depth-based Perceptual Similarity metric as a reconstruction criterion.\nWe show that predicting the depth map directly from fMRI outperforms its\nindirect sequential recovery from the reconstructed images. We further show\nthat activations from early cortical visual areas dominate our depth\nreconstruction results, and propose means to characterize fMRI voxels by their\ndegree of depth-information tuning. This work adds an important layer of\ndecoded information, extending the current envelope of visual brain decoding\ncapabilities.",
          "link": "http://arxiv.org/abs/2106.05113",
          "publishedOn": "2021-06-10T01:56:46.494Z",
          "wordCount": 696,
          "title": "More than meets the eye: Self-supervised depth reconstruction from brain activity. (arXiv:2106.05113v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2001.05849",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shaghaghian_Z/0/1/0/all/0/1\">Zohreh Shaghaghian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_W/0/1/0/all/0/1\">Wei Yan</a>",
          "description": "Most design methods contain a forward framework, asking for primary\nspecifications of a building to generate an output or assess its performance.\nHowever, architects urge for specific objectives though uncertain of the proper\ndesign parameters. Deep Learning (DL) algorithms provide an intelligent\nworkflow in which the system can learn from sequential training experiments.\nThis study applies a method using DL algorithms towards generating demanded\ndesign options. In this study, an object recognition problem is investigated to\ninitially predict the label of unseen sample images based on training dataset\nconsisting of different types of synthetic 2D shapes; later, a generative DL\nalgorithm is applied to be trained and generate new shapes for given labels. In\nthe next step, the algorithm is trained to generate a window/wall pattern for\ndesired light/shadow performance based on the spatial daylight autonomy (sDA)\nmetrics. The experiments show promising results both in predicting unseen\nsample shapes and generating new design options.",
          "link": "http://arxiv.org/abs/2001.05849",
          "publishedOn": "2021-06-10T01:56:46.487Z",
          "wordCount": 637,
          "title": "Application of Deep Learning in Generating Desired Design Options: Experiments Using Synthetic Training Dataset. (arXiv:2001.05849v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.04702",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Han Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koh_J/0/1/0/all/0/1\">Jing Yu Koh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baldridge_J/0/1/0/all/0/1\">Jason Baldridge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Honglak Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yinfei Yang</a>",
          "description": "The output of text-to-image synthesis systems should be coherent, clear,\nphoto-realistic scenes with high semantic fidelity to their conditioned text\ndescriptions. Our Cross-Modal Contrastive Generative Adversarial Network\n(XMC-GAN) addresses this challenge by maximizing the mutual information between\nimage and text. It does this via multiple contrastive losses which capture\ninter-modality and intra-modality correspondences. XMC-GAN uses an attentional\nself-modulation generator, which enforces strong text-image correspondence, and\na contrastive discriminator, which acts as a critic as well as a feature\nencoder for contrastive learning. The quality of XMC-GAN's output is a major\nstep up from previous models, as we show on three challenging datasets. On\nMS-COCO, not only does XMC-GAN improve state-of-the-art FID from 24.70 to 9.33,\nbut--more importantly--people prefer XMC-GAN by 77.3 for image quality and 74.1\nfor image-text alignment, compared to three other recent models. XMC-GAN also\ngeneralizes to the challenging Localized Narratives dataset (which has longer,\nmore detailed descriptions), improving state-of-the-art FID from 48.70 to\n14.12. Lastly, we train and evaluate XMC-GAN on the challenging Open Images\ndata, establishing a strong benchmark FID score of 26.91.",
          "link": "http://arxiv.org/abs/2101.04702",
          "publishedOn": "2021-06-10T01:56:46.481Z",
          "wordCount": 659,
          "title": "Cross-Modal Contrastive Learning for Text-to-Image Generation. (arXiv:2101.04702v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05047",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fang_H/0/1/0/all/0/1\">Hao Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Daoxin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Minghao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiawei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yao Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_D/0/1/0/all/0/1\">Deng Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiaofei He</a>",
          "description": "Instance segmentation can detect where the objects are in an image, but hard\nto understand the relationship between them. We pay attention to a typical\nrelationship, relative saliency. A closely related task, salient object\ndetection, predicts a binary map highlighting a visually salient region while\nhard to distinguish multiple objects. Directly combining two tasks by\npost-processing also leads to poor performance. There is a lack of research on\nrelative saliency at present, limiting the practical applications such as\ncontent-aware image cropping, video summary, and image labeling.\n\nIn this paper, we study the Salient Object Ranking (SOR) task, which manages\nto assign a ranking order of each detected object according to its visual\nsaliency. We propose the first end-to-end framework of the SOR task and solve\nit in a multi-task learning fashion. The framework handles instance\nsegmentation and salient object ranking simultaneously. In this framework, the\nSOR branch is independent and flexible to cooperate with different detection\nmethods, so that easy to use as a plugin. We also introduce a\nPosition-Preserved Attention (PPA) module tailored for the SOR branch. It\nconsists of the position embedding stage and feature interaction stage.\nConsidering the importance of position in saliency comparison, we preserve\nabsolute coordinates of objects in ROI pooling operation and then fuse\npositional information with semantic features in the first stage. In the\nfeature interaction stage, we apply the attention mechanism to obtain\nproposals' contextualized representations to predict their relative ranking\norders. Extensive experiments have been conducted on the ASR dataset. Without\nbells and whistles, our proposed method outperforms the former state-of-the-art\nmethod significantly. The code will be released publicly available.",
          "link": "http://arxiv.org/abs/2106.05047",
          "publishedOn": "2021-06-10T01:56:46.473Z",
          "wordCount": 703,
          "title": "Salient Object Ranking with Position-Preserved Attention. (arXiv:2106.05047v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03180",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_G/0/1/0/all/0/1\">Guolei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_Y/0/1/0/all/0/1\">Yu Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Le Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chhatkuli_A/0/1/0/all/0/1\">Ajad Chhatkuli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1\">Luc Van Gool</a>",
          "description": "We tackle the low-efficiency flaw of vision transformer caused by the high\ncomputational/space complexity in Multi-Head Self-Attention (MHSA). To this\nend, we propose the Hierarchical MHSA (H-MHSA), whose representation is\ncomputed in a hierarchical manner. Specifically, our H-MHSA first learns\nfeature relationships within small grids by viewing image patches as tokens.\nThen, small grids are merged into larger ones, within which feature\nrelationship is learned by viewing each small grid at the preceding step as a\ntoken. This process is iterated to gradually reduce the number of tokens. The\nH-MHSA module is readily pluggable into any CNN architectures and amenable to\ntraining via backpropagation. We call this new backbone TransCNN, and it\nessentially inherits the advantages of both transformer and CNN. Experiments\ndemonstrate that TransCNN achieves state-of-the-art accuracy for image\nrecognition. Code and pretrained models are available at\nhttps://github.com/yun-liu/TransCNN. This technical report will keep updating\nby adding more experiments.",
          "link": "http://arxiv.org/abs/2106.03180",
          "publishedOn": "2021-06-10T01:56:46.466Z",
          "wordCount": 596,
          "title": "Transformer in Convolutional Neural Networks. (arXiv:2106.03180v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03911",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zakka_K/0/1/0/all/0/1\">Kevin Zakka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_A/0/1/0/all/0/1\">Andy Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Florence_P/0/1/0/all/0/1\">Pete Florence</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tompson_J/0/1/0/all/0/1\">Jonathan Tompson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bohg_J/0/1/0/all/0/1\">Jeannette Bohg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dwibedi_D/0/1/0/all/0/1\">Debidatta Dwibedi</a>",
          "description": "We investigate the visual cross-embodiment imitation setting, in which agents\nlearn policies from videos of other agents (such as humans) demonstrating the\nsame task, but with stark differences in their embodiments -- shape, actions,\nend-effector dynamics, etc. In this work, we demonstrate that it is possible to\nautomatically discover and learn vision-based reward functions from\ncross-embodiment demonstration videos that are robust to these differences.\nSpecifically, we present a self-supervised method for Cross-embodiment Inverse\nReinforcement Learning (XIRL) that leverages temporal cycle-consistency\nconstraints to learn deep visual embeddings that capture task progression from\noffline videos of demonstrations across multiple expert agents, each performing\nthe same task differently due to embodiment differences. Prior to our work,\nproducing rewards from self-supervised embeddings has typically required\nalignment with a reference trajectory, which may be difficult to acquire. We\nshow empirically that if the embeddings are aware of task-progress, simply\ntaking the negative distance between the current state and goal state in the\nlearned embedding space is useful as a reward for training policies with\nreinforcement learning. We find our learned reward function not only works for\nembodiments seen during training, but also generalizes to entirely new\nembodiments. We also find that XIRL policies are more sample efficient than\nbaselines, and in some cases exceed the sample efficiency of the same agent\ntrained with ground truth sparse rewards.",
          "link": "http://arxiv.org/abs/2106.03911",
          "publishedOn": "2021-06-10T01:56:46.449Z",
          "wordCount": 656,
          "title": "XIRL: Cross-embodiment Inverse Reinforcement Learning. (arXiv:2106.03911v1 [cs.RO] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.10611",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Deb_D/0/1/0/all/0/1\">Diptodip Deb</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jiao_Z/0/1/0/all/0/1\">Zhenfei Jiao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_A/0/1/0/all/0/1\">Alex B. Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ahrens_M/0/1/0/all/0/1\">Misha B. Ahrens</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Podgorski_K/0/1/0/all/0/1\">Kaspar Podgorski</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Turaga_S/0/1/0/all/0/1\">Srinivas C. Turaga</a>",
          "description": "3D snapshot microscopy enables fast volumetric imaging by capturing a 3D\nvolume in a single 2D camera image, and has found a variety of biological\napplications such as whole brain imaging of fast neural activity in larval\nzebrafish. The optimal microscope design for this optical 3D-to-2D encoding is\nboth sample- and task-dependent, with no general solution known. Highly\nprogrammable optical elements create new possibilities for sample-specific\ncomputational optimization of microscope parameters, e.g. tuning the collection\nof light for a given sample structure. We perform such optimization with deep\nlearning, using a differentiable wave-optics simulation of light propagation\nthrough a programmable microscope and a neural network to reconstruct volumes\nfrom the microscope image. We introduce a class of global kernel Fourier\nconvolutional neural networks which can efficiently decode information from\nmultiple depths in the volume, globally encoded across a 3D snapshot image. We\nshow that our proposed networks succeed in large field of view volume\nreconstruction and microscope parameter optimization where traditional networks\nfail. We also show that our networks outperform the state-of-the-art learned\nreconstruction algorithms for lensless computational photography.",
          "link": "http://arxiv.org/abs/2104.10611",
          "publishedOn": "2021-06-10T01:56:46.444Z",
          "wordCount": 656,
          "title": "Programmable 3D snapshot microscopy with Fourier convolutional networks. (arXiv:2104.10611v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05082",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Peng_L/0/1/0/all/0/1\">Lintao Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bian_L/0/1/0/all/0/1\">Liheng Bian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tiexin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jun Zhang</a>",
          "description": "Wide-field and high-resolution (HR) imaging is essential for various\napplications such as aviation reconnaissance, topographic mapping and safety\nmonitoring. The existing techniques require a large-scale detector array to\ncapture HR images of the whole field, resulting in high complexity and heavy\ncost. In this work, we report an agile wide-field imaging framework with\nselective high resolution that requires only two detectors. It builds on the\nstatistical sparsity prior of natural scenes that the important targets locate\nonly at small regions of interests (ROI), instead of the whole field. Under\nthis assumption, we use a short-focal camera to image wide field with a certain\nlow resolution, and use a long-focal camera to acquire the HR images of ROI. To\nautomatically locate ROI in the wide field in real time, we propose an\nefficient deep-learning based multiscale registration method that is robust and\nblind to the large setting differences (focal, white balance, etc) between the\ntwo cameras. Using the registered location, the long-focal camera mounted on a\ngimbal enables real-time tracking of the ROI for continuous HR imaging. We\ndemonstrated the novel imaging framework by building a proof-of-concept setup\nwith only 1181 gram weight, and assembled it on an unmanned aerial vehicle for\nair-to-ground monitoring. Experiments show that the setup maintains\n120$^{\\circ}$ wide field-of-view (FOV) with selective 0.45$mrad$ instantaneous\nFOV.",
          "link": "http://arxiv.org/abs/2106.05082",
          "publishedOn": "2021-06-10T01:56:46.438Z",
          "wordCount": 653,
          "title": "Agile wide-field imaging with selective high resolution. (arXiv:2106.05082v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05003",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jingyuan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_G/0/1/0/all/0/1\">Guanchen Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yuchen Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_W/0/1/0/all/0/1\">Wenwei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1\">Kangmin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_T/0/1/0/all/0/1\">Tianyi Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhe Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_W/0/1/0/all/0/1\">Wanping Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_H/0/1/0/all/0/1\">Hao Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhenzhong Chen</a>",
          "description": "Traffic anomaly detection has played a crucial role in Intelligent\nTransportation System (ITS). The main challenges of this task lie in the highly\ndiversified anomaly scenes and variational lighting conditions. Although much\nwork has managed to identify the anomaly in homogenous weather and scene, few\nresolved to cope with complex ones. In this paper, we proposed a dual-modality\nmodularized methodology for the robust detection of abnormal vehicles. We\nintroduced an integrated anomaly detection framework comprising the following\nmodules: background modeling, vehicle tracking with detection, mask\nconstruction, Region of Interest (ROI) backtracking, and dual-modality tracing.\nConcretely, we employed background modeling to filter the motion information\nand left the static information for later vehicle detection. For the vehicle\ndetection and tracking module, we adopted YOLOv5 and multi-scale tracking to\nlocalize the anomalies. Besides, we utilized the frame difference and tracking\nresults to identify the road and obtain the mask. In addition, we introduced\nmultiple similarity estimation metrics to refine the anomaly period via\nbacktracking. Finally, we proposed a dual-modality bilateral tracing module to\nrefine the time further. The experiments conducted on the Track 4 testset of\nthe NVIDIA 2021 AI City Challenge yielded a result of 0.9302 F1-Score and\n3.4039 root mean square error (RMSE), indicating the effectiveness of our\nframework.",
          "link": "http://arxiv.org/abs/2106.05003",
          "publishedOn": "2021-06-10T01:56:46.432Z",
          "wordCount": 664,
          "title": "Dual-Modality Vehicle Anomaly Detection via Bilateral Trajectory Tracing. (arXiv:2106.05003v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04921",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yuhang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_Z/0/1/0/all/0/1\">Zilin Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1\">Xuan Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaomin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Ming Liu</a>",
          "description": "Traditional self-supervised learning requires CNNs using external pretext\ntasks (i.e., image- or video-based tasks) to encode high-level semantic visual\nrepresentations. In this paper, we show that feature transformations within\nCNNs can also be regarded as supervisory signals to construct the\nself-supervised task, called \\emph{internal pretext task}. And such a task can\nbe applied for the enhancement of supervised learning. Specifically, we first\ntransform the internal feature maps by discarding different channels, and then\ndefine an additional internal pretext task to identify the discarded channels.\nCNNs are trained to predict the joint labels generated by the combination of\nself-supervised labels and original labels. By doing so, we let CNNs know which\nchannels are missing while classifying in the hope to mine richer feature\ninformation. Extensive experiments show that our approach is effective on\nvarious models and datasets. And it's worth noting that we only incur\nnegligible computational overhead. Furthermore, our approach can also be\ncompatible with other methods to get better results.",
          "link": "http://arxiv.org/abs/2106.04921",
          "publishedOn": "2021-06-10T01:56:46.426Z",
          "wordCount": 597,
          "title": "Self-supervised Feature Enhancement: Applying Internal Pretext Task to Supervised Learning. (arXiv:2106.04921v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05215",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_S/0/1/0/all/0/1\">Sumit Mukherjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sederholm_T/0/1/0/all/0/1\">Tina Sederholm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roman_A/0/1/0/all/0/1\">Anthony C. Roman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sankar_R/0/1/0/all/0/1\">Ria Sankar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caltagirone_S/0/1/0/all/0/1\">Sherrie Caltagirone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferres_J/0/1/0/all/0/1\">Juan Lavista Ferres</a>",
          "description": "Child trafficking in a serious problem around the world. Every year there are\nmore than 4 million victims of child trafficking around the world, many of them\nfor the purposes of child sexual exploitation. In collaboration with UK Police\nand a non-profit focused on child abuse prevention, Global Emancipation\nNetwork, we developed a proof-of-concept machine learning pipeline to aid the\nidentification of children from intercepted images. In this work, we focus on\nimages that contain children wearing school uniforms to identify the school of\norigin. In the absence of a machine learning pipeline, this hugely time\nconsuming and labor intensive task is manually conducted by law enforcement\npersonnel. Thus, by automating aspects of the school identification process, we\nhope to significantly impact the speed of this portion of child identification.\nOur proposed pipeline consists of two machine learning models: i) to identify\nwhether an image of a child contains a school uniform in it, and ii)\nidentification of attributes of different school uniform items (such as\ncolor/texture of shirts, sweaters, blazers etc.). We describe the data\ncollection, labeling, model development and validation process, along with\nstrategies for efficient searching of schools using the model predictions.",
          "link": "http://arxiv.org/abs/2106.05215",
          "publishedOn": "2021-06-10T01:56:46.410Z",
          "wordCount": 638,
          "title": "A machine learning pipeline for aiding school identification from child trafficking images. (arXiv:2106.05215v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04957",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_Sosa_E/0/1/0/all/0/1\">E. Gonzalez-Sosa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Robledo_G/0/1/0/all/0/1\">G. Robledo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_Morin_D/0/1/0/all/0/1\">D. Gonzalez-Morin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perez_Garcia_P/0/1/0/all/0/1\">P. Perez-Garcia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Villegas_A/0/1/0/all/0/1\">A. Villegas</a>",
          "description": "Egocentric segmentation has attracted recent interest in the computer vision\ncommunity due to their potential in Mixed Reality (MR) applications. While most\nprevious works have been focused on segmenting egocentric human body parts\n(mainly hands), little attention has been given to egocentric objects. Due to\nthe lack of datasets of pixel-wise annotations of egocentric objects, in this\npaper we contribute with a semantic-wise labeling of a subset of 2124 images\nfrom the RGB-D THU-READ Dataset. We also report benchmarking results using\nThundernet, a real-time semantic segmentation network, that could allow future\nintegration with end-to-end MR applications.",
          "link": "http://arxiv.org/abs/2106.04957",
          "publishedOn": "2021-06-10T01:56:46.405Z",
          "wordCount": 539,
          "title": "Real Time Egocentric Object Segmentation: THU-READ Labeling and Benchmarking Results. (arXiv:2106.04957v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05132",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ciano_G/0/1/0/all/0/1\">Giorgio Ciano</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Andreini_P/0/1/0/all/0/1\">Paolo Andreini</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mazzierli_T/0/1/0/all/0/1\">Tommaso Mazzierli</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bianchini_M/0/1/0/all/0/1\">Monica Bianchini</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Scarselli_F/0/1/0/all/0/1\">Franco Scarselli</a>",
          "description": "Multi-organ segmentation of X-ray images is of fundamental importance for\ncomputer aided diagnosis systems. However, the most advanced semantic\nsegmentation methods rely on deep learning and require a huge amount of labeled\nimages, which are rarely available due to both the high cost of human resources\nand the time required for labeling. In this paper, we present a novel\nmulti-stage generation algorithm based on Generative Adversarial Networks\n(GANs) that can produce synthetic images along with their semantic labels and\ncan be used for data augmentation. The main feature of the method is that,\nunlike other approaches, generation occurs in several stages, which simplifies\nthe procedure and allows it to be used on very small datasets. The method has\nbeen evaluated on the segmentation of chest radiographic images, showing\npromising results. The multistage approach achieves state-of-the-art and, when\nvery few images are used to train the GANs, outperforms the corresponding\nsingle-stage approach.",
          "link": "http://arxiv.org/abs/2106.05132",
          "publishedOn": "2021-06-10T01:56:46.399Z",
          "wordCount": 598,
          "title": "A multi-stage GAN for multi-organ chest X-ray image generation and segmentation. (arXiv:2106.05132v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05095",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Lihe Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuo_W/0/1/0/all/0/1\">Wei Zhuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_L/0/1/0/all/0/1\">Lei Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yinghuan Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yang Gao</a>",
          "description": "In this paper, we investigate if we could make the self-training -- a simple\nbut popular framework -- work better for semi-supervised segmentation. Since\nthe core issue in semi-supervised setting lies in effective and efficient\nutilization of unlabeled data, we notice that increasing the diversity and\nhardness of unlabeled data is crucial to performance improvement. Being aware\nof this fact, we propose to adopt the most plain self-training scheme coupled\nwith appropriate strong data augmentations on unlabeled data (namely ST) for\nthis task, which surprisingly outperforms previous methods under various\nsettings without any bells and whistles. Moreover, to alleviate the negative\nimpact of the wrongly pseudo labeled images, we further propose an advanced\nself-training framework (namely ST++), that performs selective re-training via\nselecting and prioritizing the more reliable unlabeled images. As a result, the\nproposed ST++ boosts the performance of semi-supervised model significantly and\nsurpasses existing methods by a large margin on the Pascal VOC 2012 and\nCityscapes benchmark. Overall, we hope this straightforward and simple\nframework will serve as a strong baseline or competitor for future works. Code\nis available at https://github.com/LiheYoung/ST-PlusPlus.",
          "link": "http://arxiv.org/abs/2106.05095",
          "publishedOn": "2021-06-10T01:56:46.394Z",
          "wordCount": 624,
          "title": "ST++: Make Self-training Work Better for Semi-supervised Semantic Segmentation. (arXiv:2106.05095v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05233",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Walter_B/0/1/0/all/0/1\">Benjamin Walter</a>",
          "description": "Image classification is considered, and a hierarchical max-pooling model with\nadditional local pooling is introduced. Here the additional local pooling\nenables the hierachical model to combine parts of the image which have a\nvariable relative distance towards each other. Various convolutional neural\nnetwork image classifiers are introduced and compared in view of their rate of\nconvergence. The finite sample size performance of the estimates is analyzed by\napplying them to simulated and real data.",
          "link": "http://arxiv.org/abs/2106.05233",
          "publishedOn": "2021-06-10T01:56:46.388Z",
          "wordCount": 529,
          "title": "Analysis of convolutional neural network image classifiers in a hierarchical max-pooling model with additional local pooling. (arXiv:2106.05233v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05144",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Riba_P/0/1/0/all/0/1\">Pau Riba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Molina_A/0/1/0/all/0/1\">Adri&#xe0; Molina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gomez_L/0/1/0/all/0/1\">Lluis Gomez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramos_Terrades_O/0/1/0/all/0/1\">Oriol Ramos-Terrades</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Llados_J/0/1/0/all/0/1\">Josep Llad&#xf3;s</a>",
          "description": "In this paper, we explore and evaluate the use of ranking-based objective\nfunctions for learning simultaneously a word string and a word image encoder.\nWe consider retrieval frameworks in which the user expects a retrieval list\nranked according to a defined relevance score. In the context of a word\nspotting problem, the relevance score has been set according to the string edit\ndistance from the query string. We experimentally demonstrate the competitive\nperformance of the proposed model on query-by-string word spotting for both,\nhandwritten and real scene word images. We also provide the results for\nquery-by-example word spotting, although it is not the main focus of this work.",
          "link": "http://arxiv.org/abs/2106.05144",
          "publishedOn": "2021-06-10T01:56:46.373Z",
          "wordCount": 552,
          "title": "Learning to Rank Words: Optimizing Ranking Metrics for Word Spotting. (arXiv:2106.05144v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05209",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1\">Shuxuan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alvarez_J/0/1/0/all/0/1\">Jose M. Alvarez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salzmann_M/0/1/0/all/0/1\">Mathieu Salzmann</a>",
          "description": "Knowledge distillation constitutes a simple yet effective way to improve the\nperformance of a compact student network by exploiting the knowledge of a more\npowerful teacher. Nevertheless, the knowledge distillation literature remains\nlimited to the scenario where the student and the teacher tackle the same task.\nHere, we investigate the problem of transferring knowledge not only across\narchitectures but also across tasks. To this end, we study the case of object\ndetection and, instead of following the standard detector-to-detector\ndistillation approach, introduce a classifier-to-detector knowledge transfer\nframework. In particular, we propose strategies to exploit the classification\nteacher to improve both the detector's recognition accuracy and localization\nperformance. Our experiments on several detectors with different backbones\ndemonstrate the effectiveness of our approach, allowing us to outperform the\nstate-of-the-art detector-to-detector distillation methods.",
          "link": "http://arxiv.org/abs/2106.05209",
          "publishedOn": "2021-06-10T01:56:46.366Z",
          "wordCount": 562,
          "title": "Distilling Image Classifiers in Object Detectors. (arXiv:2106.05209v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05036",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1\">Dawei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tongliang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1\">Bo Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_N/0/1/0/all/0/1\">Nannan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_C/0/1/0/all/0/1\">Chunlei Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1\">Xinbo Gao</a>",
          "description": "Deep neural networks (DNNs) are vulnerable to adversarial noise. Their\nadversarial robustness can be improved by exploiting adversarial examples.\nHowever, given the continuously evolving attacks, models trained on seen types\nof adversarial examples generally cannot generalize well to unseen types of\nadversarial examples. To solve this problem, in this paper, we propose to\nremove adversarial noise by learning generalizable invariant features across\nattacks which maintain semantic classification information. Specifically, we\nintroduce an adversarial feature learning mechanism to disentangle invariant\nfeatures from adversarial noise. A normalization term has been proposed in the\nencoded space of the attack-invariant features to address the bias issue\nbetween the seen and unseen types of attacks. Empirical evaluations demonstrate\nthat our method could provide better protection in comparison to previous\nstate-of-the-art approaches, especially against unseen types of attacks and\nadaptive attacks.",
          "link": "http://arxiv.org/abs/2106.05036",
          "publishedOn": "2021-06-10T01:56:46.358Z",
          "wordCount": 569,
          "title": "Towards Defending against Adversarial Examples via Attack-Invariant Features. (arXiv:2106.05036v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05094",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yancong Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pintea_S/0/1/0/all/0/1\">Silvia-Laura Pintea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gemert_J/0/1/0/all/0/1\">Jan van Gemert</a>",
          "description": "Current work on lane detection relies on large manually annotated datasets.\nWe reduce the dependency on annotations by leveraging massive cheaply available\nunlabelled data. We propose a novel loss function exploiting geometric\nknowledge of lanes in Hough space, where a lane can be identified as a local\nmaximum. By splitting lanes into separate channels, we can localize each lane\nvia simple global max-pooling. The location of the maximum encodes the layout\nof a lane, while the intensity indicates the the probability of a lane being\npresent. Maximizing the log-probability of the maximal bins helps neural\nnetworks find lanes without labels. On the CULane and TuSimple datasets, we\nshow that the proposed Hough Transform loss improves performance significantly\nby learning from large amounts of unlabelled images.",
          "link": "http://arxiv.org/abs/2106.05094",
          "publishedOn": "2021-06-10T01:56:46.352Z",
          "wordCount": 553,
          "title": "Semi-supervised lane detection with Deep Hough Transform. (arXiv:2106.05094v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.14314",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yuanpeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hui_Q/0/1/0/all/0/1\">Qinglei Hui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_Z/0/1/0/all/0/1\">Zhiyi Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_S/0/1/0/all/0/1\">Shaolin Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_D/0/1/0/all/0/1\">Dexing Kong</a>",
          "description": "Accurate segmentation for medical images is important for clinical diagnosis.\nExisting automatic segmentation methods are mainly based on fully supervised\nlearning and have an extremely high demand for precise annotations, which are\nvery costly and time-consuming to obtain. To address this problem, we proposed\nan automatic CT segmentation method based on weakly supervised learning, by\nwhich one could train an accurate segmentation model only with weak annotations\nin the form of bounding boxes. The proposed method is composed of two steps: 1)\ngenerating pseudo masks with bounding box annotations by k-means clustering,\nand 2) iteratively training a 3D U-Net convolutional neural network as a\nsegmentation model. Some data pre-processing methods are used to improve\nperformance. The method was validated on four datasets containing three types\nof organs with a total of 627 CT volumes. For liver, spleen and kidney\nsegmentation, it achieved an accuracy of 95.19%, 92.11%, and 91.45%,\nrespectively. Experimental results demonstrate that our method is accurate,\nefficient, and suitable for clinical use.",
          "link": "http://arxiv.org/abs/2105.14314",
          "publishedOn": "2021-06-10T01:56:46.347Z",
          "wordCount": 627,
          "title": "Automatic CT Segmentation from Bounding Box Annotations using Convolutional Neural Networks. (arXiv:2105.14314v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05152",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Peng_L/0/1/0/all/0/1\">Le Peng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liang_H/0/1/0/all/0/1\">Hengyue Liang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_T/0/1/0/all/0/1\">Taihui Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sun_J/0/1/0/all/0/1\">Ju Sun</a>",
          "description": "Transfer learning (TL) with deep convolutional neural networks (DCNNs) has\nproved successful in medical image classification (MIC). However, the current\npractice is puzzling, as MIC typically relies only on low- and/or mid-level\nfeatures that are learned in the bottom layers of DCNNs. Following this\nintuition, we question the current strategies of TL in MIC. In this paper, we\nperform careful experimental comparisons between shallow and deep networks for\nclassification on two chest x-ray datasets, using different TL strategies. We\nfind that deep models are not always favorable, and finetuning truncated deep\nmodels almost always yields the best performance, especially in data-poor\nregimes.\n\nProject webpage:\nhttps://github.com/sun-umn/Transfer-Learning-in-Medical-Imaging\n\nKeywords: Transfer learning, Medical image classification, Feature hierarchy,\nMedical imaging, Evaluation metrics, Imbalanced data",
          "link": "http://arxiv.org/abs/2106.05152",
          "publishedOn": "2021-06-10T01:56:46.341Z",
          "wordCount": 567,
          "title": "Rethink Transfer Learning in Medical Image Classification. (arXiv:2106.05152v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05230",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Barbero_Gomez_J/0/1/0/all/0/1\">Javier Barbero-G&#xf3;mez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gutierrez_P/0/1/0/all/0/1\">Pedro-Antonio Guti&#xe9;rrez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vargas_V/0/1/0/all/0/1\">V&#xed;ctor-Manuel Vargas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vallejo_Casas_J/0/1/0/all/0/1\">Juan-Antonio Vallejo-Casas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hervas_Martinez_C/0/1/0/all/0/1\">C&#xe9;sar Herv&#xe1;s-Mart&#xed;nez</a>",
          "description": "3D image scans are an assessment tool for neurological damage in Parkinson's\ndisease (PD) patients. This diagnosis process can be automatized to help\nmedical staff through Decision Support Systems (DSSs), and Convolutional Neural\nNetworks (CNNs) are good candidates, because they are effective when applied to\nspatial data. This paper proposes a 3D CNN ordinal model for assessing the\nlevel or neurological damage in PD patients. Given that CNNs need large\ndatasets to achieve acceptable performance, a data augmentation method is\nadapted to work with spatial data. We consider the Ordinal Graph-based\nOversampling via Shortest Paths (OGO-SP) method, which applies a gamma\nprobability distribution for inter-class data generation. A modification of\nOGO-SP is proposed, the OGO-SP-$\\beta$ algorithm, which applies the beta\ndistribution for generating synthetic samples in the inter-class region, a\nbetter suited distribution when compared to gamma. The evaluation of the\ndifferent methods is based on a novel 3D image dataset provided by the Hospital\nUniversitario 'Reina Sof\\'ia' (C\\'ordoba, Spain). We show how the ordinal\nmethodology improves the performance with respect to the nominal one, and how\nOGO-SP-$\\beta$ yields better performance than OGO-SP.",
          "link": "http://arxiv.org/abs/2106.05230",
          "publishedOn": "2021-06-10T01:56:46.324Z",
          "wordCount": 645,
          "title": "An ordinal CNN approach for the assessment of neurological damage in Parkinson's disease patients. (arXiv:2106.05230v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05237",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Beyer_L/0/1/0/all/0/1\">Lucas Beyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_X/0/1/0/all/0/1\">Xiaohua Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Royer_A/0/1/0/all/0/1\">Am&#xe9;lie Royer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Markeeva_L/0/1/0/all/0/1\">Larisa Markeeva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anil_R/0/1/0/all/0/1\">Rohan Anil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolesnikov_A/0/1/0/all/0/1\">Alexander Kolesnikov</a>",
          "description": "There is a growing discrepancy in computer vision between large-scale models\nthat achieve state-of-the-art performance and models that are affordable in\npractical applications. In this paper we address this issue and significantly\nbridge the gap between these two types of models. Throughout our empirical\ninvestigation we do not aim to necessarily propose a new method, but strive to\nidentify a robust and effective recipe for making state-of-the-art large scale\nmodels affordable in practice. We demonstrate that, when performed correctly,\nknowledge distillation can be a powerful tool for reducing the size of large\nmodels without compromising their performance. In particular, we uncover that\nthere are certain implicit design choices, which may drastically affect the\neffectiveness of distillation. Our key contribution is the explicit\nidentification of these design choices, which were not previously articulated\nin the literature. We back up our findings by a comprehensive empirical study,\ndemonstrate compelling results on a wide range of vision datasets and, in\nparticular, obtain a state-of-the-art ResNet-50 model for ImageNet, which\nachieves 82.8\\% top-1 accuracy.",
          "link": "http://arxiv.org/abs/2106.05237",
          "publishedOn": "2021-06-10T01:56:46.293Z",
          "wordCount": 623,
          "title": "Knowledge distillation: A good teacher is patient and consistent. (arXiv:2106.05237v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04996",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fang_S/0/1/0/all/0/1\">Sheng Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1\">Kaiyu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhe Li</a>",
          "description": "The self-attention mechanism has attracted wide publicity for its most\nimportant advantage of modeling long dependency, and its variations in computer\nvision tasks, the non-local block tries to model the global dependency of the\ninput feature maps. Gathering global contextual information will inevitably\nneed a tremendous amount of memory and computing resources, which has been\nextensively studied in the past several years. However, there is a further\nproblem with the self-attention scheme: is all information gathered from the\nglobal scope helpful for the contextual modelling? To our knowledge, few\nstudies have focused on the problem. Aimed at both questions this paper\nproposes the salient positions-based attention scheme SPANet, which is inspired\nby some interesting observations on the attention maps and affinity matrices\ngenerated in self-attention scheme. We believe these observations are\nbeneficial for better understanding of the self-attention. SPANet uses the\nsalient positions selection algorithm to select only a limited amount of\nsalient points to attend in the attention map computing. This approach will not\nonly spare a lot of memory and computing resources, but also try to distill the\npositive information from the transformation of the input feature maps. In the\nimplementation, considering the feature maps with channel high dimensions,\nwhich are completely different from the general visual image, we take the\nsquared power of the feature maps along the channel dimension as the saliency\nmetric of the positions. In general, different from the non-local block method,\nSPANet models the contextual information using only the selected positions\ninstead of all, along the channel dimension instead of space dimension. Our\nsource code is available at https://github.com/likyoo/SPANet.",
          "link": "http://arxiv.org/abs/2106.04996",
          "publishedOn": "2021-06-10T01:56:46.285Z",
          "wordCount": 695,
          "title": "Salient Positions based Attention Network for Image Classification. (arXiv:2106.04996v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05121",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bouchacourt_D/0/1/0/all/0/1\">Diane Bouchacourt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ibrahim_M/0/1/0/all/0/1\">Mark Ibrahim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morcos_A/0/1/0/all/0/1\">Ari S. Morcos</a>",
          "description": "To perform well on unseen and potentially out-of-distribution samples, it is\ndesirable for machine learning models to have a predictable response with\nrespect to transformations affecting the factors of variation of the input.\nInvariance is commonly achieved through hand-engineered data augmentation, but\ndo standard data augmentations address transformations that explain variations\nin real data? While prior work has focused on synthetic data, we attempt here\nto characterize the factors of variation in a real dataset, ImageNet, and study\nthe invariance of both standard residual networks and the recently proposed\nvision transformer with respect to changes in these factors. We show standard\naugmentation relies on a precise combination of translation and scale, with\ntranslation recapturing most of the performance improvement -- despite the\n(approximate) translation invariance built in to convolutional architectures,\nsuch as residual networks. In fact, we found that scale and translation\ninvariance was similar across residual networks and vision transformer models\ndespite their markedly different inductive biases. We show the training data\nitself is the main source of invariance, and that data augmentation only\nfurther increases the learned invariances. Interestingly, the invariances\nbrought from the training process align with the ImageNet factors of variation\nwe found. Finally, we find that the main factors of variation in ImageNet\nmostly relate to appearance and are specific to each class.",
          "link": "http://arxiv.org/abs/2106.05121",
          "publishedOn": "2021-06-10T01:56:46.277Z",
          "wordCount": 653,
          "title": "Grounding inductive biases in natural images:invariance stems from variations in data. (arXiv:2106.05121v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05001",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_M/0/1/0/all/0/1\">Mi Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1\">Fei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_D/0/1/0/all/0/1\">Dapeng Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yifan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1\">Jian Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jiashi Feng</a>",
          "description": "A central challenge in training classification models in the real-world\nfederated system is learning with non-IID data. To cope with this, most of the\nexisting works involve enforcing regularization in local optimization or\nimproving the model aggregation scheme at the server. Other works also share\npublic datasets or synthesized samples to supplement the training of\nunder-represented classes or introduce a certain level of personalization.\nThough effective, they lack a deep understanding of how the data heterogeneity\naffects each layer of a deep classification model. In this paper, we bridge\nthis gap by performing an experimental analysis of the representations learned\nby different layers. Our observations are surprising: (1) there exists a\ngreater bias in the classifier than other layers, and (2) the classification\nperformance can be significantly improved by post-calibrating the classifier\nafter federated training. Motivated by the above findings, we propose a novel\nand simple algorithm called Classifier Calibration with Virtual Representations\n(CCVR), which adjusts the classifier using virtual representations sampled from\nan approximated gaussian mixture model. Experimental results demonstrate that\nCCVR achieves state-of-the-art performance on popular federated learning\nbenchmarks including CIFAR-10, CIFAR-100, and CINIC-10. We hope that our simple\nyet effective method can shed some light on the future research of federated\nlearning with non-IID data.",
          "link": "http://arxiv.org/abs/2106.05001",
          "publishedOn": "2021-06-10T01:56:46.259Z",
          "wordCount": 666,
          "title": "No Fear of Heterogeneity: Classifier Calibration for Federated Learning with Non-IID Data. (arXiv:2106.05001v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04732",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Berthelot_D/0/1/0/all/0/1\">David Berthelot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roelofs_R/0/1/0/all/0/1\">Rebecca Roelofs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sohn_K/0/1/0/all/0/1\">Kihyuk Sohn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carlini_N/0/1/0/all/0/1\">Nicholas Carlini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurakin_A/0/1/0/all/0/1\">Alex Kurakin</a>",
          "description": "We extend semi-supervised learning to the problem of domain adaptation to\nlearn significantly higher-accuracy models that train on one data distribution\nand test on a different one. With the goal of generality, we introduce\nAdaMatch, a method that unifies the tasks of unsupervised domain adaptation\n(UDA), semi-supervised learning (SSL), and semi-supervised domain adaptation\n(SSDA). In an extensive experimental study, we compare its behavior with\nrespective state-of-the-art techniques from SSL, SSDA, and UDA on vision\nclassification tasks. We find AdaMatch either matches or significantly exceeds\nthe state-of-the-art in each case using the same hyper-parameters regardless of\nthe dataset or task. For example, AdaMatch nearly doubles the accuracy compared\nto that of the prior state-of-the-art on the UDA task for DomainNet and even\nexceeds the accuracy of the prior state-of-the-art obtained with pre-training\nby 6.4% when AdaMatch is trained completely from scratch. Furthermore, by\nproviding AdaMatch with just one labeled example per class from the target\ndomain (i.e., the SSDA setting), we increase the target accuracy by an\nadditional 6.1%, and with 5 labeled examples, by 13.6%.",
          "link": "http://arxiv.org/abs/2106.04732",
          "publishedOn": "2021-06-10T01:56:46.254Z",
          "wordCount": 616,
          "title": "AdaMatch: A Unified Approach to Semi-Supervised Learning and Domain Adaptation. (arXiv:2106.04732v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04840",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jin Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_B/0/1/0/all/0/1\">Bin Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yaowei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yonghong Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Feng Wu</a>",
          "description": "Tracking-by-detection is a very popular framework for single object tracking\nwhich attempts to search the target object within a local search window for\neach frame. Although such local search mechanism works well on simple videos,\nhowever, it makes the trackers sensitive to extremely challenging scenarios,\nsuch as heavy occlusion and fast motion. In this paper, we propose a novel and\ngeneral target-aware attention mechanism (termed TANet) and integrate it with\ntracking-by-detection framework to conduct joint local and global search for\nrobust tracking. Specifically, we extract the features of target object patch\nand continuous video frames, then we concatenate and feed them into a decoder\nnetwork to generate target-aware global attention maps. More importantly, we\nresort to adversarial training for better attention prediction. The appearance\nand motion discriminator networks are designed to ensure its consistency in\nspatial and temporal views. In the tracking procedure, we integrate the\ntarget-aware attention with multiple trackers by exploring candidate search\nregions for robust tracking. Extensive experiments on both short-term and\nlong-term tracking benchmark datasets all validated the effectiveness of our\nalgorithm. The project page of this paper can be found at\n\\url{https://sites.google.com/view/globalattentiontracking/home/extend}.",
          "link": "http://arxiv.org/abs/2106.04840",
          "publishedOn": "2021-06-10T01:56:46.238Z",
          "wordCount": 641,
          "title": "Tracking by Joint Local and Global Search: A Target-aware Attention based Approach. (arXiv:2106.04840v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04898",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Garcia_Fernandez_A/0/1/0/all/0/1\">&#xc1;ngel F. Garc&#xed;a-Fern&#xe1;ndez</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yi_W/0/1/0/all/0/1\">Wei Yi</a>",
          "description": "This paper derives the optimal Bayesian processing of an out-of-sequence\n(OOS) set of measurements in continuous-time for multiple target tracking. We\nconsider a multi-target system modelled in continuous time that is discretised\nat the time steps when we receive the measurements, which are distributed\naccording to the standard point target model. All information about this system\nat the sampled time steps is provided by the posterior density on the set of\nall trajectories. This density can be computed via the continuous-discrete\ntrajectory Poisson multi-Bernoulli mixture (TPMBM) filter. When we receive an\nOOS measurement, the optimal Bayesian processing performs a retrodiction step\nthat adds trajectory information at the OOS measurement time stamp followed by\nan update step. After the OOS measurement update, the posterior remains in\nTPMBM form. We also provide a computationally lighter alternative based on a\ntrajectory Poisson multi-Bernoulli filter. The effectiveness of the two\napproaches to handle OOS measurements is evaluated via simulations.",
          "link": "http://arxiv.org/abs/2106.04898",
          "publishedOn": "2021-06-10T01:56:46.228Z",
          "wordCount": 589,
          "title": "Continuous-discrete multiple target tracking with out-of-sequence measurements. (arXiv:2106.04898v1 [eess.SY])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04990",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Venkataramanan_S/0/1/0/all/0/1\">Shashanka Venkataramanan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Psomas_B/0/1/0/all/0/1\">Bill Psomas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Avrithis_Y/0/1/0/all/0/1\">Yannis Avrithis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kijak_E/0/1/0/all/0/1\">Ewa Kijak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amsaleg_L/0/1/0/all/0/1\">Laurent Amsaleg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karantzalos_K/0/1/0/all/0/1\">Konstantinos Karantzalos</a>",
          "description": "Metric learning involves learning a discriminative representation such that\nembeddings of similar classes are encouraged to be close, while embeddings of\ndissimilar classes are pushed far apart. State-of-the-art methods focus mostly\non sophisticated loss functions or mining strategies. On the one hand, metric\nlearning losses consider two or more examples at a time. On the other hand,\nmodern data augmentation methods for classification consider two or more\nexamples at a time. The combination of the two ideas is under-studied.\n\nIn this work, we aim to bridge this gap and improve representations using\nmixup, which is a powerful data augmentation approach interpolating two or more\nexamples and corresponding target labels at a time. This task is challenging\nbecause, unlike classification, the loss functions used in metric learning are\nnot additive over examples, so the idea of interpolating target labels is not\nstraightforward. To the best of our knowledge, we are the first to investigate\nmixing examples and target labels for deep metric learning. We develop a\ngeneralized formulation that encompasses existing metric learning loss\nfunctions and modify it to accommodate for mixup, introducing Metric Mix, or\nMetrix. We show that mixing inputs, intermediate representations or embeddings\nalong with target labels significantly improves representations and outperforms\nstate-of-the-art metric learning methods on four benchmark datasets.",
          "link": "http://arxiv.org/abs/2106.04990",
          "publishedOn": "2021-06-10T01:56:46.222Z",
          "wordCount": 651,
          "title": "It Takes Two to Tango: Mixup for Deep Metric Learning. (arXiv:2106.04990v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04914",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lengyel_A/0/1/0/all/0/1\">Attila Lengyel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gemert_J/0/1/0/all/0/1\">Jan C. van Gemert</a>",
          "description": "Group Equivariant Convolutions (GConvs) enable convolutional neural networks\nto be equivariant to various transformation groups, but at an additional\nparameter and compute cost. We investigate the filter parameters learned by\nGConvs and find certain conditions under which they become highly redundant. We\nshow that GConvs can be efficiently decomposed into depthwise separable\nconvolutions while preserving equivariance properties and demonstrate improved\nperformance and data efficiency on two datasets. All code is publicly available\nat github.com/Attila94/SepGrouPy.",
          "link": "http://arxiv.org/abs/2106.04914",
          "publishedOn": "2021-06-10T01:56:46.215Z",
          "wordCount": 502,
          "title": "Exploiting Learned Symmetries in Group Equivariant Convolutions. (arXiv:2106.04914v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04778",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jinka_S/0/1/0/all/0/1\">Sai Sagar Jinka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chacko_R/0/1/0/all/0/1\">Rohan Chacko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_A/0/1/0/all/0/1\">Astitva Srivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Avinash Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narayanan_P/0/1/0/all/0/1\">P.J. Narayanan</a>",
          "description": "3D human body reconstruction from monocular images is an interesting and\nill-posed problem in computer vision with wider applications in multiple\ndomains. In this paper, we propose SHARP, a novel end-to-end trainable network\nthat accurately recovers the detailed geometry and appearance of 3D people in\nloose clothing from a monocular image. We propose a sparse and efficient fusion\nof a parametric body prior with a non-parametric peeled depth map\nrepresentation of clothed models. The parametric body prior constraints our\nmodel in two ways: first, the network retains geometrically consistent body\nparts that are not occluded by clothing, and second, it provides a body shape\ncontext that improves prediction of the peeled depth maps. This enables SHARP\nto recover fine-grained 3D geometrical details with just L1 losses on the 2D\nmaps, given an input image. We evaluate SHARP on publicly available Cloth3D and\nTHuman datasets and report superior performance to state-of-the-art approaches.",
          "link": "http://arxiv.org/abs/2106.04778",
          "publishedOn": "2021-06-10T01:56:46.198Z",
          "wordCount": 583,
          "title": "SHARP: Shape-Aware Reconstruction of People In Loose Clothing. (arXiv:2106.04778v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04961",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Liang_K/0/1/0/all/0/1\">Kai-Chieh Liang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bi_L/0/1/0/all/0/1\">Lei Bi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kumar_A/0/1/0/all/0/1\">Ashnil Kumar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fulham_M/0/1/0/all/0/1\">Michael Fulham</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kim_J/0/1/0/all/0/1\">Jinman Kim</a>",
          "description": "Sequential whole-body 18F-Fluorodeoxyglucose (FDG) positron emission\ntomography (PET) scans are regarded as the imaging modality of choice for the\nassessment of treatment response in the lymphomas because they detect treatment\nresponse when there may not be changes on anatomical imaging. Any computerized\nanalysis of lymphomas in whole-body PET requires automatic segmentation of the\nstudies so that sites of disease can be quantitatively monitored over time.\nState-of-the-art PET image segmentation methods are based on convolutional\nneural networks (CNNs) given their ability to leverage annotated datasets to\nderive high-level features about the disease process. Such methods, however,\nfocus on PET images from a single time-point and discard information from other\nscans or are targeted towards specific organs and cannot cater for the multiple\nstructures in whole-body PET images. In this study, we propose a\nspatio-temporal 'dual-stream' neural network (ST-DSNN) to segment sequential\nwhole-body PET scans. Our ST-DSNN learns and accumulates image features from\nthe PET images done over time. The accumulated image features are used to\nenhance the organs / structures that are consistent over time to allow easier\nidentification of sites of active lymphoma. Our results show that our method\noutperforms the state-of-the-art PET image segmentation methods.",
          "link": "http://arxiv.org/abs/2106.04961",
          "publishedOn": "2021-06-10T01:56:46.192Z",
          "wordCount": 641,
          "title": "Spatio-Temporal Dual-Stream Neural Network for Sequential Whole-Body PET Segmentation. (arXiv:2106.04961v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04803",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dai_Z/0/1/0/all/0/1\">Zihang Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hanxiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1\">Quoc V. Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_M/0/1/0/all/0/1\">Mingxing Tan</a>",
          "description": "Transformers have attracted increasing interests in computer vision, but they\nstill fall behind state-of-the-art convolutional networks. In this work, we\nshow that while Transformers tend to have larger model capacity, their\ngeneralization can be worse than convolutional networks due to the lack of the\nright inductive bias. To effectively combine the strengths from both\narchitectures, we present CoAtNets(pronounced \"coat\" nets), a family of hybrid\nmodels built from two key insights:(1) depthwise Convolution and self-Attention\ncan be naturally unified via simple relative attention; (2) vertically stacking\nconvolution layers and attention layers in a principled way is surprisingly\neffective in improving generalization, capacity and efficiency. Experiments\nshow that our CoAtNets achieve state-of-the-art performance under different\nresource constraints across various datasets. For example, CoAtNet achieves\n86.0% ImageNet top-1 accuracy without extra data, and 89.77% with extra JFT\ndata, outperforming prior arts of both convolutional networks and Transformers.\nNotably, when pre-trained with 13M images fromImageNet-21K, our CoAtNet\nachieves 88.56% top-1 accuracy, matching ViT-huge pre-trained with 300M images\nfrom JFT while using 23x less data.",
          "link": "http://arxiv.org/abs/2106.04803",
          "publishedOn": "2021-06-10T01:56:46.027Z",
          "wordCount": 607,
          "title": "CoAtNet: Marrying Convolution and Attention for All Data Sizes. (arXiv:2106.04803v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04726",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kazemi_A/0/1/0/all/0/1\">Ashkan Kazemi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garimella_K/0/1/0/all/0/1\">Kiran Garimella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shahi_G/0/1/0/all/0/1\">Gautam Kishore Shahi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaffney_D/0/1/0/all/0/1\">Devin Gaffney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hale_S/0/1/0/all/0/1\">Scott A. Hale</a>",
          "description": "WhatsApp is a popular chat application used by over 2 billion users\nworldwide. However, due to end-to-end encryption, there is currently no easy\nway to fact-check content on WhatsApp at scale. In this paper, we analyze the\nusefulness of a crowd-sourced system on WhatsApp through which users can submit\n\"tips\" containing messages they want fact-checked. We compare the tips sent to\na WhatsApp tipline run during the 2019 Indian national elections with the\nmessages circulating in large, public groups on WhatsApp and other social media\nplatforms during the same period. We find that tiplines are a very useful lens\ninto WhatsApp conversations: a significant fraction of messages and images sent\nto the tipline match with the content being shared on public WhatsApp groups\nand other social media. Our analysis also shows that tiplines cover the most\npopular content well, and a majority of such content is often shared to the\ntipline before appearing in large, public WhatsApp groups. Overall, the\nanalysis suggests tiplines can be an effective source for discovering content\nto fact-check.",
          "link": "http://arxiv.org/abs/2106.04726",
          "publishedOn": "2021-06-10T01:56:45.993Z",
          "wordCount": 635,
          "title": "Tiplines to Combat Misinformation on Encrypted Platforms: A Case Study of the 2019 Indian Election on WhatsApp. (arXiv:2106.04726v1 [cs.SI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04627",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Grcic_M/0/1/0/all/0/1\">Matej Grci&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grubisic_I/0/1/0/all/0/1\">Ivan Grubi&#x161;i&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Segvic_S/0/1/0/all/0/1\">Sini&#x161;a &#x160;egvi&#x107;</a>",
          "description": "Normalizing flows are bijective mappings between inputs and latent\nrepresentations with a fully factorized distribution. They are very attractive\ndue to exact likelihood evaluation and efficient sampling. However, their\neffective capacity is often insufficient since the bijectivity constraint\nlimits the model width. We address this issue by incrementally padding\nintermediate representations with noise. We precondition the noise in\naccordance with previous invertible units, which we describe as cross-unit\ncoupling. Our invertible glow-like modules express intra-unit affine coupling\nas a fusion of a densely connected block and Nystr\\\"om self-attention. We refer\nto our architecture as DenseFlow since both cross-unit and intra-unit couplings\nrely on dense connectivity. Experiments show significant improvements due to\nthe proposed contributions, and reveal state-of-the-art density estimation\namong all generative models under moderate computing budgets.",
          "link": "http://arxiv.org/abs/2106.04627",
          "publishedOn": "2021-06-10T01:56:45.957Z",
          "wordCount": 551,
          "title": "Densely connected normalizing flows. (arXiv:2106.04627v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04852",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1\">Baoyun Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Min Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Heng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhaoning Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dongsheng Li</a>",
          "description": "Face recognition has made significant progress in recent years due to deep\nconvolutional neural networks (CNN). In many face recognition (FR) scenarios,\nface images are acquired from a sequence with huge intra-variations. These\nintra-variations, which are mainly affected by the low-quality face images,\ncause instability of recognition performance. Previous works have focused on\nad-hoc methods to select frames from a video or use face image quality\nassessment (FIQA) methods, which consider only a particular or combination of\nseveral distortions.\n\nIn this work, we present an efficient non-reference image quality assessment\nfor FR that directly links image quality assessment (IQA) and FR. More\nspecifically, we propose a new measurement to evaluate image quality without\nany reference. Based on the proposed quality measurement, we propose a deep\nTiny Face Quality network (tinyFQnet) to learn a quality prediction function\nfrom data.\n\nWe evaluate the proposed method for different powerful FR models on two\nclassical video-based (or template-based) benchmark: IJB-B and YTF. Extensive\nexperiments show that, although the tinyFQnet is much smaller than the others,\nthe proposed method outperforms state-of-the-art quality assessment methods in\nterms of effectiveness and efficiency.",
          "link": "http://arxiv.org/abs/2106.04852",
          "publishedOn": "2021-06-10T01:56:45.951Z",
          "wordCount": 619,
          "title": "Deep Tiny Network for Recognition-Oriented Face Image Quality Assessment. (arXiv:2106.04852v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04822",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Alishahi_F/0/1/0/all/0/1\">Fatemeh Alishahi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mohajerin_Ariaei_A/0/1/0/all/0/1\">Amirhossein Mohajerin-Ariaei</a>",
          "description": "The unpaired training can be the only option available for fast deep\nlearning-based ghost imaging, where obtaining a high signal-to-noise ratio\n(SNR) image copy of each low SNR ghost image could be practically\ntime-consuming and challenging. This paper explores the capabilities of deep\nlearning to leverage computational ghost imaging when there is a lack of paired\ntraining images. The deep learning approach proposed here enables fast ghost\nimaging through reconstruction of high SNR images from faint and hastily shot\nghost images using a constrained Wasserstein generative adversarial network. In\nthe proposed approach, the objective function is regularized to enforce the\ngeneration of faithful and relevant high SNR images to the ghost copies. This\nregularization measures the distance between reconstructed images and the faint\nghost images in a low-noise manifold generated by a shadow network. The\nperformance of the constrained network is shown to be particularly important\nfor ghost images with low SNR. The proposed pipeline is able to reconstruct\nhigh-quality images from the ghost images with SNR values not necessarily equal\nto the SNR of the training set.",
          "link": "http://arxiv.org/abs/2106.04822",
          "publishedOn": "2021-06-10T01:56:45.938Z",
          "wordCount": 629,
          "title": "Fast Computational Ghost Imaging using Unpaired Deep Learning and a Constrained Generative Adversarial Network. (arXiv:2106.04822v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04605",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Si_Q/0/1/0/all/0/1\">Qingyi Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zheng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_M/0/1/0/all/0/1\">Mingyu Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_P/0/1/0/all/0/1\">Peng Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Weiping Wang</a>",
          "description": "While sophisticated Visual Question Answering models have achieved remarkable\nsuccess, they tend to answer questions only according to superficial\ncorrelations between question and answer. Several recent approaches have been\ndeveloped to address this language priors problem. However, most of them\npredict the correct answer according to one best output without checking the\nauthenticity of answers. Besides, they only explore the interaction between\nimage and question, ignoring the semantics of candidate answers. In this paper,\nwe propose a select-and-rerank (SAR) progressive framework based on Visual\nEntailment. Specifically, we first select the candidate answers relevant to the\nquestion or the image, then we rerank the candidate answers by a visual\nentailment task, which verifies whether the image semantically entails the\nsynthetic statement of the question and each candidate answer. Experimental\nresults show the effectiveness of our proposed framework, which establishes a\nnew state-of-the-art accuracy on VQA-CP v2 with a 7.55% improvement.",
          "link": "http://arxiv.org/abs/2106.04605",
          "publishedOn": "2021-06-10T01:56:45.923Z",
          "wordCount": 586,
          "title": "Check It Again: Progressive Visual Question Answering via Visual Entailment. (arXiv:2106.04605v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04767",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhilu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_V/0/1/0/all/0/1\">Vianne R. Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabuncu_M/0/1/0/all/0/1\">Mert R. Sabuncu</a>",
          "description": "Monte Carlo (MC) dropout is a simple and efficient ensembling method that can\nimprove the accuracy and confidence calibration of high-capacity deep neural\nnetwork models. However, MC dropout is not as effective as more\ncompute-intensive methods such as deep ensembles. This performance gap can be\nattributed to the relatively poor quality of individual models in the MC\ndropout ensemble and their lack of diversity. These issues can in turn be\ntraced back to the coupled training and substantial parameter sharing of the\ndropout models. Motivated by this perspective, we propose a strategy to compute\nan ensemble of subnetworks, each corresponding to a non-overlapping dropout\nmask computed via a pruning strategy and trained independently. We show that\nthe proposed subnetwork ensembling method can perform as well as standard deep\nensembles in both accuracy and uncertainty estimates, yet with a computational\nefficiency similar to MC dropout. Lastly, using several computer vision\ndatasets like CIFAR10/100, CUB200, and Tiny-Imagenet, we experimentally\ndemonstrate that subnetwork ensembling also consistently outperforms recently\nproposed approaches that efficiently ensemble neural networks.",
          "link": "http://arxiv.org/abs/2106.04767",
          "publishedOn": "2021-06-10T01:56:45.918Z",
          "wordCount": 609,
          "title": "Ex uno plures: Splitting One Model into an Ensemble of Subnetworks. (arXiv:2106.04767v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04779",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Ruihui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xianzhi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heng_P/0/1/0/all/0/1\">Pheng-Ann Heng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1\">Chi-Wing Fu</a>",
          "description": "Point clouds produced by 3D scanning are often sparse, non-uniform, and\nnoisy. Recent upsampling approaches aim to generate a dense point set, while\nachieving both distribution uniformity and proximity-to-surface, and possibly\namending small holes, all in a single network. After revisiting the task, we\npropose to disentangle the task based on its multi-objective nature and\nformulate two cascaded sub-networks, a dense generator and a spatial refiner.\nThe dense generator infers a coarse but dense output that roughly describes the\nunderlying surface, while the spatial refiner further fine-tunes the coarse\noutput by adjusting the location of each point. Specifically, we design a pair\nof local and global refinement units in the spatial refiner to evolve a coarse\nfeature map. Also, in the spatial refiner, we regress a per-point offset vector\nto further adjust the coarse outputs in fine-scale. Extensive qualitative and\nquantitative results on both synthetic and real-scanned datasets demonstrate\nthe superiority of our method over the state-of-the-arts.",
          "link": "http://arxiv.org/abs/2106.04779",
          "publishedOn": "2021-06-10T01:56:45.900Z",
          "wordCount": 590,
          "title": "Point Cloud Upsampling via Disentangled Refinement. (arXiv:2106.04779v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04776",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luan_L/0/1/0/all/0/1\">Lele Luan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Hao Sun</a>",
          "description": "Distilling analytical models from data has the potential to advance our\nunderstanding and prediction of nonlinear dynamics. Although discovery of\ngoverning equations based on observed system states (e.g., trajectory time\nseries) has revealed success in a wide range of nonlinear dynamics, uncovering\nthe closed-form equations directly from raw videos still remains an open\nchallenge. To this end, we introduce a novel end-to-end unsupervised deep\nlearning framework to uncover the mathematical structure of equations that\ngoverns the dynamics of moving objects in videos. Such an architecture consists\nof (1) an encoder-decoder network that learns low-dimensional spatial/pixel\ncoordinates of the moving object, (2) a learnable Spatial-Physical\nTransformation component that creates mapping between the extracted\nspatial/pixel coordinates and the latent physical states of dynamics, and (3) a\nnumerical integrator-based sparse regression module that uncovers the\nparsimonious closed-form governing equations of learned physical states and,\nmeanwhile, serves as a constraint to the autoencoder. The efficacy of the\nproposed method is demonstrated by uncovering the governing equations of a\nvariety of nonlinear dynamical systems depicted by moving objects in videos.\nThe resulting computational framework enables discovery of parsimonious\ninterpretable model in a flexible and accessible sensing environment where only\nvideos are available.",
          "link": "http://arxiv.org/abs/2106.04776",
          "publishedOn": "2021-06-10T01:56:45.895Z",
          "wordCount": 635,
          "title": "Uncovering Closed-form Governing Equations of Nonlinear Dynamics from Videos. (arXiv:2106.04776v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04784",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Na_B/0/1/0/all/0/1\">Byunggook Na</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mok_J/0/1/0/all/0/1\">Jisoo Mok</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choe_H/0/1/0/all/0/1\">Hyeokjun Choe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1\">Sungroh Yoon</a>",
          "description": "Despite the increasing interest in neural architecture search (NAS), the\nsignificant computational cost of NAS is a hindrance to researchers. Hence, we\npropose to reduce the cost of NAS using proxy data, i.e., a representative\nsubset of the target data, without sacrificing search performance. Even though\ndata selection has been used across various fields, our evaluation of existing\nselection methods for NAS algorithms offered by NAS-Bench-1shot1 reveals that\nthey are not always appropriate for NAS and a new selection method is\nnecessary. By analyzing proxy data constructed using various selection methods\nthrough data entropy, we propose a novel proxy data selection method tailored\nfor NAS. To empirically demonstrate the effectiveness, we conduct thorough\nexperiments across diverse datasets, search spaces, and NAS algorithms.\nConsequently, NAS algorithms with the proposed selection discover architectures\nthat are competitive with those obtained using the entire dataset. It\nsignificantly reduces the search cost: executing DARTS with the proposed\nselection requires only 40 minutes on CIFAR-10 and 7.5 hours on ImageNet with a\nsingle GPU. Additionally, when the architecture searched on ImageNet using the\nproposed selection is inversely transferred to CIFAR-10, a state-of-the-art\ntest error of 2.4\\% is yielded. Our code is available at\nhttps://github.com/nabk89/NAS-with-Proxy-data.",
          "link": "http://arxiv.org/abs/2106.04784",
          "publishedOn": "2021-06-10T01:56:45.857Z",
          "wordCount": 633,
          "title": "Accelerating Neural Architecture Search via Proxy Data. (arXiv:2106.04784v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04723",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Venieris_S/0/1/0/all/0/1\">Stylianos I. Venieris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panopoulos_I/0/1/0/all/0/1\">Ioannis Panopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venieris_I/0/1/0/all/0/1\">Iakovos S. Venieris</a>",
          "description": "Radical progress in the field of deep learning (DL) has led to unprecedented\naccuracy in diverse inference tasks. As such, deploying DL models across mobile\nplatforms is vital to enable the development and broad availability of the\nnext-generation intelligent apps. Nevertheless, the wide and optimised\ndeployment of DL models is currently hindered by the vast system heterogeneity\nof mobile devices, the varying computational cost of different DL models and\nthe variability of performance needs across DL applications. This paper\nproposes OODIn, a framework for the optimised deployment of DL apps across\nheterogeneous mobile devices. OODIn comprises a novel DL-specific software\narchitecture together with an analytical framework for modelling DL\napplications that: (1) counteract the variability in device resources and DL\nmodels by means of a highly parametrised multi-layer design; and (2) perform a\nprincipled optimisation of both model- and system-level parameters through a\nmulti-objective formulation, designed for DL inference apps, in order to adapt\nthe deployment to the user-specified performance requirements and device\ncapabilities. Quantitative evaluation shows that the proposed framework\nconsistently outperforms status-quo designs across heterogeneous devices and\ndelivers up to 4.3x and 3.5x performance gain over highly optimised platform-\nand model-aware designs respectively, while effectively adapting execution to\ndynamic changes in resource availability.",
          "link": "http://arxiv.org/abs/2106.04723",
          "publishedOn": "2021-06-10T01:56:45.840Z",
          "wordCount": 653,
          "title": "OODIn: An Optimised On-Device Inference Framework for Heterogeneous Mobile Devices. (arXiv:2106.04723v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04650",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Wang_D/0/1/0/all/0/1\">Dayang Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_Z/0/1/0/all/0/1\">Zhan Wu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yu_H/0/1/0/all/0/1\">Hengyong Yu</a>",
          "description": "Low dose computed tomography is a mainstream for clinical applications.\nHow-ever, compared to normal dose CT, in the low dose CT (LDCT) images, there\nare stronger noise and more artifacts which are obstacles for practical\napplications. In the last few years, convolution-based end-to-end deep learning\nmethods have been widely used for LDCT image denoising. Recently, transformer\nhas shown superior performance over convolution with more feature interactions.\nYet its ap-plications in LDCT denoising have not been fully cultivated. Here,\nwe propose a convolution-free T2T vision transformer-based Encoder-decoder\nDilation net-work (TED-net) to enrich the family of LDCT denoising algorithms.\nThe model is free of convolution blocks and consists of a symmetric\nencoder-decoder block with sole transformer. Our model is evaluated on the\nAAPM-Mayo clinic LDCT Grand Challenge dataset, and results show outperformance\nover the state-of-the-art denoising methods.",
          "link": "http://arxiv.org/abs/2106.04650",
          "publishedOn": "2021-06-10T01:56:45.809Z",
          "wordCount": 597,
          "title": "TED-net: Convolution-free T2T Vision Transformer-based Encoder-decoder Dilation network for Low-dose CT Denoising. (arXiv:2106.04650v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2011.08826",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wickramasinghe_U/0/1/0/all/0/1\">Udaranga Wickramasinghe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Knott_G/0/1/0/all/0/1\">Graham Knott</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fua_P/0/1/0/all/0/1\">Pascal Fua</a>",
          "description": "Active Surface Models have a long history of being useful to model complex 3D\nsurfaces but only Active Contours have been used in conjunction with deep\nnetworks, and then only to produce the data term as well as meta-parameter maps\ncontrolling them. In this paper, we advocate a much tighter integration. We\nintroduce layers that implement them that can be integrated seamlessly into\nGraph Convolutional Networks to enforce sophisticated smoothness priors at an\nacceptable computational cost. We will show that the resulting Deep Active\nSurface Models outperform equivalent architectures that use traditional\nregularization loss terms to impose smoothness priors for 3D surface\nreconstruction from 2D images and for 3D volume segmentation.",
          "link": "http://arxiv.org/abs/2011.08826",
          "publishedOn": "2021-06-09T22:43:50.359Z",
          "wordCount": 599,
          "title": "Deep Active Surface Models. (arXiv:2011.08826v5 [cs.CV] UPDATED)"
        }
      ]
    },
    {
      "title": "cs.LG updates on arXiv.org",
      "feedUrl": "http://export.arxiv.org/rss/cs.LG",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2106.03954",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pereira_G/0/1/0/all/0/1\">Geand Trindade Pereira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santos_M/0/1/0/all/0/1\">Moises Rocha dos Santos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carvalho_A/0/1/0/all/0/1\">Andre Carlos Ponce de Leon Ferreira de Carvalho</a>",
          "description": "With the popularity of Machine Learning (ML) solutions, algorithms and data\nhave been released faster than the capacity of processing them. In this\ncontext, the problem of Algorithm Recommendation (AR) is receiving a\nsignificant deal of attention recently. This problem has been addressed in the\nliterature as a learning task, often as a Meta-Learning problem where the aim\nis to recommend the best alternative for a specific dataset. For such, datasets\nencoded by meta-features are explored by ML algorithms that try to learn the\nmapping between meta-representations and the best technique to be used. One of\nthe challenges for the successful use of ML is to define which features are the\nmost valuable for a specific dataset since several meta-features can be used,\nwhich increases the meta-feature dimension. This paper presents an empirical\nanalysis of Feature Selection and Feature Extraction in the meta-level for the\nAR problem. The present study was focused on three criteria: predictive\nperformance, dimensionality reduction, and pipeline runtime. As we verified,\napplying Dimensionality Reduction (DR) methods did not improve predictive\nperformances in general. However, DR solutions reduced about 80% of the\nmeta-features, obtaining pretty much the same performance as the original setup\nbut with lower runtimes. The only exception was PCA, which presented about the\nsame runtime as the original meta-features. Experimental results also showed\nthat various datasets have many non-informative meta-features and that it is\npossible to obtain high predictive performance using around 20% of the original\nmeta-features. Therefore, due to their natural trend for high dimensionality,\nDR methods should be used for Meta-Feature Selection and Meta-Feature\nExtraction.",
          "link": "http://arxiv.org/abs/2106.03954",
          "publishedOn": "2021-06-15T22:41:25.615Z",
          "wordCount": 718,
          "title": "Evaluating Meta-Feature Selection for the Algorithm Recommendation Problem. (arXiv:2106.03954v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14710",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Patil_A/0/1/0/all/0/1\">Ameya D. Patil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuttle_M/0/1/0/all/0/1\">Michael Tuttle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schwing_A/0/1/0/all/0/1\">Alexander G. Schwing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shanbhag_N/0/1/0/all/0/1\">Naresh R. Shanbhag</a>",
          "description": "Classical adversarial training (AT) frameworks are designed to achieve high\nadversarial accuracy against a single attack type, typically $\\ell_\\infty$\nnorm-bounded perturbations. Recent extensions in AT have focused on defending\nagainst the union of multiple perturbations but this benefit is obtained at the\nexpense of a significant (up to $10\\times$) increase in training complexity\nover single-attack $\\ell_\\infty$ AT. In this work, we expand the capabilities\nof widely popular single-attack $\\ell_\\infty$ AT frameworks to provide\nrobustness to the union of ($\\ell_\\infty, \\ell_2, \\ell_1$) perturbations while\npreserving their training efficiency. Our technique, referred to as Shaped\nNoise Augmented Processing (SNAP), exploits a well-established byproduct of\nsingle-attack AT frameworks -- the reduction in the curvature of the decision\nboundary of networks. SNAP prepends a given deep net with a shaped noise\naugmentation layer whose distribution is learned along with network parameters\nusing any standard single-attack AT. As a result, SNAP enhances adversarial\naccuracy of ResNet-18 on CIFAR-10 against the union of ($\\ell_\\infty, \\ell_2,\n\\ell_1$) perturbations by 14%-to-20% for four state-of-the-art (SOTA)\nsingle-attack $\\ell_\\infty$ AT frameworks, and, for the first time, establishes\na benchmark for ResNet-50 and ResNet-101 on ImageNet.",
          "link": "http://arxiv.org/abs/2105.14710",
          "publishedOn": "2021-06-15T22:41:25.605Z",
          "wordCount": 646,
          "title": "Robustifying $\\ell_\\infty$ Adversarial Training to the Union of Perturbation Models. (arXiv:2105.14710v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04392",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1\">Yihong Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1\">Ying Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Muqiao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1\">Songtao Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Q/0/1/0/all/0/1\">Qingjiang Shi</a>",
          "description": "Deep neural networks have been shown as a class of useful tools for\naddressing signal recognition issues in recent years, especially for\nidentifying the nonlinear feature structures of signals. However, this power of\nmost deep learning techniques heavily relies on an abundant amount of training\ndata, so the performance of classic neural nets decreases sharply when the\nnumber of training data samples is small or unseen data are presented in the\ntesting phase. This calls for an advanced strategy, i.e., model-agnostic\nmeta-learning (MAML), which is able to capture the invariant representation of\nthe data samples or signals. In this paper, inspired by the special structure\nof the signal, i.e., real and imaginary parts consisted in practical\ntime-series signals, we propose a Complex-valued Attentional MEta Learner\n(CAMEL) for the problem of few-shot signal recognition by leveraging attention\nand meta-learning in the complex domain. To the best of our knowledge, this is\nalso the first complex-valued MAML that can find the first-order stationary\npoints of general nonconvex problems with theoretical convergence guarantees.\nExtensive experiments results showcase the superiority of the proposed CAMEL\ncompared with the state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2106.04392",
          "publishedOn": "2021-06-15T22:41:25.595Z",
          "wordCount": 639,
          "title": "Signal Transformer: Complex-valued Attention and Meta-Learning for Signal Recognition. (arXiv:2106.04392v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04527",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sellars_P/0/1/0/all/0/1\">Philip Sellars</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aviles_Rivero_A/0/1/0/all/0/1\">Angelica I. Aviles-Rivero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schonlieb_C/0/1/0/all/0/1\">Carola-Bibiane Sch&#xf6;nlieb</a>",
          "description": "Semi-supervised learning has received a lot of recent attention as it\nalleviates the need for large amounts of labelled data which can often be\nexpensive, requires expert knowledge and be time consuming to collect. Recent\ndevelopments in deep semi-supervised classification have reached unprecedented\nperformance and the gap between supervised and semi-supervised learning is\never-decreasing. This improvement in performance has been based on the\ninclusion of numerous technical tricks, strong augmentation techniques and\ncostly optimisation schemes with multi-term loss functions. We propose a new\nframework, LaplaceNet, for deep semi-supervised classification that has a\ngreatly reduced model complexity. We utilise a hybrid energy-neural network\nwhere graph based pseudo-labels, generated by minimising the graphical\nLaplacian, are used to iteratively improve a neural-network backbone. Our model\noutperforms state-of-the-art methods for deep semi-supervised classification,\nover several benchmark datasets. Furthermore, we consider the application of\nstrong-augmentations to neural networks theoretically and justify the use of a\nmulti-sampling approach for semi-supervised learning. We demonstrate, through\nrigorous experimentation, that a multi-sampling augmentation approach improves\ngeneralisation and reduces the sensitivity of the network to augmentation.",
          "link": "http://arxiv.org/abs/2106.04527",
          "publishedOn": "2021-06-15T22:41:25.576Z",
          "wordCount": 617,
          "title": "LaplaceNet: A Hybrid Energy-Neural Model for Deep Semi-Supervised Classification. (arXiv:2106.04527v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04563",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_S/0/1/0/all/0/1\">Subhabrata Mukherjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awadallah_A/0/1/0/all/0/1\">Ahmed Hassan Awadallah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>",
          "description": "While deep and large pre-trained models are the state-of-the-art for various\nnatural language processing tasks, their huge size poses significant challenges\nfor practical uses in resource constrained settings. Recent works in knowledge\ndistillation propose task-agnostic as well as task-specific methods to compress\nthese models, with task-specific ones often yielding higher compression rate.\nIn this work, we develop a new task-agnostic distillation framework\nXtremeDistilTransformers that leverages the advantage of task-specific methods\nfor learning a small universal model that can be applied to arbitrary tasks and\nlanguages. To this end, we study the transferability of several source tasks,\naugmentation resources and model architecture for distillation. We evaluate our\nmodel performance on multiple tasks, including the General Language\nUnderstanding Evaluation (GLUE) benchmark, SQuAD question answering dataset and\na massive multi-lingual NER dataset with 41 languages. We release three\ndistilled task-agnostic checkpoints with 13MM, 22MM and 33MM parameters\nobtaining SOTA performance in several tasks.",
          "link": "http://arxiv.org/abs/2106.04563",
          "publishedOn": "2021-06-15T22:41:25.566Z",
          "wordCount": 604,
          "title": "XtremeDistilTransformers: Task Transfer for Task-agnostic Distillation. (arXiv:2106.04563v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04496",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1\">Haotian Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1\">Chuanlong Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_T/0/1/0/all/0/1\">Tianle Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Ruichen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhenguo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Liwei Wang</a>",
          "description": "Generalization to out-of-distribution (OOD) data, or domain generalization,\nis one of the central problems in modern machine learning. Recently, there is a\nsurge of attempts to propose algorithms for OOD that mainly build upon the idea\nof extracting invariant features. Although intuitively reasonable, theoretical\nunderstanding of what kind of invariance can guarantee OOD generalization is\nstill limited, and generalization to arbitrary out-of-distribution is clearly\nimpossible. In this work, we take the first step towards rigorous and\nquantitative definitions of 1) what is OOD; and 2) what does it mean by saying\nan OOD problem is learnable. We also introduce a new concept of expansion\nfunction, which characterizes to what extent the variance is amplified in the\ntest domains over the training domains, and therefore give a quantitative\nmeaning of invariant features. Based on these, we prove OOD generalization\nerror bounds. It turns out that OOD generalization largely depends on the\nexpansion function. As recently pointed out by Gulrajani and Lopez-Paz (2020),\nany OOD learning algorithm without a model selection module is incomplete. Our\ntheory naturally induces a model selection criterion. Extensive experiments on\nbenchmark OOD datasets demonstrate that our model selection criterion has a\nsignificant advantage over baselines.",
          "link": "http://arxiv.org/abs/2106.04496",
          "publishedOn": "2021-06-15T22:41:25.555Z",
          "wordCount": 641,
          "title": "Towards a Theoretical Framework of Out-of-Distribution Generalization. (arXiv:2106.04496v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04292",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wan_C/0/1/0/all/0/1\">Changlin Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Muhan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_W/0/1/0/all/0/1\">Wei Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_S/0/1/0/all/0/1\">Sha Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Pan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chi Zhang</a>",
          "description": "Hypergraph offers a framework to depict the multilateral relationships in\nreal-world complex data. Predicting higher-order relationships, i.e hyperedge,\nbecomes a fundamental problem for the full understanding of complicated\ninteractions. The development of graph neural network (GNN) has greatly\nadvanced the analysis of ordinary graphs with pair-wise relations. However,\nthese methods could not be easily extended to the case of hypergraph. In this\npaper, we generalize the challenges of GNN in representing higher-order data in\nprinciple, which are edge- and node-level ambiguities. To overcome the\nchallenges, we present SNALS that utilizes bipartite graph neural network with\nstructural features to collectively tackle the two ambiguity issues. SNALS\ncaptures the joint interactions of a hyperedge by its local environment, which\nis retrieved by collecting the spectrum information of their connections. As a\nresult, SNALS achieves nearly 30% performance increase compared with most\nrecent GNN-based models. In addition, we applied SNALS to predict genetic\nhigher-order interactions on 3D genome organization data. SNALS showed\nconsistently high prediction accuracy across different chromosomes, and\ngenerated novel findings on 4-way gene interaction, which is further validated\nby existing literature.",
          "link": "http://arxiv.org/abs/2106.04292",
          "publishedOn": "2021-06-15T22:41:25.543Z",
          "wordCount": 656,
          "title": "Principled Hyperedge Prediction with Structural Spectral Features and Neural Networks. (arXiv:2106.04292v4 [cs.SI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.04740",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Gurbuzbalaban_M/0/1/0/all/0/1\">Mert Gurbuzbalaban</a>, <a href=\"http://arxiv.org/find/math/1/au:+Simsekli_U/0/1/0/all/0/1\">Umut &#x15e;im&#x15f;ekli</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhu_L/0/1/0/all/0/1\">Lingjiong Zhu</a>",
          "description": "In recent years, various notions of capacity and complexity have been\nproposed for characterizing the generalization properties of stochastic\ngradient descent (SGD) in deep learning. Some of the popular notions that\ncorrelate well with the performance on unseen data are (i) the `flatness' of\nthe local minimum found by SGD, which is related to the eigenvalues of the\nHessian, (ii) the ratio of the stepsize $\\eta$ to the batch-size $b$, which\nessentially controls the magnitude of the stochastic gradient noise, and (iii)\nthe `tail-index', which measures the heaviness of the tails of the network\nweights at convergence. In this paper, we argue that these three seemingly\nunrelated perspectives for generalization are deeply linked to each other. We\nclaim that depending on the structure of the Hessian of the loss at the\nminimum, and the choices of the algorithm parameters $\\eta$ and $b$, the SGD\niterates will converge to a \\emph{heavy-tailed} stationary distribution. We\nrigorously prove this claim in the setting of quadratic optimization: we show\nthat even in a simple linear regression problem with independent and\nidentically distributed data whose distribution has finite moments of all\norder, the iterates can be heavy-tailed with infinite variance. We further\ncharacterize the behavior of the tails with respect to algorithm parameters,\nthe dimension, and the curvature. We then translate our results into insights\nabout the behavior of SGD in deep learning. We support our theory with\nexperiments conducted on synthetic data, fully connected, and convolutional\nneural networks.",
          "link": "http://arxiv.org/abs/2006.04740",
          "publishedOn": "2021-06-15T22:41:25.530Z",
          "wordCount": 731,
          "title": "The Heavy-Tail Phenomenon in SGD. (arXiv:2006.04740v5 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14188",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_L/0/1/0/all/0/1\">Liyi Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_J/0/1/0/all/0/1\">Junqi Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Haoqi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zhenzhe Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhiye Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_Z/0/1/0/all/0/1\">Zhizhuang Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_F/0/1/0/all/0/1\">Fei Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_L/0/1/0/all/0/1\">Lvyin Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haiyang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1\">Chuan Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yuning Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaoqiang Zhu</a>",
          "description": "Advertising expenditures have become the major source of revenue for\ne-commerce platforms. Providing good advertising experiences for advertisers by\nreducing their costs of trial and error in discovering the optimal advertising\nstrategies is crucial for the long-term prosperity of online advertising. To\nachieve this goal, the advertising platform needs to identify the advertiser's\noptimization objectives, and then recommend the corresponding strategies to\nfulfill the objectives. In this work, we first deploy a prototype of strategy\nrecommender system on Taobao display advertising platform, which indeed\nincreases the advertisers' performance and the platform's revenue, indicating\nthe effectiveness of strategy recommendation for online advertising. We further\naugment this prototype system by explicitly learning the advertisers'\npreferences over various advertising performance indicators and then\noptimization objectives through their adoptions of different recommending\nadvertising strategies. We use contextual bandit algorithms to efficiently\nlearn the advertisers' preferences and maximize the recommendation adoption,\nsimultaneously. Simulation experiments based on Taobao online bidding data show\nthat the designed algorithms can effectively optimize the strategy adoption\nrate of advertisers.",
          "link": "http://arxiv.org/abs/2105.14188",
          "publishedOn": "2021-06-15T22:41:25.502Z",
          "wordCount": 675,
          "title": "We Know What You Want: An Advertising Strategy Recommender System for Online Advertising. (arXiv:2105.14188v3 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06916",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lixu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shichao Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">Ruiqi Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1\">Qi Zhu</a>",
          "description": "As Artificial Intelligence as a Service gains popularity, protecting\nwell-trained models as intellectual property is becoming increasingly\nimportant. Generally speaking, there are two common protection methods:\nownership verification and usage authorization. In this paper, we propose\nNon-Transferable Learning (NTL), a novel approach that captures the exclusive\ndata representation in the learned model and restricts the model generalization\nability to certain domains. This approach provides effective solutions to both\nmodel verification and authorization. For ownership verification, watermarking\ntechniques are commonly used but are often vulnerable to sophisticated\nwatermark removal methods. Our NTL-based model verification approach instead\nprovides robust resistance to state-of-the-art watermark removal methods, as\nshown in extensive experiments for four of such methods over the digits,\nCIFAR10 & STL10, and VisDA datasets. For usage authorization, prior solutions\nfocus on authorizing specific users to use the model, but authorized users can\nstill apply the model to any data without restriction. Our NTL-based\nauthorization approach instead provides data-centric usage protection by\nsignificantly degrading the performance of usage on unauthorized data. Its\neffectiveness is also shown through experiments on a variety of datasets.",
          "link": "http://arxiv.org/abs/2106.06916",
          "publishedOn": "2021-06-15T22:07:49.359Z",
          "wordCount": 617,
          "title": "Non-Transferable Learning: A New Approach for Model Verification and Authorization. (arXiv:2106.06916v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06733",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Lin_Y/0/1/0/all/0/1\">Yi Lin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_Y/0/1/0/all/0/1\">Yanfei Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_J/0/1/0/all/0/1\">Jingguang Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_G/0/1/0/all/0/1\">Guocai Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ma_K/0/1/0/all/0/1\">Kai Ma</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zheng_Y/0/1/0/all/0/1\">Yefeng Zheng</a>",
          "description": "Radiation therapy treatment planning is a complex process, as the target dose\nprescription and normal tissue sparing are conflicting objectives. Automated\nand accurate dose prediction for radiation therapy planning is in high demand.\nIn this study, we propose a novel learning-based ensemble approach, named\nLE-NAS, which integrates neural architecture search (NAS) with knowledge\ndistillation for 3D radiotherapy dose prediction. Specifically, the prediction\nnetwork first exhaustively searches each block from enormous architecture\nspace. Then, multiple architectures are selected with promising performance and\ndiversity. To reduce the inference time, we adopt the teacher-student paradigm\nby treating the combination of diverse outputs from multiple searched networks\nas supervisions to guide the student network training. In addition, we apply\nadversarial learning to optimize the student network to recover the knowledge\nin teacher networks. To the best of our knowledge, we are the first to\ninvestigate the combination of NAS and knowledge distillation. The proposed\nmethod has been evaluated on the public OpenKBP dataset, and experimental\nresults demonstrate the effectiveness of our method and its superior\nperformance to the state-of-the-art method.",
          "link": "http://arxiv.org/abs/2106.06733",
          "publishedOn": "2021-06-15T22:07:49.342Z",
          "wordCount": 622,
          "title": "LE-NAS: Learning-based Ensenble with NAS for Dose Prediction. (arXiv:2106.06733v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06769",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Junfu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bi Wang</a>",
          "description": "Working memory (WM) is a basic part of human cognition, which plays an\nimportant role in the study of human cognitive load. Among various brain\nimaging techniques, electroencephalography has shown its advantage on easy\naccess and reliability. However, one of the critical challenges is that\nindividual difference may cause the ineffective results, especially when the\nestablished model meets an unfamiliar subject. In this work, we propose a\ncross-subject deep adaptation model with spatial attention (CS-DASA) to\ngeneralize the workload classifications across subjects. First, we transform\ntime-series EEG data into multi-frame EEG images incorporating more\nspatio-temporal information. First, the subject-shared module in CS-DASA\nreceives multi-frame EEG image data from both source and target subjects and\nlearns the common feature representations. Then, in subject-specific module,\nthe maximum mean discrepancy is implemented to measure the domain distribution\ndivergence in a reproducing kernel Hilbert space, which can add an effective\npenalty loss for domain adaptation. Additionally, the subject-to-subject\nspatial attention mechanism is employed to focus on the most discriminative\nspatial feature in EEG image data. Experiments conducted on a public WM EEG\ndataset containing 13 subjects show that the proposed model is capable of\nachieve better performance than existing state-of-the art methods.",
          "link": "http://arxiv.org/abs/2106.06769",
          "publishedOn": "2021-06-15T22:07:49.270Z",
          "wordCount": 632,
          "title": "Cross-Subject Domain Adaptation for Multi-Frame EEG Images. (arXiv:2106.06769v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.01391",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Grimstad_B/0/1/0/all/0/1\">Bjarne Grimstad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hotvedt_M/0/1/0/all/0/1\">Mathilde Hotvedt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sandnes_A/0/1/0/all/0/1\">Anders T. Sandnes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolbjornsen_O/0/1/0/all/0/1\">Odd Kolbj&#xf8;rnsen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Imsland_L/0/1/0/all/0/1\">Lars S. Imsland</a>",
          "description": "Recent works have presented promising results from the application of machine\nlearning (ML) to the modeling of flow rates in oil and gas wells. Encouraging\nresults and advantageous properties of ML models, such as computationally cheap\nevaluation and ease of calibration to new data, have sparked optimism for the\ndevelopment of data-driven virtual flow meters (VFMs). Data-driven VFMs are\ndeveloped in the small data regime, where it is important to question the\nuncertainty and robustness of models. The modeling of uncertainty may help to\nbuild trust in models, which is a prerequisite for industrial applications. The\ncontribution of this paper is the introduction of a probabilistic VFM based on\nBayesian neural networks. Uncertainty in the model and measurements is\ndescribed, and the paper shows how to perform approximate Bayesian inference\nusing variational inference. The method is studied by modeling on a large and\nheterogeneous dataset, consisting of 60 wells across five different oil and gas\nassets. The predictive performance is analyzed on historical and future test\ndata, where an average error of 4-6% and 8-13% is achieved for the 50% best\nperforming models, respectively. Variational inference appears to provide more\nrobust predictions than the reference approach on future data. Prediction\nperformance and uncertainty calibration is explored in detail and discussed in\nlight of four data challenges. The findings motivate the development of\nalternative strategies to improve the robustness of data-driven VFMs.",
          "link": "http://arxiv.org/abs/2102.01391",
          "publishedOn": "2021-06-15T01:45:21.535Z",
          "wordCount": 708,
          "title": "Bayesian Neural Networks for Virtual Flow Metering: An Empirical Study. (arXiv:2102.01391v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.16205",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1\">Sang Michael Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1\">Tengyu Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1\">Percy Liang</a>",
          "description": "We focus on prediction problems with structured outputs that are subject to\noutput validity constraints, e.g. pseudocode-to-code translation where the code\nmust compile. While labeled input-output pairs are expensive to obtain,\n\"unlabeled\" outputs, i.e. outputs without corresponding inputs, are freely\navailable (e.g. code on GitHub) and provide information about output validity.\nPre-training captures this structure by training a denoiser to denoise\ncorrupted versions of unlabeled outputs. We first show that standard\nfine-tuning after pre-training destroys some of this structure. We then propose\ncomposed fine-tuning, which trains a predictor composed with the pre-trained\ndenoiser. Importantly, the denoiser is fixed to preserve output structure. Like\nstandard fine-tuning, the predictor is also initialized with the pre-trained\ndenoiser. We prove for two-layer ReLU networks that composed fine-tuning\nsignificantly reduces the complexity of the predictor, thus improving\ngeneralization. Empirically, we show that composed fine-tuning improves over\nstandard fine-tuning on two pseudocode-to-code translation datasets (3% and 6%\nrelative). The improvement is magnified on out-of-distribution (OOD) examples\n(4% and 25% relative), suggesting that reducing predictor complexity improves\nOOD extrapolation.",
          "link": "http://arxiv.org/abs/2006.16205",
          "publishedOn": "2021-06-15T01:45:21.468Z",
          "wordCount": 644,
          "title": "Composed Fine-Tuning: Freezing Pre-Trained Denoising Autoencoders for Improved Generalization. (arXiv:2006.16205v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02639",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Rosenfeld_J/0/1/0/all/0/1\">Joel A. Rosenfeld</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kamalapurkar_R/0/1/0/all/0/1\">Rushikesh Kamalapurkar</a>",
          "description": "This manuscript is aimed at addressing several long standing limitations of\ndynamic mode decompositions in the application of Koopman analysis. Principle\namong these limitations are the convergence of associated Dynamic Mode\nDecomposition algorithms and the existence of Koopman modes. To address these\nlimitations, two major modifications are made, where Koopman operators are\nremoved from the analysis in light of Liouville operators (known as Koopman\ngenerators in special cases), and these operators are shown to be compact for\ncertain pairs of Hilbert spaces selected separately as the domain and range of\nthe operator. While eigenfunctions are discarded in the general analysis, a\nviable reconstruction algorithm is still demonstrated, and the sacrifice of\neigenfunctions realizes the theoretical goals of DMD analysis that have yet to\nbe achieved in other contexts. However, in the case where the domain is\nembedded in the range, an eigenfunction approach is still achievable, where a\nmore typical DMD routine is established, but that leverages a finite rank\nrepresentation that converges in norm. The manuscript concludes with the\ndescription of two Dynamic Mode Decomposition algorithms that converges when a\ndense collection of occupation kernels, arising from the data, are leveraged in\nthe analysis.",
          "link": "http://arxiv.org/abs/2106.02639",
          "publishedOn": "2021-06-15T01:45:21.438Z",
          "wordCount": 666,
          "title": "Singular Dynamic Mode Decompositions. (arXiv:2106.02639v2 [eess.SY] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06932",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Junfeng Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Saurabh Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gummadi_R/0/1/0/all/0/1\">Ramki Gummadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schuurmans_D/0/1/0/all/0/1\">Dale Schuurmans</a>",
          "description": "Actor-critic (AC) methods are ubiquitous in reinforcement learning. Although\nit is understood that AC methods are closely related to policy gradient (PG),\ntheir precise connection has not been fully characterized previously. In this\npaper, we explain the gap between AC and PG methods by identifying the exact\nadjustment to the AC objective/gradient that recovers the true policy gradient\nof the cumulative reward objective (PG). Furthermore, by viewing the AC method\nas a two-player Stackelberg game between the actor and critic, we show that the\nStackelberg policy gradient can be recovered as a special case of our more\ngeneral analysis. Based on these results, we develop practical algorithms,\nResidual Actor-Critic and Stackelberg Actor-Critic, for estimating the\ncorrection between AC and PG and use these to modify the standard AC algorithm.\nExperiments on popular tabular and continuous environments show the proposed\ncorrections can improve both the sample efficiency and final performance of\nexisting AC methods.",
          "link": "http://arxiv.org/abs/2106.06932",
          "publishedOn": "2021-06-15T01:45:21.389Z",
          "wordCount": 584,
          "title": "Characterizing the Gap Between Actor-Critic and Policy Gradient. (arXiv:2106.06932v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2102.06752",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Xin_R/0/1/0/all/0/1\">Ran Xin</a>, <a href=\"http://arxiv.org/find/math/1/au:+Khan_U/0/1/0/all/0/1\">Usman A. Khan</a>, <a href=\"http://arxiv.org/find/math/1/au:+Kar_S/0/1/0/all/0/1\">Soummya Kar</a>",
          "description": "This paper considers decentralized stochastic optimization over a network of\n$n$ nodes, where each node possesses a smooth non-convex local cost function\nand the goal of the networked nodes is to find an $\\epsilon$-accurate\nfirst-order stationary point of the sum of the local costs. We focus on an\nonline setting, where each node accesses its local cost only by means of a\nstochastic first-order oracle that returns a noisy version of the exact\ngradient. In this context, we propose a novel single-loop decentralized hybrid\nvariance-reduced stochastic gradient method, called GT-HSGD, that outperforms\nthe existing approaches in terms of both the oracle complexity and practical\nimplementation. The GT-HSGD algorithm implements specialized local hybrid\nstochastic gradient estimators that are fused over the network to track the\nglobal gradient. Remarkably, GT-HSGD achieves a network topology-independent\noracle complexity of $O(n^{-1}\\epsilon^{-3})$ when the required error tolerance\n$\\epsilon$ is small enough, leading to a linear speedup with respect to the\ncentralized optimal online variance-reduced approaches that operate on a single\nnode. Numerical experiments are provided to illustrate our main technical\nresults.",
          "link": "http://arxiv.org/abs/2102.06752",
          "publishedOn": "2021-06-15T01:45:21.382Z",
          "wordCount": 644,
          "title": "A Hybrid Variance-Reduced Method for Decentralized Stochastic Non-Convex Optimization. (arXiv:2102.06752v2 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.09261",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1\">Xu Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Boyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Han Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miao_C/0/1/0/all/0/1\">Chunyan Miao</a>",
          "description": "The existence of multiple datasets for sarcasm detection prompts us to apply\ntransfer learning to exploit their commonality. The adversarial neural transfer\n(ANT) framework utilizes multiple loss terms that encourage the source-domain\nand the target-domain feature distributions to be similar while optimizing for\ndomain-specific performance. However, these objectives may be in conflict,\nwhich can lead to optimization difficulties and sometimes diminished transfer.\nWe propose a generalized latent optimization strategy that allows different\nlosses to accommodate each other and improves training dynamics. The proposed\nmethod outperforms transfer learning and meta-learning baselines. In\nparticular, we achieve 10.02% absolute performance gain over the previous state\nof the art on the iSarcasm dataset.",
          "link": "http://arxiv.org/abs/2104.09261",
          "publishedOn": "2021-06-15T01:45:21.376Z",
          "wordCount": 579,
          "title": "Latent-Optimized Adversarial Neural Transfer for Sarcasm Detection. (arXiv:2104.09261v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.03230",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zbontar_J/0/1/0/all/0/1\">Jure Zbontar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jing_L/0/1/0/all/0/1\">Li Jing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Misra_I/0/1/0/all/0/1\">Ishan Misra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+LeCun_Y/0/1/0/all/0/1\">Yann LeCun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deny_S/0/1/0/all/0/1\">St&#xe9;phane Deny</a>",
          "description": "Self-supervised learning (SSL) is rapidly closing the gap with supervised\nmethods on large computer vision benchmarks. A successful approach to SSL is to\nlearn embeddings which are invariant to distortions of the input sample.\nHowever, a recurring issue with this approach is the existence of trivial\nconstant solutions. Most current methods avoid such solutions by careful\nimplementation details. We propose an objective function that naturally avoids\ncollapse by measuring the cross-correlation matrix between the outputs of two\nidentical networks fed with distorted versions of a sample, and making it as\nclose to the identity matrix as possible. This causes the embedding vectors of\ndistorted versions of a sample to be similar, while minimizing the redundancy\nbetween the components of these vectors. The method is called Barlow Twins,\nowing to neuroscientist H. Barlow's redundancy-reduction principle applied to a\npair of identical networks. Barlow Twins does not require large batches nor\nasymmetry between the network twins such as a predictor network, gradient\nstopping, or a moving average on the weight updates. Intriguingly it benefits\nfrom very high-dimensional output vectors. Barlow Twins outperforms previous\nmethods on ImageNet for semi-supervised classification in the low-data regime,\nand is on par with current state of the art for ImageNet classification with a\nlinear classifier head, and for transfer tasks of classification and object\ndetection.",
          "link": "http://arxiv.org/abs/2103.03230",
          "publishedOn": "2021-06-15T01:45:21.369Z",
          "wordCount": 717,
          "title": "Barlow Twins: Self-Supervised Learning via Redundancy Reduction. (arXiv:2103.03230v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.11005",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+You_K/0/1/0/all/0/1\">Kaichao You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_M/0/1/0/all/0/1\">Mingsheng Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianmin Wang</a>",
          "description": "This paper studies task adaptive pre-trained model selection, an\nunderexplored problem of assessing pre-trained models for the target task and\nselect best ones from the model zoo \\emph{without fine-tuning}. A few pilot\nworks addressed the problem in transferring supervised pre-trained models to\nclassification tasks, but they cannot handle emerging unsupervised pre-trained\nmodels or regression tasks. In pursuit of a practical assessment method, we\npropose to estimate the maximum value of label evidence given features\nextracted by pre-trained models. Unlike the maximum likelihood, the maximum\nevidence is \\emph{immune to over-fitting}, while its expensive computation can\nbe dramatically reduced by our carefully designed algorithm. The Logarithm of\nMaximum Evidence (LogME) can be used to assess pre-trained models for transfer\nlearning: a pre-trained model with a high LogME value is likely to have good\ntransfer performance. LogME is \\emph{fast, accurate, and general},\ncharacterizing itself as the first practical method for assessing pre-trained\nmodels. Compared with brute-force fine-tuning, LogME brings at most\n$3000\\times$ speedup in wall-clock time and requires only $1\\%$ memory\nfootprint. It outperforms prior methods by a large margin in their setting and\nis applicable to new settings. It is general enough for diverse pre-trained\nmodels (supervised pre-trained and unsupervised pre-trained), downstream tasks\n(classification and regression), and modalities (vision and language). Code is\navailable at this repository:\n\\href{https://github.com/thuml/LogME}{https://github.com/thuml/LogME}.",
          "link": "http://arxiv.org/abs/2102.11005",
          "publishedOn": "2021-06-15T01:45:21.320Z",
          "wordCount": 686,
          "title": "LogME: Practical Assessment of Pre-trained Models for Transfer Learning. (arXiv:2102.11005v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.01956",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Karan_A/0/1/0/all/0/1\">Alperen Karan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kaygun_A/0/1/0/all/0/1\">Atabey Kaygun</a>",
          "description": "In this paper, we develop topological data analysis methods for\nclassification tasks on univariate time series. As an application, we perform\nbinary and ternary classification tasks on two public datasets that consist of\nphysiological signals collected under stress and non-stress conditions. We\naccomplish our goal by using persistent homology to engineer stable topological\nfeatures after we use a time delay embedding of the signals and perform a\nsubwindowing instead of using windows of fixed length. The combination of\nmethods we use can be applied to any univariate time series and in this\napplication allows us to reduce noise and use long window sizes without\nincurring an extra computational cost. We then use machine learning models on\nthe features we algorithmically engineered to obtain higher accuracies with\nfewer features.",
          "link": "http://arxiv.org/abs/2102.01956",
          "publishedOn": "2021-06-15T01:45:21.302Z",
          "wordCount": 578,
          "title": "Time Series Classification via Topological Data Analysis. (arXiv:2102.01956v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.09670",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Croce_F/0/1/0/all/0/1\">Francesco Croce</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andriushchenko_M/0/1/0/all/0/1\">Maksym Andriushchenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sehwag_V/0/1/0/all/0/1\">Vikash Sehwag</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Debenedetti_E/0/1/0/all/0/1\">Edoardo Debenedetti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Flammarion_N/0/1/0/all/0/1\">Nicolas Flammarion</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiang_M/0/1/0/all/0/1\">Mung Chiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mittal_P/0/1/0/all/0/1\">Prateek Mittal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hein_M/0/1/0/all/0/1\">Matthias Hein</a>",
          "description": "As a research community, we are still lacking a systematic understanding of\nthe progress on adversarial robustness, which often makes it hard to identify\nthe most promising ideas in training robust models. A key challenge in\nbenchmarking robustness is that its evaluation is often error-prone, leading to\noverestimation of the true robustness of models. While adaptive attacks\ndesigned for a particular defense are a potential solution, they have to be\nhighly customized for particular models, which makes it difficult to compare\ndifferent methods. Our goal is to instead establish a standardized benchmark of\nadversarial robustness, which as accurately as possible reflects the robustness\nof the considered models within a reasonable computational budget. To evaluate\nthe robustness of models for our benchmark, we consider AutoAttack, an ensemble\nof white- and black-box attacks which was recently shown in a large-scale study\nto improve almost all robustness evaluations compared to the original\npublications. We also impose some restrictions on the admitted models to rule\nout defenses that only make gradient-based attacks ineffective without\nimproving actual robustness. Our leaderboard, hosted at\nhttps://robustbench.github.io/, contains evaluations of 90+ models and aims at\nreflecting the current state of the art on a set of well-defined tasks in\n$\\ell_\\infty$- and $\\ell_2$-threat models and on common corruptions, with\npossible extensions in the future. Additionally, we open-source the library\nhttps://github.com/RobustBench/robustbench that provides unified access to 60+\nrobust models to facilitate their downstream applications. Finally, based on\nthe collected models, we analyze the impact of robustness on the performance on\ndistribution shifts, calibration, out-of-distribution detection, fairness,\nprivacy leakage, smoothness, and transferability.",
          "link": "http://arxiv.org/abs/2010.09670",
          "publishedOn": "2021-06-15T01:45:21.289Z",
          "wordCount": 763,
          "title": "RobustBench: a standardized adversarial robustness benchmark. (arXiv:2010.09670v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06989",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alcorn_M/0/1/0/all/0/1\">Michael A. Alcorn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1\">Anh Nguyen</a>",
          "description": "Order-agnostic autoregressive distribution estimation (OADE), i.e.,\nautoregressive distribution estimation where the features can occur in an\narbitrary order, is a challenging problem in generative machine learning. Prior\nwork on OADE has encoded feature identity (e.g., pixel location) by assigning\neach feature to a distinct fixed position in an input vector. As a result,\narchitectures built for these inputs must strategically mask either the input\nor model weights to learn the various conditional distributions necessary for\ninferring the full joint distribution of the dataset in an order-agnostic way.\nIn this paper, we propose an alternative approach for encoding feature\nidentities, where each feature's identity is included alongside its value in\nthe input. This feature identity encoding strategy allows neural architectures\ndesigned for sequential data to be applied to the OADE task without\nmodification. As a proof of concept, we show that a Transformer trained on this\ninput (which we refer to as \"the DEformer\", i.e., the distribution estimating\nTransformer) can effectively model binarized-MNIST, approaching the average\nnegative log-likelihood of fixed order autoregressive distribution estimating\nalgorithms while still being entirely order-agnostic.",
          "link": "http://arxiv.org/abs/2106.06989",
          "publishedOn": "2021-06-15T01:45:21.277Z",
          "wordCount": 598,
          "title": "The DEformer: An Order-Agnostic Distribution Estimating Transformer. (arXiv:2106.06989v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06613",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Treutlein_J/0/1/0/all/0/1\">Johannes Treutlein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dennis_M/0/1/0/all/0/1\">Michael Dennis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oesterheld_C/0/1/0/all/0/1\">Caspar Oesterheld</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Foerster_J/0/1/0/all/0/1\">Jakob Foerster</a>",
          "description": "In many coordination problems, independently reasoning humans are able to\ndiscover mutually compatible policies. In contrast, independently trained\nself-play policies are often mutually incompatible. Zero-shot coordination\n(ZSC) has recently been proposed as a new frontier in multi-agent reinforcement\nlearning to address this fundamental issue. Prior work approaches the ZSC\nproblem by assuming players can agree on a shared learning algorithm but not on\nlabels for actions and observations, and proposes other-play as an optimal\nsolution. However, until now, this \"label-free\" problem has only been\ninformally defined. We formalize this setting as the label-free coordination\n(LFC) problem by defining the label-free coordination game. We show that\nother-play is not an optimal solution to the LFC problem as it fails to\nconsistently break ties between incompatible maximizers of the other-play\nobjective. We introduce an extension of the algorithm, other-play with\ntie-breaking, and prove that it is optimal in the LFC problem and an\nequilibrium in the LFC game. Since arbitrary tie-breaking is precisely what the\nZSC setting aims to prevent, we conclude that the LFC problem does not reflect\nthe aims of ZSC. To address this, we introduce an alternative informal\noperationalization of ZSC as a starting point for future work.",
          "link": "http://arxiv.org/abs/2106.06613",
          "publishedOn": "2021-06-15T01:45:21.260Z",
          "wordCount": 630,
          "title": "A New Formalism, Method and Open Issues for Zero-Shot Coordination. (arXiv:2106.06613v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2103.13740",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ingolfsson_T/0/1/0/all/0/1\">Thorir Mar Ingolfsson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaying Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hersche_M/0/1/0/all/0/1\">Michael Hersche</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burrello_A/0/1/0/all/0/1\">Alessio Burrello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cavigelli_L/0/1/0/all/0/1\">Lukas Cavigelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benini_L/0/1/0/all/0/1\">Luca Benini</a>",
          "description": "Personalized ubiquitous healthcare solutions require energy-efficient\nwearable platforms that provide an accurate classification of bio-signals while\nconsuming low average power for long-term battery-operated use. Single lead\nelectrocardiogram (ECG) signals provide the ability to detect, classify, and\neven predict cardiac arrhythmia. In this paper, we propose a novel temporal\nconvolutional network (TCN) that achieves high accuracy while still being\nfeasible for wearable platform use. Experimental results on the ECG5000 dataset\nshow that the TCN has a similar accuracy (94.2%) score as the state-of-the-art\n(SoA) network while achieving an improvement of 16.5% in the balanced accuracy\nscore. This accurate classification is done with 27 times fewer parameters and\n37 times less multiply-accumulate operations. We test our implementation on two\npublicly available platforms, the STM32L475, which is based on ARM Cortex M4F,\nand the GreenWaves Technologies GAP8 on the GAPuino board, based on 1+8 RISC-V\nCV32E40P cores. Measurements show that the GAP8 implementation respects the\nreal-time constraints while consuming 0.10 mJ per inference. With 9.91\nGMAC/s/W, it is 23.0 times more energy-efficient and 46.85 times faster than an\nimplementation on the ARM Cortex M4F (0.43 GMAC/s/W). Overall, we obtain 8.1%\nhigher accuracy while consuming 19.6 times less energy and being 35.1 times\nfaster compared to a previous SoA embedded implementation.",
          "link": "http://arxiv.org/abs/2103.13740",
          "publishedOn": "2021-06-15T01:45:21.253Z",
          "wordCount": 681,
          "title": "ECG-TCN: Wearable Cardiac Arrhythmia Detection with a Temporal Convolutional Network. (arXiv:2103.13740v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.09887",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maheshwari_A/0/1/0/all/0/1\">Ayush Maheshwari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chatterjee_O/0/1/0/all/0/1\">Oishik Chatterjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Killamsetty_K/0/1/0/all/0/1\">KrishnaTeja Killamsetty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramakrishnan_G/0/1/0/all/0/1\">Ganesh Ramakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iyer_R/0/1/0/all/0/1\">Rishabh Iyer</a>",
          "description": "The paradigm of data programming, which uses weak supervision in the form of\nrules/labelling functions, and semi-supervised learning, which augments small\namounts of labelled data with a large unlabelled dataset, have shown great\npromise in several text classification scenarios. In this work, we argue that\nby not using any labelled data, data programming based approaches can yield\nsub-optimal performances, particularly when the labelling functions are noisy.\nThe first contribution of this work is an introduction of a framework, \\model\nwhich is a semi-supervised data programming paradigm that learns a \\emph{joint\nmodel} that effectively uses the rules/labelling functions along with\nsemi-supervised loss functions on the feature space. Next, we also study\n\\modelss which additionally does subset selection on top of the joint\nsemi-supervised data programming objective and \\emph{selects} a set of examples\nthat can be used as the labelled set by \\model. The goal of \\modelss is to\nensure that the labelled data can \\emph{complement} the labelling functions,\nthereby benefiting from both data-programming as well as appropriately selected\ndata for human labelling. We demonstrate that by effectively combining\nsemi-supervision, data-programming, and subset selection paradigms, we\nsignificantly outperform the current state-of-the-art on seven publicly\navailable datasets. \\footnote{The source code is available at\n\\url{https://github.com/ayushbits/Semi-Supervised-LFs-Subset-Selection}}",
          "link": "http://arxiv.org/abs/2008.09887",
          "publishedOn": "2021-06-15T01:45:21.247Z",
          "wordCount": 672,
          "title": "Semi-Supervised Data Programming with Subset Selection. (arXiv:2008.09887v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.10683",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Koeppe_A/0/1/0/all/0/1\">Arnd Koeppe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bamer_F/0/1/0/all/0/1\">Franz Bamer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Selzer_M/0/1/0/all/0/1\">Michael Selzer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nestler_B/0/1/0/all/0/1\">Britta Nestler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Markert_B/0/1/0/all/0/1\">Bernd Markert</a>",
          "description": "(Artificial) neural networks have become increasingly popular in mechanics as\nmeans to accelerate computations with model order reduction techniques and as\nuniversal models for a wide variety of materials. However, the major\ndisadvantage of neural networks remains: their numerous parameters are\nchallenging to interpret and explain. Thus, neural networks are often labeled\nas black boxes, and their results often elude human interpretation. In\nmechanics, the new and active field of physics-informed neural networks\nattempts to mitigate this disadvantage by designing deep neural networks on the\nbasis of mechanical knowledge. By using this a priori knowledge, deeper and\nmore complex neural networks became feasible, since the mechanical assumptions\ncould be explained. However, the internal reasoning and explanation of neural\nnetwork parameters remain mysterious.\n\nComplementary to the physics-informed approach, we propose a first step\ntowards a physics-informing approach, which explains neural networks trained on\nmechanical data a posteriori. This novel explainable artificial intelligence\napproach aims at elucidating the black box of neural networks and their\nhigh-dimensional representations. Therein, the principal component analysis\ndecorrelates the distributed representations in cell states of RNNs and allows\nthe comparison to known and fundamental functions. The novel approach is\nsupported by a systematic hyperparameter search strategy that identifies the\nbest neural network architectures and training parameters. The findings of\nthree case studies on fundamental constitutive models (hyperelasticity,\nelastoplasticity, and viscoelasticity) imply that the proposed strategy can\nhelp identify numerical and analytical closed-form solutions to characterize\nnew materials.",
          "link": "http://arxiv.org/abs/2104.10683",
          "publishedOn": "2021-06-15T01:45:21.241Z",
          "wordCount": 723,
          "title": "Explainable artificial intelligence for mechanics: physics-informing neural networks for constitutive models. (arXiv:2104.10683v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.07238",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Harzli_O/0/1/0/all/0/1\">Ouns El Harzli</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Valle_Perez_G/0/1/0/all/0/1\">Guillermo Valle-P&#xe9;rez</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Louis_A/0/1/0/all/0/1\">Ard A. Louis</a>",
          "description": "Double-descent curves in neural networks describe the phenomenon that the\ngeneralisation error initially descends with increasing parameters, then grows\nafter reaching an optimal number of parameters which is less than the number of\ndata points, but then descends again in the overparameterised regime. Here we\nuse a neural network Gaussian process (NNGP) which maps exactly to a fully\nconnected network (FCN) in the infinite width limit, combined with techniques\nfrom random matrix theory, to calculate this generalisation behaviour, with a\nparticular focus on the overparameterised regime. An advantage of our NNGP\napproach is that the analytical calculations are easier to interpret. We argue\nthat neural network generalization performance improves in the\noverparameterised regime precisely because that is where they converge to their\nequivalent Gaussian process.",
          "link": "http://arxiv.org/abs/2102.07238",
          "publishedOn": "2021-06-15T01:45:21.235Z",
          "wordCount": 585,
          "title": "Double-descent curves in neural networks: a new perspective using Gaussian processes. (arXiv:2102.07238v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.00467",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Castelnovo_A/0/1/0/all/0/1\">Alessandro Castelnovo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crupi_R/0/1/0/all/0/1\">Riccardo Crupi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Greco_G/0/1/0/all/0/1\">Greta Greco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Regoli_D/0/1/0/all/0/1\">Daniele Regoli</a>",
          "description": "In recent years, the problem of addressing fairness in Machine Learning (ML)\nand automatic decision-making has attracted a lot of attention in the\nscientific communities dealing with Artificial Intelligence. A plethora of\ndifferent definitions of fairness in ML have been proposed, that consider\ndifferent notions of what is a \"fair decision\" in situations impacting\nindividuals in the population. The precise differences, implications and\n\"orthogonality\" between these notions have not yet been fully analyzed in the\nliterature. In this work, we try to make some order out of this zoo of\ndefinitions.",
          "link": "http://arxiv.org/abs/2106.00467",
          "publishedOn": "2021-06-15T01:45:21.218Z",
          "wordCount": 546,
          "title": "The zoo of Fairness metrics in Machine Learning. (arXiv:2106.00467v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02556",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Farris_N/0/1/0/all/0/1\">Nicholas Farris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Model_B/0/1/0/all/0/1\">Brian Model</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Savery_R/0/1/0/all/0/1\">Richard Savery</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weinberg_G/0/1/0/all/0/1\">Gil Weinberg</a>",
          "description": "The task of classifying emotions within a musical track has received\nwidespread attention within the Music Information Retrieval (MIR) community.\nMusic emotion recognition has traditionally relied on the use of acoustic\nfeatures, verbal features, and metadata-based filtering. The role of musical\nprosody remains under-explored despite several studies demonstrating a strong\nconnection between prosody and emotion. In this study, we restrict the input of\ntraditional machine learning algorithms to the features of musical prosody.\nFurthermore, our proposed approach builds upon the prior by classifying\nemotions under an expanded emotional taxonomy, using the Geneva Wheel of\nEmotion. We utilize a methodology for individual data collection from\nvocalists, and personal ground truth labeling by the artist themselves. We\nfound that traditional machine learning algorithms when limited to the features\nof musical prosody (1) achieve high accuracies for a single singer, (2)\nmaintain high accuracy when the dataset is expanded to multiple singers, and\n(3) achieve high accuracies when trained on a reduced subset of the total\nfeatures.",
          "link": "http://arxiv.org/abs/2106.02556",
          "publishedOn": "2021-06-15T01:45:21.211Z",
          "wordCount": 622,
          "title": "Musical Prosody-Driven Emotion Classification: Interpreting Vocalists Portrayal of Emotions Through Machine Learning. (arXiv:2106.02556v2 [cs.SD] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.03767",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ozdayi_M/0/1/0/all/0/1\">Mustafa Safa Ozdayi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kantarcioglu_M/0/1/0/all/0/1\">Murat Kantarcioglu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gel_Y/0/1/0/all/0/1\">Yulia R. Gel</a>",
          "description": "Federated learning (FL) allows a set of agents to collaboratively train a\nmodel without sharing their potentially sensitive data. This makes FL suitable\nfor privacy-preserving applications. At the same time, FL is susceptible to\nadversarial attacks due to decentralized and unvetted data. One important line\nof attacks against FL is the backdoor attacks. In a backdoor attack, an\nadversary tries to embed a backdoor functionality to the model during training\nthat can later be activated to cause a desired misclassification. To prevent\nbackdoor attacks, we propose a lightweight defense that requires minimal change\nto the FL protocol. At a high level, our defense is based on carefully\nadjusting the aggregation server's learning rate, per dimension and per round,\nbased on the sign information of agents' updates. We first conjecture the\nnecessary steps to carry a successful backdoor attack in FL setting, and then,\nexplicitly formulate the defense based on our conjecture. Through experiments,\nwe provide empirical evidence that supports our conjecture, and we test our\ndefense against backdoor attacks under different settings. We observe that\neither backdoor is completely eliminated, or its accuracy is significantly\nreduced. Overall, our experiments suggest that our defense significantly\noutperforms some of the recently proposed defenses in the literature. We\nachieve this by having minimal influence over the accuracy of the trained\nmodels. In addition, we also provide convergence rate analysis for our proposed\nscheme.",
          "link": "http://arxiv.org/abs/2007.03767",
          "publishedOn": "2021-06-15T01:45:21.202Z",
          "wordCount": 710,
          "title": "Defending against Backdoors in Federated Learning with Robust Learning Rate. (arXiv:2007.03767v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06608",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ho_N/0/1/0/all/0/1\">Nhat Ho</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Walker_S/0/1/0/all/0/1\">Stephen G. Walker</a>",
          "description": "Taking the Fourier integral theorem as our starting point, in this paper we\nfocus on natural Monte Carlo and fully nonparametric estimators of multivariate\ndistributions and conditional distribution functions. We do this without the\nneed for any estimated covariance matrix or dependence structure between\nvariables. These aspects arise immediately from the integral theorem. Being\nable to model multivariate data sets using conditional distribution functions\nwe can study a number of problems, such as prediction for Markov processes,\nestimation of mixing distribution functions which depend on covariates, and\ngeneral multivariate data. Estimators are explicit Monte Carlo based and\nrequire no recursive or iterative algorithms.",
          "link": "http://arxiv.org/abs/2106.06608",
          "publishedOn": "2021-06-15T01:45:21.191Z",
          "wordCount": 536,
          "title": "Statistical Analysis from the Fourier Integral Theorem. (arXiv:2106.06608v1 [stat.ME])"
        },
        {
          "id": "http://arxiv.org/abs/2102.05140",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bahri_D/0/1/0/all/0/1\">Dara Bahri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Heinrich Jiang</a>",
          "description": "Training modern neural networks is an inherently noisy process that can lead\nto high \\emph{prediction churn} -- disagreements between re-trainings of the\nsame model due to factors such as randomization in the parameter initialization\nand mini-batches -- even when the trained models all attain similar accuracies.\nSuch prediction churn can be very undesirable in practice. In this paper, we\npresent several baselines for reducing churn and show that training on soft\nlabels obtained by adaptively smoothing each example's label based on the\nexample's neighboring labels often outperforms the baselines on churn while\nimproving accuracy on a variety of benchmark classification tasks and model\narchitectures.",
          "link": "http://arxiv.org/abs/2102.05140",
          "publishedOn": "2021-06-15T01:45:21.185Z",
          "wordCount": 554,
          "title": "Locally Adaptive Label Smoothing for Predictive Churn. (arXiv:2102.05140v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.04507",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Guo_X/0/1/0/all/0/1\">Xin Guo</a>, <a href=\"http://arxiv.org/find/math/1/au:+Han_J/0/1/0/all/0/1\">Jiequn Han</a>, <a href=\"http://arxiv.org/find/math/1/au:+Tajrobehkar_M/0/1/0/all/0/1\">Mahan Tajrobehkar</a>, <a href=\"http://arxiv.org/find/math/1/au:+Tang_W/0/1/0/all/0/1\">Wenpin Tang</a>",
          "description": "This paper develops further the idea of perturbed gradient descent (PGD), by\nadapting perturbation with the history of states via the notion of occupation\ntime. The proposed algorithm, perturbed gradient descent adapted with\noccupation time (PGDOT), is shown to converge at least as fast as the PGD\nalgorithm and is guaranteed to avoid getting stuck at saddle points. The\nanalysis is corroborated by empirical studies, in which a mini-batch version of\nPGDOT is shown to outperform alternatives such as mini-batch gradient descent,\nAdam, AMSGrad, and RMSProp in training multilayer perceptrons (MLPs). In\nparticular, the mini-batch PGDOT manages to escape saddle points whereas these\nalternatives fail.",
          "link": "http://arxiv.org/abs/2005.04507",
          "publishedOn": "2021-06-15T01:45:21.166Z",
          "wordCount": 561,
          "title": "PGDOT -- Perturbed Gradient Descent Adapted with Occupation Time. (arXiv:2005.04507v2 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.10685",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zou_X/0/1/0/all/0/1\">Xu Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_D/0/1/0/all/0/1\">Da Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_Q/0/1/0/all/0/1\">Qingyang Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1\">Ming Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhilin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jie Tang</a>",
          "description": "Large-scale pre-trained language models have demonstrated strong capabilities\nof generating realistic text. However, it remains challenging to control the\ngeneration results. Previous approaches such as prompting are far from\nsufficient, which limits the usage of language models. To tackle this\nchallenge, we propose an innovative method, inverse prompting, to better\ncontrol text generation. The core idea of inverse prompting is to use generated\ntext to inversely predict the prompt during beam search, which enhances the\nrelevance between the prompt and the generated text and provides better\ncontrollability. Empirically, we pre-train a large-scale Chinese language model\nto perform a systematic study using human evaluation on the tasks of\nopen-domain poem generation and open-domain long-form question answering. Our\nresults show that our proposed method substantially outperforms the baselines\nand that our generation quality is close to human performance on some of the\ntasks.\n\nNarrators can try our poem generation demo at\nhttps://pretrain.aminer.cn/apps/poetry.html, while our QA demo can be found at\nhttps://pretrain.aminer.cn/app/qa. For researchers, the code is provided in\nhttps://github.com/THUDM/InversePrompting.",
          "link": "http://arxiv.org/abs/2103.10685",
          "publishedOn": "2021-06-15T01:45:21.159Z",
          "wordCount": 641,
          "title": "Controllable Generation from Pre-trained Language Models via Inverse Prompting. (arXiv:2103.10685v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.10271",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walters_R/0/1/0/all/0/1\">Robin Walters</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_R/0/1/0/all/0/1\">Rose Yu</a>",
          "description": "Current deep learning models for dynamics forecasting struggle with\ngeneralization. They can only forecast in a specific domain and fail when\napplied to systems with different parameters, external forces, or boundary\nconditions. We propose a model-based meta-learning method called DyAd which can\ngeneralize across heterogeneous domains by partitioning them into different\ntasks. DyAd has two parts: an encoder which infers the time-invariant hidden\nfeatures of the task with weak supervision, and a forecaster which learns the\nshared dynamics of the entire domain. The encoder adapts and controls the\nforecaster during inference using adaptive instance normalization and adaptive\npadding. Theoretically, we prove that the generalization error of such\nprocedure is related to the task relatedness in the source domain, as well as\nthe domain differences between source and target. Experimentally, we\ndemonstrate that our model outperforms state-of-the-art approaches on both\nturbulent flow and real-world ocean data forecasting tasks.",
          "link": "http://arxiv.org/abs/2102.10271",
          "publishedOn": "2021-06-15T01:45:21.141Z",
          "wordCount": 592,
          "title": "Meta-Learning Dynamics Forecasting Using Task Inference. (arXiv:2102.10271v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03279",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Kai Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_S/0/1/0/all/0/1\">Sanket Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Haipeng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perrault_A/0/1/0/all/0/1\">Andrew Perrault</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doshi_Velez_F/0/1/0/all/0/1\">Finale Doshi-Velez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tambe_M/0/1/0/all/0/1\">Milind Tambe</a>",
          "description": "In the predict-then-optimize framework, the objective is to train a\npredictive model, mapping from environment features to parameters of an\noptimization problem, which maximizes decision quality when the optimization is\nsubsequently solved. Recent work on decision-focused learning shows that\nembedding the optimization problem in the training pipeline can improve\ndecision quality and help generalize better to unseen tasks compared to relying\non an intermediate loss function for evaluating prediction quality. We study\nthe predict-then-optimize framework in the context of sequential decision\nproblems (formulated as MDPs) that are solved via reinforcement learning. In\nparticular, we are given environment features and a set of trajectories from\ntraining MDPs, which we use to train a predictive model that generalizes to\nunseen test MDPs without trajectories. Two significant computational challenges\narise in applying decision-focused learning to MDPs: (i) large state and action\nspaces make it infeasible for existing techniques to differentiate through MDP\nproblems, and (ii) the high-dimensional policy space, as parameterized by a\nneural network, makes differentiating through a policy expensive. We resolve\nthe first challenge by sampling provably unbiased derivatives to approximate\nand differentiate through optimality conditions, and the second challenge by\nusing a low-rank approximation to the high-dimensional sample-based\nderivatives. We implement both Bellman--based and policy gradient--based\ndecision-focused learning on three different MDP problems with missing\nparameters, and show that decision-focused learning performs better in\ngeneralization to unseen tasks.",
          "link": "http://arxiv.org/abs/2106.03279",
          "publishedOn": "2021-06-15T01:45:21.135Z",
          "wordCount": 680,
          "title": "Learning MDPs from Features: Predict-Then-Optimize for Sequential Decision Problems by Reinforcement Learning. (arXiv:2106.03279v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.04850",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jesson_A/0/1/0/all/0/1\">Andrew Jesson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mindermann_S/0/1/0/all/0/1\">S&#xf6;ren Mindermann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gal_Y/0/1/0/all/0/1\">Yarin Gal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shalit_U/0/1/0/all/0/1\">Uri Shalit</a>",
          "description": "We study the problem of learning conditional average treatment effects (CATE)\nfrom high-dimensional, observational data with unobserved confounders.\nUnobserved confounders introduce ignorance -- a level of unidentifiability --\nabout an individual's response to treatment by inducing bias in CATE estimates.\nWe present a new parametric interval estimator suited for high-dimensional\ndata, that estimates a range of possible CATE values when given a predefined\nbound on the level of hidden confounding. Further, previous interval estimators\ndo not account for ignorance about the CATE associated with samples that may be\nunderrepresented in the original study, or samples that violate the overlap\nassumption. Our interval estimator also incorporates model uncertainty so that\npractitioners can be made aware of out-of-distribution data. We prove that our\nestimator converges to tight bounds on CATE when there may be unobserved\nconfounding, and assess it using semi-synthetic, high-dimensional datasets.",
          "link": "http://arxiv.org/abs/2103.04850",
          "publishedOn": "2021-06-15T01:45:21.129Z",
          "wordCount": 627,
          "title": "Quantifying Ignorance in Individual-Level Causal-Effect Estimates under Hidden Confounding. (arXiv:2103.04850v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.08633",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sirignano_J/0/1/0/all/0/1\">Justin Sirignano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+MacArt_J/0/1/0/all/0/1\">Jonathan MacArt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spiliopoulos_K/0/1/0/all/0/1\">Konstantinos Spiliopoulos</a>",
          "description": "Recent research has used deep learning to develop partial differential\nequation (PDE) models in science and engineering. The functional form of the\nPDE is determined by a neural network, and the neural network parameters are\ncalibrated to available data. Calibration of the embedded neural network can be\nperformed by optimizing over the PDE. Motivated by these applications, we\nrigorously study the optimization of a class of linear elliptic PDEs with\nneural network terms. The neural network parameters in the PDE are optimized\nusing gradient descent, where the gradient is evaluated using an adjoint PDE.\nAs the number of parameters become large, the PDE and adjoint PDE converge to a\nnon-local PDE system. Using this limit PDE system, we are able to prove\nconvergence of the neural network-PDE to a global minimum during the\noptimization. The limit PDE system contains a non-local linear operator whose\neigenvalues are positive but become arbitrarily small. The lack of a spectral\ngap for the eigenvalues poses the main challenge for the global convergence\nproof. Careful analysis of the spectral decomposition of the coupled PDE and\nadjoint PDE system is required. Finally, we use this adjoint method to train a\nneural network model for an application in fluid mechanics, in which the neural\nnetwork functions as a closure model for the Reynolds-averaged Navier-Stokes\n(RANS) equations. The RANS neural network model is trained on several datasets\nfor turbulent channel flow and is evaluated out-of-sample at different Reynolds\nnumbers.",
          "link": "http://arxiv.org/abs/2105.08633",
          "publishedOn": "2021-06-15T01:45:21.065Z",
          "wordCount": 695,
          "title": "PDE-constrained Models with Neural Network Terms: Optimization and Global Convergence. (arXiv:2105.08633v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.03129",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1\">Rui Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dash_S/0/1/0/all/0/1\">Sanjeeb Dash</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_T/0/1/0/all/0/1\">Tian Gao</a>",
          "description": "The problem of finding an ancestral acyclic directed mixed graph (ADMG) that\nrepresents the causal relationships between a set of variables is an important\narea of research on causal inference. Most existing score-based structure\nlearning methods focus on learning directed acyclic graph (DAG) models without\nlatent variables. A number of score-based methods have recently been proposed\nfor the ADMG learning, yet they are heuristic in nature and do not guarantee an\noptimal solution. We propose a novel exact score-based method that solves an\ninteger programming (IP) formulation and returns a score-maximizing ancestral\nADMG for a set of continuous variables that follow a multivariate Gaussian\ndistribution. We generalize the state-of-the-art IP model for DAG learning\nproblems and derive new classes of valid inequalities to formulate an IP model\nfor ADMG learning. Empirically, our model can be solved efficiently for\nmedium-sized problems and achieves better accuracy than state-of-the-art\nscore-based methods as well as benchmark constraint-based methods.",
          "link": "http://arxiv.org/abs/2102.03129",
          "publishedOn": "2021-06-15T01:45:20.460Z",
          "wordCount": 618,
          "title": "Integer Programming for Causal Structure Learning in the Presence of Latent Variables. (arXiv:2102.03129v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.02266",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Guo_Z/0/1/0/all/0/1\">Zhishuai Guo</a>, <a href=\"http://arxiv.org/find/math/1/au:+Hu_Q/0/1/0/all/0/1\">Quanqi Hu</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhang_L/0/1/0/all/0/1\">Lijun Zhang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Yang_T/0/1/0/all/0/1\">Tianbao Yang</a>",
          "description": "In this paper, we consider non-convex stochastic bilevel optimization (SBO)\nproblems that have many applications in machine learning. Although numerous\nstudies have proposed stochastic algorithms for solving these problems, they\nare limited in two perspectives: (i) their sample complexities are high, which\ndo not match the state-of-the-art result for non-convex stochastic\noptimization; (ii) their algorithms are tailored to problems with only one\nlower-level problem. When there are many lower-level problems, it could be\nprohibitive to process all these lower-level problems at each iteration. To\naddress these limitations, this paper proposes fast randomized stochastic\nalgorithms for non-convex SBO problems. First, we present a stochastic method\nfor non-convex SBO with only one lower problem and establish its sample\ncomplexity of $O(1/\\epsilon^3)$ for finding an $\\epsilon$-stationary point\nunder Lipschitz continuous conditions of stochastic oracles, matching the lower\nbound for stochastic smooth non-convex optimization. Second, we present a\nrandomized stochastic method for non-convex SBO with $m>1$ lower level problems\n(multi-task SBO) by processing a constant number of lower problems at each\niteration, and establish its sample complexity no worse than $O(m/\\epsilon^3)$,\nwhich could be a better complexity than that of simply processing all $m$ lower\nproblems at each iteration. Lastly, we establish even faster convergence\nresults for gradient-dominant functions. To the best of our knowledge, this is\nthe first work considering multi-task SBO and developing state-of-the-art\nsample complexity results.",
          "link": "http://arxiv.org/abs/2105.02266",
          "publishedOn": "2021-06-15T01:45:20.453Z",
          "wordCount": 674,
          "title": "Randomized Stochastic Variance-Reduced Methods for Multi-Task Stochastic Bilevel Optimization. (arXiv:2105.02266v2 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.15082",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_A/0/1/0/all/0/1\">An Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Junyang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Men_R/0/1/0/all/0/1\">Rui Men</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Chang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1\">Le Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_X/0/1/0/all/0/1\">Xianyan Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_A/0/1/0/all/0/1\">Ang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jie Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiamang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Di Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1\">Wei Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_L/0/1/0/all/0/1\">Lin Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jingren Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hongxia Yang</a>",
          "description": "Mixture-of-Experts (MoE) models can achieve promising results with outrageous\nlarge amount of parameters but constant computation cost, and thus it has\nbecome a trend in model scaling. Still it is a mystery how MoE layers bring\nquality gains by leveraging the parameters with sparse activation. In this\nwork, we investigate several key factors in sparse expert models. We observe\nthat load imbalance may not be a significant problem affecting model quality,\ncontrary to the perspectives of recent studies, while the number of sparsely\nactivated experts $k$ and expert capacity $C$ in top-$k$ routing can\nsignificantly make a difference in this context. Furthermore, we take a step\nforward to propose a simple method called expert prototyping that splits\nexperts into different prototypes and applies $k$ top-$1$ routing. This\nstrategy improves the model quality but maintains constant computational costs,\nand our further exploration on extremely large-scale models reflects that it is\nmore effective in training larger models. We push the model scale to over $1$\ntrillion parameters and implement it on solely $480$ NVIDIA V100-32GB GPUs, in\ncomparison with the recent SOTAs on $2048$ TPU cores. The proposed giant model\nachieves substantial speedup in convergence over the same-size baseline.",
          "link": "http://arxiv.org/abs/2105.15082",
          "publishedOn": "2021-06-15T01:45:20.439Z",
          "wordCount": 674,
          "title": "Exploring Sparse Expert Models and Beyond. (arXiv:2105.15082v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.11982",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1\">Dongxia Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1\">Liyao Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_X/0/1/0/all/0/1\">Xinyue Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chinazzi_M/0/1/0/all/0/1\">Matteo Chinazzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vespignani_A/0/1/0/all/0/1\">Alessandro Vespignani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yi-An Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_R/0/1/0/all/0/1\">Rose Yu</a>",
          "description": "Deep learning is gaining increasing popularity for spatiotemporal\nforecasting. However, prior works have mostly focused on point estimates\nwithout quantifying the uncertainty of the predictions. In high stakes domains,\nbeing able to generate probabilistic forecasts with confidence intervals is\ncritical to risk assessment and decision making. Hence, a systematic study of\nuncertainty quantification (UQ) methods for spatiotemporal forecasting is\nmissing in the community. In this paper, we describe two types of\nspatiotemporal forecasting problems: regular grid-based and graph-based. Then\nwe analyze UQ methods from both the Bayesian and the frequentist point of view,\ncasting in a unified framework via statistical decision theory. Through\nextensive experiments on real-world road network traffic, epidemics, and air\nquality forecasting tasks, we reveal the statistical and computational\ntrade-offs for different UQ methods: Bayesian methods are typically more robust\nin mean prediction, while confidence levels obtained from frequentist methods\nprovide more extensive coverage over data variations. Computationally, quantile\nregression type methods are cheaper for a single confidence interval but\nrequire re-training for different intervals. Sampling based methods generate\nsamples that can form multiple confidence intervals, albeit at a higher\ncomputational cost.",
          "link": "http://arxiv.org/abs/2105.11982",
          "publishedOn": "2021-06-15T01:45:20.433Z",
          "wordCount": 661,
          "title": "Quantifying Uncertainty in Deep Spatiotemporal Forecasting. (arXiv:2105.11982v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.08452",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Leino_K/0/1/0/all/0/1\">Klas Leino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zifan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fredrikson_M/0/1/0/all/0/1\">Matt Fredrikson</a>",
          "description": "The threat of adversarial examples has motivated work on training certifiably\nrobust neural networks to facilitate efficient verification of local robustness\nat inference time. We formalize a notion of global robustness, which captures\nthe operational properties of on-line local robustness certification while\nyielding a natural learning objective for robust training. We show that\nwidely-used architectures can be easily adapted to this objective by\nincorporating efficient global Lipschitz bounds into the network, yielding\ncertifiably-robust models by construction that achieve state-of-the-art\nverifiable accuracy. Notably, this approach requires significantly less time\nand memory than recent certifiable training methods, and leads to negligible\ncosts when certifying points on-line; for example, our evaluation shows that it\nis possible to train a large robust Tiny-Imagenet model in a matter of hours.\nOur models effectively leverage inexpensive global Lipschitz bounds for\nreal-time certification, despite prior suggestions that tighter local bounds\nare needed for good performance; we posit this is possible because our models\nare specifically trained to achieve tighter global bounds. Namely, we prove\nthat the maximum achievable verifiable accuracy for a given dataset is not\nimproved by using a local bound.",
          "link": "http://arxiv.org/abs/2102.08452",
          "publishedOn": "2021-06-15T01:45:20.416Z",
          "wordCount": 639,
          "title": "Globally-Robust Neural Networks. (arXiv:2102.08452v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.07496",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Skarding_J/0/1/0/all/0/1\">Joakim Skarding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gabrys_B/0/1/0/all/0/1\">Bogdan Gabrys</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Musial_K/0/1/0/all/0/1\">Katarzyna Musial</a>",
          "description": "Dynamic networks are used in a wide range of fields, including social network\nanalysis, recommender systems, and epidemiology. Representing complex networks\nas structures changing over time allow network models to leverage not only\nstructural but also temporal patterns. However, as dynamic network literature\nstems from diverse fields and makes use of inconsistent terminology, it is\nchallenging to navigate. Meanwhile, graph neural networks (GNNs) have gained a\nlot of attention in recent years for their ability to perform well on a range\nof network science tasks, such as link prediction and node classification.\nDespite the popularity of graph neural networks and the proven benefits of\ndynamic network models, there has been little focus on graph neural networks\nfor dynamic networks. To address the challenges resulting from the fact that\nthis research crosses diverse fields as well as to survey dynamic graph neural\nnetworks, this work is split into two main parts. First, to address the\nambiguity of the dynamic network terminology we establish a foundation of\ndynamic networks with consistent, detailed terminology and notation. Second, we\npresent a comprehensive survey of dynamic graph neural network models using the\nproposed terminology",
          "link": "http://arxiv.org/abs/2005.07496",
          "publishedOn": "2021-06-15T01:45:20.410Z",
          "wordCount": 680,
          "title": "Foundations and modelling of dynamic networks using Dynamic Graph Neural Networks: A survey. (arXiv:2005.07496v2 [cs.SI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.13010",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jian Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_Y/0/1/0/all/0/1\">Yuling Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yunfei Yang</a>",
          "description": "This paper studies how well generative adversarial networks (GANs) learn\nprobability distributions from finite samples. Our main results establish the\nconvergence rates of GANs under a collection of integral probability metrics\ndefined through H\\\"older classes, including the Wasserstein distance as a\nspecial case. We also show that GANs are able to adaptively learn data\ndistributions with low-dimensional structures or have H\\\"older densities, when\nthe network architectures are chosen properly. In particular, for distributions\nconcentrated around a low-dimensional set, we show that the learning rates of\nGANs do not depend on the high ambient dimension, but on the lower intrinsic\ndimension. Our analysis is based on a new oracle inequality decomposing the\nestimation error into the generator and discriminator approximation error and\nthe statistical error, which may be of independent interest.",
          "link": "http://arxiv.org/abs/2105.13010",
          "publishedOn": "2021-06-15T01:45:20.404Z",
          "wordCount": 613,
          "title": "An error analysis of generative adversarial networks for learning distributions. (arXiv:2105.13010v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.00123",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Killamsetty_K/0/1/0/all/0/1\">Krishnateja Killamsetty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sivasubramanian_D/0/1/0/all/0/1\">Durga Sivasubramanian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramakrishnan_G/0/1/0/all/0/1\">Ganesh Ramakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+De_A/0/1/0/all/0/1\">Abir De</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iyer_R/0/1/0/all/0/1\">Rishabh Iyer</a>",
          "description": "The great success of modern machine learning models on large datasets is\ncontingent on extensive computational resources with high financial and\nenvironmental costs. One way to address this is by extracting subsets that\ngeneralize on par with the full data. In this work, we propose a general\nframework, GRAD-MATCH, which finds subsets that closely match the gradient of\nthe training or validation set. We find such subsets effectively using an\northogonal matching pursuit algorithm. We show rigorous theoretical and\nconvergence guarantees of the proposed algorithm and, through our extensive\nexperiments on real-world datasets, show the effectiveness of our proposed\nframework. We show that GRAD-MATCH significantly and consistently outperforms\nseveral recent data-selection algorithms and achieves the best\naccuracy-efficiency trade-off. GRAD-MATCH is available as a part of the CORDS\ntoolkit: \\url{https://github.com/decile-team/cords}.",
          "link": "http://arxiv.org/abs/2103.00123",
          "publishedOn": "2021-06-15T01:45:20.397Z",
          "wordCount": 611,
          "title": "GRAD-MATCH: Gradient Matching based Data Subset Selection for Efficient Deep Model Training. (arXiv:2103.00123v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.03821",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yuheng Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jinpeng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1\">ChuXiong Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1\">Jie Hu</a>",
          "description": "Learning node representations that incorporate information from graph\nstructure benefits wide range of tasks on graph. The majority of existing graph\nneural networks (GNNs) have limited power in capturing position information for\na given node. The idea of positioning nodes with selected anchors has been\nexploited, yet mainly relying on explicit labeling of distance information.\nHere we propose Graph Inference Representation (GIR), an anchor based GNN model\nencoding path information related to pre-selected anchors for each node.\nAbilities to get position-aware embeddings are theoretically and experimentally\ninvestigated on GIR and its core variants. Further, the complementarity between\nGIRs and typical GNNs is demonstrated. We show that GIRs get outperformed\nresults in position-aware scenarios, and performances on typical GNNs could be\nimproved by fusing GIR embeddings.",
          "link": "http://arxiv.org/abs/2105.03821",
          "publishedOn": "2021-06-15T01:45:20.374Z",
          "wordCount": 590,
          "title": "Graph Inference Representation: Learning Graph Positional Embeddings with Anchor Path Encoding. (arXiv:2105.03821v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.11417",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singla_S/0/1/0/all/0/1\">Sahil Singla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feizi_S/0/1/0/all/0/1\">Soheil Feizi</a>",
          "description": "Training convolutional neural networks with a Lipschitz constraint under the\n$l_{2}$ norm is useful for provable adversarial robustness, interpretable\ngradients, stable training, etc. While 1-Lipschitz networks can be designed by\nimposing a 1-Lipschitz constraint on each layer, training such networks\nrequires each layer to be gradient norm preserving (GNP) to prevent gradients\nfrom vanishing. However, existing GNP convolutions suffer from slow training,\nlead to significant reduction in accuracy and provide no guarantees on their\napproximations. In this work, we propose a GNP convolution layer called Skew\nOrthogonal Convolution (SOC) that uses the following mathematical property:\nwhen a matrix is {\\it Skew-Symmetric}, its exponential function is an {\\it\northogonal} matrix. To use this property, we first construct a convolution\nfilter whose Jacobian is Skew-Symmetric. Then, we use the Taylor series\nexpansion of the Jacobian exponential to construct the SOC layer that is\northogonal. To efficiently implement SOC, we keep a finite number of terms from\nthe Taylor series and provide a provable guarantee on the approximation error.\nOur experiments on CIFAR-10 and CIFAR-100 show that SOC allows us to train\nprovably Lipschitz, large convolutional neural networks significantly faster\nthan prior works while achieving significant improvements for both standard and\ncertified robust accuracies.",
          "link": "http://arxiv.org/abs/2105.11417",
          "publishedOn": "2021-06-15T01:45:20.367Z",
          "wordCount": 642,
          "title": "Skew Orthogonal Convolutions. (arXiv:2105.11417v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1911.10258",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singla_S/0/1/0/all/0/1\">Sahil Singla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feizi_S/0/1/0/all/0/1\">Soheil Feizi</a>",
          "description": "In deep neural networks, the spectral norm of the Jacobian of a layer bounds\nthe factor by which the norm of a signal changes during forward/backward\npropagation. Spectral norm regularizations have been shown to improve\ngeneralization, robustness and optimization of deep learning methods. Existing\nmethods to compute the spectral norm of convolution layers either rely on\nheuristics that are efficient in computation but lack guarantees or are\ntheoretically-sound but computationally expensive. In this work, we obtain the\nbest of both worlds by deriving {\\it four} provable upper bounds on the\nspectral norm of a standard 2D multi-channel convolution layer. These bounds\nare differentiable and can be computed efficiently during training with\nnegligible overhead. One of these bounds is in fact the popular heuristic\nmethod of Miyato et al. (multiplied by a constant factor depending on filter\nsizes). Each of these four bounds can achieve the tightest gap depending on\nconvolution filters. Thus, we propose to use the minimum of these four bounds\nas a tight, differentiable and efficient upper bound on the spectral norm of\nconvolution layers. We show that our spectral bound is an effective regularizer\nand can be used to bound either the lipschitz constant or curvature values\n(eigenvalues of the Hessian) of neural networks. Through experiments on MNIST\nand CIFAR-10, we demonstrate the effectiveness of our spectral bound in\nimproving generalization and provable robustness of deep networks.",
          "link": "http://arxiv.org/abs/1911.10258",
          "publishedOn": "2021-06-15T01:45:20.361Z",
          "wordCount": 700,
          "title": "Fantastic Four: Differentiable Bounds on Singular Values of Convolution Layers. (arXiv:1911.10258v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.12013",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chi_J/0/1/0/all/0/1\">Jianfeng Chi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yuan Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gordon_G/0/1/0/all/0/1\">Geoffrey J. Gordon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Han Zhao</a>",
          "description": "With the widespread deployment of large-scale prediction systems in\nhigh-stakes domains, e.g., face recognition, criminal justice, etc., disparity\nin prediction accuracy between different demographic subgroups has called for\nfundamental understanding on the source of such disparity and algorithmic\nintervention to mitigate it. In this paper, we study the accuracy disparity\nproblem in regression. To begin with, we first propose an error decomposition\ntheorem, which decomposes the accuracy disparity into the distance between\nmarginal label distributions and the distance between conditional\nrepresentations, to help explain why such accuracy disparity appears in\npractice. Motivated by this error decomposition and the general idea of\ndistribution alignment with statistical distances, we then propose an algorithm\nto reduce this disparity, and analyze its game-theoretic optima of the proposed\nobjective functions. To corroborate our theoretical findings, we also conduct\nexperiments on five benchmark datasets. The experimental results suggest that\nour proposed algorithms can effectively mitigate accuracy disparity while\nmaintaining the predictive power of the regression models.",
          "link": "http://arxiv.org/abs/2102.12013",
          "publishedOn": "2021-06-15T01:45:20.354Z",
          "wordCount": 626,
          "title": "Understanding and Mitigating Accuracy Disparity in Regression. (arXiv:2102.12013v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.08622",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tai_K/0/1/0/all/0/1\">Kai Sheng Tai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bailis_P/0/1/0/all/0/1\">Peter Bailis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valiant_G/0/1/0/all/0/1\">Gregory Valiant</a>",
          "description": "Self-training is a standard approach to semi-supervised learning where the\nlearner's own predictions on unlabeled data are used as supervision during\ntraining. In this paper, we reinterpret this label assignment process as an\noptimal transportation problem between examples and classes, wherein the cost\nof assigning an example to a class is mediated by the current predictions of\nthe classifier. This formulation facilitates a practical annealing strategy for\nlabel assignment and allows for the inclusion of prior knowledge on class\nproportions via flexible upper bound constraints. The solutions to these\nassignment problems can be efficiently approximated using Sinkhorn iteration,\nthus enabling their use in the inner loop of standard stochastic optimization\nalgorithms. We demonstrate the effectiveness of our algorithm on the CIFAR-10,\nCIFAR-100, and SVHN datasets in comparison with FixMatch, a state-of-the-art\nself-training algorithm. Our code is available at\nhttps://github.com/stanford-futuredata/sinkhorn-label-allocation.",
          "link": "http://arxiv.org/abs/2102.08622",
          "publishedOn": "2021-06-15T01:45:20.347Z",
          "wordCount": 604,
          "title": "Sinkhorn Label Allocation: Semi-Supervised Classification via Annealed Self-Training. (arXiv:2102.08622v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.01714",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Polar_A/0/1/0/all/0/1\">Andrew Polar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poluektov_M/0/1/0/all/0/1\">Michael Poluektov</a>",
          "description": "The terms tree and forest are normally associated with an ensemble of\nclassifiers. In this article Urysohn tree is a regression model representing\nmultiple discrete Urysohn operators connected as a tree, where the inputs of\none operator are outputs of the others. This structure, referred as Urysohn\ntree, is not completely new. One example of such tree is known for more than\nhalf a century. It is Kolmogorov-Arnold representation. The authors of this\npaper in their recently published research offered the new computational\ntechnique for generating of Kolmogorov-Arnold representation as a deep machine\nlearning process. This article is two steps further into this research. First\nis a Urysohn tree with multiple hidden layers which is generalization of\nKolmogorov-Arnold model and second is a boosting algorithm for building of the\nforest of such trees for modeling of aleatoric uncertainty of the data.",
          "link": "http://arxiv.org/abs/2104.01714",
          "publishedOn": "2021-06-15T01:45:20.331Z",
          "wordCount": 584,
          "title": "Urysohn Forest for Aleatoric Uncertainty Quantification. (arXiv:2104.01714v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.01338",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_N/0/1/0/all/0/1\">Naman Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goel_S/0/1/0/all/0/1\">Surbhi Goel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Cyril Zhang</a>",
          "description": "In practical applications of iterative first-order optimization, the learning\nrate schedule remains notoriously difficult to understand and expensive to\ntune. We demonstrate the presence of these subtleties even in the innocuous\ncase when the objective is a convex quadratic. We reinterpret an iterative\nalgorithm from the numerical analysis literature as what we call the Chebyshev\nlearning rate schedule for accelerating vanilla gradient descent, and show that\nthe problem of mitigating instability leads to a fractal ordering of step\nsizes. We provide some experiments to challenge conventional beliefs about\nstable learning rates in deep learning: the fractal schedule enables training\nto converge with locally unstable updates which make negative progress on the\nobjective.",
          "link": "http://arxiv.org/abs/2103.01338",
          "publishedOn": "2021-06-15T01:45:20.322Z",
          "wordCount": 575,
          "title": "Acceleration via Fractal Learning Rate Schedules. (arXiv:2103.01338v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02549",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Frank_T/0/1/0/all/0/1\">Thorben Frank</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chmiela_S/0/1/0/all/0/1\">Stefan Chmiela</a>",
          "description": "Attention mechanisms are developing into a viable alternative to\nconvolutional layers as elementary building block of NNs. Their main advantage\nis that they are not restricted to capture local dependencies in the input, but\ncan draw arbitrary connections. This unprecedented capability coincides with\nthe long-standing problem of modeling global atomic interactions in molecular\nforce fields and other many-body problems. In its original formulation,\nhowever, attention is not applicable to the continuous domains in which the\natoms live. For this purpose we propose a variant to describe geometric\nrelations for arbitrary atomic configurations in Euclidean space that also\nrespects all relevant physical symmetries. We furthermore demonstrate, how the\nsuccessive application of our learned attention matrices effectively translates\nthe molecular geometry into a set of individual atomic contributions\non-the-fly.",
          "link": "http://arxiv.org/abs/2106.02549",
          "publishedOn": "2021-06-15T01:45:20.317Z",
          "wordCount": 578,
          "title": "Detect the Interactions that Matter in Matter: Geometric Attention for Many-Body Systems. (arXiv:2106.02549v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.00455",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Strobl_E/0/1/0/all/0/1\">Eric V. Strobl</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lasko_T/0/1/0/all/0/1\">Thomas A. Lasko</a>",
          "description": "We consider estimating the conditional average treatment effect for everyone\nby eliminating confounding and selection bias. Unfortunately, randomized\nclinical trials (RCTs) eliminate confounding but impose strict exclusion\ncriteria that prevent sampling of the entire clinical population. Observational\ndatasets are more inclusive but suffer from confounding. We therefore analyze\nRCT and observational data simultaneously in order to extract the strengths of\neach. Our solution builds upon Difference in Differences (DD), an algorithm\nthat eliminates confounding from observational data by comparing outcomes\nbefore and after treatment administration. DD requires a parallel slopes\nassumption that may not apply in practice when confounding shifts across time.\nWe instead propose Synthesized Difference in Differences (SDD) that infers the\ncorrect (possibly non-parallel) slopes by linearly adjusting a conditional\nversion of DD using additional RCT data. The algorithm achieves state of the\nart performance across multiple synthetic and real datasets even when the RCT\nexcludes the majority of patients.",
          "link": "http://arxiv.org/abs/2105.00455",
          "publishedOn": "2021-06-15T01:45:20.310Z",
          "wordCount": 596,
          "title": "Synthesized Difference in Differences. (arXiv:2105.00455v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.12672",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lo_S/0/1/0/all/0/1\">Shaw-Hwa Lo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1\">Yiqiao Yin</a>",
          "description": "In the field of eXplainable AI (XAI), robust ``blackbox'' algorithms such as\nConvolutional Neural Networks (CNNs) are known for making high prediction\nperformance. However, the ability to explain and interpret these algorithms\nstill require innovation in the understanding of influential and, more\nimportantly, explainable features that directly or indirectly impact the\nperformance of predictivity. A number of methods existing in literature focus\non visualization techniques but the concepts of explainability and\ninterpretability still require rigorous definition. In view of the above needs,\nthis paper proposes an interaction-based methodology -- Influence Score\n(I-score) -- to screen out the noisy and non-informative variables in the\nimages hence it nourishes an environment with explainable and interpretable\nfeatures that are directly associated to feature predictivity. We apply the\nproposed method on a real world application in Pneumonia Chest X-ray Image data\nset and produced state-of-the-art results. We demonstrate how to apply the\nproposed approach for more general big data problems by improving the\nexplainability and interpretability without sacrificing the prediction\nperformance. The contribution of this paper opens a novel angle that moves the\ncommunity closer to the future pipelines of XAI problems.",
          "link": "http://arxiv.org/abs/2104.12672",
          "publishedOn": "2021-06-15T01:45:20.304Z",
          "wordCount": 656,
          "title": "A Novel Interaction-based Methodology Towards Explainable AI with Better Understanding of Pneumonia Chest X-ray Images. (arXiv:2104.12672v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.03212",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bodnar_C/0/1/0/all/0/1\">Cristian Bodnar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frasca_F/0/1/0/all/0/1\">Fabrizio Frasca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu Guang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Otter_N/0/1/0/all/0/1\">Nina Otter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Montufar_G/0/1/0/all/0/1\">Guido Mont&#xfa;far</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lio_P/0/1/0/all/0/1\">Pietro Li&#xf2;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bronstein_M/0/1/0/all/0/1\">Michael Bronstein</a>",
          "description": "The pairwise interaction paradigm of graph machine learning has predominantly\ngoverned the modelling of relational systems. However, graphs alone cannot\ncapture the multi-level interactions present in many complex systems and the\nexpressive power of such schemes was proven to be limited. To overcome these\nlimitations, we propose Message Passing Simplicial Networks (MPSNs), a class of\nmodels that perform message passing on simplicial complexes (SCs). To\ntheoretically analyse the expressivity of our model we introduce a Simplicial\nWeisfeiler-Lehman (SWL) colouring procedure for distinguishing non-isomorphic\nSCs. We relate the power of SWL to the problem of distinguishing non-isomorphic\ngraphs and show that SWL and MPSNs are strictly more powerful than the WL test\nand not less powerful than the 3-WL test. We deepen the analysis by comparing\nour model with traditional graph neural networks (GNNs) with ReLU activations\nin terms of the number of linear regions of the functions they can represent.\nWe empirically support our theoretical claims by showing that MPSNs can\ndistinguish challenging strongly regular graphs for which GNNs fail and, when\nequipped with orientation equivariant layers, they can improve classification\naccuracy in oriented SCs compared to a GNN baseline.",
          "link": "http://arxiv.org/abs/2103.03212",
          "publishedOn": "2021-06-15T01:45:20.280Z",
          "wordCount": 669,
          "title": "Weisfeiler and Lehman Go Topological: Message Passing Simplicial Networks. (arXiv:2103.03212v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06991",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_N/0/1/0/all/0/1\">Nianhui Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bethge_J/0/1/0/all/0/1\">Joseph Bethge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Haojin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_K/0/1/0/all/0/1\">Kai Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ning_X/0/1/0/all/0/1\">Xuefei Ning</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meinel_C/0/1/0/all/0/1\">Christoph Meinel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu Wang</a>",
          "description": "Recent works on Binary Neural Networks (BNNs) have made promising progress in\nnarrowing the accuracy gap of BNNs to their 32-bit counterparts. However, the\naccuracy gains are often based on specialized model designs using additional\n32-bit components. Furthermore, almost all previous BNNs use 32-bit for feature\nmaps and the shortcuts enclosing the corresponding binary convolution blocks,\nwhich helps to effectively maintain the accuracy, but is not friendly to\nhardware accelerators with limited memory, energy, and computing resources.\nThus, we raise the following question: How can accuracy and energy consumption\nbe balanced in a BNN network design? We extensively study this fundamental\nproblem in this work and propose a novel BNN architecture without most commonly\nused 32-bit components: \\textit{BoolNet}. Experimental results on ImageNet\ndemonstrate that BoolNet can achieve 4.6x energy reduction coupled with 1.2\\%\nhigher accuracy than the commonly used BNN architecture Bi-RealNet. Code and\ntrained models are available at: https://github.com/hpi-xnor/BoolNet.",
          "link": "http://arxiv.org/abs/2106.06991",
          "publishedOn": "2021-06-15T01:45:20.268Z",
          "wordCount": 588,
          "title": "BoolNet: Minimizing The Energy Consumption of Binary Neural Networks. (arXiv:2106.06991v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2012.01926",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pahar_M/0/1/0/all/0/1\">Madhurananda Pahar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klopper_M/0/1/0/all/0/1\">Marisa Klopper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Warren_R/0/1/0/all/0/1\">Robin Warren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niesler_T/0/1/0/all/0/1\">Thomas Niesler</a>",
          "description": "We present a machine learning based COVID-19 cough classifier which can\ndiscriminate COVID-19 positive coughs from both COVID-19 negative and healthy\ncoughs recorded on a smartphone. This type of screening is non-contact, easy to\napply, and can reduce the workload in testing centres as well as limit\ntransmission by recommending early self-isolation to those who have a cough\nsuggestive of COVID-19. The datasets used in this study include subjects from\nall six continents and contain both forced and natural coughs, indicating that\nthe approach is widely applicable. The publicly available Coswara dataset\ncontains 92 COVID-19 positive and 1079 healthy subjects, while the second\nsmaller dataset was collected mostly in South Africa and contains 18 COVID-19\npositive and 26 COVID-19 negative subjects who have undergone a SARS-CoV\nlaboratory test. Both datasets indicate that COVID-19 positive coughs are\n15\\%-20\\% shorter than non-COVID coughs. Dataset skew was addressed by applying\nthe synthetic minority oversampling technique (SMOTE). A leave-$p$-out\ncross-validation scheme was used to train and evaluate seven machine learning\nclassifiers: LR, KNN, SVM, MLP, CNN, LSTM and Resnet50. Our results show that\nalthough all classifiers were able to identify COVID-19 coughs, the best\nperformance was exhibited by the Resnet50 classifier, which was best able to\ndiscriminate between the COVID-19 positive and the healthy coughs with an area\nunder the ROC curve (AUC) of 0.98. An LSTM classifier was best able to\ndiscriminate between the COVID-19 positive and COVID-19 negative coughs, with\nan AUC of 0.94 after selecting the best 13 features from a sequential forward\nselection (SFS). Since this type of cough audio classification is\ncost-effective and easy to deploy, it is potentially a useful and viable means\nof non-contact COVID-19 screening.",
          "link": "http://arxiv.org/abs/2012.01926",
          "publishedOn": "2021-06-15T01:45:20.262Z",
          "wordCount": 802,
          "title": "COVID-19 Cough Classification using Machine Learning and Global Smartphone Recordings. (arXiv:2012.01926v2 [cs.SD] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2004.00202",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Choi_C/0/1/0/all/0/1\">Chiho Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1\">Joon Hee Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malla_S/0/1/0/all/0/1\">Srikanth Malla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiachen Li</a>",
          "description": "Predicting future trajectories of traffic agents in highly interactive\nenvironments is an essential and challenging problem for the safe operation of\nautonomous driving systems. On the basis of the fact that self-driving vehicles\nare equipped with various types of sensors (e.g., LiDAR scanner, RGB camera,\nradar, etc.), we propose a Cross-Modal Embedding framework that aims to benefit\nfrom the use of multiple input modalities. At training time, our model learns\nto embed a set of complementary features in a shared latent space by jointly\noptimizing the objective functions across different types of input data. At\ntest time, a single input modality (e.g., LiDAR data) is required to generate\npredictions from the input perspective (i.e., in the LiDAR space), while taking\nadvantages from the model trained with multiple sensor modalities. An extensive\nevaluation is conducted to show the efficacy of the proposed framework using\ntwo benchmark driving datasets.",
          "link": "http://arxiv.org/abs/2004.00202",
          "publishedOn": "2021-06-15T01:45:20.237Z",
          "wordCount": 629,
          "title": "Shared Cross-Modal Trajectory Prediction for Autonomous Driving. (arXiv:2004.00202v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2003.03196",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yoon_J/0/1/0/all/0/1\">Jaehong Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeong_W/0/1/0/all/0/1\">Wonyong Jeong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_G/0/1/0/all/0/1\">Giwoong Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_E/0/1/0/all/0/1\">Eunho Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1\">Sung Ju Hwang</a>",
          "description": "There has been a surge of interest in continual learning and federated\nlearning, both of which are important in deep neural networks in real-world\nscenarios. Yet little research has been done regarding the scenario where each\nclient learns on a sequence of tasks from a private local data stream. This\nproblem of federated continual learning poses new challenges to continual\nlearning, such as utilizing knowledge from other clients, while preventing\ninterference from irrelevant knowledge. To resolve these issues, we propose a\nnovel federated continual learning framework, Federated Weighted Inter-client\nTransfer (FedWeIT), which decomposes the network weights into global federated\nparameters and sparse task-specific parameters, and each client receives\nselective knowledge from other clients by taking a weighted combination of\ntheir task-specific parameters. FedWeIT minimizes interference between\nincompatible tasks, and also allows positive knowledge transfer across clients\nduring learning. We validate our FedWeIT against existing federated learning\nand continual learning methods under varying degrees of task similarity across\nclients, and our model significantly outperforms them with a large reduction in\nthe communication cost. Code is available at https://github.com/wyjeong/FedWeIT",
          "link": "http://arxiv.org/abs/2003.03196",
          "publishedOn": "2021-06-15T01:45:20.231Z",
          "wordCount": 668,
          "title": "Federated Continual Learning with Weighted Inter-client Transfer. (arXiv:2003.03196v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06718",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Vago_N/0/1/0/all/0/1\">Nicol&#xf2; Oreste Pinciroli Vago</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Hameed_I/0/1/0/all/0/1\">Ibrahim A. Hameed</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Kachelriess_M/0/1/0/all/0/1\">Michael Kachelriess</a>",
          "description": "The presence of non-zero helicity in intergalactic magnetic fields is a\nsmoking gun for their primordial origin since they have to be generated by\nprocesses that break CP invariance. As an experimental signature for the\npresence of helical magnetic fields, an estimator $Q$ based on the triple\nscalar product of the wave-vectors of photons generated in electromagnetic\ncascades from, e.g., TeV blazars, has been suggested previously. We propose to\napply deep learning to helicity classification employing Convolutional Neural\nNetworks and show that this method outperforms the $Q$ estimator.",
          "link": "http://arxiv.org/abs/2106.06718",
          "publishedOn": "2021-06-15T01:45:20.224Z",
          "wordCount": 567,
          "title": "Using Convolutional Neural Networks for the Helicity Classification of Magnetic Fields. (arXiv:2106.06718v1 [astro-ph.HE])"
        },
        {
          "id": "http://arxiv.org/abs/2103.05331",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kossen_J/0/1/0/all/0/1\">Jannik Kossen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Farquhar_S/0/1/0/all/0/1\">Sebastian Farquhar</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gal_Y/0/1/0/all/0/1\">Yarin Gal</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rainforth_T/0/1/0/all/0/1\">Tom Rainforth</a>",
          "description": "We introduce a new framework for sample-efficient model evaluation that we\ncall active testing. While approaches like active learning reduce the number of\nlabels needed for model training, existing literature largely ignores the cost\nof labeling test data, typically unrealistically assuming large test sets for\nmodel evaluation. This creates a disconnect to real applications, where test\nlabels are important and just as expensive, e.g. for optimizing\nhyperparameters. Active testing addresses this by carefully selecting the test\npoints to label, ensuring model evaluation is sample-efficient. To this end, we\nderive theoretically-grounded and intuitive acquisition strategies that are\nspecifically tailored to the goals of active testing, noting these are distinct\nto those of active learning. As actively selecting labels introduces a bias; we\nfurther show how to remove this bias while reducing the variance of the\nestimator at the same time. Active testing is easy to implement and can be\napplied to any supervised machine learning method. We demonstrate its\neffectiveness on models including WideResNets and Gaussian processes on\ndatasets including Fashion-MNIST and CIFAR-100.",
          "link": "http://arxiv.org/abs/2103.05331",
          "publishedOn": "2021-06-15T01:45:20.216Z",
          "wordCount": 623,
          "title": "Active Testing: Sample-Efficient Model Evaluation. (arXiv:2103.05331v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.08554",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Katiyar_A/0/1/0/all/0/1\">Ashish Katiyar</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Basu_S/0/1/0/all/0/1\">Soumya Basu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shah_V/0/1/0/all/0/1\">Vatsal Shah</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Caramanis_C/0/1/0/all/0/1\">Constantine Caramanis</a>",
          "description": "We study the problem of learning tree-structured Markov random fields (MRF)\non discrete random variables with common support when the observations are\ncorrupted by a $k$-ary symmetric noise channel with unknown probability of\nerror. For Ising models (support size = 2), past work has shown that graph\nstructure can only be recovered up to the leaf clusters (a leaf node, its\nparent, and its siblings form a leaf cluster) and exact recovery is impossible.\nNo prior work has addressed the setting of support size of 3 or more, and\nindeed this setting is far richer. As we show, when the support size is 3 or\nmore, the structure of the leaf clusters may be partially or fully\nidentifiable. We provide a precise characterization of this phenomenon and show\nthat the extent of recoverability is dictated by the joint PMF of the random\nvariables. In particular, we provide necessary and sufficient conditions for\nexact recoverability. Furthermore, we present a polynomial time, sample\nefficient algorithm that recovers the exact tree when this is possible, or up\nto the unidentifiability as promised by our characterization, when full\nrecoverability is impossible. Finally, we demonstrate the efficacy of our\nalgorithm experimentally.",
          "link": "http://arxiv.org/abs/2102.08554",
          "publishedOn": "2021-06-15T01:45:20.198Z",
          "wordCount": 655,
          "title": "Recoverability Landscape of Tree Structured Markov Random Fields under Symmetric Noise. (arXiv:2102.08554v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03207",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chang_J/0/1/0/all/0/1\">Jonathan D. Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uehara_M/0/1/0/all/0/1\">Masatoshi Uehara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sreenivas_D/0/1/0/all/0/1\">Dhruv Sreenivas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kidambi_R/0/1/0/all/0/1\">Rahul Kidambi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1\">Wen Sun</a>",
          "description": "This paper studies offline Imitation Learning (IL) where an agent learns to\nimitate an expert demonstrator without additional online environment\ninteractions. Instead, the learner is presented with a static offline dataset\nof state-action-next state transition triples from a potentially less\nproficient behavior policy. We introduce Model-based IL from Offline data\n(MILO): an algorithmic framework that utilizes the static dataset to solve the\noffline IL problem efficiently both in theory and in practice. In theory, even\nif the behavior policy is highly sub-optimal compared to the expert, we show\nthat as long as the data from the behavior policy provides sufficient coverage\non the expert state-action traces (and with no necessity for a global coverage\nover the entire state-action space), MILO can provably combat the covariate\nshift issue in IL. Complementing our theory results, we also demonstrate that a\npractical implementation of our approach mitigates covariate shift on benchmark\nMuJoCo continuous control tasks. We demonstrate that with behavior policies\nwhose performances are less than half of that of the expert, MILO still\nsuccessfully imitates with an extremely low number of expert state-action pairs\nwhile traditional offline IL method such as behavior cloning (BC) fails\ncompletely. Source code is provided at https://github.com/jdchang1/milo.",
          "link": "http://arxiv.org/abs/2106.03207",
          "publishedOn": "2021-06-15T01:45:20.186Z",
          "wordCount": 666,
          "title": "Mitigating Covariate Shift in Imitation Learning via Offline Data Without Great Coverage. (arXiv:2106.03207v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.04097",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Garriga_Alonso_A/0/1/0/all/0/1\">Adri&#xe0; Garriga-Alonso</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wilk_M/0/1/0/all/0/1\">Mark van der Wilk</a>",
          "description": "Infinite width limits of deep neural networks often have tractable forms.\nThey have been used to analyse the behaviour of finite networks, as well as\nbeing useful methods in their own right. When investigating infinitely wide\nconvolutional neural networks (CNNs), it was observed that the correlations\narising from spatial weight sharing disappear in the infinite limit. This is\nundesirable, as spatial correlation is the main motivation behind CNNs. We show\nthat the loss of this property is not a consequence of the infinite limit, but\nrather of choosing an independent weight prior. Correlating the weights\nmaintains the correlations in the activations. Varying the amount of\ncorrelation interpolates between independent-weight limits and mean-pooling.\nEmpirical evaluation of the infinitely wide network shows that optimal\nperformance is achieved between the extremes, indicating that correlations can\nbe useful.",
          "link": "http://arxiv.org/abs/2101.04097",
          "publishedOn": "2021-06-15T01:45:20.179Z",
          "wordCount": 593,
          "title": "Correlated Weights in Infinite Limits of Deep Convolutional Neural Networks. (arXiv:2101.04097v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.07850",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Corenflos_A/0/1/0/all/0/1\">Adrien Corenflos</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Thornton_J/0/1/0/all/0/1\">James Thornton</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Doucet_A/0/1/0/all/0/1\">Arnaud Doucet</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Deligiannidis_G/0/1/0/all/0/1\">George Deligiannidis</a>",
          "description": "Particle Filtering (PF) methods are an established class of procedures for\nperforming inference in non-linear state-space models. Resampling is a key\ningredient of PF, necessary to obtain low variance likelihood and states\nestimates. However, traditional resampling methods result in PF-based loss\nfunctions being non-differentiable with respect to model and PF parameters. In\na variational inference context, resampling also yields high variance gradient\nestimates of the PF-based evidence lower bound. By leveraging optimal transport\nideas, we introduce a principled differentiable particle filter and provide\nconvergence results. We demonstrate this novel method on a variety of\napplications.",
          "link": "http://arxiv.org/abs/2102.07850",
          "publishedOn": "2021-06-15T01:45:20.173Z",
          "wordCount": 555,
          "title": "Differentiable Particle Filtering via Entropy-Regularized Optimal Transport. (arXiv:2102.07850v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.05632",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ball_P/0/1/0/all/0/1\">Philip J. Ball</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1\">Cong Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parker_Holder_J/0/1/0/all/0/1\">Jack Parker-Holder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roberts_S/0/1/0/all/0/1\">Stephen Roberts</a>",
          "description": "Reinforcement learning from large-scale offline datasets provides us with the\nability to learn policies without potentially unsafe or impractical\nexploration. Significant progress has been made in the past few years in\ndealing with the challenge of correcting for differing behavior between the\ndata collection and learned policies. However, little attention has been paid\nto potentially changing dynamics when transferring a policy to the online\nsetting, where performance can be up to 90% reduced for existing methods. In\nthis paper we address this problem with Augmented World Models (AugWM). We\naugment a learned dynamics model with simple transformations that seek to\ncapture potential changes in physical properties of the robot, leading to more\nrobust policies. We not only train our policy in this new setting, but also\nprovide it with the sampled augmentation as a context, allowing it to adapt to\nchanges in the environment. At test time we learn the context in a\nself-supervised fashion by approximating the augmentation which corresponds to\nthe new environment. We rigorously evaluate our approach on over 100 different\nchanged dynamics settings, and show that this simple approach can significantly\nimprove the zero-shot generalization of a recent state-of-the-art baseline,\noften achieving successful policies where the baseline fails.",
          "link": "http://arxiv.org/abs/2104.05632",
          "publishedOn": "2021-06-15T01:45:20.166Z",
          "wordCount": 682,
          "title": "Augmented World Models Facilitate Zero-Shot Dynamics Generalization From a Single Offline Environment. (arXiv:2104.05632v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06981",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weiss_G/0/1/0/all/0/1\">Gail Weiss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldberg_Y/0/1/0/all/0/1\">Yoav Goldberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yahav_E/0/1/0/all/0/1\">Eran Yahav</a>",
          "description": "What is the computational model behind a Transformer? Where recurrent neural\nnetworks have direct parallels in finite state machines, allowing clear\ndiscussion and thought around architecture variants or trained models,\nTransformers have no such familiar parallel. In this paper we aim to change\nthat, proposing a computational model for the transformer-encoder in the form\nof a programming language. We map the basic components of a transformer-encoder\n-- attention and feed-forward computation -- into simple primitives, around\nwhich we form a programming language: the Restricted Access Sequence Processing\nLanguage (RASP). We show how RASP can be used to program solutions to tasks\nthat could conceivably be learned by a Transformer, and how a Transformer can\nbe trained to mimic a RASP solution. In particular, we provide RASP programs\nfor histograms, sorting, and Dyck-languages. We further use our model to relate\ntheir difficulty in terms of the number of required layers and attention heads:\nanalyzing a RASP program implies a maximum number of heads and layers necessary\nto encode a task in a transformer. Finally, we see how insights gained from our\nabstraction might be used to explain phenomena seen in recent works.",
          "link": "http://arxiv.org/abs/2106.06981",
          "publishedOn": "2021-06-15T01:45:20.150Z",
          "wordCount": 611,
          "title": "Thinking Like Transformers. (arXiv:2106.06981v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.05912",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Nguyen_K/0/1/0/all/0/1\">Khai Nguyen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nguyen_Q/0/1/0/all/0/1\">Quoc Nguyen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ho_N/0/1/0/all/0/1\">Nhat Ho</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pham_T/0/1/0/all/0/1\">Tung Pham</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bui_H/0/1/0/all/0/1\">Hung Bui</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Phung_D/0/1/0/all/0/1\">Dinh Phung</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Le_T/0/1/0/all/0/1\">Trung Le</a>",
          "description": "Mini-batch optimal transport (m-OT) has been successfully used in practical\napplications that involve probability measures with intractable density, or\nprobability measures with a very high number of supports. The m-OT solves\nseveral sparser optimal transport problems and then returns the average of\ntheir costs and transportation plans. Despite its scalability advantage, the\nm-OT does not consider the relationship between mini-batches which leads to\nundesirable estimation. Moreover, the m-OT does not approximate a proper metric\nbetween probability measures since the identity property is not satisfied. To\naddress these problems, we propose a novel mini-batching scheme for optimal\ntransport, named Batch of Mini-batches Optimal Transport (BoMb-OT), that finds\nthe optimal coupling between mini-batches and it can be seen as an\napproximation to a well-defined distance on the space of probability measures.\nFurthermore, we show that the m-OT is a limit of the entropic regularized\nversion of the BoMb-OT when the regularized parameter goes to infinity.\nFinally, we carry out extensive experiments to show that the BoMb-OT can\nestimate a better transportation plan between two original measures than the\nm-OT. It leads to a favorable performance of the BoMb-OT in the matching and\ncolor transfer tasks. Furthermore, we observe that the BoMb-OT also provides a\nbetter objective loss than the m-OT for doing approximate Bayesian computation,\nestimating parameters of interest in parametric generative models, and learning\nnon-parametric generative models with gradient flow.",
          "link": "http://arxiv.org/abs/2102.05912",
          "publishedOn": "2021-06-15T01:45:20.143Z",
          "wordCount": 683,
          "title": "BoMb-OT: On Batch of Mini-batches Optimal Transport. (arXiv:2102.05912v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.01454",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dai_E/0/1/0/all/0/1\">Enyan Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Suhang Wang</a>",
          "description": "Graph neural networks (GNNs) have achieved state-of-the-art performance in\nmodeling graphs. Despite its great success, as with many other models, GNNs\nhave the risk to inherit the bias from the training data. In addition, the bias\nof GNN can be magnified by the graph structures and message-passing mechanism\nof GNNs. The risk of discrimination limits the adoption of GNNs in sensitive\ndomains such as credit score estimation. Though extensive studies of fair\nclassification have been conducted on i.i.d data, methods to address the\nproblem of discrimination on non-i.i.d data are rather limited. Furthermore,\nthe practical scenario of sparse annotations in sensitive attributes is rarely\nconsidered in existing works. Therefore, we study the novel and important\nproblem of learning fair GNNs with limited sensitive information. We propose a\nnovel framework called FairGNN, which is able to reduce the bias of GNNs and\nmaintain high node classification accuracy by leveraging graph structured data\nand sensitive information. Theoretical analysis is conducted to show that\nFairGNN can ensure fairness under mild conditions given limited nodes with\nknown sensitive attributes. Experiments on real-world datasets demonstrated the\neffectiveness of the proposed framework in eliminating discrimination while\nmaintaining high node classification accuracy.",
          "link": "http://arxiv.org/abs/2009.01454",
          "publishedOn": "2021-06-15T01:45:20.100Z",
          "wordCount": 664,
          "title": "Say No to the Discrimination: Learning Fair Graph Neural Networks with Limited Sensitive Attribute Information. (arXiv:2009.01454v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06815",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hanika_T/0/1/0/all/0/1\">Tom Hanika</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hirth_J/0/1/0/all/0/1\">Johannes Hirth</a>",
          "description": "Dimension reduction of data sets is a standard problem in the realm of\nmachine learning and knowledge reasoning. They affect patterns in and\ndependencies on data dimensions and ultimately influence any decision-making\nprocesses. Therefore, a wide variety of reduction procedures are in use, each\npursuing different objectives. A so far not considered criterion is the\nconceptual continuity of the reduction mapping, i.e., the preservation of the\nconceptual structure with respect to the original data set. Based on the notion\nscale-measure from formal concept analysis we present in this work a) the\ntheoretical foundations to detect and quantify conceptual errors in data\nscalings; b) an experimental investigation of our approach on eleven data sets\nthat were respectively treated with a variant of non-negative matrix\nfactorization.",
          "link": "http://arxiv.org/abs/2106.06815",
          "publishedOn": "2021-06-15T01:45:20.083Z",
          "wordCount": 564,
          "title": "Quantifying the Conceptual Error in Dimensionality Reduction. (arXiv:2106.06815v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06860",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fujimoto_S/0/1/0/all/0/1\">Scott Fujimoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_S/0/1/0/all/0/1\">Shixiang Shane Gu</a>",
          "description": "Offline reinforcement learning (RL) defines the task of learning from a fixed\nbatch of data. Due to errors in value estimation from out-of-distribution\nactions, most offline RL algorithms take the approach of constraining or\nregularizing the policy with the actions contained in the dataset. Built on\npre-existing RL algorithms, modifications to make an RL algorithm work offline\ncomes at the cost of additional complexity. Offline RL algorithms introduce new\nhyperparameters and often leverage secondary components such as generative\nmodels, while adjusting the underlying RL algorithm. In this paper we aim to\nmake a deep RL algorithm work while making minimal changes. We find that we can\nmatch the performance of state-of-the-art offline RL algorithms by simply\nadding a behavior cloning term to the policy update of an online RL algorithm\nand normalizing the data. The resulting algorithm is a simple to implement and\ntune baseline, while more than halving the overall run time by removing the\nadditional computational overheads of previous methods.",
          "link": "http://arxiv.org/abs/2106.06860",
          "publishedOn": "2021-06-15T01:45:19.652Z",
          "wordCount": null,
          "title": "A Minimalist Approach to Offline Reinforcement Learning. (arXiv:2106.06860v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.06828",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1\">Xiaoyong Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_Y/0/1/0/all/0/1\">Youngsuk Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maddix_D/0/1/0/all/0/1\">Danielle C. Maddix</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1\">Xifeng Yan</a>",
          "description": "Recent years have witnessed deep neural networks gaining increasing\npopularity in the field of time series forecasting. A primary reason of their\nsuccess is their ability to effectively capture complex temporal dynamics\nacross multiple related time series. However, the advantages of these deep\nforecasters only start to emerge in the presence of a sufficient amount of\ndata. This poses a challenge for typical forecasting problems in practice,\nwhere one either has a small number of time series, or limited observations per\ntime series, or both. To cope with the issue of data scarcity, we propose a\nnovel domain adaptation framework, Domain Adaptation Forecaster (DAF), that\nleverages the statistical strengths from another relevant domain with abundant\ndata samples (source) to improve the performance on the domain of interest with\nlimited data (target). In particular, we propose an attention-based shared\nmodule with a domain discriminator across domains as well as private modules\nfor individual domains. This allows us to jointly train the source and target\ndomains by generating domain-invariant latent features while retraining\ndomain-specific features. Extensive experiments on various domains demonstrate\nthat our proposed method outperforms state-of-the-art baselines on synthetic\nand real-world datasets.",
          "link": "http://arxiv.org/abs/2102.06828",
          "publishedOn": "2021-06-15T01:45:19.649Z",
          "wordCount": null,
          "title": "Domain Adaptation for Time Series Forecasting via Attention Sharing. (arXiv:2102.06828v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.00922",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghiassian_S/0/1/0/all/0/1\">Sina Ghiassian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sutton_R/0/1/0/all/0/1\">Richard S. Sutton</a>",
          "description": "Off-policy prediction -- learning the value function for one policy from data\ngenerated while following another policy -- is one of the most challenging\nsubproblems in reinforcement learning. This paper presents empirical results\nwith eleven prominent off-policy learning algorithms that use linear function\napproximation: five Gradient-TD methods, two Emphatic-TD methods, Off-policy\nTD($\\lambda$), Vtrace, and versions of Tree Backup and ABQ modified to apply to\na prediction setting. Our experiments used the Collision task, a small\nidealized off-policy problem analogous to that of an autonomous car trying to\npredict whether it will collide with an obstacle. We assessed the performance\nof the algorithms according to their learning rate, asymptotic error level, and\nsensitivity to step-size and bootstrapping parameters. By these measures, the\neleven algorithms can be partially ordered on the Collision task. In the top\ntier, the two Emphatic-TD algorithms learned the fastest, reached the lowest\nerrors, and were robust to parameter settings. In the middle tier, the five\nGradient-TD algorithms and Off-policy TD($\\lambda$) were more sensitive to the\nbootstrapping parameter. The bottom tier comprised Vtrace, Tree Backup, and\nABQ; these algorithms were no faster and had higher asymptotic error than the\nothers. Our results are definitive for this task, though of course experiments\nwith more tasks are needed before an overall assessment of the algorithms'\nmerits can be made.",
          "link": "http://arxiv.org/abs/2106.00922",
          "publishedOn": "2021-06-15T01:45:19.632Z",
          "wordCount": null,
          "title": "An Empirical Comparison of Off-policy Prediction Learning Algorithms on the Collision Task. (arXiv:2106.00922v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06969",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yuhang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trigoni_N/0/1/0/all/0/1\">Niki Trigoni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Markham_A/0/1/0/all/0/1\">Andrew Markham</a>",
          "description": "We present a new framework SoundDet, which is an end-to-end trainable and\nlight-weight framework, for polyphonic moving sound event detection and\nlocalization. Prior methods typically approach this problem by preprocessing\nraw waveform into time-frequency representations, which is more amenable to\nprocess with well-established image processing pipelines. Prior methods also\ndetect in segment-wise manner, leading to incomplete and partial detections.\nSoundDet takes a novel approach and directly consumes the raw, multichannel\nwaveform and treats the spatio-temporal sound event as a complete\n``sound-object\" to be detected. Specifically, SoundDet consists of a backbone\nneural network and two parallel heads for temporal detection and spatial\nlocalization, respectively. Given the large sampling rate of raw waveform, the\nbackbone network first learns a set of phase-sensitive and frequency-selective\nbank of filters to explicitly retain direction-of-arrival information, whilst\nbeing highly computationally and parametrically efficient than standard 1D/2D\nconvolution. A dense sound event proposal map is then constructed to handle the\nchallenges of predicting events with large varying temporal duration.\nAccompanying the dense proposal map are a temporal overlapness map and a motion\nsmoothness map that measure a proposal's confidence to be an event from\ntemporal detection accuracy and movement consistency perspective. Involving the\ntwo maps guarantees SoundDet to be trained in a spatio-temporally unified\nmanner. Experimental results on the public DCASE dataset show the advantage of\nSoundDet on both segment-based and our newly proposed event-based evaluation\nsystem.",
          "link": "http://arxiv.org/abs/2106.06969",
          "publishedOn": "2021-06-15T01:45:19.631Z",
          "wordCount": null,
          "title": "SoundDet: Polyphonic Sound Event Detection and Localization from Raw Waveform. (arXiv:2106.06969v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2004.08891",
          "author": "<a href=\"http://arxiv.org/find/q-fin/1/au:+Ruf_J/0/1/0/all/0/1\">Johannes Ruf</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Wang_W/0/1/0/all/0/1\">Weiguan Wang</a>",
          "description": "We study neural networks as nonparametric estimation tools for the hedging of\noptions. To this end, we design a network, named HedgeNet, that directly\noutputs a hedging strategy. This network is trained to minimise the hedging\nerror instead of the pricing error. Applied to end-of-day and tick prices of\nS&P 500 and Euro Stoxx 50 options, the network is able to reduce the mean\nsquared hedging error of the Black-Scholes benchmark significantly. However, a\nsimilar benefit arises by simple linear regressions that incorporate the\nleverage effect.",
          "link": "http://arxiv.org/abs/2004.08891",
          "publishedOn": "2021-06-15T01:45:19.625Z",
          "wordCount": null,
          "title": "Hedging with Linear Regressions and Neural Networks. (arXiv:2004.08891v3 [q-fin.RM] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06805",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Mbuvha_R/0/1/0/all/0/1\">Rendani Mbuvha</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zondo_P/0/1/0/all/0/1\">Patience Zondo</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mauda_A/0/1/0/all/0/1\">Aluwani Mauda</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Marwala_T/0/1/0/all/0/1\">Tshilidzi Marwala</a>",
          "description": "We use gradient boosting machines and logistic regression to predict academic\nthroughput at a South African university. The results highlight the significant\ninfluence of socio-economic factors and field of study as predictors of\nthroughput. We further find that socio-economic factors become less of a\npredictor relative to the field of study as the time to completion increases.\nWe provide recommendations on interventions to counteract the identified\neffects, which include academic, psychosocial and financial support.",
          "link": "http://arxiv.org/abs/2106.06805",
          "publishedOn": "2021-06-15T01:45:19.624Z",
          "wordCount": null,
          "title": "Predicting Higher Education Throughput in South Africa Using a Tree-Based Ensemble Technique. (arXiv:2106.06805v1 [stat.AP])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06830",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1\">Anthony Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gudipati_P/0/1/0/all/0/1\">Pallavi Gudipati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Longpre_S/0/1/0/all/0/1\">Shayne Longpre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_X/0/1/0/all/0/1\">Xiao Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Sameer Singh</a>",
          "description": "Retrieval is a core component for open-domain NLP tasks. In open-domain\ntasks, multiple entities can share a name, making disambiguation an inherent\nyet under-explored problem. We propose an evaluation benchmark for assessing\nthe entity disambiguation capabilities of these retrievers, which we call\nAmbiguous Entity Retrieval (AmbER) sets. We define an AmbER set as a collection\nof entities that share a name along with queries about those entities. By\ncovering the set of entities for polysemous names, AmbER sets act as a\nchallenging test of entity disambiguation. We create AmbER sets for three\npopular open-domain tasks: fact checking, slot filling, and question answering,\nand evaluate a diverse set of retrievers. We find that the retrievers exhibit\npopularity bias, significantly under-performing on rarer entities that share a\nname, e.g., they are twice as likely to retrieve erroneous documents on queries\nfor the less popular entity under the same name. These experiments on AmbER\nsets show their utility as an evaluation tool and highlight the weaknesses of\npopular retrieval systems.",
          "link": "http://arxiv.org/abs/2106.06830",
          "publishedOn": "2021-06-15T01:45:19.623Z",
          "wordCount": null,
          "title": "Evaluating Entity Disambiguation and the Role of Popularity in Retrieval-Based NLP. (arXiv:2106.06830v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2102.03895",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhu_J/0/1/0/all/0/1\">Jiacheng Zhu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Guha_A/0/1/0/all/0/1\">Aritra Guha</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Do_D/0/1/0/all/0/1\">Dat Do</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Xu_M/0/1/0/all/0/1\">Mengdi Xu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nguyen_X/0/1/0/all/0/1\">XuanLong Nguyen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhao_D/0/1/0/all/0/1\">Ding Zhao</a>",
          "description": "We introduce a formulation of optimal transport problem for distributions on\nfunction spaces, where the stochastic map between functional domains can be\npartially represented in terms of an (infinite-dimensional) Hilbert-Schmidt\noperator mapping a Hilbert space of functions to another. For numerous machine\nlearning tasks, data can be naturally viewed as samples drawn from spaces of\nfunctions, such as curves and surfaces, in high dimensions. Optimal transport\nfor functional data analysis provides a useful framework of treatment for such\ndomains. In this work, we develop an efficient algorithm for finding the\nstochastic transport map between functional domains and provide theoretical\nguarantees on the existence, uniqueness, and consistency of our estimate for\nthe Hilbert-Schmidt operator. We validate our method on synthetic datasets and\nstudy the geometric properties of the transport map. Experiments on real-world\ndatasets of robot arm trajectories further demonstrate the effectiveness of our\nmethod on applications in domain adaptation.",
          "link": "http://arxiv.org/abs/2102.03895",
          "publishedOn": "2021-06-15T01:45:19.623Z",
          "wordCount": null,
          "title": "Functional optimal transport: map estimation and domain adaptation for functional data. (arXiv:2102.03895v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1812.03664",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1\">Han-Jia Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Hexiang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_D/0/1/0/all/0/1\">De-Chuan Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sha_F/0/1/0/all/0/1\">Fei Sha</a>",
          "description": "Learning with limited data is a key challenge for visual recognition. Many\nfew-shot learning methods address this challenge by learning an instance\nembedding function from seen classes and apply the function to instances from\nunseen classes with limited labels. This style of transfer learning is\ntask-agnostic: the embedding function is not learned optimally discriminative\nwith respect to the unseen classes, where discerning among them leads to the\ntarget task. In this paper, we propose a novel approach to adapt the instance\nembeddings to the target classification task with a set-to-set function,\nyielding embeddings that are task-specific and are discriminative. We\nempirically investigated various instantiations of such set-to-set functions\nand observed the Transformer is most effective -- as it naturally satisfies key\nproperties of our desired model. We denote this model as FEAT (few-shot\nembedding adaptation w/ Transformer) and validate it on both the standard\nfew-shot classification benchmark and four extended few-shot learning settings\nwith essential use cases, i.e., cross-domain, transductive, generalized\nfew-shot learning, and low-shot learning. It archived consistent improvements\nover baseline models as well as previous methods and established the new\nstate-of-the-art results on two benchmarks.",
          "link": "http://arxiv.org/abs/1812.03664",
          "publishedOn": "2021-06-15T01:45:19.621Z",
          "wordCount": null,
          "title": "Few-Shot Learning via Embedding Adaptation with Set-to-Set Functions. (arXiv:1812.03664v6 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06799",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiang_L/0/1/0/all/0/1\">Lichuan Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dudziak_L/0/1/0/all/0/1\">&#x141;ukasz Dudziak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdelfattah_M/0/1/0/all/0/1\">Mohamed S. Abdelfattah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chau_T/0/1/0/all/0/1\">Thomas Chau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lane_N/0/1/0/all/0/1\">Nicholas D. Lane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_H/0/1/0/all/0/1\">Hongkai Wen</a>",
          "description": "Differentiable neural architecture search (NAS) has attracted significant\nattention in recent years due to its ability to quickly discover promising\narchitectures of deep neural networks even in very large search spaces. Despite\nits success, DARTS lacks robustness in certain cases, e.g. it may degenerate to\ntrivial architectures with excessive parametric-free operations such as skip\nconnection or random noise, leading to inferior performance. In particular,\noperation selection based on the magnitude of architectural parameters was\nrecently proven to be fundamentally wrong showcasing the need to rethink this\naspect. On the other hand, zero-cost proxies have been recently studied in the\ncontext of sample-based NAS showing promising results -- speeding up the search\nprocess drastically in some cases but also failing on some of the large search\nspaces typical for differentiable NAS. In this work we propose a novel\noperation selection paradigm in the context of differentiable NAS which\nutilises zero-cost proxies. Our perturbation-based zero-cost operation\nselection (Zero-Cost-PT) improves searching time and, in many cases, accuracy\ncompared to the best available differentiable architecture search, regardless\nof the search space size. Specifically, we are able to find comparable\narchitectures to DARTS-PT on the DARTS CNN search space while being over 40x\nfaster (total searching time 25 minutes on a single GPU).",
          "link": "http://arxiv.org/abs/2106.06799",
          "publishedOn": "2021-06-15T01:45:19.620Z",
          "wordCount": null,
          "title": "Zero-Cost Proxies Meet Differentiable Architecture Search. (arXiv:2106.06799v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06630",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xuezhou Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yiding Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jerry Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1\">Wen Sun</a>",
          "description": "We study the adversarial robustness in offline reinforcement learning. Given\na batch dataset consisting of tuples $(s, a, r, s')$, an adversary is allowed\nto arbitrarily modify $\\epsilon$ fraction of the tuples. From the corrupted\ndataset the learner aims to robustly identify a near-optimal policy. We first\nshow that a worst-case $\\Omega(d\\epsilon)$ optimality gap is unavoidable in\nlinear MDP of dimension $d$, even if the adversary only corrupts the reward\nelement in a tuple. This contrasts with dimension-free results in robust\nsupervised learning and best-known lower-bound in the online RL setting with\ncorruption. Next, we propose robust variants of the Least-Square Value\nIteration (LSVI) algorithm utilizing robust supervised learning oracles, which\nachieve near-matching performances in cases both with and without full data\ncoverage. The algorithm requires the knowledge of $\\epsilon$ to design the\npessimism bonus in the no-coverage case. Surprisingly, in this case, the\nknowledge of $\\epsilon$ is necessary, as we show that being adaptive to unknown\n$\\epsilon$ is impossible.This again contrasts with recent results on\ncorruption-robust online RL and implies that robust offline RL is a strictly\nharder problem.",
          "link": "http://arxiv.org/abs/2106.06630",
          "publishedOn": "2021-06-15T01:45:19.619Z",
          "wordCount": null,
          "title": "Corruption-Robust Offline Reinforcement Learning. (arXiv:2106.06630v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00305",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ruis_F/0/1/0/all/0/1\">Frank Ruis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burghouts_G/0/1/0/all/0/1\">Gertjan Burghouts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bucur_D/0/1/0/all/0/1\">Doina Bucur</a>",
          "description": "Humans are good at compositional zero-shot reasoning; someone who has never\nseen a zebra before could nevertheless recognize one when we tell them it looks\nlike a horse with black and white stripes. Machine learning systems, on the\nother hand, usually leverage spurious correlations in the training data, and\nwhile such correlations can help recognize objects in context, they hurt\ngeneralization. To be able to deal with underspecified datasets while still\nleveraging contextual clues during classification, we propose ProtoProp, a\nnovel prototype propagation graph method. First we learn prototypical\nrepresentations of objects (e.g., zebra) that are conditionally independent\nw.r.t. their attribute labels (e.g., stripes) and vice versa. Next we propagate\nthe independent prototypes through a compositional graph, to learn\ncompositional prototypes of novel attribute-object combinations that reflect\nthe dependencies of the target distribution. The method does not rely on any\nexternal data, such as class hierarchy graphs or pretrained word embeddings. We\nevaluate our approach on AO-Clever, a synthetic and strongly visual dataset\nwith clean labels, and UT-Zappos, a noisy real-world dataset of fine-grained\nshoe types. We show that in the generalized compositional zero-shot setting we\noutperform state-of-the-art results, and through ablations we show the\nimportance of each part of the method and their contribution to the final\nresults.",
          "link": "http://arxiv.org/abs/2106.00305",
          "publishedOn": "2021-06-15T01:45:19.618Z",
          "wordCount": null,
          "title": "Independent Prototype Propagation for Zero-Shot Compositionality. (arXiv:2106.00305v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06666",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiying Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuzhao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1\">Xi Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_R/0/1/0/all/0/1\">Runiu Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_S/0/1/0/all/0/1\">Shu-Tao Xia</a>",
          "description": "HyperGraph Convolutional Neural Networks (HGCNNs) have demonstrated their\npotential in modeling high-order relations preserved in graph structured data.\nHowever, most existing convolution filters are localized and determined by the\npre-defined initial hypergraph topology, neglecting to explore implicit and\nlong-ange relations in real-world data. In this paper, we propose the first\nlearning-based method tailored for constructing adaptive hypergraph structure,\ntermed HypERgrAph Laplacian aDaptor (HERALD), which serves as a generic\nplug-in-play module for improving the representational power of HGCNNs.\nSpecifically, HERALD adaptively optimizes the adjacency relationship between\nhypernodes and hyperedges in an end-to-end manner and thus the task-aware\nhypergraph is learned. Furthermore, HERALD employs the self-attention mechanism\nto capture the non-local paired-nodes relation. Extensive experiments on\nvarious popular hypergraph datasets for node classification and graph\nclassification tasks demonstrate that our approach obtains consistent and\nconsiderable performance enhancement, proving its effectiveness and\ngeneralization ability.",
          "link": "http://arxiv.org/abs/2106.06666",
          "publishedOn": "2021-06-15T01:45:19.614Z",
          "wordCount": null,
          "title": "Learnable Hypergraph Laplacian for Hypergraph Learning. (arXiv:2106.06666v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06854",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fujimoto_S/0/1/0/all/0/1\">Scott Fujimoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meger_D/0/1/0/all/0/1\">David Meger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Precup_D/0/1/0/all/0/1\">Doina Precup</a>",
          "description": "Marginalized importance sampling (MIS), which measures the density ratio\nbetween the state-action occupancy of a target policy and that of a sampling\ndistribution, is a promising approach for off-policy evaluation. However,\ncurrent state-of-the-art MIS methods rely on complex optimization tricks and\nsucceed mostly on simple toy problems. We bridge the gap between MIS and deep\nreinforcement learning by observing that the density ratio can be computed from\nthe successor representation of the target policy. The successor representation\ncan be trained through deep reinforcement learning methodology and decouples\nthe reward optimization from the dynamics of the environment, making the\nresulting algorithm stable and applicable to high-dimensional domains. We\nevaluate the empirical performance of our approach on a variety of challenging\nAtari and MuJoCo environments.",
          "link": "http://arxiv.org/abs/2106.06854",
          "publishedOn": "2021-06-15T01:45:19.610Z",
          "wordCount": null,
          "title": "A Deep Reinforcement Learning Approach to Marginalized Importance Sampling with the Successor Representation. (arXiv:2106.06854v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.09768",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Honghua Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Juba_B/0/1/0/all/0/1\">Brendan Juba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Broeck_G/0/1/0/all/0/1\">Guy Van den Broeck</a>",
          "description": "Generating functions, which are widely used in combinatorics and probability\ntheory, encode function values into the coefficients of a polynomial. In this\npaper, we explore their use as a tractable probabilistic model, and propose\nprobabilistic generating circuits (PGCs) for their efficient representation.\nPGCs are strictly more expressive efficient than many existing tractable\nprobabilistic models, including determinantal point processes (DPPs),\nprobabilistic circuits (PCs) such as sum-product networks, and tractable\ngraphical models. We contend that PGCs are not just a theoretical framework\nthat unifies vastly different existing models, but also show great potential in\nmodeling realistic data. We exhibit a simple class of PGCs that are not\ntrivially subsumed by simple combinations of PCs and DPPs, and obtain\ncompetitive performance on a suite of density estimation benchmarks. We also\nhighlight PGCs' connection to the theory of strongly Rayleigh distributions.",
          "link": "http://arxiv.org/abs/2102.09768",
          "publishedOn": "2021-06-15T01:45:19.607Z",
          "wordCount": null,
          "title": "Probabilistic Generating Circuits. (arXiv:2102.09768v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.10255",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1\">Zuoyu Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1\">Tengfei Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1\">Liangcai Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1\">Zhi Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chao Chen</a>",
          "description": "Link prediction is an important learning task for graph-structured data. In\nthis paper, we propose a novel topological approach to characterize\ninteractions between two nodes. Our topological feature, based on the extended\npersistent homology, encodes rich structural information regarding the\nmulti-hop paths connecting nodes. Based on this feature, we propose a graph\nneural network method that outperforms state-of-the-arts on different\nbenchmarks. As another contribution, we propose a novel algorithm to more\nefficiently compute the extended persistence diagrams for graphs. This\nalgorithm can be generally applied to accelerate many other topological methods\nfor graph learning tasks.",
          "link": "http://arxiv.org/abs/2102.10255",
          "publishedOn": "2021-06-15T01:45:19.601Z",
          "wordCount": null,
          "title": "Link Prediction with Persistent Homology: An Interactive View. (arXiv:2102.10255v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06882",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vedder_K/0/1/0/all/0/1\">Kyle Vedder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eaton_E/0/1/0/all/0/1\">Eric Eaton</a>",
          "description": "Bird's Eye View (BEV) is a popular representation for processing 3D point\nclouds, and by its nature is fundamentally sparse. Motivated by the\ncomputational limitations of mobile robot platforms, we take a fast\nhigh-performance BEV 3D object detector - PointPillars - and modify its\nbackbone to exploit this sparsity, leading to decreased runtimes. We present\npreliminary results demonstrating decreased runtimes with either the same\nperformance or a modest decrease in performance, which we anticipate will be\nremedied by model specific hyperparameter tuning. Our work is a first step\ntowards a new class of 3D object detectors that exploit sparsity throughout\ntheir entire pipeline in order to reduce runtime and resource usage while\nmaintaining good detection performance.",
          "link": "http://arxiv.org/abs/2106.06882",
          "publishedOn": "2021-06-15T01:45:19.600Z",
          "wordCount": null,
          "title": "Sparse PointPillars: Exploiting Sparsity in Birds-Eye-View Object Detection. (arXiv:2106.06882v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06712",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haike Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jian Li</a>",
          "description": "We consider the stochastic combinatorial semi-bandit problem with adversarial\ncorruptions. We provide a simple combinatorial algorithm that can achieve a\nregret of $\\tilde{O}\\left(C+d^2K/\\Delta_{min}\\right)$ where $C$ is the total\namount of corruptions, $d$ is the maximal number of arms one can play in each\nround, $K$ is the number of arms. If one selects only one arm in each round, we\nachieves a regret of $\\tilde{O}\\left(C+\\sum_{\\Delta_i>0}(1/\\Delta_i)\\right)$.\nOur algorithm is combinatorial and improves on the previous combinatorial\nalgorithm by [Gupta et al., COLT2019] (their bound is\n$\\tilde{O}\\left(KC+\\sum_{\\Delta_i>0}(1/\\Delta_i)\\right)$), and almost matches\nthe best known bounds obtained by [Zimmert et al., ICML2019] and [Zimmert and\nSeldin, AISTATS2019] (up to logarithmic factor). Note that the algorithms in\n[Zimmert et al., ICML2019] and [Zimmert and Seldin, AISTATS2019] require one to\nsolve complex convex programs while our algorithm is combinatorial, very easy\nto implement, requires weaker assumptions and has very low oracle complexity\nand running time. We also study the setting where we only get access to an\napproximation oracle for the stochastic combinatorial semi-bandit problem. Our\nalgorithm achieves an (approximation) regret bound of\n$\\tilde{O}\\left(d\\sqrt{KT}\\right)$. Our algorithm is very simple, only worse\nthan the best known regret bound by $\\sqrt{d}$, and has much lower oracle\ncomplexity than previous work.",
          "link": "http://arxiv.org/abs/2106.06712",
          "publishedOn": "2021-06-15T01:45:19.599Z",
          "wordCount": null,
          "title": "Simple Combinatorial Algorithms for Combinatorial Bandits: Corruptions and Approximations. (arXiv:2106.06712v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06577",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1\">Yonggan Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chaojian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhongzhi Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yingyan Lin</a>",
          "description": "Driven by the explosive interest in applying deep reinforcement learning\n(DRL) agents to numerous real-time control and decision-making applications,\nthere has been a growing demand to deploy DRL agents to empower daily-life\nintelligent devices, while the prohibitive complexity of DRL stands at odds\nwith limited on-device resources. In this work, we propose an Automated Agent\nAccelerator Co-Search (A3C-S) framework, which to our best knowledge is the\nfirst to automatically co-search the optimally matched DRL agents and\naccelerators that maximize both test scores and hardware efficiency. Extensive\nexperiments consistently validate the superiority of our A3C-S over\nstate-of-the-art techniques.",
          "link": "http://arxiv.org/abs/2106.06577",
          "publishedOn": "2021-06-15T01:45:19.597Z",
          "wordCount": null,
          "title": "A3C-S: Automated Agent Accelerator Co-Search towards Efficient Deep Reinforcement Learning. (arXiv:2106.06577v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06620",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Taghanaki_S/0/1/0/all/0/1\">Saeid Asgari Taghanaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_K/0/1/0/all/0/1\">Kristy Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khasahmadi_A/0/1/0/all/0/1\">Amir Khasahmadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_A/0/1/0/all/0/1\">Anirudh Goyal</a>",
          "description": "A fundamental challenge in artificial intelligence is learning useful\nrepresentations of data that yield good performance on a downstream task,\nwithout overfitting to spurious input features. Extracting such task-relevant\npredictive information is particularly difficult for real-world datasets. In\nthis work, we propose Contrastive Input Morphing (CIM), a representation\nlearning framework that learns input-space transformations of the data to\nmitigate the effect of irrelevant input features on downstream performance. Our\nmethod leverages a perceptual similarity metric via a triplet loss to ensure\nthat the transformation preserves task-relevant information.Empirically, we\ndemonstrate the efficacy of our approach on tasks which typically suffer from\nthe presence of spurious correlations: classification with nuisance\ninformation, out-of-distribution generalization, and preservation of subgroup\naccuracies. We additionally show that CIM is complementary to other mutual\ninformation-based representation learning techniques, and demonstrate that it\nimproves the performance of variational information bottleneck (VIB) when used\ntogether.",
          "link": "http://arxiv.org/abs/2106.06620",
          "publishedOn": "2021-06-15T01:45:19.595Z",
          "wordCount": null,
          "title": "Robust Representation Learning via Perceptual Similarity Metrics. (arXiv:2106.06620v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.06961",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_A/0/1/0/all/0/1\">Anish Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alomar_A/0/1/0/all/0/1\">Abdullah Alomar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alumootil_V/0/1/0/all/0/1\">Varkey Alumootil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_D/0/1/0/all/0/1\">Devavrat Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_D/0/1/0/all/0/1\">Dennis Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zhi Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Cindy Yang</a>",
          "description": "We consider offline reinforcement learning (RL) with heterogeneous agents\nunder severe data scarcity, i.e., we only observe a single historical\ntrajectory for every agent under an unknown, potentially sub-optimal policy. We\nfind that the performance of state-of-the-art offline and model-based RL\nmethods degrade significantly given such limited data availability, even for\ncommonly perceived \"solved\" benchmark settings such as \"MountainCar\" and\n\"CartPole\". To address this challenge, we propose PerSim, a model-based offline\nRL approach which first learns a personalized simulator for each agent by\ncollectively using the historical trajectories across all agents, prior to\nlearning a policy. We do so by positing that the transition dynamics across\nagents can be represented as a latent function of latent factors associated\nwith agents, states, and actions; subsequently, we theoretically establish that\nthis function is well-approximated by a \"low-rank\" decomposition of separable\nagent, state, and action latent functions. This representation suggests a\nsimple, regularized neural network architecture to effectively learn the\ntransition dynamics per agent, even with scarce, offline data. We perform\nextensive experiments across several benchmark environments and RL methods. The\nconsistent improvement of our approach, measured in terms of both state\ndynamics prediction and eventual reward, confirms the efficacy of our framework\nin leveraging limited historical data to simultaneously learn personalized\npolicies across agents.",
          "link": "http://arxiv.org/abs/2102.06961",
          "publishedOn": "2021-06-15T01:45:19.590Z",
          "wordCount": null,
          "title": "PerSim: Data-Efficient Offline Reinforcement Learning with Heterogeneous Agents via Personalized Simulators. (arXiv:2102.06961v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06935",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1\">Zhaocheng Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zuobai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xhonneux_L/0/1/0/all/0/1\">Louis-Pascal Xhonneux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jian Tang</a>",
          "description": "Link prediction is a very fundamental task on graphs. Inspired by traditional\npath-based methods, in this paper we propose a general and flexible\nrepresentation learning framework based on paths for link prediction.\nSpecifically, we define the representation of a pair of nodes as the\ngeneralized sum of all path representations, with each path representation as\nthe generalized product of the edge representations in the path. Motivated by\nthe Bellman-Ford algorithm for solving the shortest path problem, we show that\nthe proposed path formulation can be efficiently solved by the generalized\nBellman-Ford algorithm. To further improve the capacity of the path\nformulation, we propose the Neural Bellman-Ford Network (NBFNet), a general\ngraph neural network framework that solves the path formulation with learned\noperators in the generalized Bellman-Ford algorithm. The NBFNet parameterizes\nthe generalized Bellman-Ford algorithm with 3 neural components, namely\nINDICATOR, MESSAGE and AGGREGATE functions, which corresponds to the boundary\ncondition, multiplication operator, and summation operator respectively. The\nNBFNet is very general, covers many traditional path-based methods, and can be\napplied to both homogeneous graphs and multi-relational graphs (e.g., knowledge\ngraphs) in both transductive and inductive settings. Experiments on both\nhomogeneous graphs and knowledge graphs show that the proposed NBFNet\noutperforms existing methods by a large margin in both transductive and\ninductive settings, achieving new state-of-the-art results.",
          "link": "http://arxiv.org/abs/2106.06935",
          "publishedOn": "2021-06-15T01:45:19.585Z",
          "wordCount": null,
          "title": "Neural Bellman-Ford Networks: A General Graph Neural Network Framework for Link Prediction. (arXiv:2106.06935v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2002.00526",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yang Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_W/0/1/0/all/0/1\">Wenbo Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_X/0/1/0/all/0/1\">Xinyu Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noble_W/0/1/0/all/0/1\">William Stafford Noble</a>",
          "description": "Saliency methods can make deep neural network predictions more interpretable\nby identifying a set of critical features in an input sample, such as pixels\nthat contribute most strongly to a prediction made by an image classifier.\nUnfortunately, recent evidence suggests that many saliency methods poorly\nperform, especially in situations where gradients are saturated, inputs contain\nadversarial perturbations, or predictions rely upon inter-feature dependence.\nTo address these issues, we propose a framework that improves the robustness of\nsaliency methods by following a two-step procedure. First, we introduce a\nperturbation mechanism that subtly varies the input sample without changing its\nintermediate representations. Using this approach, we can gather a corpus of\nperturbed data samples while ensuring that the perturbed and original input\nsamples follow the same distribution. Second, we compute saliency maps for the\nperturbed samples and propose a new method to aggregate saliency maps. With\nthis design, we offset the gradient saturation influence upon interpretation.\nFrom a theoretical perspective, we show the aggregated saliency map could not\nonly capture inter-feature dependence but, more importantly, robustify\ninterpretation against previously described adversarial perturbation methods.\nFollowing our theoretical analysis, we present experimental results suggesting\nthat, both qualitatively and quantitatively, our saliency method outperforms\nexisting methods.",
          "link": "http://arxiv.org/abs/2002.00526",
          "publishedOn": "2021-06-15T01:45:19.581Z",
          "wordCount": 666,
          "title": "DANCE: Enhancing saliency maps using decoys. (arXiv:2002.00526v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06765",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abaimov_S/0/1/0/all/0/1\">Stanislav Abaimov</a>",
          "description": "Data Distribution Service (DDS) is an innovative approach towards\ncommunication in ICS/IoT infrastructure and robotics. Being based on the\ncross-platform and cross-language API to be applicable in any computerised\ndevice, it offers the benefits of modern programming languages and the\nopportunities to develop more complex and advanced systems. However, the DDS\ncomplexity equally increases its vulnerability, while the existing security\nmeasures are limited to plug-ins and static rules, with the rest of the\nsecurity provided by third-party applications and operating system.\nSpecifically, traditional intrusion detection systems (IDS) do not detect any\nanomalies in the publish/subscribe method. With the exponentially growing\nglobal communication exchange, securing DDS is of the utmost importance to\nfutureproofing industrial, public, and even personal devices and systems. This\nreport presents an experimental work on the simulation of several specific\nattacks against DDS, and the application of Deep Learning for their detection.\nThe findings show that even though Deep Learning allows to detect all simulated\nattacks using only metadata analysis, their detection level varies, with some\nof the advanced attacks being harder to detect. The limitations imposed by the\nattempts to preserve privacy significantly decrease the detection rate. The\nreport also reviews the drawbacks and limitations of the Deep Learning approach\nand proposes a set of selected solutions and configurations, that can further\nimprove the DDS security.",
          "link": "http://arxiv.org/abs/2106.06765",
          "publishedOn": "2021-06-15T01:45:19.564Z",
          "wordCount": 648,
          "title": "Towards a Privacy-preserving Deep Learning-based Network Intrusion Detection in Data Distribution Services. (arXiv:2106.06765v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.05858",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1\">Chung-Wei Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1\">Haipeng Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1\">Chen-Yu Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mengxiao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaojin Zhang</a>",
          "description": "In this work, we develop linear bandit algorithms that automatically adapt to\ndifferent environments. By plugging a novel loss estimator into the\noptimization problem that characterizes the instance-optimal strategy, our\nfirst algorithm not only achieves nearly instance-optimal regret in stochastic\nenvironments, but also works in corrupted environments with additional regret\nbeing the amount of corruption, while the state-of-the-art (Li et al., 2019)\nachieves neither instance-optimality nor the optimal dependence on the\ncorruption amount. Moreover, by equipping this algorithm with an adversarial\ncomponent and carefully-designed testings, our second algorithm additionally\nenjoys minimax-optimal regret in completely adversarial environments, which is\nthe first of this kind to our knowledge. Finally, all our guarantees hold with\nhigh probability, while existing instance-optimal guarantees only hold in\nexpectation.",
          "link": "http://arxiv.org/abs/2102.05858",
          "publishedOn": "2021-06-15T01:45:19.554Z",
          "wordCount": 595,
          "title": "Achieving Near Instance-Optimality and Minimax-Optimality in Stochastic and Adversarial Linear Bandits Simultaneously. (arXiv:2102.05858v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.08266",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aggarwal_A/0/1/0/all/0/1\">Abhinav Aggarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kasiviswanathan_S/0/1/0/all/0/1\">Shiva Prasad Kasiviswanathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zekun Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feyisetan_O/0/1/0/all/0/1\">Oluwaseyi Feyisetan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teissier_N/0/1/0/all/0/1\">Nathanael Teissier</a>",
          "description": "Log-loss (also known as cross-entropy loss) metric is ubiquitously used\nacross machine learning applications to assess the performance of\nclassification algorithms. In this paper, we investigate the problem of\ninferring the labels of a dataset from single (or multiple) log-loss score(s),\nwithout any other access to the dataset. Surprisingly, we show that for any\nfinite number of label classes, it is possible to accurately infer the labels\nof the dataset from the reported log-loss score of a single carefully\nconstructed prediction vector if we allow arbitrary precision arithmetic.\nAdditionally, we present label inference algorithms (attacks) that succeed even\nunder addition of noise to the log-loss scores and under limited precision\narithmetic. All our algorithms rely on ideas from number theory and\ncombinatorics and require no model training. We run experimental simulations on\nsome real datasets to demonstrate the ease of running these attacks in\npractice.",
          "link": "http://arxiv.org/abs/2105.08266",
          "publishedOn": "2021-06-15T01:45:19.545Z",
          "wordCount": 602,
          "title": "Label Inference Attacks from Log-loss Scores. (arXiv:2105.08266v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2003.06601",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Takahashi_T/0/1/0/all/0/1\">Tomoei Takahashi</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Chikenji_G/0/1/0/all/0/1\">George Chikenji</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Tokita_K/0/1/0/all/0/1\">Kei Tokita</a>",
          "description": "Protein design is the inverse approach of the three-dimensional (3D)\nstructure prediction for elucidating the relationship between the 3D structures\nand amino acid sequences. In general, the computation of the protein design\ninvolves a double loop: a loop for amino acid sequence changes and a loop for\nan exhaustive conformational search for each amino acid sequence. Herein, we\npropose a novel statistical mechanical design method using Bayesian learning,\nwhich can design lattice proteins without the exhaustive conformational search.\nWe consider a thermodynamic hypothesis of the evolution of proteins and apply\nit to the prior distribution of amino acid sequences. Furthermore, we take the\nwater effect into account in view of the grand canonical picture. As a result,\non applying the 2D lattice hydrophobic-polar (HP) model, our design method\nsuccessfully finds an amino acid sequence for which the target conformation has\na unique ground state. However, the performance was not as good for the 3D\nlattice HP models compared to the 2D models. The performance of the 3D model\nimproves on using a 20-letter lattice proteins. Furthermore, we find a strong\nlinearity between the chemical potential of water and the number of surface\nresidues, thereby revealing the relationship between protein structure and the\neffect of water molecules. The advantage of our method is that it greatly\nreduces computation time, because it does not require long calculations for the\npartition function corresponding to an exhaustive conformational search. As our\nmethod uses a general form of Bayesian learning and statistical mechanics and\nis not limited to lattice proteins, the results presented here elucidate some\nheuristics used successfully in previous protein design methods.",
          "link": "http://arxiv.org/abs/2003.06601",
          "publishedOn": "2021-06-15T01:45:19.534Z",
          "wordCount": 748,
          "title": "Lattice protein design using Bayesian learning. (arXiv:2003.06601v5 [physics.bio-ph] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06868",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hoyos_Gomez_L/0/1/0/all/0/1\">Laura S. Hoyos-G&#xf3;mez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruiz_Munoz_J/0/1/0/all/0/1\">Jose F. Ruiz-Mu&#xf1;oz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruiz_Mendoza_B/0/1/0/all/0/1\">Belizza J. Ruiz-Mendoza</a>",
          "description": "Accurate mechanisms for forecasting solar irradiance and insolation provide\nimportant information for the planning of renewable energy and agriculture\nprojects as well as for environmental and socio-economical studies. This\nresearch introduces a pipeline for the one-day ahead forecasting of solar\nirradiance and insolation that only requires solar irradiance historical data\nfor training. Furthermore, our approach is able to deal with missing data since\nit includes a data imputation state. In the prediction stage, we consider four\ndata-driven approaches: Autoregressive Integrated Moving Average (ARIMA),\nSingle Layer Feed Forward Network (SL-FNN), Multiple Layer Feed Forward Network\n(FL-FNN), and Long Short-Term Memory (LSTM). The experiments are performed in a\nreal-world dataset collected with 12 Automatic Weather Stations (AWS) located\nin the Nari\\~no - Colombia. The results show that the neural network-based\nmodels outperform ARIMA in most cases. Furthermore, LSTM exhibits better\nperformance in cloudy environments (where more randomness is expected).",
          "link": "http://arxiv.org/abs/2106.06868",
          "publishedOn": "2021-06-15T01:45:19.498Z",
          "wordCount": 578,
          "title": "Short-term forecasting of global solar irradiance with incomplete data. (arXiv:2106.06868v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2008.05221",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_M/0/1/0/all/0/1\">Manish Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_P/0/1/0/all/0/1\">Puneet Agrawal</a>",
          "description": "In recent years, the fields of natural language processing (NLP) and\ninformation retrieval (IR) have made tremendous progress thanksto deep learning\nmodels like Recurrent Neural Networks (RNNs), Gated Recurrent Units (GRUs) and\nLong Short-Term Memory (LSTMs)networks, and Transformer [120] based models like\nBidirectional Encoder Representations from Transformers (BERT) [24],\nGenerativePre-training Transformer (GPT-2) [94], Multi-task Deep Neural Network\n(MT-DNN) [73], Extra-Long Network (XLNet) [134], Text-to-text transfer\ntransformer (T5) [95], T-NLG [98] and GShard [63]. But these models are\nhumongous in size. On the other hand,real world applications demand small model\nsize, low response times and low computational power wattage. In this survey,\nwediscuss six different types of methods (Pruning, Quantization, Knowledge\nDistillation, Parameter Sharing, Tensor Decomposition, andSub-quadratic\nTransformer based methods) for compression of such models to enable their\ndeployment in real industry NLP projects.Given the critical need of building\napplications with efficient and small models, and the large amount of recently\npublished work inthis area, we believe that this survey organizes the plethora\nof work done by the 'deep learning for NLP' community in the past fewyears and\npresents it as a coherent story.",
          "link": "http://arxiv.org/abs/2008.05221",
          "publishedOn": "2021-06-15T01:45:19.480Z",
          "wordCount": 675,
          "title": "Compression of Deep Learning Models for Text: A Survey. (arXiv:2008.05221v4 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.05185",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ross_A/0/1/0/all/0/1\">Andrew Slavin Ross</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doshi_Velez_F/0/1/0/all/0/1\">Finale Doshi-Velez</a>",
          "description": "In representation learning, there has been recent interest in developing\nalgorithms to disentangle the ground-truth generative factors behind a dataset,\nand metrics to quantify how fully this occurs. However, these algorithms and\nmetrics often assume that both representations and ground-truth factors are\nflat, continuous, and factorized, whereas many real-world generative processes\ninvolve rich hierarchical structure, mixtures of discrete and continuous\nvariables with dependence between them, and even varying intrinsic\ndimensionality. In this work, we develop benchmarks, algorithms, and metrics\nfor learning such hierarchical representations.",
          "link": "http://arxiv.org/abs/2102.05185",
          "publishedOn": "2021-06-15T01:45:19.464Z",
          "wordCount": null,
          "title": "Benchmarks, Algorithms, and Metrics for Hierarchical Disentanglement. (arXiv:2102.05185v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06586",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Suresh_S/0/1/0/all/0/1\">Susheel Suresh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Budde_V/0/1/0/all/0/1\">Vinith Budde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neville_J/0/1/0/all/0/1\">Jennifer Neville</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Pan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jianzhu Ma</a>",
          "description": "Graph neural networks (GNNs) have achieved tremendous success on multiple\ngraph-based learning tasks by fusing network structure and node features.\nModern GNN models are built upon iterative aggregation of neighbor's/proximity\nfeatures by message passing. Its prediction performance has been shown to be\nstrongly bounded by assortative mixing in the graph, a key property wherein\nnodes with similar attributes mix/connect with each other. We observe that real\nworld networks exhibit heterogeneous or diverse mixing patterns and the\nconventional global measurement of assortativity, such as global assortativity\ncoefficient, may not be a representative statistic in quantifying this mixing.\nWe adopt a generalized concept, node-level assortativity, one that is based at\nthe node level to better represent the diverse patterns and accurately quantify\nthe learnability of GNNs. We find that the prediction performance of a wide\nrange of GNN models is highly correlated with the node level assortativity. To\nbreak this limit, in this work, we focus on transforming the input graph into a\ncomputation graph which contains both proximity and structural information as\ndistinct type of edges. The resulted multi-relational graph has an enhanced\nlevel of assortativity and, more importantly, preserves rich information from\nthe original graph. We then propose to run GNNs on this computation graph and\nshow that adaptively choosing between structure and proximity leads to improved\nperformance under diverse mixing. Empirically, we show the benefits of adopting\nour transformation framework for semi-supervised node classification task on a\nvariety of real world graph learning benchmarks.",
          "link": "http://arxiv.org/abs/2106.06586",
          "publishedOn": "2021-06-15T01:45:19.461Z",
          "wordCount": null,
          "title": "Breaking the Limit of Graph Neural Networks by Improving the Assortativity of Graphs with Local Mixing Patterns. (arXiv:2106.06586v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.11367",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lai_F/0/1/0/all/0/1\">Fan Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_Y/0/1/0/all/0/1\">Yinwei Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiangfeng Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chowdhury_M/0/1/0/all/0/1\">Mosharaf Chowdhury</a>",
          "description": "We present FedScale, a diverse set of challenging and realistic benchmark\ndatasets to facilitate scalable, comprehensive, and reproducible federated\nlearning (FL) research. FedScale datasets are large-scale, encompassing a\ndiverse range of important FL tasks, such as image classification, object\ndetection, language modeling, speech recognition, and reinforcement learning.\nFor each dataset, we provide a unified evaluation protocol using realistic data\nsplits and evaluation metrics. To meet the pressing need for reproducing\nrealistic FL at scale, we have also built an efficient evaluation platform to\nsimplify and standardize the process of FL experimental setup and model\nevaluation. Our evaluation platform provides flexible APIs to implement new FL\nalgorithms and includes new execution backends with minimal developer efforts.\nFinally, we perform indepth benchmark experiments on these datasets. Our\nexperiments suggest fruitful opportunities in heterogeneity-aware\nco-optimizations of the system and statistical efficiency under realistic FL\ncharacteristics. FedScale is open-source with permissive licenses and actively\nmaintained,1 and we welcome feedback and contributions from the community.",
          "link": "http://arxiv.org/abs/2105.11367",
          "publishedOn": "2021-06-15T01:45:19.459Z",
          "wordCount": null,
          "title": "FedScale: Benchmarking Model and System Performance of Federated Learning. (arXiv:2105.11367v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.07003",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1\">Gyuwan Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1\">Kyunghyun Cho</a>",
          "description": "Despite transformers' impressive accuracy, their computational cost is often\nprohibitive to use with limited computational resources. Most previous\napproaches to improve inference efficiency require a separate model for each\npossible computational budget. In this paper, we extend PoWER-BERT (Goyal et\nal., 2020) and propose Length-Adaptive Transformer that can be used for various\ninference scenarios after one-shot training. We train a transformer with\nLengthDrop, a structural variant of dropout, which stochastically determines a\nsequence length at each layer. We then conduct a multi-objective evolutionary\nsearch to find a length configuration that maximizes the accuracy and minimizes\nthe efficiency metric under any given computational budget. Additionally, we\nsignificantly extend the applicability of PoWER-BERT beyond sequence-level\nclassification into token-level classification with Drop-and-Restore process\nthat drops word-vectors temporarily in intermediate layers and restores at the\nlast layer if necessary. We empirically verify the utility of the proposed\napproach by demonstrating the superior accuracy-efficiency trade-off under\nvarious setups, including span-based question answering and text\nclassification. Code is available at\nhttps://github.com/clovaai/length-adaptive-transformer.",
          "link": "http://arxiv.org/abs/2010.07003",
          "publishedOn": "2021-06-15T01:45:19.445Z",
          "wordCount": 633,
          "title": "Length-Adaptive Transformer: Train Once with Length Drop, Use Anytime with Search. (arXiv:2010.07003v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.10025",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liao_W/0/1/0/all/0/1\">Wenlong Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bak_Jensen_B/0/1/0/all/0/1\">Birgitte Bak-Jensen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pillai_J/0/1/0/all/0/1\">Jayakrishnan Radhakrishna Pillai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuelong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yusen Wang</a>",
          "description": "Deep neural networks have revolutionized many machine learning tasks in power\nsystems, ranging from pattern recognition to signal processing. The data in\nthese tasks is typically represented in Euclidean domains. Nevertheless, there\nis an increasing number of applications in power systems, where data are\ncollected from non-Euclidean domains and represented as graph-structured data\nwith high dimensional features and interdependency among nodes. The complexity\nof graph-structured data has brought significant challenges to the existing\ndeep neural networks defined in Euclidean domains. Recently, many publications\ngeneralizing deep neural networks for graph-structured data in power systems\nhave emerged. In this paper, a comprehensive overview of graph neural networks\n(GNNs) in power systems is proposed. Specifically, several classical paradigms\nof GNNs structures (e.g., graph convolutional networks) are summarized, and key\napplications in power systems, such as fault scenario application, time series\nprediction, power flow calculation, and data generation are reviewed in detail.\nFurthermore, main issues and some research trends about the applications of\nGNNs in power systems are discussed.",
          "link": "http://arxiv.org/abs/2101.10025",
          "publishedOn": "2021-06-15T01:45:19.437Z",
          "wordCount": 633,
          "title": "A Review of Graph Neural Networks and Their Applications in Power Systems. (arXiv:2101.10025v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.03216",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nekoei_H/0/1/0/all/0/1\">Hadi Nekoei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Badrinaaraayanan_A/0/1/0/all/0/1\">Akilesh Badrinaaraayanan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Courville_A/0/1/0/all/0/1\">Aaron Courville</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandar_S/0/1/0/all/0/1\">Sarath Chandar</a>",
          "description": "Current deep reinforcement learning (RL) algorithms are still highly\ntask-specific and lack the ability to generalize to new environments. Lifelong\nlearning (LLL), however, aims at solving multiple tasks sequentially by\nefficiently transferring and using knowledge between tasks. Despite a surge of\ninterest in lifelong RL in recent years, the lack of a realistic testbed makes\nrobust evaluation of LLL algorithms difficult. Multi-agent RL (MARL), on the\nother hand, can be seen as a natural scenario for lifelong RL due to its\ninherent non-stationarity, since the agents' policies change over time. In this\nwork, we introduce a multi-agent lifelong learning testbed that supports both\nzero-shot and few-shot settings. Our setup is based on Hanabi -- a\npartially-observable, fully cooperative multi-agent game that has been shown to\nbe challenging for zero-shot coordination. Its large strategy space makes it a\ndesirable environment for lifelong RL tasks. We evaluate several recent MARL\nmethods, and benchmark state-of-the-art LLL algorithms in limited memory and\ncomputation regimes to shed light on their strengths and weaknesses. This\ncontinual learning paradigm also provides us with a pragmatic way of going\nbeyond centralized training which is the most commonly used training protocol\nin MARL. We empirically show that the agents trained in our setup are able to\ncoordinate well with unseen agents, without any additional assumptions made by\nprevious works. The code and all pre-trained models are available at\nhttps://github.com/chandar-lab/Lifelong-Hanabi.",
          "link": "http://arxiv.org/abs/2103.03216",
          "publishedOn": "2021-06-15T01:45:19.414Z",
          "wordCount": 713,
          "title": "Continuous Coordination As a Realistic Scenario for Lifelong Learning. (arXiv:2103.03216v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.06701",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sato_T/0/1/0/all/0/1\">Takami Sato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1\">Junjie Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_N/0/1/0/all/0/1\">Ningfei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1\">Yunhan Jack Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1\">Xue Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qi Alfred Chen</a>",
          "description": "Automated Lane Centering (ALC) systems are convenient and widely deployed\ntoday, but also highly security and safety critical. In this work, we are the\nfirst to systematically study the security of state-of-the-art deep learning\nbased ALC systems in their designed operational domains under physical-world\nadversarial attacks. We formulate the problem with a safety-critical attack\ngoal, and a novel and domain-specific attack vector: dirty road patches. To\nsystematically generate the attack, we adopt an optimization-based approach and\novercome domain-specific design challenges such as camera frame\ninter-dependencies due to attack-influenced vehicle control, and the lack of\nobjective function design for lane detection models.\n\nWe evaluate our attack on a production ALC using 80 scenarios from real-world\ndriving traces. The results show that our attack is highly effective with over\n97.5% success rates and less than 0.903 sec average success time, which is\nsubstantially lower than the average driver reaction time. This attack is also\nfound (1) robust to various real-world factors such as lighting conditions and\nview angles, (2) general to different model designs, and (3) stealthy from the\ndriver's view. To understand the safety impacts, we conduct experiments using\nsoftware-in-the-loop simulation and attack trace injection in a real vehicle.\nThe results show that our attack can cause a 100% collision rate in different\nscenarios, including when tested with common safety features such as automatic\nemergency braking. We also evaluate and discuss defenses.",
          "link": "http://arxiv.org/abs/2009.06701",
          "publishedOn": "2021-06-15T01:45:19.398Z",
          "wordCount": null,
          "title": "Dirty Road Can Attack: Security of Deep Learning based Automated Lane Centering under Physical-World Attack. (arXiv:2009.06701v2 [cs.CR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.14824",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yoo_S/0/1/0/all/0/1\">Soyoung Yoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_N/0/1/0/all/0/1\">Namwoo Kang</a>",
          "description": "Studies on manufacturing cost prediction based on deep learning have begun in\nrecent years, but the cost prediction rationale cannot be explained because the\nmodels are still used as a black box. This study aims to propose a\nmanufacturing cost prediction process for 3D computer-aided design (CAD) models\nusing explainable artificial intelligence. The proposed process can visualize\nthe machining features of the 3D CAD model that are influencing the increase in\nmanufacturing costs. The proposed process consists of (1) data collection and\npre-processing, (2) 3D deep learning architecture exploration, and (3)\nvisualization to explain the prediction results. The proposed deep learning\nmodel shows high predictability of manufacturing cost for the computer\nnumerical control (CNC) machined parts. In particular, using 3D\ngradient-weighted class activation mapping proves that the proposed model not\nonly can detect the CNC machining features but also can differentiate the\nmachining difficulty for the same feature. Using the proposed process, we can\nprovide a design guidance to engineering designers in reducing manufacturing\ncosts during the conceptual design phase. We can also provide real-time\nquotations and redesign proposals to online manufacturing platform customers.",
          "link": "http://arxiv.org/abs/2010.14824",
          "publishedOn": "2021-06-15T01:45:19.390Z",
          "wordCount": 639,
          "title": "Explainable Artificial Intelligence for Manufacturing Cost Estimation and Machining Feature Visualization. (arXiv:2010.14824v2 [cs.CG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.15190",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Nakagawa_A/0/1/0/all/0/1\">Akira Nakagawa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kato_K/0/1/0/all/0/1\">Keizo Kato</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Suzuki_T/0/1/0/all/0/1\">Taiji Suzuki</a>",
          "description": "Variational autoencoder (VAE) estimates the posterior parameters (mean and\nvariance) of latent variables corresponding to each input data. While it is\nused for many tasks, the transparency of the model is still an underlying\nissue. This paper provides a quantitative understanding of VAE property through\nthe differential geometric and information-theoretic interpretations of VAE.\nAccording to the Rate-distortion theory, the optimal transform coding is\nachieved by using an orthonormal transform with PCA basis where the transform\nspace is isometric to the input. Considering the analogy of transform coding to\nVAE, we clarify theoretically and experimentally that VAE can be mapped to an\nimplicit isometric embedding with a scale factor derived from the posterior\nparameter. As a result, we can estimate the data probabilities in the input\nspace from the prior, loss metrics, and corresponding posterior parameters, and\nfurther, the quantitative importance of each latent variable can be evaluated\nlike the eigenvalue of PCA.",
          "link": "http://arxiv.org/abs/2007.15190",
          "publishedOn": "2021-06-15T01:45:19.378Z",
          "wordCount": 622,
          "title": "Quantitative Understanding of VAE as a Non-linearly Scaled Isometric Embedding. (arXiv:2007.15190v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06555",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lovelace_J/0/1/0/all/0/1\">Justin Lovelace</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Newman_Griffis_D/0/1/0/all/0/1\">Denis Newman-Griffis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vashishth_S/0/1/0/all/0/1\">Shikhar Vashishth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lehman_J/0/1/0/all/0/1\">Jill Fain Lehman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rose_C/0/1/0/all/0/1\">Carolyn Penstein Ros&#xe9;</a>",
          "description": "Knowledge Graph (KG) completion research usually focuses on densely connected\nbenchmark datasets that are not representative of real KGs. We curate two KG\ndatasets that include biomedical and encyclopedic knowledge and use an existing\ncommonsense KG dataset to explore KG completion in the more realistic setting\nwhere dense connectivity is not guaranteed. We develop a deep convolutional\nnetwork that utilizes textual entity representations and demonstrate that our\nmodel outperforms recent KG completion methods in this challenging setting. We\nfind that our model's performance improvements stem primarily from its\nrobustness to sparsity. We then distill the knowledge from the convolutional\nnetwork into a student network that re-ranks promising candidate entities. This\nre-ranking stage leads to further improvements in performance and demonstrates\nthe effectiveness of entity re-ranking for KG completion.",
          "link": "http://arxiv.org/abs/2106.06555",
          "publishedOn": "2021-06-15T01:45:19.372Z",
          "wordCount": 591,
          "title": "Robust Knowledge Graph Completion with Stacked Convolutions and a Student Re-Ranking Network. (arXiv:2106.06555v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06749",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_K/0/1/0/all/0/1\">Kun Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jinlan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1\">Zhixia Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1\">Dongpo Xu</a>",
          "description": "Currently, researchers have proposed the adaptive gradient descent algorithm\nand its variants, such as AdaGrad, RMSProp, Adam, AmsGrad, etc. Although these\nalgorithms have a faster speed in the early stage, the generalization ability\nin the later stage of training is often not as good as the stochastic gradient\ndescent. Recently, some researchers have combined the adaptive gradient descent\nand stochastic gradient descent to obtain the advantages of both and achieved\ngood results. Based on this research, we propose a decreasing scaling\ntransition from adaptive gradient descent to stochastic gradient descent\nmethod(DSTAda). For the training stage of the stochastic gradient descent, we\nuse a learning rate that decreases linearly with the number of iterations\ninstead of a constant learning rate. We achieve a smooth and stable transition\nfrom adaptive gradient descent to stochastic gradient descent through scaling.\nAt the same time, we give a theoretical proof of the convergence of DSTAda\nunder the framework of online learning. Our experimental results show that the\nDSTAda algorithm has a faster convergence speed, higher accuracy, and better\nstability and robustness. Our implementation is available at:\nhttps://github.com/kunzeng/DSTAdam.",
          "link": "http://arxiv.org/abs/2106.06749",
          "publishedOn": "2021-06-15T01:45:19.354Z",
          "wordCount": 616,
          "title": "Decreasing scaling transition from adaptive gradient descent to stochastic gradient descent. (arXiv:2106.06749v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2104.13352",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_A/0/1/0/all/0/1\">Ajay Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_B/0/1/0/all/0/1\">Basant Agarwal</a>",
          "description": "On 26 January 2021, India witnessed a national embarrassment from the\ndemographic least expected from - farmers. People across the nation watched in\nhorror as a pseudo-patriotic mob of farmers stormed capital Delhi and\nvandalized the national pride- Red Fort. Investigations that followed the event\nrevealed the existence of a social media trail that led to the likes of such an\nevent. Consequently, it became essential and necessary to archive this trail\nfor social media analysis - not only to understand the bread-crumbs that are\ndispersed across the trail but also to visualize the role played by\nmisinformation and fake news in this event. In this paper, we propose the\ntractor2twitter dataset which contains around 0.05 million tweets that were\nposted before, during, and after this event. Also, we benchmark our dataset\nwith an Explainable AI ML model for classification of each tweet into either of\nthe three categories - disinformation, misinformation, and opinion.",
          "link": "http://arxiv.org/abs/2104.13352",
          "publishedOn": "2021-06-15T01:45:19.340Z",
          "wordCount": null,
          "title": "Tracking Peaceful Tractors on Social Media -- XAI-enabled analysis of Red Fort Riots 2021. (arXiv:2104.13352v2 [cs.SI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06753",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_K/0/1/0/all/0/1\">Kun Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jinlan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1\">Zhixia Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1\">Dongpo Xu</a>",
          "description": "The plain stochastic gradient descent and momentum stochastic gradient\ndescent have extremely wide applications in deep learning due to their simple\nsettings and low computational complexity. The momentum stochastic gradient\ndescent uses the accumulated gradient as the updated direction of the current\nparameters, which has a faster training speed. Because the direction of the\nplain stochastic gradient descent has not been corrected by the accumulated\ngradient. For the parameters that currently need to be updated, it is the\noptimal direction, and its update is more accurate. We combine the advantages\nof the momentum stochastic gradient descent with fast training speed and the\nplain stochastic gradient descent with high accuracy, and propose a scaling\ntransition from momentum stochastic gradient descent to plain stochastic\ngradient descent(TSGD) method. At the same time, a learning rate that decreases\nlinearly with the iterations is used instead of a constant learning rate. The\nTSGD algorithm has a larger step size in the early stage to speed up the\ntraining, and training with a smaller step size in the later stage can steadily\nconverge. Our experimental results show that the TSGD algorithm has faster\ntraining speed, higher accuracy and better stability. Our implementation is\navailable at: https://github.com/kunzeng/TSGD.",
          "link": "http://arxiv.org/abs/2106.06753",
          "publishedOn": "2021-06-15T01:45:19.338Z",
          "wordCount": 638,
          "title": "Scaling transition from momentum stochastic gradient descent to plain stochastic gradient descent. (arXiv:2106.06753v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2004.12908",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vogelstein_J/0/1/0/all/0/1\">Joshua T. Vogelstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dey_J/0/1/0/all/0/1\">Jayanta Dey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Helm_H/0/1/0/all/0/1\">Hayden S. Helm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+LeVine_W/0/1/0/all/0/1\">Will LeVine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehta_R/0/1/0/all/0/1\">Ronak D. Mehta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geisa_A/0/1/0/all/0/1\">Ali Geisa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ven_G/0/1/0/all/0/1\">Gido M. van de Ven</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_E/0/1/0/all/0/1\">Emily Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1\">Chenyu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1\">Weiwei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tower_B/0/1/0/all/0/1\">Bryan Tower</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Larson_J/0/1/0/all/0/1\">Jonathan Larson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+White_C/0/1/0/all/0/1\">Christopher M. White</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Priebe_C/0/1/0/all/0/1\">Carey E. Priebe</a>",
          "description": "In biological learning, data are used to improve performance not only on the\ncurrent task, but also on previously encountered and as yet unencountered\ntasks. In contrast, classical machine learning starts from a blank slate, or\ntabula rasa, using data only for the single task at hand. While typical\ntransfer learning algorithms can improve performance on future tasks, their\nperformance on prior tasks degrades upon learning new tasks (called\ncatastrophic forgetting). Many recent approaches for continual or lifelong\nlearning have attempted to maintain performance given new tasks. But striving\nto avoid forgetting sets the goal unnecessarily low: the goal of lifelong\nlearning, whether biological or artificial, should be to improve performance on\nall tasks (including past and future) with any new data. We propose\nomnidirectional transfer learning algorithms, which includes two special cases\nof interest: decision forests and deep networks. Our key insight is the\ndevelopment of the omni-voter layer, which ensembles representations learned\nindependently on all tasks to jointly decide how to proceed on any given new\ndata point, thereby improving performance on both past and future tasks. Our\nalgorithms demonstrate omnidirectional transfer in a variety of simulated and\nreal data scenarios, including tabular data, image data, spoken data, and\nadversarial tasks. Moreover, they do so with quasilinear space and time\ncomplexity.",
          "link": "http://arxiv.org/abs/2004.12908",
          "publishedOn": "2021-06-15T01:45:19.332Z",
          "wordCount": null,
          "title": "Omnidirectional Transfer for Quasilinear Lifelong Learning. (arXiv:2004.12908v7 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06858",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Deshmukh_S/0/1/0/all/0/1\">Soham Deshmukh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Raj_B/0/1/0/all/0/1\">Bhiksha Raj</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Singh_R/0/1/0/all/0/1\">Rita Singh</a>",
          "description": "While multitask and transfer learning has shown to improve the performance of\nneural networks in limited data settings, they require pretraining of the model\non large datasets beforehand. In this paper, we focus on improving the\nperformance of weakly supervised sound event detection in low data and noisy\nsettings simultaneously without requiring any pretraining task. To that extent,\nwe propose a shared encoder architecture with sound event detection as a\nprimary task and an additional secondary decoder for a self-supervised\nauxiliary task. We empirically evaluate the proposed framework for weakly\nsupervised sound event detection on a remix dataset of the DCASE 2019 task 1\nacoustic scene data with DCASE 2018 Task 2 sounds event data under 0, 10 and 20\ndB SNR. To ensure we retain the localisation information of multiple sound\nevents, we propose a two-step attention pooling mechanism that provides a\ntime-frequency localisation of multiple audio events in the clip. The proposed\nframework with two-step attention outperforms existing benchmark models by\n22.3%, 12.8%, 5.9% on 0, 10 and 20 dB SNR respectively. We carry out an\nablation study to determine the contribution of the auxiliary task and two-step\nattention pooling to the SED performance improvement.",
          "link": "http://arxiv.org/abs/2106.06858",
          "publishedOn": "2021-06-15T01:45:19.330Z",
          "wordCount": 639,
          "title": "Improving weakly supervised sound event detection with self-supervised auxiliary tasks. (arXiv:2106.06858v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2010.09317",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qingqing Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jie Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1\">Yong Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ng_D/0/1/0/all/0/1\">Derrick Wing Kwan Ng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Al_Dhahir_N/0/1/0/all/0/1\">Naofal Al-Dhahir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schober_R/0/1/0/all/0/1\">Robert Schober</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swindlehurst_A/0/1/0/all/0/1\">A. Lee Swindlehurst</a>",
          "description": "Due to the advancements in cellular technologies and the dense deployment of\ncellular infrastructure, integrating unmanned aerial vehicles (UAVs) into the\nfifth-generation (5G) and beyond cellular networks is a promising solution to\nachieve safe UAV operation as well as enabling diversified applications with\nmission-specific payload data delivery. In particular, 5G networks need to\nsupport three typical usage scenarios, namely, enhanced mobile broadband\n(eMBB), ultra-reliable low-latency communications (URLLC), and massive\nmachine-type communications (mMTC). On the one hand, UAVs can be leveraged as\ncost-effective aerial platforms to provide ground users with enhanced\ncommunication services by exploiting their high cruising altitude and\ncontrollable maneuverability in three-dimensional (3D) space. On the other\nhand, providing such communication services simultaneously for both UAV and\nground users poses new challenges due to the need for ubiquitous 3D signal\ncoverage as well as the strong air-ground network interference. Besides the\nrequirement of high-performance wireless communications, the ability to support\neffective and efficient sensing as well as network intelligence is also\nessential for 5G-and-beyond 3D heterogeneous wireless networks with coexisting\naerial and ground users. In this paper, we provide a comprehensive overview of\nthe latest research efforts on integrating UAVs into cellular networks, with an\nemphasis on how to exploit advanced techniques (e.g., intelligent reflecting\nsurface, short packet transmission, energy harvesting, joint communication and\nradar sensing, and edge intelligence) to meet the diversified service\nrequirements of next-generation wireless systems. Moreover, we highlight\nimportant directions for further investigation in future work.",
          "link": "http://arxiv.org/abs/2010.09317",
          "publishedOn": "2021-06-15T01:45:19.304Z",
          "wordCount": 740,
          "title": "A Comprehensive Overview on 5G-and-Beyond Networks with UAVs: From Communications to Sensing and Intelligence. (arXiv:2010.09317v2 [cs.IT] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06926",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1\">Tengyang Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1\">Ching-An Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_N/0/1/0/all/0/1\">Nan Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mineiro_P/0/1/0/all/0/1\">Paul Mineiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_A/0/1/0/all/0/1\">Alekh Agarwal</a>",
          "description": "The use of pessimism, when reasoning about datasets lacking exhaustive\nexploration has recently gained prominence in offline reinforcement learning.\nDespite the robustness it adds to the algorithm, overly pessimistic reasoning\ncan be equally damaging in precluding the discovery of good policies, which is\nan issue for the popular bonus-based pessimism. In this paper, we introduce the\nnotion of Bellman-consistent pessimism for general function approximation:\ninstead of calculating a point-wise lower bound for the value function, we\nimplement pessimism at the initial state over the set of functions consistent\nwith the Bellman equations. Our theoretical guarantees only require Bellman\nclosedness as standard in the exploratory setting, in which case bonus-based\npessimism fails to provide guarantees. Even in the special case of linear MDPs\nwhere stronger function-approximation assumptions hold, our result improves\nupon a recent bonus-based approach by $\\mathcal{O}(d)$ in its sample complexity\nwhen the action space is finite. Remarkably, our algorithms automatically adapt\nto the best bias-variance tradeoff in the hindsight, whereas most prior\napproaches require tuning extra hyperparameters a priori.",
          "link": "http://arxiv.org/abs/2106.06926",
          "publishedOn": "2021-06-15T01:45:19.298Z",
          "wordCount": 601,
          "title": "Bellman-consistent Pessimism for Offline Reinforcement Learning. (arXiv:2106.06926v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06927",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rojas_Gomez_R/0/1/0/all/0/1\">Renan A. Rojas-Gomez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeh_R/0/1/0/all/0/1\">Raymond A. Yeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Do_M/0/1/0/all/0/1\">Minh N. Do</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1\">Anh Nguyen</a>",
          "description": "Recent research in adversarially robust classifiers suggests their\nrepresentations tend to be aligned with human perception, which makes them\nattractive for image synthesis and restoration applications. Despite favorable\nempirical results on a few downstream tasks, their advantages are limited to\nslow and sensitive optimization-based techniques. Moreover, their use on\ngenerative models remains unexplored. This work proposes the use of robust\nrepresentations as a perceptual primitive for feature inversion models, and\nshow its benefits with respect to standard non-robust image features. We\nempirically show that adopting robust representations as an image prior\nsignificantly improves the reconstruction accuracy of CNN-based feature\ninversion models. Furthermore, it allows reconstructing images at multiple\nscales out-of-the-box. Following these findings, we propose an\nencoding-decoding network based on robust representations and show its\nadvantages for applications such as anomaly detection, style transfer and image\ndenoising.",
          "link": "http://arxiv.org/abs/2106.06927",
          "publishedOn": "2021-06-15T01:45:19.290Z",
          "wordCount": 577,
          "title": "Inverting Adversarially Robust Networks for Image Synthesis. (arXiv:2106.06927v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/1905.13298",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Elhoushi_M/0/1/0/all/0/1\">Mostafa Elhoushi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zihao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shafiq_F/0/1/0/all/0/1\">Farhan Shafiq</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Ye Henry Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Joey Yiwei Li</a>",
          "description": "The high computation, memory, and power budgets of inferring convolutional\nneural networks (CNNs) are major bottlenecks of model deployment to edge\ncomputing platforms, e.g., mobile devices and IoT. Moreover, training CNNs is\ntime and energy-intensive even on high-grade servers. Convolution layers and\nfully connected layers, because of their intense use of multiplications, are\nthe dominant contributor to this computation budget.\n\nWe propose to alleviate this problem by introducing two new operations:\nconvolutional shifts and fully-connected shifts which replace multiplications\nwith bitwise shift and sign flipping during both training and inference. During\ninference, both approaches require only 5 bits (or less) to represent the\nweights. This family of neural network architectures (that use convolutional\nshifts and fully connected shifts) is referred to as DeepShift models. We\npropose two methods to train DeepShift models: DeepShift-Q which trains regular\nweights constrained to powers of 2, and DeepShift-PS that trains the values of\nthe shifts and sign flips directly.\n\nVery close accuracy, and in some cases higher accuracy, to baselines are\nachieved. Converting pre-trained 32-bit floating-point baseline models of\nResNet18, ResNet50, VGG16, and GoogleNet to DeepShift and training them for 15\nto 30 epochs, resulted in Top-1/Top-5 accuracies higher than that of the\noriginal model.\n\nLast but not least, we implemented the convolutional shifts and fully\nconnected shift GPU kernels and showed a reduction in latency time of 25% when\ninferring ResNet18 compared to unoptimized multiplication-based GPU kernels.\nThe code can be found at https://github.com/mostafaelhoushi/DeepShift.",
          "link": "http://arxiv.org/abs/1905.13298",
          "publishedOn": "2021-06-15T01:45:19.259Z",
          "wordCount": 786,
          "title": "DeepShift: Towards Multiplication-Less Neural Networks. (arXiv:1905.13298v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06885",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Flaspohler_G/0/1/0/all/0/1\">Genevieve Flaspohler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Orabona_F/0/1/0/all/0/1\">Francesco Orabona</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_J/0/1/0/all/0/1\">Judah Cohen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mouatadid_S/0/1/0/all/0/1\">Soukayna Mouatadid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oprescu_M/0/1/0/all/0/1\">Miruna Oprescu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Orenstein_P/0/1/0/all/0/1\">Paulo Orenstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mackey_L/0/1/0/all/0/1\">Lester Mackey</a>",
          "description": "Inspired by the demands of real-time climate and weather forecasting, we\ndevelop optimistic online learning algorithms that require no parameter tuning\nand have optimal regret guarantees under delayed feedback. Our algorithms --\nDORM, DORMP, and AdaHedgeD -- arise from a novel reduction of delayed online\nlearning to optimistic online learning that reveals how optimistic hints can\nmitigate the regret penalty caused by delay. We pair this delay-as-optimism\nperspective with a new analysis of optimistic learning that exposes its\nrobustness to hinting errors and a new meta-algorithm for learning effective\nhinting strategies in the presence of delay. We conclude by benchmarking our\nalgorithms on four subseasonal climate forecasting tasks, demonstrating low\nregret relative to state-of-the-art forecasting models.",
          "link": "http://arxiv.org/abs/2106.06885",
          "publishedOn": "2021-06-15T01:45:19.232Z",
          "wordCount": 560,
          "title": "Online Learning with Optimism and Delay. (arXiv:2106.06885v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2006.04648",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_G/0/1/0/all/0/1\">Guihua Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chapman_A/0/1/0/all/0/1\">Adriane Chapman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_P/0/1/0/all/0/1\">Pei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_M/0/1/0/all/0/1\">Mingnan Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yingxue Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_D/0/1/0/all/0/1\">Dan Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hall_W/0/1/0/all/0/1\">Wendy Hall</a>",
          "description": "Zero-shot learning uses semantic attributes to connect the search space of\nunseen objects. In recent years, although the deep convolutional network brings\npowerful visual modeling capabilities to the ZSL task, its visual features have\nsevere pattern inertia and lack of representation of semantic relationships,\nwhich leads to severe bias and ambiguity. In response to this, we propose the\nGraph-based Visual-Semantic Entanglement Network to conduct graph modeling of\nvisual features, which is mapped to semantic attributes by using a knowledge\ngraph, it contains several novel designs: 1. it establishes a multi-path\nentangled network with the convolutional neural network (CNN) and the graph\nconvolutional network (GCN), which input the visual features from CNN to GCN to\nmodel the implicit semantic relations, then GCN feedback the graph modeled\ninformation to CNN features; 2. it uses attribute word vectors as the target\nfor the graph semantic modeling of GCN, which forms a self-consistent\nregression for graph modeling and supervise GCN to learn more personalized\nattribute relations; 3. it fuses and supplements the hierarchical\nvisual-semantic features refined by graph modeling into visual embedding. Our\nmethod outperforms state-of-the-art approaches on multiple representative ZSL\ndatasets: AwA2, CUB, and SUN by promoting the semantic linkage modelling of\nvisual features.",
          "link": "http://arxiv.org/abs/2006.04648",
          "publishedOn": "2021-06-15T01:45:19.224Z",
          "wordCount": 699,
          "title": "Graph-based Visual-Semantic Entanglement Network for Zero-shot Image Recognition. (arXiv:2006.04648v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.02194",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Le_D/0/1/0/all/0/1\">Duc Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_M/0/1/0/all/0/1\">Mahaveer Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keren_G/0/1/0/all/0/1\">Gil Keren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Suyoun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yangyang Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahadeokar_J/0/1/0/all/0/1\">Jay Mahadeokar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_J/0/1/0/all/0/1\">Julian Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shangguan_Y/0/1/0/all/0/1\">Yuan Shangguan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fuegen_C/0/1/0/all/0/1\">Christian Fuegen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalinli_O/0/1/0/all/0/1\">Ozlem Kalinli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saraf_Y/0/1/0/all/0/1\">Yatharth Saraf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seltzer_M/0/1/0/all/0/1\">Michael L. Seltzer</a>",
          "description": "How to leverage dynamic contextual information in end-to-end speech\nrecognition has remained an active research area. Previous solutions to this\nproblem were either designed for specialized use cases that did not generalize\nwell to open-domain scenarios, did not scale to large biasing lists, or\nunderperformed on rare long-tail words. We address these limitations by\nproposing a novel solution that combines shallow fusion, trie-based deep\nbiasing, and neural network language model contextualization. These techniques\nresult in significant 19.5% relative Word Error Rate improvement over existing\ncontextual biasing approaches and 5.4%-9.3% improvement compared to a strong\nhybrid baseline on both open-domain and constrained contextualization tasks,\nwhere the targets consist of mostly rare long-tail words. Our final system\nremains lightweight and modular, allowing for quick modification without model\nre-training.",
          "link": "http://arxiv.org/abs/2104.02194",
          "publishedOn": "2021-06-15T01:45:19.216Z",
          "wordCount": 626,
          "title": "Contextualized Streaming End-to-End Speech Recognition with Trie-Based Deep Biasing and Shallow Fusion. (arXiv:2104.02194v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06845",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rongguang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhari_P/0/1/0/all/0/1\">Pratik Chaudhari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Davatzikos_C/0/1/0/all/0/1\">Christos Davatzikos</a>",
          "description": "Heterogeneity in medical data, e.g., from data collected at different sites\nand with different protocols in a clinical study, is a fundamental hurdle for\naccurate prediction using machine learning models, as such models often fail to\ngeneralize well. This paper presents a normalizing-flow-based method to perform\ncounterfactual inference upon a structural causal model (SCM) to harmonize such\ndata. We formulate a causal model for observed effects (brain magnetic\nresonance imaging data) that result from known confounders (site, gender and\nage) and exogenous noise variables. Our method exploits the bijection induced\nby flow for harmonization. We can infer the posterior of exogenous variables,\nintervene on observations, and draw samples from the resultant SCM to obtain\ncounterfactuals. We evaluate on multiple, large, real-world medical datasets to\nobserve that this method leads to better cross-domain generalization compared\nto state-of-the-art algorithms. Further experiments that evaluate the quality\nof confounder-independent data generated by our model using regression and\nclassification tasks are provided.",
          "link": "http://arxiv.org/abs/2106.06845",
          "publishedOn": "2021-06-15T01:45:19.205Z",
          "wordCount": 579,
          "title": "Harmonization with Flow-based Causal Inference. (arXiv:2106.06845v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2003.01926",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Singh_C/0/1/0/all/0/1\">Chandan Singh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ha_W/0/1/0/all/0/1\">Wooseok Ha</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lanusse_F/0/1/0/all/0/1\">Francois Lanusse</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Boehm_V/0/1/0/all/0/1\">Vanessa Boehm</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liu_J/0/1/0/all/0/1\">Jia Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yu_B/0/1/0/all/0/1\">Bin Yu</a>",
          "description": "Machine learning lies at the heart of new possibilities for scientific\ndiscovery, knowledge generation, and artificial intelligence. Its potential\nbenefits to these fields requires going beyond predictive accuracy and focusing\non interpretability. In particular, many scientific problems require\ninterpretations in a domain-specific interpretable feature space (e.g. the\nfrequency domain) whereas attributions to the raw features (e.g. the pixel\nspace) may be unintelligible or even misleading. To address this challenge, we\npropose TRIM (TRansformation IMportance), a novel approach which attributes\nimportances to features in a transformed space and can be applied post-hoc to a\nfully trained model. TRIM is motivated by a cosmological parameter estimation\nproblem using deep neural networks (DNNs) on simulated data, but it is\ngenerally applicable across domains/models and can be combined with any local\ninterpretation method. In our cosmology example, combining TRIM with contextual\ndecomposition shows promising results for identifying which frequencies a DNN\nuses, helping cosmologists to understand and validate that the model learns\nappropriate physical features rather than simulation artifacts.",
          "link": "http://arxiv.org/abs/2003.01926",
          "publishedOn": "2021-06-15T01:45:19.188Z",
          "wordCount": 632,
          "title": "Transformation Importance with Applications to Cosmology. (arXiv:2003.01926v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06713",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xiangyu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Haochen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_W/0/1/0/all/0/1\">Wenqi Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jiliang Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chong Wang</a>",
          "description": "Designing an effective loss function plays a crucial role in training deep\nrecommender systems. Most existing works often leverage a predefined and fixed\nloss function that could lead to suboptimal recommendation quality and training\nefficiency. Some recent efforts rely on exhaustively or manually searched\nweights to fuse a group of candidate loss functions, which is exceptionally\ncostly in computation and time. They also neglect the various convergence\nbehaviors of different data examples. In this work, we propose an AutoLoss\nframework that can automatically and adaptively search for the appropriate loss\nfunction from a set of candidates. To be specific, we develop a novel\ncontroller network, which can dynamically adjust the loss probabilities in a\ndifferentiable manner. Unlike existing algorithms, the proposed controller can\nadaptively generate the loss probabilities for different data examples\naccording to their varied convergence behaviors. Such design improves the\nmodel's generalizability and transferability between deep recommender systems\nand datasets. We evaluate the proposed framework on two benchmark datasets. The\nresults show that AutoLoss outperforms representative baselines. Further\nexperiments have been conducted to deepen our understandings of AutoLoss,\nincluding its transferability, components and training efficiency.",
          "link": "http://arxiv.org/abs/2106.06713",
          "publishedOn": "2021-06-15T01:45:19.177Z",
          "wordCount": 634,
          "title": "AutoLoss: Automated Loss Function Search in Recommendations. (arXiv:2106.06713v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06676",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Devvrit_F/0/1/0/all/0/1\">Fnu Devvrit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajaraman_N/0/1/0/all/0/1\">Nived Rajaraman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awasthi_P/0/1/0/all/0/1\">Pranjal Awasthi</a>",
          "description": "Labelled data often comes at a high cost as it may require recruiting human\nlabelers or running costly experiments. At the same time, in many practical\nscenarios, one already has access to a partially labelled, potentially biased\ndataset that can help with the learning task at hand. Motivated by such\nsettings, we formally initiate a study of $semi-supervised$ $active$ $learning$\nthrough the frame of linear regression. In this setting, the learner has access\nto a dataset $X \\in \\mathbb{R}^{(n_1+n_2) \\times d}$ which is composed of $n_1$\nunlabelled examples that an algorithm can actively query, and $n_2$ examples\nlabelled a-priori. Concretely, denoting the true labels by $Y \\in\n\\mathbb{R}^{n_1 + n_2}$, the learner's objective is to find $\\widehat{\\beta}\n\\in \\mathbb{R}^d$ such that, \\begin{equation}\n\n\\| X \\widehat{\\beta} - Y \\|_2^2 \\le (1 + \\epsilon) \\min_{\\beta \\in\n\\mathbb{R}^d} \\| X \\beta - Y \\|_2^2 \\end{equation} while making as few\nadditional label queries as possible. In order to bound the label queries, we\nintroduce an instance dependent parameter called the reduced rank, denoted by\n$R_X$, and propose an efficient algorithm with query complexity\n$O(R_X/\\epsilon)$. This result directly implies improved upper bounds for two\nimportant special cases: (i) active ridge regression, and (ii) active kernel\nridge regression, where the reduced-rank equates to the statistical dimension,\n$sd_\\lambda$ and effective dimension, $d_\\lambda$ of the problem respectively,\nwhere $\\lambda \\ge 0$ denotes the regularization parameter. For active ridge\nregression we also prove a matching lower bound of $O(sd_\\lambda / \\epsilon)$\non the query complexity of any algorithm. This subsumes prior work that only\nconsidered the unregularized case, i.e., $\\lambda = 0$.",
          "link": "http://arxiv.org/abs/2106.06676",
          "publishedOn": "2021-06-15T01:45:19.150Z",
          "wordCount": 675,
          "title": "Semi-supervised Active Regression. (arXiv:2106.06676v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.02959",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+DAnniballe_V/0/1/0/all/0/1\">Vincent M. D&#x27;Anniballe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tushar_F/0/1/0/all/0/1\">Fakrul I. Tushar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faryna_K/0/1/0/all/0/1\">Khrystyna Faryna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Songyue Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mazurowski_M/0/1/0/all/0/1\">Maciej A. Mazurowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubin_G/0/1/0/all/0/1\">Geoffrey D. Rubin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lo_J/0/1/0/all/0/1\">Joseph Y. Lo</a>",
          "description": "Purpose: To develop high throughput multi-label annotators for body (chest,\nabdomen, and pelvis) Computed Tomography (CT) reports that can be applied\nacross a variety of abnormalities, organs, and disease states.\n\nApproach: We used a dictionary approach to develop rule-based algorithms\n(RBA) for extraction of disease labels from radiology text reports. We targeted\nthree organ systems (lungs/pleura, liver/gallbladder, kidneys/ureters) with\nfour diseases per system based on their prevalence in our dataset. To expand\nthe algorithms beyond pre-defined keywords, attention-guided recurrent neural\nnetworks (RNN) were trained using the RBA-extracted labels to classify reports\nas being positive for one or more diseases or normal for each organ system.\nConfounding effects on model performance were evaluated using random\ninitialization or pre-trained embedding as well as different sizes of training\ndatasets. Performance was evaluated using the receiver operating characteristic\n(ROC) area under the curve (AUC) against 2,158 manually obtained labels.\n\nResults: Our models extracted disease labels from 261,229 radiology reports\nof 112,501 unique subjects. Pre-trained models outperformed random\ninitialization across all diseases. As the training dataset size was reduced,\nperformance was robust except for a few diseases with relatively small number\nof cases. Pre-trained classification AUCs achieved > 0.95 for all five disease\noutcomes across all three organ systems.\n\nConclusions: Our label-extracting pipeline was able to encompass a variety of\ncases and diseases by generalizing beyond strict rules with exceptional\naccuracy. This method can be easily adapted to enable automated labeling of\nhospital-scale medical data sets for training image-based disease classifiers.",
          "link": "http://arxiv.org/abs/2102.02959",
          "publishedOn": "2021-06-15T01:45:19.142Z",
          "wordCount": 748,
          "title": "Multi-Label Annotation of Chest Abdomen Pelvis Computed Tomography Text Reports Using Deep Learning. (arXiv:2102.02959v4 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06561",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chong_M/0/1/0/all/0/1\">Min Jin Chong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Forsyth_D/0/1/0/all/0/1\">David Forsyth</a>",
          "description": "We show how to learn a map that takes a content code, derived from a face\nimage, and a randomly chosen style code to an anime image. We derive an\nadversarial loss from our simple and effective definitions of style and\ncontent. This adversarial loss guarantees the map is diverse -- a very wide\nrange of anime can be produced from a single content code. Under plausible\nassumptions, the map is not just diverse, but also correctly represents the\nprobability of an anime, conditioned on an input face. In contrast, current\nmultimodal generation procedures cannot capture the complex styles that appear\nin anime. Extensive quantitative experiments support the idea the map is\ncorrect. Extensive qualitative results show that the method can generate a much\nmore diverse range of styles than SOTA comparisons. Finally, we show that our\nformalization of content and style allows us to perform video to video\ntranslation without ever training on videos.",
          "link": "http://arxiv.org/abs/2106.06561",
          "publishedOn": "2021-06-15T01:45:19.128Z",
          "wordCount": 609,
          "title": "GANs N' Roses: Stable, Controllable, Diverse Image to Image Translation (works for videos too!). (arXiv:2106.06561v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2006.09179",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Buzzicotti_M/0/1/0/all/0/1\">M. Buzzicotti</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Bonaccorso_F/0/1/0/all/0/1\">F. Bonaccorso</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Leoni_P/0/1/0/all/0/1\">P. Clark Di Leoni</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Biferale_L/0/1/0/all/0/1\">L. Biferale</a>",
          "description": "We study the applicability of tools developed by the computer vision\ncommunity for features learning and semantic image inpainting to perform data\nreconstruction of fluid turbulence configurations. The aim is twofold. First,\nwe explore on a quantitative basis, the capability of Convolutional Neural\nNetworks embedded in a Deep Generative Adversarial Model (Deep-GAN) to generate\nmissing data in turbulence, a paradigmatic high dimensional chaotic system. In\nparticular, we investigate their use in reconstructing two-dimensional damaged\nsnapshots extracted from a large database of numerical configurations of 3d\nturbulence in the presence of rotation, a case with multi-scale random features\nwhere both large-scale organised structures and small-scale highly intermittent\nand non-Gaussian fluctuations are present. Second, following a reverse\nengineering approach, we aim to rank the input flow properties (features) in\nterms of their qualitative and quantitative importance to obtain a better set\nof reconstructed fields. We present two approaches both based on Context\nEncoders. The first one infers the missing data via a minimization of the L2\npixel-wise reconstruction loss, plus a small adversarial penalisation. The\nsecond searches for the closest encoding of the corrupted flow configuration\nfrom a previously trained generator. Finally, we present a comparison with a\ndifferent data assimilation tool, based on Nudging, an equation-informed\nunbiased protocol, well known in the numerical weather prediction community.\nThe TURB-Rot database, this http URL, of roughly 300K 2d\nturbulent images is released and details on how to download it are given.",
          "link": "http://arxiv.org/abs/2006.09179",
          "publishedOn": "2021-06-15T01:45:19.109Z",
          "wordCount": 723,
          "title": "Reconstruction of turbulent data with deep generative models for semantic inpainting from TURB-Rot database. (arXiv:2006.09179v2 [physics.flu-dyn] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.10911",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Liu_K/0/1/0/all/0/1\">Kai-Chun Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Can_M/0/1/0/all/0/1\">Michael Can</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kuo_H/0/1/0/all/0/1\">Heng-Cheng Kuo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hsieh_C/0/1/0/all/0/1\">Chia-Yeh Hsieh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huang_H/0/1/0/all/0/1\">Hsiang-Yun Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chan_C/0/1/0/all/0/1\">Chia-Tai Chan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tsao_Y/0/1/0/all/0/1\">Yu Tsao</a>",
          "description": "Fall detection (FD) systems are important assistive technologies for\nhealthcare that can detect emergency fall events and alert caregivers. However,\nit is not easy to obtain large-scale annotated fall events with various\nspecifications of sensors or sensor positions during the implementation of\naccurate FD systems. Moreover, the knowledge obtained through machine learning\nhas been restricted to tasks in the same domain. The mismatch between different\ndomains might hinder the performance of FD systems. Cross-domain knowledge\ntransfer is very beneficial for machine-learning-based FD systems to train a\nreliable FD model with well-labeled data in new environments. In this study, we\npropose domain-adaptive fall detection (DAFD) using deep adversarial training\n(DAT) to tackle cross-domain problems, such as cross-position and\ncross-configuration. The proposed DAFD can transfer knowledge from the source\ndomain to the target domain by minimizing the domain discrepancy to avoid\nmismatch problems. The experimental results show that the average F1-score\nimprovement when using DAFD ranges from 1.5% to 7% in the cross-position\nscenario, and from 3.5% to 12% in the cross-configuration scenario, compared to\nusing the conventional FD model without domain adaptation training. The results\ndemonstrate that the proposed DAFD successfully helps to deal with cross-domain\nproblems and to achieve better detection performance.",
          "link": "http://arxiv.org/abs/2012.10911",
          "publishedOn": "2021-06-15T01:45:19.094Z",
          "wordCount": 671,
          "title": "Domain-adaptive Fall Detection Using Deep Adversarial Training. (arXiv:2012.10911v2 [eess.SP] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06786",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lamb_A/0/1/0/all/0/1\">Alex Lamb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clanuwat_T/0/1/0/all/0/1\">Tarin Clanuwat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Siyu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bober_Irizar_M/0/1/0/all/0/1\">Mikel Bober-Irizar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kitamoto_A/0/1/0/all/0/1\">Asanobu Kitamoto</a>",
          "description": "Japan is a unique country with a distinct cultural heritage, which is\nreflected in billions of historical documents that have been preserved.\nHowever, the change in Japanese writing system in 1900 made these documents\ninaccessible for the general public. A major research project has been to make\nthese historical documents accessible and understandable. An increasing amount\nof research has focused on the character recognition task and the location of\ncharacters on image, yet less research has focused on how to predict the\nsequential ordering of the characters. This is because sequence in classical\nJapanese is very different from modern Japanese. Ordering characters into a\nsequence is important for making the document text easily readable and\nsearchable. Additionally, it is a necessary step for any kind of natural\nlanguage processing on the data (e.g. machine translation, language modeling,\nand word embeddings). We explore a few approaches to the task of predicting the\nsequential ordering of the characters: one using simple hand-crafted rules,\nanother using hand-crafted rules with adaptive thresholds, and another using a\ndeep recurrent sequence model trained with teacher forcing. We provide a\nquantitative and qualitative comparison of these techniques as well as their\ndistinct trade-offs. Our best-performing system has an accuracy of 98.65\\% and\nhas a perfect accuracy on 49\\% of the books in our dataset, suggesting that the\ntechnique is able to predict the order of the characters well enough for many\ntasks.",
          "link": "http://arxiv.org/abs/2106.06786",
          "publishedOn": "2021-06-15T01:45:19.088Z",
          "wordCount": 673,
          "title": "Predicting the Ordering of Characters in Japanese Historical Documents. (arXiv:2106.06786v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2009.12480",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kurka_D/0/1/0/all/0/1\">David Burth Kurka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gunduz_D/0/1/0/all/0/1\">Deniz G&#xfc;nd&#xfc;z</a>",
          "description": "We propose deep learning based communication methods for adaptive-bandwidth\ntransmission of images over wireless channels. We consider the scenario in\nwhich images are transmitted progressively in layers over time or frequency,\nand such layers can be aggregated by receivers in order to increase the quality\nof their reconstructions. We investigate two scenarios, one in which the layers\nare sent sequentially, and incrementally contribute to the refinement of a\nreconstruction, and another in which the layers are independent and can be\nretrieved in any order. Those scenarios correspond to the well known problems\nof \\textit{successive refinement} and \\textit{multiple descriptions},\nrespectively, in the context of joint source-channel coding (JSCC). We propose\nDeepJSCC-$l$, an innovative solution that uses convolutional autoencoders, and\npresent three architectures with different complexity trade-offs. To the best\nof our knowledge, this is the first practical multiple-description JSCC scheme\ndeveloped and tested for practical information sources and channels. Numerical\nresults show that DeepJSCC-$l$ can learn to transmit the source progressively\nwith negligible losses in the end-to-end performance compared with a single\ntransmission. Moreover, DeepJSCC-$l$ has comparable performance with state of\nthe art digital progressive transmission schemes in the challenging low\nsignal-to-noise ratio (SNR) and small bandwidth regimes, with the additional\nadvantage of graceful degradation with channel SNR.",
          "link": "http://arxiv.org/abs/2009.12480",
          "publishedOn": "2021-06-15T01:45:19.066Z",
          "wordCount": 674,
          "title": "Bandwidth-Agile Image Transmission with Deep Joint Source-Channel Coding. (arXiv:2009.12480v2 [cs.IT] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06607",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ahuja_K/0/1/0/all/0/1\">Kartik Ahuja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caballero_E/0/1/0/all/0/1\">Ethan Caballero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dinghuai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1\">Yoshua Bengio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitliagkas_I/0/1/0/all/0/1\">Ioannis Mitliagkas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rish_I/0/1/0/all/0/1\">Irina Rish</a>",
          "description": "The invariance principle from causality is at the heart of notable approaches\nsuch as invariant risk minimization (IRM) that seek to address\nout-of-distribution (OOD) generalization failures. Despite the promising\ntheory, invariance principle-based approaches fail in common classification\ntasks, where invariant (causal) features capture all the information about the\nlabel. Are these failures due to the methods failing to capture the invariance?\nOr is the invariance principle itself insufficient? To answer these questions,\nwe revisit the fundamental assumptions in linear regression tasks, where\ninvariance-based approaches were shown to provably generalize OOD. In contrast\nto the linear regression tasks, we show that for linear classification tasks we\nneed much stronger restrictions on the distribution shifts, or otherwise OOD\ngeneralization is impossible. Furthermore, even with appropriate restrictions\non distribution shifts in place, we show that the invariance principle alone is\ninsufficient. We prove that a form of the information bottleneck constraint\nalong with invariance helps address key failures when invariant features\ncapture all the information about the label and also retains the existing\nsuccess when they do not. We propose an approach that incorporates both of\nthese principles and demonstrate its effectiveness in several experiments.",
          "link": "http://arxiv.org/abs/2106.06607",
          "publishedOn": "2021-06-15T01:45:19.021Z",
          "wordCount": 625,
          "title": "Invariance Principle Meets Information Bottleneck for Out-of-Distribution Generalization. (arXiv:2106.06607v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2101.06983",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1\">Luyu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yunyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Callan_J/0/1/0/all/0/1\">Jamie Callan</a>",
          "description": "Contrastive learning has been applied successfully to learn vector\nrepresentations of text. Previous research demonstrated that learning\nhigh-quality representations benefits from batch-wise contrastive loss with a\nlarge number of negatives. In practice, the technique of in-batch negative is\nused, where for each example in a batch, other batch examples' positives will\nbe taken as its negatives, avoiding encoding extra negatives. This, however,\nstill conditions each example's loss on all batch examples and requires fitting\nthe entire large batch into GPU memory. This paper introduces a gradient\ncaching technique that decouples backpropagation between contrastive loss and\nthe encoder, removing encoder backward pass data dependency along the batch\ndimension. As a result, gradients can be computed for one subset of the batch\nat a time, leading to almost constant memory usage.",
          "link": "http://arxiv.org/abs/2101.06983",
          "publishedOn": "2021-06-15T01:45:19.013Z",
          "wordCount": 584,
          "title": "Scaling Deep Contrastive Learning Batch Size under Memory Limited Setup. (arXiv:2101.06983v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06848",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Azizi_M/0/1/0/all/0/1\">MohammadJavad Azizi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ross_S/0/1/0/all/0/1\">Sheldon M Ross</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhengyu Zhang</a>",
          "description": "We consider the problem of finding, through adaptive sampling, which of n\npopulations (arms) has the largest mean. Our objective is to determine a rule\nwhich identifies the best population with a fixed minimum confidence using as\nfew observations as possible, i.e. fixed-confidence (FC) best arm\nidentification (BAI) in multi-armed bandits. We study such problems under the\nBayesian setting with both Bernoulli and Gaussian populations. We propose to\nuse the classical vector at a time (VT) rule, which samples each alive\npopulation once in each round. We show how VT can be implemented and analyzed\nin our Bayesian setting and be improved by early elimination. We also propose\nand analyze a variant of the classical play the winner (PW) algorithm.\nNumerical results show that these rules compare favorably with state-of-art\nalgorithms.",
          "link": "http://arxiv.org/abs/2106.06848",
          "publishedOn": "2021-06-15T01:45:19.004Z",
          "wordCount": 555,
          "title": "Guaranteed Fixed-Confidence Best Arm Identification in Multi-Armed Bandit. (arXiv:2106.06848v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00671",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khazatsky_A/0/1/0/all/0/1\">Alexander Khazatsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nair_A/0/1/0/all/0/1\">Ashvin Nair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jing_D/0/1/0/all/0/1\">Daniel Jing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1\">Sergey Levine</a>",
          "description": "A generalist robot equipped with learned skills must be able to perform many\ntasks in many different environments. However, zero-shot generalization to new\nsettings is not always possible. When the robot encounters a new environment or\nobject, it may need to finetune some of its previously learned skills to\naccommodate this change. But crucially, previously learned behaviors and models\nshould still be suitable to accelerate this relearning. In this paper, we aim\nto study how generative models of possible outcomes can allow a robot to learn\nvisual representations of affordances, so that the robot can sample potentially\npossible outcomes in new situations, and then further train its policy to\nachieve those outcomes. In effect, prior data is used to learn what kinds of\noutcomes may be possible, such that when the robot encounters an unfamiliar\nsetting, it can sample potential outcomes from its model, attempt to reach\nthem, and thereby update both its skills and its outcome model. This approach,\nvisuomotor affordance learning (VAL), can be used to train goal-conditioned\npolicies that operate on raw image inputs, and can rapidly learn to manipulate\nnew objects via our proposed affordance-directed exploration scheme. We show\nthat VAL can utilize prior data to solve real-world tasks such drawer opening,\ngrasping, and placing objects in new scenes with only five minutes of online\nexperience in the new scene.",
          "link": "http://arxiv.org/abs/2106.00671",
          "publishedOn": "2021-06-15T01:45:18.979Z",
          "wordCount": 696,
          "title": "What Can I Do Here? Learning New Skills by Imagining Visual Affordances. (arXiv:2106.00671v2 [cs.RO] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.13112",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Beznosikov_A/0/1/0/all/0/1\">Aleksandr Beznosikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samokhin_V/0/1/0/all/0/1\">Valentin Samokhin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gasnikov_A/0/1/0/all/0/1\">Alexander Gasnikov</a>",
          "description": "This paper focuses on the distributed optimization of smooth stochastic\nsaddle-point problems. The first part of the paper is devoted to lower bounds\nfor the cenralized and decentralized distributed methods for smooth\n(strongly-)convex-(strongly-)concave saddle-point problems as well as the\noptimal algorithms by which these bounds are achieved. Next, we present a new\nfederated algorithm for saddle-point problems - Extra Step Local SGD.\nTheoretical analysis of the new method is carried out for\n(strongly-)convex-(strongly-)concave and non-convex-non-concave problems. In\nthe experimental part of the paper, we show the effectiveness of our method in\npractice. In particular, we train GANs in a distributed manner.",
          "link": "http://arxiv.org/abs/2010.13112",
          "publishedOn": "2021-06-15T01:45:18.972Z",
          "wordCount": 598,
          "title": "Distributed Saddle-Point Problems: Lower Bounds, Optimal and Robust Algorithms. (arXiv:2010.13112v6 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2002.07285",
          "author": "<a href=\"http://arxiv.org/find/econ/1/au:+Lewis_G/0/1/0/all/0/1\">Greg Lewis</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Syrgkanis_V/0/1/0/all/0/1\">Vasilis Syrgkanis</a>",
          "description": "We consider the estimation of treatment effects in settings when multiple\ntreatments are assigned over time and treatments can have a causal effect on\nfuture outcomes or the state of the treated unit. We propose an extension of\nthe double/debiased machine learning framework to estimate the dynamic effects\nof treatments, which can be viewed as a Neyman orthogonal (locally robust)\ncross-fitted version of $g$-estimation in the dynamic treatment regime. Our\nmethod applies to a general class of non-linear dynamic treatment models known\nas Structural Nested Mean Models and allows the use of machine learning methods\nto control for potentially high dimensional state variables, subject to a mean\nsquare error guarantee, while still allowing parametric estimation and\nconstruction of confidence intervals for the structural parameters of interest.\nThese structural parameters can be used for off-policy evaluation of any target\ndynamic policy at parametric rates, subject to semi-parametric restrictions on\nthe data generating process. Our work is based on a recursive peeling process,\ntypical in $g$-estimation, and formulates a strongly convex objective at each\nstage, which allows us to extend the $g$-estimation framework in multiple\ndirections: i) to provide finite sample guarantees, ii) to estimate non-linear\neffect heterogeneity with respect to fixed unit characteristics, within\narbitrary function spaces, enabling a dynamic analogue of the RLearner\nalgorithm for heterogeneous effects, iii) to allow for high-dimensional sparse\nparameterizations of the target structural functions, enabling automated model\nselection via a recursive lasso algorithm. We also provide guarantees for data\nstemming from a single treated unit over a long horizon and under stationarity\nconditions.",
          "link": "http://arxiv.org/abs/2002.07285",
          "publishedOn": "2021-06-15T01:45:18.958Z",
          "wordCount": 722,
          "title": "Double/Debiased Machine Learning for Dynamic Treatment Effects via g-Estimation. (arXiv:2002.07285v4 [econ.EM] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.03419",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Duan_S/0/1/0/all/0/1\">Shiyu Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Principe_J/0/1/0/all/0/1\">Jose C. Principe</a>",
          "description": "This tutorial paper surveys training alternatives to end-to-end\nbackpropagation (E2EBP) -- the de facto standard for training deep\narchitectures. Modular training refers to strictly local training without both\nthe forward and the backward pass, i.e., dividing a deep architecture into\nseveral nonoverlapping modules and training them separately without any\nend-to-end operation. Between the fully global E2EBP and the strictly local\nmodular training, there are \"weakly modular\" hybrids performing training\nwithout the backward pass only. These alternatives can match or surpass the\nperformance of E2EBP on challenging datasets such as ImageNet, and are gaining\nincreased attention primarily because they offer practical advantages over\nE2EBP, which will be enumerated herein. In particular, they allow for greater\nmodularity and transparency in deep learning workflows, aligning deep learning\nwith the mainstream computer science engineering that heavily exploits\nmodularization for scalability. Modular training has also revealed novel\ninsights about learning and has further implications on other important\nresearch domains. Specifically, it induces natural and effective solutions to\nsome important practical problems such as data efficiency and transferability\nestimation.",
          "link": "http://arxiv.org/abs/2101.03419",
          "publishedOn": "2021-06-15T01:45:18.946Z",
          "wordCount": 635,
          "title": "Training Deep Architectures Without End-to-End Backpropagation: A Brief Survey. (arXiv:2101.03419v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.09947",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yaodong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zitong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dobriban_E/0/1/0/all/0/1\">Edgar Dobriban</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steinhardt_J/0/1/0/all/0/1\">Jacob Steinhardt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yi Ma</a>",
          "description": "Adversarially trained models exhibit a large generalization gap: they can\ninterpolate the training set even for large perturbation radii, but at the cost\nof large test error on clean samples. To investigate this gap, we decompose the\ntest risk into its bias and variance components and study their behavior as a\nfunction of adversarial training perturbation radii ($\\varepsilon$). We find\nthat the bias increases monotonically with $\\varepsilon$ and is the dominant\nterm in the risk. Meanwhile, the variance is unimodal as a function of\n$\\varepsilon$, peaking near the interpolation threshold for the training set.\nThis characteristic behavior occurs robustly across different datasets and also\nfor other robust training procedures such as randomized smoothing. It thus\nprovides a test for proposed explanations of the generalization gap. We find\nthat some existing explanations fail this test--for instance, by predicting a\nmonotonically increasing variance curve. This underscores the power of\nbias-variance decompositions in modern settings-by providing two measurements\ninstead of one, they can rule out more explanations than test accuracy alone.\nWe also show that bias and variance can provide useful guidance for scalably\nreducing the generalization gap, highlighting pre-training and unlabeled data\nas promising routes.",
          "link": "http://arxiv.org/abs/2103.09947",
          "publishedOn": "2021-06-15T01:45:18.919Z",
          "wordCount": 666,
          "title": "Understanding Generalization in Adversarial Training via the Bias-Variance Decomposition. (arXiv:2103.09947v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.01755",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Haliem_M/0/1/0/all/0/1\">Marina Haliem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mani_G/0/1/0/all/0/1\">Ganapathy Mani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aggarwal_V/0/1/0/all/0/1\">Vaneet Aggarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhargava_B/0/1/0/all/0/1\">Bharat Bhargava</a>",
          "description": "Significant development of ride-sharing services presents a plethora of\nopportunities to transform urban mobility by providing personalized and\nconvenient transportation while ensuring efficiency of large-scale ride\npooling. However, a core problem for such services is route planning for each\ndriver to fulfill the dynamically arriving requests while satisfying given\nconstraints. Current models are mostly limited to static routes with only two\nrides per vehicle (optimally) or three (with heuristics). In this paper, we\npresent a dynamic, demand aware, and pricing-based vehicle-passenger matching\nand route planning framework that (1) dynamically generates optimal routes for\neach vehicle based on online demand, pricing associated with each ride, vehicle\ncapacities and locations. This matching algorithm starts greedily and optimizes\nover time using an insertion operation, (2) involves drivers in the\ndecision-making process by allowing them to propose a different price based on\nthe expected reward for a particular ride as well as the destination locations\nfor future rides, which is influenced by supply-and demand computed by the Deep\nQ-network, (3) allows customers to accept or reject rides based on their set of\npreferences with respect to pricing and delay windows, vehicle type and\ncarpooling preferences, and (4) based on demand prediction, our approach\nre-balances idle vehicles by dispatching them to the areas of anticipated high\ndemand using deep Reinforcement Learning (RL). Our framework is validated using\nthe New York City Taxi public dataset; however, we consider different vehicle\ntypes and designed customer utility functions to validate the setup and study\ndifferent settings. Experimental results show the effectiveness of our approach\nin real-time and large scale settings.",
          "link": "http://arxiv.org/abs/2010.01755",
          "publishedOn": "2021-06-15T01:45:18.897Z",
          "wordCount": 736,
          "title": "A Distributed Model-Free Ride-Sharing Approach for Joint Matching, Pricing, and Dispatching using Deep Reinforcement Learning. (arXiv:2010.01755v2 [cs.MA] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06707",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Barcelo_P/0/1/0/all/0/1\">Pablo Barcel&#xf3;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geerts_F/0/1/0/all/0/1\">Floris Geerts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reutter_J/0/1/0/all/0/1\">Juan Reutter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ryschkov_M/0/1/0/all/0/1\">Maksimilian Ryschkov</a>",
          "description": "Various recent proposals increase the distinguishing power of Graph Neural\nNetworks GNNs by propagating features between $k$-tuples of vertices. The\ndistinguishing power of these \"higher-order'' GNNs is known to be bounded by\nthe $k$-dimensional Weisfeiler-Leman (WL) test, yet their $\\mathcal O(n^k)$\nmemory requirements limit their applicability. Other proposals infuse GNNs with\nlocal higher-order graph structural information from the start, hereby\ninheriting the desirable $\\mathcal O(n)$ memory requirement from GNNs at the\ncost of a one-time, possibly non-linear, preprocessing step. We propose local\ngraph parameter enabled GNNs as a framework for studying the latter kind of\napproaches and precisely characterize their distinguishing power, in terms of a\nvariant of the WL test, and in terms of the graph structural properties that\nthey can take into account. Local graph parameters can be added to any GNN\narchitecture, and are cheap to compute. In terms of expressive power, our\nproposal lies in the middle of GNNs and their higher-order counterparts.\nFurther, we propose several techniques to aide in choosing the right local\ngraph parameters. Our results connect GNNs with deep results in finite model\ntheory and finite variable logics. Our experimental evaluation shows that\nadding local graph parameters often has a positive effect for a variety of\nGNNs, datasets and graph learning tasks.",
          "link": "http://arxiv.org/abs/2106.06707",
          "publishedOn": "2021-06-15T01:45:18.817Z",
          "wordCount": 631,
          "title": "Graph Neural Networks with Local Graph Parameters. (arXiv:2106.06707v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06770",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ortiz_Jimenez_G/0/1/0/all/0/1\">Guillermo Ortiz-Jim&#xe9;nez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moosavi_Dezfooli_S/0/1/0/all/0/1\">Seyed-Mohsen Moosavi-Dezfooli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frossard_P/0/1/0/all/0/1\">Pascal Frossard</a>",
          "description": "For certain infinitely-wide neural networks, the neural tangent kernel (NTK)\ntheory fully characterizes generalization. However, for the networks used in\npractice, the empirical NTK represents only a rough first-order approximation\nof these architectures. Still, a growing body of work keeps leveraging this\napproximation to successfully analyze important deep learning phenomena and\nderive algorithms for new applications. In our work, we provide strong\nempirical evidence to determine the practical validity of such approximation by\nconducting a systematic comparison of the behaviour of different neural\nnetworks and their linear approximations on different tasks. We show that the\nlinear approximations can indeed rank the learning complexity of certain tasks\nfor neural networks, albeit with important nuances. Specifically, we discover\nthat, in contrast to what was previously observed, neural networks do not\nalways perform better than their kernel approximations, and reveal that their\nperformance gap heavily depends on architecture, number of samples and training\ntask. In fact, we show that during training, deep networks increase the\nalignment of their empirical NTK with the target task, which explains why\nlinear approximations at the end of training can better explain the dynamics of\ndeep networks. Overall, our work provides concrete examples of novel deep\nlearning phenomena which can inspire future theoretical research, as well as\nprovides a new perspective on the use of the NTK approximation in deep\nlearning.",
          "link": "http://arxiv.org/abs/2106.06770",
          "publishedOn": "2021-06-15T01:45:18.785Z",
          "wordCount": 655,
          "title": "What can linearized neural networks actually say about generalization?. (arXiv:2106.06770v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06575",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1\">Yonggan Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cox_D/0/1/0/all/0/1\">David Cox</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yingyan Lin</a>",
          "description": "While maximizing deep neural networks' (DNNs') acceleration efficiency\nrequires a joint search/design of three different yet highly coupled aspects,\nincluding the networks, bitwidths, and accelerators, the challenges associated\nwith such a joint search have not yet been fully understood and addressed. The\nkey challenges include (1) the dilemma of whether to explode the memory\nconsumption due to the huge joint space or achieve sub-optimal designs, (2) the\ndiscrete nature of the accelerator design space that is coupled yet different\nfrom that of the networks and bitwidths, and (3) the chicken and egg problem\nassociated with network-accelerator co-search, i.e., co-search requires\noperation-wise hardware cost, which is lacking during search as the optimal\naccelerator depending on the whole network is still unknown during search. To\ntackle these daunting challenges towards optimal and fast development of DNN\naccelerators, we propose a framework dubbed Auto-NBA to enable jointly\nsearching for the Networks, Bitwidths, and Accelerators, by efficiently\nlocalizing the optimal design within the huge joint design space for each\ntarget dataset and acceleration specification. Our Auto-NBA integrates a\nheterogeneous sampling strategy to achieve unbiased search with constant memory\nconsumption, and a novel joint-search pipeline equipped with a generic\ndifferentiable accelerator search engine. Extensive experiments and ablation\nstudies validate that both Auto-NBA generated networks and accelerators\nconsistently outperform state-of-the-art designs (including\nco-search/exploration techniques, hardware-aware NAS methods, and DNN\naccelerators), in terms of search time, task accuracy, and accelerator\nefficiency. Our codes are available at: https://github.com/RICE-EIC/Auto-NBA.",
          "link": "http://arxiv.org/abs/2106.06575",
          "publishedOn": "2021-06-15T01:45:18.779Z",
          "wordCount": 685,
          "title": "Auto-NBA: Efficient and Effective Search Over the Joint Space of Networks, Bitwidths, and Accelerators. (arXiv:2106.06575v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06624",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Leino_K/0/1/0/all/0/1\">Klas Leino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fredrikson_M/0/1/0/all/0/1\">Matt Fredrikson</a>",
          "description": "Certifiable local robustness, which rigorously precludes small-norm\nadversarial examples, has received significant attention as a means of\naddressing security concerns in deep learning. However, for some classification\nproblems, local robustness is not a natural objective, even in the presence of\nadversaries; for example, if an image contains two classes of subjects, the\ncorrect label for the image may be considered arbitrary between the two, and\nthus enforcing strict separation between them is unnecessary. In this work, we\nintroduce two relaxed safety properties for classifiers that address this\nobservation: (1) relaxed top-k robustness, which serves as the analogue of\ntop-k accuracy; and (2) affinity robustness, which specifies which sets of\nlabels must be separated by a robustness margin, and which can be\n$\\epsilon$-close in $\\ell_p$ space. We show how to construct models that can be\nefficiently certified against each relaxed robustness property, and trained\nwith very little overhead relative to standard gradient descent. Finally, we\ndemonstrate experimentally that these relaxed variants of robustness are\nwell-suited to several significant classification problems, leading to lower\nrejection rates and higher certified accuracies than can be obtained when\ncertifying \"standard\" local robustness.",
          "link": "http://arxiv.org/abs/2106.06624",
          "publishedOn": "2021-06-15T01:45:18.764Z",
          "wordCount": 597,
          "title": "Relaxing Local Robustness. (arXiv:2106.06624v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02968",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mahmood_R/0/1/0/all/0/1\">Rafid Mahmood</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fidler_S/0/1/0/all/0/1\">Sanja Fidler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Law_M/0/1/0/all/0/1\">Marc T. Law</a>",
          "description": "Given restrictions on the availability of data, active learning is the\nprocess of training a model with limited labeled data by selecting a core\nsubset of an unlabeled data pool to label. Although selecting the most useful\npoints for training is an optimization problem, the scale of deep learning data\nsets forces most selection strategies to employ efficient heuristics. Instead,\nwe propose a new integer optimization problem for selecting a core set that\nminimizes the discrete Wasserstein distance from the unlabeled pool. We\ndemonstrate that this problem can be tractably solved with a Generalized\nBenders Decomposition algorithm. Our strategy requires high-quality latent\nfeatures which we obtain by unsupervised learning on the unlabeled pool.\nNumerical results on several data sets show that our optimization approach is\ncompetitive with baselines and particularly outperforms them in the low budget\nregime where less than one percent of the data set is labeled.",
          "link": "http://arxiv.org/abs/2106.02968",
          "publishedOn": "2021-06-15T01:45:18.727Z",
          "wordCount": 599,
          "title": "Low Budget Active Learning via Wasserstein Distance: An Integer Programming Approach. (arXiv:2106.02968v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03153",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Min_D/0/1/0/all/0/1\">Dongchan Min</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_D/0/1/0/all/0/1\">Dong Bok Lee</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_E/0/1/0/all/0/1\">Eunho Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hwang_S/0/1/0/all/0/1\">Sung Ju Hwang</a>",
          "description": "With rapid progress in neural text-to-speech (TTS) models, personalized\nspeech generation is now in high demand for many applications. For practical\napplicability, a TTS model should generate high-quality speech with only a few\naudio samples from the given speaker, that are also short in length. However,\nexisting methods either require to fine-tune the model or achieve low\nadaptation quality without fine-tuning. In this work, we propose StyleSpeech, a\nnew TTS model which not only synthesizes high-quality speech but also\neffectively adapts to new speakers. Specifically, we propose Style-Adaptive\nLayer Normalization (SALN) which aligns gain and bias of the text input\naccording to the style extracted from a reference speech audio. With SALN, our\nmodel effectively synthesizes speech in the style of the target speaker even\nfrom single speech audio. Furthermore, to enhance StyleSpeech's adaptation to\nspeech from new speakers, we extend it to Meta-StyleSpeech by introducing two\ndiscriminators trained with style prototypes, and performing episodic training.\nThe experimental results show that our models generate high-quality speech\nwhich accurately follows the speaker's voice with single short-duration (1-3\nsec) speech audio, significantly outperforming baselines.",
          "link": "http://arxiv.org/abs/2106.03153",
          "publishedOn": "2021-06-15T01:45:18.700Z",
          "wordCount": 645,
          "title": "Meta-StyleSpeech : Multi-Speaker Adaptive Text-to-Speech Generation. (arXiv:2106.03153v2 [eess.AS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.05390",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yoo_J/0/1/0/all/0/1\">Jason Yoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joseph_T/0/1/0/all/0/1\">Tony Joseph</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yung_D/0/1/0/all/0/1\">Dylan Yung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nasseri_S/0/1/0/all/0/1\">S. Ali Nasseri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wood_F/0/1/0/all/0/1\">Frank Wood</a>",
          "description": "There are currently many barriers that prevent non-experts from exploiting\nmachine learning solutions ranging from the lack of intuition on statistical\nlearning techniques to the trickiness of hyperparameter tuning. Such barriers\nhave led to an explosion of interest in automated machine learning (AutoML),\nwhereby an off-the-shelf system can take care of many of the steps for\nend-users without the need for expertise in machine learning. This paper\npresents Ensemble Squared (Ensemble$^2$), an AutoML system that ensembles the\nresults of state-of-the-art open-source AutoML systems. Ensemble$^2$ exploits\nthe diversity of existing AutoML systems by leveraging the differences in their\nmodel search space and heuristics. Empirically, we show that diversity of each\nAutoML system is sufficient to justify ensembling at the AutoML system level.\nIn demonstrating this, we also establish new state-of-the-art AutoML results on\nthe OpenML tabular classification benchmark.",
          "link": "http://arxiv.org/abs/2012.05390",
          "publishedOn": "2021-06-15T01:45:18.406Z",
          "wordCount": 591,
          "title": "Ensemble Squared: A Meta AutoML System. (arXiv:2012.05390v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.04222",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Iqbal_S/0/1/0/all/0/1\">Shariq Iqbal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Witt_C/0/1/0/all/0/1\">Christian A. Schroeder de Witt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1\">Bei Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bohmer_W/0/1/0/all/0/1\">Wendelin B&#xf6;hmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Whiteson_S/0/1/0/all/0/1\">Shimon Whiteson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sha_F/0/1/0/all/0/1\">Fei Sha</a>",
          "description": "Multi-agent settings in the real world often involve tasks with varying types\nand quantities of agents and non-agent entities; however, common patterns of\nbehavior often emerge among these agents/entities. Our method aims to leverage\nthese commonalities by asking the question: ``What is the expected utility of\neach agent when only considering a randomly selected sub-group of its observed\nentities?'' By posing this counterfactual question, we can recognize\nstate-action trajectories within sub-groups of entities that we may have\nencountered in another task and use what we learned in that task to inform our\nprediction in the current one. We then reconstruct a prediction of the full\nreturns as a combination of factors considering these disjoint groups of\nentities and train this ``randomly factorized\" value function as an auxiliary\nobjective for value-based multi-agent reinforcement learning. By doing so, our\nmodel can recognize and leverage similarities across tasks to improve learning\nefficiency in a multi-task setting. Our approach, Randomized Entity-wise\nFactorization for Imagined Learning (REFIL), outperforms all strong baselines\nby a significant margin in challenging multi-task StarCraft micromanagement\nsettings.",
          "link": "http://arxiv.org/abs/2006.04222",
          "publishedOn": "2021-06-15T01:45:18.397Z",
          "wordCount": 666,
          "title": "Randomized Entity-wise Factorization for Multi-Agent Reinforcement Learning. (arXiv:2006.04222v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06957",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_F/0/1/0/all/0/1\">Feng Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ning_Y/0/1/0/all/0/1\">Yilin Ning</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1\">Han Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldstein_B/0/1/0/all/0/1\">Benjamin Alan Goldstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ong_M/0/1/0/all/0/1\">Marcus Eng Hock Ong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1\">Nan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_B/0/1/0/all/0/1\">Bibhas Chakraborty</a>",
          "description": "Scoring systems are highly interpretable and widely used to evaluate\ntime-to-event outcomes in healthcare research. However, existing time-to-event\nscores are predominantly created ad-hoc using a few manually selected variables\nbased on clinician's knowledge, suggesting an unmet need for a robust and\nefficient generic score-generating method.\n\nAutoScore was previously developed as an interpretable machine learning score\ngenerator, integrated both machine learning and point-based scores in the\nstrong discriminability and accessibility. We have further extended it to\ntime-to-event data and developed AutoScore-Survival, for automatically\ngenerating time-to-event scores with right-censored survival data. Random\nsurvival forest provides an efficient solution for selecting variables, and Cox\nregression was used for score weighting. We illustrated our method in a\nreal-life study of 90-day mortality of patients in intensive care units and\ncompared its performance with survival models (i.e., Cox) and the random\nsurvival forest.\n\nThe AutoScore-Survival-derived scoring model was more parsimonious than\nsurvival models built using traditional variable selection methods (e.g.,\npenalized likelihood approach and stepwise variable selection), and its\nperformance was comparable to survival models using the same set of variables.\nAlthough AutoScore-Survival achieved a comparable integrated area under the\ncurve of 0.782 (95% CI: 0.767-0.794), the integer-valued time-to-event scores\ngenerated are favorable in clinical applications because they are easier to\ncompute and interpret.\n\nOur proposed AutoScore-Survival provides an automated, robust and easy-to-use\nmachine learning-based clinical score generator to studies of time-to-event\noutcomes. It provides a systematic guideline to facilitate the future\ndevelopment of time-to-event scores for clinical applications.",
          "link": "http://arxiv.org/abs/2106.06957",
          "publishedOn": "2021-06-15T01:45:18.378Z",
          "wordCount": 681,
          "title": "AutoScore-Survival: Developing interpretable machine learning-based time-to-event scores with right-censored survival data. (arXiv:2106.06957v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09369",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wainakh_A/0/1/0/all/0/1\">Aidmar Wainakh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ventola_F/0/1/0/all/0/1\">Fabrizio Ventola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mussig_T/0/1/0/all/0/1\">Till M&#xfc;&#xdf;ig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keim_J/0/1/0/all/0/1\">Jens Keim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cordero_C/0/1/0/all/0/1\">Carlos Garcia Cordero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zimmer_E/0/1/0/all/0/1\">Ephraim Zimmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grube_T/0/1/0/all/0/1\">Tim Grube</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kersting_K/0/1/0/all/0/1\">Kristian Kersting</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muhlhauser_M/0/1/0/all/0/1\">Max M&#xfc;hlh&#xe4;user</a>",
          "description": "Federated learning enables multiple users to build a joint model by sharing\ntheir model updates (gradients), while their raw data remains local on their\ndevices. In contrast to the common belief that this provides privacy benefits,\nwe here add to the very recent results on privacy risks when sharing gradients.\nSpecifically, we propose Label Leakage from Gradients (LLG), a novel attack to\nextract the labels of the users' training data from their shared gradients. The\nattack exploits the direction and magnitude of gradients to determine the\npresence or absence of any label. LLG is simple yet effective, capable of\nleaking potential sensitive information represented by labels, and scales well\nto arbitrary batch sizes and multiple classes. We empirically and\nmathematically demonstrate the validity of our attack under different settings.\nMoreover, empirical results show that LLG successfully extracts labels with\nhigh accuracy at the early stages of model training. We also discuss different\ndefense mechanisms against such leakage. Our findings suggest that gradient\ncompression is a practical technique to prevent our attack.",
          "link": "http://arxiv.org/abs/2105.09369",
          "publishedOn": "2021-06-15T01:45:18.371Z",
          "wordCount": 650,
          "title": "User Label Leakage from Gradients in Federated Learning. (arXiv:2105.09369v3 [cs.CR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06964",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tikhonov_A/0/1/0/all/0/1\">Alexey Tikhonov</a>",
          "description": "Pre-trained word representations became a key component in many NLP tasks.\nHowever, the global geometry of the word embeddings remains poorly understood.\nIn this paper, we demonstrate that a typical word embeddings cloud is shaped as\na high-dimensional simplex with interpretable vertices and propose a simple yet\neffective method for enumeration of these vertices. We show that the proposed\nmethod can detect and describe vertices of the simplex for GloVe and fasttext\nspaces.",
          "link": "http://arxiv.org/abs/2106.06964",
          "publishedOn": "2021-06-15T01:45:18.360Z",
          "wordCount": 514,
          "title": "Shape of Elephant: Study of Macro Properties of Word Embeddings Spaces. (arXiv:2106.06964v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2011.11057",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhao-Zhou Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_Z/0/1/0/all/0/1\">Zhengyi Shao</a>",
          "description": "The Gaussian process (GP) regression can be severely biased when the data are\ncontaminated by outliers. This paper presents a new robust GP regression\nalgorithm that iteratively trims the most extreme data points. While the new\nalgorithm retains the attractive properties of the standard GP as a\nnonparametric and flexible regression method, it can greatly improve the model\naccuracy for contaminated data even in the presence of extreme or abundant\noutliers. It is also easier to implement compared with previous robust GP\nvariants that rely on approximate inference. Applied to a wide range of\nexperiments with different contamination levels, the proposed method\nsignificantly outperforms the standard GP and the popular robust GP variant\nwith the Student-t likelihood in most test cases. In addition, as a practical\nexample in the astrophysical study, we show that this method can precisely\ndetermine the main-sequence ridge line in the color-magnitude diagram of star\nclusters.",
          "link": "http://arxiv.org/abs/2011.11057",
          "publishedOn": "2021-06-15T01:45:18.336Z",
          "wordCount": 633,
          "title": "Robust Gaussian Process Regression Based on Iterative Trimming. (arXiv:2011.11057v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06662",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shakerinava_M/0/1/0/all/0/1\">Mehran Shakerinava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ravanbakhsh_S/0/1/0/all/0/1\">Siamak Ravanbakhsh</a>",
          "description": "Pixelizations of Platonic solids such as the cube and icosahedron have been\nwidely used to represent spherical data, from climate records to Cosmic\nMicrowave Background maps. Platonic solids have well-known global symmetries.\nOnce we pixelize each face of the solid, each face also possesses its own local\nsymmetries in the form of Euclidean isometries. One way to combine these\nsymmetries is through a hierarchy. However, this approach does not adequately\nmodel the interplay between the two levels of symmetry transformations. We show\nhow to model this interplay using ideas from group theory, identify the\nequivariant linear maps, and introduce equivariant padding that respects these\nsymmetries. Deep networks that use these maps as their building blocks\ngeneralize gauge equivariant CNNs on pixelized spheres. These deep networks\nachieve state-of-the-art results on semantic segmentation for climate data and\nomnidirectional image processing. Code is available at https://git.io/JGiZA.",
          "link": "http://arxiv.org/abs/2106.06662",
          "publishedOn": "2021-06-15T01:45:18.324Z",
          "wordCount": 564,
          "title": "Equivariant Networks for Pixelized Spheres. (arXiv:2106.06662v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06777",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hahn_E/0/1/0/all/0/1\">Ernst Moritz Hahn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perez_M/0/1/0/all/0/1\">Mateo Perez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schewe_S/0/1/0/all/0/1\">Sven Schewe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Somenzi_F/0/1/0/all/0/1\">Fabio Somenzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trivedi_A/0/1/0/all/0/1\">Ashutosh Trivedi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wojtczak_D/0/1/0/all/0/1\">Dominik Wojtczak</a>",
          "description": "We study reinforcement learning for the optimal control of Branching Markov\nDecision Processes (BMDPs), a natural extension of (multitype) Branching Markov\nChains (BMCs). The state of a (discrete-time) BMCs is a collection of entities\nof various types that, while spawning other entities, generate a payoff. In\ncomparison with BMCs, where the evolution of a each entity of the same type\nfollows the same probabilistic pattern, BMDPs allow an external controller to\npick from a range of options. This permits us to study the best/worst behaviour\nof the system. We generalise model-free reinforcement learning techniques to\ncompute an optimal control strategy of an unknown BMDP in the limit. We present\nresults of an implementation that demonstrate the practicality of the approach.",
          "link": "http://arxiv.org/abs/2106.06777",
          "publishedOn": "2021-06-15T01:45:18.273Z",
          "wordCount": 568,
          "title": "Model-free Reinforcement Learning for Branching Markov Decision Processes. (arXiv:2106.06777v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2012.12854",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Wu_Z/0/1/0/all/0/1\">Zhaolong Wu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhang_S/0/1/0/all/0/1\">Shuwen Zhang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Wang_W/0/1/0/all/0/1\">Wei Li Wang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ma_Y/0/1/0/all/0/1\">Yinping Ma</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Dong_Y/0/1/0/all/0/1\">Yuanchen Dong</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Mao_Y/0/1/0/all/0/1\">Youdong Mao</a>",
          "description": "The 2.5-MDa 26S proteasome maintains proteostasis and regulates myriad\ncellular processes. How polyubiquitylated substrate interactions regulate\nproteasome activity is not understood. Here we introduce a deep manifold\nlearning framework, named AlphaCryo4D, which enables atomic-level cryogenic\nelectron microscopy (cryo-EM) reconstructions of nonequilibrium conformational\ncontinuum and reconstitutes hidden dynamics of proteasome autoregulation in the\nact of substrate degradation. AlphaCryo4D integrates 3D deep residual learning\nwith manifold embedding of free-energy landscapes, which directs 3D clustering\nvia an energy-based particle-voting algorithm. In blind assessments using\nsimulated heterogeneous cryo-EM datasets, AlphaCryo4D achieved 3D\nclassification accuracy three times that of conventional method and\nreconstructed continuous conformational changes of a 130-kDa protein at\nsub-3-angstrom resolution. By using AlphaCryo4D to analyze a single\nexperimental cryo-EM dataset, we identified 64 conformers of the\nsubstrate-bound human 26S proteasome, revealing conformational entanglement of\ntwo regulatory particles in the doubly capped holoenzymes and their energetic\ndifferences with singly capped ones. Novel ubiquitin-binding sites are\ndiscovered on the RPN2, RPN10 and Alpha5 subunits to remodel polyubiquitin\nchains for deubiquitylation and recycle. Importantly, AlphaCryo4D choreographs\nsingle-nucleotide-exchange dynamics of proteasomal AAA-ATPase motor during\ntranslocation initiation, which upregulates proteolytic activity by\nallosterically promoting nucleophilic attack. Our systemic analysis illuminates\na grand hierarchical allostery for proteasome autoregulation.",
          "link": "http://arxiv.org/abs/2012.12854",
          "publishedOn": "2021-06-15T01:45:18.267Z",
          "wordCount": 671,
          "title": "Deep manifold learning reveals hidden dynamics of proteasome autoregulation. (arXiv:2012.12854v2 [q-bio.QM] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.13658",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Amin_S/0/1/0/all/0/1\">Susan Amin</a> (1 and 2), <a href=\"http://arxiv.org/find/cs/1/au:+Gomrokchi_M/0/1/0/all/0/1\">Maziar Gomrokchi</a> (1 and 2), <a href=\"http://arxiv.org/find/cs/1/au:+Aboutalebi_H/0/1/0/all/0/1\">Hossein Aboutalebi</a> (3), <a href=\"http://arxiv.org/find/cs/1/au:+Satija_H/0/1/0/all/0/1\">Harsh Satija</a> (1 and 2), <a href=\"http://arxiv.org/find/cs/1/au:+Precup_D/0/1/0/all/0/1\">Doina Precup</a> (1 and 2) ((1) McGill University, (2) Mila- Quebec Artificial Intelligence Institute, (3) University of Waterloo)",
          "description": "A major challenge in reinforcement learning is the design of exploration\nstrategies, especially for environments with sparse reward structures and\ncontinuous state and action spaces. Intuitively, if the reinforcement signal is\nvery scarce, the agent should rely on some form of short-term memory in order\nto cover its environment efficiently. We propose a new exploration method,\nbased on two intuitions: (1) the choice of the next exploratory action should\ndepend not only on the (Markovian) state of the environment, but also on the\nagent's trajectory so far, and (2) the agent should utilize a measure of spread\nin the state space to avoid getting stuck in a small region. Our method\nleverages concepts often used in statistical physics to provide explanations\nfor the behavior of simplified (polymer) chains in order to generate persistent\n(locally self-avoiding) trajectories in state space. We discuss the theoretical\nproperties of locally self-avoiding walks and their ability to provide a kind\nof short-term memory through a decaying temporal correlation within the\ntrajectory. We provide empirical evaluations of our approach in a simulated 2D\nnavigation task, as well as higher-dimensional MuJoCo continuous control\nlocomotion tasks with sparse rewards.",
          "link": "http://arxiv.org/abs/2012.13658",
          "publishedOn": "2021-06-15T01:45:18.261Z",
          "wordCount": 683,
          "title": "Locally Persistent Exploration in Continuous Control Tasks with Sparse Rewards. (arXiv:2012.13658v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.05145",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+ODonoghue_B/0/1/0/all/0/1\">Brendan O&#x27;Donoghue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lattimore_T/0/1/0/all/0/1\">Tor Lattimore</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Osband_I/0/1/0/all/0/1\">Ian Osband</a>",
          "description": "We study a version of the classical zero-sum matrix game with unknown payoff\nmatrix and bandit feedback, where the players only observe each others actions\nand a noisy payoff. This generalizes the usual matrix game, where the payoff\nmatrix is known to the players. Despite numerous applications, this problem has\nreceived relatively little attention. Although adversarial bandit algorithms\nachieve low regret, they do not exploit the matrix structure and perform poorly\nrelative to the new algorithms. The main contributions are regret analyses of\nvariants of UCB and K-learning that hold for any opponent, e.g., even when the\nopponent adversarially plays the best-response to the learner's mixed strategy.\nAlong the way, we show that Thompson fails catastrophically in this setting and\nprovide empirical comparison to existing algorithms.",
          "link": "http://arxiv.org/abs/2006.05145",
          "publishedOn": "2021-06-15T01:45:18.255Z",
          "wordCount": 578,
          "title": "Matrix games with bandit feedback. (arXiv:2006.05145v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06895",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Odetola_T/0/1/0/all/0/1\">Tolulope Odetola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khalid_F/0/1/0/all/0/1\">Faiq Khalid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sandefur_T/0/1/0/all/0/1\">Travis Sandefur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohammed_H/0/1/0/all/0/1\">Hawzhin Mohammed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasan_S/0/1/0/all/0/1\">Syed Rafay Hasan</a>",
          "description": "Convolutional Neural Networks (CNN) have shown impressive performance in\ncomputer vision, natural language processing, and many other applications, but\nthey exhibit high computations and substantial memory requirements. To address\nthese limitations, especially in resource-constrained devices, the use of cloud\ncomputing for CNNs is becoming more popular. This comes with privacy and\nlatency concerns that have motivated the designers to develop embedded hardware\naccelerators for CNNs. However, designing a specialized accelerator increases\nthe time-to-market and cost of production. Therefore, to reduce the\ntime-to-market and access to state-of-the-art techniques, CNN hardware mapping\nand deployment on embedded accelerators are often outsourced to untrusted third\nparties, which is going to be more prevalent in futuristic artificial\nintelligence of things (AIoT) systems. These AIoT systems anticipate horizontal\ncollaboration among different resource-constrained AIoT node devices, where CNN\nlayers are partitioned and these devices collaboratively compute complex CNN\ntasks Therefore, there is a dire need to explore this attack surface for\ndesigning secure embedded hardware accelerators for CNNs. Towards this goal, in\nthis paper, we exploited this attack surface to propose an HT-based attack\ncalled FeSHI. This attack exploits the statistical distribution i.e., Gaussian\ndistribution, of the layer-by-layer feature maps of the CNN to design two\ntriggers for stealthy HT with a very low probability of triggering. To\nillustrate the effectiveness of the proposed attack, we deployed the LeNet and\nLeNet-3D on PYNQ to classify the MNIST and CIFAR-10 datasets, respectively, and\ntested FeSHI. The experimental results show that FeSHI utilizes up to 2% extra\nLUTs, and the overall resource overhead is less than 1% compared to the\noriginal designs",
          "link": "http://arxiv.org/abs/2106.06895",
          "publishedOn": "2021-06-15T01:45:18.236Z",
          "wordCount": 700,
          "title": "FeSHI: Feature Map Based Stealthy Hardware Intrinsic Attack. (arXiv:2106.06895v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06596",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Noci_L/0/1/0/all/0/1\">Lorenzo Noci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_K/0/1/0/all/0/1\">Kevin Roth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bachmann_G/0/1/0/all/0/1\">Gregor Bachmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nowozin_S/0/1/0/all/0/1\">Sebastian Nowozin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hofmann_T/0/1/0/all/0/1\">Thomas Hofmann</a>",
          "description": "The \"cold posterior effect\" (CPE) in Bayesian deep learning describes the\nuncomforting observation that the predictive performance of Bayesian neural\nnetworks can be significantly improved if the Bayes posterior is artificially\nsharpened using a temperature parameter T<1. The CPE is problematic in theory\nand practice and since the effect was identified many researchers have proposed\nhypotheses to explain the phenomenon. However, despite this intensive research\neffort the effect remains poorly understood. In this work we provide novel and\nnuanced evidence relevant to existing explanations for the cold posterior\neffect, disentangling three hypotheses: 1. The dataset curation hypothesis of\nAitchison (2020): we show empirically that the CPE does not arise in a real\ncurated data set but can be produced in a controlled experiment with varying\ncuration strength. 2. The data augmentation hypothesis of Izmailov et al.\n(2021) and Fortuin et al. (2021): we show empirically that data augmentation is\nsufficient but not necessary for the CPE to be present. 3. The bad prior\nhypothesis of Wenzel et al. (2020): we use a simple experiment evaluating the\nrelative importance of the prior and the likelihood, strongly linking the CPE\nto the prior. Our results demonstrate how the CPE can arise in isolation from\nsynthetic curation, data augmentation, and bad priors. Cold posteriors observed\n\"in the wild\" are therefore unlikely to arise from a single simple cause; as a\nresult, we do not expect a simple \"fix\" for cold posteriors.",
          "link": "http://arxiv.org/abs/2106.06596",
          "publishedOn": "2021-06-15T01:45:18.194Z",
          "wordCount": 680,
          "title": "Disentangling the Roles of Curation, Data-Augmentation and the Prior in the Cold Posterior Effect. (arXiv:2106.06596v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2008.00483",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fu_Z/0/1/0/all/0/1\">Zuyue Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhuoran Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhaoran Wang</a>",
          "description": "We study the global convergence and global optimality of actor-critic, one of\nthe most popular families of reinforcement learning algorithms. While most\nexisting works on actor-critic employ bi-level or two-timescale updates, we\nfocus on the more practical single-timescale setting, where the actor and\ncritic are updated simultaneously. Specifically, in each iteration, the critic\nupdate is obtained by applying the Bellman evaluation operator only once while\nthe actor is updated in the policy gradient direction computed using the\ncritic. Moreover, we consider two function approximation settings where both\nthe actor and critic are represented by linear or deep neural networks. For\nboth cases, we prove that the actor sequence converges to a globally optimal\npolicy at a sublinear $O(K^{-1/2})$ rate, where $K$ is the number of\niterations. To the best of our knowledge, we establish the rate of convergence\nand global optimality of single-timescale actor-critic with linear function\napproximation for the first time. Moreover, under the broader scope of policy\noptimization with nonlinear function approximation, we prove that actor-critic\nwith deep neural network finds the globally optimal policy at a sublinear rate\nfor the first time.",
          "link": "http://arxiv.org/abs/2008.00483",
          "publishedOn": "2021-06-15T01:45:18.183Z",
          "wordCount": 644,
          "title": "Single-Timescale Actor-Critic Provably Finds Globally Optimal Policy. (arXiv:2008.00483v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.07639",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_H/0/1/0/all/0/1\">Hongyu Gong</a>",
          "description": "Multilingual models are parameter-efficient with the prospect improving\nlow-resource languages by leveraging crosslingual transfer. Despite recent\nadvance in massive multilingual translation with ever-growing model and data,\nhow to effectively train multilingual models has not been well understood. In\nthis paper, we show that a common situation in multilingual training, data\nimbalance among languages, poses optimization tension between high resource and\nlow resource languages where the found multilingual solution is often\nsub-optimal for low resources. We show that common training method which\nupsamples low resources can not robustly optimize population loss with risks of\neither underfitting high resource languages or overfitting low resource ones.\nDrawing on recent findings on the geometry of loss landscape and its effect on\ngeneralization, we propose a principled optimization algorithm, Curvature Aware\nTask Scaling (CATS), which adaptively rescales gradients from different tasks\nwith a meta objective of guiding multilingual training to low-curvature\nneighborhoods with uniformly low loss for all languages. We ran experiments on\ncommon benchmarks (TED, WMT and OPUS-100) with varying degrees of data\nimbalance. CATS effectively improved multilingual optimization and as a result\ndemonstrated consistent gains on low resources ( to BLEU) without hurting high\nresources. In addition, CATS is robust to overparameterization and large batch\nsize training, making it a promising training method for massive multilingual\nmodels that truly improve low resource languages.",
          "link": "http://arxiv.org/abs/2104.07639",
          "publishedOn": "2021-06-15T01:45:18.156Z",
          "wordCount": 685,
          "title": "Robust Optimization for Multilingual Translation with Imbalanced Data. (arXiv:2104.07639v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06947",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_A/0/1/0/all/0/1\">Ailin Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hooi_B/0/1/0/all/0/1\">Bryan Hooi</a>",
          "description": "Given high-dimensional time series data (e.g., sensor data), how can we\ndetect anomalous events, such as system faults and attacks? More challengingly,\nhow can we do this in a way that captures complex inter-sensor relationships,\nand detects and explains anomalies which deviate from these relationships?\nRecently, deep learning approaches have enabled improvements in anomaly\ndetection in high-dimensional datasets; however, existing methods do not\nexplicitly learn the structure of existing relationships between variables, or\nuse them to predict the expected behavior of time series. Our approach combines\na structure learning approach with graph neural networks, additionally using\nattention weights to provide explainability for the detected anomalies.\nExperiments on two real-world sensor datasets with ground truth anomalies show\nthat our method detects anomalies more accurately than baseline approaches,\naccurately captures correlations between sensors, and allows users to deduce\nthe root cause of a detected anomaly.",
          "link": "http://arxiv.org/abs/2106.06947",
          "publishedOn": "2021-06-15T01:45:18.141Z",
          "wordCount": 578,
          "title": "Graph Neural Network-Based Anomaly Detection in Multivariate Time Series. (arXiv:2106.06947v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2103.00164",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Menglin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Z/0/1/0/all/0/1\">Ziqiao Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+King_I/0/1/0/all/0/1\">Irwin King</a>",
          "description": "Dynamic graphs arise in a plethora of practical scenarios such as social\nnetworks, communication networks, and financial transaction networks. Given a\ndynamic graph, it is fundamental and essential to learn a graph representation\nthat is expected not only to preserve structural proximity but also jointly\ncapture the time-evolving patterns. Recently, graph convolutional network (GCN)\nhas been widely explored and used in non-Euclidean application domains. The\nmain success of GCN, especially in handling dependencies and passing messages\nwithin nodes, lies in its approximation to Laplacian smoothing. As a matter of\nfact, this smoothing technique can not only encourage must-link node pairs to\nget closer but also push cannot-link pairs to shrink together, which\npotentially cause serious feature shrink or oversmoothing problem, especially\nwhen stacking graph convolution in multiple layers or steps. For learning\ntime-evolving patterns, a natural solution is to preserve historical state and\ncombine it with the current interactions to obtain the most recent\nrepresentation. Then the serious feature shrink or oversmoothing problem could\nhappen when stacking graph convolution explicitly or implicitly according to\ncurrent prevalent methods, which would make nodes too similar to distinguish\neach other. To solve this problem in dynamic graph embedding, we analyze the\nshrinking properties in the node embedding space at first, and then design a\nsimple yet versatile method, which exploits L2 feature normalization constraint\nto rescale all nodes to hypersphere of a unit ball so that nodes would not\nshrink together, and yet similar nodes can still get closer. Extensive\nexperiments on four real-world dynamic graph datasets compared with competitive\nbaseline models demonstrate the effectiveness of the proposed method.",
          "link": "http://arxiv.org/abs/2103.00164",
          "publishedOn": "2021-06-15T01:45:18.070Z",
          "wordCount": 720,
          "title": "FeatureNorm: L2 Feature Normalization for Dynamic Graph Embedding. (arXiv:2103.00164v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.13962",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Leibfried_F/0/1/0/all/0/1\">Felix Leibfried</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dutordoir_V/0/1/0/all/0/1\">Vincent Dutordoir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+John_S/0/1/0/all/0/1\">ST John</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durrande_N/0/1/0/all/0/1\">Nicolas Durrande</a>",
          "description": "Gaussian processes (GPs) provide a framework for Bayesian inference that can\noffer principled uncertainty estimates for a large range of problems. For\nexample, if we consider regression problems with Gaussian likelihoods, a GP\nmodel enjoys a posterior in closed form. However, identifying the posterior GP\nscales cubically with the number of training examples and requires to store all\nexamples in memory. In order to overcome these obstacles, sparse GPs have been\nproposed that approximate the true posterior GP with pseudo-training examples.\nImportantly, the number of pseudo-training examples is user-defined and enables\ncontrol over computational and memory complexity. In the general case, sparse\nGPs do not enjoy closed-form solutions and one has to resort to approximate\ninference. In this context, a convenient choice for approximate inference is\nvariational inference (VI), where the problem of Bayesian inference is cast as\nan optimization problem -- namely, to maximize a lower bound of the log\nmarginal likelihood. This paves the way for a powerful and versatile framework,\nwhere pseudo-training examples are treated as optimization arguments of the\napproximate posterior that are jointly identified together with hyperparameters\nof the generative model (i.e. prior and likelihood). The framework can\nnaturally handle a wide scope of supervised learning problems, ranging from\nregression with heteroscedastic and non-Gaussian likelihoods to classification\nproblems with discrete labels, but also multilabel problems. The purpose of\nthis tutorial is to provide access to the basic matter for readers without\nprior knowledge in both GPs and VI. A proper exposition to the subject enables\nalso access to more recent advances (like importance-weighted VI as well as\ninterdomain, multioutput and deep GPs) that can serve as an inspiration for new\nresearch ideas.",
          "link": "http://arxiv.org/abs/2012.13962",
          "publishedOn": "2021-06-15T01:45:18.022Z",
          "wordCount": 810,
          "title": "A Tutorial on Sparse Gaussian Processes and Variational Inference. (arXiv:2012.13962v10 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2002.04839",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ziyin_L/0/1/0/all/0/1\">Liu Ziyin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhikang T.Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ueda_M/0/1/0/all/0/1\">Masahito Ueda</a>",
          "description": "We identity a by-far-unrecognized problem of Adam-style optimizers which\nresults from unnecessary coupling between momentum and adaptivity. The coupling\nleads to instability and divergence when the momentum and adaptivity parameters\nare mismatched. In this work, we propose a method, Laprop, which decouples\nmomentum and adaptivity in the Adam-style methods. We show that the decoupling\nleads to greater flexibility in the hyperparameters and allows for a\nstraightforward interpolation between the signed gradient methods and the\nadaptive gradient methods. We experimentally show that Laprop has consistently\nimproved speed and stability over Adam on a variety of tasks. We also bound the\nregret of Laprop on a convex problem and show that our bound differs from that\nof Adam by a key factor, which demonstrates its advantage.",
          "link": "http://arxiv.org/abs/2002.04839",
          "publishedOn": "2021-06-15T01:45:18.015Z",
          "wordCount": 587,
          "title": "LaProp: Separating Momentum and Adaptivity in Adam. (arXiv:2002.04839v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06788",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qiufeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_X/0/1/0/all/0/1\">Xin Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1\">Shuxia Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_S/0/1/0/all/0/1\">Shiyu Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_L/0/1/0/all/0/1\">Lei Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_N/0/1/0/all/0/1\">Ning Xu</a>",
          "description": "Although deep learning has made significant progress on fixed large-scale\ndatasets, it typically encounters challenges regarding improperly detecting\nnew/unseen classes in the open-world classification, over-parametrized, and\noverfitting small samples. In contrast, biological systems can overcome the\nabove difficulties very well. Individuals inherit an innate gene from\ncollective creatures that have evolved over hundreds of millions of years, and\ncan learn new skills through a few examples. Inspired by this, we propose a\npractical collective-individual paradigm where open-world tasks are trained in\nsequence using an evolution (expandable) network. To be specific, we\ninnovatively introduce learngene that inherits the meta-knowledge from the\ncollective model and reconstructs a new lightweight individual model for the\ntarget task, to realize the collective-individual paradigm. Particularly, we\npresent a novel criterion that can discover the learngene in the collective\nmodel, according to the gradient information. Finally, the individual model is\ntrained only with a few samples in the absence of the source data. We\ndemonstrate the effectiveness of our approach in an extensive empirical study\nand theoretical analysis.",
          "link": "http://arxiv.org/abs/2106.06788",
          "publishedOn": "2021-06-15T01:45:17.959Z",
          "wordCount": 601,
          "title": "Learngene: From Open-World to Your Learning Task. (arXiv:2106.06788v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2101.07393",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hanjie_A/0/1/0/all/0/1\">Austin W. Hanjie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_V/0/1/0/all/0/1\">Victor Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narasimhan_K/0/1/0/all/0/1\">Karthik Narasimhan</a>",
          "description": "We investigate the use of natural language to drive the generalization of\ncontrol policies and introduce the new multi-task environment Messenger with\nfree-form text manuals describing the environment dynamics. Unlike previous\nwork, Messenger does not assume prior knowledge connecting text and state\nobservations $-$ the control policy must simultaneously ground the game manual\nto entity symbols and dynamics in the environment. We develop a new model, EMMA\n(Entity Mapper with Multi-modal Attention) which uses an entity-conditioned\nattention module that allows for selective focus over relevant descriptions in\nthe manual for each entity in the environment. EMMA is end-to-end\ndifferentiable and learns a latent grounding of entities and dynamics from text\nto observations using only environment rewards. EMMA achieves successful\nzero-shot generalization to unseen games with new dynamics, obtaining a 40%\nhigher win rate compared to multiple baselines. However, win rate on the\nhardest stage of Messenger remains low (10%), demonstrating the need for\nadditional work in this direction.",
          "link": "http://arxiv.org/abs/2101.07393",
          "publishedOn": "2021-06-15T01:45:17.930Z",
          "wordCount": 638,
          "title": "Grounding Language to Entities and Dynamics for Generalization in Reinforcement Learning. (arXiv:2101.07393v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.04657",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sandler_M/0/1/0/all/0/1\">Mark Sandler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vladymyrov_M/0/1/0/all/0/1\">Max Vladymyrov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhmoginov_A/0/1/0/all/0/1\">Andrey Zhmoginov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miller_N/0/1/0/all/0/1\">Nolan Miller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jackson_A/0/1/0/all/0/1\">Andrew Jackson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madams_T/0/1/0/all/0/1\">Tom Madams</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arcas_B/0/1/0/all/0/1\">Blaise Aguera y Arcas</a>",
          "description": "In this paper, we introduce a new type of generalized neural network where\nneurons and synapses maintain multiple states. We show that classical\ngradient-based backpropagation in neural networks can be seen as a special case\nof a two-state network where one state is used for activations and another for\ngradients, with update rules derived from the chain rule. In our generalized\nframework, networks have neither explicit notion of nor ever receive gradients.\nThe synapses and neurons are updated using a bidirectional Hebb-style update\nrule parameterized by a shared low-dimensional \"genome\". We show that such\ngenomes can be meta-learned from scratch, using either conventional\noptimization techniques, or evolutionary strategies, such as CMA-ES. Resulting\nupdate rules generalize to unseen tasks and train faster than gradient descent\nbased optimizers for several standard computer vision and synthetic tasks.",
          "link": "http://arxiv.org/abs/2104.04657",
          "publishedOn": "2021-06-15T01:45:17.924Z",
          "wordCount": 600,
          "title": "Meta-Learning Bidirectional Update Rules. (arXiv:2104.04657v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06680",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_M/0/1/0/all/0/1\">Mridul Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_Q/0/1/0/all/0/1\">Qinbo Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aggarwal_V/0/1/0/all/0/1\">Vaneet Aggarwal</a>",
          "description": "We consider the problem of constrained Markov Decision Process (CMDP) where\nan agent interacts with a unichain Markov Decision Process. At every\ninteraction, the agent obtains a reward. Further, there are $K$ cost functions.\nThe agent aims to maximize the long-term average reward while simultaneously\nkeeping the $K$ long-term average costs lower than a certain threshold. In this\npaper, we propose CMDP-PSRL, a posterior sampling based algorithm using which\nthe agent can learn optimal policies to interact with the CMDP. Further, for\nMDP with $S$ states, $A$ actions, and diameter $D$, we prove that following\nCMDP-PSRL algorithm, the agent can bound the regret of not accumulating rewards\nfrom optimal policy by $\\Tilde{O}(poly(DSA)\\sqrt{T})$. Further, we show that\nthe violations for any of the $K$ constraints is also bounded by\n$\\Tilde{O}(poly(DSA)\\sqrt{T})$. To the best of our knowledge, this is the first\nwork which obtains a $\\Tilde{O}(\\sqrt{T})$ regret bounds for ergodic MDPs with\nlong-term average constraints.",
          "link": "http://arxiv.org/abs/2106.06680",
          "publishedOn": "2021-06-15T01:45:17.918Z",
          "wordCount": 583,
          "title": "Markov Decision Processes with Long-Term Average Constraints. (arXiv:2106.06680v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.09626",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wenjie Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barik_A/0/1/0/all/0/1\">Adarsh Barik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Honorio_J/0/1/0/all/0/1\">Jean Honorio</a>",
          "description": "Stochastic high dimensional bandit problems with low dimensional structures\nare useful in different applications such as online advertising and drug\ndiscovery. In this work, we propose a simple unified algorithm for such\nproblems and present a general analysis framework for the regret upper bound of\nour algorithm. We show that under some mild unified assumptions, our algorithm\ncan be applied to different high dimensional bandit problems. Our framework\nutilizes the low dimensional structure to guide the parameter estimation in the\nproblem, therefore our algorithm achieves the best regret bounds in the LASSO\nbandit, as well as novel bounds in the low-rank matrix bandit, the group sparse\nmatrix bandit, and in a new problem: the multi-agent LASSO bandit.",
          "link": "http://arxiv.org/abs/2102.09626",
          "publishedOn": "2021-06-15T01:45:17.912Z",
          "wordCount": 574,
          "title": "A Simple Unified Framework for High Dimensional Bandit Problems. (arXiv:2102.09626v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06842",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Keynan_S/0/1/0/all/0/1\">Shai Keynan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarafian_E/0/1/0/all/0/1\">Elad Sarafian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kraus_S/0/1/0/all/0/1\">Sarit Kraus</a>",
          "description": "The Reinforcement Learning (RL) building blocks, i.e. Q-functions and policy\nnetworks, usually take elements from the cartesian product of two domains as\ninput. In particular, the input of the Q-function is both the state and the\naction, and in multi-task problems (Meta-RL) the policy can take a state and a\ncontext. Standard architectures tend to ignore these variables' underlying\ninterpretations and simply concatenate their features into a single vector. In\nthis work, we argue that this choice may lead to poor gradient estimation in\nactor-critic algorithms and high variance learning steps in Meta-RL algorithms.\nTo consider the interaction between the input variables, we suggest using a\nHypernetwork architecture where a primary network determines the weights of a\nconditional dynamic network. We show that this approach improves the gradient\napproximation and reduces the learning step variance, which both accelerates\nlearning and improves the final performance. We demonstrate a consistent\nimprovement across different locomotion tasks and different algorithms both in\nRL (TD3 and SAC) and in Meta-RL (MAML and PEARL).",
          "link": "http://arxiv.org/abs/2106.06842",
          "publishedOn": "2021-06-15T01:45:17.835Z",
          "wordCount": 597,
          "title": "Recomposing the Reinforcement Learning Building Blocks with Hypernetworks. (arXiv:2106.06842v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06843",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Hangyu Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jinjin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shiqing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1\">Yaochu Jin</a>",
          "description": "Federated learning is an emerging distributed machine learning framework for\nprivacy preservation. However, models trained in federated learning usually\nhave worse performance than those trained in the standard centralized learning\nmode, especially when the training data are not independent and identically\ndistributed (Non-IID) on the local devices. In this survey, we pro-vide a\ndetailed analysis of the influence of Non-IID data on both parametric and\nnon-parametric machine learning models in both horizontal and vertical\nfederated learning. In addition, cur-rent research work on handling challenges\nof Non-IID data in federated learning are reviewed, and both advantages and\ndisadvantages of these approaches are discussed. Finally, we suggest several\nfuture research directions before concluding the paper.",
          "link": "http://arxiv.org/abs/2106.06843",
          "publishedOn": "2021-06-15T01:45:17.830Z",
          "wordCount": 543,
          "title": "Federated Learning on Non-IID Data: A Survey. (arXiv:2106.06843v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2003.11991",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Gupta_S/0/1/0/all/0/1\">Shantanu Gupta</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lipton_Z/0/1/0/all/0/1\">Zachary C. Lipton</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Childers_D/0/1/0/all/0/1\">David Childers</a>",
          "description": "Given a causal graph, the do-calculus can express treatment effects as\nfunctionals of the observational joint distribution that can be estimated\nempirically. Sometimes the do-calculus identifies multiple valid formulae,\nprompting us to compare the statistical properties of the corresponding\nestimators. For example, the backdoor formula applies when all confounders are\nobserved and the frontdoor formula applies when an observed mediator transmits\nthe causal effect. In this paper, we investigate the over-identified scenario\nwhere both confounders and mediators are observed, rendering both estimators\nvalid. Addressing the linear Gaussian causal model, we demonstrate that either\nestimator can dominate the other by an unbounded constant factor. Next, we\nderive an optimal estimator, which leverages all observed variables, and bound\nits finite-sample variance. We show that it strictly outperforms the backdoor\nand frontdoor estimators and that this improvement can be unbounded. We also\npresent a procedure for combining two datasets, one with observed confounders\nand another with observed mediators. Finally, we evaluate our methods on both\nsimulated data and the IHDP and JTPA datasets.",
          "link": "http://arxiv.org/abs/2003.11991",
          "publishedOn": "2021-06-15T01:45:17.824Z",
          "wordCount": 630,
          "title": "Estimating Treatment Effects with Observed Confounders and Mediators. (arXiv:2003.11991v3 [stat.ME] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1911.11090",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Elsken_T/0/1/0/all/0/1\">Thomas Elsken</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Staffler_B/0/1/0/all/0/1\">Benedikt Staffler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Metzen_J/0/1/0/all/0/1\">Jan Hendrik Metzen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hutter_F/0/1/0/all/0/1\">Frank Hutter</a>",
          "description": "The recent progress in neural architecture search (NAS) has allowed scaling\nthe automated design of neural architectures to real-world domains, such as\nobject detection and semantic segmentation. However, one prerequisite for the\napplication of NAS are large amounts of labeled data and compute resources.\nThis renders its application challenging in few-shot learning scenarios, where\nmany related tasks need to be learned, each with limited amounts of data and\ncompute time. Thus, few-shot learning is typically done with a fixed neural\narchitecture. To improve upon this, we propose MetaNAS, the first method which\nfully integrates NAS with gradient-based meta-learning. MetaNAS optimizes a\nmeta-architecture along with the meta-weights during meta-training. During\nmeta-testing, architectures can be adapted to a novel task with a few steps of\nthe task optimizer, that is: task adaptation becomes computationally cheap and\nrequires only little data per task. Moreover, MetaNAS is agnostic in that it\ncan be used with arbitrary model-agnostic meta-learning algorithms and\narbitrary gradient-based NAS methods. %We present encouraging results for\nMetaNAS with a combination of DARTS and REPTILE on few-shot classification\nbenchmarks. Empirical results on standard few-shot classification benchmarks\nshow that MetaNAS with a combination of DARTS and REPTILE yields\nstate-of-the-art results.",
          "link": "http://arxiv.org/abs/1911.11090",
          "publishedOn": "2021-06-15T01:45:17.818Z",
          "wordCount": 676,
          "title": "Meta-Learning of Neural Architectures for Few-Shot Learning. (arXiv:1911.11090v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06946",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Horvath_M/0/1/0/all/0/1\">Mikl&#xf3;s Z. Horv&#xe1;th</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muller_M/0/1/0/all/0/1\">Mark Niklas M&#xfc;ller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fischer_M/0/1/0/all/0/1\">Marc Fischer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vechev_M/0/1/0/all/0/1\">Martin Vechev</a>",
          "description": "Randomized Smoothing (RS) is a promising method for obtaining robustness\ncertificates by evaluating a base model under noise. In this work we: (i)\ntheoretically motivate why ensembles are a particularly suitable choice as base\nmodels for RS, and (ii) empirically confirm this choice, obtaining state of the\nart results in multiple settings. The key insight of our work is that the\nreduced variance of ensembles over the perturbations introduced in RS leads to\nsignificantly more consistent classifications for a given input, in turn\nleading to substantially increased certifiable radii for difficult samples. We\nalso introduce key optimizations which enable an up to 50-fold decrease in\nsample complexity of RS, thus drastically reducing its computational overhead.\nExperimentally, we show that ensembles of only 3 to 10 classifiers consistently\nimprove on the strongest single model with respect to their average certified\nradius (ACR) by 5% to 21% on both CIFAR-10 and ImageNet. On the latter, we\nachieve a state-of-the-art ACR of 1.11. We release all code and models required\nto reproduce our results upon publication.",
          "link": "http://arxiv.org/abs/2106.06946",
          "publishedOn": "2021-06-15T01:45:17.801Z",
          "wordCount": 608,
          "title": "Boosting Randomized Smoothing with Variance Reduced Classifiers. (arXiv:2106.06946v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2007.01612",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Neu_G/0/1/0/all/0/1\">Gergely Neu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Olkhovskaya_J/0/1/0/all/0/1\">Julia Olkhovskaya</a>",
          "description": "We consider an online learning problem where the learner interacts with a\nMarkov decision process in a sequence of episodes, where the reward function is\nallowed to change between episodes in an adversarial manner and the learner\nonly gets to observe the rewards associated with its actions. We allow the\nstate space to be arbitrarily large, but we assume that all action-value\nfunctions can be represented as linear functions in terms of a known\nlow-dimensional feature map, and that the learner has access to a simulator of\nthe environment that allows generating trajectories from the true MDP dynamics.\nOur main contribution is developing a computationally efficient algorithm that\nwe call MDP-LinExp3, and prove that its regret is bounded by\n$\\widetilde{\\mathcal{O}}\\big(H^2 T^{2/3} (dK)^{1/3}\\big)$, where $T$ is the\nnumber of episodes, $H$ is the number of steps in each episode, $K$ is the\nnumber of actions, and $d$ is the dimension of the feature map. We also show\nthat the regret can be improved to $\\widetilde{\\mathcal{O}}\\big(H^2\n\\sqrt{TdK}\\big)$ under much stronger assumptions on the MDP dynamics. To our\nknowledge, MDP-LinExp3 is the first provably efficient algorithm for this\nproblem setting.",
          "link": "http://arxiv.org/abs/2007.01612",
          "publishedOn": "2021-06-15T01:45:17.795Z",
          "wordCount": 646,
          "title": "Online learning in MDPs with linear function approximation and bandit feedback. (arXiv:2007.01612v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06743",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Varmazyar_H/0/1/0/all/0/1\">Hadi Varmazyar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yousefi_Banaem_H/0/1/0/all/0/1\">Hossein Yousefi-Banaem</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Malekzadeh_S/0/1/0/all/0/1\">Saber Malekzadeh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gharehaghaji_N/0/1/0/all/0/1\">Nahideh Gharehaghaji</a>",
          "description": "Background: Alzheimers disease is a progressive neurodegenerative disorder\nand the main cause of dementia in aging. Hippocampus is prone to changes in the\nearly stages of Alzheimers disease. Detection and observation of the\nhippocampus changes using magnetic resonance imaging (MRI) before the onset of\nAlzheimers disease leads to the faster preventive and therapeutic measures.\nObjective: The aim of this study was the segmentation of the hippocampus in\nmagnetic resonance (MR) images of Alzheimers patients using deep machine\nlearning method. Methods: U-Net architecture of convolutional neural network\nwas proposed to segment the hippocampus in the real MRI data. The MR images of\nthe 100 and 35 patients available in Alzheimers disease Neuroimaging Initiative\n(ADNI) dataset, was used for the train and test of the model, respectively. The\nperformance of the proposed method was compared with manual segmentation by\nmeasuring the similarity metrics. Results: The desired segmentation achieved\nafter 10 iterations. A Dice similarity coefficient (DSC) = 92.3%, sensitivity =\n96.5%, positive predicted value (PPV) = 90.4%, and Intersection over Union\n(IoU) value for the train 92.94 and test 92.93 sets were obtained which are\nacceptable. Conclusion: The proposed approach is promising and can be extended\nin the prognosis of Alzheimers disease by the prediction of the hippocampus\nvolume changes in the early stage of the disease.",
          "link": "http://arxiv.org/abs/2106.06743",
          "publishedOn": "2021-06-15T01:45:17.789Z",
          "wordCount": 674,
          "title": "Hippocampus segmentation in magnetic resonance images of Alzheimer's patients using Deep machine learning. (arXiv:2106.06743v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.06548",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sukhbaatar_S/0/1/0/all/0/1\">Sainbayar Sukhbaatar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ju_D/0/1/0/all/0/1\">Da Ju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poff_S/0/1/0/all/0/1\">Spencer Poff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roller_S/0/1/0/all/0/1\">Stephen Roller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szlam_A/0/1/0/all/0/1\">Arthur Szlam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weston_J/0/1/0/all/0/1\">Jason Weston</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_A/0/1/0/all/0/1\">Angela Fan</a>",
          "description": "Attention mechanisms have shown promising results in sequence modeling tasks\nthat require long-term memory. Recent work investigated mechanisms to reduce\nthe computational cost of preserving and storing memories. However, not all\ncontent in the past is equally important to remember. We propose Expire-Span, a\nmethod that learns to retain the most important information and expire the\nirrelevant information. This forgetting of memories enables Transformers to\nscale to attend over tens of thousands of previous timesteps efficiently, as\nnot all states from previous timesteps are preserved. We demonstrate that\nExpire-Span can help models identify and retain critical information and show\nit can achieve strong performance on reinforcement learning tasks specifically\ndesigned to challenge this functionality. Next, we show that Expire-Span can\nscale to memories that are tens of thousands in size, setting a new state of\nthe art on incredibly long context tasks such as character-level language\nmodeling and a frame-by-frame moving objects task. Finally, we analyze the\nefficiency of Expire-Span compared to existing approaches and demonstrate that\nit trains faster and uses less memory.",
          "link": "http://arxiv.org/abs/2105.06548",
          "publishedOn": "2021-06-15T01:45:17.782Z",
          "wordCount": 645,
          "title": "Not All Memories are Created Equal: Learning to Forget by Expiring. (arXiv:2105.06548v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.15134",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wen_Z/0/1/0/all/0/1\">Zixin Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuanzhi Li</a>",
          "description": "How can neural networks trained by contrastive learning extract features from\nthe unlabeled data? Why does contrastive learning usually need much stronger\ndata augmentations than supervised learning to ensure good representations?\nThese questions involve both the optimization and statistical aspects of deep\nlearning, but can hardly be answered by analyzing supervised learning, where\nthe target functions are the highest pursuit. Indeed, in self-supervised\nlearning, it is inevitable to relate to the optimization/generalization of\nneural networks to how they can encode the latent structures in the data, which\nwe refer to as the feature learning process.\n\nIn this work, we formally study how contrastive learning learns the feature\nrepresentations for neural networks by analyzing its feature learning process.\nWe consider the case where our data are comprised of two types of features: the\nmore semantically aligned sparse features which we want to learn from, and the\nother dense features we want to avoid. Theoretically, we prove that contrastive\nlearning using $\\mathbf{ReLU}$ networks provably learns the desired sparse\nfeatures if proper augmentations are adopted. We present an underlying\nprinciple called $\\textbf{feature decoupling}$ to explain the effects of\naugmentations, where we theoretically characterize how augmentations can reduce\nthe correlations of dense features between positive samples while keeping the\ncorrelations of sparse features intact, thereby forcing the neural networks to\nlearn from the self-supervision of sparse features. Empirically, we verified\nthat the feature decoupling principle matches the underlying mechanism of\ncontrastive learning in practice.",
          "link": "http://arxiv.org/abs/2105.15134",
          "publishedOn": "2021-06-15T01:45:17.776Z",
          "wordCount": 703,
          "title": "Toward Understanding the Feature Learning Process of Self-supervised Contrastive Learning. (arXiv:2105.15134v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.01558",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_R/0/1/0/all/0/1\">Rui Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1\">Yanmin Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yuanxiong Guo</a>",
          "description": "Federated learning (FL) enables distributed agents to collaboratively learn a\ncentralized model without sharing their raw data with each other. However, data\nlocality does not provide sufficient privacy protection, and it is desirable to\nfacilitate FL with rigorous differential privacy (DP) guarantee. Existing DP\nmechanisms would introduce random noise with magnitude proportional to the\nmodel size, which can be quite large in deep neural networks. In this paper, we\npropose a new FL framework with sparsification-amplified privacy. Our approach\nintegrates random sparsification with gradient perturbation on each agent to\namplify privacy guarantee. Since sparsification would increase the number of\ncommunication rounds required to achieve a certain target accuracy, which is\nunfavorable for DP guarantee, we further introduce acceleration techniques to\nhelp reduce the privacy cost. We rigorously analyze the convergence of our\napproach and utilize Renyi DP to tightly account the end-to-end DP guarantee.\nExtensive experiments on benchmark datasets validate that our approach\noutperforms previous differentially-private FL approaches in both privacy\nguarantee and communication efficiency.",
          "link": "http://arxiv.org/abs/2008.01558",
          "publishedOn": "2021-06-15T01:45:17.756Z",
          "wordCount": 637,
          "title": "Federated Learning with Sparsification-Amplified Privacy and Adaptive Optimization. (arXiv:2008.01558v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.04223",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sayin_M/0/1/0/all/0/1\">Muhammed O. Sayin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parise_F/0/1/0/all/0/1\">Francesca Parise</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ozdaglar_A/0/1/0/all/0/1\">Asuman Ozdaglar</a>",
          "description": "We present fictitious play dynamics for stochastic games and analyze its\nconvergence properties in zero-sum stochastic games. Our dynamics involves\nplayers forming beliefs on opponent strategy and their own continuation payoff\n(Q-function), and playing a greedy best response using estimated continuation\npayoffs. Players update their beliefs from observations of opponent actions. A\nkey property of the learning dynamics is that update of the beliefs on\nQ-functions occurs at a slower timescale than update of the beliefs on\nstrategies. We show both in the model-based and model-free cases (without\nknowledge of player payoff functions and state transition probabilities), the\nbeliefs on strategies converge to a stationary mixed Nash equilibrium of the\nzero-sum stochastic game.",
          "link": "http://arxiv.org/abs/2010.04223",
          "publishedOn": "2021-06-15T01:45:17.749Z",
          "wordCount": 596,
          "title": "Fictitious play in zero-sum stochastic games. (arXiv:2010.04223v4 [cs.GT] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.05724",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Indelman_H/0/1/0/all/0/1\">Hedda Cohen Indelman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hazan_T/0/1/0/all/0/1\">Tamir Hazan</a>",
          "description": "Direct loss minimization is a popular approach for learning predictors over\nstructured label spaces. This approach is computationally appealing as it\nreplaces integration with optimization and allows to propagate gradients in a\ndeep net using loss-perturbed prediction. Recently, this technique was extended\nto generative models, while introducing a randomized predictor that samples a\nstructure from a randomly perturbed score function. In this work, we learn the\nvariance of these randomized structured predictors and show that it balances\nbetter between the learned score function and the randomized noise in\nstructured prediction. We demonstrate empirically the effectiveness of learning\nthe balance between the signal and the random noise in structured discrete\nspaces.",
          "link": "http://arxiv.org/abs/2007.05724",
          "publishedOn": "2021-06-15T01:45:17.741Z",
          "wordCount": 566,
          "title": "Learning Randomly Perturbed Structured Predictors for Direct Loss Minimization. (arXiv:2007.05724v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2002.10904",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rucker_M/0/1/0/all/0/1\">Mark A. Rucker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watson_L/0/1/0/all/0/1\">Layne T. Watson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barnes_L/0/1/0/all/0/1\">Laura E. Barnes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gerber_M/0/1/0/all/0/1\">Matthew S. Gerber</a>",
          "description": "It has been well demonstrated that inverse reinforcement learning (IRL) is an\neffective technique for teaching machines to perform tasks at human skill\nlevels given human demonstrations (i.e., human to machine apprenticeship\nlearning). This paper seeks to show that a similar application can be\ndemonstrated with human learners. That is, given demonstrations from human\nexperts inverse reinforcement learning techniques can be used to teach other\nhumans to perform at higher skill levels (i.e., human to human apprenticeship\nlearning). To show this two experiments were conducted using a simple,\nreal-time web game where players were asked to touch targets in order to earn\nas many points as possible. For the experiment player performance was defined\nas the number of targets a player touched, irrespective of the points that a\nplayer actually earned. This allowed for in-game points to be modified and the\neffect of these alterations on performance measured. At no time were\nparticipants told the true performance metric. To determine the point\nmodifications IRL was applied on demonstrations of human experts playing the\ngame. The results of the experiment show with significance that performance\nimproved over the control for select treatment groups. Finally, in addition to\nthe experiment, we also detail the algorithmic challenges we faced when\nconducting the experiment and the techniques we used to overcome them.",
          "link": "http://arxiv.org/abs/2002.10904",
          "publishedOn": "2021-06-15T01:45:17.735Z",
          "wordCount": 701,
          "title": "Human Apprenticeship Learning via Kernel-based Inverse Reinforcement Learning. (arXiv:2002.10904v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.06648",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ndiaye_E/0/1/0/all/0/1\">Eugene Ndiaye</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Takeuchi_I/0/1/0/all/0/1\">Ichiro Takeuchi</a>",
          "description": "Conformal prediction constructs a confidence set for an unobserved response\nof a feature vector based on previous identically distributed and exchangeable\nobservations of responses and features. It has a coverage guarantee at any\nnominal level without additional assumptions on their distribution. Its\ncomputation deplorably requires a refitting procedure for all replacement\ncandidates of the target response. In regression settings, this corresponds to\nan infinite number of model fit. Apart from relatively simple estimators that\ncan be written as pieces of linear function of the response, efficiently\ncomputing such sets is difficult and is still considered as an open problem. We\nexploit the fact that, \\emph{often}, conformal prediction sets are intervals\nwhose boundaries can be efficiently approximated by classical root-finding\nalgorithm. We investigate how this approach can overcome many limitations of\nformerly used strategies and we discuss its complexity and drawbacks.",
          "link": "http://arxiv.org/abs/2104.06648",
          "publishedOn": "2021-06-15T01:45:17.727Z",
          "wordCount": 581,
          "title": "Root-finding Approaches for Computing Conformal Prediction Set. (arXiv:2104.06648v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06896",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yunhao Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mengmeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianbu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1\">Weiwei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_R/0/1/0/all/0/1\">Ran Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_Q/0/1/0/all/0/1\">Qian Du</a>",
          "description": "The monitoring of coastal wetlands is of great importance to the protection\nof marine and terrestrial ecosystems. However, due to the complex environment,\nsevere vegetation mixture, and difficulty of access, it is impossible to\naccurately classify coastal wetlands and identify their species with\ntraditional classifiers. Despite the integration of multisource remote sensing\ndata for performance enhancement, there are still challenges with acquiring and\nexploiting the complementary merits from multisource data. In this paper, the\nDeepwise Feature Interaction Network (DFINet) is proposed for wetland\nclassification. A depthwise cross attention module is designed to extract\nself-correlation and cross-correlation from multisource feature pairs. In this\nway, meaningful complementary information is emphasized for classification.\nDFINet is optimized by coordinating consistency loss, discrimination loss, and\nclassification loss. Accordingly, DFINet reaches the standard solution-space\nunder the regularity of loss functions, while the spatial consistency and\nfeature discrimination are preserved. Comprehensive experimental results on two\nhyperspectral and multispectral wetland datasets demonstrate that the proposed\nDFINet outperforms other competitive methods in terms of overall accuracy.",
          "link": "http://arxiv.org/abs/2106.06896",
          "publishedOn": "2021-06-15T01:45:17.709Z",
          "wordCount": 621,
          "title": "Hyperspectral and Multispectral Classification for Coastal Wetland Using Depthwise Feature Interaction Network. (arXiv:2106.06896v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06898",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zongyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kovachki_N/0/1/0/all/0/1\">Nikola Kovachki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azizzadenesheli_K/0/1/0/all/0/1\">Kamyar Azizzadenesheli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Burigede Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharya_K/0/1/0/all/0/1\">Kaushik Bhattacharya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stuart_A/0/1/0/all/0/1\">Andrew Stuart</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1\">Anima Anandkumar</a>",
          "description": "Chaotic systems are notoriously challenging to predict because of their\ninstability. Small errors accumulate in the simulation of each time step,\nresulting in completely different trajectories. However, the trajectories of\nmany prominent chaotic systems live in a low-dimensional subspace (attractor).\nIf the system is Markovian, the attractor is uniquely determined by the Markov\noperator that maps the evolution of infinitesimal time steps. This makes it\npossible to predict the behavior of the chaotic system by learning the Markov\noperator even if we cannot predict the exact trajectory. Recently, a new\nframework for learning resolution-invariant solution operators for PDEs was\nproposed, known as neural operators. In this work, we train a Markov neural\noperator (MNO) with only the local one-step evolution information. We then\ncompose the learned operator to obtain the global attractor and invariant\nmeasure. Such a Markov neural operator forms a discrete semigroup and we\nempirically observe that does not collapse or blow up. Experiments show neural\noperators are more accurate and stable compared to previous methods on chaotic\nsystems such as the Kuramoto-Sivashinsky and Navier-Stokes equations.",
          "link": "http://arxiv.org/abs/2106.06898",
          "publishedOn": "2021-06-15T01:45:17.702Z",
          "wordCount": 611,
          "title": "Markov Neural Operators for Learning Chaotic Systems. (arXiv:2106.06898v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/1912.09522",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Siqi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hauskrecht_M/0/1/0/all/0/1\">Milos Hauskrecht</a>",
          "description": "Continuous-time event sequences represent discrete events occurring in\ncontinuous time. Such sequences arise frequently in real-life. Usually we\nexpect the sequences to follow some regular pattern over time. However,\nsometimes these patterns may be interrupted by unexpected absence or\noccurrences of events. Identification of these unexpected cases can be very\nimportant as they may point to abnormal situations that need human attention.\nIn this work, we study and develop methods for detecting outliers in\ncontinuous-time event sequences, including unexpected absence and unexpected\noccurrences of events. Since the patterns that event sequences tend to follow\nmay change in different contexts, we develop outlier detection methods based on\npoint processes that can take context information into account. Our methods are\nbased on Bayesian decision theory and hypothesis testing with theoretical\nguarantees. To test the performance of the methods, we conduct experiments on\nboth synthetic data and real-world clinical data and show the effectiveness of\nthe proposed methods.",
          "link": "http://arxiv.org/abs/1912.09522",
          "publishedOn": "2021-06-15T01:45:17.696Z",
          "wordCount": 616,
          "title": "Event Outlier Detection in Continuous Time. (arXiv:1912.09522v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.07435",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shiebler_D/0/1/0/all/0/1\">Dan Shiebler</a>",
          "description": "We adapt previous research on category theory and topological unsupervised\nlearning to develop a functorial perspective on manifold learning. We first\ncharacterize manifold learning algorithms as functors that map pseudometric\nspaces to optimization objectives and factor through hierachical clustering\nfunctors. We then use this characterization to prove refinement bounds on\nmanifold learning loss functions and construct a hierarchy of manifold learning\nalgorithms based on their invariants. We express several popular manifold\nlearning algorithms as functors at different levels of this hierarchy,\nincluding Metric Multidimensional Scaling, IsoMap, and UMAP. Next, we use\ninterleaving distance to study the stability of a broad class of manifold\nlearning algorithms. We present bounds on how closely the embeddings these\nalgorithms produce from noisy data approximate the embeddings they would learn\nfrom noiseless data. Finally, we use our framework to derive a set of novel\nmanifold learning algorithms, which we experimentally demonstrate are\ncompetitive with the state of the art.",
          "link": "http://arxiv.org/abs/2011.07435",
          "publishedOn": "2021-06-15T01:45:17.688Z",
          "wordCount": 619,
          "title": "Functorial Manifold Learning. (arXiv:2011.07435v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06955",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maene_J/0/1/0/all/0/1\">Jaron Maene</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Mingxiao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moens_M/0/1/0/all/0/1\">Marie-Francine Moens</a>",
          "description": "The lottery ticket hypothesis states that sparse subnetworks exist in\nrandomly initialized dense networks that can be trained to the same accuracy as\nthe dense network they reside in. However, the subsequent work has failed to\nreplicate this on large-scale models and required rewinding to an early stable\nstate instead of initialization. We show that by using a training method that\nis stable with respect to linear mode connectivity, large networks can also be\nentirely rewound to initialization. Our subsequent experiments on common vision\ntasks give strong credence to the hypothesis in Evci et al. (2020b) that\nlottery tickets simply retrain to the same regions (although not necessarily to\nthe same basin). These results imply that existing lottery tickets could not\nhave been found without the preceding dense training by iterative magnitude\npruning, raising doubts about the use of the lottery ticket hypothesis.",
          "link": "http://arxiv.org/abs/2106.06955",
          "publishedOn": "2021-06-15T01:45:17.682Z",
          "wordCount": 566,
          "title": "Towards Understanding Iterative Magnitude Pruning: Why Lottery Tickets Win. (arXiv:2106.06955v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2012.08156",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1\">Sagar Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1\">Keke Chen</a>",
          "description": "With the ever-growing data and the need for developing powerful machine\nlearning models, data owners increasingly depend on various untrusted platforms\n(e.g., public clouds, edges, and machine learning service providers) for\nscalable processing or collaborative learning. Thus, sensitive data and models\nare in danger of unauthorized access, misuse, and privacy compromises. A\nrelatively new body of research confidentially trains machine learning models\non protected data to address these concerns. In this survey, we summarize\nnotable studies in this emerging area of research. With a unified framework, we\nhighlight the critical challenges and innovations in outsourcing machine\nlearning confidentially. We focus on the cryptographic approaches for\nconfidential machine learning (CML), primarily on model training, while also\ncovering other directions such as perturbation-based approaches and CML in the\nhardware-assisted computing environment. The discussion will take a holistic\nway to consider a rich context of the related threat models, security\nassumptions, design principles, and associated trade-offs amongst data utility,\ncost, and confidentiality.",
          "link": "http://arxiv.org/abs/2012.08156",
          "publishedOn": "2021-06-15T01:45:17.676Z",
          "wordCount": 618,
          "title": "Confidential Machine Learning on Untrusted Platforms: A Survey. (arXiv:2012.08156v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.00382",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1\">Dong-Ki Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Miao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riemer_M/0/1/0/all/0/1\">Matthew Riemer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1\">Chuangchuang Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdulhai_M/0/1/0/all/0/1\">Marwa Abdulhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Habibi_G/0/1/0/all/0/1\">Golnaz Habibi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lopez_Cot_S/0/1/0/all/0/1\">Sebastian Lopez-Cot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tesauro_G/0/1/0/all/0/1\">Gerald Tesauro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+How_J/0/1/0/all/0/1\">Jonathan P. How</a>",
          "description": "A fundamental challenge in multiagent reinforcement learning is to learn\nbeneficial behaviors in a shared environment with other simultaneously learning\nagents. In particular, each agent perceives the environment as effectively\nnon-stationary due to the changing policies of other agents. Moreover, each\nagent is itself constantly learning, leading to natural non-stationarity in the\ndistribution of experiences encountered. In this paper, we propose a novel\nmeta-multiagent policy gradient theorem that directly accounts for the\nnon-stationary policy dynamics inherent to multiagent learning settings. This\nis achieved by modeling our gradient updates to consider both an agent's own\nnon-stationary policy dynamics and the non-stationary policy dynamics of other\nagents in the environment. We show that our theoretically grounded approach\nprovides a general solution to the multiagent learning problem, which\ninherently comprises all key aspects of previous state of the art approaches on\nthis topic. We test our method on a diverse suite of multiagent benchmarks and\ndemonstrate a more efficient ability to adapt to new agents as they learn than\nbaseline methods across the full spectrum of mixed incentive, competitive, and\ncooperative domains.",
          "link": "http://arxiv.org/abs/2011.00382",
          "publishedOn": "2021-06-15T01:45:17.659Z",
          "wordCount": 704,
          "title": "A Policy Gradient Algorithm for Learning to Learn in Multiagent Reinforcement Learning. (arXiv:2011.00382v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.01158",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tushar_F/0/1/0/all/0/1\">Fakrul Islam Tushar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DAnniballe_V/0/1/0/all/0/1\">Vincent M. D&#x27;Anniballe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_R/0/1/0/all/0/1\">Rui Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mazurowski_M/0/1/0/all/0/1\">Maciej A. Mazurowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_W/0/1/0/all/0/1\">Wanyi Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samei_E/0/1/0/all/0/1\">Ehsan Samei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubin_G/0/1/0/all/0/1\">Geoffrey D. Rubin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lo_J/0/1/0/all/0/1\">Joseph Y. Lo</a>",
          "description": "Background: Training deep learning classifiers typically requires massive\namounts of manual annotation. Weak supervision may leverage existing medical\ndata to classify multiple diseases and organ systems. Purpose: To design\nmulti-disease classifiers for body computed tomography (CT) scans using\nautomatically extracted labels from radiology text reports. Materials &\nMethods: This retrospective study deployed rule-based algorithms to extract\n19,255 disease labels from reports of 13,667 body CT scans of 12,092 subjects\nfor training. Using a 3D DenseVNet, three organ systems were segmented:\nlungs/pleura, liver/gallbladder, and kidneys/ureters. For each organ, a 3D\nconvolutional neural network classified normality versus four common diseases.\nTesting was performed on an additional 2,158 CT volumes relative to 2,875\nmanually derived reference labels. Results: Manual validation of the extracted\nlabels confirmed 91 to 99% accuracy. Performance using the receiver operating\ncharacteristic area under the curve (AUC) for lungs/pleura labels were as\nfollows: atelectasis 0.77 (95% CI: 0.74 to 0.81), nodule 0.65 (0.61 to 0.69),\nemphysema 0.89 (0.86 to 0.92), effusion 0.97 (0.96 to 0.98), and normal 0.89\n(0.87 to 0.91). For liver/gallbladder: stone 0.62 (0.56 to 0.67), lesion 0.73\n(0.69 to 0.77), dilation 0.87 (0.84 to 0.90), fatty 0.89 (0.86 to 0.92), and\nnormal 0.82 (0.78 to 0.85). For kidneys/ureters: stone 0.83 (0.79 to 0.87),\natrophy 0.92 (0.89 to 0.94), lesion 0.68 (0.64 to 0.72), cyst 0.70 (0.66 to\n0.73), and normal 0.79 (0.75 to 0.83). Conclusion: Weakly supervised deep\nlearning classifiers leveraged massive amounts of unannotated body CT data to\nclassify multiple organ systems and diverse diseases.",
          "link": "http://arxiv.org/abs/2008.01158",
          "publishedOn": "2021-06-15T01:45:17.653Z",
          "wordCount": 749,
          "title": "Multi-Disease Classification of 13,667 Body CT Scans Using Weakly Supervised Deep Learning. (arXiv:2008.01158v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06828",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1\">Ying Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hui Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yaodong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Z/0/1/0/all/0/1\">Zheng Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Minne Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jun Wang</a>",
          "description": "Trust region methods are widely applied in single-agent reinforcement\nlearning problems due to their monotonic performance-improvement guarantee at\nevery iteration. Nonetheless, when applied in multi-agent settings, the\nguarantee of trust region methods no longer holds because an agent's payoff is\nalso affected by other agents' adaptive behaviors. To tackle this problem, we\nconduct a game-theoretical analysis in the policy space, and propose a\nmulti-agent trust region learning method (MATRL), which enables trust region\noptimization for multi-agent learning. Specifically, MATRL finds a stable\nimprovement direction that is guided by the solution concept of Nash\nequilibrium at the meta-game level. We derive the monotonic improvement\nguarantee in multi-agent settings and empirically show the local convergence of\nMATRL to stable fixed points in the two-player rotational differential game. To\ntest our method, we evaluate MATRL in both discrete and continuous multiplayer\ngeneral-sum games including checker and switch grid worlds, multi-agent MuJoCo,\nand Atari games. Results suggest that MATRL significantly outperforms strong\nmulti-agent reinforcement learning baselines.",
          "link": "http://arxiv.org/abs/2106.06828",
          "publishedOn": "2021-06-15T01:45:17.645Z",
          "wordCount": 626,
          "title": "A Game-Theoretic Approach to Multi-Agent Trust Region Optimization. (arXiv:2106.06828v1 [cs.MA])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06621",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Greydanus_S/0/1/0/all/0/1\">Sam Greydanus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Stefan Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fern_A/0/1/0/all/0/1\">Alan Fern</a>",
          "description": "Neural networks are a popular tool for modeling sequential data but they\ngenerally do not treat time as a continuous variable. Neural ODEs represent an\nimportant exception: they parameterize the time derivative of a hidden state\nwith a neural network and then integrate over arbitrary amounts of time. But\nthese parameterizations, which have arbitrary curvature, can be hard to\nintegrate and thus train and evaluate. In this paper, we propose making a\npiecewise-constant approximation to Neural ODEs to mitigate these issues. Our\nmodel can be integrated exactly via Euler integration and can generate\nautoregressive samples in 3-20 times fewer steps than comparable RNN and\nODE-RNN models. We evaluate our model on several synthetic physics tasks and a\nplanning task inspired by the game of billiards. We find that it matches the\nperformance of baseline approaches while requiring less time to train and\nevaluate.",
          "link": "http://arxiv.org/abs/2106.06621",
          "publishedOn": "2021-06-15T01:45:17.639Z",
          "wordCount": 566,
          "title": "Piecewise-constant Neural ODEs. (arXiv:2106.06621v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06761",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Burduk_R/0/1/0/all/0/1\">Robert Burduk</a>",
          "description": "The ensemble methods are meta-algorithms that combine several base machine\nlearning techniques to increase the effectiveness of the classification. Many\nexisting committees of classifiers use the classifier selection process to\ndetermine the optimal set of base classifiers. In this article, we propose the\nclassifiers selection framework with relearning base classifiers. Additionally,\nwe use in the proposed framework the new generated feature, which can be\nobtained after the relearning process. The proposed technique was compared with\nstate-of-the-art ensemble methods using three benchmark datasets and one\nsynthetic dataset. Four classification performance measures are used to\nevaluate the proposed method.",
          "link": "http://arxiv.org/abs/2106.06761",
          "publishedOn": "2021-06-15T01:45:17.623Z",
          "wordCount": 515,
          "title": "Relearning ensemble selection based on new generated features. (arXiv:2106.06761v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2009.05567",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brophy_J/0/1/0/all/0/1\">Jonathan Brophy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lowd_D/0/1/0/all/0/1\">Daniel Lowd</a>",
          "description": "Responding to user data deletion requests, removing noisy examples, or\ndeleting corrupted training data are just a few reasons for wanting to delete\ninstances from a machine learning (ML) model. However, efficiently removing\nthis data from an ML model is generally difficult. In this paper, we introduce\ndata removal-enabled (DaRE) forests, a variant of random forests that enables\nthe removal of training data with minimal retraining. Model updates for each\nDaRE tree in the forest are exact, meaning that removing instances from a DaRE\nmodel yields exactly the same model as retraining from scratch on updated data.\n\nDaRE trees use randomness and caching to make data deletion efficient. The\nupper levels of DaRE trees use random nodes, which choose split attributes and\nthresholds uniformly at random. These nodes rarely require updates because they\nonly minimally depend on the data. At the lower levels, splits are chosen to\ngreedily optimize a split criterion such as Gini index or mutual information.\nDaRE trees cache statistics at each node and training data at each leaf, so\nthat only the necessary subtrees are updated as data is removed. For numerical\nattributes, greedy nodes optimize over a random subset of thresholds, so that\nthey can maintain statistics while approximating the optimal threshold. By\nadjusting the number of thresholds considered for greedy nodes, and the number\nof random nodes, DaRE trees can trade off between more accurate predictions and\nmore efficient updates.\n\nIn experiments on 13 real-world datasets and one synthetic dataset, we find\nDaRE forests delete data orders of magnitude faster than retraining from\nscratch while sacrificing little to no predictive power.",
          "link": "http://arxiv.org/abs/2009.05567",
          "publishedOn": "2021-06-15T01:45:17.617Z",
          "wordCount": 726,
          "title": "Machine Unlearning for Random Forests. (arXiv:2009.05567v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.05153",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Chen_X/0/1/0/all/0/1\">Xin Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1\">Yingying Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shimada_J/0/1/0/all/0/1\">Jun Shimada</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_N/0/1/0/all/0/1\">Na Li</a>",
          "description": "This paper studies the automated control method for regulating air\nconditioner (AC) loads in incentive-based residential demand response (DR). The\ncritical challenge is that the customer responses to load adjustment are\nuncertain and unknown in practice. In this paper, we formulate the AC control\nproblem in a DR event as a multi-period stochastic optimization that integrates\nthe indoor thermal dynamics and customer opt-out status transition.\nSpecifically, machine learning techniques including Gaussian process and\nlogistic regression are employed to learn the unknown thermal dynamics model\nand customer opt-out behavior model, respectively. We consider two typical DR\nobjectives for AC load control: 1) minimizing the total demand, 2) closely\ntracking a regulated power trajectory. Based on the Thompson sampling\nframework, we propose an online DR control algorithm to learn customer\nbehaviors and make real-time AC control schemes. This algorithm considers the\ninfluence of various environmental factors on customer behaviors and is\nimplemented in a distributed fashion to preserve the privacy of customers.\nNumerical simulations demonstrate the control optimality and learning\nefficiency of the proposed algorithm.",
          "link": "http://arxiv.org/abs/2010.05153",
          "publishedOn": "2021-06-15T01:45:17.611Z",
          "wordCount": 626,
          "title": "Online Learning and Distributed Control for Residential Demand Response. (arXiv:2010.05153v2 [eess.SY] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.03323",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Podkopaev_A/0/1/0/all/0/1\">Aleksandr Podkopaev</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ramdas_A/0/1/0/all/0/1\">Aaditya Ramdas</a>",
          "description": "Trustworthy deployment of ML models requires a proper measure of uncertainty,\nespecially in safety-critical applications. We focus on uncertainty\nquantification (UQ) for classification problems via two avenues -- prediction\nsets using conformal prediction and calibration of probabilistic predictors by\npost-hoc binning -- since these possess distribution-free guarantees for i.i.d.\ndata. Two common ways of generalizing beyond the i.i.d. setting include\nhandling covariate and label shift. Within the context of distribution-free UQ,\nthe former has already received attention, but not the latter. It is known that\nlabel shift hurts prediction, and we first argue that it also hurts UQ, by\nshowing degradation in coverage and calibration. Piggybacking on recent\nprogress in addressing label shift (for better prediction), we examine the\nright way to achieve UQ by reweighting the aforementioned conformal and\ncalibration procedures whenever some unlabeled data from the target\ndistribution is available. We examine these techniques theoretically in a\ndistribution-free framework and demonstrate their excellent practical\nperformance.",
          "link": "http://arxiv.org/abs/2103.03323",
          "publishedOn": "2021-06-15T01:45:17.605Z",
          "wordCount": 607,
          "title": "Distribution-free uncertainty quantification for classification under label shift. (arXiv:2103.03323v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06921",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1\">Sixing Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_P/0/1/0/all/0/1\">Phuong Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anwar_A/0/1/0/all/0/1\">Ali Anwar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jannesari_A/0/1/0/all/0/1\">Ali Jannesari</a>",
          "description": "Federated Learning~(FL) has emerged as a new paradigm of training machine\nlearning models without sacrificing data security and privacy. Learning models\nat edge devices such as cell phones is one of the most common use case of FL.\nHowever, the limited computing power and energy constraints of edge devices\nhinder the adoption of FL for both model training and deployment, especially\nfor the resource-hungry Deep Neural Networks~(DNNs). To this end, many model\ncompression methods have been proposed and network pruning is among the most\nwell-known. However, a pruning policy for a given model is highly\ndataset-dependent, which is not suitable for non-Independent and Identically\nDistributed~(Non-IID) FL edge devices. In this paper, we present an adaptive\npruning scheme for edge devices in an FL system, which applies dataset-aware\ndynamic pruning for inference acceleration on Non-IID datasets. Our evaluation\nshows that the proposed method accelerates inference by $2\\times$~($50\\%$ FLOPs\nreduction) while maintaining the model's quality on edge devices.",
          "link": "http://arxiv.org/abs/2106.06921",
          "publishedOn": "2021-06-15T01:45:17.599Z",
          "wordCount": 585,
          "title": "Adaptive Dynamic Pruning for Non-IID Federated Learning. (arXiv:2106.06921v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06811",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pritom_M/0/1/0/all/0/1\">Mir Mehedi A. Pritom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_R/0/1/0/all/0/1\">Rosana Montanez Rodriguez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1\">Asad Ali Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nugroho_S/0/1/0/all/0/1\">Sebastian A. Nugroho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alrashydah_E/0/1/0/all/0/1\">Esra&#x27;a Alrashydah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruiz_B/0/1/0/all/0/1\">Beatrice N. Ruiz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rios_A/0/1/0/all/0/1\">Anthony Rios</a>",
          "description": "COVID-19 pandemic has generated what public health officials called an\ninfodemic of misinformation. As social distancing and stay-at-home orders came\ninto effect, many turned to social media for socializing. This increase in\nsocial media usage has made it a prime vehicle for the spreading of\nmisinformation. This paper presents a mechanism to detect COVID-19\nhealth-related misinformation in social media following an interdisciplinary\napproach. Leveraging social psychology as a foundation and existing\nmisinformation frameworks, we defined misinformation themes and associated\nkeywords incorporated into the misinformation detection mechanism using applied\nmachine learning techniques. Next, using the Twitter dataset, we explored the\nperformance of the proposed methodology using multiple state-of-the-art machine\nlearning classifiers. Our method shows promising results with at most 78%\naccuracy in classifying health-related misinformation versus true information\nusing uni-gram-based NLP feature generations from tweets and the Decision Tree\nclassifier. We also provide suggestions on alternatives for countering\nmisinformation and ethical consideration for the study.",
          "link": "http://arxiv.org/abs/2106.06811",
          "publishedOn": "2021-06-15T01:45:17.592Z",
          "wordCount": 656,
          "title": "Case Study on Detecting COVID-19 Health-Related Misinformation in Social Media. (arXiv:2106.06811v1 [cs.SI])"
        },
        {
          "id": "http://arxiv.org/abs/2006.05468",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kapoor_S/0/1/0/all/0/1\">Sanyam Kapoor</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Karaletsos_T/0/1/0/all/0/1\">Theofanis Karaletsos</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bui_T/0/1/0/all/0/1\">Thang D. Bui</a>",
          "description": "Through sequential construction of posteriors on observing data online,\nBayes' theorem provides a natural framework for continual learning. We develop\nVariational Auto-Regressive Gaussian Processes (VAR-GPs), a principled\nposterior updating mechanism to solve sequential tasks in continual learning.\nBy relying on sparse inducing point approximations for scalable posteriors, we\npropose a novel auto-regressive variational distribution which reveals two\nfruitful connections to existing results in Bayesian inference, expectation\npropagation and orthogonal inducing points. Mean predictive entropy estimates\nshow VAR-GPs prevent catastrophic forgetting, which is empirically supported by\nstrong performance on modern continual learning benchmarks against competitive\nbaselines. A thorough ablation study demonstrates the efficacy of our modeling\nchoices.",
          "link": "http://arxiv.org/abs/2006.05468",
          "publishedOn": "2021-06-15T01:45:17.576Z",
          "wordCount": 565,
          "title": "Variational Auto-Regressive Gaussian Processes for Continual Learning. (arXiv:2006.05468v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.01440",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhuzhel_V/0/1/0/all/0/1\">Vladislav Zhuzhel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rivera_Castro_R/0/1/0/all/0/1\">Rodrigo Rivera-Castro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaploukhaya_N/0/1/0/all/0/1\">Nina Kaploukhaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mironova_L/0/1/0/all/0/1\">Liliya Mironova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaytsev_A/0/1/0/all/0/1\">Alexey Zaytsev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burnaev_E/0/1/0/all/0/1\">Evgeny Burnaev</a>",
          "description": "Cohort analysis is a pervasive activity in web analytics. One divides users\ninto groups according to specific criteria and tracks their behavior over time.\nDespite its extensive use, academic circles do not discuss cohort analysis to\nevaluate user behavior online. This work introduces an unsupervised\nnon-parametric approach to group Internet users based on their activities. In\ncomparison, canonical methods in marketing and engineering-based techniques\nunderperform. COHORTNEY is the first machine learning-based cohort analysis\nalgorithm with a robust theoretical explanation.",
          "link": "http://arxiv.org/abs/2104.01440",
          "publishedOn": "2021-06-15T01:45:17.569Z",
          "wordCount": 539,
          "title": "COHORTNEY: Non-Parametric Clustering of Event Sequences. (arXiv:2104.01440v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.13052",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chu_Z/0/1/0/all/0/1\">Zhendong Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jing Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongning Wang</a>",
          "description": "Crowdsourcing provides a practical way to obtain large amounts of labeled\ndata at a low cost. However, the annotation quality of annotators varies\nconsiderably, which imposes new challenges in learning a high-quality model\nfrom the crowdsourced annotations. In this work, we provide a new perspective\nto decompose annotation noise into common noise and individual noise and\ndifferentiate the source of confusion based on instance difficulty and\nannotator expertise on a per-instance-annotator basis. We realize this new\ncrowdsourcing model by an end-to-end learning solution with two types of noise\nadaptation layers: one is shared across annotators to capture their commonly\nshared confusions, and the other one is pertaining to each annotator to realize\nindividual confusion. To recognize the source of noise in each annotation, we\nuse an auxiliary network to choose the two noise adaptation layers with respect\nto both instances and annotators. Extensive experiments on both synthesized and\nreal-world benchmarks demonstrate the effectiveness of our proposed common\nnoise adaptation solution.",
          "link": "http://arxiv.org/abs/2012.13052",
          "publishedOn": "2021-06-15T01:45:17.563Z",
          "wordCount": 624,
          "title": "Learning from Crowds by Modeling Common Confusions. (arXiv:2012.13052v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06685",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Picot_M/0/1/0/all/0/1\">Marine Picot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Messina_F/0/1/0/all/0/1\">Francisco Messina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boudiaf_M/0/1/0/all/0/1\">Malik Boudiaf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Labeau_F/0/1/0/all/0/1\">Fabrice Labeau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ayed_I/0/1/0/all/0/1\">Ismail Ben Ayed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piantanida_P/0/1/0/all/0/1\">Pablo Piantanida</a>",
          "description": "Adversarial robustness has become a topic of growing interest in machine\nlearning since it was observed that neural networks tend to be brittle. We\npropose an information-geometric formulation of adversarial defense and\nintroduce FIRE, a new Fisher-Rao regularization for the categorical\ncross-entropy loss, which is based on the geodesic distance between natural and\nperturbed input features. Based on the information-geometric properties of the\nclass of softmax distributions, we derive an explicit characterization of the\nFisher-Rao Distance (FRD) for the binary and multiclass cases, and draw some\ninteresting properties as well as connections with standard regularization\nmetrics. Furthermore, for a simple linear and Gaussian model, we show that all\nPareto-optimal points in the accuracy-robustness region can be reached by FIRE\nwhile other state-of-the-art methods fail. Empirically, we evaluate the\nperformance of various classifiers trained with the proposed loss on standard\ndatasets, showing up to 2\\% of improvements in terms of robustness while\nreducing the training time by 20\\% over the best-performing methods.",
          "link": "http://arxiv.org/abs/2106.06685",
          "publishedOn": "2021-06-15T01:45:17.555Z",
          "wordCount": 595,
          "title": "Adversarial Robustness via Fisher-Rao Regularization. (arXiv:2106.06685v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06579",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Venkatesha_Y/0/1/0/all/0/1\">Yeshwanth Venkatesha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Youngeun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tassiulas_L/0/1/0/all/0/1\">Leandros Tassiulas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panda_P/0/1/0/all/0/1\">Priyadarshini Panda</a>",
          "description": "As neural networks get widespread adoption in resource-constrained embedded\ndevices, there is a growing need for low-power neural systems. Spiking Neural\nNetworks (SNNs)are emerging to be an energy-efficient alternative to the\ntraditional Artificial Neural Networks (ANNs) which are known to be\ncomputationally intensive. From an application perspective, as federated\nlearning involves multiple energy-constrained devices, there is a huge scope to\nleverage energy efficiency provided by SNNs. Despite its importance, there has\nbeen little attention on training SNNs on a large-scale distributed system like\nfederated learning. In this paper, we bring SNNs to a more realistic federated\nlearning scenario. Specifically, we propose a federated learning framework for\ndecentralized and privacy-preserving training of SNNs. To validate the proposed\nfederated learning framework, we experimentally evaluate the advantages of SNNs\non various aspects of federated learning with CIFAR10 and CIFAR100 benchmarks.\nWe observe that SNNs outperform ANNs in terms of overall accuracy by over 15%\nwhen the data is distributed across a large number of clients in the federation\nwhile providing up to5.3x energy efficiency. In addition to efficiency, we also\nanalyze the sensitivity of the proposed federated SNN framework to data\ndistribution among the clients, stragglers, and gradient noise and perform a\ncomprehensive comparison with ANNs.",
          "link": "http://arxiv.org/abs/2106.06579",
          "publishedOn": "2021-06-15T01:45:17.549Z",
          "wordCount": 636,
          "title": "Federated Learning with Spiking Neural Networks. (arXiv:2106.06579v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2103.01638",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fumero_M/0/1/0/all/0/1\">Marco Fumero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cosmo_L/0/1/0/all/0/1\">Luca Cosmo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Melzi_S/0/1/0/all/0/1\">Simone Melzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodola_E/0/1/0/all/0/1\">Emanuele Rodol&#xe0;</a>",
          "description": "We propose a novel approach to disentangle the generative factors of\nvariation underlying a given set of observations. Our method builds upon the\nidea that the (unknown) low-dimensional manifold underlying the data space can\nbe explicitly modeled as a product of submanifolds. This definition of\ndisentanglement gives rise to a novel weakly-supervised algorithm for\nrecovering the unknown explanatory factors behind the data. At training time,\nour algorithm only requires pairs of non i.i.d. data samples whose elements\nshare at least one, possibly multidimensional, generative factor of variation.\nWe require no knowledge on the nature of these transformations, and do not make\nany limiting assumption on the properties of each subspace. Our approach is\neasy to implement, and can be successfully applied to different kinds of data\n(from images to 3D surfaces) undergoing arbitrary transformations. In addition\nto standard synthetic benchmarks, we showcase our method in challenging\nreal-world applications, where we compare favorably with the state of the art.",
          "link": "http://arxiv.org/abs/2103.01638",
          "publishedOn": "2021-06-15T01:45:17.528Z",
          "wordCount": 626,
          "title": "Learning disentangled representations via product manifold projection. (arXiv:2103.01638v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.03853",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Xin_R/0/1/0/all/0/1\">Ran Xin</a>, <a href=\"http://arxiv.org/find/math/1/au:+Khan_U/0/1/0/all/0/1\">Usman A. Khan</a>, <a href=\"http://arxiv.org/find/math/1/au:+Kar_S/0/1/0/all/0/1\">Soummya Kar</a>",
          "description": "We study decentralized non-convex finite-sum minimization problems described\nover a network of nodes, where each node possesses a local batch of data\nsamples. In this context, we analyze a single-timescale randomized incremental\ngradient method, called GT-SAGA. GT-SAGA is computationally efficient as it\nevaluates one component gradient per node per iteration and achieves provably\nfast and robust performance by leveraging node-level variance reduction and\nnetwork-level gradient tracking. For general smooth non-convex problems, we\nshow the almost sure and mean-squared convergence of GT-SAGA to a first-order\nstationary point and further describe regimes of practical significance where\nit outperforms the existing approaches and achieves a network\ntopology-independent iteration complexity respectively. When the global\nfunction satisfies the Polyak-Lojaciewisz condition, we show that GT-SAGA\nexhibits linear convergence to an optimal solution in expectation and describe\nregimes of practical interest where the performance is network\ntopology-independent and improves upon the existing methods. Numerical\nexperiments are included to highlight the main convergence aspects of GT-SAGA\nin non-convex settings.",
          "link": "http://arxiv.org/abs/2011.03853",
          "publishedOn": "2021-06-15T01:45:17.519Z",
          "wordCount": 633,
          "title": "A fast randomized incremental gradient method for decentralized non-convex optimization. (arXiv:2011.03853v2 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06804",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Barbiero_P/0/1/0/all/0/1\">Pietro Barbiero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ciravegna_G/0/1/0/all/0/1\">Gabriele Ciravegna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giannini_F/0/1/0/all/0/1\">Francesco Giannini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lio_P/0/1/0/all/0/1\">Pietro Li&#xf3;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gori_M/0/1/0/all/0/1\">Marco Gori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Melacci_S/0/1/0/all/0/1\">Stefano Melacci</a>",
          "description": "Explainable artificial intelligence has rapidly emerged since lawmakers have\nstarted requiring interpretable models for safety-critical domains.\nConcept-based neural networks have arisen as explainable-by-design methods as\nthey leverage human-understandable symbols (i.e. concepts) to predict class\nmemberships. However, most of these approaches focus on the identification of\nthe most relevant concepts but do not provide concise, formal explanations of\nhow such concepts are leveraged by the classifier to make predictions. In this\npaper, we propose a novel end-to-end differentiable approach enabling the\nextraction of logic explanations from neural networks using the formalism of\nFirst-Order Logic. The method relies on an entropy-based criterion which\nautomatically identifies the most relevant concepts. We consider four different\ncase studies to demonstrate that: (i) this entropy-based criterion enables the\ndistillation of concise logic explanations in safety-critical domains from\nclinical data to computer vision; (ii) the proposed approach outperforms\nstate-of-the-art white-box models in terms of classification accuracy.",
          "link": "http://arxiv.org/abs/2106.06804",
          "publishedOn": "2021-06-15T01:45:17.495Z",
          "wordCount": 591,
          "title": "Entropy-based Logic Explanations of Neural Networks. (arXiv:2106.06804v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06688",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pandey_P/0/1/0/all/0/1\">Pankaj Pandey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miyapuram_K/0/1/0/all/0/1\">Krishna Prasad Miyapuram</a>",
          "description": "Several Convolutional Deep Learning models have been proposed to classify the\ncognitive states utilizing several neuro-imaging domains. These models have\nachieved significant results, but they are heavily designed with millions of\nparameters, which increases train and test time, making the model complex and\nless suitable for real-time analysis. This paper proposes a simple, lightweight\nCNN model to classify cognitive states from Electroencephalograph (EEG)\nrecordings. We develop a novel pipeline to learn distinct cognitive\nrepresentation consisting of two stages. The first stage is to generate the 2D\nspectral images from neural time series signals in a particular frequency band.\nImages are generated to preserve the relationship between the neighboring\nelectrodes and the spectral property of the cognitive events. The second is to\ndevelop a time-efficient, computationally less loaded, and high-performing\nmodel. We design a network containing 4 blocks and major components include\nstandard and depth-wise convolution for increasing the performance and followed\nby separable convolution to decrease the number of parameters which maintains\nthe tradeoff between time and performance. We experiment on open access EEG\nmeditation dataset comprising expert, nonexpert meditative, and control states.\nWe compare performance with six commonly used machine learning classifiers and\nfour state of the art deep learning models. We attain comparable performance\nutilizing less than 4\\% of the parameters of other models. This model can be\nemployed in a real-time computation environment such as neurofeedback.",
          "link": "http://arxiv.org/abs/2106.06688",
          "publishedOn": "2021-06-15T01:45:17.475Z",
          "wordCount": 678,
          "title": "BRAIN2DEPTH: Lightweight CNN Model for Classification of Cognitive States from EEG Recordings. (arXiv:2106.06688v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06899",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Ankit Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dar_G/0/1/0/all/0/1\">Guy Dar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goodman_S/0/1/0/all/0/1\">Shaya Goodman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ciprut_D/0/1/0/all/0/1\">David Ciprut</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berant_J/0/1/0/all/0/1\">Jonathan Berant</a>",
          "description": "Following the success of dot-product attention in Transformers, numerous\napproximations have been recently proposed to address its quadratic complexity\nwith respect to the input length. While these variants are memory and compute\nefficient, it is not possible to directly use them with popular pre-trained\nlanguage models trained using vanilla attention, without an expensive\ncorrective pre-training stage. In this work, we propose a simple yet highly\naccurate approximation for vanilla attention. We process the queries in chunks,\nand for each query, compute the top-$k$ scores with respect to the keys. Our\napproach offers several advantages: (a) its memory usage is linear in the input\nsize, similar to linear attention variants, such as Performer and RFA (b) it is\na drop-in replacement for vanilla attention that does not require any\ncorrective pre-training, and (c) it can also lead to significant memory savings\nin the feed-forward layers after casting them into the familiar query-key-value\nframework. We evaluate the quality of top-$k$ approximation for multi-head\nattention layers on the Long Range Arena Benchmark, and for feed-forward layers\nof T5 and UnifiedQA on multiple QA datasets. We show our approach leads to\naccuracy that is nearly-identical to vanilla attention in multiple setups\nincluding training from scratch, fine-tuning, and zero-shot inference.",
          "link": "http://arxiv.org/abs/2106.06899",
          "publishedOn": "2021-06-15T01:45:17.458Z",
          "wordCount": 630,
          "title": "Memory-efficient Transformers via Top-$k$ Attention. (arXiv:2106.06899v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2104.05752",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cha_S/0/1/0/all/0/1\">Sujeong Cha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_W/0/1/0/all/0/1\">Wangrui Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_H/0/1/0/all/0/1\">Hyun Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Phung_M/0/1/0/all/0/1\">My Phung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Picheny_M/0/1/0/all/0/1\">Michael Picheny</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuo_H/0/1/0/all/0/1\">Hong-Kwang Kuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thomas_S/0/1/0/all/0/1\">Samuel Thomas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morais_E/0/1/0/all/0/1\">Edmilson Morais</a>",
          "description": "A major focus of recent research in spoken language understanding (SLU) has\nbeen on the end-to-end approach where a single model can predict intents\ndirectly from speech inputs without intermediate transcripts. However, this\napproach presents some challenges. First, since speech can be considered as\npersonally identifiable information, in some cases only automatic speech\nrecognition (ASR) transcripts are accessible. Second, intent-labeled speech\ndata is scarce. To address the first challenge, we propose a novel system that\ncan predict intents from flexible types of inputs: speech, ASR transcripts, or\nboth. We demonstrate strong performance for either modality separately, and\nwhen both speech and ASR transcripts are available, through system combination,\nwe achieve better results than using a single input modality. To address the\nsecond challenge, we leverage a semantically robust pre-trained BERT model and\nadopt a cross-modal system that co-trains text embeddings and acoustic\nembeddings in a shared latent space. We further enhance this system by\nutilizing an acoustic module pre-trained on LibriSpeech and domain-adapting the\ntext module on our target datasets. Our experiments show significant advantages\nfor these pre-training and fine-tuning strategies, resulting in a system that\nachieves competitive intent-classification performance on Snips SLU and Fluent\nSpeech Commands datasets.",
          "link": "http://arxiv.org/abs/2104.05752",
          "publishedOn": "2021-06-15T01:45:17.245Z",
          "wordCount": 689,
          "title": "Speak or Chat with Me: End-to-End Spoken Language Understanding System with Flexible Inputs. (arXiv:2104.05752v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09356",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rezaei_S/0/1/0/all/0/1\">Seyed Saeed Changiz Rezaei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_F/0/1/0/all/0/1\">Fred X. Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_D/0/1/0/all/0/1\">Di Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salameh_M/0/1/0/all/0/1\">Mohammad Salameh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mills_K/0/1/0/all/0/1\">Keith Mills</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lian_S/0/1/0/all/0/1\">Shuo Lian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1\">Wei Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jui_S/0/1/0/all/0/1\">Shangling Jui</a>",
          "description": "Despite the empirical success of neural architecture search (NAS) in deep\nlearning applications, the optimality, reproducibility and cost of NAS schemes\nremain hard to assess. In this paper, we propose Generative Adversarial NAS\n(GA-NAS) with theoretically provable convergence guarantees, promoting\nstability and reproducibility in neural architecture search. Inspired by\nimportance sampling, GA-NAS iteratively fits a generator to previously\ndiscovered top architectures, thus increasingly focusing on important parts of\na large search space. Furthermore, we propose an efficient adversarial learning\napproach, where the generator is trained by reinforcement learning based on\nrewards provided by a discriminator, thus being able to explore the search\nspace without evaluating a large number of architectures. Extensive experiments\nshow that GA-NAS beats the best published results under several cases on three\npublic NAS benchmarks. In the meantime, GA-NAS can handle ad-hoc search\nconstraints and search spaces. We show that GA-NAS can be used to improve\nalready optimized baselines found by other NAS methods, including EfficientNet\nand ProxylessNAS, in terms of ImageNet accuracy or the number of parameters, in\ntheir original search space.",
          "link": "http://arxiv.org/abs/2105.09356",
          "publishedOn": "2021-06-15T01:45:17.236Z",
          "wordCount": 655,
          "title": "Generative Adversarial Neural Architecture Search. (arXiv:2105.09356v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.05632",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1\">Renyi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_M/0/1/0/all/0/1\">Molei Tao</a>",
          "description": "We consider the learning and prediction of nonlinear time series generated by\na latent symplectic map. A special case is (not necessarily separable)\nHamiltonian systems, whose solution flows give such symplectic maps. For this\nspecial case, both generic approaches based on learning the vector field of the\nlatent ODE and specialized approaches based on learning the Hamiltonian that\ngenerates the vector field exist. Our method, however, is different as it does\nnot rely on the vector field nor assume its existence; instead, it directly\nlearns the symplectic evolution map in discrete time. Moreover, we do so by\nrepresenting the symplectic map via a generating function, which we approximate\nby a neural network (hence the name GFNN). This way, our approximation of the\nevolution map is always \\emph{exactly} symplectic. This additional geometric\nstructure allows the local prediction error at each step to accumulate in a\ncontrolled fashion, and we will prove, under reasonable assumptions, that the\nglobal prediction error grows at most \\emph{linearly} with long prediction\ntime, which significantly improves an otherwise exponential growth. In\naddition, as a map-based and thus purely data-driven method, GFNN avoids two\nadditional sources of inaccuracies common in vector-field based approaches,\nnamely the error in approximating the vector field by finite difference of the\ndata, and the error in numerical integration of the vector field for making\npredictions. Numerical experiments further demonstrate our claims.",
          "link": "http://arxiv.org/abs/2103.05632",
          "publishedOn": "2021-06-15T01:45:17.227Z",
          "wordCount": 700,
          "title": "Data-driven Prediction of General Hamiltonian Dynamics via Learning Exactly-Symplectic Maps. (arXiv:2103.05632v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.05077",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chrysos_G/0/1/0/all/0/1\">Grigorios G Chrysos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Georgopoulos_M/0/1/0/all/0/1\">Markos Georgopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panagakis_Y/0/1/0/all/0/1\">Yannis Panagakis</a>",
          "description": "Generative modeling has evolved to a notable field of machine learning. Deep\npolynomial neural networks (PNNs) have demonstrated impressive results in\nunsupervised image generation, where the task is to map an input vector (i.e.,\nnoise) to a synthesized image. However, the success of PNNs has not been\nreplicated in conditional generation tasks, such as super-resolution. Existing\nPNNs focus on single-variable polynomial expansions which do not fare well to\ntwo-variable inputs, i.e., the noise variable and the conditional variable. In\nthis work, we introduce a general framework, called CoPE, that enables a\npolynomial expansion of two input variables and captures their auto- and\ncross-correlations. We exhibit how CoPE can be trivially augmented to accept an\narbitrary number of input variables. CoPE is evaluated in five tasks\n(class-conditional generation, inverse problems, edges-to-image translation,\nimage-to-image translation, attribute-guided generation) involving eight\ndatasets. The thorough evaluation suggests that CoPE can be useful for tackling\ndiverse conditional generation tasks.",
          "link": "http://arxiv.org/abs/2104.05077",
          "publishedOn": "2021-06-15T01:45:17.218Z",
          "wordCount": 612,
          "title": "CoPE: Conditional image generation using Polynomial Expansions. (arXiv:2104.05077v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.12668",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tsukamoto_H/0/1/0/all/0/1\">Hiroyasu Tsukamoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chung_S/0/1/0/all/0/1\">Soon-Jo Chung</a>",
          "description": "This paper presents Learning-based Autonomous Guidance with RObustness and\nStability guarantees (LAG-ROS), which provides machine learning-based nonlinear\nmotion planners with formal robustness and stability guarantees, by designing a\ndifferential Lyapunov function using contraction theory. LAG-ROS utilizes a\nneural network to model a robust tracking controller independently of a target\ntrajectory, for which we show that the Euclidean distance between the target\nand controlled trajectories is exponentially bounded linearly in the learning\nerror, even under the existence of bounded external disturbances. We also\npresent a convex optimization approach that minimizes the steady-state bound of\nthe tracking error to construct the robust control law for neural network\ntraining. In numerical simulations, it is demonstrated that the proposed method\nindeed possesses superior properties of robustness and nonlinear stability\nresulting from contraction theory, whilst retaining the computational\nefficiency of existing learning-based motion planners.",
          "link": "http://arxiv.org/abs/2102.12668",
          "publishedOn": "2021-06-15T01:45:17.212Z",
          "wordCount": 623,
          "title": "Learning-based Robust Motion Planning with Guaranteed Stability: A Contraction Theory Approach. (arXiv:2102.12668v3 [cs.RO] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.01826",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Levanon_S/0/1/0/all/0/1\">Sagi Levanon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosenfeld_N/0/1/0/all/0/1\">Nir Rosenfeld</a>",
          "description": "Strategic classification regards the problem of learning in settings where\nusers can strategically modify their features to improve outcomes. This setting\napplies broadly and has received much recent attention. But despite its\npractical significance, work in this space has so far been predominantly\ntheoretical. In this paper we present a learning framework for strategic\nclassification that is practical. Our approach directly minimizes the\n\"strategic\" empirical risk, achieved by differentiating through the strategic\nresponse of users. This provides flexibility that allows us to extend beyond\nthe original problem formulation and towards more realistic learning scenarios.\nA series of experiments demonstrates the effectiveness of our approach on\nvarious learning settings.",
          "link": "http://arxiv.org/abs/2103.01826",
          "publishedOn": "2021-06-15T01:45:17.204Z",
          "wordCount": 552,
          "title": "Strategic Classification Made Practical. (arXiv:2103.01826v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02297",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Kim_J/0/1/0/all/0/1\">Ji-Hoon Kim</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_S/0/1/0/all/0/1\">Sang-Hoon Lee</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_J/0/1/0/all/0/1\">Ji-Hyun Lee</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_S/0/1/0/all/0/1\">Seong-Whan Lee</a>",
          "description": "Although recent works on neural vocoder have improved the quality of\nsynthesized audio, there still exists a gap between generated and ground-truth\naudio in frequency space. This difference leads to spectral artifacts such as\nhissing noise or reverberation, and thus degrades the sample quality. In this\npaper, we propose Fre-GAN which achieves frequency-consistent audio synthesis\nwith highly improved generation quality. Specifically, we first present\nresolution-connected generator and resolution-wise discriminators, which help\nlearn various scales of spectral distributions over multiple frequency bands.\nAdditionally, to reproduce high-frequency components accurately, we leverage\ndiscrete wavelet transform in the discriminators. From our experiments, Fre-GAN\nachieves high-fidelity waveform generation with a gap of only 0.03 MOS compared\nto ground-truth audio while outperforming standard models in quality.",
          "link": "http://arxiv.org/abs/2106.02297",
          "publishedOn": "2021-06-15T01:45:17.166Z",
          "wordCount": 573,
          "title": "Fre-GAN: Adversarial Frequency-consistent Audio Synthesis. (arXiv:2106.02297v2 [eess.AS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.10040",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Combettes_C/0/1/0/all/0/1\">Cyrille W. Combettes</a>, <a href=\"http://arxiv.org/find/math/1/au:+Pokutta_S/0/1/0/all/0/1\">Sebastian Pokutta</a>",
          "description": "The Frank-Wolfe algorithm is a method for constrained optimization that\nrelies on linear minimizations, as opposed to projections. Therefore, a\nmotivation put forward in a large body of work on the Frank-Wolfe algorithm is\nthe computational advantage of solving linear minimizations instead of\nprojections. However, the discussions supporting this advantage are often too\nsuccinct or incomplete. In this paper, we review the complexity bounds for both\ntasks on several sets commonly used in optimization. Projection methods onto\nthe $\\ell_p$-ball, $p\\in\\left]1,2\\right[\\cup\\left]2,+\\infty\\right[$, and the\nBirkhoff polytope are also proposed.",
          "link": "http://arxiv.org/abs/2101.10040",
          "publishedOn": "2021-06-15T01:45:17.151Z",
          "wordCount": 545,
          "title": "Complexity of Linear Minimization and Projection on Some Sets. (arXiv:2101.10040v2 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.07108",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yan_S/0/1/0/all/0/1\">Shen Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_K/0/1/0/all/0/1\">Kaiqiang Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mi Zhang</a>",
          "description": "Recent works (White et al., 2020a; Yan et al., 2020) demonstrate the\nimportance of architecture encodings in Neural Architecture Search (NAS). These\nencodings encode either structure or computation information of the neural\narchitectures. Compared to structure-aware encodings, computation-aware\nencodings map architectures with similar accuracies to the same region, which\nimproves the downstream architecture search performance (Zhang et al., 2019;\nWhite et al., 2020a). In this work, we introduce a Computation-Aware\nTransformer-based Encoding method called CATE. Different from existing\ncomputation-aware encodings based on fixed transformation (e.g. path encoding),\nCATE employs a pairwise pre-training scheme to learn computation-aware\nencodings using Transformers with cross-attention. Such learned encodings\ncontain dense and contextualized computation information of neural\narchitectures. We compare CATE with eleven encodings under three major\nencoding-dependent NAS subroutines in both small and large search spaces. Our\nexperiments show that CATE is beneficial to the downstream search, especially\nin the large search space. Moreover, the outside search space experiment\ndemonstrates its superior generalization ability beyond the search space on\nwhich it was trained. Our code is available at:\nhttps://github.com/MSU-MLSys-Lab/CATE.",
          "link": "http://arxiv.org/abs/2102.07108",
          "publishedOn": "2021-06-15T01:45:17.145Z",
          "wordCount": 635,
          "title": "CATE: Computation-aware Neural Architecture Encoding with Transformers. (arXiv:2102.07108v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.02414",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_Y/0/1/0/all/0/1\">Yivan Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Niu_G/0/1/0/all/0/1\">Gang Niu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masashi Sugiyama</a>",
          "description": "Many weakly supervised classification methods employ a noise transition\nmatrix to capture the class-conditional label corruption. To estimate the\ntransition matrix from noisy data, existing methods often need to estimate the\nnoisy class-posterior, which could be unreliable due to the overconfidence of\nneural networks. In this work, we propose a theoretically grounded method that\ncan estimate the noise transition matrix and learn a classifier simultaneously,\nwithout relying on the error-prone noisy class-posterior estimation.\nConcretely, inspired by the characteristics of the stochastic label corruption\nprocess, we propose total variation regularization, which encourages the\npredicted probabilities to be more distinguishable from each other. Under mild\nassumptions, the proposed method yields a consistent estimator of the\ntransition matrix. We show the effectiveness of the proposed method through\nexperiments on benchmark and real-world datasets.",
          "link": "http://arxiv.org/abs/2102.02414",
          "publishedOn": "2021-06-15T01:45:17.125Z",
          "wordCount": 586,
          "title": "Learning Noise Transition Matrix from Only Noisy Labels via Total Variation Regularization. (arXiv:2102.02414v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.07475",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Christianos_F/0/1/0/all/0/1\">Filippos Christianos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papoudakis_G/0/1/0/all/0/1\">Georgios Papoudakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahman_A/0/1/0/all/0/1\">Arrasy Rahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Albrecht_S/0/1/0/all/0/1\">Stefano V. Albrecht</a>",
          "description": "Sharing parameters in multi-agent deep reinforcement learning has played an\nessential role in allowing algorithms to scale to a large number of agents.\nParameter sharing between agents significantly decreases the number of\ntrainable parameters, shortening training times to tractable levels, and has\nbeen linked to more efficient learning. However, having all agents share the\nsame parameters can also have a detrimental effect on learning. We demonstrate\nthe impact of parameter sharing methods on training speed and converged\nreturns, establishing that when applied indiscriminately, their effectiveness\nis highly dependent on the environment. We propose a novel method to\nautomatically identify agents which may benefit from sharing parameters by\npartitioning them based on their abilities and goals. Our approach combines the\nincreased sample efficiency of parameter sharing with the representational\ncapacity of multiple independent networks to reduce training time and increase\nfinal returns.",
          "link": "http://arxiv.org/abs/2102.07475",
          "publishedOn": "2021-06-15T01:45:17.007Z",
          "wordCount": 616,
          "title": "Scaling Multi-Agent Reinforcement Learning with Selective Parameter Sharing. (arXiv:2102.07475v2 [cs.MA] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.00151",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Le_H/0/1/0/all/0/1\">Hung Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sankar_C/0/1/0/all/0/1\">Chinnadhurai Sankar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moon_S/0/1/0/all/0/1\">Seungwhan Moon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beirami_A/0/1/0/all/0/1\">Ahmad Beirami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geramifard_A/0/1/0/all/0/1\">Alborz Geramifard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kottur_S/0/1/0/all/0/1\">Satwik Kottur</a>",
          "description": "A video-grounded dialogue system is required to understand both dialogue,\nwhich contains semantic dependencies from turn to turn, and video, which\ncontains visual cues of spatial and temporal scene variations. Building such\ndialogue systems is a challenging problem, involving various reasoning types on\nboth visual and language inputs. Existing benchmarks do not have enough\nannotations to thoroughly analyze dialogue systems and understand their\ncapabilities and limitations in isolation. These benchmarks are also not\nexplicitly designed to minimise biases that models can exploit without actual\nreasoning. To address these limitations, in this paper, we present DVD, a\nDiagnostic Dataset for Video-grounded Dialogues. The dataset is designed to\ncontain minimal biases and has detailed annotations for the different types of\nreasoning over the spatio-temporal space of video. Dialogues are synthesized\nover multiple question turns, each of which is injected with a set of\ncross-turn semantic relationships. We use DVD to analyze existing approaches,\nproviding interesting insights into their abilities and limitations. In total,\nDVD is built from $11k$ CATER synthetic videos and contains $10$ instances of\n$10$-round dialogues for each video, resulting in more than $100k$ dialogues\nand $1M$ question-answer pairs. Our code and dataset are publicly available at\nhttps://github.com/facebookresearch/DVDialogues.",
          "link": "http://arxiv.org/abs/2101.00151",
          "publishedOn": "2021-06-15T01:45:16.958Z",
          "wordCount": 688,
          "title": "DVD: A Diagnostic Dataset for Multi-step Reasoning in Video Grounded Dialogue. (arXiv:2101.00151v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06615",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Noci_L/0/1/0/all/0/1\">Lorenzo Noci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bachmann_G/0/1/0/all/0/1\">Gregor Bachmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_K/0/1/0/all/0/1\">Kevin Roth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nowozin_S/0/1/0/all/0/1\">Sebastian Nowozin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hofmann_T/0/1/0/all/0/1\">Thomas Hofmann</a>",
          "description": "Recent works on Bayesian neural networks (BNNs) have highlighted the need to\nbetter understand the implications of using Gaussian priors in combination with\nthe compositional structure of the network architecture. Similar in spirit to\nthe kind of analysis that has been developed to devise better initialization\nschemes for neural networks (cf. He- or Xavier initialization), we derive a\nprecise characterization of the prior predictive distribution of finite-width\nReLU networks with Gaussian weights. While theoretical results have been\nobtained for their heavy-tailedness, the full characterization of the prior\npredictive distribution (i.e. its density, CDF and moments), remained unknown\nprior to this work. Our analysis, based on the Meijer-G function, allows us to\nquantify the influence of architectural choices such as the width or depth of\nthe network on the resulting shape of the prior predictive distribution. We\nalso formally connect our results to previous work in the infinite width\nsetting, demonstrating that the moments of the distribution converge to those\nof a normal log-normal mixture in the infinite depth limit. Finally, our\nresults provide valuable guidance on prior design: for instance, controlling\nthe predictive variance with depth- and width-informed priors on the weights of\nthe network.",
          "link": "http://arxiv.org/abs/2106.06615",
          "publishedOn": "2021-06-15T01:45:16.951Z",
          "wordCount": 627,
          "title": "Precise characterization of the prior predictive distribution of deep ReLU networks. (arXiv:2106.06615v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06616",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_W/0/1/0/all/0/1\">Wenshuo Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kandasamy_K/0/1/0/all/0/1\">Kirthevasan Kandasamy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1\">Joseph E Gonzalez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1\">Michael I. Jordan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stoica_I/0/1/0/all/0/1\">Ion Stoica</a>",
          "description": "The sharing of scarce resources among multiple rational agents is one of the\nclassical problems in economics. In exchange economies, which are used to model\nsuch situations, agents begin with an initial endowment of resources and\nexchange them in a way that is mutually beneficial until they reach a\ncompetitive equilibrium (CE). CE allocations are Pareto efficient and fair.\nConsequently, they are used widely in designing mechanisms for fair division.\nHowever, computing CEs requires the knowledge of agent preferences which are\nunknown in several applications of interest. In this work, we explore a new\nonline learning mechanism, which, on each round, allocates resources to the\nagents and collects stochastic feedback on their experience in using that\nallocation. Its goal is to learn the agent utilities via this feedback and\nimitate the allocations at a CE in the long run. We quantify CE behavior via\ntwo losses and propose a randomized algorithm which achieves\n$\\bigOtilde(\\sqrt{T})$ loss after $T$ rounds under both criteria. Empirically,\nwe demonstrate the effectiveness of this mechanism through numerical\nsimulations.",
          "link": "http://arxiv.org/abs/2106.06616",
          "publishedOn": "2021-06-15T01:45:16.926Z",
          "wordCount": 605,
          "title": "Online Learning of Competitive Equilibria in Exchange Economies. (arXiv:2106.06616v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06976",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moghadam_M/0/1/0/all/0/1\">Monireh Mohebbi Moghadam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boroumand_B/0/1/0/all/0/1\">Bahar Boroumand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jalali_M/0/1/0/all/0/1\">Mohammad Jalali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zareian_A/0/1/0/all/0/1\">Arman Zareian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Javad_A/0/1/0/all/0/1\">Alireza Daei Javad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manshaei_M/0/1/0/all/0/1\">Mohammad Hossein Manshaei</a>",
          "description": "Generative Adversarial Network, as a promising research direction in the AI\ncommunity, recently attracts considerable attention due to its ability to\ngenerating high-quality realistic data. GANs are a competing game between two\nneural networks trained in an adversarial manner to reach a Nash equilibrium.\nDespite the improvement accomplished in GANs in the last years, there remain\nseveral issues to solve. In this way, how to tackle these issues and make\nadvances leads to rising research interests. This paper reviews literature that\nleverages the game theory in GANs and addresses how game models can relieve\nspecific generative models' challenges and improve the GAN's performance. In\nparticular, we firstly review some preliminaries, including the basic GAN model\nand some game theory backgrounds. After that, we present our taxonomy to\nsummarize the state-of-the-art solutions into three significant categories:\nmodified game model, modified architecture, and modified learning method. The\nclassification is based on the modifications made in the basic model by the\nproposed approaches from the game-theoretic perspective. We further classify\neach category into several subcategories. Following the proposed taxonomy, we\nexplore the main objective of each class and review the recent work in each\ngroup. Finally, we discuss the remaining challenges in this field and present\nthe potential future research topics.",
          "link": "http://arxiv.org/abs/2106.06976",
          "publishedOn": "2021-06-15T01:45:16.912Z",
          "wordCount": 663,
          "title": "Game of GANs: Game Theoretical Models for Generative Adversarial Networks. (arXiv:2106.06976v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2010.14860",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lucke_J/0/1/0/all/0/1\">J&#xf6;rg L&#xfc;cke</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Forster_D/0/1/0/all/0/1\">Dennis Forster</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dai_Z/0/1/0/all/0/1\">Zhenwen Dai</a>",
          "description": "The central objective function of a variational autoencoder (VAE) is its\nvariational lower bound. Here we show that for standard VAEs the variational\nbound converges to a value given by the sum of three entropies: the (negative)\nentropy of the latent distribution, the expected (negative) entropy of the\nobservable distribution, and the average entropy of the variational\ndistributions. Our derived analytical results are exact and apply for small as\nwell as complex neural networks for decoder and encoder. Furthermore, they\napply for finitely and infinitely many data points and at any stationary point\n(including local and global maxima). As a consequence, we show that the\nvariance parameters of encoder and decoder play the key role in determining the\nvalues of variational bounds at stationary points. Furthermore, the obtained\nresults can allow for closed-form analytical expressions at points of\nconvergence, which may be unexpected as neither variational lower bounds of\nVAEs nor log-likelihoods of VAEs are closed-form during learning. As our main\ncontribution, we provide the proofs for convergence of standard VAEs to sums of\nentropies. Furthermore, we numerically verify our analytical results and\ndiscuss some potential applications. The obtained equality to entropy sums\nprovides novel information on those points in parameter space that variational\nlearning converges to. As such, we believe, they can contribute to our\nunderstanding of established as well as novel VAE approaches.",
          "link": "http://arxiv.org/abs/2010.14860",
          "publishedOn": "2021-06-15T01:45:16.905Z",
          "wordCount": 704,
          "title": "The Evidence Lower Bound of Variational Autoencoders Converges to a Sum of Three Entropies. (arXiv:2010.14860v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06920",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Katuwandeniya_K/0/1/0/all/0/1\">Kavindie Katuwandeniya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiss_S/0/1/0/all/0/1\">Stefan H. Kiss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_L/0/1/0/all/0/1\">Lei Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miro_J/0/1/0/all/0/1\">Jaime Valls Miro</a>",
          "description": "A multi-modal framework to generated user intention distributions when\noperating a mobile vehicle is proposed in this work. The model learns from past\nobserved trajectories and leverages traversability information derived from the\nvisual surroundings to produce a set of future trajectories, suitable to be\ndirectly embedded into a perception-action shared control strategy on a mobile\nagent, or as a safety layer to supervise the prudent operation of the vehicle.\nWe base our solution on a conditional Generative Adversarial Network with\nLong-Short Term Memory cells to capture trajectory distributions conditioned on\npast trajectories, further fused with traversability probabilities derived from\nvisual segmentation with a Convolutional Neural Network. The proposed\ndata-driven framework results in a significant reduction in error of the\npredicted trajectories (versus the ground truth) from comparable strategies in\nthe literature (e.g. Social-GAN) that fail to account for information other\nthan the agent's past history. Experiments were conducted on a dataset\ncollected with a custom wheelchair model built onto the open-source urban\ndriving simulator CARLA, proving also that the proposed framework can be used\nwith a small, un-annotated dataset.",
          "link": "http://arxiv.org/abs/2106.06920",
          "publishedOn": "2021-06-15T01:45:16.897Z",
          "wordCount": 610,
          "title": "Multi-modal Scene-compliant User Intention Estimation for Navigation. (arXiv:2106.06920v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06741",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Li_M/0/1/0/all/0/1\">Mengmeng Li</a>, <a href=\"http://arxiv.org/find/math/1/au:+Sutter_T/0/1/0/all/0/1\">Tobias Sutter</a>, <a href=\"http://arxiv.org/find/math/1/au:+Kuhn_D/0/1/0/all/0/1\">Daniel Kuhn</a>",
          "description": "We study a stochastic program where the probability distribution of the\nuncertain problem parameters is unknown and only indirectly observed via\nfinitely many correlated samples generated by an unknown Markov chain with $d$\nstates. We propose a data-driven distributionally robust optimization model to\nestimate the problem's objective function and optimal solution. By leveraging\nresults from large deviations theory, we derive statistical guarantees on the\nquality of these estimators. The underlying worst-case expectation problem is\nnonconvex and involves $\\mathcal O(d^2)$ decision variables. Thus, it cannot be\nsolved efficiently for large $d$. By exploiting the structure of this problem,\nwe devise a customized Frank-Wolfe algorithm with convex direction-finding\nsubproblems of size $\\mathcal O(d)$. We prove that this algorithm finds a\nstationary point efficiently under mild conditions. The efficiency of the\nmethod is predicated on a dimensionality reduction enabled by a dual\nreformulation. Numerical experiments indicate that our approach has better\ncomputational and statistical properties than the state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2106.06741",
          "publishedOn": "2021-06-15T01:45:16.884Z",
          "wordCount": 587,
          "title": "Distributionally Robust Optimization with Markovian Data. (arXiv:2106.06741v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06984",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuhang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Shikuang Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1\">Xin Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_R/0/1/0/all/0/1\">Ruihao Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_S/0/1/0/all/0/1\">Shi Gu</a>",
          "description": "Spiking Neural Network (SNN) has been recognized as one of the next\ngeneration of neural networks. Conventionally, SNN can be converted from a\npre-trained ANN by only replacing the ReLU activation to spike activation while\nkeeping the parameters intact. Perhaps surprisingly, in this work we show that\na proper way to calibrate the parameters during the conversion of ANN to SNN\ncan bring significant improvements. We introduce SNN Calibration, a cheap but\nextraordinarily effective method by leveraging the knowledge within a\npre-trained Artificial Neural Network (ANN). Starting by analyzing the\nconversion error and its propagation through layers theoretically, we propose\nthe calibration algorithm that can correct the error layer-by-layer. The\ncalibration only takes a handful number of training data and several minutes to\nfinish. Moreover, our calibration algorithm can produce SNN with\nstate-of-the-art architecture on the large-scale ImageNet dataset, including\nMobileNet and RegNet. Extensive experiments demonstrate the effectiveness and\nefficiency of our algorithm. For example, our advanced pipeline can increase up\nto 69% top-1 accuracy when converting MobileNet on ImageNet compared to\nbaselines. Codes are released at https://github.com/yhhhli/SNN_Calibration.",
          "link": "http://arxiv.org/abs/2106.06984",
          "publishedOn": "2021-06-15T01:45:16.794Z",
          "wordCount": 613,
          "title": "A Free Lunch From ANN: Towards Efficient, Accurate Spiking Neural Networks Calibration. (arXiv:2106.06984v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.04779",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1\">Yu Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiusheng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_W/0/1/0/all/0/1\">Weizhen Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhendawade_N/0/1/0/all/0/1\">Nikhil Bhendawade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1\">Yeyun Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1\">Nan Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ruofei Zhang</a>",
          "description": "Transformer model with multi-head attention requires caching intermediate\nresults for efficient inference in generation tasks. However, cache brings new\nmemory-related costs and prevents leveraging larger batch size for faster\nspeed. We propose memory-efficient lossless attention (called EL-attention) to\naddress this issue. It avoids heavy operations for building multi-head keys and\nvalues, cache for them is not needed. EL-attention constructs an ensemble of\nattention results by expanding query while keeping key and value shared. It\nproduces the same result as multi-head attention with less GPU memory and\nfaster inference speed. We conduct extensive experiments on Transformer, BART,\nand GPT-2 for summarization and question generation tasks. The results show\nEL-attention speeds up existing models by 1.6x to 5.3x without accuracy loss.",
          "link": "http://arxiv.org/abs/2105.04779",
          "publishedOn": "2021-06-15T01:45:16.717Z",
          "wordCount": 589,
          "title": "EL-Attention: Memory Efficient Lossless Attention for Generation. (arXiv:2105.04779v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06682",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Liang_S/0/1/0/all/0/1\">Senwei Liang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Jiang_S/0/1/0/all/0/1\">Shixiao W. Jiang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Harlim_J/0/1/0/all/0/1\">John Harlim</a>, <a href=\"http://arxiv.org/find/math/1/au:+Yang_H/0/1/0/all/0/1\">Haizhao Yang</a>",
          "description": "This paper proposes a mesh-free computational framework and machine learning\ntheory for solving elliptic PDEs on unknown manifolds, identified with point\nclouds, based on diffusion maps (DM) and deep learning. The PDE solver is\nformulated as a supervised learning task to solve a least-squares regression\nproblem that imposes an algebraic equation approximating a PDE (and boundary\nconditions if applicable). This algebraic equation involves a graph-Laplacian\ntype matrix obtained via DM asymptotic expansion, which is a consistent\nestimator of second-order elliptic differential operators. The resulting\nnumerical method is to solve a highly non-convex empirical risk minimization\nproblem subjected to a solution from a hypothesis space of neural-network type\nfunctions. In a well-posed elliptic PDE setting, when the hypothesis space\nconsists of feedforward neural networks with either infinite width or depth, we\nshow that the global minimizer of the empirical loss function is a consistent\nsolution in the limit of large training data. When the hypothesis space is a\ntwo-layer neural network, we show that for a sufficiently large width, the\ngradient descent method can identify a global minimizer of the empirical loss\nfunction. Supporting numerical examples demonstrate the convergence of the\nsolutions and the effectiveness of the proposed solver in avoiding numerical\nissues that hampers the traditional approach when a large data set becomes\navailable, e.g., large matrix inversion.",
          "link": "http://arxiv.org/abs/2106.06682",
          "publishedOn": "2021-06-15T01:45:16.711Z",
          "wordCount": 648,
          "title": "Solving PDEs on Unknown Manifolds with Machine Learning. (arXiv:2106.06682v1 [math.NA])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06796",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wadu_M/0/1/0/all/0/1\">Madhusanka Manimel Wadu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samarakoon_S/0/1/0/all/0/1\">Sumudu Samarakoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bennis_M/0/1/0/all/0/1\">Mehdi Bennis</a>",
          "description": "The performance of federated learning (FL) over wireless networks depend on\nthe reliability of the client-server connectivity and clients' local\ncomputation capabilities. In this article we investigate the problem of client\nscheduling and resource block (RB) allocation to enhance the performance of\nmodel training using FL, over a pre-defined training duration under imperfect\nchannel state information (CSI) and limited local computing resources. First,\nwe analytically derive the gap between the training losses of FL with clients\nscheduling and a centralized training method for a given training duration.\nThen, we formulate the gap of the training loss minimization over client\nscheduling and RB allocation as a stochastic optimization problem and solve it\nusing Lyapunov optimization. A Gaussian process regression-based channel\nprediction method is leveraged to learn and track the wireless channel, in\nwhich, the clients' CSI predictions and computing power are incorporated into\nthe scheduling decision. Using an extensive set of simulations, we validate the\nrobustness of the proposed method under both perfect and imperfect CSI over an\narray of diverse data distributions. Results show that the proposed method\nreduces the gap of the training accuracy loss by up to 40.7% compared to\nstate-of-theart client scheduling and RB allocation methods.",
          "link": "http://arxiv.org/abs/2106.06796",
          "publishedOn": "2021-06-15T01:45:16.689Z",
          "wordCount": 641,
          "title": "Joint Client Scheduling and Resource Allocation under Channel Uncertainty in Federated Learning. (arXiv:2106.06796v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2003.00330",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lamb_L/0/1/0/all/0/1\">Luis C. Lamb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garcez_A/0/1/0/all/0/1\">Artur Garcez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gori_M/0/1/0/all/0/1\">Marco Gori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prates_M/0/1/0/all/0/1\">Marcelo Prates</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Avelar_P/0/1/0/all/0/1\">Pedro Avelar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vardi_M/0/1/0/all/0/1\">Moshe Vardi</a>",
          "description": "Neural-symbolic computing has now become the subject of interest of both\nacademic and industry research laboratories. Graph Neural Networks (GNN) have\nbeen widely used in relational and symbolic domains, with widespread\napplication of GNNs in combinatorial optimization, constraint satisfaction,\nrelational reasoning and other scientific domains. The need for improved\nexplainability, interpretability and trust of AI systems in general demands\nprincipled methodologies, as suggested by neural-symbolic computing. In this\npaper, we review the state-of-the-art on the use of GNNs as a model of\nneural-symbolic computing. This includes the application of GNNs in several\ndomains as well as its relationship to current developments in neural-symbolic\ncomputing.",
          "link": "http://arxiv.org/abs/2003.00330",
          "publishedOn": "2021-06-15T01:45:16.653Z",
          "wordCount": 645,
          "title": "Graph Neural Networks Meet Neural-Symbolic Computing: A Survey and Perspective. (arXiv:2003.00330v7 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06784",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Khan_Z/0/1/0/all/0/1\">Zohaib Amjad Khan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Beghdadi_A/0/1/0/all/0/1\">Azeddine Beghdadi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kaaniche_M/0/1/0/all/0/1\">Mounir Kaaniche</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cheikh_F/0/1/0/all/0/1\">Faouzi Alaya Cheikh</a>",
          "description": "Laparoscopic images and videos are often affected by different types of\ndistortion like noise, smoke, blur and nonuniform illumination. Automatic\ndetection of these distortions, followed generally by application of\nappropriate image quality enhancement methods, is critical to avoid errors\nduring surgery. In this context, a crucial step involves an objective\nassessment of the image quality, which is a two-fold problem requiring both the\nclassification of the distortion type affecting the image and the estimation of\nthe severity level of that distortion. Unlike existing image quality measures\nwhich focus mainly on estimating a quality score, we propose in this paper to\nformulate the image quality assessment task as a multi-label classification\nproblem taking into account both the type as well as the severity level (or\nrank) of distortions. Here, this problem is then solved by resorting to a deep\nneural networks based approach. The obtained results on a laparoscopic image\ndataset show the efficiency of the proposed approach.",
          "link": "http://arxiv.org/abs/2106.06784",
          "publishedOn": "2021-06-15T01:45:16.640Z",
          "wordCount": 611,
          "title": "Residual Networks based Distortion Classification and Ranking for Laparoscopic Image Quality Assessment. (arXiv:2106.06784v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2102.03716",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_W/0/1/0/all/0/1\">Wuxinlin Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_C/0/1/0/all/0/1\">Chenhui Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1\">Zhiqiang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1\">Yaohui Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhiru Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1\">Zhuo Feng</a>",
          "description": "A black-box spectral method is introduced for evaluating the adversarial\nrobustness of a given machine learning (ML) model. Our approach, named SPADE,\nexploits bijective distance mapping between the input/output graphs constructed\nfor approximating the manifolds corresponding to the input/output data. By\nleveraging the generalized Courant-Fischer theorem, we propose a SPADE score\nfor evaluating the adversarial robustness of a given model, which is proved to\nbe an upper bound of the best Lipschitz constant under the manifold setting. To\nreveal the most non-robust data samples highly vulnerable to adversarial\nattacks, we develop a spectral graph embedding procedure leveraging dominant\ngeneralized eigenvectors. This embedding step allows assigning each data sample\na robustness score that can be further harnessed for more effective adversarial\ntraining. Our experiments show the proposed SPADE method leads to promising\nempirical results for neural network models that are adversarially trained with\nthe MNIST and CIFAR-10 data sets.",
          "link": "http://arxiv.org/abs/2102.03716",
          "publishedOn": "2021-06-15T01:45:16.631Z",
          "wordCount": 635,
          "title": "SPADE: A Spectral Method for Black-Box Adversarial Robustness Evaluation. (arXiv:2102.03716v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2002.03629",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yang Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_C/0/1/0/all/0/1\">Chenlin Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_R/0/1/0/all/0/1\">Renjie Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ermon_S/0/1/0/all/0/1\">Stefano Ermon</a>",
          "description": "Feedforward computation, such as evaluating a neural network or sampling from\nan autoregressive model, is ubiquitous in machine learning. The sequential\nnature of feedforward computation, however, requires a strict order of\nexecution and cannot be easily accelerated with parallel computing. To enable\nparallelization, we frame the task of feedforward computation as solving a\nsystem of nonlinear equations. We then propose to find the solution using a\nJacobi or Gauss-Seidel fixed-point iteration method, as well as hybrid methods\nof both. Crucially, Jacobi updates operate independently on each equation and\ncan be executed in parallel. Our method is guaranteed to give exactly the same\nvalues as the original feedforward computation with a reduced (or equal) number\nof parallelizable iterations, and hence reduced time given sufficient parallel\ncomputing power. Experimentally, we demonstrate the effectiveness of our\napproach in accelerating (i) backpropagation of RNNs, (ii) evaluation of\nDenseNets, and (iii) autoregressive sampling of MADE and PixelCNN++, with\nspeedup factors between 2.1 and 26 under various settings.",
          "link": "http://arxiv.org/abs/2002.03629",
          "publishedOn": "2021-06-15T01:45:16.611Z",
          "wordCount": 623,
          "title": "Accelerating Feedforward Computation via Parallel Nonlinear Equation Solving. (arXiv:2002.03629v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.06810",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yuandong Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xinlei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganguli_S/0/1/0/all/0/1\">Surya Ganguli</a>",
          "description": "While contrastive approaches of self-supervised learning (SSL) learn\nrepresentations by minimizing the distance between two augmented views of the\nsame data point (positive pairs) and maximizing views from different data\npoints (negative pairs), recent \\emph{non-contrastive} SSL (e.g., BYOL and\nSimSiam) show remarkable performance {\\it without} negative pairs, with an\nextra learnable predictor and a stop-gradient operation. A fundamental question\narises: why do these methods not collapse into trivial representations? We\nanswer this question via a simple theoretical study and propose a novel\napproach, DirectPred, that \\emph{directly} sets the linear predictor based on\nthe statistics of its inputs, without gradient training. On ImageNet, it\nperforms comparably with more complex two-layer non-linear predictors that\nemploy BatchNorm and outperforms a linear predictor by $2.5\\%$ in 300-epoch\ntraining (and $5\\%$ in 60-epoch). DirectPred is motivated by our theoretical\nstudy of the nonlinear learning dynamics of non-contrastive SSL in simple\nlinear networks. Our study yields conceptual insights into how non-contrastive\nSSL methods learn, how they avoid representational collapse, and how multiple\nfactors, like predictor networks, stop-gradients, exponential moving averages,\nand weight decay all come into play. Our simple theory recapitulates the\nresults of real-world ablation studies in both STL-10 and ImageNet. Code is\nreleased\\footnote{\\url{https://github.com/facebookresearch/luckmatters/tree/master/ssl}}.",
          "link": "http://arxiv.org/abs/2102.06810",
          "publishedOn": "2021-06-15T01:45:16.589Z",
          "wordCount": 664,
          "title": "Understanding self-supervised Learning Dynamics without Contrastive Pairs. (arXiv:2102.06810v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.13906",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Martin_J/0/1/0/all/0/1\">J&#xf6;rg Martin</a>",
          "description": "In cases where a Wasserstein GAN depends on a condition the latter is usually\nhandled via an expectation within the loss function. Depending on the way this\nis motivated, the discriminator is either required to be Lipschitz-1 in both or\nin only one of its arguments. For the weaker requirement to become usable one\nneeds to exchange a supremum and an expectation. This is a mathematically\nperilous operation, which is, so far, only partially justified in the\nliterature. This short mathematical note intends to fill this gap and provides\nthe mathematical rationale for discriminators that are only partially\nLipschitz-1 for cases where this approach is more appropriate or successful.",
          "link": "http://arxiv.org/abs/2103.13906",
          "publishedOn": "2021-06-15T01:45:16.578Z",
          "wordCount": 556,
          "title": "About exchanging expectation and supremum for conditional Wasserstein GANs. (arXiv:2103.13906v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.10630",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Killamsetty_K/0/1/0/all/0/1\">Krishnateja Killamsetty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sivasubramanian_D/0/1/0/all/0/1\">Durga Sivasubramanian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramakrishnan_G/0/1/0/all/0/1\">Ganesh Ramakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iyer_R/0/1/0/all/0/1\">Rishabh Iyer</a>",
          "description": "Large scale machine learning and deep models are extremely data-hungry.\nUnfortunately, obtaining large amounts of labeled data is expensive, and\ntraining state-of-the-art models (with hyperparameter tuning) requires\nsignificant computing resources and time. Secondly, real-world data is noisy\nand imbalanced. As a result, several recent papers try to make the training\nprocess more efficient and robust. However, most existing work either focuses\non robustness or efficiency, but not both. In this work, we introduce Glister,\na GeneraLIzation based data Subset selecTion for Efficient and Robust learning\nframework. We formulate Glister as a mixed discrete-continuous bi-level\noptimization problem to select a subset of the training data, which maximizes\nthe log-likelihood on a held-out validation set. Next, we propose an iterative\nonline algorithm Glister-Online, which performs data selection iteratively\nalong with the parameter updates and can be applied to any loss-based learning\nalgorithm. We then show that for a rich class of loss functions including\ncross-entropy, hinge-loss, squared-loss, and logistic-loss, the inner discrete\ndata selection is an instance of (weakly) submodular optimization, and we\nanalyze conditions for which Glister-Online reduces the validation loss and\nconverges. Finally, we propose Glister-Active, an extension to batch active\nlearning, and we empirically demonstrate the performance of Glister on a wide\nrange of tasks including, (a) data selection to reduce training time, (b)\nrobust learning under label noise and imbalance settings, and (c) batch-active\nlearning with several deep and shallow models. We show that our framework\nimproves upon state of the art both in efficiency and accuracy (in cases (a)\nand (c)) and is more efficient compared to other state-of-the-art robust\nlearning algorithms in case (b).",
          "link": "http://arxiv.org/abs/2012.10630",
          "publishedOn": "2021-06-15T01:45:16.546Z",
          "wordCount": 760,
          "title": "GLISTER: Generalization based Data Subset Selection for Efficient and Robust Learning. (arXiv:2012.10630v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03039",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ban_Y/0/1/0/all/0/1\">Yikun Ban</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jingrui He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cook_C/0/1/0/all/0/1\">Curtiss B. Cook</a>",
          "description": "Contextual multi-armed bandit has shown to be an effective tool in\nrecommender systems. In this paper, we study a novel problem of multi-facet\nbandits involving a group of bandits, each characterizing the users' needs from\none unique aspect. In each round, for the given user, we need to select one arm\nfrom each bandit, such that the combination of all arms maximizes the final\nreward. This problem can find immediate applications in E-commerce, healthcare,\netc. To address this problem, we propose a novel algorithm, named MuFasa, which\nutilizes an assembled neural network to jointly learn the underlying reward\nfunctions of multiple bandits. It estimates an Upper Confidence Bound (UCB)\nlinked with the expected reward to balance between exploitation and\nexploration. Under mild assumptions, we provide the regret analysis of MuFasa.\nIt can achieve the near-optimal $\\widetilde{ \\mathcal{O}}((K+1)\\sqrt{T})$\nregret bound where $K$ is the number of bandits and $T$ is the number of played\nrounds. Furthermore, we conduct extensive experiments to show that MuFasa\noutperforms strong baselines on real-world data sets.",
          "link": "http://arxiv.org/abs/2106.03039",
          "publishedOn": "2021-06-15T01:45:16.532Z",
          "wordCount": 611,
          "title": "Multi-facet Contextual Bandits: A Neural Network Perspective. (arXiv:2106.03039v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.03818",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiashuo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Zheyuan Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_P/0/1/0/all/0/1\">Peng Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1\">Zheyan Shen</a>",
          "description": "Machine learning algorithms with empirical risk minimization usually suffer\nfrom poor generalization performance due to the greedy exploitation of\ncorrelations among the training data, which are not stable under distributional\nshifts. Recently, some invariant learning methods for out-of-distribution (OOD)\ngeneralization have been proposed by leveraging multiple training environments\nto find invariant relationships. However, modern datasets are frequently\nassembled by merging data from multiple sources without explicit source labels.\nThe resultant unobserved heterogeneity renders many invariant learning methods\ninapplicable. In this paper, we propose Heterogeneous Risk Minimization (HRM)\nframework to achieve joint learning of latent heterogeneity among the data and\ninvariant relationship, which leads to stable prediction despite distributional\nshifts. We theoretically characterize the roles of the environment labels in\ninvariant learning and justify our newly proposed HRM framework. Extensive\nexperimental results validate the effectiveness of our HRM framework.",
          "link": "http://arxiv.org/abs/2105.03818",
          "publishedOn": "2021-06-15T01:45:16.505Z",
          "wordCount": 596,
          "title": "Heterogeneous Risk Minimization. (arXiv:2105.03818v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10682",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_H/0/1/0/all/0/1\">Haitong Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guan_Y/0/1/0/all/0/1\">Yang Guan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shegnbo Eben Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiangteng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1\">Sifa Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jianyu Chen</a>",
          "description": "The safety constraints commonly used by existing safe reinforcement learning\n(RL) methods are defined only on expectation of initial states, but allow each\ncertain state to be unsafe, which is unsatisfying for real-world\nsafety-critical tasks. In this paper, we introduce the feasible actor-critic\n(FAC) algorithm, which is the first model-free constrained RL method that\nconsiders statewise safety, e.g, safety for each initial state. We claim that\nsome states are inherently unsafe no matter what policy we choose, while for\nother states there exist policies ensuring safety, where we say such states and\npolicies are feasible. By constructing a statewise Lagrange function available\non RL sampling and adopting an additional neural network to approximate the\nstatewise Lagrange multiplier, we manage to obtain the optimal feasible policy\nwhich ensures safety for each feasible state and the safest possible policy for\ninfeasible states. Furthermore, the trained multiplier net can indicate whether\na given state is feasible or not through the statewise complementary slackness\ncondition. We provide theoretical guarantees that FAC outperforms previous\nexpectation-based constrained RL methods in terms of both constraint\nsatisfaction and reward optimization. Experimental results on both robot\nlocomotive tasks and safe exploration tasks verify the safety enhancement and\nfeasibility interpretation of the proposed method.",
          "link": "http://arxiv.org/abs/2105.10682",
          "publishedOn": "2021-06-15T01:45:16.498Z",
          "wordCount": 673,
          "title": "Feasible Actor-Critic: Constrained Reinforcement Learning for Ensuring Statewise Safety. (arXiv:2105.10682v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.10626",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sharma_Y/0/1/0/all/0/1\">Yash Sharma</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shrivastava_A/0/1/0/all/0/1\">Aman Shrivastava</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ehsan_L/0/1/0/all/0/1\">Lubaina Ehsan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Moskaluk_C/0/1/0/all/0/1\">Christopher A. Moskaluk</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Syed_S/0/1/0/all/0/1\">Sana Syed</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Brown_D/0/1/0/all/0/1\">Donald E. Brown</a>",
          "description": "In recent years, the availability of digitized Whole Slide Images (WSIs) has\nenabled the use of deep learning-based computer vision techniques for automated\ndisease diagnosis. However, WSIs present unique computational and algorithmic\nchallenges. WSIs are gigapixel-sized ($\\sim$100K pixels), making them\ninfeasible to be used directly for training deep neural networks. Also, often\nonly slide-level labels are available for training as detailed annotations are\ntedious and can be time-consuming for experts. Approaches using\nmultiple-instance learning (MIL) frameworks have been shown to overcome these\nchallenges. Current state-of-the-art approaches divide the learning framework\ninto two decoupled parts: a convolutional neural network (CNN) for encoding the\npatches followed by an independent aggregation approach for slide-level\nprediction. In this approach, the aggregation step has no bearing on the\nrepresentations learned by the CNN encoder. We have proposed an end-to-end\nframework that clusters the patches from a WSI into ${k}$-groups, samples\n${k}'$ patches from each group for training, and uses an adaptive attention\nmechanism for slide level prediction; Cluster-to-Conquer (C2C). We have\ndemonstrated that dividing a WSI into clusters can improve the model training\nby exposing it to diverse discriminative features extracted from the patches.\nWe regularized the clustering mechanism by introducing a KL-divergence loss\nbetween the attention weights of patches in a cluster and the uniform\ndistribution. The framework is optimized end-to-end on slide-level\ncross-entropy, patch-level cross-entropy, and KL-divergence loss\n(Implementation: https://github.com/YashSharma/C2C).",
          "link": "http://arxiv.org/abs/2103.10626",
          "publishedOn": "2021-06-15T01:45:16.492Z",
          "wordCount": 711,
          "title": "Cluster-to-Conquer: A Framework for End-to-End Multi-Instance Learning for Whole Slide Image Classification. (arXiv:2103.10626v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06639",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_J/0/1/0/all/0/1\">John Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malik_K/0/1/0/all/0/1\">Kshitiz Malik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_H/0/1/0/all/0/1\">Hongyuan Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yousefpour_A/0/1/0/all/0/1\">Ashkan Yousefpour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rabbat_M/0/1/0/all/0/1\">Michael Rabbat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Esmaeili_M/0/1/0/all/0/1\">Mani Malek Esmaeili</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huba_D/0/1/0/all/0/1\">Dzmitry Huba</a>",
          "description": "Federated Learning (FL) trains a shared model across distributed devices\nwhile keeping the training data on the devices. Most FL schemes are\nsynchronous: they perform a synchronized aggregation of model updates from\nindividual devices. Synchronous training can be slow because of late-arriving\ndevices (stragglers). On the other hand, completely asynchronous training makes\nFL less private because of incompatibility with secure aggregation. In this\nwork, we propose a model aggregation scheme, FedBuff, that combines the best\nproperties of synchronous and asynchronous FL. Similar to synchronous FL,\nFedBuff is compatible with secure aggregation. Similar to asynchronous FL,\nFedBuff is robust to stragglers. In FedBuff, clients trains asynchronously and\nsend updates to the server. The server aggregates client updates in a private\nbuffer until updates have been received, at which point a server model update\nis immediately performed. We provide theoretical convergence guarantees for\nFedBuff in a non-convex setting. Empirically, FedBuff converges up to 3.8x\nfaster than previous proposals for synchronous FL (e.g., FedAvgM), and up to\n2.5x faster than previous proposals for asynchronous FL (e.g., FedAsync). We\nshow that FedBuff is robust to different staleness distributions and is more\nscalable than synchronous FL techniques.",
          "link": "http://arxiv.org/abs/2106.06639",
          "publishedOn": "2021-06-15T01:45:16.485Z",
          "wordCount": 619,
          "title": "Federated Learning with Buffered Asynchronous Aggregation. (arXiv:2106.06639v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2103.13308",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Radovanovic_A/0/1/0/all/0/1\">Ana Radovanovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Bokan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Talukdar_S/0/1/0/all/0/1\">Saurav Talukdar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_B/0/1/0/all/0/1\">Binz Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duarte_A/0/1/0/all/0/1\">Alexandre Duarte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shahbazi_M/0/1/0/all/0/1\">Mahya Shahbazi</a>",
          "description": "Datacenter power demand has been continuously growing and is the key driver\nof its cost. An accurate mapping of compute resources (CPU, RAM, etc.) and\nhardware types (servers, accelerators, etc.) to power consumption has emerged\nas a critical requirement for major Web and cloud service providers. With the\nglobal growth in datacenter capacity and associated power consumption, such\nmodels are essential for important decisions around datacenter design and\noperation. In this paper, we discuss two classes of statistical power models\ndesigned and validated to be accurate, simple, interpretable and applicable to\nall hardware configurations and workloads across hyperscale datacenters of\nGoogle fleet. To the best of our knowledge, this is the largest scale power\nmodeling study of this kind, in both the scope of diverse datacenter planning\nand real-time management use cases, as well as the variety of hardware\nconfigurations and workload types used for modeling and validation. We\ndemonstrate that the proposed statistical modeling techniques, while simple and\nscalable, predict power with less than 5% Mean Absolute Percent Error (MAPE)\nfor more than 95% diverse Power Distribution Units (more than 2000) using only\n4 features. This performance matches the reported accuracy of the previous\nstarted-of-the-art methods, while using significantly less features and\ncovering a wider range of use cases.",
          "link": "http://arxiv.org/abs/2103.13308",
          "publishedOn": "2021-06-15T01:45:16.479Z",
          "wordCount": 679,
          "title": "Power Modeling for Effective Datacenter Planning and Compute Management. (arXiv:2103.13308v2 [cs.DC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.03198",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Murata_T/0/1/0/all/0/1\">Tomoya Murata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suzuki_T/0/1/0/all/0/1\">Taiji Suzuki</a>",
          "description": "Recently, local SGD has got much attention and been extensively studied in\nthe distributed learning community to overcome the communication bottleneck\nproblem. However, the superiority of local SGD to minibatch SGD only holds in\nquite limited situations. In this paper, we study a new local algorithm called\nBias-Variance Reduced Local SGD (BVR-L-SGD) for nonconvex distributed\noptimization. Algorithmically, our proposed bias and variance reduced local\ngradient estimator fully utilizes small second-order heterogeneity of local\nobjectives and suggests randomly picking up one of the local models instead of\ntaking the average of them when workers are synchronized. Theoretically, under\nsmall heterogeneity of local objectives, we show that BVR-L-SGD achieves better\ncommunication complexity than both the previous non-local and local methods\nunder mild conditions, and particularly BVR-L-SGD is the first method that\nbreaks the barrier of communication complexity $\\Theta(1/\\varepsilon)$ for\ngeneral nonconvex smooth objectives when the heterogeneity is small and the\nlocal computation budget is large. Numerical results are given to verify the\ntheoretical findings and give empirical evidence of the superiority of our\nmethod.",
          "link": "http://arxiv.org/abs/2102.03198",
          "publishedOn": "2021-06-15T01:45:16.455Z",
          "wordCount": 630,
          "title": "Bias-Variance Reduced Local SGD for Less Heterogeneous Federated Learning. (arXiv:2102.03198v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.05284",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Liyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1\">Haipeng Luo</a>",
          "description": "We make significant progress toward the stochastic shortest path problem with\nadversarial costs and unknown transition. Specifically, we develop algorithms\nthat achieve $\\widetilde{O}(\\sqrt{S^2ADT_\\star K})$ regret for the\nfull-information setting and $\\widetilde{O}(\\sqrt{S^3A^2DT_\\star K})$ regret\nfor the bandit feedback setting, where $D$ is the diameter, $T_\\star$ is the\nexpected hitting time of the optimal policy, $S$ is the number of states, $A$\nis the number of actions, and $K$ is the number of episodes. Our work strictly\nimproves (Rosenberg and Mansour, 2020) in the full information setting, extends\n(Chen et al., 2020) from known transition to unknown transition, and is also\nthe first to consider the most challenging combination: bandit feedback with\nadversarial costs and unknown transition. To remedy the gap between our upper\nbounds and the current best lower bounds constructed via a stochastically\noblivious adversary, we also propose algorithms with near-optimal regret for\nthis special case.",
          "link": "http://arxiv.org/abs/2102.05284",
          "publishedOn": "2021-06-15T01:45:16.442Z",
          "wordCount": 615,
          "title": "Finding the Stochastic Shortest Path with Low Regret: The Adversarial Cost and Unknown Transition Case. (arXiv:2102.05284v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.07060",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Deo_A/0/1/0/all/0/1\">Anand Deo</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Murthy_K/0/1/0/all/0/1\">Karthyek Murthy</a>",
          "description": "Motivated by the increasing adoption of models which facilitate greater\nautomation in risk management and decision-making, this paper presents a novel\nImportance Sampling (IS) scheme for measuring distribution tails of objectives\nmodelled with enabling tools such as feature-based decision rules, mixed\ninteger linear programs, deep neural networks, etc. Conventional efficient IS\napproaches suffer from feasibility and scalability concerns due to the need to\nintricately tailor the sampler to the underlying probability distribution and\nthe objective. This challenge is overcome in the proposed black-box scheme by\nautomating the selection of an effective IS distribution with a transformation\nthat implicitly learns and replicates the concentration properties observed in\nless rare samples. This novel approach is guided by a large deviations\nprinciple that brings out the phenomenon of self-similarity of optimal IS\ndistributions. The proposed sampler is the first to attain asymptotically\noptimal variance reduction across a spectrum of multivariate distributions\ndespite being oblivious to the underlying structure. The large deviations\nprinciple additionally results in new distribution tail asymptotics capable of\nyielding operational insights. The applicability is illustrated by considering\nproduct distribution networks and portfolio credit risk models informed by\nneural networks as examples.",
          "link": "http://arxiv.org/abs/2102.07060",
          "publishedOn": "2021-06-15T01:45:16.435Z",
          "wordCount": 651,
          "title": "Achieving Efficiency in Black Box Simulation of Distribution Tails with Self-structuring Importance Samplers. (arXiv:2102.07060v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.04627",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zantedeschi_V/0/1/0/all/0/1\">Valentina Zantedeschi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kusner_M/0/1/0/all/0/1\">Matt J. Kusner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niculae_V/0/1/0/all/0/1\">Vlad Niculae</a>",
          "description": "We address the problem of learning binary decision trees that partition data\nfor some downstream task. We propose to learn discrete parameters (i.e., for\ntree traversals and node pruning) and continuous parameters (i.e., for tree\nsplit functions and prediction functions) simultaneously using argmin\ndifferentiation. We do so by sparsely relaxing a mixed-integer program for the\ndiscrete parameters, to allow gradients to pass through the program to\ncontinuous parameters. We derive customized algorithms to efficiently compute\nthe forward and backward passes. This means that our tree learning procedure\ncan be used as an (implicit) layer in arbitrary deep networks, and can be\noptimized with arbitrary loss functions. We demonstrate that our approach\nproduces binary trees that are competitive with existing single tree and\nensemble approaches, in both supervised and unsupervised settings. Further,\napart from greedy approaches (which do not have competitive accuracies), our\nmethod is faster to train than all other tree-learning baselines we compare\nwith. The code for reproducing the results is available at\nhttps://github.com/vzantedeschi/LatentTrees.",
          "link": "http://arxiv.org/abs/2010.04627",
          "publishedOn": "2021-06-15T01:45:16.411Z",
          "wordCount": 626,
          "title": "Learning Binary Decision Trees by Argmin Differentiation. (arXiv:2010.04627v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.11387",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Boateng_G/0/1/0/all/0/1\">George Boateng</a>",
          "description": "Introductory hands-on courses such as our smartphone-based coding course,\nSuaCode require a lot of support for students to accomplish learning goals.\nOnline environments make it even more difficult to get assistance especially\nmore recently because of COVID-19. Given the multilingual context of SuaCode\nstudents - learners across 42 African countries that are mostly Anglophone or\nFrancophone - in this work, we developed a bilingual Artificial Intelligence\n(AI) Teaching Assistant (TA) - Kwame - that provides answers to students'\ncoding questions from SuaCode courses in English and French. Kwame is a\nSentence-BERT (SBERT)-based question-answering (QA) system that we trained and\nevaluated offline using question-answer pairs created from the course's\nquizzes, lesson notes and students' questions in past cohorts. Kwame finds the\nparagraph most semantically similar to the question via cosine similarity. We\ncompared the system with TF-IDF and Universal Sentence Encoder. Our results\nshowed that fine-tuning on the course data and returning the top 3 and 5\nanswers improved the accuracy results. Kwame will make it easy for students to\nget quick and accurate answers to questions in SuaCode courses.",
          "link": "http://arxiv.org/abs/2010.11387",
          "publishedOn": "2021-06-15T01:45:16.398Z",
          "wordCount": 701,
          "title": "Kwame: A Bilingual AI Teaching Assistant for Online SuaCode Courses. (arXiv:2010.11387v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.11256",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Long_Z/0/1/0/all/0/1\">Ziang Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_P/0/1/0/all/0/1\">Penghang Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xin_J/0/1/0/all/0/1\">Jack Xin</a>",
          "description": "Quantized or low-bit neural networks are attractive due to their inference\nefficiency. However, training deep neural networks with quantized activations\ninvolves minimizing a discontinuous and piecewise constant loss function. Such\na loss function has zero gradients almost everywhere (a.e.), which makes the\nconventional gradient-based algorithms inapplicable. To this end, we study a\nnovel class of \\emph{biased} first-order oracle, termed coarse gradient, for\novercoming the vanished gradient issue. A coarse gradient is generated by\nreplacing the a.e. zero derivatives of quantized (i.e., stair-case) ReLU\nactivation composited in the chain rule with some heuristic proxy derivative\ncalled straight-through estimator (STE). Although having been widely used in\ntraining quantized networks empirically, fundamental questions like when and\nwhy the ad-hoc STE trick works, still lacks theoretical understanding. In this\npaper, we propose a class of STEs with certain monotonicity, and consider their\napplications to the training of a two-linear-layer network with quantized\nactivation functions for non-linear multi-category classification. We establish\nperformance guarantees for the proposed STEs by showing that the corresponding\ncoarse gradient methods converge to the global minimum, which leads to a\nperfect classification. Lastly, we present experimental results on synthetic\ndata as well as MNIST dataset to verify our theoretical findings and\ndemonstrate the effectiveness of our proposed STEs.",
          "link": "http://arxiv.org/abs/2011.11256",
          "publishedOn": "2021-06-15T01:45:16.379Z",
          "wordCount": 662,
          "title": "Learning Quantized Neural Nets by Coarse Gradient Method for Non-linear Classification. (arXiv:2011.11256v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02096",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Yu_B/0/1/0/all/0/1\">Byeongsu Yu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+You_K/0/1/0/all/0/1\">Kisung You</a>",
          "description": "We introduce a linear dimensionality reduction technique preserving\ntopological features via persistent homology. The method is designed to find\nlinear projection $L$ which preserves the persistent diagram of a point cloud\n$\\mathbb{X}$ via simulated annealing. The projection $L$ induces a set of\ncanonical simplicial maps from the Rips (or \\v{C}ech) filtration of\n$\\mathbb{X}$ to that of $L\\mathbb{X}$. In addition to the distance between\npersistent diagrams, the projection induces a map between filtrations, called\nfiltration homomorphism. Using the filtration homomorphism, one can measure the\ndifference between shapes of two filtrations directly comparing simplicial\ncomplexes with respect to quasi-isomorphism $\\mu_{\\operatorname{quasi-iso}}$ or\nstrong homotopy equivalence $\\mu_{\\operatorname{equiv}}$. These\n$\\mu_{\\operatorname{quasi-iso}}$ and $\\mu_{\\operatorname{equiv}}$ measures how\nmuch portion of corresponding simplicial complexes is quasi-isomorphic or\nhomotopy equivalence respectively. We validate the effectiveness of our\nframework with simple examples.",
          "link": "http://arxiv.org/abs/2106.02096",
          "publishedOn": "2021-06-15T01:45:16.315Z",
          "wordCount": 592,
          "title": "Shape-Preserving Dimensionality Reduction : An Algorithm and Measures of Topological Equivalence. (arXiv:2106.02096v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06695",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kapoor_S/0/1/0/all/0/1\">Sanyam Kapoor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Finzi_M/0/1/0/all/0/1\">Marc Finzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Ke Alexander Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilson_A/0/1/0/all/0/1\">Andrew Gordon Wilson</a>",
          "description": "State-of-the-art methods for scalable Gaussian processes use iterative\nalgorithms, requiring fast matrix vector multiplies (MVMs) with the covariance\nkernel. The Structured Kernel Interpolation (SKI) framework accelerates these\nMVMs by performing efficient MVMs on a grid and interpolating back to the\noriginal space. In this work, we develop a connection between SKI and the\npermutohedral lattice used for high-dimensional fast bilateral filtering. Using\na sparse simplicial grid instead of a dense rectangular one, we can perform GP\ninference exponentially faster in the dimension than SKI. Our approach,\nSimplex-GP, enables scaling SKI to high dimensions, while maintaining strong\npredictive performance. We additionally provide a CUDA implementation of\nSimplex-GP, which enables significant GPU acceleration of MVM based inference.",
          "link": "http://arxiv.org/abs/2106.06695",
          "publishedOn": "2021-06-15T01:45:16.284Z",
          "wordCount": 564,
          "title": "SKIing on Simplices: Kernel Interpolation on the Permutohedral Lattice for Scalable Gaussian Processes. (arXiv:2106.06695v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2008.10898",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhize Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bao_H/0/1/0/all/0/1\">Hongyan Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiangliang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Richtarik_P/0/1/0/all/0/1\">Peter Richt&#xe1;rik</a>",
          "description": "In this paper, we propose a novel stochastic gradient estimator --\nProbAbilistic Gradient Estimator (PAGE) -- for nonconvex optimization. PAGE is\neasy to implement as it is designed via a small adjustment to vanilla SGD: in\neach iteration, PAGE uses the vanilla minibatch SGD update with probability\n$p_t$ or reuses the previous gradient with a small adjustment, at a much lower\ncomputational cost, with probability $1-p_t$. We give a simple formula for the\noptimal choice of $p_t$. Moreover, we prove the first tight lower bound\n$\\Omega(n+\\frac{\\sqrt{n}}{\\epsilon^2})$ for nonconvex finite-sum problems,\nwhich also leads to a tight lower bound $\\Omega(b+\\frac{\\sqrt{b}}{\\epsilon^2})$\nfor nonconvex online problems, where $b:= \\min\\{\\frac{\\sigma^2}{\\epsilon^2},\nn\\}$. Then, we show that PAGE obtains the optimal convergence results\n$O(n+\\frac{\\sqrt{n}}{\\epsilon^2})$ (finite-sum) and\n$O(b+\\frac{\\sqrt{b}}{\\epsilon^2})$ (online) matching our lower bounds for both\nnonconvex finite-sum and online problems. Besides, we also show that for\nnonconvex functions satisfying the Polyak-\\L{}ojasiewicz (PL) condition, PAGE\ncan automatically switch to a faster linear convergence rate $O(\\cdot\\log\n\\frac{1}{\\epsilon})$. Finally, we conduct several deep learning experiments\n(e.g., LeNet, VGG, ResNet) on real datasets in PyTorch showing that PAGE not\nonly converges much faster than SGD in training but also achieves the higher\ntest accuracy, validating the optimal theoretical results and confirming the\npractical superiority of PAGE.",
          "link": "http://arxiv.org/abs/2008.10898",
          "publishedOn": "2021-06-15T01:45:16.278Z",
          "wordCount": 702,
          "title": "PAGE: A Simple and Optimal Probabilistic Gradient Estimator for Nonconvex Optimization. (arXiv:2008.10898v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.03934",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1\">Minqi Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grefenstette_E/0/1/0/all/0/1\">Edward Grefenstette</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rocktaschel_T/0/1/0/all/0/1\">Tim Rockt&#xe4;schel</a>",
          "description": "Environments with procedurally generated content serve as important\nbenchmarks for testing systematic generalization in deep reinforcement\nlearning. In this setting, each level is an algorithmically created environment\ninstance with a unique configuration of its factors of variation. Training on a\nprespecified subset of levels allows for testing generalization to unseen\nlevels. What can be learned from a level depends on the current policy, yet\nprior work defaults to uniform sampling of training levels independently of the\npolicy. We introduce Prioritized Level Replay (PLR), a general framework for\nselectively sampling the next training level by prioritizing those with higher\nestimated learning potential when revisited in the future. We show TD-errors\neffectively estimate a level's future learning potential and, when used to\nguide the sampling procedure, induce an emergent curriculum of increasingly\ndifficult levels. By adapting the sampling of training levels, PLR\nsignificantly improves sample efficiency and generalization on Procgen\nBenchmark--matching the previous state-of-the-art in test return--and readily\ncombines with other methods. Combined with the previous leading method, PLR\nraises the state-of-the-art to over 76% improvement in test return relative to\nstandard RL baselines.",
          "link": "http://arxiv.org/abs/2010.03934",
          "publishedOn": "2021-06-15T01:45:16.272Z",
          "wordCount": 643,
          "title": "Prioritized Level Replay. (arXiv:2010.03934v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1912.07812",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1\">Guangyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Etemad_A/0/1/0/all/0/1\">Ali Etemad</a>",
          "description": "Driver vigilance estimation is an important task for transportation safety.\nWearable and portable brain-computer interface devices provide a powerful means\nfor real-time monitoring of the vigilance level of drivers to help with\navoiding distracted or impaired driving. In this paper, we propose a novel\nmultimodal architecture for in-vehicle vigilance estimation from\nElectroencephalogram and Electrooculogram. To enable the system to focus on the\nmost salient parts of the learned multimodal representations, we propose an\narchitecture composed of a capsule attention mechanism following a deep Long\nShort-Term Memory (LSTM) network. Our model learns hierarchical dependencies in\nthe data through the LSTM and capsule feature representation layers. To better\nexplore the discriminative ability of the learned representations, we study the\neffect of the proposed capsule attention mechanism including the number of\ndynamic routing iterations as well as other parameters. Experiments show the\nrobustness of our method by outperforming other solutions and baseline\ntechniques, setting a new state-of-the-art. We then provide an analysis on\ndifferent frequency bands and brain regions to evaluate their suitability for\ndriver vigilance estimation. Lastly, an analysis on the role of capsule\nattention, multimodality, and robustness to noise is performed, highlighting\nthe advantages of our approach.",
          "link": "http://arxiv.org/abs/1912.07812",
          "publishedOn": "2021-06-15T01:45:16.266Z",
          "wordCount": 700,
          "title": "Capsule Attention for Multimodal EEG-EOG Representation Learning with Application to Driver Vigilance Estimation. (arXiv:1912.07812v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06600",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yasunaga_M/0/1/0/all/0/1\">Michihiro Yasunaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1\">Percy Liang</a>",
          "description": "We consider repair tasks: given a critic (e.g., compiler) that assesses the\nquality of an input, the goal is to train a fixer that converts a bad example\n(e.g., code with syntax errors) into a good one (e.g., code with no errors).\nExisting works create training data consisting of (bad, good) pairs by\ncorrupting good examples using heuristics (e.g., dropping tokens). However,\nfixers trained on this synthetically-generated data do not extrapolate well to\nthe real distribution of bad inputs. To bridge this gap, we propose a new\ntraining approach, Break-It-Fix-It (BIFI), which has two key ideas: (i) we use\nthe critic to check a fixer's output on real bad inputs and add good (fixed)\noutputs to the training data, and (ii) we train a breaker to generate realistic\nbad code from good code. Based on these ideas, we iteratively update the\nbreaker and the fixer while using them in conjunction to generate more paired\ndata. We evaluate BIFI on two code repair datasets: GitHub-Python, a new\ndataset we introduce where the goal is to repair Python code with AST parse\nerrors; and DeepFix, where the goal is to repair C code with compiler errors.\nBIFI outperforms existing methods, obtaining 90.5% repair accuracy on\nGitHub-Python (+28.5%) and 71.7% on DeepFix (+5.6%). Notably, BIFI does not\nrequire any labeled data; we hope it will be a strong starting point for\nunsupervised learning of various repair tasks.",
          "link": "http://arxiv.org/abs/2106.06600",
          "publishedOn": "2021-06-15T01:45:16.232Z",
          "wordCount": 669,
          "title": "Break-It-Fix-It: Unsupervised Learning for Program Repair. (arXiv:2106.06600v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.09695",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ciolino_M/0/1/0/all/0/1\">Matthew Ciolino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalin_J/0/1/0/all/0/1\">Josh Kalin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noever_D/0/1/0/all/0/1\">David Noever</a>",
          "description": "Production machine learning systems are consistently under attack by\nadversarial actors. Various deep learning models must be capable of accurately\ndetecting fake or adversarial input while maintaining speed. In this work, we\npropose one piece of the production protection system: detecting an incoming\nadversarial attack and its characteristics. Detecting types of adversarial\nattacks has two primary effects: the underlying model can be trained in a\nstructured manner to be robust from those attacks and the attacks can be\npotentially filtered out in real-time before causing any downstream damage. The\nadversarial image classification space is explored for models commonly used in\ntransfer learning.",
          "link": "http://arxiv.org/abs/2102.09695",
          "publishedOn": "2021-06-15T01:45:16.173Z",
          "wordCount": 581,
          "title": "Fortify Machine Learning Production Systems: Detect and Classify Adversarial Attacks. (arXiv:2102.09695v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.10902",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Liu_G/0/1/0/all/0/1\">Ge Liu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Dimitrakakis_A/0/1/0/all/0/1\">Alexander Dimitrakakis</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Carter_B/0/1/0/all/0/1\">Brandon Carter</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Gifford_D/0/1/0/all/0/1\">David Gifford</a>",
          "description": "We introduce the maximum $n$-times coverage problem that selects $k$ overlays\nto maximize the summed coverage of weighted elements, where each element must\nbe covered at least $n$ times. We also define the min-cost $n$-times coverage\nproblem where the objective is to select the minimum set of overlays such that\nthe sum of the weights of elements that are covered at least $n$ times is at\nleast $\\tau$. Maximum $n$-times coverage is a generalization of the multi-set\nmulti-cover problem, is NP-complete, and is not submodular. We introduce two\nnew practical solutions for $n$-times coverage based on integer linear\nprogramming and sequential greedy optimization. We show that maximum $n$-times\ncoverage is a natural way to frame peptide vaccine design, and find that it\nproduces a pan-strain COVID-19 vaccine design that is superior to 29 other\npublished designs in predicted population coverage and the expected number of\npeptides displayed by each individual's HLA molecules.",
          "link": "http://arxiv.org/abs/2101.10902",
          "publishedOn": "2021-06-15T01:45:16.147Z",
          "wordCount": 644,
          "title": "Maximum n-times Coverage for Vaccine Design. (arXiv:2101.10902v2 [q-bio.QM] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.08477",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nanayakkara_T/0/1/0/all/0/1\">Thesath Nanayakkara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clermont_G/0/1/0/all/0/1\">Gilles Clermont</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Langmead_C/0/1/0/all/0/1\">Christopher James Langmead</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swigon_D/0/1/0/all/0/1\">David Swigon</a>",
          "description": "Sepsis is a potentially life threatening inflammatory response to infection\nor severe tissue damage. It has a highly variable clinical course, requiring\nconstant monitoring of the patient's state to guide the management of\nintravenous fluids and vasopressors, among other interventions. Despite decades\nof research, there's still debate among experts on optimal treatment. Here, we\ncombine for the first time, distributional deep reinforcement learning with\nmechanistic physiological models to find personalized sepsis treatment\nstrategies. Our method handles partial observability by leveraging known\ncardiovascular physiology, introducing a novel physiology-driven recurrent\nautoencoder, and quantifies the uncertainty of its own results. Moreover, we\nintroduce a framework for uncertainty aware decision support with humans in the\nloop. We show that our method learns physiologically explainable, robust\npolicies that are consistent with clinical knowledge. Further our method\nconsistently identifies high risk states that lead to death, which could\npotentially benefit from more frequent vasopressor administration, providing\nvaluable guidance for future research",
          "link": "http://arxiv.org/abs/2101.08477",
          "publishedOn": "2021-06-15T01:45:16.122Z",
          "wordCount": 634,
          "title": "Unifying Cardiovascular Modelling with Deep Reinforcement Learning for Uncertainty Aware Control of Sepsis Treatment. (arXiv:2101.08477v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06663",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zou_X/0/1/0/all/0/1\">Xu Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Q/0/1/0/all/0/1\">Qinkai Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1\">Yuxiao Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guan_X/0/1/0/all/0/1\">Xinyu Guan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kharlamov_E/0/1/0/all/0/1\">Evgeny Kharlamov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jialiang Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jie Tang</a>",
          "description": "Graph Neural Networks (GNNs) have achieved promising performance in various\nreal-world applications. However, recent studies have shown that GNNs are\nvulnerable to adversarial attacks. In this paper, we study a\nrecently-introduced realistic attack scenario on graphs -- graph injection\nattack (GIA). In the GIA scenario, the adversary is not able to modify the\nexisting link structure and node attributes of the input graph, instead the\nattack is performed by injecting adversarial nodes into it. We present an\nanalysis on the topological vulnerability of GNNs under GIA setting, based on\nwhich we propose the Topological Defective Graph Injection Attack (TDGIA) for\neffective injection attacks. TDGIA first introduces the topological defective\nedge selection strategy to choose the original nodes for connecting with the\ninjected ones. It then designs the smooth feature optimization objective to\ngenerate the features for the injected nodes. Extensive experiments on\nlarge-scale datasets show that TDGIA can consistently and significantly\noutperform various attack baselines in attacking dozens of defense GNN models.\nNotably, the performance drop on target GNNs resultant from TDGIA is more than\ndouble the damage brought by the best attack solution among hundreds of\nsubmissions on KDD-CUP 2020.",
          "link": "http://arxiv.org/abs/2106.06663",
          "publishedOn": "2021-06-15T01:45:16.046Z",
          "wordCount": 629,
          "title": "TDGIA:Effective Injection Attacks on Graph Neural Networks. (arXiv:2106.06663v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00273",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Haibin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Andy T. Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhiyong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_H/0/1/0/all/0/1\">Helen Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hung-yi Lee</a>",
          "description": "Previous works have shown that automatic speaker verification (ASV) is\nseriously vulnerable to malicious spoofing attacks, such as replay, synthetic\nspeech, and recently emerged adversarial attacks. Great efforts have been\ndedicated to defending ASV against replay and synthetic speech; however, only a\nfew approaches have been explored to deal with adversarial attacks. All the\nexisting approaches to tackle adversarial attacks for ASV require the knowledge\nfor adversarial samples generation, but it is impractical for defenders to know\nthe exact attack algorithms that are applied by the in-the-wild attackers. This\nwork is among the first to perform adversarial defense for ASV without knowing\nthe specific attack algorithms. Inspired by self-supervised learning models\n(SSLMs) that possess the merits of alleviating the superficial noise in the\ninputs and reconstructing clean samples from the interrupted ones, this work\nregards adversarial perturbations as one kind of noise and conducts adversarial\ndefense for ASV by SSLMs. Specifically, we propose to perform adversarial\ndefense from two perspectives: 1) adversarial perturbation purification and 2)\nadversarial perturbation detection. Experimental results show that our\ndetection module effectively shields the ASV by detecting adversarial samples\nwith an accuracy of around 80%. Moreover, since there is no common metric for\nevaluating the adversarial defense performance for ASV, this work also\nformalizes evaluation metrics for adversarial defense considering both\npurification and detection based approaches into account. We sincerely\nencourage future works to benchmark their approaches based on the proposed\nevaluation framework.",
          "link": "http://arxiv.org/abs/2106.00273",
          "publishedOn": "2021-06-15T01:45:16.036Z",
          "wordCount": 704,
          "title": "Improving the Adversarial Robustness for Speaker Verification by Self-Supervised Learning. (arXiv:2106.00273v2 [cs.SD] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.11592",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghalme_G/0/1/0/all/0/1\">Ganesh Ghalme</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nair_V/0/1/0/all/0/1\">Vineet Nair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eilat_I/0/1/0/all/0/1\">Itay Eilat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Talgam_Cohen_I/0/1/0/all/0/1\">Inbal Talgam-Cohen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosenfeld_N/0/1/0/all/0/1\">Nir Rosenfeld</a>",
          "description": "Strategic classification studies the interaction between a classification\nrule and the strategic agents it governs. Under the assumption that the\nclassifier is known, rational agents respond to it by manipulating their\nfeatures. However, in many real-life scenarios of high-stake classification\n(e.g., credit scoring), the classifier is not revealed to the agents, which\nleads agents to attempt to learn the classifier and game it too. In this paper\nwe generalize the strategic classification model to such scenarios. We define\nthe price of opacity as the difference in prediction error between opaque and\ntransparent strategy-robust classifiers, characterize it, and give a sufficient\ncondition for this price to be strictly positive, in which case transparency is\nthe recommended policy. Our experiments show how Hardt et al.'s robust\nclassifier is affected by keeping agents in the dark.",
          "link": "http://arxiv.org/abs/2102.11592",
          "publishedOn": "2021-06-15T01:45:16.000Z",
          "wordCount": 591,
          "title": "Strategic Classification in the Dark. (arXiv:2102.11592v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06573",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ge_R/0/1/0/all/0/1\">Rong Ge</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ren_Y/0/1/0/all/0/1\">Yunwei Ren</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_X/0/1/0/all/0/1\">Xiang Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhou_M/0/1/0/all/0/1\">Mo Zhou</a>",
          "description": "In this paper we study the training dynamics for gradient flow on\nover-parametrized tensor decomposition problems. Empirically, such training\nprocess often first fits larger components and then discovers smaller\ncomponents, which is similar to a tensor deflation process that is commonly\nused in tensor decomposition algorithms. We prove that for orthogonally\ndecomposable tensor, a slightly modified version of gradient flow would follow\na tensor deflation process and recover all the tensor components. Our proof\nsuggests that for orthogonal tensors, gradient flow dynamics works similarly as\ngreedy low-rank learning in the matrix setting, which is a first step towards\nunderstanding the implicit regularization effect of over-parametrized models\nfor low-rank tensors.",
          "link": "http://arxiv.org/abs/2106.06573",
          "publishedOn": "2021-06-15T01:45:15.988Z",
          "wordCount": 536,
          "title": "Understanding Deflation Process in Over-parametrized Tensor Decomposition. (arXiv:2106.06573v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2101.02523",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ochal_M/0/1/0/all/0/1\">Mateusz Ochal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patacchiola_M/0/1/0/all/0/1\">Massimiliano Patacchiola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Storkey_A/0/1/0/all/0/1\">Amos Storkey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vazquez_J/0/1/0/all/0/1\">Jose Vazquez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Sen Wang</a>",
          "description": "Few-Shot Learning (FSL) algorithms are commonly trained through Meta-Learning\n(ML), which exposes models to batches of tasks sampled from a meta-dataset to\nmimic tasks seen during evaluation. However, the standard training procedures\noverlook the real-world dynamics where classes commonly occur at different\nfrequencies. While it is generally understood that class imbalance harms the\nperformance of supervised methods, limited research examines the impact of\nimbalance on the FSL evaluation task. Our analysis compares 10 state-of-the-art\nmeta-learning and FSL methods on different imbalance distributions and\nrebalancing techniques. Our results reveal that 1) some FSL methods display a\nnatural disposition against imbalance while most other approaches produce a\nperformance drop by up to 17\\% compared to the balanced task without the\nappropriate mitigation; 2) contrary to popular belief, many meta-learning\nalgorithms will not automatically learn to balance from exposure to imbalanced\ntraining tasks; 3) classical rebalancing strategies, such as random\noversampling, can still be very effective, leading to state-of-the-art\nperformances and should not be overlooked; 4) FSL methods are more robust\nagainst meta-dataset imbalance than imbalance at the task-level with a similar\nimbalance ratio ($\\rho<20$), with the effect holding even in long-tail datasets\nunder a larger imbalance ($\\rho=65$).",
          "link": "http://arxiv.org/abs/2101.02523",
          "publishedOn": "2021-06-15T01:45:15.982Z",
          "wordCount": 677,
          "title": "Few-Shot Learning with Class Imbalance. (arXiv:2101.02523v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.02068",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1\">Bo Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghaddar_B/0/1/0/all/0/1\">Bissan Ghaddar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nathwani_J/0/1/0/all/0/1\">Jatin Nathwani</a>",
          "description": "The past decade has seen a rapid penetration of electric vehicles (EV) in the\nmarket, more and more logistics and transportation companies start to deploy\nEVs for service provision. In order to model the operations of a commercial EV\nfleet, we utilize the EV routing problem with time windows (EVRPTW). In this\nresearch, we propose an end-to-end deep reinforcement learning framework to\nsolve the EVRPTW. In particular, we develop an attention model incorporating\nthe pointer network and a graph embedding technique to parameterize a\nstochastic policy for solving the EVRPTW. The model is then trained using\npolicy gradient with rollout baseline. Our numerical studies show that the\nproposed model is able to efficiently solve EVRPTW instances of large sizes\nthat are not solvable with any existing approaches.",
          "link": "http://arxiv.org/abs/2010.02068",
          "publishedOn": "2021-06-15T01:45:15.966Z",
          "wordCount": 606,
          "title": "Deep Reinforcement Learning for Electric Vehicle Routing Problem with Time Windows. (arXiv:2010.02068v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.10333",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Karimireddy_S/0/1/0/all/0/1\">Sai Praneeth Karimireddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1\">Lie He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaggi_M/0/1/0/all/0/1\">Martin Jaggi</a>",
          "description": "Byzantine robustness has received significant attention recently given its\nimportance for distributed and federated learning. In spite of this, we\nidentify severe flaws in existing algorithms even when the data across the\nparticipants is identically distributed. First, we show realistic examples\nwhere current state of the art robust aggregation rules fail to converge even\nin the absence of any Byzantine attackers. Secondly, we prove that even if the\naggregation rules may succeed in limiting the influence of the attackers in a\nsingle round, the attackers can couple their attacks across time eventually\nleading to divergence. To address these issues, we present two surprisingly\nsimple strategies: a new robust iterative clipping procedure, and incorporating\nworker momentum to overcome time-coupled attacks. This is the first provably\nrobust method for the standard stochastic optimization setting. Our code is\nopen sourced at https://github.com/epfml/byzantine-robust-optimizer.",
          "link": "http://arxiv.org/abs/2012.10333",
          "publishedOn": "2021-06-15T01:45:15.959Z",
          "wordCount": 621,
          "title": "Learning from History for Byzantine Robust Optimization. (arXiv:2012.10333v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.07983",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kyrillidis_A/0/1/0/all/0/1\">Anastasios Kyrillidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vardi_M/0/1/0/all/0/1\">Moshe Y. Vardi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhiwei Zhang</a>",
          "description": "We explore the potential of continuous local search (CLS) in SAT solving by\nproposing a novel approach for finding a solution of a hybrid system of Boolean\nconstraints. The algorithm is based on CLS combined with belief propagation on\nbinary decision diagrams (BDDs). Our framework accepts all Boolean constraints\nthat admit compact BDDs, including symmetric Boolean constraints and\nsmall-coefficient pseudo-Boolean constraints as interesting families. We\npropose a novel algorithm for efficiently computing the gradient needed by CLS.\nWe study the capabilities and limitations of our versatile CLS solver, GradSAT,\nby applying it on many benchmark instances. The experimental results indicate\nthat GradSAT can be a useful addition to the portfolio of existing SAT and\nMaxSAT solvers for solving Boolean satisfiability and optimization problems.",
          "link": "http://arxiv.org/abs/2012.07983",
          "publishedOn": "2021-06-15T01:45:15.945Z",
          "wordCount": 601,
          "title": "On Continuous Local BDD-Based Search for Hybrid SAT Solving. (arXiv:2012.07983v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1905.10696",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ororbia_A/0/1/0/all/0/1\">Alexander Ororbia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mali_A/0/1/0/all/0/1\">Ankur Mali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kifer_D/0/1/0/all/0/1\">Daniel Kifer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giles_C/0/1/0/all/0/1\">C. Lee Giles</a>",
          "description": "In lifelong learning systems, especially those based on artificial neural\nnetworks, one of the biggest obstacles is the severe inability to retain old\nknowledge as new information is encountered. This phenomenon is known as\ncatastrophic forgetting. In this article, we propose a new kind of\nconnectionist architecture, the Sequential Neural Coding Network, that is\nrobust to forgetting when learning from streams of data points and, unlike\nnetworks of today, does not learn via the immensely popular back-propagation of\nerrors. Grounded in the neurocognitive theory of predictive processing, our\nmodel adapts its synapses in a biologically-plausible fashion, while another,\ncomplementary neural system rapidly learns to direct and control this\ncortex-like structure by mimicking the task-executive control functionality of\nthe basal ganglia. In our experiments, we demonstrate that our self-organizing\nsystem experiences significantly less forgetting as compared to standard neural\nmodels and outperforms a wide swath of previously proposed methods even though\nit is trained across task datasets in a stream-like fashion. The promising\nperformance of our complementary system on benchmarks, e.g., SplitMNIST, Split\nFashion MNIST, and Split NotMNIST, offers evidence that by incorporating\nmechanisms prominent in real neuronal systems, such as competition, sparse\nactivation patterns, and iterative input processing, a new possibility for\ntackling the grand challenge of lifelong machine learning opens up.",
          "link": "http://arxiv.org/abs/1905.10696",
          "publishedOn": "2021-06-15T01:45:15.922Z",
          "wordCount": 698,
          "title": "Lifelong Neural Predictive Coding: Learning Cumulatively Online without Forgetting. (arXiv:1905.10696v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.03194",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chen_X/0/1/0/all/0/1\">Xinyu Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1\">Yixian Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Saunier_N/0/1/0/all/0/1\">Nicolas Saunier</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sun_L/0/1/0/all/0/1\">Lijun Sun</a>",
          "description": "Missing value problem in spatiotemporal traffic data has long been a\nchallenging topic, in particular for large-scale and high-dimensional data with\ncomplex missing mechanisms and diverse degrees of missingness. Recent studies\nbased on tensor nuclear norm have demonstrated the superiority of tensor\nlearning in imputation tasks by effectively characterizing the complex\ncorrelations/dependencies in spatiotemporal data. However, despite the\npromising results, these approaches do not scale well to large data tensors. In\nthis paper, we focus on addressing the missing data imputation problem for\nlarge-scale spatiotemporal traffic data. To achieve both high accuracy and\nefficiency, we develop a scalable tensor learning model -- Low-Tubal-Rank\nSmoothing Tensor Completion (LSTC-Tubal) -- based on the existing framework of\nLow-Rank Tensor Completion, which is well-suited for spatiotemporal traffic\ndata that is characterized by multidimensional structure of location$\\times$\ntime of day $\\times$ day. In particular, the proposed LSTC-Tubal model involves\na scalable tensor nuclear norm minimization scheme by integrating linear\nunitary transformation. Therefore, tensor nuclear norm minimization can be\nsolved by singular value thresholding on the transformed matrix of each day\nwhile the day-to-day correlation can be effectively preserved by the unitary\ntransform matrix. We compare LSTC-Tubal with state-of-the-art baseline models,\nand find that LSTC-Tubal can achieve competitive accuracy with a significantly\nlower computational cost. In addition, the LSTC-Tubal will also benefit other\ntasks in modeling large-scale spatiotemporal traffic data, such as\nnetwork-level traffic forecasting.",
          "link": "http://arxiv.org/abs/2008.03194",
          "publishedOn": "2021-06-15T01:45:15.899Z",
          "wordCount": 698,
          "title": "Scalable Low-Rank Tensor Learning for Spatiotemporal Traffic Data Imputation. (arXiv:2008.03194v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06762",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Darvariu_V/0/1/0/all/0/1\">Victor-Alexandru Darvariu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hailes_S/0/1/0/all/0/1\">Stephen Hailes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Musolesi_M/0/1/0/all/0/1\">Mirco Musolesi</a>",
          "description": "Public goods games represent insightful settings for studying incentives for\nindividual agents to make contributions that, while costly for each of them,\nbenefit the wider society. In this work, we adopt the perspective of a central\nplanner with a global view of a network of self-interested agents and the goal\nof maximizing some desired property in the context of a best-shot public goods\ngame. Existing algorithms for this known NP-complete problem find solutions\nthat are sub-optimal and cannot optimize for criteria other than social\nwelfare.\n\nIn order to efficiently solve public goods games, our proposed method\ndirectly exploits the correspondence between equilibria and the Maximal\nIndependent Set (mIS) structural property of graphs. In particular, we define a\nMarkov Decision Process, which incrementally generates an mIS, and adopt a\nplanning method to search for equilibria, outperforming existing methods.\nFurthermore, we devise an imitation learning technique that uses demonstrations\nof the search to obtain a graph neural network parametrized policy which\nquickly generalizes to unseen game instances. Our evaluation results show that\nthis policy is able to reach 99.5% of the performance of the planning method\nwhile being approximately three orders of magnitude faster to evaluate on the\nlargest graphs tested. The methods presented in this work can be applied to a\nlarge class of public goods games of potentially high societal impact.",
          "link": "http://arxiv.org/abs/2106.06762",
          "publishedOn": "2021-06-15T01:45:15.893Z",
          "wordCount": 664,
          "title": "Solving Graph-based Public Good Games with Tree Search and Imitation Learning. (arXiv:2106.06762v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2009.13504",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liao_P/0/1/0/all/0/1\">Peiyuan Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Han Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1\">Keyulu Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaakkola_T/0/1/0/all/0/1\">Tommi Jaakkola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gordon_G/0/1/0/all/0/1\">Geoffrey Gordon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jegelka_S/0/1/0/all/0/1\">Stefanie Jegelka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1\">Ruslan Salakhutdinov</a>",
          "description": "While the advent of Graph Neural Networks (GNNs) has greatly improved node\nand graph representation learning in many applications, the neighborhood\naggregation scheme exposes additional vulnerabilities to adversaries seeking to\nextract node-level information about sensitive attributes. In this paper, we\nstudy the problem of protecting sensitive attributes by information obfuscation\nwhen learning with graph structured data. We propose a framework to locally\nfilter out pre-determined sensitive attributes via adversarial training with\nthe total variation and the Wasserstein distance. Our method creates a strong\ndefense against inference attacks, while only suffering small loss in task\nperformance. Theoretically, we analyze the effectiveness of our framework\nagainst a worst-case adversary, and characterize an inherent trade-off between\nmaximizing predictive accuracy and minimizing information leakage. Experiments\nacross multiple datasets from recommender systems, knowledge graphs and quantum\nchemistry demonstrate that the proposed approach provides a robust defense\nacross various graph structures and tasks, while producing competitive GNN\nencoders for downstream tasks.",
          "link": "http://arxiv.org/abs/2009.13504",
          "publishedOn": "2021-06-15T01:45:15.855Z",
          "wordCount": 667,
          "title": "Information Obfuscation of Graph Neural Networks. (arXiv:2009.13504v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06988",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhangy_W/0/1/0/all/0/1\">Weichuan Zhangy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liuy_X/0/1/0/all/0/1\">Xuefang Liuy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_Z/0/1/0/all/0/1\">Zhe Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yongsheng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1\">Changming Sun</a>",
          "description": "Metric-based few-shot fine-grained image classification (FSFGIC) aims to\nlearn a transferable feature embedding network by estimating the similarities\nbetween query images and support classes from very few examples. In this work,\nwe propose, for the first time, to introduce the non-linear data projection\nconcept into the design of FSFGIC architecture in order to address the limited\nsample problem in few-shot learning and at the same time to increase the\ndiscriminability of the model for fine-grained image classification.\nSpecifically, we first design a feature re-abstraction embedding network that\nhas the ability to not only obtain the required semantic features for effective\nmetric learning but also re-enhance such features with finer details from input\nimages. Then the descriptors of the query images and the support classes are\nprojected into different non-linear spaces in our proposed similarity metric\nlearning network to learn discriminative projection factors. This design can\neffectively operate in the challenging and restricted condition of a FSFGIC\ntask for making the distance between the samples within the same class smaller\nand the distance between samples from different classes larger and for reducing\nthe coupling relationship between samples from different categories.\nFurthermore, a novel similarity measure based on the proposed non-linear data\nproject is presented for evaluating the relationships of feature information\nbetween a query image and a support set. It is worth to note that our proposed\narchitecture can be easily embedded into any episodic training mechanisms for\nend-to-end training from scratch. Extensive experiments on FSFGIC tasks\ndemonstrate the superiority of the proposed methods over the state-of-the-art\nbenchmarks.",
          "link": "http://arxiv.org/abs/2106.06988",
          "publishedOn": "2021-06-15T01:45:15.826Z",
          "wordCount": 701,
          "title": "NDPNet: A novel non-linear data projection network for few-shot fine-gained image classification. (arXiv:2106.06988v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06755",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Goyal_D/0/1/0/all/0/1\">Dishant Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaiswal_R/0/1/0/all/0/1\">Ragesh Jaiswal</a>",
          "description": "In this work, we study the socially fair $k$-median/$k$-means problem. We are\ngiven a set of points $P$ in a metric space $\\mathcal{X}$ with a distance\nfunction $d(.,.)$. There are $\\ell$ groups: $P_1,\\dotsc,P_{\\ell} \\subseteq P$.\nWe are also given a set $F$ of feasible centers in $\\mathcal{X}$. The goal of\nthe socially fair $k$-median problem is to find a set $C \\subseteq F$ of $k$\ncenters that minimizes the maximum average cost over all the groups. That is,\nfind $C$ that minimizes the objective function $\\Phi(C,P) \\equiv \\max_{j}\n\\sum_{x \\in P_j} d(C,x)/|P_j|$, where $d(C,x)$ is the distance of $x$ to the\nclosest center in $C$. The socially fair $k$-means problem is defined similarly\nby using squared distances, i.e., $d^{2}(.,.)$ instead of $d(.,.)$. In this\nwork, we design $(5+\\varepsilon)$ and $(33 + \\varepsilon)$ approximation\nalgorithms for the socially fair $k$-median and $k$-means problems,\nrespectively. For the parameters: $k$ and $\\ell$, the algorithms have an FPT\n(fixed parameter tractable) running time of $f(k,\\ell,\\varepsilon) \\cdot n$ for\n$f(k,\\ell,\\varepsilon) = 2^{{O}(k \\, \\ell/\\varepsilon)}$ and $n = |P \\cup F|$.\nWe also study a special case of the problem where the centers are allowed to be\nchosen from the point set $P$, i.e., $P \\subseteq F$. For this special case,\nour algorithms give better approximation guarantees of $(4+\\varepsilon)$ and\n$(18+\\varepsilon)$ for the socially fair $k$-median and $k$-means problems,\nrespectively. Furthermore, we convert these algorithms to constant pass\nlog-space streaming algorithms. Lastly, we show FPT hardness of approximation\nresults for the problem with a small gap between our upper and lower bounds.",
          "link": "http://arxiv.org/abs/2106.06755",
          "publishedOn": "2021-06-15T01:45:15.819Z",
          "wordCount": 686,
          "title": "FPT Approximation for Socially Fair Clustering. (arXiv:2106.06755v1 [cs.DS])"
        },
        {
          "id": "http://arxiv.org/abs/2006.10529",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lakshminarayanan_C/0/1/0/all/0/1\">Chandrashekar Lakshminarayanan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1\">Amit Vikram Singh</a>",
          "description": "Rectified linear unit (ReLU) activations can also be thought of as 'gates',\nwhich, either pass or stop their pre-activation input when they are 'on' (when\nthe pre-activation input is positive) or 'off' (when the pre-activation input\nis negative) respectively. A deep neural network (DNN) with ReLU activations\nhas many gates, and the on/off status of each gate changes across input\nexamples as well as network weights. For a given input example, only a subset\nof gates are 'active', i.e., on, and the sub-network of weights connected to\nthese active gates is responsible for producing the output. At randomised\ninitialisation, the active sub-network corresponding to a given input example\nis random. During training, as the weights are learnt, the active sub-networks\nare also learnt, and potentially hold very valuable information. In this paper,\nwe analytically characterise the role of active sub-networks in deep learning.\nTo this end, we encode the on/off state of the gates of a given input in a\nnovel 'neural path feature' (NPF), and the weights of the DNN are encoded in a\nnovel 'neural path value' (NPV). Further, we show that the output of network is\nindeed the inner product of NPF and NPV. The main result of the paper shows\nthat the 'neural path kernel' associated with the NPF is a fundamental quantity\nthat characterises the information stored in the gates of a DNN. We show via\nexperiments (on MNIST and CIFAR-10) that in standard DNNs with ReLU activations\nNPFs are learnt during training and such learning is key for generalisation.\nFurthermore, NPFs and NPVs can be learnt in two separate networks and such\nlearning also generalises well in experiments.",
          "link": "http://arxiv.org/abs/2006.10529",
          "publishedOn": "2021-06-15T01:45:15.813Z",
          "wordCount": 749,
          "title": "Neural Path Features and Neural Path Kernel : Understanding the role of gates in deep learning. (arXiv:2006.10529v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.14512",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liang_K/0/1/0/all/0/1\">Kaizhao Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jacky Y. Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koyejo_O/0/1/0/all/0/1\">Oluwasanmi Koyejo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>",
          "description": "Knowledge transferability, or transfer learning, has been widely adopted to\nallow a pre-trained model in the source domain to be effectively adapted to\ndownstream tasks in the target domain. It is thus important to explore and\nunderstand the factors affecting knowledge transferability. In this paper, as\nthe first work, we analyze and demonstrate the connections between knowledge\ntransferability and another important phenomenon--adversarial transferability,\n\\emph{i.e.}, adversarial examples generated against one model can be\ntransferred to attack other models. Our theoretical studies show that\nadversarial transferability indicates knowledge transferability and vice versa.\nMoreover, based on the theoretical insights, we propose two practical\nadversarial transferability metrics to characterize this process, serving as\nbidirectional indicators between adversarial and knowledge transferability. We\nconduct extensive experiments for different scenarios on diverse datasets,\nshowing a positive correlation between adversarial transferability and\nknowledge transferability. Our findings will shed light on future research\nabout effective knowledge transfer learning and adversarial transferability\nanalyses.",
          "link": "http://arxiv.org/abs/2006.14512",
          "publishedOn": "2021-06-15T01:45:15.792Z",
          "wordCount": 628,
          "title": "Uncovering the Connections Between Adversarial Transferability and Knowledge Transferability. (arXiv:2006.14512v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1904.12171",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hou_B/0/1/0/all/0/1\">Bo-Jian Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lijun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zhi-Hua Zhou</a>",
          "description": "Learning with feature evolution studies the scenario where the features of\nthe data streams can evolve, i.e., old features vanish and new features emerge.\nIts goal is to keep the model always performing well even when the features\nhappen to evolve. To tackle this problem, canonical methods assume that the old\nfeatures will vanish simultaneously and the new features themselves will emerge\nsimultaneously as well. They also assume there is an overlapping period where\nold and new features both exist when the feature space starts to change.\nHowever, in reality, the feature evolution could be unpredictable, which means\nthe features can vanish or emerge arbitrarily, causing the overlapping period\nincomplete. In this paper, we propose a novel paradigm: Prediction with\nUnpredictable Feature Evolution (PUFE) where the feature evolution is\nunpredictable. To address this problem, we fill the incomplete overlapping\nperiod and formulate it as a new matrix completion problem. We give a\ntheoretical bound on the least number of observed entries to make the\noverlapping period intact. With this intact overlapping period, we leverage an\nensemble method to take the advantage of both the old and new feature spaces\nwithout manually deciding which base models should be incorporated. Theoretical\nand experimental results validate that our method can always follow the best\nbase models and thus realize the goal of learning with feature evolution.",
          "link": "http://arxiv.org/abs/1904.12171",
          "publishedOn": "2021-06-15T01:45:15.780Z",
          "wordCount": 672,
          "title": "Prediction with Unpredictable Feature Evolution. (arXiv:1904.12171v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1907.12972",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Levie_R/0/1/0/all/0/1\">Ron Levie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Wei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bucci_L/0/1/0/all/0/1\">Lorenzo Bucci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bronstein_M/0/1/0/all/0/1\">Michael M. Bronstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kutyniok_G/0/1/0/all/0/1\">Gitta Kutyniok</a>",
          "description": "This paper focuses on spectral graph convolutional neural networks\n(ConvNets), where filters are defined as elementwise multiplication in the\nfrequency domain of a graph. In machine learning settings where the dataset\nconsists of signals defined on many different graphs, the trained ConvNet\nshould generalize to signals on graphs unseen in the training set. It is thus\nimportant to transfer ConvNets between graphs. Transferability, which is a\ncertain type of generalization capability, can be loosely defined as follows:\nif two graphs describe the same phenomenon, then a single filter or ConvNet\nshould have similar repercussions on both graphs. This paper aims at debunking\nthe common misconception that spectral filters are not transferable. We show\nthat if two graphs discretize the same \"continuous\" space, then a spectral\nfilter or ConvNet has approximately the same repercussion on both graphs. Our\nanalysis is more permissive than the standard analysis. Transferability is\ntypically described as the robustness of the filter to small graph\nperturbations and re-indexing of the vertices. Our analysis accounts also for\nlarge graph perturbations. We prove transferability between graphs that can\nhave completely different dimensions and topologies, only requiring that both\ngraphs discretize the same underlying space in some generic sense.",
          "link": "http://arxiv.org/abs/1907.12972",
          "publishedOn": "2021-06-15T01:45:15.743Z",
          "wordCount": 667,
          "title": "Transferability of Spectral Graph Convolutional Neural Networks. (arXiv:1907.12972v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06654",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Evtimov_I/0/1/0/all/0/1\">Ivan Evtimov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Covert_I/0/1/0/all/0/1\">Ian Covert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kusupati_A/0/1/0/all/0/1\">Aditya Kusupati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kohno_T/0/1/0/all/0/1\">Tadayoshi Kohno</a>",
          "description": "When data is publicly released for human consumption, it is unclear how to\nprevent its unauthorized usage for machine learning purposes. Successful model\ntraining may be preventable with carefully designed dataset modifications, and\nwe present a proof-of-concept approach for the image classification setting. We\npropose methods based on the notion of adversarial shortcuts, which encourage\nmodels to rely on non-robust signals rather than semantic features, and our\nexperiments demonstrate that these measures successfully prevent deep learning\nmodels from achieving high accuracy on real, unmodified data examples.",
          "link": "http://arxiv.org/abs/2106.06654",
          "publishedOn": "2021-06-15T01:45:15.737Z",
          "wordCount": 521,
          "title": "Disrupting Model Training with Adversarial Shortcuts. (arXiv:2106.06654v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06603",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meehan_C/0/1/0/all/0/1\">Casey Meehan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chowdhury_A/0/1/0/all/0/1\">Amrita Roy Chowdhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhuri_K/0/1/0/all/0/1\">Kamalika Chaudhuri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jha_S/0/1/0/all/0/1\">Somesh Jha</a>",
          "description": "ldp deployments are vulnerable to inference attacks as an adversary can link\nthe noisy responses to their identity and subsequently, auxiliary information\nusing the order of the data. An alternative model, shuffle DP, prevents this by\nshuffling the noisy responses uniformly at random. However, this limits the\ndata learnability -- only symmetric functions (input order agnostic) can be\nlearned. In this paper, we strike a balance and propose a generalized shuffling\nframework that interpolates between the two deployment models. We show that\nsystematic shuffling of the noisy responses can thwart specific inference\nattacks while retaining some meaningful data learnability. To this end, we\npropose a novel privacy guarantee, d-sigma privacy, that captures the privacy\nof the order of a data sequence. d-sigma privacy allows tuning the granularity\nat which the ordinal information is maintained, which formalizes the degree the\nresistance to inference attacks trading it off with data learnability.\nAdditionally, we propose a novel shuffling mechanism that can achieve d-sigma\nprivacy and demonstrate the practicality of our mechanism via evaluation on\nreal-world datasets.",
          "link": "http://arxiv.org/abs/2106.06603",
          "publishedOn": "2021-06-15T01:45:15.722Z",
          "wordCount": 596,
          "title": "A Shuffling Framework for Local Differential Privacy. (arXiv:2106.06603v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/1906.00460",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Malyshkin_V/0/1/0/all/0/1\">Vladislav Gennadievich Malyshkin</a>",
          "description": "Problems of interpolation, classification, and clustering are considered. In\nthe tenets of Radon--Nikodym approach $\\langle f(\\mathbf{x})\\psi^2 \\rangle /\n\\langle\\psi^2\\rangle$, where the $\\psi(\\mathbf{x})$ is a linear function on\ninput attributes, all the answers are obtained from a generalized eigenproblem\n$|f|\\psi^{[i]}\\rangle = \\lambda^{[i]} |\\psi^{[i]}\\rangle$. The solution to the\ninterpolation problem is a regular Radon-Nikodym derivative. The solution to\nthe classification problem requires prior and posterior probabilities that are\nobtained using the Lebesgue quadrature[1] technique. Whereas in a Bayesian\napproach new observations change only outcome probabilities, in the\nRadon-Nikodym approach not only outcome probabilities but also the probability\nspace $|\\psi^{[i]}\\rangle$ change with new observations. This is a remarkable\nfeature of the approach: both the probabilities and the probability space are\nconstructed from the data. The Lebesgue quadrature technique can be also\napplied to the optimal clustering problem. The problem is solved by\nconstructing a Gaussian quadrature on the Lebesgue measure. A distinguishing\nfeature of the Radon-Nikodym approach is the knowledge of the invariant group:\nall the answers are invariant relatively any non-degenerated linear transform\nof input vector $\\mathbf{x}$ components. A software product implementing the\nalgorithms of interpolation, classification, and optimal clustering is\navailable from the authors.",
          "link": "http://arxiv.org/abs/1906.00460",
          "publishedOn": "2021-06-15T01:45:15.716Z",
          "wordCount": 840,
          "title": "On The Radon-Nikodym Spectral Approach With Optimal Clustering. (arXiv:1906.00460v16 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06778",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ye_L/0/1/0/all/0/1\">Longqing Ye</a>",
          "description": "Convolutional networks (ConvNets) have shown impressive capability to solve\nvarious vision tasks. Nevertheless, the trade-off between performance and\nefficiency is still a challenge for a feasible model deployment on\nresource-constrained platforms. In this paper, we introduce a novel concept\ntermed multi-path fully connected pattern (MPFC) to rethink the\ninterdependencies of topology pattern, accuracy and efficiency for ConvNets.\nInspired by MPFC, we further propose a dual-branch module named dynamic clone\ntransformer (DCT) where one branch generates multiple replicas from inputs and\nanother branch reforms those clones through a series of difference vectors\nconditional on inputs itself to produce more variants. This operation allows\nthe self-expansion of channel-wise information in a data-driven way with little\ncomputational cost while providing sufficient learning capacity, which is a\npotential unit to replace computationally expensive pointwise convolution as an\nexpansion layer in the bottleneck structure.",
          "link": "http://arxiv.org/abs/2106.06778",
          "publishedOn": "2021-06-15T01:45:15.703Z",
          "wordCount": 567,
          "title": "Dynamic Clone Transformer for Efficient Convolutional Neural Netwoks. (arXiv:2106.06778v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/1905.12418",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alsubaihi_S/0/1/0/all/0/1\">Salman Alsubaihi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bibi_A/0/1/0/all/0/1\">Adel Bibi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alfadly_M/0/1/0/all/0/1\">Modar Alfadly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamdi_A/0/1/0/all/0/1\">Abdullah Hamdi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghanem_B/0/1/0/all/0/1\">Bernard Ghanem</a>",
          "description": "Training Deep Neural Networks that are robust to norm bounded adversarial\nattacks remains an elusive problem. While exact and inexact verification-based\nmethods are generally too expensive to train large networks, it was\ndemonstrated that bounded input intervals can be inexpensively propagated from\na layer to another through deep networks. This interval bound propagation\napproach (IBP) not only has improved both robustness and certified accuracy but\nwas the first to be employed on large/deep networks. However, due to the very\nloose nature of the IBP bounds, the required training procedure is complex and\ninvolved. In this paper, we closely examine the bounds of a block of layers\ncomposed in the form of Affine-ReLU-Affine. To this end, we propose expected\ntight bounds (true bounds in expectation), referred to as ETB, which are\nprovably tighter than IBP bounds in expectation. We then extend this result to\ndeeper networks through blockwise propagation and show that we can achieve\norders of magnitudes tighter bounds compared to IBP. Furthermore, using a\nsimple standard training procedure, we can achieve impressive\nrobustness-accuracy trade-off on both MNIST and CIFAR10.",
          "link": "http://arxiv.org/abs/1905.12418",
          "publishedOn": "2021-06-15T01:45:15.697Z",
          "wordCount": 678,
          "title": "Expected Tight Bounds for Robust Training. (arXiv:1905.12418v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06873",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ding_K/0/1/0/all/0/1\">Kaize Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianling Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jundong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caverlee_J/0/1/0/all/0/1\">James Caverlee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Huan Liu</a>",
          "description": "Graphs are widely used to model the relational structure of data, and the\nresearch of graph machine learning (ML) has a wide spectrum of applications\nranging from drug design in molecular graphs to friendship recommendation in\nsocial networks. Prevailing approaches for graph ML typically require abundant\nlabeled instances in achieving satisfactory results, which is commonly\ninfeasible in real-world scenarios since labeled data for newly emerged\nconcepts (e.g., new categorizations of nodes) on graphs is limited. Though\nmeta-learning has been applied to different few-shot graph learning problems,\nmost existing efforts predominately assume that all the data from those seen\nclasses is gold-labeled, while those methods may lose their efficacy when the\nseen data is weakly-labeled with severe label noise. As such, we aim to\ninvestigate a novel problem of weakly-supervised graph meta-learning for\nimproving the model robustness in terms of knowledge transfer. To achieve this\ngoal, we propose a new graph meta-learning framework -- Graph Hallucination\nNetworks (Meta-GHN) in this paper. Based on a new robustness-enhanced episodic\ntraining, Meta-GHN is meta-learned to hallucinate clean node representations\nfrom weakly-labeled data and extracts highly transferable meta-knowledge, which\nenables the model to quickly adapt to unseen tasks with few labeled instances.\nExtensive experiments demonstrate the superiority of Meta-GHN over existing\ngraph meta-learning studies on the task of weakly-supervised few-shot node\nclassification.",
          "link": "http://arxiv.org/abs/2106.06873",
          "publishedOn": "2021-06-15T01:45:15.684Z",
          "wordCount": 640,
          "title": "Weakly-supervised Graph Meta-learning for Few-shot Node Classification. (arXiv:2106.06873v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06631",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Parmentier_A/0/1/0/all/0/1\">Axel Parmentier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vidal_T/0/1/0/all/0/1\">Thibaut Vidal</a>",
          "description": "Counterfactual explanations are usually generated through heuristics that are\nsensitive to the search's initial conditions. The absence of guarantees of\nperformance and robustness hinders trustworthiness. In this paper, we take a\ndisciplined approach towards counterfactual explanations for tree ensembles. We\nadvocate for a model-based search aiming at \"optimal\" explanations and propose\nefficient mixed-integer programming approaches. We show that isolation forests\ncan be modeled within our framework to focus the search on plausible\nexplanations with a low outlier score. We provide comprehensive coverage of\nadditional constraints that model important objectives, heterogeneous data\ntypes, structural constraints on the feature space, along with resource and\nactionability restrictions. Our experimental analyses demonstrate that the\nproposed search approach requires a computational effort that is orders of\nmagnitude smaller than previous mathematical programming algorithms. It scales\nup to large data sets and tree ensembles, where it provides, within seconds,\nsystematic explanations grounded on well-defined models solved to optimality.",
          "link": "http://arxiv.org/abs/2106.06631",
          "publishedOn": "2021-06-15T01:45:15.678Z",
          "wordCount": 600,
          "title": "Optimal Counterfactual Explanations in Tree Ensembles. (arXiv:2106.06631v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06610",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Villar_S/0/1/0/all/0/1\">Soledad Villar</a> (JHU), <a href=\"http://arxiv.org/find/cs/1/au:+Hogg_D/0/1/0/all/0/1\">David W.Hogg</a> (Flatiron, NYU), <a href=\"http://arxiv.org/find/cs/1/au:+Storey_Fisher_K/0/1/0/all/0/1\">Kate Storey-Fisher</a> (NYU), <a href=\"http://arxiv.org/find/cs/1/au:+Yao_W/0/1/0/all/0/1\">Weichi Yao</a> (NYU), <a href=\"http://arxiv.org/find/cs/1/au:+Blum_Smith_B/0/1/0/all/0/1\">Ben Blum-Smith</a> (NYU)",
          "description": "There has been enormous progress in the last few years in designing\nconceivable (though not always practical) neural networks that respect the\ngauge symmetries -- or coordinate freedom -- of physical law. Some of these\nframeworks make use of irreducible representations, some make use of higher\norder tensor objects, and some apply symmetry-enforcing constraints. Different\nphysical laws obey different combinations of fundamental symmetries, but a\nlarge fraction (possibly all) of classical physics is equivariant to\ntranslation, rotation, reflection (parity), boost (relativity), and\npermutations. Here we show that it is simple to parameterize universally\napproximating polynomial functions that are equivariant under these symmetries,\nor under the Euclidean, Lorentz, and Poincar\\'e groups, at any dimensionality\n$d$. The key observation is that nonlinear O($d$)-equivariant (and\nrelated-group-equivariant) functions can be expressed in terms of a lightweight\ncollection of scalars -- scalar products and scalar contractions of the scalar,\nvector, and tensor inputs. These results demonstrate theoretically that\ngauge-invariant deep learning models for classical physics with good scaling\nfor large problems are feasible right now.",
          "link": "http://arxiv.org/abs/2106.06610",
          "publishedOn": "2021-06-15T01:45:15.671Z",
          "wordCount": 618,
          "title": "Scalars are universal: Gauge-equivariant machine learning, structured like classical physics. (arXiv:2106.06610v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06917",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alparslan_Y/0/1/0/all/0/1\">Yigit Alparslan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_E/0/1/0/all/0/1\">Edward Kim</a>",
          "description": "In this paper, we explore the effect of architecture completeness on\nadversarial robustness. We train models with different architectures on\nCIFAR-10 and MNIST dataset. For each model, we vary different number of layers\nand different number of nodes in the layer. For every architecture candidate,\nwe use Fast Gradient Sign Method (FGSM) to generate untargeted adversarial\nattacks and use adversarial training to defend against those attacks. For each\narchitecture candidate, we report pre-attack, post-attack and post-defense\naccuracy for the model as well as the architecture parameters and the impact of\ncompleteness to the model accuracies.",
          "link": "http://arxiv.org/abs/2106.06917",
          "publishedOn": "2021-06-15T01:45:15.638Z",
          "wordCount": 517,
          "title": "ATRAS: Adversarially Trained Robust Architecture Search. (arXiv:2106.06917v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06691",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Schein_A/0/1/0/all/0/1\">Aaron Schein</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nagulpally_A/0/1/0/all/0/1\">Anjali Nagulpally</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wallach_H/0/1/0/all/0/1\">Hanna Wallach</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Flaherty_P/0/1/0/all/0/1\">Patrick Flaherty</a>",
          "description": "We present a new non-negative matrix factorization model for $(0,1)$\nbounded-support data based on the doubly non-central beta (DNCB) distribution,\na generalization of the beta distribution. The expressiveness of the DNCB\ndistribution is particularly useful for modeling DNA methylation datasets,\nwhich are typically highly dispersed and multi-modal; however, the model\nstructure is sufficiently general that it can be adapted to many other domains\nwhere latent representations of $(0,1)$ bounded-support data are of interest.\nAlthough the DNCB distribution lacks a closed-form conjugate prior, several\naugmentations let us derive an efficient posterior inference algorithm composed\nentirely of analytic updates. Our model improves out-of-sample predictive\nperformance on both real and synthetic DNA methylation datasets over\nstate-of-the-art methods in bioinformatics. In addition, our model yields\nmeaningful latent representations that accord with existing biological\nknowledge.",
          "link": "http://arxiv.org/abs/2106.06691",
          "publishedOn": "2021-06-15T01:45:15.626Z",
          "wordCount": 583,
          "title": "Doubly Non-Central Beta Matrix Factorization for DNA Methylation Data. (arXiv:2106.06691v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06880",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Safran_I/0/1/0/all/0/1\">Itay Safran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shamir_O/0/1/0/all/0/1\">Ohad Shamir</a>",
          "description": "Recently, there has been much interest in studying the convergence rates of\nwithout-replacement SGD, and proving that it is faster than with-replacement\nSGD in the worst case. However, these works ignore or do not provide tight\nbounds in terms of the problem's geometry, including its condition number.\nPerhaps surprisingly, we prove that when the condition number is taken into\naccount, without-replacement SGD \\emph{does not} significantly improve on\nwith-replacement SGD in terms of worst-case bounds, unless the number of epochs\n(passes over the data) is larger than the condition number. Since many problems\nin machine learning and other areas are both ill-conditioned and involve large\ndatasets, this indicates that without-replacement does not necessarily improve\nover with-replacement sampling for realistic iteration budgets. We show this by\nproviding new lower and upper bounds which are tight (up to log factors), for\nquadratic problems with commuting quadratic terms, precisely quantifying the\ndependence on the problem parameters.",
          "link": "http://arxiv.org/abs/2106.06880",
          "publishedOn": "2021-06-15T01:45:15.617Z",
          "wordCount": 578,
          "title": "Random Shuffling Beats SGD Only After Many Epochs on Ill-Conditioned Problems. (arXiv:2106.06880v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06819",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sinha_A/0/1/0/all/0/1\">Abhishek Sinha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1\">Jiaming Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_C/0/1/0/all/0/1\">Chenlin Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ermon_S/0/1/0/all/0/1\">Stefano Ermon</a>",
          "description": "Conditional generative models of high-dimensional images have many\napplications, but supervision signals from conditions to images can be\nexpensive to acquire. This paper describes Diffusion-Decoding models with\nContrastive representations (D2C), a paradigm for training unconditional\nvariational autoencoders (VAEs) for few-shot conditional image generation. D2C\nuses a learned diffusion-based prior over the latent representations to improve\ngeneration and contrastive self-supervised learning to improve representation\nquality. D2C can adapt to novel generation tasks conditioned on labels or\nmanipulation constraints, by learning from as few as 100 labeled examples. On\nconditional generation from new labels, D2C achieves superior performance over\nstate-of-the-art VAEs and diffusion models. On conditional image manipulation,\nD2C generations are two orders of magnitude faster to produce over StyleGAN2\nones and are preferred by 50% - 60% of the human evaluators in a double-blind\nstudy.",
          "link": "http://arxiv.org/abs/2106.06819",
          "publishedOn": "2021-06-15T01:45:15.596Z",
          "wordCount": 567,
          "title": "D2C: Diffusion-Denoising Models for Few-shot Conditional Generation. (arXiv:2106.06819v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/1907.08738",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lee_T/0/1/0/all/0/1\">Taehee Lee</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lisiecki_L/0/1/0/all/0/1\">Lorraine E. Lisiecki</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rand_D/0/1/0/all/0/1\">Devin Rand</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gebbie_G/0/1/0/all/0/1\">Geoffrey Gebbie</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lawrence_C/0/1/0/all/0/1\">Charles E. Lawrence</a>",
          "description": "We first introduce a novel profile-based alignment algorithm, the multiple\ncontinuous Signal Alignment algorithm with Gaussian Process Regression profiles\n(SA-GPR). SA-GPR addresses the limitations of currently available signal\nalignment methods by adopting a hybrid of the particle smoothing and\nMarkov-chain Monte Carlo (MCMC) algorithms to align signals, and by applying\nthe Gaussian process regression to construct profiles to be aligned\ncontinuously. SA-GPR shares all the strengths of the existing alignment\nalgorithms that depend on profiles but is more exact in the sense that profiles\ndo not need to be discretized as sequential bins. The uncertainty of\nperformance over the resolution of such bins is thereby eliminated. This\nmethodology produces alignments that are consistent, that regularize extreme\ncases, and that properly reflect the inherent uncertainty.\n\nThen we extend SA-GPR to a specific problem in the field of paleoceanography\nwith a method called Bayesian Inference Gaussian Process Multiproxy Alignment\nof Continuous Signals (BIGMACS). The goal of BIGMACS is to infer continuous\nages for ocean sediment cores using two classes of age proxies: proxies that\nexplicitly return calendar ages (e.g., radiocarbon) and those used to\nsynchronize ages in multiple marine records (e.g., an oxygen isotope based\nmarine proxy known as benthic ${\\delta}^{18}{\\rm O}$). BIGMACS integrates these\ntwo proxies by iteratively performing two steps: profile construction from\nbenthic ${\\delta}^{18}{\\rm O}$ age models and alignment of each core to the\nprofile also reflecting radiocarbon dates. We use BIGMACS to construct a new\nDeep Northeastern Atlantic stack (i.e., a profile from a particular benthic\n${\\delta}^{18}{\\rm O}$ records) of five ocean sediment cores. We conclude by\nconstructing multiproxy age models for two additional cores from the same\nregion by aligning them to the stack.",
          "link": "http://arxiv.org/abs/1907.08738",
          "publishedOn": "2021-06-15T01:45:15.577Z",
          "wordCount": 765,
          "title": "Bayesian Inference Gaussian Process Multiproxy Alignment of Continuous Signals (BIGMACS): Applications for Paleoceanography. (arXiv:1907.08738v4 [stat.AP] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06667",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Dian Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Hongxin Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qian Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yinli Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Cong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1\">Chao Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qi Li</a>",
          "description": "Transfer learning eases the burden of training a well-performed model from\nscratch, especially when training data is scarce and computation power is\nlimited. In deep learning, a typical strategy for transfer learning is to\nfreeze the early layers of a pre-trained model and fine-tune the rest of its\nlayers on the target domain. Previous work focuses on the accuracy of the\ntransferred model but neglects the transfer of adversarial robustness. In this\nwork, we first show that transfer learning improves the accuracy on the target\ndomain but degrades the inherited robustness of the target model. To address\nsuch a problem, we propose a novel cooperative adversarially-robust transfer\nlearning (CARTL) by pre-training the model via feature distance minimization\nand fine-tuning the pre-trained model with non-expansive fine-tuning for target\ndomain tasks. Empirical results show that CARTL improves the inherited\nrobustness by about 28% at most compared with the baseline with the same degree\nof accuracy. Furthermore, we study the relationship between the batch\nnormalization (BN) layers and the robustness in the context of transfer\nlearning, and we reveal that freezing BN layers can further boost the\nrobustness transfer.",
          "link": "http://arxiv.org/abs/2106.06667",
          "publishedOn": "2021-06-15T01:45:15.548Z",
          "wordCount": 618,
          "title": "CARTL: Cooperative Adversarially-Robust Transfer Learning. (arXiv:2106.06667v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06983",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Esmaeili_A/0/1/0/all/0/1\">Ashkan Esmaeili</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joneidi_M/0/1/0/all/0/1\">Mohsen Joneidi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salimitari_M/0/1/0/all/0/1\">Mehrdad Salimitari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khalid_U/0/1/0/all/0/1\">Umar Khalid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahnavard_N/0/1/0/all/0/1\">Nazanin Rahnavard</a>",
          "description": "The problem of simultaneous column and row subset selection is addressed in\nthis paper. The column space and row space of a matrix are spanned by its left\nand right singular vectors, respectively. However, the singular vectors are not\nwithin actual columns/rows of the matrix. In this paper, an iterative approach\nis proposed to capture the most structural information of columns/rows via\nselecting a subset of actual columns/rows. This algorithm is referred to as\ntwo-way spectrum pursuit (TWSP) which provides us with an accurate solution for\nthe CUR matrix decomposition. TWSP is applicable in a wide range of\napplications since it enjoys a linear complexity w.r.t. number of original\ncolumns/rows. We demonstrated the application of TWSP for joint channel and\nsensor selection in cognitive radio networks, informative users and contents\ndetection, and efficient supervised data reduction.",
          "link": "http://arxiv.org/abs/2106.06983",
          "publishedOn": "2021-06-15T01:45:15.525Z",
          "wordCount": 573,
          "title": "Two-way Spectrum Pursuit for CUR Decomposition and Its Application in Joint Column/Row Subset Selection. (arXiv:2106.06983v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06891",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Lin_F/0/1/0/all/0/1\">Feng Lin</a>, <a href=\"http://arxiv.org/find/math/1/au:+Li_W/0/1/0/all/0/1\">Weiyu Li</a>, <a href=\"http://arxiv.org/find/math/1/au:+Ling_Q/0/1/0/all/0/1\">Qing Ling</a>",
          "description": "This paper aims to solve a distributed learning problem under Byzantine\nattacks. In the underlying distributed system, a number of unknown but\nmalicious workers (termed as Byzantine workers) can send arbitrary messages to\nthe master and bias the learning process, due to data corruptions, computation\nerrors or malicious attacks. Prior work has considered a total variation (TV)\nnorm-penalized approximation formulation to handle the Byzantine attacks, where\nthe TV norm penalty forces the regular workers' local variables to be close,\nand meanwhile, tolerates the outliers sent by the Byzantine workers. To solve\nthe TV norm-penalized approximation formulation, we propose a Byzantine-robust\nstochastic alternating direction method of multipliers (ADMM) that fully\nutilizes the separable problem structure. Theoretically, we prove that the\nproposed method converges to a bounded neighborhood of the optimal solution at\na rate of O(1/k) under mild assumptions, where k is the number of iterations\nand the size of neighborhood is determined by the number of Byzantine workers.\nNumerical experiments on the MNIST and COVERTYPE datasets demonstrate the\neffectiveness of the proposed method to various Byzantine attacks.",
          "link": "http://arxiv.org/abs/2106.06891",
          "publishedOn": "2021-06-15T01:45:15.518Z",
          "wordCount": 615,
          "title": "Stochastic Alternating Direction Method of Multipliers for Byzantine-Robust Distributed Learning. (arXiv:2106.06891v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06795",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Karim_M/0/1/0/all/0/1\">Mohammed Asad Karim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verma_V/0/1/0/all/0/1\">Vinay Kumar Verma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_P/0/1/0/all/0/1\">Pravendra Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Namboodiri_V/0/1/0/all/0/1\">Vinay Namboodiri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rai_P/0/1/0/all/0/1\">Piyush Rai</a>",
          "description": "We propose a novel approach for class incremental online learning in a\nlimited data setting. This problem setting is challenging because of the\nfollowing constraints: (1) Classes are given incrementally, which necessitates\na class incremental learning approach; (2) Data for each class is given in an\nonline fashion, i.e., each training example is seen only once during training;\n(3) Each class has very few training examples; and (4) We do not use or assume\naccess to any replay/memory to store data from previous classes. Therefore, in\nthis setting, we have to handle twofold problems of catastrophic forgetting and\noverfitting. In our approach, we learn robust representations that are\ngeneralizable across tasks without suffering from the problems of catastrophic\nforgetting and overfitting to accommodate future classes with limited samples.\nOur proposed method leverages the meta-learning framework with knowledge\nconsolidation. The meta-learning framework helps the model for rapid learning\nwhen samples appear in an online fashion. Simultaneously, knowledge\nconsolidation helps to learn a robust representation against forgetting under\nonline updates to facilitate future learning. Our approach significantly\noutperforms other methods on several benchmarks.",
          "link": "http://arxiv.org/abs/2106.06795",
          "publishedOn": "2021-06-15T01:45:15.488Z",
          "wordCount": 631,
          "title": "Knowledge Consolidation based Class Incremental Online Learning with Limited Data. (arXiv:2106.06795v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06593",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1\">Kedan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chong_M/0/1/0/all/0/1\">Min jin Chong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jeffrey Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jingen Liu</a>",
          "description": "Virtual try-on methods aim to generate images of fashion models wearing\narbitrary combinations of garments. This is a challenging task because the\ngenerated image must appear realistic and accurately display the interaction\nbetween garments. Prior works produce images that are filled with artifacts and\nfail to capture important visual details necessary for commercial applications.\nWe propose Outfit Visualization Net (OVNet) to capture these important details\n(e.g. buttons, shading, textures, realistic hemlines, and interactions between\ngarments) and produce high quality multiple-garment virtual try-on images.\nOVNet consists of 1) a semantic layout generator and 2) an image generation\npipeline using multiple coordinated warps. We train the warper to output\nmultiple warps using a cascade loss, which refines each successive warp to\nfocus on poorly generated regions of a previous warp and yields consistent\nimprovements in detail. In addition, we introduce a method for matching outfits\nwith the most suitable model and produce significant improvements for both our\nand other previous try-on methods. Through quantitative and qualitative\nanalysis, we demonstrate our method generates substantially higher-quality\nstudio images compared to prior works for multi-garment outfits. An interactive\ninterface powered by this method has been deployed on fashion e-commerce\nwebsites and received overwhelmingly positive feedback.",
          "link": "http://arxiv.org/abs/2106.06593",
          "publishedOn": "2021-06-15T01:45:15.436Z",
          "wordCount": 653,
          "title": "Toward Accurate and Realistic Outfits Visualization with Attention to Details. (arXiv:2106.06593v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06657",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1\">Zhili Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Shaobo Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_S/0/1/0/all/0/1\">Simon S. Du</a>",
          "description": "This paper studies zero-shot domain adaptation where each domain is indexed\non a multi-dimensional array, and we only have data from a small subset of\ndomains. Our goal is to produce predictors that perform well on \\emph{unseen}\ndomains. We propose a model which consists of a domain-invariant latent\nrepresentation layer and a domain-specific linear prediction layer with a\nlow-rank tensor structure. Theoretically, we present explicit sample complexity\nbounds to characterize the prediction error on unseen domains in terms of the\nnumber of domains with training data and the number of data per domain. To our\nknowledge, this is the first finite-sample guarantee for zero-shot domain\nadaptation. In addition, we provide experiments on two-way MNIST and four-way\nfiber sensing datasets to demonstrate the effectiveness of our proposed model.",
          "link": "http://arxiv.org/abs/2106.06657",
          "publishedOn": "2021-06-15T01:45:15.425Z",
          "wordCount": 551,
          "title": "Provable Adaptation across Multiway Domains via Representation Learning. (arXiv:2106.06657v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06683",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jialu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Eric Wang</a>",
          "description": "Recently pre-trained multimodal models, such as CLIP, have received a surge\nof attention for their exceptional capabilities towards connecting images and\nnatural language. The textual representations in English can be desirably\ntransferred to multilingualism and support promising downstream multimodal\ntasks for different languages. Nevertheless, previous fairness discourse in\nvision-and-language learning mainly focuses on monolingual representational\nbiases, and rarely scrutinizes the principles of multilingual fairness in this\nmultimodal setting, where one language is equated to a group of individuals and\nimages provide the universal grounding for bridging different languages.\n\nIn this paper, we provide a nuanced understanding of individual fairness and\ngroup fairness by viewing language as the recipient of fairness notions. We\ndefine new fairness notions within multilingual context and analytically\narticulate that, pre-trained vision-and-language representations are\nindividually fair across languages but not guaranteed to group fairness.\nFurthermore, we conduct extensive experiments to explore the prevalent group\ndisparity across languages and protected groups including race, gender and age.",
          "link": "http://arxiv.org/abs/2106.06683",
          "publishedOn": "2021-06-15T01:45:15.289Z",
          "wordCount": 593,
          "title": "Assessing Multilingual Fairness in Pre-trained Multimodal Representations. (arXiv:2106.06683v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2103.02014",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mladenovic_A/0/1/0/all/0/1\">Andjela Mladenovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bose_A/0/1/0/all/0/1\">Avishek Joey Bose</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berard_H/0/1/0/all/0/1\">Hugo Berard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamilton_W/0/1/0/all/0/1\">William L. Hamilton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lacoste_Julien_S/0/1/0/all/0/1\">Simon Lacoste-Julien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vincent_P/0/1/0/all/0/1\">Pascal Vincent</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gidel_G/0/1/0/all/0/1\">Gauthier Gidel</a>",
          "description": "Adversarial attacks expose important vulnerabilities of deep learning models,\nyet little attention has been paid to settings where data arrives as a stream.\nIn this paper, we formalize the online adversarial attack problem, emphasizing\ntwo key elements found in real-world use-cases: attackers must operate under\npartial knowledge of the target model, and the decisions made by the attacker\nare irrevocable since they operate on a transient data stream. We first\nrigorously analyze a deterministic variant of the online threat model by\ndrawing parallels to the well-studied $k$-secretary problem in theoretical\ncomputer science and propose Virtual+, a simple yet practical online algorithm.\nOur main theoretical result show Virtual+ yields provably the best competitive\nratio over all single-threshold algorithms for $k<5$ -- extending previous\nanalysis of the $k$-secretary problem. We also introduce the \\textit{stochastic\n$k$-secretary} -- effectively reducing online blackbox transfer attacks to a\n$k$-secretary problem under noise -- and prove theoretical bounds on the\nperformance of \\textit{any} online algorithms adapted to this setting. Finally,\nwe complement our theoretical results by conducting experiments on both MNIST\nand CIFAR-10 with both vanilla and robust classifiers, revealing not only the\nnecessity of online algorithms in achieving near-optimal performance but also\nthe rich interplay of a given attack strategy towards online attack selection,\nenabling simple strategies like FGSM to outperform classically strong whitebox\nadversaries.",
          "link": "http://arxiv.org/abs/2103.02014",
          "publishedOn": "2021-06-14T22:41:41.478Z",
          "wordCount": 696,
          "title": "Online Adversarial Attacks. (arXiv:2103.02014v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.09612",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_Q/0/1/0/all/0/1\">Quynh Nguyen</a>",
          "description": "We give a simple proof for the global convergence of gradient descent in\ntraining deep ReLU networks with the standard square loss, and show some of its\nimprovements over the state-of-the-art. In particular, while prior works\nrequire all the hidden layers to be wide with width at least $\\Omega(N^8)$ ($N$\nbeing the number of training samples), we require a single wide layer of\nlinear, quadratic or cubic width depending on the type of initialization.\nUnlike many recent proofs based on the Neural Tangent Kernel (NTK), our proof\nneed not track the evolution of the entire NTK matrix, or more generally, any\nquantities related to the changes of activation patterns during training.\nInstead, we only need to track the evolution of the output at the last hidden\nlayer, which can be done much more easily thanks to the Lipschitz property of\nReLU. Some highlights of our setting: (i) all the layers are trained with\nstandard gradient descent, (ii) the network has standard parameterization as\nopposed to the NTK one, and (iii) the network has a single wide layer as\nopposed to having all wide hidden layers as in most of NTK-related results.",
          "link": "http://arxiv.org/abs/2101.09612",
          "publishedOn": "2021-06-14T22:41:41.457Z",
          "wordCount": 669,
          "title": "On the Proof of Global Convergence of Gradient Descent for Deep ReLU Networks with Linear Widths. (arXiv:2101.09612v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02770",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1\">Dongxia Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chinazzi_M/0/1/0/all/0/1\">Matteo Chinazzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vespignani_A/0/1/0/all/0/1\">Alessandro Vespignani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yi-An Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_R/0/1/0/all/0/1\">Rose Yu</a>",
          "description": "Stochastic simulations such as large-scale, spatiotemporal, age-structured\nepidemic models are computationally expensive at fine-grained resolution. We\npropose Interactive Neural Process (INP), an interactive framework to\ncontinuously learn a deep learning surrogate model and accelerate simulation.\nOur framework is based on the novel integration of Bayesian active learning,\nstochastic simulation and deep sequence modeling. In particular, we develop a\nnovel spatiotemporal neural process model to mimic the underlying process\ndynamics. Our model automatically infers the latent process which describes the\nintrinsic uncertainty of the simulator. This also gives rise to a new\nacquisition function that can quantify the uncertainty of deep learning\npredictions. We design Bayesian active learning algorithms to iteratively query\nthe simulator, gather more data, and continuously improve the model. We perform\ntheoretical analysis and demonstrate that our approach reduces sample\ncomplexity compared with random sampling in high dimension. Empirically, we\ndemonstrate our framework can faithfully imitate the behavior of a complex\ninfectious disease simulator with a small number of examples, enabling rapid\nsimulation and scenario exploration.",
          "link": "http://arxiv.org/abs/2106.02770",
          "publishedOn": "2021-06-14T22:41:41.445Z",
          "wordCount": 614,
          "title": "Accelerating Stochastic Simulation with Interactive Neural Processes. (arXiv:2106.02770v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.05313",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Remlinger_C/0/1/0/all/0/1\">Carl Remlinger</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mikael_J/0/1/0/all/0/1\">Joseph Mikael</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Elie_R/0/1/0/all/0/1\">Romuald Elie</a>",
          "description": "We introduce three new generative models for time series. Based on Euler\ndiscretization and Wasserstein metrics, they are able to capture time marginal\ndistributions and temporal dynamics. Two of these methods rely on the\nadaptation of generative adversarial networks (GANs) to time series. Both of\nthem outperform state-of-the-art benchmarks by capturing the underlying\ntemporal structure on synthetic time series. The third algorithm, called\nConditional Euler Generator (CEGEN), minimizes a dedicated distance between the\ntransition probability distributions over all time steps. In the context of Ito\nprocesses, we provide theoretical guarantees that minimizing this criterion\nimplies accurate estimations of the drift and volatility parameters. We\ndemonstrate empirically that CEGEN outperforms state-of-the-art and GAN\ngenerators on both marginal and temporal dynamics metrics. Besides, it\nidentifies accurate correlation structures in high dimension. When few data\npoints are available, we verify the effectiveness of CEGEN, when combined with\ntransfer learning methods on Monte Carlo simulations. Finally, we illustrate\nthe robustness of our method on various real-world datasets.",
          "link": "http://arxiv.org/abs/2102.05313",
          "publishedOn": "2021-06-14T22:41:41.415Z",
          "wordCount": 636,
          "title": "Conditional and Adversarial Euler-based Generators For Time Series. (arXiv:2102.05313v4 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.09500",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sapir_M/0/1/0/all/0/1\">Marina Sapir</a>",
          "description": "I propose a new, logical, foundation for ML. ML is approached as a problem of\nmaximizing consistency of a hypothesis in a context of a given training set.\nNonjudgmental logic (NjL) with modalities ``It appears that'', ``Assume that''\nis introduced to formalize and quantify the inconsistency. Many popular ML\nalgorithms (from hierarchical clustering to k-NN and SVM) are shown to\ncorroborate the conjecture. In addition, it is demonstrated that NjL allows to\nformalize and solve several general learning problems which are not considered\nas ML usually.",
          "link": "http://arxiv.org/abs/2006.09500",
          "publishedOn": "2021-06-14T22:41:41.392Z",
          "wordCount": 537,
          "title": "Logic of Machine Learning. (arXiv:2006.09500v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.01618",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jun-Kun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chi-Heng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abernethy_J/0/1/0/all/0/1\">Jacob Abernethy</a>",
          "description": "Incorporating a so-called \"momentum\" dynamic in gradient descent methods is\nwidely used in neural net training as it has been broadly observed that, at\nleast empirically, it often leads to significantly faster convergence. At the\nsame time, there are very few theoretical guarantees in the literature to\nexplain this apparent acceleration effect. Even for the classical strongly\nconvex quadratic problems, several existing results only show Polyak's momentum\nhas an accelerated linear rate asymptotically. In this paper, we first revisit\nthe quadratic problems and show a non-asymptotic accelerated linear rate of\nPolyak's momentum. Then, we provably show that Polyak's momentum achieves\nacceleration for training a one-layer wide ReLU network and a deep linear\nnetwork, which are perhaps the two most popular canonical models for studying\noptimization and deep learning in the literature. Prior work Du at al. 2019 and\nWu et al. 2019 showed that using vanilla gradient descent, and with an use of\nover-parameterization, the error decays as $(1- \\Theta(\\frac{1}{ \\kappa'}))^t$\nafter $t$ iterations, where $\\kappa'$ is the condition number of a Gram Matrix.\nOur result shows that with the appropriate choice of parameters Polyak's\nmomentum has a rate of $(1-\\Theta(\\frac{1}{\\sqrt{\\kappa'}}))^t$. For the deep\nlinear network, prior work Hu et al. 2020 showed that vanilla gradient descent\nhas a rate of $(1-\\Theta(\\frac{1}{\\kappa}))^t$, where $\\kappa$ is the condition\nnumber of a data matrix. Our result shows an acceleration rate $(1-\n\\Theta(\\frac{1}{\\sqrt{\\kappa}}))^t$ is achievable by Polyak's momentum. All the\nresults in this work are obtained from a modular analysis, which can be of\nindependent interest. This work establishes that momentum does indeed speed up\nneural net training.",
          "link": "http://arxiv.org/abs/2010.01618",
          "publishedOn": "2021-06-14T22:41:41.359Z",
          "wordCount": 789,
          "title": "A Modular Analysis of Provable Acceleration via Polyak's Momentum: Training a Wide ReLU Network and a Deep Linear Network. (arXiv:2010.01618v6 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.07006",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Camuto_A/0/1/0/all/0/1\">Alexander Camuto</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_X/0/1/0/all/0/1\">Xiaoyu Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhu_L/0/1/0/all/0/1\">Lingjiong Zhu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Holmes_C/0/1/0/all/0/1\">Chris Holmes</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gurbuzbalaban_M/0/1/0/all/0/1\">Mert G&#xfc;rb&#xfc;zbalaban</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Simsekli_U/0/1/0/all/0/1\">Umut &#x15e;im&#x15f;ekli</a>",
          "description": "Gaussian noise injections (GNIs) are a family of simple and widely-used\nregularisation methods for training neural networks, where one injects additive\nor multiplicative Gaussian noise to the network activations at every iteration\nof the optimisation algorithm, which is typically chosen as stochastic gradient\ndescent (SGD). In this paper we focus on the so-called `implicit effect' of\nGNIs, which is the effect of the injected noise on the dynamics of SGD. We show\nthat this effect induces an asymmetric heavy-tailed noise on SGD gradient\nupdates. In order to model this modified dynamics, we first develop a\nLangevin-like stochastic differential equation that is driven by a general\nfamily of asymmetric heavy-tailed noise. Using this model we then formally\nprove that GNIs induce an `implicit bias', which varies depending on the\nheaviness of the tails and the level of asymmetry. Our empirical results\nconfirm that different types of neural networks trained with GNIs are\nwell-modelled by the proposed dynamics and that the implicit effect of these\ninjections induces a bias that degrades the performance of networks.",
          "link": "http://arxiv.org/abs/2102.07006",
          "publishedOn": "2021-06-14T01:38:56.498Z",
          "wordCount": 634,
          "title": "Asymmetric Heavy Tails and Implicit Bias in Gaussian Noise Injections. (arXiv:2102.07006v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.09690",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tony Z. Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wallace_E/0/1/0/all/0/1\">Eric Wallace</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1\">Shi Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klein_D/0/1/0/all/0/1\">Dan Klein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Sameer Singh</a>",
          "description": "GPT-3 can perform numerous tasks when provided a natural language prompt that\ncontains a few training examples. We show that this type of few-shot learning\ncan be unstable: the choice of prompt format, training examples, and even the\norder of the training examples can cause accuracy to vary from near chance to\nnear state-of-the-art. We demonstrate that this instability arises from the\nbias of language models towards predicting certain answers, e.g., those that\nare placed near the end of the prompt or are common in the pre-training data.\nTo mitigate this, we first estimate the model's bias towards each answer by\nasking for its prediction when given the training prompt and a content-free\ntest input such as \"N/A\". We then fit calibration parameters that cause the\nprediction for this input to be uniform across answers. On a diverse set of\ntasks, this contextual calibration procedure substantially improves GPT-3 and\nGPT-2's average accuracy (up to 30.0% absolute) and reduces variance across\ndifferent choices of the prompt.",
          "link": "http://arxiv.org/abs/2102.09690",
          "publishedOn": "2021-06-14T01:38:56.490Z",
          "wordCount": 632,
          "title": "Calibrate Before Use: Improving Few-Shot Performance of Language Models. (arXiv:2102.09690v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06533",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bhattad_A/0/1/0/all/0/1\">Anand Bhattad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dundar_A/0/1/0/all/0/1\">Aysegul Dundar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Guilin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_A/0/1/0/all/0/1\">Andrew Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Catanzaro_B/0/1/0/all/0/1\">Bryan Catanzaro</a>",
          "description": "Humans can easily infer the underlying 3D geometry and texture of an object\nonly from a single 2D image. Current computer vision methods can do this, too,\nbut suffer from view generalization problems - the models inferred tend to make\npoor predictions of appearance in novel views. As for generalization problems\nin machine learning, the difficulty is balancing single-view accuracy (cf.\ntraining error; bias) with novel view accuracy (cf. test error; variance). We\ndescribe a class of models whose geometric rigidity is easily controlled to\nmanage this tradeoff. We describe a cycle consistency loss that improves view\ngeneralization (roughly, a model from a generated view should predict the\noriginal view well). View generalization of textures requires that models share\ntexture information, so a car seen from the back still has headlights because\nother cars have headlights. We describe a cycle consistency loss that\nencourages model textures to be aligned, so as to encourage sharing. We compare\nour method against the state-of-the-art method and show both qualitative and\nquantitative improvements.",
          "link": "http://arxiv.org/abs/2106.06533",
          "publishedOn": "2021-06-14T01:38:56.482Z",
          "wordCount": 620,
          "title": "View Generalization for Single Image Textured 3D Models. (arXiv:2106.06533v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2012.01316",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1\">Yilun Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shuang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1\">Joshua Tenenbaum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mordatch_I/0/1/0/all/0/1\">Igor Mordatch</a>",
          "description": "Contrastive divergence is a popular method of training energy-based models,\nbut is known to have difficulties with training stability. We propose an\nadaptation to improve contrastive divergence training by scrutinizing a\ngradient term that is difficult to calculate and is often left out for\nconvenience. We show that this gradient term is numerically significant and in\npractice is important to avoid training instabilities, while being tractable to\nestimate. We further highlight how data augmentation and multi-scale processing\ncan be used to improve model robustness and generation quality. Finally, we\nempirically evaluate stability of model architectures and show improved\nperformance on a host of benchmarks and use cases,such as image generation, OOD\ndetection, and compositional generation.",
          "link": "http://arxiv.org/abs/2012.01316",
          "publishedOn": "2021-06-14T01:38:56.462Z",
          "wordCount": 596,
          "title": "Improved Contrastive Divergence Training of Energy Based Models. (arXiv:2012.01316v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.06192",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rister_B/0/1/0/all/0/1\">Blaine Rister</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubin_D/0/1/0/all/0/1\">Daniel L. Rubin</a>",
          "description": "Neuron death is a complex phenomenon with implications for model\ntrainability: the deeper the network, the lower the probability of finding a\nvalid initialization. In this work, we derive both upper and lower bounds on\nthe probability that a ReLU network is initialized to a trainable point, as a\nfunction of model hyperparameters. We show that it is possible to increase the\ndepth of a network indefinitely, so long as the width increases as well.\nFurthermore, our bounds are asymptotically tight under reasonable assumptions:\nfirst, the upper bound coincides with the true probability for a single-layer\nnetwork with the largest possible input set. Second, the true probability\nconverges to our lower bound as the input set shrinks to a single point, or as\nthe network complexity grows under an assumption about the output variance. We\nconfirm these results by numerical simulation, showing rapid convergence to the\nlower bound with increasing network depth. Then, motivated by the theory, we\npropose a practical sign flipping scheme which guarantees that the ratio of\nliving data points in a $k$-layer network is at least $2^{-k}$. Finally, we\nshow how these issues are mitigated by network design features currently seen\nin practice, such as batch normalization, residual connections, dense networks\nand skip connections. This suggests that neuron death may provide insight into\nthe efficacy of various model architectures.",
          "link": "http://arxiv.org/abs/2007.06192",
          "publishedOn": "2021-06-14T01:38:56.451Z",
          "wordCount": 685,
          "title": "Probabilistic bounds on neuron death in deep rectifier networks. (arXiv:2007.06192v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.11568",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mengyan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ong_C/0/1/0/all/0/1\">Cheng Soon Ong</a>",
          "description": "We consider a variant of the best arm identification task in stochastic\nmulti-armed bandits. Motivated by risk-averse decision-making problems, our\ngoal is to identify a set of $m$ arms with the highest $\\tau$-quantile values\nwithin a fixed budget. We prove asymmetric two-sided concentration inequalities\nfor order statistics and quantiles of random variables that have non-decreasing\nhazard rate, which may be of independent interest. With these inequalities, we\nanalyse a quantile version of Successive Accepts and Rejects (Q-SAR). We derive\nan upper bound for the probability of arm misidentification, the first\njustification of a quantile based algorithm for fixed budget multiple best arms\nidentification. We show illustrative experiments for best arm identification.",
          "link": "http://arxiv.org/abs/2010.11568",
          "publishedOn": "2021-06-14T01:38:56.444Z",
          "wordCount": 566,
          "title": "Quantile Bandits for Best Arms Identification. (arXiv:2010.11568v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.07641",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rizk_G/0/1/0/all/0/1\">Geovani Rizk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thomas_A/0/1/0/all/0/1\">Albert Thomas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Colin_I/0/1/0/all/0/1\">Igor Colin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laraki_R/0/1/0/all/0/1\">Rida Laraki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chevaleyre_Y/0/1/0/all/0/1\">Yann Chevaleyre</a>",
          "description": "We introduce a new graphical bilinear bandit problem where a learner (or a\n\\emph{central entity}) allocates arms to the nodes of a graph and observes for\neach edge a noisy bilinear reward representing the interaction between the two\nend nodes. We study the best arm identification problem in which the learner\nwants to find the graph allocation maximizing the sum of the bilinear rewards.\nBy efficiently exploiting the geometry of this bandit problem, we propose a\n\\emph{decentralized} allocation strategy based on random sampling with\ntheoretical guarantees. In particular, we characterize the influence of the\ngraph structure (e.g. star, complete or circle) on the convergence rate and\npropose empirical experiments that confirm this dependency.",
          "link": "http://arxiv.org/abs/2012.07641",
          "publishedOn": "2021-06-14T01:38:56.437Z",
          "wordCount": 574,
          "title": "Best Arm Identification in Graphical Bilinear Bandits. (arXiv:2012.07641v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.04764",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yildiz_C/0/1/0/all/0/1\">&#xc7;a&#x11f;atay Y&#x131;ld&#x131;z</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heinonen_M/0/1/0/all/0/1\">Markus Heinonen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lahdesmaki_H/0/1/0/all/0/1\">Harri L&#xe4;hdesm&#xe4;ki</a>",
          "description": "Model-based reinforcement learning (MBRL) approaches rely on discrete-time\nstate transition models whereas physical systems and the vast majority of\ncontrol tasks operate in continuous-time. To avoid time-discretization\napproximation of the underlying process, we propose a continuous-time MBRL\nframework based on a novel actor-critic method. Our approach also infers the\nunknown state evolution differentials with Bayesian neural ordinary\ndifferential equations (ODE) to account for epistemic uncertainty. We implement\nand test our method on a new ODE-RL suite that explicitly solves\ncontinuous-time control systems. Our experiments illustrate that the model is\nrobust against irregular and noisy data, is sample-efficient, and can solve\ncontrol problems which pose challenges to discrete-time MBRL methods.",
          "link": "http://arxiv.org/abs/2102.04764",
          "publishedOn": "2021-06-14T01:38:56.430Z",
          "wordCount": 565,
          "title": "Continuous-Time Model-Based Reinforcement Learning. (arXiv:2102.04764v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03211",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1\">Nhuong V. Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Legitime_S/0/1/0/all/0/1\">Sybille Legitime</a>",
          "description": "Extreme events are occurrences whose magnitude and potential cause extensive\ndamage on people, infrastructure, and the environment. Motivated by the extreme\nnature of the current global health landscape, which is plagued by the\ncoronavirus pandemic, we seek to better understand and model extreme events.\nModeling extreme events is common in practice and plays an important role in\ntime-series prediction applications. Our goal is to (i) compare and investigate\nthe effect of some common extreme events modeling methods to explore which\nmethod can be practical in reality and (ii) accelerate the deep learning\ntraining process, which commonly uses deep recurrent neural network (RNN), by\nimplementing the asynchronous local Stochastic Gradient Descent (SGD) framework\namong multiple compute nodes. In order to verify our distributed extreme events\nmodeling, we evaluate our proposed framework on a stock data set S\\&P500, with\na standard recurrent neural network. Our intuition is to explore the (best)\nextreme events modeling method which could work well under the distributed deep\nlearning setting. Moreover, by using asynchronous distributed learning, we aim\nto significantly reduce the communication cost among the compute nodes and\ncentral server, which is the main bottleneck of almost all distributed learning\nframeworks.\n\nWe implement our proposed work and evaluate its performance on representative\ndata sets, such as S&P500 stock in $5$-year period. The experimental results\nvalidate the correctness of the design principle and show a significant\ntraining duration reduction upto $8$x, compared to the baseline single compute\nnode. Our results also show that our proposed work can achieve the same level\nof test accuracy, compared to the baseline setting.",
          "link": "http://arxiv.org/abs/2106.03211",
          "publishedOn": "2021-06-14T01:38:56.408Z",
          "wordCount": 764,
          "title": "Distributed Learning and its Application for Time-Series Prediction. (arXiv:2106.03211v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06475",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Baghali_S/0/1/0/all/0/1\">Sina Baghali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasan_S/0/1/0/all/0/1\">Samiul Hasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1\">Zhaomiao Guo</a>",
          "description": "The increasing market penetration of electric vehicles (EVs) may pose\nsignificant electricity demand on power systems. This electricity demand is\naffected by the inherent uncertainties of EVs' travel behavior that makes\nforecasting the daily charging demand (CD) very challenging. In this project,\nwe use the National House Hold Survey (NHTS) data to form sequences of trips,\nand develop machine learning models to predict the parameters of the next trip\nof the drivers, including trip start time, end time, and distance. These\nparameters are later used to model the temporal charging behavior of EVs. The\nsimulation results show that the proposed modeling can effectively estimate the\ndaily CD pattern based on travel behavior of EVs, and simple machine learning\ntechniques can forecast the travel parameters with acceptable accuracy.",
          "link": "http://arxiv.org/abs/2106.06475",
          "publishedOn": "2021-06-14T01:38:56.398Z",
          "wordCount": 575,
          "title": "Analyzing the Travel and Charging Behavior of Electric Vehicles -- A Data-driven Approach. (arXiv:2106.06475v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06437",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cunningham_P/0/1/0/all/0/1\">Padraig Cunningham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kathirgamanathan_B/0/1/0/all/0/1\">Bahavathy Kathirgamanathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Delany_S/0/1/0/all/0/1\">Sarah Jane Delany</a>",
          "description": "In Machine Learning, feature selection entails selecting a subset of the\navailable features in a dataset to use for model development. There are many\nmotivations for feature selection, it may result in better models, it may\nprovide insight into the data and it may deliver economies in data gathering or\ndata processing. For these reasons feature selection has received a lot of\nattention in data analytics research. In this paper we provide an overview of\nthe main methods and present practical examples with Python implementations.\nWhile the main focus is on supervised feature selection techniques, we also\ncover some feature transformation methods.",
          "link": "http://arxiv.org/abs/2106.06437",
          "publishedOn": "2021-06-14T01:38:56.391Z",
          "wordCount": 525,
          "title": "Feature Selection Tutorial with Python Examples. (arXiv:2106.06437v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03640",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Masters_D/0/1/0/all/0/1\">Dominic Masters</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Labatie_A/0/1/0/all/0/1\">Antoine Labatie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eaton_Rosen_Z/0/1/0/all/0/1\">Zach Eaton-Rosen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luschi_C/0/1/0/all/0/1\">Carlo Luschi</a>",
          "description": "Much recent research has been dedicated to improving the efficiency of\ntraining and inference for image classification. This effort has commonly\nfocused on explicitly improving theoretical efficiency, often measured as\nImageNet validation accuracy per FLOP. These theoretical savings have, however,\nproven challenging to achieve in practice, particularly on high-performance\ntraining accelerators.\n\nIn this work, we focus on improving the practical efficiency of the\nstate-of-the-art EfficientNet models on a new class of accelerator, the\nGraphcore IPU. We do this by extending this family of models in the following\nways: (i) generalising depthwise convolutions to group convolutions; (ii)\nadding proxy-normalized activations to match batch normalization performance\nwith batch-independent statistics; (iii) reducing compute by lowering the\ntraining resolution and inexpensively fine-tuning at higher resolution. We find\nthat these three methods improve the practical efficiency for both training and\ninference. Our code will be made available online.",
          "link": "http://arxiv.org/abs/2106.03640",
          "publishedOn": "2021-06-14T01:38:56.380Z",
          "wordCount": 605,
          "title": "Making EfficientNet More Efficient: Exploring Batch-Independent Normalization, Group Convolutions and Reduced Resolution Training. (arXiv:2106.03640v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.03636",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Liu_K/0/1/0/all/0/1\">Kangqiao Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ziyin_L/0/1/0/all/0/1\">Liu Ziyin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ueda_M/0/1/0/all/0/1\">Masahito Ueda</a>",
          "description": "In the vanishing learning rate regime, stochastic gradient descent (SGD) is\nnow relatively well understood. In this work, we propose to study the basic\nproperties of SGD and its variants in the non-vanishing learning rate regime.\nThe focus is on deriving exactly solvable results and discussing their\nimplications. The main contributions of this work are to derive the stationary\ndistribution for discrete-time SGD in a quadratic loss function with and\nwithout momentum; in particular, one implication of our result is that the\nfluctuation caused by discrete-time dynamics takes a distorted shape and is\ndramatically larger than a continuous-time theory could predict. Examples of\napplications of the proposed theory considered in this work include the\napproximation error of variants of SGD, the effect of minibatch noise, the\noptimal Bayesian inference, the escape rate from a sharp minimum, and the\nstationary covariance of a few second-order methods including damped Newton's\nmethod, natural gradient descent, and Adam.",
          "link": "http://arxiv.org/abs/2012.03636",
          "publishedOn": "2021-06-14T01:38:56.373Z",
          "wordCount": 649,
          "title": "Noise and Fluctuation of Finite Learning Rate Stochastic Gradient Descent. (arXiv:2012.03636v4 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.02569",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Liu_Q/0/1/0/all/0/1\">Qingfeng Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Feng_Y/0/1/0/all/0/1\">Yang Feng</a>",
          "description": "We propose a new ensemble framework for supervised learning, called machine\ncollaboration (MaC), using a collection of base machines for prediction tasks.\nUnlike bagging/stacking (a parallel & independent framework) and boosting (a\nsequential & top-down framework), MaC is a type of circular & interactive\nlearning framework. The circular & interactive feature helps the base machines\nto transfer information circularly and update their structures and parameters\naccordingly. The theoretical result on the risk bound of the estimator from MaC\nreveals that the circular & interactive feature can help MaC reduce risk via a\nparsimonious ensemble. We conduct extensive experiments on MaC using both\nsimulated data and 119 benchmark real datasets. The results demonstrate that in\nmost cases, MaC performs significantly better than several other\nstate-of-the-art methods, including classification and regression trees, neural\nnetworks, stacking, and boosting.",
          "link": "http://arxiv.org/abs/2105.02569",
          "publishedOn": "2021-06-14T01:38:56.355Z",
          "wordCount": 584,
          "title": "Machine Collaboration. (arXiv:2105.02569v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14866",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Camuto_A/0/1/0/all/0/1\">Alexander Camuto</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Willetts_M/0/1/0/all/0/1\">Matthew Willetts</a>",
          "description": "In this work we study Variational Autoencoders (VAEs) from the perspective of\nharmonic analysis. By viewing a VAE's latent space as a Gaussian Space, a\nvariety of measure space, we derive a series of results that show that the\nencoder variance of a VAE controls the frequency content of the functions\nparameterised by the VAE encoder and decoder neural networks. In particular we\ndemonstrate that larger encoder variances reduce the high frequency content of\nthese functions. Our analysis allows us to show that increasing this variance\neffectively induces a soft Lipschitz constraint on the decoder network of a\nVAE, which is a core contributor to the adversarial robustness of VAEs. We\nfurther demonstrate that adding Gaussian noise to the input of a VAE allows us\nto more finely control the frequency content and the Lipschitz constant of the\nVAE encoder networks. To support our theoretical analysis we run experiments\nwith VAEs with small fully-connected neural networks and with larger\nconvolutional networks, demonstrating empirically that our theory holds for a\nvariety of neural network architectures.",
          "link": "http://arxiv.org/abs/2105.14866",
          "publishedOn": "2021-06-14T01:38:56.348Z",
          "wordCount": 629,
          "title": "Variational Autoencoders: A Harmonic Perspective. (arXiv:2105.14866v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.02710",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jennifer J. Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karigo_T/0/1/0/all/0/1\">Tomomi Karigo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_D/0/1/0/all/0/1\">Dipam Chakraborty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohanty_S/0/1/0/all/0/1\">Sharada P. Mohanty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wild_B/0/1/0/all/0/1\">Benjamin Wild</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Q/0/1/0/all/0/1\">Quan Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anderson_D/0/1/0/all/0/1\">David J. Anderson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perona_P/0/1/0/all/0/1\">Pietro Perona</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yue_Y/0/1/0/all/0/1\">Yisong Yue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kennedy_A/0/1/0/all/0/1\">Ann Kennedy</a>",
          "description": "Multi-agent behavior modeling aims to understand the interactions that occur\nbetween agents. We present a multi-agent dataset from behavioral neuroscience,\nthe Caltech Mouse Social Interactions (CalMS21) Dataset. Our dataset consists\nof trajectory data of social interactions, recorded from videos of freely\nbehaving mice in a standard resident-intruder assay. To help accelerate\nbehavioral studies, the CalMS21 dataset provides benchmarks to evaluate the\nperformance of automated behavior classification methods in three settings: (1)\nfor training on large behavioral datasets all annotated by a single annotator,\n(2) for style transfer to learn inter-annotator differences in behavior\ndefinitions, and (3) for learning of new behaviors of interest given limited\ntraining data. The dataset consists of 6 million frames of unlabeled tracked\nposes of interacting mice, as well as over 1 million frames with tracked poses\nand corresponding frame-level behavior annotations. The challenge of our\ndataset is to be able to classify behaviors accurately using both labeled and\nunlabeled tracking data, as well as being able to generalize to new settings.",
          "link": "http://arxiv.org/abs/2104.02710",
          "publishedOn": "2021-06-14T01:38:56.339Z",
          "wordCount": 662,
          "title": "The Multi-Agent Behavior Dataset: Mouse Dyadic Social Interactions. (arXiv:2104.02710v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.10836",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meng_T/0/1/0/all/0/1\">Tao Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>",
          "description": "Structured output prediction problems (e.g., sequential tagging, hierarchical\nmulti-class classification) often involve constraints over the output label\nspace. These constraints interact with the learned models to filter infeasible\nsolutions and facilitate in building an accountable system. However, although\nconstraints are useful, they are often based on hand-crafted rules. This raises\na question -- \\emph{can we mine constraints and rules from data based on a\nlearning algorithm?}\n\nIn this paper, we present a general framework for mining constraints from\ndata. In particular, we consider the inference in structured output prediction\nas an integer linear programming (ILP) problem. Then, given the coefficients of\nthe objective function and the corresponding solution, we mine the underlying\nconstraints by estimating the outer and inner polytopes of the feasible set. We\nverify the proposed constraint mining algorithm in various synthetic and\nreal-world applications and demonstrate that the proposed approach successfully\nidentifies the feasible set at scale.\n\nIn particular, we show that our approach can learn to solve 9x9 Sudoku\npuzzles and minimal spanning tree problems from examples without providing the\nunderlying rules. Our algorithm can also integrate with a neural network model\nto learn the hierarchical label structure of a multi-label classification task.\nBesides, we provide a theoretical analysis about the tightness of the polytopes\nand the reliability of the mined constraints.",
          "link": "http://arxiv.org/abs/2006.10836",
          "publishedOn": "2021-06-14T01:38:56.331Z",
          "wordCount": 681,
          "title": "An Integer Linear Programming Framework for Mining Constraints from Data. (arXiv:2006.10836v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.07869",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Papoudakis_G/0/1/0/all/0/1\">Georgios Papoudakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Christianos_F/0/1/0/all/0/1\">Filippos Christianos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schafer_L/0/1/0/all/0/1\">Lukas Sch&#xe4;fer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Albrecht_S/0/1/0/all/0/1\">Stefano V. Albrecht</a>",
          "description": "Multi-agent deep reinforcement learning (MARL) suffers from a lack of\ncommonly-used evaluation tasks and criteria, making comparisons between\napproaches difficult. In this work, we consistently evaluate and compare three\ndifferent classes of MARL algorithms (independent learning, centralised\nmulti-agent policy gradient, value decomposition) in a diverse range of\ncooperative multi-agent learning tasks. Our experiments serve as a reference\nfor the expected performance of algorithms across different learning tasks, and\nwe provide insights regarding the effectiveness of different learning\napproaches. We open-source EPyMARL, which extends the PyMARL\ncodebase~\\citep{samvelyan19smac} to include additional algorithms and allow for\nflexible configuration of algorithm implementation details such as parameter\nsharing. Finally, we open-source two environments for multi-agent research\nwhich focus on coordination under sparse rewards.",
          "link": "http://arxiv.org/abs/2006.07869",
          "publishedOn": "2021-06-14T01:38:56.323Z",
          "wordCount": 596,
          "title": "Benchmarking Multi-Agent Deep Reinforcement Learning Algorithms in Cooperative Tasks. (arXiv:2006.07869v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.00990",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pope_A/0/1/0/all/0/1\">Adrian P. Pope</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ide_J/0/1/0/all/0/1\">Jaime S. Ide</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Micovic_D/0/1/0/all/0/1\">Daria Micovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diaz_H/0/1/0/all/0/1\">Henry Diaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosenbluth_D/0/1/0/all/0/1\">David Rosenbluth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ritholtz_L/0/1/0/all/0/1\">Lee Ritholtz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Twedt_J/0/1/0/all/0/1\">Jason C. Twedt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walker_T/0/1/0/all/0/1\">Thayne T. Walker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alcedo_K/0/1/0/all/0/1\">Kevin Alcedo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Javorsek_D/0/1/0/all/0/1\">Daniel Javorsek</a>",
          "description": "Artificial Intelligence (AI) is becoming a critical component in the defense\nindustry, as recently demonstrated by DARPA`s AlphaDogfight Trials (ADT). ADT\nsought to vet the feasibility of AI algorithms capable of piloting an F-16 in\nsimulated air-to-air combat. As a participant in ADT, Lockheed Martin`s (LM)\napproach combines a hierarchical architecture with maximum-entropy\nreinforcement learning (RL), integrates expert knowledge through reward\nshaping, and supports modularity of policies. This approach achieved a $2^{nd}$\nplace finish in the final ADT event (among eight total competitors) and\ndefeated a graduate of the US Air Force's (USAF) F-16 Weapons Instructor Course\nin match play.",
          "link": "http://arxiv.org/abs/2105.00990",
          "publishedOn": "2021-06-14T01:38:56.302Z",
          "wordCount": 583,
          "title": "Hierarchical Reinforcement Learning for Air-to-Air Combat. (arXiv:2105.00990v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.07749",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chebotar_Y/0/1/0/all/0/1\">Yevgen Chebotar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hausman_K/0/1/0/all/0/1\">Karol Hausman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yao Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_T/0/1/0/all/0/1\">Ted Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalashnikov_D/0/1/0/all/0/1\">Dmitry Kalashnikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Varley_J/0/1/0/all/0/1\">Jake Varley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Irpan_A/0/1/0/all/0/1\">Alex Irpan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eysenbach_B/0/1/0/all/0/1\">Benjamin Eysenbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Julian_R/0/1/0/all/0/1\">Ryan Julian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1\">Chelsea Finn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1\">Sergey Levine</a>",
          "description": "We consider the problem of learning useful robotic skills from previously\ncollected offline data without access to manually specified rewards or\nadditional online exploration, a setting that is becoming increasingly\nimportant for scaling robot learning by reusing past robotic data. In\nparticular, we propose the objective of learning a functional understanding of\nthe environment by learning to reach any goal state in a given dataset. We\nemploy goal-conditioned Q-learning with hindsight relabeling and develop\nseveral techniques that enable training in a particularly challenging offline\nsetting. We find that our method can operate on high-dimensional camera images\nand learn a variety of skills on real robots that generalize to previously\nunseen scenes and objects. We also show that our method can learn to reach\nlong-horizon goals across multiple episodes through goal chaining, and learn\nrich representations that can help with downstream tasks through pre-training\nor auxiliary objectives. The videos of our experiments can be found at\nhttps://actionable-models.github.io",
          "link": "http://arxiv.org/abs/2104.07749",
          "publishedOn": "2021-06-14T01:38:56.294Z",
          "wordCount": 640,
          "title": "Actionable Models: Unsupervised Offline Reinforcement Learning of Robotic Skills. (arXiv:2104.07749v3 [cs.RO] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06150",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1\">Jialin Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_D/0/1/0/all/0/1\">Da Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Lin F. Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karypis_G/0/1/0/all/0/1\">Geroge Karypis</a>",
          "description": "Graph neural networks (GNNs) are powerful tools for learning from graph data\nand are widely used in various applications such as social network\nrecommendation, fraud detection, and graph search. The graphs in these\napplications are typically large, usually containing hundreds of millions of\nnodes. Training GNN models on such large graphs efficiently remains a big\nchallenge. Despite a number of sampling-based methods have been proposed to\nenable mini-batch training on large graphs, these methods have not been proved\nto work on truly industry-scale graphs, which require GPUs or mixed-CPU-GPU\ntraining. The state-of-the-art sampling-based methods are usually not optimized\nfor these real-world hardware setups, in which data movement between CPUs and\nGPUs is a bottleneck. To address this issue, we propose Global Neighborhood\nSampling that aims at training GNNs on giant graphs specifically for\nmixed-CPU-GPU training. The algorithm samples a global cache of nodes\nperiodically for all mini-batches and stores them in GPUs. This global cache\nallows in-GPU importance sampling of mini-batches, which drastically reduces\nthe number of nodes in a mini-batch, especially in the input layer, to reduce\ndata copy between CPU and GPU and mini-batch computation without compromising\nthe training convergence rate or model accuracy. We provide a highly efficient\nimplementation of this method and show that our implementation outperforms an\nefficient node-wise neighbor sampling baseline by a factor of 2X-4X on giant\ngraphs. It outperforms an efficient implementation of LADIES with small layers\nby a factor of 2X-14X while achieving much higher accuracy than LADIES.We also\ntheoretically analyze the proposed algorithm and show that with cached node\ndata of a proper size, it enjoys a comparable convergence rate as the\nunderlying node-wise sampling method.",
          "link": "http://arxiv.org/abs/2106.06150",
          "publishedOn": "2021-06-14T01:38:56.287Z",
          "wordCount": 720,
          "title": "Global Neighbor Sampling for Mixed CPU-GPU Training on Giant Graphs. (arXiv:2106.06150v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2103.11888",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ali_A/0/1/0/all/0/1\">Ameen Ali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galanti_T/0/1/0/all/0/1\">Tomer Galanti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheltonozhskiy_E/0/1/0/all/0/1\">Evgeniy Zheltonozhskiy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baskin_C/0/1/0/all/0/1\">Chaim Baskin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolf_L/0/1/0/all/0/1\">Lior Wolf</a>",
          "description": "We consider the problem of the extraction of semantic attributes, supervised\nonly with classification labels. For example, when learning to classify images\nof birds into species, we would like to observe the emergence of features that\nzoologists use to classify birds. To tackle this problem, we propose training a\nneural network with discrete features in the last layer, which is followed by\ntwo heads: a multi-layered perceptron (MLP) and a decision tree. Since decision\ntrees utilize simple binary decision stumps we expect those discrete features\nto obtain semantic meaning. We present a theoretical analysis as well as a\npractical method for learning in the intersection of two hypothesis classes.\nOur results on multiple benchmarks show an improved ability to extract a set of\nfeatures that are highly correlated with the set of unseen attributes.",
          "link": "http://arxiv.org/abs/2103.11888",
          "publishedOn": "2021-06-14T01:38:56.278Z",
          "wordCount": 583,
          "title": "Weakly Supervised Recovery of Semantic Attributes. (arXiv:2103.11888v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.10834",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Levine_A/0/1/0/all/0/1\">Alexander Levine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feizi_S/0/1/0/all/0/1\">Soheil Feizi</a>",
          "description": "Randomized smoothing is a general technique for computing sample-dependent\nrobustness guarantees against adversarial attacks for deep classifiers. Prior\nworks on randomized smoothing against L_1 adversarial attacks use additive\nsmoothing noise and provide probabilistic robustness guarantees. In this work,\nwe propose a non-additive and deterministic smoothing method, Deterministic\nSmoothing with Splitting Noise (DSSN). To develop DSSN, we first develop SSN, a\nrandomized method which involves generating each noisy smoothing sample by\nfirst randomly splitting the input space and then returning a representation of\nthe center of the subdivision occupied by the input sample. In contrast to\nuniform additive smoothing, the SSN certification does not require the random\nnoise components used to be independent. Thus, smoothing can be done\neffectively in just one dimension and can therefore be efficiently derandomized\nfor quantized data (e.g., images). To the best of our knowledge, this is the\nfirst work to provide deterministic \"randomized smoothing\" for a norm-based\nadversarial threat model while allowing for an arbitrary classifier (i.e., a\ndeep model) to be used as a base classifier and without requiring an\nexponential number of smoothing samples. On CIFAR-10 and ImageNet datasets, we\nprovide substantially larger L_1 robustness certificates compared to prior\nworks, establishing a new state-of-the-art. The determinism of our method also\nleads to significantly faster certificate computation. Code is available at:\nhttps://github.com/alevine0/smoothingSplittingNoise",
          "link": "http://arxiv.org/abs/2103.10834",
          "publishedOn": "2021-06-14T01:38:56.270Z",
          "wordCount": 670,
          "title": "Improved, Deterministic Smoothing for L_1 Certified Robustness. (arXiv:2103.10834v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14742",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Linzner_D/0/1/0/all/0/1\">Dominik Linzner</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Koeppl_H/0/1/0/all/0/1\">Heinz Koeppl</a>",
          "description": "We consider the problem of learning structures and parameters of\nContinuous-time Bayesian Networks (CTBNs) from time-course data under minimal\nexperimental resources. In practice, the cost of generating experimental data\nposes a bottleneck, especially in the natural and social sciences. A popular\napproach to overcome this is Bayesian optimal experimental design (BOED).\nHowever, BOED becomes infeasible in high-dimensional settings, as it involves\nintegration over all possible experimental outcomes. We propose a novel\ncriterion for experimental design based on a variational approximation of the\nexpected information gain. We show that for CTBNs, a semi-analytical expression\nfor this criterion can be calculated for structure and parameter learning. By\ndoing so, we can replace sampling over experimental outcomes by solving the\nCTBNs master-equation, for which scalable approximations exist. This alleviates\nthe computational burden of sampling possible experimental outcomes in\nhigh-dimensions. We employ this framework in order to recommend interventional\nsequences. In this context, we extend the CTBN model to conditional CTBNs in\norder to incorporate interventions. We demonstrate the performance of our\ncriterion on synthetic and real-world data.",
          "link": "http://arxiv.org/abs/2105.14742",
          "publishedOn": "2021-06-14T01:38:56.248Z",
          "wordCount": 619,
          "title": "Active Learning of Continuous-time Bayesian Networks through Interventions. (arXiv:2105.14742v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06519",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ganesan_K/0/1/0/all/0/1\">Karthik Ganesan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bamdev_P/0/1/0/all/0/1\">Pakhi Bamdev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+B_J/0/1/0/all/0/1\">Jaivarsan B</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venugopal_A/0/1/0/all/0/1\">Amresh Venugopal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tushar_A/0/1/0/all/0/1\">Abhinav Tushar</a>",
          "description": "Spoken Language Understanding (SLU) systems parse speech into semantic\nstructures like dialog acts and slots. This involves the use of an Automatic\nSpeech Recognizer (ASR) to transcribe speech into multiple text alternatives\n(hypotheses). Transcription errors, common in ASRs, impact downstream SLU\nperformance negatively. Approaches to mitigate such errors involve using richer\ninformation from the ASR, either in form of N-best hypotheses or word-lattices.\nWe hypothesize that transformer models learn better with a simpler utterance\nrepresentation using the concatenation of the N-best ASR alternatives, where\neach alternative is separated by a special delimiter [SEP]. In our work, we\ntest our hypothesis by using concatenated N-best ASR alternatives as the input\nto transformer encoder models, namely BERT and XLM-RoBERTa, and achieve\nperformance equivalent to the prior state-of-the-art model on DSTC2 dataset. We\nalso show that our approach significantly outperforms the prior\nstate-of-the-art when subjected to the low data regime. Additionally, this\nmethodology is accessible to users of third-party ASR APIs which do not provide\nword-lattice information.",
          "link": "http://arxiv.org/abs/2106.06519",
          "publishedOn": "2021-06-14T01:38:56.241Z",
          "wordCount": 623,
          "title": "N-Best ASR Transformer: Enhancing SLU Performance using Multiple ASR Hypotheses. (arXiv:2106.06519v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06526",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1\">Shiji Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Han Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shanghang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lianzhe Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_H/0/1/0/all/0/1\">Heng Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">Wenwu Zhu</a>",
          "description": "Models trained with offline data often suffer from continual distribution\nshifts and expensive labeling in changing environments. This calls for a new\nonline learning paradigm where the learner can continually adapt to changing\nenvironments with limited labels. In this paper, we propose a new online\nsetting -- Online Active Continual Adaptation, where the learner aims to\ncontinually adapt to changing distributions using both unlabeled samples and\nactive queries of limited labels. To this end, we propose Online Self-Adaptive\nMirror Descent (OSAMD), which adopts an online teacher-student structure to\nenable online self-training from unlabeled data, and a margin-based criterion\nthat decides whether to query the labels to track changing distributions.\nTheoretically, we show that, in the separable case, OSAMD has an $O({T}^{1/2})$\ndynamic regret bound under mild assumptions, which is even tighter than the\nlower bound $\\Omega(T^{2/3})$ of traditional online learning with full labels.\nIn the general case, we show a regret bound of $O({\\alpha^*}^{1/3} {T}^{2/3} +\n\\alpha^* T)$, where $\\alpha^*$ denotes the separability of domains and is\nusually small. Our theoretical results show that OSAMD can fast adapt to\nchanging environments with active queries. Empirically, we demonstrate that\nOSAMD achieves favorable regrets under changing environments with limited\nlabels on both simulated and real-world data, which corroborates our\ntheoretical findings.",
          "link": "http://arxiv.org/abs/2106.06526",
          "publishedOn": "2021-06-14T01:38:56.234Z",
          "wordCount": 644,
          "title": "Online Continual Adaptation with Active Self-Training. (arXiv:2106.06526v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.05596",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qi_Z/0/1/0/all/0/1\">Zhiyuan Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Ziheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiaoyan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_Y/0/1/0/all/0/1\">Yuejia Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yefeng Zheng</a>",
          "description": "Knowledge Graph (KG) alignment is to discover the mappings (i.e., equivalent\nentities, relations, and others) between two KGs. The existing methods can be\ndivided into the embedding-based models, and the conventional reasoning and\nlexical matching based systems. The former compute the similarity of entities\nvia their cross-KG embeddings, but they usually rely on an ideal supervised\nlearning setting for good performance and lack appropriate reasoning to avoid\nlogically wrong mappings; while the latter address the reasoning issue but are\npoor at utilizing the KG graph structures and the entity contexts. In this\nstudy, we aim at combining the above two solutions and thus propose an\niterative framework named PRASE which is based on probabilistic reasoning and\nsemantic embedding. It learns the KG embeddings via entity mappings from a\nprobabilistic reasoning system named PARIS, and feeds the resultant entity\nmappings and embeddings back into PARIS for augmentation. The PRASE framework\nis compatible with different embedding-based models, and our experiments on\nmultiple datasets have demonstrated its state-of-the-art performance.",
          "link": "http://arxiv.org/abs/2105.05596",
          "publishedOn": "2021-06-14T01:38:56.227Z",
          "wordCount": 653,
          "title": "Unsupervised Knowledge Graph Alignment by Probabilistic Reasoning and Semantic Embedding. (arXiv:2105.05596v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06115",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yoon_J/0/1/0/all/0/1\">Jinsung Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sohn_K/0/1/0/all/0/1\">Kihyuk Sohn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chun-Liang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arik_S/0/1/0/all/0/1\">Sercan O. Arik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1\">Chen-Yu Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfister_T/0/1/0/all/0/1\">Tomas Pfister</a>",
          "description": "Anomaly detection (AD), separating anomalies from normal data, has various\napplications across domains, from manufacturing to healthcare. While most\nprevious works have shown to be effective for cases with fully or partially\nlabeled data, they are less practical for AD applications due to tedious data\nlabeling processes. In this work, we focus on unsupervised AD problems whose\nentire training data are unlabeled and may contain both normal and anomalous\nsamples. To tackle this problem, we build a robust one-class classification\nframework via data refinement. To refine the data accurately, we propose an\nensemble of one-class classifiers, each of which is trained on a disjoint\nsubset of training data. Moreover, we propose a self-training of deep\nrepresentation one-class classifiers (STOC) that iteratively refines the data\nand deep representations. In experiments, we show the efficacy of our method\nfor unsupervised anomaly detection on benchmarks from image and tabular data\ndomains. For example, with a 10% anomaly ratio on CIFAR-10 data, the proposed\nmethod outperforms state-of-the-art one-class classification method by 6.3 AUC\nand 12.5 average precision.",
          "link": "http://arxiv.org/abs/2106.06115",
          "publishedOn": "2021-06-14T01:38:56.220Z",
          "wordCount": 599,
          "title": "Self-Trained One-class Classification for Unsupervised Anomaly Detection. (arXiv:2106.06115v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06171",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Phuc_L/0/1/0/all/0/1\">Luu Huu Phuc</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takeuchi_K/0/1/0/all/0/1\">Koh Takeuchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Okajima_S/0/1/0/all/0/1\">Seiji Okajima</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tolmachev_A/0/1/0/all/0/1\">Arseny Tolmachev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takebayashi_T/0/1/0/all/0/1\">Tomoyoshi Takebayashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maruhashi_K/0/1/0/all/0/1\">Koji Maruhashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kashima_H/0/1/0/all/0/1\">Hisashi Kashima</a>",
          "description": "Multi-relational graph is a ubiquitous and important data structure, allowing\nflexible representation of multiple types of interactions and relations between\nentities. Similar to other graph-structured data, link prediction is one of the\nmost important tasks on multi-relational graphs and is often used for knowledge\ncompletion. When related graphs coexist, it is of great benefit to build a\nlarger graph via integrating the smaller ones. The integration requires\npredicting hidden relational connections between entities belonged to different\ngraphs (inter-domain link prediction). However, this poses a real challenge to\nexisting methods that are exclusively designed for link prediction between\nentities of the same graph only (intra-domain link prediction). In this study,\nwe propose a new approach to tackle the inter-domain link prediction problem by\nsoftly aligning the entity distributions between different domains with optimal\ntransport and maximum mean discrepancy regularizers. Experiments on real-world\ndatasets show that optimal transport regularizer is beneficial and considerably\nimproves the performance of baseline methods.",
          "link": "http://arxiv.org/abs/2106.06171",
          "publishedOn": "2021-06-14T01:38:56.202Z",
          "wordCount": 587,
          "title": "Inter-domain Multi-relational Link Prediction. (arXiv:2106.06171v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06279",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kozuno_T/0/1/0/all/0/1\">Tadashi Kozuno</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Menard_P/0/1/0/all/0/1\">Pierre M&#xe9;nard</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Munos_R/0/1/0/all/0/1\">R&#xe9;mi Munos</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Valko_M/0/1/0/all/0/1\">Michal Valko</a>",
          "description": "We study the problem of learning a Nash equilibrium (NE) in an imperfect\ninformation game (IIG) through self-play. Precisely, we focus on two-player,\nzero-sum, episodic, tabular IIG under the perfect-recall assumption where the\nonly feedback is realizations of the game (bandit feedback). In particular, the\ndynamic of the IIG is not known -- we can only access it by sampling or\ninteracting with a game simulator. For this learning setting, we provide the\nImplicit Exploration Online Mirror Descent (IXOMD) algorithm. It is a\nmodel-free algorithm with a high-probability bound on the convergence rate to\nthe NE of order $1/\\sqrt{T}$ where $T$ is the number of played games. Moreover,\nIXOMD is computationally efficient as it needs to perform the updates only\nalong the sampled trajectory.",
          "link": "http://arxiv.org/abs/2106.06279",
          "publishedOn": "2021-06-14T01:38:56.196Z",
          "wordCount": 563,
          "title": "Model-Free Learning for Two-Player Zero-Sum Partially Observable Markov Games with Perfect Recall. (arXiv:2106.06279v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02078",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sridhar_K/0/1/0/all/0/1\">Kaustubh Sridhar</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sokolsky_O/0/1/0/all/0/1\">Oleg Sokolsky</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lee_I/0/1/0/all/0/1\">Insup Lee</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Weimer_J/0/1/0/all/0/1\">James Weimer</a>",
          "description": "Improving adversarial robustness of neural networks remains a major\nchallenge. Fundamentally, training a network is a parameter estimation problem.\nIn adaptive control theory, maintaining persistency of excitation (PoE) is\nintegral to ensuring convergence of parameter estimates in dynamical systems to\ntheir robust optima. In this work, we show that network training using gradient\ndescent is equivalent to a dynamical system parameter estimation problem.\nLeveraging this relationship, we prove a sufficient condition for PoE of\ngradient descent is achieved when the learning rate is less than the inverse of\nthe Lipschitz constant of the gradient of loss function. We provide an\nefficient technique for estimating the corresponding Lipschitz constant using\nextreme value theory and demonstrate that by only scaling the learning rate\nschedule we can increase adversarial accuracy by up to 15% points on benchmark\ndatasets. Our approach also universally increases the adversarial accuracy by\n0.1% to 0.3% points in various state-of-the-art adversarially trained models on\nthe AutoAttack benchmark, where every small margin of improvement is\nsignificant.",
          "link": "http://arxiv.org/abs/2106.02078",
          "publishedOn": "2021-06-14T01:38:56.189Z",
          "wordCount": 630,
          "title": "Robust Learning via Persistency of Excitation. (arXiv:2106.02078v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.00651",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zavatone_Veth_J/0/1/0/all/0/1\">Jacob A. Zavatone-Veth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Canatar_A/0/1/0/all/0/1\">Abdulkadir Canatar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pehlevan_C/0/1/0/all/0/1\">Cengiz Pehlevan</a>",
          "description": "Recent works have suggested that finite Bayesian neural networks may\noutperform their infinite cousins because finite networks can flexibly adapt\ntheir internal representations. However, our theoretical understanding of how\nthe learned hidden layer representations of finite networks differ from the\nfixed representations of infinite networks remains incomplete. Perturbative\nfinite-width corrections to the network prior and posterior have been studied,\nbut the asymptotics of learned features have not been fully characterized.\nHere, we argue that the leading finite-width corrections to the average feature\nkernels for any Bayesian network with linear readout and quadratic cost have a\nlargely universal form. We illustrate this explicitly for two classes of fully\nconnected networks: deep linear networks and networks with a single nonlinear\nhidden layer. Our results begin to elucidate which features of data wide\nBayesian neural networks learn to represent.",
          "link": "http://arxiv.org/abs/2106.00651",
          "publishedOn": "2021-06-14T01:38:56.183Z",
          "wordCount": 603,
          "title": "Asymptotics of representation learning in finite Bayesian neural networks. (arXiv:2106.00651v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02522",
          "author": "<a href=\"http://arxiv.org/find/q-fin/1/au:+Wu_J/0/1/0/all/0/1\">Junran Wu</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Xu_K/0/1/0/all/0/1\">Ke Xu</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Chen_X/0/1/0/all/0/1\">Xueyuan Chen</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Li_S/0/1/0/all/0/1\">Shangzhe Li</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Zhao_J/0/1/0/all/0/1\">Jichang Zhao</a>",
          "description": "Stock prediction, with the purpose of forecasting the future price trends of\nstocks, is crucial for maximizing profits from stock investments. While great\nresearch efforts have been devoted to exploiting deep neural networks for\nimproved stock prediction, two major issues still exist in recent studies.\nFirst, the capture of long-range dependencies in time series is not\nsufficiently addressed. Second, the chaotic property of financial time series\nfundamentally lowers prediction performance. In this study, we propose a novel\nframework to address both issues regarding stock prediction. Specifically, in\nterms of transforming time series into complex networks, we convert market\nprice series into graphs. Then, structural information, referring to\nassociations among temporal points and the node weights, is extracted from the\nmapped graphs to resolve the problems regarding long-range dependencies and the\nchaotic property. We take graph embeddings to represent the associations among\ntemporal points as the prediction model inputs. Node weights are used as a\npriori knowledge to enhance the learning of temporal attention. The\neffectiveness of our proposed framework is validated using real-world stock\ndata, and our approach obtains the best performance among several\nstate-of-the-art benchmarks. Moreover, in the conducted trading simulations,\nour framework further obtains the highest cumulative profits. Our results\nsupplement the existing applications of complex network methods in the\nfinancial realm and provide insightful implications for investment applications\nregarding decision support in financial markets.",
          "link": "http://arxiv.org/abs/2106.02522",
          "publishedOn": "2021-06-14T01:38:56.176Z",
          "wordCount": 690,
          "title": "Price graphs: Utilizing the structural information of financial time series for stock prediction. (arXiv:2106.02522v2 [q-fin.ST] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10446",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chan_K/0/1/0/all/0/1\">Kwan Ho Ryan Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yaodong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1\">Chong You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_H/0/1/0/all/0/1\">Haozhi Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wright_J/0/1/0/all/0/1\">John Wright</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yi Ma</a>",
          "description": "This work attempts to provide a plausible theoretical framework that aims to\ninterpret modern deep (convolutional) networks from the principles of data\ncompression and discriminative representation. We argue that for\nhigh-dimensional multi-class data, the optimal linear discriminative\nrepresentation maximizes the coding rate difference between the whole dataset\nand the average of all the subsets. We show that the basic iterative gradient\nascent scheme for optimizing the rate reduction objective naturally leads to a\nmulti-layer deep network, named ReduNet, which shares common characteristics of\nmodern deep networks. The deep layered architectures, linear and nonlinear\noperators, and even parameters of the network are all explicitly constructed\nlayer-by-layer via forward propagation, although they are amenable to\nfine-tuning via back propagation. All components of so-obtained ``white-box''\nnetwork have precise optimization, statistical, and geometric interpretation.\nMoreover, all linear operators of the so-derived network naturally become\nmulti-channel convolutions when we enforce classification to be rigorously\nshift-invariant. The derivation in the invariant setting suggests a trade-off\nbetween sparsity and invariance, and also indicates that such a deep\nconvolution network is significantly more efficient to construct and learn in\nthe spectral domain. Our preliminary simulations and experiments clearly verify\nthe effectiveness of both the rate reduction objective and the associated\nReduNet. All code and data are available at https://github.com/Ma-Lab-Berkeley.",
          "link": "http://arxiv.org/abs/2105.10446",
          "publishedOn": "2021-06-14T01:38:56.157Z",
          "wordCount": 723,
          "title": "ReduNet: A White-box Deep Network from the Principle of Maximizing Rate Reduction. (arXiv:2105.10446v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06418",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jansson_Y/0/1/0/all/0/1\">Ylva Jansson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lindeberg_T/0/1/0/all/0/1\">Tony Lindeberg</a>",
          "description": "The ability to handle large scale variations is crucial for many real world\nvisual tasks. A straightforward approach for handling scale in a deep network\nis to process an image at several scales simultaneously in a set of scale\nchannels. Scale invariance can then, in principle, be achieved by using weight\nsharing between the scale channels together with max or average pooling over\nthe outputs from the scale channels. The ability of such scale channel networks\nto generalise to scales not present in the training set over significant scale\nranges has, however, not previously been explored.\n\nIn this paper, we present a systematic study of this methodology by\nimplementing different types of scale channel networks and evaluating their\nability to generalise to previously unseen scales. We develop a formalism for\nanalysing the covariance and invariance properties of scale channel networks,\nand explore how different design choices, unique to scaling transformations,\naffect the overall performance of scale channel networks. We first show that\ntwo previously proposed scale channel network designs do not generalise well to\nscales not present in the training set. We explain theoretically and\ndemonstrate experimentally why generalisation fails in these cases.\n\nWe then propose a new type of foveated scale channel architecture}, where the\nscale channels process increasingly larger parts of the image with decreasing\nresolution. This new type of scale channel network is shown to generalise\nextremely well, provided sufficient image resolution and the absence of\nboundary effects. Our proposed FovMax and FovAvg networks perform almost\nidentically over a scale range of 8, also when training on single scale\ntraining data, and do also give improved performance when learning from\ndatasets with large scale variations in the small sample regime.",
          "link": "http://arxiv.org/abs/2106.06418",
          "publishedOn": "2021-06-14T01:38:56.150Z",
          "wordCount": 734,
          "title": "Scale-invariant scale-channel networks: Deep networks that generalise to previously unseen scales. (arXiv:2106.06418v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06291",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Talpur_A/0/1/0/all/0/1\">Anum Talpur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurusamy_M/0/1/0/all/0/1\">Mohan Gurusamy</a>",
          "description": "The growth of 5G and edge computing has enabled the emergence of Internet of\nVehicles. It supports different types of services with different resource and\nservice requirements. However, limited resources at the edge, high mobility of\nvehicles, increasing demand, and dynamicity in service request-types have made\nservice placement a challenging task. A typical static placement solution is\nnot effective as it does not consider the traffic mobility and service\ndynamics. Handling dynamics in IoV for service placement is an important and\nchallenging problem which is the primary focus of our work in this paper. We\npropose a Deep Reinforcement Learning-based Dynamic Service Placement (DRLD-SP)\nframework with the objective of minimizing the maximum edge resource usage and\nservice delay while considering the vehicle's mobility, varying demand, and\ndynamics in the requests for different types of services. We use SUMO and\nMATLAB to carry out simulation experiments. The experimental results show that\nthe proposed DRLD-SP approach is effective and outperforms other static and\ndynamic placement approaches.",
          "link": "http://arxiv.org/abs/2106.06291",
          "publishedOn": "2021-06-14T01:38:56.142Z",
          "wordCount": 610,
          "title": "DRLD-SP: A Deep Reinforcement Learning-based Dynamic Service Placement in Edge-Enabled Internet of Vehicles. (arXiv:2106.06291v1 [cs.NI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06295",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Irie_K/0/1/0/all/0/1\">Kazuki Irie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schlag_I/0/1/0/all/0/1\">Imanol Schlag</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Csordas_R/0/1/0/all/0/1\">R&#xf3;bert Csord&#xe1;s</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidhuber_J/0/1/0/all/0/1\">J&#xfc;rgen Schmidhuber</a>",
          "description": "Transformers with linearised attention (\"linear Transformers\") have\ndemonstrated the practical scalability and effectiveness of outer product-based\nFast Weight Programmers (FWPs) from the '90s. However, the original FWP\nformulation is more general than the one of linear Transformers: a slow neural\nnetwork (NN) continually reprograms the weights of a fast NN with arbitrary NN\narchitectures. In existing linear Transformers, both NNs are feedforward and\nconsist of a single layer. Here we explore new variations by adding recurrence\nto the slow and fast nets. We evaluate our novel recurrent FWPs (RFWPs) on two\nsynthetic algorithmic tasks (code execution and sequential ListOps),\nWikitext-103 language models, and on the Atari 2600 2D game environment. Our\nmodels exhibit properties of Transformers and RNNs. In the reinforcement\nlearning setting, we report large improvements over LSTM in several Atari\ngames. Our code is public.",
          "link": "http://arxiv.org/abs/2106.06295",
          "publishedOn": "2021-06-14T01:38:56.135Z",
          "wordCount": 562,
          "title": "Going Beyond Linear Transformers with Recurrent Fast Weight Programmers. (arXiv:2106.06295v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06426",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Greshler_G/0/1/0/all/0/1\">Gal Greshler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shaham_T/0/1/0/all/0/1\">Tamar Rott Shaham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Michaeli_T/0/1/0/all/0/1\">Tomer Michaeli</a>",
          "description": "Models for audio generation are typically trained on hours of recordings.\nHere, we illustrate that capturing the essence of an audio source is typically\npossible from as little as a few tens of seconds from a single training signal.\nSpecifically, we present a GAN-based generative model that can be trained on\none short audio signal from any domain (e.g. speech, music, etc.) and does not\nrequire pre-training or any other form of external supervision. Once trained,\nour model can generate random samples of arbitrary duration that maintain\nsemantic similarity to the training waveform, yet exhibit new compositions of\nits audio primitives. This enables a long line of interesting applications,\nincluding generating new jazz improvisations or new a-cappella rap variants\nbased on a single short example, producing coherent modifications to famous\nsongs (e.g. adding a new verse to a Beatles song based solely on the original\nrecording), filling-in of missing parts (inpainting), extending the bandwidth\nof a speech signal (super-resolution), and enhancing old recordings without\naccess to any clean training example. We show that in all cases, no more than\n20 seconds of training audio commonly suffice for our model to achieve\nstate-of-the-art results. This is despite its complete lack of prior knowledge\nabout the nature of audio signals in general.",
          "link": "http://arxiv.org/abs/2106.06426",
          "publishedOn": "2021-06-14T01:38:56.127Z",
          "wordCount": 647,
          "title": "Catch-A-Waveform: Learning to Generate Audio from a Single Short Example. (arXiv:2106.06426v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06196",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yonggang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_M/0/1/0/all/0/1\">Mingming Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tongliang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1\">Gang Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_X/0/1/0/all/0/1\">Xinmei Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1\">Bo Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1\">Bernhard Sch&#xf6;lkopf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kun Zhang</a>",
          "description": "The adversarial vulnerability of deep neural networks has attracted\nsignificant attention in machine learning. From a causal viewpoint, adversarial\nattacks can be considered as a specific type of distribution change on natural\ndata. As causal reasoning has an instinct for modeling distribution change, we\npropose to incorporate causality into mitigating adversarial vulnerability.\nHowever, causal formulations of the intuition of adversarial attack and the\ndevelopment of robust DNNs are still lacking in the literature. To bridge this\ngap, we construct a causal graph to model the generation process of adversarial\nexamples and define the adversarial distribution to formalize the intuition of\nadversarial attacks. From a causal perspective, we find that the label is\nspuriously correlated with the style (content-independent) information when an\ninstance is given. The spurious correlation implies that the adversarial\ndistribution is constructed via making the statistical conditional association\nbetween style information and labels drastically different from that in natural\ndistribution. Thus, DNNs that fit the spurious correlation are vulnerable to\nthe adversarial distribution. Inspired by the observation, we propose the\nadversarial distribution alignment method to eliminate the difference between\nthe natural distribution and the adversarial distribution. Extensive\nexperiments demonstrate the efficacy of the proposed method. Our method can be\nseen as the first attempt to leverage causality for mitigating adversarial\nvulnerability.",
          "link": "http://arxiv.org/abs/2106.06196",
          "publishedOn": "2021-06-14T01:38:56.111Z",
          "wordCount": 643,
          "title": "Adversarial Robustness through the Lens of Causality. (arXiv:2106.06196v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2006.16495",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wang_X/0/1/0/all/0/1\">Xiang Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yuan_S/0/1/0/all/0/1\">Shuai Yuan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wu_C/0/1/0/all/0/1\">Chenwei Wu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ge_R/0/1/0/all/0/1\">Rong Ge</a>",
          "description": "Choosing the right parameters for optimization algorithms is often the key to\ntheir success in practice. Solving this problem using a learning-to-learn\napproach -- using meta-gradient descent on a meta-objective based on the\ntrajectory that the optimizer generates -- was recently shown to be effective.\nHowever, the meta-optimization problem is difficult. In particular, the\nmeta-gradient can often explode/vanish, and the learned optimizer may not have\ngood generalization performance if the meta-objective is not chosen carefully.\nIn this paper we give meta-optimization guarantees for the learning-to-learn\napproach on a simple problem of tuning the step size for quadratic loss. Our\nresults show that the na\\\"ive objective suffers from meta-gradient\nexplosion/vanishing problem. Although there is a way to design the\nmeta-objective so that the meta-gradient remains polynomially bounded,\ncomputing the meta-gradient directly using backpropagation leads to numerical\nissues. We also characterize when it is necessary to compute the meta-objective\non a separate validation set to ensure the generalization performance of the\nlearned optimizer. Finally, we verify our results empirically and show that a\nsimilar phenomenon appears even for more complicated learned optimizers\nparametrized by neural networks.",
          "link": "http://arxiv.org/abs/2006.16495",
          "publishedOn": "2021-06-14T01:38:56.104Z",
          "wordCount": 640,
          "title": "Guarantees for Tuning the Step Size using a Learning-to-Learn Approach. (arXiv:2006.16495v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.03788",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Guan-Horng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tianrong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Theodorou_E/0/1/0/all/0/1\">Evangelos A. Theodorou</a>",
          "description": "The connection between training deep neural networks (DNNs) and optimal\ncontrol theory (OCT) has attracted considerable attention as a principled tool\nof algorithmic design. Despite few attempts being made, they have been limited\nto architectures where the layer propagation resembles a Markovian dynamical\nsystem. This casts doubts on their flexibility to modern networks that heavily\nrely on non-Markovian dependencies between layers (e.g. skip connections in\nresidual networks). In this work, we propose a novel dynamic game perspective\nby viewing each layer as a player in a dynamic game characterized by the DNN\nitself. Through this lens, different classes of optimizers can be seen as\nmatching different types of Nash equilibria, depending on the implicit\ninformation structure of each (p)layer. The resulting method, called Dynamic\nGame Theoretic Neural Optimizer (DGNOpt), not only generalizes OCT-inspired\noptimizers to richer network class; it also motivates a new training principle\nby solving a multi-player cooperative game. DGNOpt shows convergence\nimprovements over existing methods on image classification datasets with\nresidual and inception networks. Our work marries strengths from both OCT and\ngame theory, paving ways to new algorithmic opportunities from robust optimal\ncontrol and bandit-based optimization.",
          "link": "http://arxiv.org/abs/2105.03788",
          "publishedOn": "2021-06-14T01:38:56.097Z",
          "wordCount": 660,
          "title": "Dynamic Game Theoretic Neural Optimizer. (arXiv:2105.03788v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06243",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kandanaarachchi_S/0/1/0/all/0/1\">Sevvandi Kandanaarachchi</a>",
          "description": "Constructing an ensemble from a heterogeneous set of unsupervised anomaly\ndetection methods is challenging because the class labels or the ground truth\nis unknown. Thus, traditional ensemble techniques that use the response\nvariable or the class labels cannot be used to construct an ensemble for\nunsupervised anomaly detection.\n\nWe use Item Response Theory (IRT) -- a class of models used in educational\npsychometrics to assess student and test question characteristics -- to\nconstruct an unsupervised anomaly detection ensemble. IRT's latent trait\ncomputation lends itself to anomaly detection because the latent trait can be\nused to uncover the hidden ground truth. Using a novel IRT mapping to the\nanomaly detection problem, we construct an ensemble that can downplay noisy,\nnon-discriminatory methods and accentuate sharper methods. We demonstrate the\neffectiveness of the IRT ensemble on an extensive data repository, by comparing\nits performance to other ensemble techniques.",
          "link": "http://arxiv.org/abs/2106.06243",
          "publishedOn": "2021-06-14T01:38:56.090Z",
          "wordCount": 573,
          "title": "Unsupervised Anomaly Detection Ensembles using Item Response Theory. (arXiv:2106.06243v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06152",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lv_J/0/1/0/all/0/1\">Jiaqi Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_L/0/1/0/all/0/1\">Lei Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1\">Miao Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+An_B/0/1/0/all/0/1\">Bo An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1\">Gang Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_X/0/1/0/all/0/1\">Xin Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masashi Sugiyama</a>",
          "description": "Partial-label (PL) learning is a typical weakly supervised classification\nproblem, where a PL of an instance is a set of candidate labels such that a\nfixed but unknown candidate is the true label. For PL learning, there are two\nlines of research: (a) the identification-based strategy (IBS) purifies each\nlabel set and extracts the true label; (b) the average-based strategy (ABS)\ntreats all candidates equally for training. In the past two decades, IBS was a\nmuch hotter topic than ABS, since it was believed that IBS is more promising.\nIn this paper, we theoretically analyze ABS and find it also promising in the\nsense of the robustness of its loss functions. Specifically, we consider five\nproblem settings for the generation of clean or noisy PLs, and we prove that\naverage PL losses with bounded multi-class losses are always robust under mild\nassumptions on the domination of true labels, while average PL losses with\nunbounded multi-class losses (e.g., the cross-entropy loss) may not be robust.\nWe also conduct experiments to validate our theoretical findings. Note that IBS\nis heuristic, and we cannot prove its robustness by a similar proof technique;\nhence, ABS is more advantageous from a theoretical point of view, and it is\nworth paying attention to the design of more advanced PL learning methods\nfollowing ABS.",
          "link": "http://arxiv.org/abs/2106.06152",
          "publishedOn": "2021-06-14T01:38:56.083Z",
          "wordCount": 649,
          "title": "On the Robustness of Average Losses for Partial-Label Learning. (arXiv:2106.06152v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03743",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Labatie_A/0/1/0/all/0/1\">Antoine Labatie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Masters_D/0/1/0/all/0/1\">Dominic Masters</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eaton_Rosen_Z/0/1/0/all/0/1\">Zach Eaton-Rosen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luschi_C/0/1/0/all/0/1\">Carlo Luschi</a>",
          "description": "We investigate the reasons for the performance degradation incurred with\nbatch-independent normalization. We find that the prototypical techniques of\nlayer normalization and instance normalization both induce the appearance of\nfailure modes in the neural network's pre-activations: (i) layer normalization\ninduces a collapse towards channel-wise constant functions; (ii) instance\nnormalization induces a lack of variability in instance statistics, symptomatic\nof an alteration of the expressivity. To alleviate failure mode (i) without\naggravating failure mode (ii), we introduce the technique \"Proxy Normalization\"\nthat normalizes post-activations using a proxy distribution. When combined with\nlayer normalization or group normalization, this batch-independent\nnormalization emulates batch normalization's behavior and consistently matches\nor exceeds its performance.",
          "link": "http://arxiv.org/abs/2106.03743",
          "publishedOn": "2021-06-14T01:38:56.048Z",
          "wordCount": 553,
          "title": "Proxy-Normalizing Activations to Match Batch Normalization while Removing Batch Dependence. (arXiv:2106.03743v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.13840",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chu_X/0/1/0/all/0/1\">Xiangxiang Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Z/0/1/0/all/0/1\">Zhi Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuqing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Bo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_H/0/1/0/all/0/1\">Haibing Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1\">Xiaolin Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_H/0/1/0/all/0/1\">Huaxia Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1\">Chunhua Shen</a>",
          "description": "Very recently, a variety of vision transformer architectures for dense\nprediction tasks have been proposed and they show that the design of spatial\nattention is critical to their success in these tasks. In this work, we revisit\nthe design of the spatial attention and demonstrate that a carefully-devised\nyet simple spatial attention mechanism performs favourably against the\nstate-of-the-art schemes. As a result, we propose two vision transformer\narchitectures, namely, Twins-PCPVT and Twins-SVT. Our proposed architectures\nare highly-efficient and easy to implement, only involving matrix\nmultiplications that are highly optimized in modern deep learning frameworks.\nMore importantly, the proposed architectures achieve excellent performance on a\nwide range of visual tasks including imagelevel classification as well as dense\ndetection and segmentation. The simplicity and strong performance suggest that\nour proposed architectures may serve as stronger backbones for many vision\ntasks. Our code will be released soon at\nhttps://github.com/Meituan-AutoML/Twins .",
          "link": "http://arxiv.org/abs/2104.13840",
          "publishedOn": "2021-06-14T01:38:55.853Z",
          "wordCount": 656,
          "title": "Twins: Revisiting the Design of Spatial Attention in Vision Transformers. (arXiv:2104.13840v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.13416",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Terjek_D/0/1/0/all/0/1\">D&#xe1;vid Terj&#xe9;k</a>",
          "description": "Variational representations of $f$-divergences are central to many machine\nlearning algorithms, with Lipschitz constrained variants recently gaining\nattention. Inspired by this, we define the Moreau-Yosida approximation of\n$f$-divergences with respect to the Wasserstein-$1$ metric. The corresponding\nvariational formulas provide a generalization of a number of recent results,\nnovel special cases of interest and a relaxation of the hard Lipschitz\nconstraint. Additionally, we prove that the so-called tight variational\nrepresentation of $f$-divergences can be to be taken over the quotient space of\nLipschitz functions, and give a characterization of functions achieving the\nsupremum in the variational representation. On the practical side, we propose\nan algorithm to calculate the tight convex conjugate of $f$-divergences\ncompatible with automatic differentiation frameworks. As an application of our\nresults, we propose the Moreau-Yosida $f$-GAN, providing an implementation of\nthe variational formulas for the Kullback-Leibler, reverse Kullback-Leibler,\n$\\chi^2$, reverse $\\chi^2$, squared Hellinger, Jensen-Shannon, Jeffreys,\ntriangular discrimination and total variation divergences as GANs trained on\nCIFAR-10, leading to competitive results and a simple solution to the problem\nof uniqueness of the optimal critic.",
          "link": "http://arxiv.org/abs/2102.13416",
          "publishedOn": "2021-06-14T01:38:55.846Z",
          "wordCount": 645,
          "title": "Moreau-Yosida $f$-divergences. (arXiv:2102.13416v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09163",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_H/0/1/0/all/0/1\">Hongxiang Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferianc_M/0/1/0/all/0/1\">Martin Ferianc</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodrigues_M/0/1/0/all/0/1\">Miguel Rodrigues</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Hongyu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_X/0/1/0/all/0/1\">Xinyu Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luk_W/0/1/0/all/0/1\">Wayne Luk</a>",
          "description": "Neural networks (NNs) have demonstrated their potential in a wide range of\napplications such as image recognition, decision making or recommendation\nsystems. However, standard NNs are unable to capture their model uncertainty\nwhich is crucial for many safety-critical applications including healthcare and\nautonomous vehicles. In comparison, Bayesian neural networks (BNNs) are able to\nexpress uncertainty in their prediction via a mathematical grounding.\nNevertheless, BNNs have not been as widely used in industrial practice, mainly\nbecause of their expensive computational cost and limited hardware performance.\nThis work proposes a novel FPGA-based hardware architecture to accelerate BNNs\ninferred through Monte Carlo Dropout. Compared with other state-of-the-art BNN\naccelerators, the proposed accelerator can achieve up to 4 times higher energy\nefficiency and 9 times better compute efficiency. Considering partial Bayesian\ninference, an automatic framework is proposed, which explores the trade-off\nbetween hardware and algorithmic performance. Extensive experiments are\nconducted to demonstrate that our proposed framework can effectively find the\noptimal points in the design space.",
          "link": "http://arxiv.org/abs/2105.09163",
          "publishedOn": "2021-06-14T01:38:55.837Z",
          "wordCount": 633,
          "title": "High-Performance FPGA-based Accelerator for Bayesian Neural Networks. (arXiv:2105.09163v2 [cs.AR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.03864",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maziarz_K/0/1/0/all/0/1\">Krzysztof Maziarz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jackson_Flux_H/0/1/0/all/0/1\">Henry Jackson-Flux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cameron_P/0/1/0/all/0/1\">Pashmina Cameron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sirockin_F/0/1/0/all/0/1\">Finton Sirockin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schneider_N/0/1/0/all/0/1\">Nadine Schneider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stiefl_N/0/1/0/all/0/1\">Nikolaus Stiefl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Segler_M/0/1/0/all/0/1\">Marwin Segler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brockschmidt_M/0/1/0/all/0/1\">Marc Brockschmidt</a>",
          "description": "Recent advancements in deep learning-based modeling of molecules promise to\naccelerate in silico drug discovery. A plethora of generative models is\navailable, building molecules either atom-by-atom and bond-by-bond or\nfragment-by-fragment. However, many drug discovery projects require a fixed\nscaffold to be present in the generated molecule, and incorporating that\nconstraint has only recently been explored. In this work, we propose a new\ngraph-based model that naturally supports scaffolds as initial seed of the\ngenerative procedure, which is possible because our model is not conditioned on\nthe generation history. At the same time, our generation procedure can flexibly\nchoose between adding individual atoms and entire fragments. We show that\ntraining using a randomized generation order is necessary for good performance\nwhen extending scaffolds, and that the results are further improved by\nincreasing the fragment vocabulary size. Our model pushes the state-of-the-art\nof graph-based molecule generation, while being an order of magnitude faster to\ntrain and sample from than existing approaches.",
          "link": "http://arxiv.org/abs/2103.03864",
          "publishedOn": "2021-06-14T01:38:55.830Z",
          "wordCount": 623,
          "title": "Learning to Extend Molecular Scaffolds with Structural Motifs. (arXiv:2103.03864v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.02153",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rozemberczki_B/0/1/0/all/0/1\">Benedek Rozemberczki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarkar_R/0/1/0/all/0/1\">Rik Sarkar</a>",
          "description": "What is the value of an individual model in an ensemble of binary\nclassifiers? We answer this question by introducing a class of transferable\nutility cooperative games called \\textit{ensemble games}. In machine learning\nensembles, pre-trained models cooperate to make classification decisions. To\nquantify the importance of models in these ensemble games, we define\n\\textit{Troupe} -- an efficient algorithm which allocates payoffs based on\napproximate Shapley values of the classifiers. We argue that the Shapley value\nof models in these games is an effective decision metric for choosing a high\nperforming subset of models from the ensemble. Our analytical findings prove\nthat our Shapley value estimation scheme is precise and scalable; its\nperformance increases with size of the dataset and ensemble. Empirical results\non real world graph classification tasks demonstrate that our algorithm\nproduces high quality estimates of the Shapley value. We find that Shapley\nvalues can be utilized for ensemble pruning, and that adversarial models\nreceive a low valuation. Complex classifiers are frequently found to be\nresponsible for both correct and incorrect classification decisions.",
          "link": "http://arxiv.org/abs/2101.02153",
          "publishedOn": "2021-06-14T01:38:55.810Z",
          "wordCount": 652,
          "title": "The Shapley Value of Classifiers in Ensemble Games. (arXiv:2101.02153v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06064",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Pal_S/0/1/0/all/0/1\">Soumyasundar Pal</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ma_L/0/1/0/all/0/1\">Liheng Ma</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_Y/0/1/0/all/0/1\">Yingxue Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Coates_M/0/1/0/all/0/1\">Mark Coates</a>",
          "description": "Spatio-temporal forecasting has numerous applications in analyzing wireless,\ntraffic, and financial networks. Many classical statistical models often fall\nshort in handling the complexity and high non-linearity present in time-series\ndata. Recent advances in deep learning allow for better modelling of spatial\nand temporal dependencies. While most of these models focus on obtaining\naccurate point forecasts, they do not characterize the prediction uncertainty.\nIn this work, we consider the time-series data as a random realization from a\nnonlinear state-space model and target Bayesian inference of the hidden states\nfor probabilistic forecasting. We use particle flow as the tool for\napproximating the posterior distribution of the states, as it is shown to be\nhighly effective in complex, high-dimensional settings. Thorough\nexperimentation on several real world time-series datasets demonstrates that\nour approach provides better characterization of uncertainty while maintaining\ncomparable accuracy to the state-of-the art point forecasting methods.",
          "link": "http://arxiv.org/abs/2106.06064",
          "publishedOn": "2021-06-14T01:38:55.803Z",
          "wordCount": 575,
          "title": "RNN with Particle Flow for Probabilistic Spatio-temporal Forecasting. (arXiv:2106.06064v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2102.00678",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_N/0/1/0/all/0/1\">Nan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_S/0/1/0/all/0/1\">Shida Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1\">Gang Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sato_I/0/1/0/all/0/1\">Issei Sato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masashi Sugiyama</a>",
          "description": "To cope with high annotation costs, training a classifier only from weakly\nsupervised data has attracted a great deal of attention these days. Among\nvarious approaches, strengthening supervision from completely unsupervised\nclassification is a promising direction, which typically employs class priors\nas the only supervision and trains a binary classifier from unlabeled (U)\ndatasets. While existing risk-consistent methods are theoretically grounded\nwith high flexibility, they can learn only from two U sets. In this paper, we\npropose a new approach for binary classification from $m$ U-sets for $m\\ge2$.\nOur key idea is to consider an auxiliary classification task called surrogate\nset classification (SSC), which is aimed at predicting from which U set each\nobserved data is drawn. SSC can be solved by a standard (multi-class)\nclassification method, and we use the SSC solution to obtain the final binary\nclassifier through a certain linear-fractional transformation. We built our\nmethod in a flexible and efficient end-to-end deep learning framework and prove\nit to be classifier-consistent. Through experiments, we demonstrate the\nsuperiority of our proposed method over state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2102.00678",
          "publishedOn": "2021-06-14T01:38:55.796Z",
          "wordCount": 644,
          "title": "Binary Classification from Multiple Unlabeled Datasets via Surrogate Set Classification. (arXiv:2102.00678v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.03923",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Leung_R/0/1/0/all/0/1\">Raymond Leung</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Balamurali_M/0/1/0/all/0/1\">Mehala Balamurali</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Lowe_A/0/1/0/all/0/1\">Alexander Lowe</a>",
          "description": "This paper illustrates an application of machine learning (ML) within a\ncomplex system that performs grade estimation. In surface mining, assay\nmeasurements taken from production drilling often provide useful information\nthat allows initially inaccurate surfaces created using sparse exploration data\nto be revised and subsequently improved. Recently, a Bayesian warping technique\nhas been proposed to reshape modeled surfaces using geochemical and spatial\nconstraints imposed by newly acquired blasthole data. This paper focuses on\nincorporating machine learning into this warping framework to make the\nlikelihood computation generalizable. The technique works by adjusting the\nposition of vertices on the surface to maximize the integrity of modeled\ngeological boundaries with respect to sparse geochemical observations. Its\nfoundation is laid by a Bayesian derivation in which the geological domain\nlikelihood given the chemistry, p(g|c), plays a similar role to p(y(c)|g). This\nobservation allows a manually calibrated process centered around the latter to\nbe automated since ML techniques may be used to estimate the former in a\ndata-driven way. Machine learning performance is evaluated for gradient\nboosting, neural network, random forest and other classifiers in a binary and\nmulti-class context using precision and recall rates. Once ML likelihood\nestimators are integrated in the surface warping framework, surface shaping\nperformance is evaluated using unseen data by examining the categorical\ndistribution of test samples located above and below the warped surface.\nLarge-scale validation experiments are performed to assess the overall efficacy\nof ML assisted surface warping as a fully integrated component within an ore\ngrade estimation system where the posterior mean is obtained via Gaussian\nProcess inference with a Matern 3/2 kernel.",
          "link": "http://arxiv.org/abs/2103.03923",
          "publishedOn": "2021-06-14T01:38:55.790Z",
          "wordCount": 764,
          "title": "Surface Warping Incorporating Machine Learning Assisted Domain Likelihood Estimation: A New Paradigm in Mine Geology Modelling and Automation. (arXiv:2103.03923v2 [physics.geo-ph] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.11351",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ng_Y/0/1/0/all/0/1\">Yuting Ng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasan_A/0/1/0/all/0/1\">Ali Hasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elkhalil_K/0/1/0/all/0/1\">Khalil Elkhalil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tarokh_V/0/1/0/all/0/1\">Vahid Tarokh</a>",
          "description": "We propose a new generative modeling technique for learning multidimensional\ncumulative distribution functions (CDFs) in the form of copulas. Specifically,\nwe consider certain classes of copulas known as Archimedean and hierarchical\nArchimedean copulas, popular for their parsimonious representation and ability\nto model different tail dependencies. We consider their representation as\nmixture models with Laplace transforms of latent random variables from\ngenerative neural networks. This alternative representation allows for\ncomputational efficiencies and easy sampling, especially in high dimensions. We\ndescribe multiple methods for optimizing the network parameters. Finally, we\npresent empirical results that demonstrate the efficacy of our proposed method\nin learning multidimensional CDFs and its computational efficiency compared to\nexisting methods.",
          "link": "http://arxiv.org/abs/2102.11351",
          "publishedOn": "2021-06-14T01:38:55.782Z",
          "wordCount": 564,
          "title": "Generative Archimedean Copulas. (arXiv:2102.11351v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.02966",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Stelzer_F/0/1/0/all/0/1\">Florian Stelzer</a> (1, 2 and 3), <a href=\"http://arxiv.org/find/cs/1/au:+Yanchuk_S/0/1/0/all/0/1\">Serhiy Yanchuk</a> (1) ((1) Institute of Mathematics, Technische Universit&#xe4;t Berlin, Germany, (2) Department of Mathematics, Humboldt-Universit&#xe4;t zu Berlin, Germany, (3) Institute of Computer Science, University of Tartu, Estonia)",
          "description": "The method recently introduced in arXiv:2011.10115 realizes a deep neural\nnetwork with just a single nonlinear element and delayed feedback. It is\napplicable for the description of physically implemented neural networks. In\nthis work, we present an infinite-dimensional generalization, which allows for\na more rigorous mathematical analysis and a higher flexibility in choosing the\nweight functions. Precisely speaking, the weights are described by Lebesgue\nintegrable functions instead of step functions. We also provide a functional\nback-propagation algorithm, which enables gradient descent training of the\nweights. In addition, with a slight modification, our concept realizes\nrecurrent neural networks.",
          "link": "http://arxiv.org/abs/2101.02966",
          "publishedOn": "2021-06-14T01:38:55.776Z",
          "wordCount": 588,
          "title": "Infinite-dimensional Folded-in-time Deep Neural Networks. (arXiv:2101.02966v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.03236",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Swamy_G/0/1/0/all/0/1\">Gokul Swamy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choudhury_S/0/1/0/all/0/1\">Sanjiban Choudhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bagnell_J/0/1/0/all/0/1\">J. Andrew Bagnell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhiwei Steven Wu</a>",
          "description": "We provide a unifying view of a large family of previous imitation learning\nalgorithms through the lens of moment matching. At its core, our classification\nscheme is based on whether the learner attempts to match (1) reward or (2)\naction-value moments of the expert's behavior, with each option leading to\ndiffering algorithmic approaches. By considering adversarially chosen\ndivergences between learner and expert behavior, we are able to derive bounds\non policy performance that apply for all algorithms in each of these classes,\nthe first to our knowledge. We also introduce the notion of moment\nrecoverability, implicit in many previous analyses of imitation learning, which\nallows us to cleanly delineate how well each algorithmic family is able to\nmitigate compounding errors. We derive three novel algorithm templates (AdVIL,\nAdRIL, and DAeQuIL) with strong guarantees, simple implementation, and\ncompetitive empirical performance.",
          "link": "http://arxiv.org/abs/2103.03236",
          "publishedOn": "2021-06-14T01:38:55.757Z",
          "wordCount": 612,
          "title": "Of Moments and Matching: A Game-Theoretic Framework for Closing the Imitation Gap. (arXiv:2103.03236v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.05510",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schaub_M/0/1/0/all/0/1\">Michael T. Schaub</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yu Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seby_J/0/1/0/all/0/1\">Jean-Baptiste Seby</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roddenberry_T/0/1/0/all/0/1\">T. Mitchell Roddenberry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Segarra_S/0/1/0/all/0/1\">Santiago Segarra</a>",
          "description": "In this tutorial, we provide a didactic treatment of the emerging topic of\nsignal processing on higher-order networks. Drawing analogies from discrete and\ngraph signal processing, we introduce the building blocks for processing data\non simplicial complexes and hypergraphs, two common higher-order network\nabstractions that can incorporate polyadic relationships. We provide brief\nintroductions to simplicial complexes and hypergraphs, with a special emphasis\non the concepts needed for the processing of signals supported on these\nstructures. Specifically, we discuss Fourier analysis, signal denoising, signal\ninterpolation, node embeddings, and nonlinear processing through neural\nnetworks, using these two higher-order network models. In the context of\nsimplicial complexes, we specifically focus on signal processing using the\nHodge Laplacian matrix, a multi-relational operator that leverages the special\nstructure of simplicial complexes and generalizes desirable properties of the\nLaplacian matrix in graph signal processing. For hypergraphs, we present both\nmatrix and tensor representations, and discuss the trade-offs in adopting one\nor the other. We also highlight limitations and potential research avenues,\nboth to inform practitioners and to motivate the contribution of new\nresearchers to the area.",
          "link": "http://arxiv.org/abs/2101.05510",
          "publishedOn": "2021-06-14T01:38:55.749Z",
          "wordCount": 690,
          "title": "Signal Processing on Higher-Order Networks: Livin' on the Edge ... and Beyond. (arXiv:2101.05510v3 [cs.SI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.05918",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jia_C/0/1/0/all/0/1\">Chao Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yinfei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1\">Ye Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yi-Ting Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parekh_Z/0/1/0/all/0/1\">Zarana Parekh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pham_H/0/1/0/all/0/1\">Hieu Pham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1\">Quoc V. Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sung_Y/0/1/0/all/0/1\">Yunhsuan Sung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duerig_T/0/1/0/all/0/1\">Tom Duerig</a>",
          "description": "Pre-trained representations are becoming crucial for many NLP and perception\ntasks. While representation learning in NLP has transitioned to training on raw\ntext without human annotations, visual and vision-language representations\nstill rely heavily on curated training datasets that are expensive or require\nexpert knowledge. For vision applications, representations are mostly learned\nusing datasets with explicit class labels such as ImageNet or OpenImages. For\nvision-language, popular datasets like Conceptual Captions, MSCOCO, or CLIP all\ninvolve a non-trivial data collection (and cleaning) process. This costly\ncuration process limits the size of datasets and hence hinders the scaling of\ntrained models. In this paper, we leverage a noisy dataset of over one billion\nimage alt-text pairs, obtained without expensive filtering or post-processing\nsteps in the Conceptual Captions dataset. A simple dual-encoder architecture\nlearns to align visual and language representations of the image and text pairs\nusing a contrastive loss. We show that the scale of our corpus can make up for\nits noise and leads to state-of-the-art representations even with such a simple\nlearning scheme. Our visual representation achieves strong performance when\ntransferred to classification tasks such as ImageNet and VTAB. The aligned\nvisual and language representations enables zero-shot image classification and\nalso set new state-of-the-art results on Flickr30K and MSCOCO image-text\nretrieval benchmarks, even when compared with more sophisticated\ncross-attention models. The representations also enable cross-modality search\nwith complex text and text + image queries.",
          "link": "http://arxiv.org/abs/2102.05918",
          "publishedOn": "2021-06-14T01:38:55.742Z",
          "wordCount": 733,
          "title": "Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision. (arXiv:2102.05918v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.11203",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cai_T/0/1/0/all/0/1\">Tianle Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_R/0/1/0/all/0/1\">Ruiqi Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jason D. Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_Q/0/1/0/all/0/1\">Qi Lei</a>",
          "description": "One of the central problems in machine learning is domain adaptation. Unlike\npast theoretical work, we consider a new model for subpopulation shift in the\ninput or representation space. In this work, we propose a provably effective\nframework for domain adaptation based on label propagation. In our analysis, we\nuse a simple but realistic expansion assumption, proposed in\n\\citet{wei2021theoretical}. Using a teacher classifier trained on the source\ndomain, our algorithm not only propagates to the target domain but also\nimproves upon the teacher. By leveraging existing generalization bounds, we\nalso obtain end-to-end finite-sample guarantees on the entire algorithm. In\naddition, we extend our theoretical framework to a more general setting of\nsource-to-target transfer based on a third unlabeled dataset, which can be\neasily applied in various learning scenarios. Inspired by our theory, we adapt\nconsistency-based semi-supervised learning methods to domain adaptation\nsettings and gain significant improvements.",
          "link": "http://arxiv.org/abs/2102.11203",
          "publishedOn": "2021-06-14T01:38:55.735Z",
          "wordCount": 615,
          "title": "A Theory of Label Propagation for Subpopulation Shift. (arXiv:2102.11203v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.10707",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Cai_H/0/1/0/all/0/1\">HanQin Cai</a>, <a href=\"http://arxiv.org/find/math/1/au:+Lou_Y/0/1/0/all/0/1\">Yuchen Lou</a>, <a href=\"http://arxiv.org/find/math/1/au:+McKenzie_D/0/1/0/all/0/1\">Daniel McKenzie</a>, <a href=\"http://arxiv.org/find/math/1/au:+Yin_W/0/1/0/all/0/1\">Wotao Yin</a>",
          "description": "We consider the zeroth-order optimization problem in the huge-scale setting,\nwhere the dimension of the problem is so large that performing even basic\nvector operations on the decision variables is infeasible. In this paper, we\npropose a novel algorithm, coined ZO-BCD, that exhibits favorable overall query\ncomplexity and has a much smaller per-iteration computational complexity. In\naddition, we discuss how the memory footprint of ZO-BCD can be reduced even\nfurther by the clever use of circulant measurement matrices. As an application\nof our new method, we propose the idea of crafting adversarial attacks on\nneural network based classifiers in a wavelet domain, which can result in\nproblem dimensions of over 1.7 million. In particular, we show that crafting\nadversarial examples to audio classifiers in a wavelet domain can achieve the\nstate-of-the-art attack success rate of 97.9%.",
          "link": "http://arxiv.org/abs/2102.10707",
          "publishedOn": "2021-06-14T01:38:55.721Z",
          "wordCount": 601,
          "title": "A Zeroth-Order Block Coordinate Descent Algorithm for Huge-Scale Black-Box Optimization. (arXiv:2102.10707v2 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.11376",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wilmot_C/0/1/0/all/0/1\">Charles Wilmot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Triesch_J/0/1/0/all/0/1\">Jochen Triesch</a>",
          "description": "A key competence for open-ended learning is the formation of increasingly\nabstract representations useful for driving complex behavior. Abstract\nrepresentations ignore specific details and facilitate generalization. Here we\nconsider the learning of abstract representations in a multi-modal setting with\ntwo or more input modalities. We treat the problem as a lossy compression\nproblem and show that generic lossy compression of multimodal sensory input\nnaturally extracts abstract representations that tend to strip away modalitiy\nspecific details and preferentially retain information that is shared across\nthe different modalities. Furthermore, we propose an architecture to learn\nabstract representations by identifying and retaining only the information that\nis shared across multiple modalities while discarding any modality specific\ninformation.",
          "link": "http://arxiv.org/abs/2101.11376",
          "publishedOn": "2021-06-14T01:38:55.714Z",
          "wordCount": 568,
          "title": "Learning Abstract Representations through Lossy Compression of Multi-Modal Signals. (arXiv:2101.11376v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.14203",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Watanabe_C/0/1/0/all/0/1\">Chihiro Watanabe</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Suzuki_T/0/1/0/all/0/1\">Taiji Suzuki</a>",
          "description": "Matrix reordering is a task to permute the rows and columns of a given\nobserved matrix such that the resulting reordered matrix shows meaningful or\ninterpretable structural patterns. Most existing matrix reordering techniques\nshare the common processes of extracting some feature representations from an\nobserved matrix in a predefined manner, and applying matrix reordering based on\nit. However, in some practical cases, we do not always have prior knowledge\nabout the structural pattern of an observed matrix. To address this problem, we\npropose a new matrix reordering method, called deep two-way matrix reordering\n(DeepTMR), using a neural network model. The trained network can automatically\nextract nonlinear row/column features from an observed matrix, which can then\nbe used for matrix reordering. Moreover, the proposed DeepTMR provides the\ndenoised mean matrix of a given observed matrix as an output of the trained\nnetwork. This denoised mean matrix can be used to visualize the global\nstructure of the reordered observed matrix. We demonstrate the effectiveness of\nthe proposed DeepTMR by applying it to both synthetic and practical datasets.",
          "link": "http://arxiv.org/abs/2103.14203",
          "publishedOn": "2021-06-14T01:38:55.708Z",
          "wordCount": 634,
          "title": "Deep Two-Way Matrix Reordering for Relational Data Analysis. (arXiv:2103.14203v4 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.05363",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Bohang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_T/0/1/0/all/0/1\">Tianle Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1\">Zhou Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1\">Di He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Liwei Wang</a>",
          "description": "It is well-known that standard neural networks, even with a high\nclassification accuracy, are vulnerable to small $\\ell_\\infty$-norm bounded\nadversarial perturbations. Although many attempts have been made, most previous\nworks either can only provide empirical verification of the defense to a\nparticular attack method, or can only develop a certified guarantee of the\nmodel robustness in limited scenarios. In this paper, we seek for a new\napproach to develop a theoretically principled neural network that inherently\nresists $\\ell_\\infty$ perturbations. In particular, we design a novel neuron\nthat uses $\\ell_\\infty$-distance as its basic operation (which we call\n$\\ell_\\infty$-dist neuron), and show that any neural network constructed with\n$\\ell_\\infty$-dist neurons (called $\\ell_{\\infty}$-dist net) is naturally a\n1-Lipschitz function with respect to $\\ell_\\infty$-norm. This directly provides\na rigorous guarantee of the certified robustness based on the margin of\nprediction outputs. We then prove that such networks have enough expressive\npower to approximate any 1-Lipschitz function with robust generalization\nguarantee. We further provide a holistic training strategy that can greatly\nalleviate optimization difficulties. Experimental results show that using\n$\\ell_{\\infty}$-dist nets as basic building blocks, we consistently achieve\nstate-of-the-art performance on commonly used datasets: 93.09% certified\naccuracy on MNIST ($\\epsilon=0.3$), 35.42% on CIFAR-10 ($\\epsilon=8/255$) and\n16.31% on TinyImageNet ($\\epsilon=1/255$).",
          "link": "http://arxiv.org/abs/2102.05363",
          "publishedOn": "2021-06-14T01:38:55.702Z",
          "wordCount": 696,
          "title": "Towards Certifying L-infinity Robustness using Neural Networks with L-inf-dist Neurons. (arXiv:2102.05363v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.07437",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dong_C/0/1/0/all/0/1\">Chengyu Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Liyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shang_J/0/1/0/all/0/1\">Jingbo Shang</a>",
          "description": "There are multiple intriguing problems hovering in adversarial training,\nincluding robustness-accuracy trade-off, robust overfitting, and robustness\noverestimation. These problems pose great challenges to both reliable\nevaluation and practical deployment. Here, we show that these problems share\none common cause -- low quality samples in the dataset. We first identify an\nintrinsic property of the data called \\emph{problematic score} and then design\ncontrolled experiments to investigate its connections with these problems.\nSpecifically, we find that when problematic data is removed, robust overfitting\nand robustness overestimation can be largely alleviated; and\nrobustness-accuracy trade-off becomes less significant. These observations not\nonly verify our intuition about data quality but also open new opportunities to\nadvance adversarial training. Interestingly, simply removing problematic data\nfrom adversarial training, while making the training set smaller, yields better\nrobustness for leading adversarial training strategies.",
          "link": "http://arxiv.org/abs/2102.07437",
          "publishedOn": "2021-06-14T01:38:55.695Z",
          "wordCount": 590,
          "title": "Data Profiling for Adversarial Training: On the Ruin of Problematic Data. (arXiv:2102.07437v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.12871",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1\">Han Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jiahui Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiaozhe Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Hang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1\">Xiaodan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhenguo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwok_J/0/1/0/all/0/1\">James T. Kwok</a>",
          "description": "Transformer-based models are popularly used in natural language processing\n(NLP). Its core component, self-attention, has aroused widespread interest. To\nunderstand the self-attention mechanism, a direct method is to visualize the\nattention map of a pre-trained model. Based on the patterns observed, a series\nof efficient Transformers with different sparse attention masks have been\nproposed. From a theoretical perspective, universal approximability of\nTransformer-based models is also recently proved. However, the above\nunderstanding and analysis of self-attention is based on a pre-trained model.\nTo rethink the importance analysis in self-attention, we study the significance\nof different positions in attention matrix during pre-training. A surprising\nresult is that diagonal elements in the attention map are the least important\ncompared with other attention positions. We provide a proof showing that these\ndiagonal elements can indeed be removed without deteriorating model\nperformance. Furthermore, we propose a Differentiable Attention Mask (DAM)\nalgorithm, which further guides the design of the SparseBERT. Extensive\nexperiments verify our interesting findings and illustrate the effect of the\nproposed algorithm.",
          "link": "http://arxiv.org/abs/2102.12871",
          "publishedOn": "2021-06-14T01:38:55.687Z",
          "wordCount": 633,
          "title": "SparseBERT: Rethinking the Importance Analysis in Self-attention. (arXiv:2102.12871v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.04002",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chi_H/0/1/0/all/0/1\">Haoang Chi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Feng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1\">Wenjing Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_L/0/1/0/all/0/1\">Long Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tongliang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1\">Bo Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1\">Gang Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1\">Mingyuan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masashi Sugiyama</a>",
          "description": "In learning to discover novel classes (L2DNC), we are given labeled data from\nseen classes and unlabeled data from unseen classes, and we train clustering\nmodels for the unseen classes. However, the rigorous definition of L2DNC is\nunexplored, which results in that its implicit assumptions are still unclear.\nIn this paper, we demystify assumptions behind L2DNC and find that high-level\nsemantic features should be shared among the seen and unseen classes. This\nnaturally motivates us to link L2DNC to meta-learning that has exactly the same\nassumption as L2DNC. Based on this finding, L2DNC is not only theoretically\nsolvable, but can also be empirically solved by meta-learning algorithms after\nslight modifications. This L2DNC methodology significantly reduces the amount\nof unlabeled data needed for training and makes it more practical, as\ndemonstrated in experiments. The use of very limited data is also justified by\nthe application scenario of L2DNC: since it is unnatural to label only\nseen-class data, L2DNC is sampling instead of labeling in causality. Therefore,\nunseen-class data should be collected on the way of collecting seen-class data,\nwhich is why they are novel and first need to be clustered.",
          "link": "http://arxiv.org/abs/2102.04002",
          "publishedOn": "2021-06-14T01:38:55.681Z",
          "wordCount": 661,
          "title": "Demystifying Assumptions in Learning to Discover Novel Classes. (arXiv:2102.04002v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.11391",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xitong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yixuan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brugnone_N/0/1/0/all/0/1\">Nathan Brugnone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perlmutter_M/0/1/0/all/0/1\">Michael Perlmutter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hirn_M/0/1/0/all/0/1\">Matthew Hirn</a>",
          "description": "The prevalence of graph-based data has spurred the rapid development of graph\nneural networks (GNNs) and related machine learning algorithms. Yet, despite\nthe many datasets naturally modeled as directed graphs, including citation,\nwebsite, and traffic networks, the vast majority of this research focuses on\nundirected graphs. In this paper, we propose MagNet, a spectral GNN for\ndirected graphs based on a complex Hermitian matrix known as the magnetic\nLaplacian. This matrix encodes undirected geometric structure in the magnitude\nof its entries and directional information in their phase. A \"charge\" parameter\nattunes spectral information to variation among directed cycles. We apply our\nnetwork to a variety of directed graph node classification and link prediction\ntasks showing that MagNet performs well on all tasks and that its performance\nexceeds all other methods on a majority of such tasks. The underlying\nprinciples of MagNet are such that it can be adapted to other spectral GNN\narchitectures.",
          "link": "http://arxiv.org/abs/2102.11391",
          "publishedOn": "2021-06-14T01:38:55.674Z",
          "wordCount": 633,
          "title": "MagNet: A Neural Network for Directed Graphs. (arXiv:2102.11391v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.02062",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yucheng Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_Y/0/1/0/all/0/1\">Youngsuk Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lifan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sa_C/0/1/0/all/0/1\">Christopher De Sa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Foster_D/0/1/0/all/0/1\">Dean Foster</a>",
          "description": "In large-scale time series forecasting, one often encounters the situation\nwhere the temporal patterns of time series, while drifting over time, differ\nfrom one another in the same dataset. In this paper, we provably show under\nsuch heterogeneity, training a forecasting model with commonly used stochastic\noptimizers (e.g. SGD) potentially suffers large variance on gradient\nestimation, and thus incurs long-time training. We show that this issue can be\nefficiently alleviated via stratification, which allows the optimizer to sample\nfrom pre-grouped time series strata. For better trading-off gradient variance\nand computation complexity, we further propose SCott (Stochastic Stratified\nControl Variate Gradient Descent), a variance reduced SGD-style optimizer that\nutilizes stratified sampling via control variate. In theory, we provide the\nconvergence guarantee of SCott on smooth non-convex objectives. Empirically, we\nevaluate SCott and other baseline optimizers on both synthetic and real-world\ntime series forecasting problems, and demonstrate SCott converges faster with\nrespect to both iterations and wall clock time.",
          "link": "http://arxiv.org/abs/2103.02062",
          "publishedOn": "2021-06-14T01:38:55.640Z",
          "wordCount": 623,
          "title": "Variance Reduced Training with Stratified Sampling for Forecasting Models. (arXiv:2103.02062v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.09855",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Wager_S/0/1/0/all/0/1\">Stefan Wager</a>, <a href=\"http://arxiv.org/find/math/1/au:+Xu_K/0/1/0/all/0/1\">Kuang Xu</a>",
          "description": "We propose a new diffusion-asymptotic analysis for sequentially randomized\nexperiments, including those that arise in solving multi-armed bandit problems.\nIn an experiment with $ n $ time steps, we let the mean reward gaps between\nactions scale to the order $1/\\sqrt{n}$ so as to preserve the difficulty of the\nlearning task as $n$ grows. In this regime, we show that the behavior of a\nclass of sequentially randomized Markov experiments converges to a diffusion\nlimit, given as the solution of a stochastic differential equation. The\ndiffusion limit thus enables us to derive refined, instance-specific\ncharacterization of the stochastic dynamics of adaptive experiments. As an\napplication of this framework, we use the diffusion limit to obtain several new\ninsights on the regret and belief evolution of Thompson sampling. We show that\na version of Thompson sampling with an asymptotically uninformative prior\nvariance achieves nearly-optimal instance-specific regret scaling when the\nreward gaps are relatively large. We also demonstrate that, in this regime, the\nposterior beliefs underlying Thompson sampling are highly unstable over time.",
          "link": "http://arxiv.org/abs/2101.09855",
          "publishedOn": "2021-06-14T01:38:55.630Z",
          "wordCount": 620,
          "title": "Diffusion Asymptotics for Sequential Experiments. (arXiv:2101.09855v3 [math.ST] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.13240",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Krishnamurthy_S/0/1/0/all/0/1\">Sanath Kumar Krishnamurthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hadad_V/0/1/0/all/0/1\">Vitor Hadad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Athey_S/0/1/0/all/0/1\">Susan Athey</a>",
          "description": "Computationally efficient contextual bandits are often based on estimating a\npredictive model of rewards given contexts and arms using past data. However,\nwhen the reward model is not well-specified, the bandit algorithm may incur\nunexpected regret, so recent work has focused on algorithms that are robust to\nmisspecification. We propose a simple family of contextual bandit algorithms\nthat adapt to misspecification error by reverting to a good safe policy when\nthere is evidence that misspecification is causing a regret increase. Our\nalgorithm requires only an offline regression oracle to ensure regret\nguarantees that gracefully degrade in terms of a measure of the average\nmisspecification level. Compared to prior work, we attain similar regret\nguarantees, but we do no rely on a master algorithm, and do not require more\nrobust oracles like online or constrained regression oracles (e.g., Foster et\nal. (2020a); Krishnamurthy et al. (2020)). This allows us to design algorithms\nfor more general function approximation classes.",
          "link": "http://arxiv.org/abs/2102.13240",
          "publishedOn": "2021-06-14T01:38:55.619Z",
          "wordCount": 621,
          "title": "Adapting to Misspecification in Contextual Bandits with Offline Regression Oracles. (arXiv:2102.13240v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.02438",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Foster_A/0/1/0/all/0/1\">Adam Foster</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ivanova_D/0/1/0/all/0/1\">Desi R. Ivanova</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Malik_I/0/1/0/all/0/1\">Ilyas Malik</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rainforth_T/0/1/0/all/0/1\">Tom Rainforth</a>",
          "description": "We introduce Deep Adaptive Design (DAD), a method for amortizing the cost of\nadaptive Bayesian experimental design that allows experiments to be run in\nreal-time. Traditional sequential Bayesian optimal experimental design\napproaches require substantial computation at each stage of the experiment.\nThis makes them unsuitable for most real-world applications, where decisions\nmust typically be made quickly. DAD addresses this restriction by learning an\namortized design network upfront and then using this to rapidly run (multiple)\nadaptive experiments at deployment time. This network represents a design\npolicy which takes as input the data from previous steps, and outputs the next\ndesign using a single forward pass; these design decisions can be made in\nmilliseconds during the live experiment. To train the network, we introduce\ncontrastive information bounds that are suitable objectives for the sequential\nsetting, and propose a customized network architecture that exploits key\nsymmetries. We demonstrate that DAD successfully amortizes the process of\nexperimental design, outperforming alternative strategies on a number of\nproblems.",
          "link": "http://arxiv.org/abs/2103.02438",
          "publishedOn": "2021-06-14T01:38:55.609Z",
          "wordCount": 625,
          "title": "Deep Adaptive Design: Amortizing Sequential Bayesian Experimental Design. (arXiv:2103.02438v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.08358",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Frongillo_R/0/1/0/all/0/1\">Rafael Frongillo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gomez_R/0/1/0/all/0/1\">Robert Gomez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thilagar_A/0/1/0/all/0/1\">Anish Thilagar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Waggoner_B/0/1/0/all/0/1\">Bo Waggoner</a>",
          "description": "Winner-take-all competitions in forecasting and machine-learning suffer from\ndistorted incentives. Witkowski et al. 2018 identified this problem and\nproposed ELF, a truthful mechanism to select a winner. We show that, from a\npool of $n$ forecasters, ELF requires $\\Theta(n\\log n)$ events or test data\npoints to select a near-optimal forecaster with high probability. We then show\nthat standard online learning algorithms select an $\\epsilon$-optimal\nforecaster using only $O(\\log(n) / \\epsilon^2)$ events, by way of a strong\napproximate-truthfulness guarantee. This bound matches the best possible even\nin the nonstrategic setting. We then apply these mechanisms to obtain the first\nno-regret guarantee for non-myopic strategic experts.",
          "link": "http://arxiv.org/abs/2102.08358",
          "publishedOn": "2021-06-14T01:38:55.592Z",
          "wordCount": 586,
          "title": "Efficient Competitions and Online Learning with Strategic Forecasters. (arXiv:2102.08358v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.02893",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Yoshida_S/0/1/0/all/0/1\">Shuhei M. Yoshida</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Takenouchi_T/0/1/0/all/0/1\">Takashi Takenouchi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masashi Sugiyama</a>",
          "description": "This paper discusses the problem of weakly supervised classification, in\nwhich instances are given weak labels that are produced by some\nlabel-corruption process. The goal is to derive conditions under which loss\nfunctions for weak-label learning are proper and lower-bounded -- two essential\nrequirements for the losses used in class-probability estimation. To this end,\nwe derive a representation theorem for proper losses in supervised learning,\nwhich dualizes the Savage representation. We use this theorem to characterize\nproper weak-label losses and find a condition for them to be lower-bounded.\nFrom these theoretical findings, we derive a novel regularization scheme called\ngeneralized logit squeezing, which makes any proper weak-label loss bounded\nfrom below, without losing properness. Furthermore, we experimentally\ndemonstrate the effectiveness of our proposed approach, as compared to improper\nor unbounded losses. The results highlight the importance of properness and\nlower-boundedness.",
          "link": "http://arxiv.org/abs/2103.02893",
          "publishedOn": "2021-06-14T01:38:55.562Z",
          "wordCount": 593,
          "title": "Lower-Bounded Proper Losses for Weakly Supervised Classification. (arXiv:2103.02893v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.01350",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Yang_X/0/1/0/all/0/1\">Xiangyu Yang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Wang_J/0/1/0/all/0/1\">Jiashan Wang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Wang_H/0/1/0/all/0/1\">Hao Wang</a>",
          "description": "This paper primarily focuses on computing the Euclidean projection of a\nvector onto the $\\ell_{p}$ ball in which $p\\in(0,1)$. Such a problem emerges as\nthe core building block in statistical machine learning and signal processing\ntasks because of its ability to promote sparsity. However, efficient numerical\nalgorithms for finding the projections are still not available, particularly in\nlarge-scale optimization. To meet this challenge, we first derive the\nfirst-order necessary optimality conditions of this problem using Fr\\'echet\nnormal cone. Based on this characterization, we develop a novel numerical\napproach for computing the stationary point through solving a sequence of\nprojections onto the reweighted $\\ell_{1}$-balls. This method is practically\nsimple to implement and computationally efficient. Moreover, the proposed\nalgorithm is shown to converge uniquely under mild conditions and has a\nworst-case $O(1/\\sqrt{k})$ convergence rate. Numerical experiments demonstrate\nthe efficiency of our proposed algorithm.",
          "link": "http://arxiv.org/abs/2101.01350",
          "publishedOn": "2021-06-14T01:38:55.555Z",
          "wordCount": 630,
          "title": "Towards an efficient approach for the nonconvex $\\ell_p$ ball projection: algorithm and analysis. (arXiv:2101.01350v3 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.09808",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Iuzzolino_M/0/1/0/all/0/1\">Michael L. Iuzzolino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mozer_M/0/1/0/all/0/1\">Michael C. Mozer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_S/0/1/0/all/0/1\">Samy Bengio</a>",
          "description": "Although deep feedforward neural networks share some characteristics with the\nprimate visual system, a key distinction is their dynamics. Deep nets typically\noperate in serial stages wherein each layer completes its computation before\nprocessing begins in subsequent layers. In contrast, biological systems have\ncascaded dynamics: information propagates from neurons at all layers in\nparallel but transmission occurs gradually over time, leading to speed-accuracy\ntrade offs even in feedforward architectures. We explore the consequences of\nbiologically inspired parallel hardware by constructing cascaded ResNets in\nwhich each residual block has propagation delays but all blocks update in\nparallel in a stateful manner. Because information transmitted through skip\nconnections avoids delays, the functional depth of the architecture increases\nover time, yielding anytime predictions that improve with internal-processing\ntime. We introduce a temporal-difference training loss that achieves a strictly\nsuperior speed-accuracy profile over standard losses and enables the cascaded\narchitecture to outperform state-of-the-art anytime-prediction methods. The\ncascaded architecture has intriguing properties, including: it classifies\ntypical instances more rapidly than atypical instances; it is more robust to\nboth persistent and transient noise than is a conventional ResNet; and its\ntime-varying output trace provides a signal that can be exploited to improve\ninformation processing and inference.",
          "link": "http://arxiv.org/abs/2102.09808",
          "publishedOn": "2021-06-14T01:38:55.548Z",
          "wordCount": 676,
          "title": "Improving Anytime Prediction with Parallel Cascaded Networks and a Temporal-Difference Loss. (arXiv:2102.09808v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.03502",
          "author": "<a href=\"http://arxiv.org/find/q-fin/1/au:+Huang_Z/0/1/0/all/0/1\">Zhenhan Huang</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Tanaka_F/0/1/0/all/0/1\">Fumihide Tanaka</a>",
          "description": "Financial portfolio management is one of the most applicable problems in\nreinforcement learning (RL) owing to its sequential decision-making nature.\nExisting RL-based approaches, while inspiring, often lack scalability,\nreusability, or profundity of intake information to accommodate the\never-changing capital markets. In this paper, we propose MSPM, a modularized\nand scalable, multi-agent RL-based system for financial portfolio management.\nMSPM involves two asynchronously updated units: an Evolving Agent Module (EAM)\nand Strategic Agent Module (SAM). A self-sustained EAM produces\nsignal-comprised information for a specific asset using heterogeneous data\ninputs, and each EAM employs its reusability to have connections to multiple\nSAMs. An SAM is responsible for asset reallocation in a portfolio using\nprofound information from the connected EAMs. With the elaborate architecture\nand the multi-step condensation of volatile market information, MSPM aims to\nprovide a customizable, stable, and dedicated solution to portfolio management,\nunlike existing approaches. We also tackle the data-shortage issue of\nnewly-listed stocks by transfer learning, and validate the indispensability of\nEAM with four different portfolios. Experiments on 8-year U.S. stock market\ndata prove the effectiveness of MSPM in profit accumulation, by its\noutperformance over existing benchmarks.",
          "link": "http://arxiv.org/abs/2102.03502",
          "publishedOn": "2021-06-14T01:38:55.539Z",
          "wordCount": 656,
          "title": "MSPM: A Modularized and Scalable Multi-Agent Reinforcement Learning-based System for Financial Portfolio Management. (arXiv:2102.03502v3 [q-fin.PM] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.00010",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sinha_K/0/1/0/all/0/1\">Koustuv Sinha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parthasarathi_P/0/1/0/all/0/1\">Prasanna Parthasarathi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pineau_J/0/1/0/all/0/1\">Joelle Pineau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Williams_A/0/1/0/all/0/1\">Adina Williams</a>",
          "description": "Recent investigations into the inner-workings of state-of-the-art large-scale\npre-trained Transformer-based Natural Language Understanding (NLU) models\nindicate that they appear to know humanlike syntax, at least to some extent. We\nprovide novel evidence that complicates this claim: we find that\nstate-of-the-art Natural Language Inference (NLI) models assign the same labels\nto permuted examples as they do to the original, i.e. they are largely\ninvariant to random word-order permutations. This behavior notably differs from\nthat of humans; we struggle with ungrammatical sentences. To measure the\nseverity of this issue, we propose a suite of metrics and investigate which\nproperties of particular permutations lead models to be word-order invariant.\nIn the MNLI dataset, for example, we find almost all (98.7%) examples contain\nat least one permutation which elicits the gold label. Models are sometimes\neven able to assign gold labels to permutations that they originally failed to\npredict correctly. We provide a comprehensive empirical evaluation of this\nphenomenon, and further show that this issue exists for both Transformers and\npre-Transformer RNN / ConvNet based encoders, as well as across multiple\nlanguages (English and Mandarin Chinese). Our code and data are available at\nhttps://github.com/facebookresearch/unlu.",
          "link": "http://arxiv.org/abs/2101.00010",
          "publishedOn": "2021-06-14T01:38:55.532Z",
          "wordCount": 652,
          "title": "UnNatural Language Inference. (arXiv:2101.00010v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.08598",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Terrance Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vietri_G/0/1/0/all/0/1\">Giuseppe Vietri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steinke_T/0/1/0/all/0/1\">Thomas Steinke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ullman_J/0/1/0/all/0/1\">Jonathan Ullman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhiwei Steven Wu</a>",
          "description": "In many statistical problems, incorporating priors can significantly improve\nperformance. However, the use of prior knowledge in differentially private\nquery release has remained underexplored, despite such priors commonly being\navailable in the form of public datasets, such as previous US Census releases.\nWith the goal of releasing statistics about a private dataset, we present\nPMW^Pub, which -- unlike existing baselines -- leverages public data drawn from\na related distribution as prior information. We provide a theoretical analysis\nand an empirical evaluation on the American Community Survey (ACS) and ADULT\ndatasets, which shows that our method outperforms state-of-the-art methods.\nFurthermore, PMW^Pub scales well to high-dimensional data domains, where\nrunning many existing methods would be computationally infeasible.",
          "link": "http://arxiv.org/abs/2102.08598",
          "publishedOn": "2021-06-14T01:38:55.507Z",
          "wordCount": 586,
          "title": "Leveraging Public Data for Practical Private Query Release. (arXiv:2102.08598v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.06177",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sodhani_S/0/1/0/all/0/1\">Shagun Sodhani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1\">Amy Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pineau_J/0/1/0/all/0/1\">Joelle Pineau</a>",
          "description": "The benefit of multi-task learning over single-task learning relies on the\nability to use relations across tasks to improve performance on any single\ntask. While sharing representations is an important mechanism to share\ninformation across tasks, its success depends on how well the structure\nunderlying the tasks is captured. In some real-world situations, we have access\nto metadata, or additional information about a task, that may not provide any\nnew insight in the context of a single task setup alone but inform relations\nacross multiple tasks. While this metadata can be useful for improving\nmulti-task learning performance, effectively incorporating it can be an\nadditional challenge. We posit that an efficient approach to knowledge transfer\nis through the use of multiple context-dependent, composable representations\nshared across a family of tasks. In this framework, metadata can help to learn\ninterpretable representations and provide the context to inform which\nrepresentations to compose and how to compose them. We use the proposed\napproach to obtain state-of-the-art results in Meta-World, a challenging\nmulti-task benchmark consisting of 50 distinct robotic manipulation tasks.",
          "link": "http://arxiv.org/abs/2102.06177",
          "publishedOn": "2021-06-14T01:38:55.501Z",
          "wordCount": 647,
          "title": "Multi-Task Reinforcement Learning with Context-based Representations. (arXiv:2102.06177v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.09318",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khodadadian_S/0/1/0/all/0/1\">Sajad Khodadadian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zaiwei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maguluri_S/0/1/0/all/0/1\">Siva Theja Maguluri</a>",
          "description": "In this paper, we provide finite-sample convergence guarantees for an\noff-policy variant of the natural actor-critic (NAC) algorithm based on\nImportance Sampling. In particular, we show that the algorithm converges to a\nglobal optimal policy with a sample complexity of\n$\\mathcal{O}(\\epsilon^{-3}\\log^2(1/\\epsilon))$ under an appropriate choice of\nstepsizes. In order to overcome the issue of large variance due to Importance\nSampling, we propose the $Q$-trace algorithm for the critic, which is inspired\nby the V-trace algorithm \\cite{espeholt2018impala}. This enables us to\nexplicitly control the bias and variance, and characterize the trade-off\nbetween them. As an advantage of off-policy sampling, a major feature of our\nresult is that we do not need any additional assumptions, beyond the ergodicity\nof the Markov chain induced by the behavior policy.",
          "link": "http://arxiv.org/abs/2102.09318",
          "publishedOn": "2021-06-14T01:38:55.494Z",
          "wordCount": 585,
          "title": "Finite-Sample Analysis of Off-Policy Natural Actor-Critic Algorithm. (arXiv:2102.09318v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.14193",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jastrzebski_S/0/1/0/all/0/1\">Stanislaw Jastrzebski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arpit_D/0/1/0/all/0/1\">Devansh Arpit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Astrand_O/0/1/0/all/0/1\">Oliver Astrand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kerg_G/0/1/0/all/0/1\">Giancarlo Kerg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Huan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1\">Caiming Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Socher_R/0/1/0/all/0/1\">Richard Socher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1\">Kyunghyun Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geras_K/0/1/0/all/0/1\">Krzysztof Geras</a>",
          "description": "The early phase of training a deep neural network has a dramatic effect on\nthe local curvature of the loss function. For instance, using a small learning\nrate does not guarantee stable optimization because the optimization trajectory\nhas a tendency to steer towards regions of the loss surface with increasing\nlocal curvature. We ask whether this tendency is connected to the widely\nobserved phenomenon that the choice of the learning rate strongly influences\ngeneralization. We first show that stochastic gradient descent (SGD) implicitly\npenalizes the trace of the Fisher Information Matrix (FIM), a measure of the\nlocal curvature, from the start of training. We argue it is an implicit\nregularizer in SGD by showing that explicitly penalizing the trace of the FIM\ncan significantly improve generalization. We highlight that poor final\ngeneralization coincides with the trace of the FIM attaining a large value\nearly in training, to which we refer as catastrophic Fisher explosion. Finally,\nto gain insight into the regularization effect of penalizing the trace of the\nFIM, we show that it limits memorization by reducing the learning speed of\nexamples with noisy labels more than that of the examples with clean labels.",
          "link": "http://arxiv.org/abs/2012.14193",
          "publishedOn": "2021-06-14T01:38:55.434Z",
          "wordCount": 691,
          "title": "Catastrophic Fisher Explosion: Early Phase Fisher Matrix Impacts Generalization. (arXiv:2012.14193v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.15477",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Nitanda_A/0/1/0/all/0/1\">Atsushi Nitanda</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wu_D/0/1/0/all/0/1\">Denny Wu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Suzuki_T/0/1/0/all/0/1\">Taiji Suzuki</a>",
          "description": "We propose the particle dual averaging (PDA) method, which generalizes the\ndual averaging method in convex optimization to the optimization over\nprobability distributions with quantitative runtime guarantee. The algorithm\nconsists of an inner loop and outer loop: the inner loop utilizes the Langevin\nalgorithm to approximately solve for a stationary distribution, which is then\noptimized in the outer loop. The method can thus be interpreted as an extension\nof the Langevin algorithm to naturally handle nonlinear functional on the\nprobability space. An important application of the proposed method is the\noptimization of neural network in the mean field regime, which is theoretically\nattractive due to the presence of nonlinear feature learning, but quantitative\nconvergence rate can be challenging to obtain. By adapting finite-dimensional\nconvex optimization theory into the space of distributions, we analyze PDA in\nregularized empirical / expected risk minimization, and establish quantitative\nglobal convergence in learning two-layer mean field neural networks under more\ngeneral settings. Our theoretical results are supported by numerical\nsimulations on neural networks with reasonable size.",
          "link": "http://arxiv.org/abs/2012.15477",
          "publishedOn": "2021-06-14T01:38:55.368Z",
          "wordCount": 629,
          "title": "Particle Dual Averaging: Optimization of Mean Field Neural Networks with Global Convergence Rate Analysis. (arXiv:2012.15477v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.15764",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Peeples_J/0/1/0/all/0/1\">Joshua Peeples</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walker_S/0/1/0/all/0/1\">Sarah Walker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McCurley_C/0/1/0/all/0/1\">Connor McCurley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zare_A/0/1/0/all/0/1\">Alina Zare</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keller_J/0/1/0/all/0/1\">James Keller</a>",
          "description": "In this paper, we investigate performing joint dimensionality reduction and\nclassification using a novel histogram neural network. Motivated by a popular\ndimensionality reduction approach, t-Distributed Stochastic Neighbor Embedding\n(t-SNE), our proposed method incorporates a classification loss computed on\nsamples in a low-dimensional embedding space. We compare the learned sample\nembeddings against coordinates found by t-SNE in terms of classification\naccuracy and qualitative assessment. We also explore use of various divergence\nmeasures in the t-SNE objective. The proposed method has several advantages\nsuch as readily embedding out-of-sample points and reducing feature\ndimensionality while retaining class discriminability. Our results show that\nthe proposed approach maintains and/or improves classification performance and\nreveals characteristics of features produced by neural networks that may be\nhelpful for other applications.",
          "link": "http://arxiv.org/abs/2012.15764",
          "publishedOn": "2021-06-14T01:38:55.308Z",
          "wordCount": 610,
          "title": "Divergence Regulated Encoder Network for Joint Dimensionality Reduction and Classification. (arXiv:2012.15764v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.11875",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Yemini_Y/0/1/0/all/0/1\">Yochai Yemini</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fetaya_E/0/1/0/all/0/1\">Ethan Fetaya</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Maron_H/0/1/0/all/0/1\">Haggai Maron</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gannot_S/0/1/0/all/0/1\">Sharon Gannot</a>",
          "description": "Neural networks (NNs) have been widely applied in speech processing tasks,\nand, in particular, those employing microphone arrays. Nevertheless, most\nexisting NN architectures can only deal with fixed and position-specific\nmicrophone arrays. In this paper, we present an NN architecture that can cope\nwith microphone arrays whose number and positions of the microphones are\nunknown, and demonstrate its applicability in the speech dereverberation task.\nTo this end, our approach harnesses recent advances in deep learning on\nset-structured data to design an architecture that enhances the reverberant\nlog-spectrum. We use noisy and noiseless versions of a simulated reverberant\ndataset to test the proposed architecture. Our experiments on the noisy data\nshow that the proposed scene-agnostic setup outperforms a powerful scene-aware\nframework, sometimes even with fewer microphones. With the noiseless dataset we\nshow that, in most cases, our method outperforms the position-aware network as\nwell as the state-of-the-art weighted linear prediction error (WPE) algorithm.",
          "link": "http://arxiv.org/abs/2010.11875",
          "publishedOn": "2021-06-14T01:38:55.301Z",
          "wordCount": 600,
          "title": "Scene-Agnostic Multi-Microphone Speech Dereverberation. (arXiv:2010.11875v2 [eess.AS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.07648",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhunxuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1\">Linyun He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_C/0/1/0/all/0/1\">Chunchuan Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_S/0/1/0/all/0/1\">Shay B. Cohen</a>",
          "description": "We describe an algorithm that learns two-layer residual units with rectified\nlinear unit (ReLU) activation: suppose the input $\\mathbf{x}$ is from a\ndistribution with support space $\\mathbb{R}^d$ and the ground-truth generative\nmodel is such a residual unit, given by \\[\\mathbf{y}=\n\\boldsymbol{B}^\\ast\\left[\\left(\\boldsymbol{A}^\\ast\\mathbf{x}\\right)^+ +\n\\mathbf{x}\\right]\\text{,}\\] where ground-truth network parameters\n$\\boldsymbol{A}^\\ast \\in \\mathbb{R}^{d\\times d}$ is a nonnegative full-rank\nmatrix and $\\boldsymbol{B}^\\ast \\in \\mathbb{R}^{m\\times d}$ is full-rank with\n$m \\geq d$ and for $\\mathbf{c} \\in \\mathbb{R}^d$, $[\\mathbf{c}^{+}]_i =\n\\max\\{0, c_i\\}$. We design layer-wise objectives as functionals whose analytic\nminimizers express the exact ground-truth network in terms of its parameters\nand nonlinearities. Following this objective landscape, learning residual units\nfrom finite samples can be formulated using convex optimization of a\nnonparametric function: for each layer, we first formulate the corresponding\nempirical risk minimization (ERM) as a positive semi-definite quadratic program\n(QP), then we show the solution space of the QP can be equivalently determined\nby a set of linear inequalities, which can then be efficiently solved by linear\nprogramming (LP). We further prove the statistical strong consistency of our\nalgorithm, and demonstrate the robustness and sample efficiency of our\nalgorithm by experiments.",
          "link": "http://arxiv.org/abs/2008.07648",
          "publishedOn": "2021-06-14T01:38:55.295Z",
          "wordCount": 644,
          "title": "Nonparametric Learning of Two-Layer ReLU Residual Units. (arXiv:2008.07648v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.07210",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shukla_S/0/1/0/all/0/1\">Satya Narayan Shukla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sahu_A/0/1/0/all/0/1\">Anit Kumar Sahu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Willmott_D/0/1/0/all/0/1\">Devin Willmott</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolter_J/0/1/0/all/0/1\">J. Zico Kolter</a>",
          "description": "We focus on the problem of black-box adversarial attacks, where the aim is to\ngenerate adversarial examples for deep learning models solely based on\ninformation limited to output label~(hard label) to a queried data input. We\npropose a simple and efficient Bayesian Optimization~(BO) based approach for\ndeveloping black-box adversarial attacks. Issues with BO's performance in high\ndimensions are avoided by searching for adversarial examples in a structured\nlow-dimensional subspace. We demonstrate the efficacy of our proposed attack\nmethod by evaluating both $\\ell_\\infty$ and $\\ell_2$ norm constrained\nuntargeted and targeted hard label black-box attacks on three standard datasets\n- MNIST, CIFAR-10 and ImageNet. Our proposed approach consistently achieves 2x\nto 10x higher attack success rate while requiring 10x to 20x fewer queries\ncompared to the current state-of-the-art black-box adversarial attacks.",
          "link": "http://arxiv.org/abs/2007.07210",
          "publishedOn": "2021-06-14T01:38:55.288Z",
          "wordCount": 617,
          "title": "Simple and Efficient Hard Label Black-box Adversarial Attacks in Low Query Budget Regimes. (arXiv:2007.07210v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2001.02811",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Duan_J/0/1/0/all/0/1\">Jingliang Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guan_Y/0/1/0/all/0/1\">Yang Guan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shengbo Eben Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_Y/0/1/0/all/0/1\">Yangang Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_B/0/1/0/all/0/1\">Bo Cheng</a>",
          "description": "In reinforcement learning (RL), function approximation errors are known to\neasily lead to the Q-value overestimations, thus greatly reducing policy\nperformance. This paper presents a distributional soft actor-critic (DSAC)\nalgorithm, which is an off-policy RL method for continuous control setting, to\nimprove the policy performance by mitigating Q-value overestimations. We first\ndiscover in theory that learning a distribution function of state-action\nreturns can effectively mitigate Q-value overestimations because it is capable\nof adaptively adjusting the update stepsize of the Q-value function. Then, a\ndistributional soft policy iteration (DSPI) framework is developed by embedding\nthe return distribution function into maximum entropy RL. Finally, we present a\ndeep off-policy actor-critic variant of DSPI, called DSAC, which directly\nlearns a continuous return distribution by keeping the variance of the\nstate-action returns within a reasonable range to address exploding and\nvanishing gradient problems. We evaluate DSAC on the suite of MuJoCo continuous\ncontrol tasks, achieving the state-of-the-art performance.",
          "link": "http://arxiv.org/abs/2001.02811",
          "publishedOn": "2021-06-14T01:38:55.271Z",
          "wordCount": 649,
          "title": "Distributional Soft Actor-Critic: Off-Policy Reinforcement Learning for Addressing Value Estimation Errors. (arXiv:2001.02811v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2002.11318",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kamath_S/0/1/0/all/0/1\">Sandesh Kamath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deshpande_A/0/1/0/all/0/1\">Amit Deshpande</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Subrahmanyam_K/0/1/0/all/0/1\">K V Subrahmanyam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balasubramanian_V/0/1/0/all/0/1\">Vineeth N Balasubramanian</a>",
          "description": "(Non-)robustness of neural networks to small, adversarial pixel-wise\nperturbations, and as more recently shown, to even random spatial\ntransformations (e.g., translations, rotations) entreats both theoretical and\nempirical understanding. Spatial robustness to random translations and\nrotations is commonly attained via equivariant models (e.g., StdCNNs, GCNNs)\nand training augmentation, whereas adversarial robustness is typically achieved\nby adversarial training. In this paper, we prove a quantitative trade-off\nbetween spatial and adversarial robustness in a simple statistical setting. We\ncomplement this empirically by showing that: (a) as the spatial robustness of\nequivariant models improves by training augmentation with progressively larger\ntransformations, their adversarial robustness worsens progressively, and (b) as\nthe state-of-the-art robust models are adversarially trained with progressively\nlarger pixel-wise perturbations, their spatial robustness drops progressively.\nTowards achieving pareto-optimality in this trade-off, we propose a method\nbased on curriculum learning that trains gradually on more difficult\nperturbations (both spatial and adversarial) to improve spatial and adversarial\nrobustness simultaneously.",
          "link": "http://arxiv.org/abs/2002.11318",
          "publishedOn": "2021-06-14T01:38:55.256Z",
          "wordCount": 689,
          "title": "Can we have it all? On the Trade-off between Spatial and Adversarial Robustness of Neural Networks. (arXiv:2002.11318v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.08154",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Hult_L/0/1/0/all/0/1\">Ludvig Hult</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zachariah_D/0/1/0/all/0/1\">Dave Zachariah</a>",
          "description": "Conventional methods in causal effect inferencetypically rely on specifying a\nvalid set of control variables. When this set is unknown or misspecified,\ninferences will be erroneous. We propose a method for inferring average causal\neffects when all potential confounders are observed, but thecontrol variables\nare unknown. When the data-generating process belongs to the class of acyclical\nlinear structural causal models, we prove that themethod yields asymptotically\nvalid confidence intervals. Our results build upon a smooth characterization of\nlinear directed acyclic graphs. We verify the capability of the method to\nproduce valid confidence intervals for average causal effects using synthetic\ndata, even when the appropriate specification of control variables is unknown.",
          "link": "http://arxiv.org/abs/2012.08154",
          "publishedOn": "2021-06-14T01:38:55.250Z",
          "wordCount": 564,
          "title": "Inference of Causal Effects when Control Variables are Unknown. (arXiv:2012.08154v3 [stat.ME] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.09649",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meyer_R/0/1/0/all/0/1\">Raphael A. Meyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Musco_C/0/1/0/all/0/1\">Cameron Musco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Musco_C/0/1/0/all/0/1\">Christopher Musco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1\">David P. Woodruff</a>",
          "description": "We study the problem of estimating the trace of a matrix $A$ that can only be\naccessed through matrix-vector multiplication. We introduce a new randomized\nalgorithm, Hutch++, which computes a $(1 \\pm \\epsilon)$ approximation to\n$tr(A)$ for any positive semidefinite (PSD) $A$ using just $O(1/\\epsilon)$\nmatrix-vector products. This improves on the ubiquitous Hutchinson's estimator,\nwhich requires $O(1/\\epsilon^2)$ matrix-vector products. Our approach is based\non a simple technique for reducing the variance of Hutchinson's estimator using\na low-rank approximation step, and is easy to implement and analyze. Moreover,\nwe prove that, up to a logarithmic factor, the complexity of Hutch++ is optimal\namongst all matrix-vector query algorithms, even when queries can be chosen\nadaptively. We show that it significantly outperforms Hutchinson's method in\nexperiments. While our theory mainly requires $A$ to be positive semidefinite,\nwe provide generalized guarantees for general square matrices, and show\nempirical gains in such applications.",
          "link": "http://arxiv.org/abs/2010.09649",
          "publishedOn": "2021-06-14T01:38:55.242Z",
          "wordCount": 646,
          "title": "Hutch++: Optimal Stochastic Trace Estimation. (arXiv:2010.09649v5 [cs.DS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2001.03040",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jianfeng Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1\">Zuowei Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Haizhao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shijun Zhang</a>",
          "description": "This paper establishes optimal approximation error characterization of deep\nReLU networks for smooth functions in terms of both width and depth\nsimultaneously. To that end, we first prove that multivariate polynomials can\nbe approximated by deep ReLU networks of width $\\mathcal{O}(N)$ and depth\n$\\mathcal{O}(L)$ with an approximation error $\\mathcal{O}(N^{-L})$. Through\nlocal Taylor expansions and their deep ReLU network approximations, we show\nthat deep ReLU networks of width $\\mathcal{O}(N\\ln N)$ and depth\n$\\mathcal{O}(L\\ln L)$ can approximate $f\\in C^s([0,1]^d)$ with a nearly optimal\napproximation rate $\\mathcal{O}(\\|f\\|_{C^s([0,1]^d)}N^{-2s/d}L^{-2s/d})$. Our\nestimate is non-asymptotic in the sense that it is valid for arbitrary width\nand depth specified by $N\\in\\mathbb{N}^+$ and $L\\in\\mathbb{N}^+$, respectively.",
          "link": "http://arxiv.org/abs/2001.03040",
          "publishedOn": "2021-06-14T01:38:55.233Z",
          "wordCount": 584,
          "title": "Deep Network Approximation for Smooth Functions. (arXiv:2001.03040v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.01557",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brown_D/0/1/0/all/0/1\">Daniel S. Brown</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schneider_J/0/1/0/all/0/1\">Jordan Schneider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dragan_A/0/1/0/all/0/1\">Anca D. Dragan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niekum_S/0/1/0/all/0/1\">Scott Niekum</a>",
          "description": "As humans interact with autonomous agents to perform increasingly\ncomplicated, potentially risky tasks, it is important to be able to efficiently\nevaluate an agent's performance and correctness. In this paper we formalize and\ntheoretically analyze the problem of efficient value alignment verification:\nhow to efficiently test whether the behavior of another agent is aligned with a\nhuman's values. The goal is to construct a kind of \"driver's test\" that a human\ncan give to any agent which will verify value alignment via a minimal number of\nqueries. We study alignment verification problems with both idealized humans\nthat have an explicit reward function as well as problems where they have\nimplicit values. We analyze verification of exact value alignment for rational\nagents and propose and analyze heuristic and approximate value alignment\nverification tests in a wide range of gridworlds and a continuous autonomous\ndriving domain. Finally, we prove that there exist sufficient conditions such\nthat we can verify exact and approximate alignment across an infinite set of\ntest environments via a constant-query-complexity alignment test.",
          "link": "http://arxiv.org/abs/2012.01557",
          "publishedOn": "2021-06-14T01:38:55.213Z",
          "wordCount": 627,
          "title": "Value Alignment Verification. (arXiv:2012.01557v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.09361",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ibrahim_Z/0/1/0/all/0/1\">Zina M Ibrahim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bean_D/0/1/0/all/0/1\">Daniel Bean</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Searle_T/0/1/0/all/0/1\">Thomas Searle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Honghan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shek_A/0/1/0/all/0/1\">Anthony Shek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kraljevic_Z/0/1/0/all/0/1\">Zeljko Kraljevic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galloway_J/0/1/0/all/0/1\">James Galloway</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Norton_S/0/1/0/all/0/1\">Sam Norton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teo_J/0/1/0/all/0/1\">James T Teo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dobson_R/0/1/0/all/0/1\">Richard JB Dobson</a>",
          "description": "The ability to perform accurate prognosis of patients is crucial for\nproactive clinical decision making, informed resource management and\npersonalised care. Existing outcome prediction models suffer from a low recall\nof infrequent positive outcomes. We present a highly-scalable and robust\nmachine learning framework to automatically predict adversity represented by\nmortality and ICU admission from time-series vital signs and laboratory results\nobtained within the first 24 hours of hospital admission. The stacked platform\ncomprises two components: a) an unsupervised LSTM Autoencoder that learns an\noptimal representation of the time-series, using it to differentiate the less\nfrequent patterns which conclude with an adverse event from the majority\npatterns that do not, and b) a gradient boosting model, which relies on the\nconstructed representation to refine prediction, incorporating static features\nof demographics, admission details and clinical summaries. The model is used to\nassess a patient's risk of adversity over time and provides visual\njustifications of its prediction based on the patient's static features and\ndynamic signals. Results of three case studies for predicting mortality and ICU\nadmission show that the model outperforms all existing outcome prediction\nmodels, achieving PR-AUC of 0.891 (95$%$ CI: 0.878 - 0.969) in predicting\nmortality in ICU and general ward settings and 0.908 (95$%$ CI: 0.870-0.935) in\npredicting ICU admission.",
          "link": "http://arxiv.org/abs/2011.09361",
          "publishedOn": "2021-06-14T01:38:55.206Z",
          "wordCount": 708,
          "title": "A Knowledge Distillation Ensemble Framework for Predicting Short and Long-term Hospitalisation Outcomes from Electronic Health Records Data. (arXiv:2011.09361v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1806.06142",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Strazzeri_F/0/1/0/all/0/1\">Fabio Strazzeri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanchez_Garcia_R/0/1/0/all/0/1\">Rub&#xe9;n J. S&#xe1;nchez-Garc&#xed;a</a>",
          "description": "Kleinberg introduced three natural clustering properties, or axioms, and\nshowed they cannot be simultaneously satisfied by any clustering algorithm. We\npresent a new clustering property, Monotonic Consistency, which avoids the\nwell-known problematic behaviour of Kleinberg's Consistency axiom, and the\nimpossibility result. Namely, we describe a clustering algorithm, Morse\nClustering, inspired by Morse Theory in Differential Topology, which satisfies\nKleinberg's original axioms with Consistency replaced by Monotonic Consistency.\nMorse clustering uncovers the underlying flow structure on a set or graph and\nreturns a partition into trees representing basins of attraction of critical\nvertices. We also generalise Kleinberg's axiomatic approach to sparse graphs,\nshowing an impossibility result for Consistency, and a possibility result for\nMonotonic Consistency and Morse clustering.",
          "link": "http://arxiv.org/abs/1806.06142",
          "publishedOn": "2021-06-14T01:38:55.197Z",
          "wordCount": 620,
          "title": "Possibility results for graph clustering: A novel consistency axiom. (arXiv:1806.06142v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.00344",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Konobeev_M/0/1/0/all/0/1\">Mikhail Konobeev</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kuzborskij_I/0/1/0/all/0/1\">Ilja Kuzborskij</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Szepesvari_C/0/1/0/all/0/1\">Csaba Szepesv&#xe1;ri</a>",
          "description": "A key problem in the theory of meta-learning is to understand how the task\ndistributions influence transfer risk, the expected error of a meta-learner on\na new task drawn from the unknown task distribution. In this paper, focusing on\nfixed design linear regression with Gaussian noise and a Gaussian task (or\nparameter) distribution, we give distribution-dependent lower bounds on the\ntransfer risk of any algorithm, while we also show that a novel, weighted\nversion of the so-called biased regularized regression method is able to match\nthese lower bounds up to a fixed constant factor. Notably, the weighting is\nderived from the covariance of the Gaussian task distribution. Altogether, our\nresults provide a precise characterization of the difficulty of meta-learning\nin this Gaussian setting. While this problem setting may appear simple, we show\nthat it is rich enough to unify the \"parameter sharing\" and \"representation\nlearning\" streams of meta-learning; in particular, representation learning is\nobtained as the special case when the covariance matrix of the task\ndistribution is unknown. For this case we propose to adopt the EM method, which\nis shown to enjoy efficient updates in our case. The paper is completed by an\nempirical study of EM. In particular, our experimental results show that the EM\nalgorithm can attain the lower bound as the number of tasks grows, while the\nalgorithm is also successful in competing with its alternatives when used in a\nrepresentation learning context.",
          "link": "http://arxiv.org/abs/2011.00344",
          "publishedOn": "2021-06-14T01:38:55.190Z",
          "wordCount": 679,
          "title": "A Distribution-Dependent Analysis of Meta-Learning. (arXiv:2011.00344v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.09536",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1\">Hongyao Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Z/0/1/0/all/0/1\">Zhaopeng Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_J/0/1/0/all/0/1\">Jianye Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Graves_D/0/1/0/all/0/1\">Daniel Graves</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_H/0/1/0/all/0/1\">Hangyu Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wulong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yaodong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1\">Changmin Yu</a>",
          "description": "We study Policy-extended Value Function Approximator (PeVFA) in Reinforcement\nLearning (RL), which extends conventional value function approximator (VFA) to\ntake as input not only the state (and action) but also an explicit policy\nrepresentation. Such an extension enables PeVFA to preserve values of multiple\npolicies at the same time and brings an appealing characteristic, i.e.,\n\\emph{value generalization among policies}. We formally analyze the value\ngeneralization under Generalized Policy Iteration (GPI). From theoretical and\nempirical lens, we show that generalized value estimates offered by PeVFA may\nhave lower initial approximation error to true values of successive policies,\nwhich is expected to improve consecutive value approximation during GPI. Based\non above clues, we introduce a new form of GPI with PeVFA which leverages the\nvalue generalization along policy improvement path. Moreover, we propose a\nrepresentation learning framework for RL policy, providing several approaches\nto learn effective policy embeddings from policy network parameters or\nstate-action pairs. In our experiments, we evaluate the efficacy of value\ngeneralization offered by PeVFA and policy representation learning in several\nOpenAI Gym continuous control tasks. For a representative instance of algorithm\nimplementation, Proximal Policy Optimization (PPO) re-implemented under the\nparadigm of GPI with PeVFA achieves about 40\\% performance improvement on its\nvanilla counterpart in most environments.",
          "link": "http://arxiv.org/abs/2010.09536",
          "publishedOn": "2021-06-14T01:38:55.182Z",
          "wordCount": 699,
          "title": "Represent Your Own Policies: Reinforcement Learning with Policy-extended Value Function Approximator. (arXiv:2010.09536v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06442",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Su_X/0/1/0/all/0/1\">Xiu Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_S/0/1/0/all/0/1\">Shan You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_M/0/1/0/all/0/1\">Mingkai Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Fei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_C/0/1/0/all/0/1\">Chen Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Changshui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chang Xu</a>",
          "description": "In one-shot weight sharing for NAS, the weights of each operation (at each\nlayer) are supposed to be identical for all architectures (paths) in the\nsupernet. However, this rules out the possibility of adjusting operation\nweights to cater for different paths, which limits the reliability of the\nevaluation results. In this paper, instead of counting on a single supernet, we\nintroduce $K$-shot supernets and take their weights for each operation as a\ndictionary. The operation weight for each path is represented as a convex\ncombination of items in a dictionary with a simplex code. This enables a matrix\napproximation of the stand-alone weight matrix with a higher rank ($K>1$). A\n\\textit{simplex-net} is introduced to produce architecture-customized code for\neach path. As a result, all paths can adaptively learn how to share weights in\nthe $K$-shot supernets and acquire corresponding weights for better evaluation.\n$K$-shot supernets and simplex-net can be iteratively trained, and we further\nextend the search to the channel dimension. Extensive experiments on benchmark\ndatasets validate that K-shot NAS significantly improves the evaluation\naccuracy of paths and thus brings in impressive performance improvements.",
          "link": "http://arxiv.org/abs/2106.06442",
          "publishedOn": "2021-06-14T01:38:55.163Z",
          "wordCount": 631,
          "title": "K-shot NAS: Learnable Weight-Sharing for NAS with K-shot Supernets. (arXiv:2106.06442v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2006.03204",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Petsiuk_V/0/1/0/all/0/1\">Vitali Petsiuk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_R/0/1/0/all/0/1\">Rajiv Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manjunatha_V/0/1/0/all/0/1\">Varun Manjunatha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morariu_V/0/1/0/all/0/1\">Vlad I. Morariu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehra_A/0/1/0/all/0/1\">Ashutosh Mehra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ordonez_V/0/1/0/all/0/1\">Vicente Ordonez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saenko_K/0/1/0/all/0/1\">Kate Saenko</a>",
          "description": "We propose D-RISE, a method for generating visual explanations for the\npredictions of object detectors. Utilizing the proposed similarity metric that\naccounts for both localization and categorization aspects of object detection\nallows our method to produce saliency maps that show image areas that most\naffect the prediction. D-RISE can be considered \"black-box\" in the software\ntesting sense, as it only needs access to the inputs and outputs of an object\ndetector. Compared to gradient-based methods, D-RISE is more general and\nagnostic to the particular type of object detector being tested, and does not\nneed knowledge of the inner workings of the model. We show that D-RISE can be\neasily applied to different object detectors including one-stage detectors such\nas YOLOv3 and two-stage detectors such as Faster-RCNN. We present a detailed\nanalysis of the generated visual explanations to highlight the utilization of\ncontext and possible biases learned by object detectors.",
          "link": "http://arxiv.org/abs/2006.03204",
          "publishedOn": "2021-06-14T01:38:55.155Z",
          "wordCount": 633,
          "title": "Black-box Explanation of Object Detectors via Saliency Maps. (arXiv:2006.03204v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06513",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Alberti_G/0/1/0/all/0/1\">Giovanni S. Alberti</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vito_E/0/1/0/all/0/1\">Ernesto De Vito</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lassas_M/0/1/0/all/0/1\">Matti Lassas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ratti_L/0/1/0/all/0/1\">Luca Ratti</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Santacesaria_M/0/1/0/all/0/1\">Matteo Santacesaria</a>",
          "description": "In this work, we consider the linear inverse problem $y=Ax+\\epsilon$, where\n$A\\colon X\\to Y$ is a known linear operator between the separable Hilbert\nspaces $X$ and $Y$, $x$ is a random variable in $X$ and $\\epsilon$ is a\nzero-mean random process in $Y$. This setting covers several inverse problems\nin imaging including denoising, deblurring, and X-ray tomography. Within the\nclassical framework of regularization, we focus on the case where the\nregularization functional is not given a priori but learned from data. Our\nfirst result is a characterization of the optimal generalized Tikhonov\nregularizer, with respect to the mean squared error. We find that it is\ncompletely independent of the forward operator $A$ and depends only on the mean\nand covariance of $x$. Then, we consider the problem of learning the\nregularizer from a finite training set in two different frameworks: one\nsupervised, based on samples of both $x$ and $y$, and one unsupervised, based\nonly on samples of $x$. In both cases, we prove generalization bounds, under\nsome weak assumptions on the distribution of $x$ and $\\epsilon$, including the\ncase of sub-Gaussian variables. Our bounds hold in infinite-dimensional spaces,\nthereby showing that finer and finer discretizations do not make this learning\nproblem harder. The results are validated through numerical simulations.",
          "link": "http://arxiv.org/abs/2106.06513",
          "publishedOn": "2021-06-14T01:38:55.148Z",
          "wordCount": 646,
          "title": "Learning the optimal regularizer for inverse problems. (arXiv:2106.06513v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2010.05690",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+B_L/0/1/0/all/0/1\">Lalith Bharadwaj B</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boddeda_R/0/1/0/all/0/1\">Rohit Boddeda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+K_S/0/1/0/all/0/1\">Sai Vardhan K</a>, <a href=\"http://arxiv.org/find/cs/1/au:+G_M/0/1/0/all/0/1\">Madhu G</a>",
          "description": "The issue of COVID-19, increasing with a massive mortality rate. This led to\nthe WHO declaring it as a pandemic. In this situation, it is crucial to perform\nefficient and fast diagnosis. The reverse transcript polymerase chain reaction\n(RTPCR) test is conducted to detect the presence of SARS-CoV-2. This test is\ntime-consuming and instead chest CT (or Chest X-ray) can be used for a fast and\naccurate diagnosis. Automated diagnosis is considered to be important as it\nreduces human effort and provides accurate and low-cost tests. The\ncontributions of our research are three-fold. First, it is aimed to analyse the\nbehaviour and performance of variant vision models ranging from Inception to\nNAS networks with the appropriate fine-tuning procedure. Second, the behaviour\nof these models is visually analysed by plotting CAMs for individual networks\nand determining classification performance with AUCROC curves. Thirdly, stacked\nensembles techniques are imparted to provide higher generalisation on combining\nthe fine-tuned models, in which six ensemble neural networks are designed by\ncombining the existing fine-tuned networks. Implying these stacked ensembles\nprovides a great generalization to the models. The ensemble model designed by\ncombining all the fine-tuned networks obtained a state-of-the-art accuracy\nscore of 99.17%. The precision and recall for the COVID-19 class are 99.99% and\n89.79% respectively, which resembles the robustness of the stacked ensembles.",
          "link": "http://arxiv.org/abs/2010.05690",
          "publishedOn": "2021-06-14T01:38:55.141Z",
          "wordCount": 741,
          "title": "COVID-19 Classification Using Staked Ensembles: A Comprehensive Analysis. (arXiv:2010.05690v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.01668",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fanghui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xiaolin Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yudong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suykens_J/0/1/0/all/0/1\">Johan A.K. Suykens</a>",
          "description": "In this paper, we develop a quadrature framework for large-scale kernel\nmachines via a numerical integration representation. Considering that the\nintegration domain and measure of typical kernels, e.g., Gaussian kernels,\narc-cosine kernels, are fully symmetric, we leverage deterministic fully\nsymmetric interpolatory rules to efficiently compute quadrature nodes and\nassociated weights for kernel approximation. The developed interpolatory rules\nare able to reduce the number of needed nodes while retaining a high\napproximation accuracy. Further, we randomize the above deterministic rules by\nthe classical Monte-Carlo sampling and control variates techniques with two\nmerits: 1) The proposed stochastic rules make the dimension of the feature\nmapping flexibly varying, such that we can control the discrepancy between the\noriginal and approximate kernels by tuning the dimnension. 2) Our stochastic\nrules have nice statistical properties of unbiasedness and variance reduction\nwith fast convergence rate. In addition, we elucidate the relationship between\nour deterministic/stochastic interpolatory rules and current quadrature rules\nfor kernel approximation, including the sparse grids quadrature and stochastic\nspherical-radial rules, thereby unifying these methods under our framework.\nExperimental results on several benchmark datasets show that our methods\ncompare favorably with other representative kernel approximation based methods.",
          "link": "http://arxiv.org/abs/2011.01668",
          "publishedOn": "2021-06-14T01:38:55.132Z",
          "wordCount": 660,
          "title": "Towards a Unified Quadrature Framework for Large-Scale Kernel Machines. (arXiv:2011.01668v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06440",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Michalkiewicz_M/0/1/0/all/0/1\">Mateusz Michalkiewicz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsogkas_S/0/1/0/all/0/1\">Stavros Tsogkas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parisot_S/0/1/0/all/0/1\">Sarah Parisot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baktashmotlagh_M/0/1/0/all/0/1\">Mahsa Baktashmotlagh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eriksson_A/0/1/0/all/0/1\">Anders Eriksson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belilovsky_E/0/1/0/all/0/1\">Eugene Belilovsky</a>",
          "description": "The impressive performance of deep convolutional neural networks in\nsingle-view 3D reconstruction suggests that these models perform non-trivial\nreasoning about the 3D structure of the output space. Recent work has\nchallenged this belief, showing that, on standard benchmarks, complex\nencoder-decoder architectures perform similarly to nearest-neighbor baselines\nor simple linear decoder models that exploit large amounts of per-category\ndata. However, building large collections of 3D shapes for supervised training\nis a laborious process; a more realistic and less constraining task is\ninferring 3D shapes for categories with few available training examples,\ncalling for a model that can successfully generalize to novel object classes.\nIn this work we experimentally demonstrate that naive baselines fail in this\nfew-shot learning setting, in which the network must learn informative shape\npriors for inference of new categories. We propose three ways to learn a\nclass-specific global shape prior, directly from data. Using these techniques,\nwe are able to capture multi-scale information about the 3D shape, and account\nfor intra-class variability by virtue of an implicit compositional structure.\nExperiments on the popular ShapeNet dataset show that our method outperforms a\nzero-shot baseline by over 40%, and the current state-of-the-art by over 10%,\nin terms of relative performance, in the few-shot setting.12",
          "link": "http://arxiv.org/abs/2106.06440",
          "publishedOn": "2021-06-14T01:38:55.110Z",
          "wordCount": 655,
          "title": "Learning Compositional Shape Priors for Few-Shot 3D Reconstruction. (arXiv:2106.06440v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2010.03485",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Saad_F/0/1/0/all/0/1\">Feras A. Saad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rinard_M/0/1/0/all/0/1\">Martin C. Rinard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mansinghka_V/0/1/0/all/0/1\">Vikash K. Mansinghka</a>",
          "description": "We present the Sum-Product Probabilistic Language (SPPL), a new probabilistic\nprogramming language that automatically delivers exact solutions to a broad\nrange of probabilistic inference queries. SPPL translates probabilistic\nprograms into sum-product expressions, a new symbolic representation and\nassociated semantic domain that extends standard sum-product networks to\nsupport mixed-type distributions, numeric transformations, logical formulas,\nand pointwise and set-valued constraints. We formalize SPPL via a novel\ntranslation strategy from probabilistic programs to sum-product expressions and\ngive sound exact algorithms for conditioning on and computing probabilities of\nevents. SPPL imposes a collection of restrictions on probabilistic programs to\nensure they can be translated into sum-product expressions, which allow the\nsystem to leverage new techniques for improving the scalability of translation\nand inference by automatically exploiting probabilistic structure. We implement\na prototype of SPPL with a modular architecture and evaluate it on benchmarks\nthe system targets, showing that it obtains up to 3500x speedups over\nstate-of-the-art symbolic systems on tasks such as verifying the fairness of\ndecision tree classifiers, smoothing hidden Markov models, conditioning\ntransformed random variables, and computing rare event probabilities.",
          "link": "http://arxiv.org/abs/2010.03485",
          "publishedOn": "2021-06-14T01:38:55.101Z",
          "wordCount": 689,
          "title": "SPPL: Probabilistic Programming with Fast Exact Symbolic Inference. (arXiv:2010.03485v3 [cs.PL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.14986",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kopetzki_A/0/1/0/all/0/1\">Anna-Kathrin Kopetzki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Charpentier_B/0/1/0/all/0/1\">Bertrand Charpentier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zugner_D/0/1/0/all/0/1\">Daniel Z&#xfc;gner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giri_S/0/1/0/all/0/1\">Sandhya Giri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gunnemann_S/0/1/0/all/0/1\">Stephan G&#xfc;nnemann</a>",
          "description": "Dirichlet-based uncertainty (DBU) models are a recent and promising class of\nuncertainty-aware models. DBU models predict the parameters of a Dirichlet\ndistribution to provide fast, high-quality uncertainty estimates alongside with\nclass predictions. In this work, we present the first large-scale, in-depth\nstudy of the robustness of DBU models under adversarial attacks. Our results\nsuggest that uncertainty estimates of DBU models are not robust w.r.t. three\nimportant tasks: (1) indicating correctly and wrongly classified samples; (2)\ndetecting adversarial examples; and (3) distinguishing between in-distribution\n(ID) and out-of-distribution (OOD) data. Additionally, we explore the first\napproaches to make DBU models more robust. While adversarial training has a\nminor effect, our median smoothing based approach significantly increases\nrobustness of DBU models.",
          "link": "http://arxiv.org/abs/2010.14986",
          "publishedOn": "2021-06-14T01:38:55.092Z",
          "wordCount": 586,
          "title": "Evaluating Robustness of Predictive Uncertainty Estimation: Are Dirichlet-based Models Reliable?. (arXiv:2010.14986v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.03294",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cai_T/0/1/0/all/0/1\">Tianle Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1\">Shengjie Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1\">Keyulu Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1\">Di He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tie-Yan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Liwei Wang</a>",
          "description": "Normalization is known to help the optimization of deep neural networks.\nCuriously, different architectures require specialized normalization methods.\nIn this paper, we study what normalization is effective for Graph Neural\nNetworks (GNNs). First, we adapt and evaluate the existing methods from other\ndomains to GNNs. Faster convergence is achieved with InstanceNorm compared to\nBatchNorm and LayerNorm. We provide an explanation by showing that InstanceNorm\nserves as a preconditioner for GNNs, but such preconditioning effect is weaker\nwith BatchNorm due to the heavy batch noise in graph datasets. Second, we show\nthat the shift operation in InstanceNorm results in an expressiveness\ndegradation of GNNs for highly regular graphs. We address this issue by\nproposing GraphNorm with a learnable shift. Empirically, GNNs with GraphNorm\nconverge faster compared to GNNs using other normalization. GraphNorm also\nimproves the generalization of GNNs, achieving better performance on graph\nclassification benchmarks.",
          "link": "http://arxiv.org/abs/2009.03294",
          "publishedOn": "2021-06-14T01:38:55.085Z",
          "wordCount": 633,
          "title": "GraphNorm: A Principled Approach to Accelerating Graph Neural Network Training. (arXiv:2009.03294v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06483",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Krishnamurthy_S/0/1/0/all/0/1\">Sanath Kumar Krishnamurthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Athey_S/0/1/0/all/0/1\">Susan Athey</a>",
          "description": "We study the problem of model selection for contextual bandits, in which the\nalgorithm must balance the bias-variance trade-off for model estimation while\nalso balancing the exploration-exploitation trade-off. In this paper, we\npropose the first reduction of model selection in contextual bandits to offline\nmodel selection oracles, allowing for flexible general purpose algorithms with\ncomputational requirements no worse than those for model selection for\nregression. Our main result is a new model selection guarantee for stochastic\ncontextual bandits. When one of the classes in our set is realizable, up to a\nlogarithmic dependency on the number of classes, our algorithm attains optimal\nrealizability-based regret bounds for that class under one of two conditions:\nif the time-horizon is large enough, or if an assumption that helps with\ndetecting misspecification holds. Hence our algorithm adapts to the complexity\nof this unknown class. Even when this realizable class is known, we prove\nimproved regret guarantees in early rounds by relying on simpler model classes\nfor those rounds and hence further establish the importance of model selection\nin contextual bandits.",
          "link": "http://arxiv.org/abs/2106.06483",
          "publishedOn": "2021-06-14T01:38:55.078Z",
          "wordCount": 612,
          "title": "Optimal Model Selection in Contextual Bandits with Many Classes via Offline Oracles. (arXiv:2106.06483v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2006.04647",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mellor_J/0/1/0/all/0/1\">Joseph Mellor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turner_J/0/1/0/all/0/1\">Jack Turner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Storkey_A/0/1/0/all/0/1\">Amos Storkey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crowley_E/0/1/0/all/0/1\">Elliot J. Crowley</a>",
          "description": "The time and effort involved in hand-designing deep neural networks is\nimmense. This has prompted the development of Neural Architecture Search (NAS)\ntechniques to automate this design. However, NAS algorithms tend to be slow and\nexpensive; they need to train vast numbers of candidate networks to inform the\nsearch process. This could be alleviated if we could partially predict a\nnetwork's trained accuracy from its initial state. In this work, we examine the\noverlap of activations between datapoints in untrained networks and motivate\nhow this can give a measure which is usefully indicative of a network's trained\nperformance. We incorporate this measure into a simple algorithm that allows us\nto search for powerful networks without any training in a matter of seconds on\na single GPU, and verify its effectiveness on NAS-Bench-101, NAS-Bench-201,\nNATS-Bench, and Network Design Spaces. Our approach can be readily combined\nwith more expensive search methods; we examine a simple adaptation of\nregularised evolutionary search. Code for reproducing our experiments is\navailable at https://github.com/BayesWatch/nas-without-training.",
          "link": "http://arxiv.org/abs/2006.04647",
          "publishedOn": "2021-06-14T01:38:55.057Z",
          "wordCount": 649,
          "title": "Neural Architecture Search without Training. (arXiv:2006.04647v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.03310",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sundaram_R/0/1/0/all/0/1\">Ravi Sundaram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vullikanti_A/0/1/0/all/0/1\">Anil Vullikanti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haifeng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_F/0/1/0/all/0/1\">Fan Yao</a>",
          "description": "The study of strategic or adversarial manipulation of testing data to fool a\nclassifier has attracted much recent attention. Most previous works have\nfocused on two extreme situations where any testing data point either is\ncompletely adversarial or always equally prefers the positive label. In this\npaper, we generalize both of these through a unified framework for strategic\nclassification, and introduce the notion of strategic VC-dimension (SVC) to\ncapture the PAC-learnability in our general strategic setup. SVC provably\ngeneralizes the recent concept of adversarial VC-dimension (AVC) introduced by\nCullina et al. arXiv:1806.01471. We instantiate our framework for the\nfundamental strategic linear classification problem. We fully characterize: (1)\nthe statistical learnability of linear classifiers by pinning down its SVC; (2)\nits computational tractability by pinning down the complexity of the empirical\nrisk minimization problem. Interestingly, the SVC of linear classifiers is\nalways upper bounded by its standard VC-dimension. This characterization also\nstrictly generalizes the AVC bound for linear classifiers in arXiv:1806.01471.",
          "link": "http://arxiv.org/abs/2012.03310",
          "publishedOn": "2021-06-14T01:38:55.050Z",
          "wordCount": 627,
          "title": "PAC-Learning for Strategic Classification. (arXiv:2012.03310v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06529",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pleiss_G/0/1/0/all/0/1\">Geoff Pleiss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cunningham_J/0/1/0/all/0/1\">John P. Cunningham</a>",
          "description": "Large width limits have been a recent focus of deep learning research: modulo\ncomputational practicalities, do wider networks outperform narrower ones?\nAnswering this question has been challenging, as conventional networks gain\nrepresentational power with width, potentially masking any negative effects.\nOur analysis in this paper decouples capacity and width via the generalization\nof neural networks to Deep Gaussian Processes (Deep GP), a class of\nhierarchical models that subsume neural nets. In doing so, we aim to understand\nhow width affects standard neural networks once they have sufficient capacity\nfor a given modeling task. Our theoretical and empirical results on Deep GP\nsuggest that large width is generally detrimental to hierarchical models.\nSurprisingly, we prove that even nonparametric Deep GP converge to Gaussian\nprocesses, effectively becoming shallower without any increase in\nrepresentational power. The posterior, which corresponds to a mixture of\ndata-adaptable basis functions, becomes less data-dependent with width. Our\ntail analysis demonstrates that width and depth have opposite effects: depth\naccentuates a model's non-Gaussianity, while width makes models increasingly\nGaussian. We find there is a \"sweet spot\" that maximizes test set performance\nbefore the limiting GP behavior prevents adaptability, occurring at width = 1\nor width = 2 for nonparametric Deep GP. These results make strong predictions\nabout the same phenomenon in conventional neural networks: we show empirically\nthat many neural network architectures need 10 - 500 hidden units for\nsufficient capacity - depending on the dataset - but further width degrades\ntest performance.",
          "link": "http://arxiv.org/abs/2106.06529",
          "publishedOn": "2021-06-14T01:38:55.044Z",
          "wordCount": 680,
          "title": "The Limitations of Large Width in Neural Networks: A Deep Gaussian Process Perspective. (arXiv:2106.06529v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2011.06125",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Boussioux_L/0/1/0/all/0/1\">L&#xe9;onard Boussioux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_C/0/1/0/all/0/1\">Cynthia Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guenais_T/0/1/0/all/0/1\">Th&#xe9;o Gu&#xe9;nais</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bertsimas_D/0/1/0/all/0/1\">Dimitris Bertsimas</a>",
          "description": "This paper describes a machine learning (ML) framework for tropical cyclone\nintensity and track forecasting, combining multiple distinct ML techniques and\nutilizing diverse data sources. Our framework, which we refer to as Hurricast\n(HURR), is built upon the combination of distinct data processing techniques\nusing gradient-boosted trees and novel encoder-decoder architectures, including\nCNN, GRU and Transformers components. We propose a deep-feature extractor\nmethodology to mix spatial-temporal data with statistical data efficiently. Our\nmultimodal framework unleashes the potential of making forecasts based on a\nwide range of data sources, including historical storm data, and visual data\nsuch as reanalysis atmospheric images. We evaluate our models with current\noperational forecasts in North Atlantic and Eastern Pacific basins on 2016-2019\nfor 24-hour lead time, and show our models consistently outperform\nstatistical-dynamical models and compete with the best dynamical models, while\ncomputing forecasts in seconds. Furthermore, the inclusion of Hurricast into an\noperational forecast consensus model leads to a significant improvement of 5% -\n15% over NHC's official forecast, thus highlighting the complementary\nproperties with existing approaches. In summary, our work demonstrates that\ncombining different data sources and distinct machine learning methodologies\ncan lead to superior tropical cyclone forecasting. We hope that this work opens\nthe door for further use of machine learning in meteorological forecasting.",
          "link": "http://arxiv.org/abs/2011.06125",
          "publishedOn": "2021-06-14T01:38:55.036Z",
          "wordCount": 683,
          "title": "Hurricane Forecasting: A Novel Multimodal Machine Learning Framework. (arXiv:2011.06125v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06362",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kinnunen_T/0/1/0/all/0/1\">Tomi Kinnunen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nautsch_A/0/1/0/all/0/1\">Andreas Nautsch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sahidullah_M/0/1/0/all/0/1\">Md Sahidullah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Evans_N/0/1/0/all/0/1\">Nicholas Evans</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Todisco_M/0/1/0/all/0/1\">Massimiliano Todisco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Delgado_H/0/1/0/all/0/1\">H&#xe9;ctor Delgado</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamagishi_J/0/1/0/all/0/1\">Junichi Yamagishi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Kong Aik Lee</a>",
          "description": "Whether it be for results summarization, or the analysis of classifier\nfusion, some means to compare different classifiers can often provide\nilluminating insight into their behaviour, (dis)similarity or complementarity.\nWe propose a simple method to derive 2D representation from detection scores\nproduced by an arbitrary set of binary classifiers in response to a common\ndataset. Based upon rank correlations, our method facilitates a visual\ncomparison of classifiers with arbitrary scores and with close relation to\nreceiver operating characteristic (ROC) and detection error trade-off (DET)\nanalyses. While the approach is fully versatile and can be applied to any\ndetection task, we demonstrate the method using scores produced by automatic\nspeaker verification and voice anti-spoofing systems. The former are produced\nby a Gaussian mixture model system trained with VoxCeleb data whereas the\nlatter stem from submissions to the ASVspoof 2019 challenge.",
          "link": "http://arxiv.org/abs/2106.06362",
          "publishedOn": "2021-06-14T01:38:55.030Z",
          "wordCount": 608,
          "title": "Visualizing Classifier Adjacency Relations: A Case Study in Speaker Verification and Voice Anti-Spoofing. (arXiv:2106.06362v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/1905.12346",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fanuel_M/0/1/0/all/0/1\">Micha&#xeb;l Fanuel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schreurs_J/0/1/0/all/0/1\">Joachim Schreurs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suykens_J/0/1/0/all/0/1\">Johan A.K. Suykens</a>",
          "description": "Selecting diverse and important items, called landmarks, from a large set is\na problem of interest in machine learning. As a specific example, in order to\ndeal with large training sets, kernel methods often rely on low rank matrix\nNystr\\\"om approximations based on the selection or sampling of landmarks. In\nthis context, we propose a deterministic and a randomized adaptive algorithm\nfor selecting landmark points within a training data set, which are related to\nthe minima of a sequence of kernelized Christoffel functions. Beyond the known\nconnection between Christoffel functions and leverage scores, a connection of\nour method with determinantal point processes (DPPs) is also explained. Namely,\nour construction promotes diversity among important landmark points in a way\nsimilar to DPPs. Also, we explain how our randomized adaptive algorithm can\ninfluence the accuracy of Kernel Ridge Regression.",
          "link": "http://arxiv.org/abs/1905.12346",
          "publishedOn": "2021-06-14T01:38:55.012Z",
          "wordCount": 610,
          "title": "Nystr\\\"om landmark sampling and regularized Christoffel functions. (arXiv:1905.12346v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.07249",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Creager_E/0/1/0/all/0/1\">Elliot Creager</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jacobsen_J/0/1/0/all/0/1\">J&#xf6;rn-Henrik Jacobsen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zemel_R/0/1/0/all/0/1\">Richard Zemel</a>",
          "description": "Learning models that gracefully handle distribution shifts is central to\nresearch on domain generalization, robust optimization, and fairness. A\npromising formulation is domain-invariant learning, which identifies the key\nissue of learning which features are domain-specific versus domain-invariant.\nAn important assumption in this area is that the training examples are\npartitioned into \"domains\" or \"environments\". Our focus is on the more common\nsetting where such partitions are not provided. We propose EIIL, a general\nframework for domain-invariant learning that incorporates Environment Inference\nto directly infer partitions that are maximally informative for downstream\nInvariant Learning. We show that EIIL outperforms invariant learning methods on\nthe CMNIST benchmark without using environment labels, and significantly\noutperforms ERM on worst-group performance in the Waterbirds and CivilComments\ndatasets. Finally, we establish connections between EIIL and algorithmic\nfairness, which enables EIIL to improve accuracy and calibration in a fair\nprediction problem.",
          "link": "http://arxiv.org/abs/2010.07249",
          "publishedOn": "2021-06-14T01:38:55.006Z",
          "wordCount": 611,
          "title": "Environment Inference for Invariant Learning. (arXiv:2010.07249v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2002.09773",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ergen_T/0/1/0/all/0/1\">Tolga Ergen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pilanci_M/0/1/0/all/0/1\">Mert Pilanci</a>",
          "description": "We study regularized deep neural networks (DNNs) and introduce a convex\nanalytic framework to characterize the structure of the hidden layers. We show\nthat a set of optimal hidden layer weights for a norm regularized DNN training\nproblem can be explicitly found as the extreme points of a convex set. For the\nspecial case of deep linear networks, we prove that each optimal weight matrix\naligns with the previous layers via duality. More importantly, we apply the\nsame characterization to deep ReLU networks with whitened data and prove the\nsame weight alignment holds. As a corollary, we also prove that norm\nregularized deep ReLU networks yield spline interpolation for one-dimensional\ndatasets which was previously known only for two-layer networks. Furthermore,\nwe provide closed-form solutions for the optimal layer weights when data is\nrank-one or whitened. The same analysis also applies to architectures with\nbatch normalization even for arbitrary data. Therefore, we obtain a complete\nexplanation for a recent empirical observation termed Neural Collapse where\nclass means collapse to the vertices of a simplex equiangular tight frame.",
          "link": "http://arxiv.org/abs/2002.09773",
          "publishedOn": "2021-06-14T01:38:54.999Z",
          "wordCount": 655,
          "title": "Revealing the Structure of Deep Neural Networks via Convex Duality. (arXiv:2002.09773v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.08844",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jinghan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boloor_A/0/1/0/all/0/1\">Adith Boloor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakrabarti_A/0/1/0/all/0/1\">Ayan Chakrabarti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vorobeychik_Y/0/1/0/all/0/1\">Yevgeniy Vorobeychik</a>",
          "description": "There is considerable evidence that deep neural networks are vulnerable to\nadversarial perturbations applied directly to their digital inputs. However, it\nremains an open question whether this translates to vulnerabilities in real\nsystems. For example, an attack on self-driving cars would in practice entail\nmodifying the driving environment, which then impacts the video inputs to the\ncar's controller, thereby indirectly leading to incorrect driving decisions.\nSuch attacks require accounting for system dynamics and tracking viewpoint\nchanges. We propose a scalable approach for finding adversarial modifications\nof a simulated autonomous driving environment using a differentiable\napproximation for the mapping from environmental modifications (rectangles on\nthe road) to the corresponding video inputs to the controller neural network.\nGiven the parameters of the rectangles, our proposed differentiable mapping\ncomposites them onto pre-recorded video streams of the original environment,\naccounting for geometric and color variations. Moreover, we propose a multiple\ntrajectory sampling approach that enables our attacks to be robust to a car's\nself-correcting behavior. When combined with a neural network-based controller,\nour approach allows the design of adversarial modifications through end-to-end\ngradient-based optimization. Using the Carla autonomous driving simulator, we\nshow that our approach is significantly more scalable and far more effective at\nidentifying autonomous vehicle vulnerabilities in simulation experiments than a\nstate-of-the-art approach based on Bayesian Optimization.",
          "link": "http://arxiv.org/abs/2010.08844",
          "publishedOn": "2021-06-14T01:38:54.988Z",
          "wordCount": 694,
          "title": "Finding Physical Adversarial Examples for Autonomous Driving with Fast and Differentiable Image Compositing. (arXiv:2010.08844v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.16617",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Acharyya_R/0/1/0/all/0/1\">Rupam Acharyya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chattoraj_A/0/1/0/all/0/1\">Ankani Chattoraj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Boyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1\">Shouman Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stefankovic_D/0/1/0/all/0/1\">Daniel Stefankovic</a>",
          "description": "Deep learning architectures with a huge number of parameters are often\ncompressed using pruning techniques to ensure computational efficiency of\ninference during deployment. Despite multitude of empirical advances, there is\na lack of theoretical understanding of the effectiveness of different pruning\nmethods. We inspect different pruning techniques under the statistical\nmechanics formulation of a teacher-student framework and derive their\ngeneralization error (GE) bounds. It has been shown that Determinantal Point\nProcess (DPP) based node pruning method is notably superior to competing\napproaches when tested on real datasets. Using GE bounds in the aforementioned\nsetup we provide theoretical guarantees for their empirical observations.\nAnother consistent finding in literature is that sparse neural networks (edge\npruned) generalize better than dense neural networks (node pruned) for a fixed\nnumber of parameters. We use our theoretical setup to prove this finding and\nshow that even the baseline random edge pruning method performs better than the\nDPP node pruning method. We also validate this empirically on real datasets.",
          "link": "http://arxiv.org/abs/2006.16617",
          "publishedOn": "2021-06-14T01:38:54.980Z",
          "wordCount": 639,
          "title": "Statistical Mechanical Analysis of Neural Network Pruning. (arXiv:2006.16617v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.07615",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ath_G/0/1/0/all/0/1\">George De Ath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Everson_R/0/1/0/all/0/1\">Richard M. Everson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fieldsend_J/0/1/0/all/0/1\">Jonathan E. Fieldsend</a>",
          "description": "Batch Bayesian optimisation (BO) is a successful technique for the\noptimisation of expensive black-box functions. Asynchronous BO can reduce\nwallclock time by starting a new evaluation as soon as another finishes, thus\nmaximising resource utilisation. To maximise resource allocation, we develop a\nnovel asynchronous BO method, AEGiS (Asynchronous $\\epsilon$-Greedy Global\nSearch) that combines greedy search, exploiting the surrogate's mean\nprediction, with Thompson sampling and random selection from the approximate\nPareto set describing the trade-off between exploitation (surrogate mean\nprediction) and exploration (surrogate posterior variance). We demonstrate\nempirically the efficacy of AEGiS on synthetic benchmark problems,\nmeta-surrogate hyperparameter tuning problems and real-world problems, showing\nthat AEGiS generally outperforms existing methods for asynchronous BO. When a\nsingle worker is available performance is no worse than BO using expected\nimprovement.",
          "link": "http://arxiv.org/abs/2010.07615",
          "publishedOn": "2021-06-14T01:38:54.962Z",
          "wordCount": 625,
          "title": "Asynchronous \\epsilon-Greedy Bayesian Optimisation. (arXiv:2010.07615v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06478",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Liwei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beek_A/0/1/0/all/0/1\">Anton van Beek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Da_D/0/1/0/all/0/1\">Daicong Da</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_Y/0/1/0/all/0/1\">Yu-Chin Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_P/0/1/0/all/0/1\">Ping Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wei Chen</a>",
          "description": "For natural frequency optimization of engineering structures, cellular\ncomposites have been shown to possess an edge over solid. However, existing\nmultiscale design methods for cellular composites are either computationally\nexhaustive or confined to a single class of microstructures. In this paper, we\npropose a data-driven topology optimization (TO) approach to enable the\nmultiscale design of cellular structures with various choices of microstructure\nclasses. The key component is a newly proposed latent-variable Gaussian process\n(LVGP) model through which different classes of microstructures are mapped into\na low-dimensional continuous latent space. It provides an interpretable\ndistance metric between classes and captures their effects on the homogenized\nstiffness tensors. By introducing latent vectors as design variables, a\ndifferentiable transition of stiffness matrix between classes can be easily\nachieved with an analytical gradient. After integrating LVGP with the\ndensity-based TO, an efficient data-driven cellular composite optimization\nprocess is developed to enable concurrent exploration of microstructure\nconcepts and the associated volume fractions for natural frequency\noptimization. Examples reveal that the proposed cellular designs with\nmulticlass microstructures achieve higher natural frequencies than both\nsingle-scale and single-class designs. This framework can be easily extended to\nother multi-scale TO problems, such as thermal compliance and dynamic response\noptimization.",
          "link": "http://arxiv.org/abs/2106.06478",
          "publishedOn": "2021-06-14T01:38:54.954Z",
          "wordCount": 659,
          "title": "Data-Driven Multiscale Design of Cellular Composites with Multiclass Microstructures for Natural Frequency Maximization. (arXiv:2106.06478v1 [cs.CE])"
        },
        {
          "id": "http://arxiv.org/abs/2006.08816",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Cheng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheung_G/0/1/0/all/0/1\">Gene Cheung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1\">Wei Hu</a>",
          "description": "Given a convex and differentiable objective $Q(\\M)$ for a real symmetric\nmatrix $\\M$ in the positive definite (PD) cone -- used to compute Mahalanobis\ndistances -- we propose a fast general metric learning framework that is\nentirely projection-free. We first assume that $\\M$ resides in a space $\\cS$ of\ngeneralized graph Laplacian matrices corresponding to balanced signed graphs.\n$\\M \\in \\cS$ that is also PD is called a graph metric matrix. Unlike low-rank\nmetric matrices common in the literature, $\\cS$ includes the important\ndiagonal-only matrices as a special case. The key theorem to circumvent full\neigen-decomposition and enable fast metric matrix optimization is Gershgorin\ndisc perfect alignment (GDPA): given $\\M \\in \\cS$ and diagonal matrix $\\S$,\nwhere $S_{ii} = 1/v_i$ and $\\v$ is $\\M$'s first eigenvector, we prove that\nGershgorin disc left-ends of similarity transform $\\B = \\S \\M \\S^{-1}$ are\nperfectly aligned at the smallest eigenvalue $\\lambda_{\\min}$. Using this\ntheorem, we replace the PD cone constraint in the metric learning problem with\ntightest possible linear constraints per iteration, so that the alternating\noptimization of the diagonal / off-diagonal terms in $\\M$ can be solved\nefficiently as linear programs via the Frank-Wolfe method. We update $\\v$ using\nLocally Optimal Block Preconditioned Conjugate Gradient (LOBPCG) with warm\nstart as entries in $\\M$ are optimized successively. Experiments show that our\ngraph metric optimization is significantly faster than cone-projection schemes,\nand produces competitive binary classification performance.",
          "link": "http://arxiv.org/abs/2006.08816",
          "publishedOn": "2021-06-14T01:38:54.527Z",
          "wordCount": 731,
          "title": "Signed Graph Metric Learning via Gershgorin Disc Perfect Alignment. (arXiv:2006.08816v6 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.08166",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Makarova_A/0/1/0/all/0/1\">Anastasia Makarova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1\">Huibin Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perrone_V/0/1/0/all/0/1\">Valerio Perrone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klein_A/0/1/0/all/0/1\">Aaron Klein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faddoul_J/0/1/0/all/0/1\">Jean Baptiste Faddoul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krause_A/0/1/0/all/0/1\">Andreas Krause</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seeger_M/0/1/0/all/0/1\">Matthias Seeger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Archambeau_C/0/1/0/all/0/1\">Cedric Archambeau</a>",
          "description": "Tuning machine learning models with Bayesian optimization (BO) is a\nsuccessful strategy to find good hyperparameters. BO defines an iterative\nprocedure where a cross-validated metric is evaluated on promising\nhyperparameters. In practice, however, an improvement of the validation metric\nmay not translate in better predictive performance on a test set, especially\nwhen tuning models trained on small datasets. In other words, unlike\nconventional wisdom dictates, BO can overfit. In this paper, we carry out the\nfirst systematic investigation of overfitting in BO and demonstrate that this\nissue is serious, yet often overlooked in practice. We propose a novel\ncriterion to early stop BO, which aims to maintain the solution quality while\nsaving the unnecessary iterations that can lead to overfitting. Experiments on\nreal-world hyperparameter optimization problems show that our approach\neffectively meets these goals and is more adaptive comparing to baselines.",
          "link": "http://arxiv.org/abs/2104.08166",
          "publishedOn": "2021-06-14T01:38:54.519Z",
          "wordCount": 622,
          "title": "Overfitting in Bayesian Optimization: an empirical study and early-stopping solution. (arXiv:2104.08166v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.11883",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pan_L/0/1/0/all/0/1\">Ling Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rashid_T/0/1/0/all/0/1\">Tabish Rashid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1\">Bei Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1\">Longbo Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Whiteson_S/0/1/0/all/0/1\">Shimon Whiteson</a>",
          "description": "Tackling overestimation in $Q$-learning is an important problem that has been\nextensively studied in single-agent reinforcement learning, but has received\ncomparatively little attention in the multi-agent setting. In this work, we\nempirically demonstrate that QMIX, a popular $Q$-learning algorithm for\ncooperative multi-agent reinforcement learning (MARL), suffers from a more\nsevere overestimation in practice than previously acknowledged, and is not\nmitigated by existing approaches. We rectify this with a novel\nregularization-based update scheme that penalizes large joint action-values\nthat deviate from a baseline and demonstrate its effectiveness in stabilizing\nlearning. Furthermore, we propose to employ a softmax operator, which we\nefficiently approximate in a novel way in the multi-agent setting, to further\nreduce the potential overestimation bias. Our approach, Regularized Softmax\n(RES) Deep Multi-Agent $Q$-Learning, is general and can be applied to any\n$Q$-learning based MARL algorithm. We demonstrate that, when applied to QMIX,\nRES avoids severe overestimation and significantly improves performance,\nyielding state-of-the-art results in a variety of cooperative multi-agent\ntasks, including the challenging StarCraft II micromanagement benchmarks.",
          "link": "http://arxiv.org/abs/2103.11883",
          "publishedOn": "2021-06-14T01:38:54.513Z",
          "wordCount": 622,
          "title": "Regularized Softmax Deep Multi-Agent $Q$-Learning. (arXiv:2103.11883v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.07788",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rozemberczki_B/0/1/0/all/0/1\">Benedek Rozemberczki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scherer_P/0/1/0/all/0/1\">Paul Scherer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yixuan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panagopoulos_G/0/1/0/all/0/1\">George Panagopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riedel_A/0/1/0/all/0/1\">Alexander Riedel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Astefanoaei_M/0/1/0/all/0/1\">Maria Astefanoaei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiss_O/0/1/0/all/0/1\">Oliver Kiss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beres_F/0/1/0/all/0/1\">Ferenc Beres</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lopez_G/0/1/0/all/0/1\">Guzm&#xe1;n L&#xf3;pez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Collignon_N/0/1/0/all/0/1\">Nicolas Collignon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarkar_R/0/1/0/all/0/1\">Rik Sarkar</a>",
          "description": "We present PyTorch Geometric Temporal a deep learning framework combining\nstate-of-the-art machine learning algorithms for neural spatiotemporal signal\nprocessing. The main goal of the library is to make temporal geometric deep\nlearning available for researchers and machine learning practitioners in a\nunified easy-to-use framework. PyTorch Geometric Temporal was created with\nfoundations on existing libraries in the PyTorch eco-system, streamlined neural\nnetwork layer definitions, temporal snapshot generators for batching, and\nintegrated benchmark datasets. These features are illustrated with a\ntutorial-like case study. Experiments demonstrate the predictive performance of\nthe models implemented in the library on real world problems such as\nepidemiological forecasting, ridehail demand prediction and web-traffic\nmanagement. Our sensitivity analysis of runtime shows that the framework can\npotentially operate on web-scale datasets with rich temporal features and\nspatial structure.",
          "link": "http://arxiv.org/abs/2104.07788",
          "publishedOn": "2021-06-14T01:38:54.496Z",
          "wordCount": 627,
          "title": "PyTorch Geometric Temporal: Spatiotemporal Signal Processing with Neural Machine Learning Models. (arXiv:2104.07788v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.06469",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Hao Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jianing Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_G/0/1/0/all/0/1\">Guangxiang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_Z/0/1/0/all/0/1\">Zhizhou Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chongjie Zhang</a>",
          "description": "Episodic memory-based methods can rapidly latch onto past successful\nstrategies by a non-parametric memory and improve sample efficiency of\ntraditional reinforcement learning. However, little effort is put into the\ncontinuous domain, where a state is never visited twice, and previous episodic\nmethods fail to efficiently aggregate experience across trajectories. To\naddress this problem, we propose Generalizable Episodic Memory (GEM), which\neffectively organizes the state-action values of episodic memory in a\ngeneralizable manner and supports implicit planning on memorized trajectories.\nGEM utilizes a double estimator to reduce the overestimation bias induced by\nvalue propagation in the planning process. Empirical evaluation shows that our\nmethod significantly outperforms existing trajectory-based methods on various\nMuJoCo continuous control tasks. To further show the general applicability, we\nevaluate our method on Atari games with discrete action space, which also shows\na significant improvement over baseline algorithms.",
          "link": "http://arxiv.org/abs/2103.06469",
          "publishedOn": "2021-06-14T01:38:54.489Z",
          "wordCount": 606,
          "title": "Generalizable Episodic Memory for Deep Reinforcement Learning. (arXiv:2103.06469v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.07878",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chitra_U/0/1/0/all/0/1\">Uthsav Chitra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_K/0/1/0/all/0/1\">Kimberly Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jasper C.H. Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raphael_B/0/1/0/all/0/1\">Benjamin J. Raphael</a>",
          "description": "Anomaly estimation, or the problem of finding a subset of a dataset that\ndiffers from the rest of the dataset, is a classic problem in machine learning\nand data mining. In both theoretical work and in applications, the anomaly is\nassumed to have a specific structure defined by membership in an\n$\\textit{anomaly family}$. For example, in temporal data the anomaly family may\nbe time intervals, while in network data the anomaly family may be connected\nsubgraphs. The most prominent approach for anomaly estimation is to compute the\nMaximum Likelihood Estimator (MLE) of the anomaly; however, it was recently\nobserved that for normally distributed data, the MLE is a $\\textit{biased}$\nestimator for some anomaly families. In this work, we demonstrate that in the\nnormal means setting, the bias of the MLE depends on the size of the anomaly\nfamily. We prove that if the number of sets in the anomaly family that contain\nthe anomaly is sub-exponential, then the MLE is asymptotically unbiased. We\nalso provide empirical evidence that the converse is true: if the number of\nsuch sets is exponential, then the MLE is asymptotically biased. Our analysis\nunifies a number of earlier results on the bias of the MLE for specific anomaly\nfamilies. Next, we derive a new anomaly estimator using a mixture model, and we\nprove that our anomaly estimator is asymptotically unbiased regardless of the\nsize of the anomaly family. We illustrate the advantages of our estimator\nversus the MLE on disease outbreak and highway traffic data.",
          "link": "http://arxiv.org/abs/2007.07878",
          "publishedOn": "2021-06-14T01:38:54.483Z",
          "wordCount": 731,
          "title": "Quantifying and Reducing Bias in Maximum Likelihood Estimation of Structured Anomalies. (arXiv:2007.07878v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.00100",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Young-min Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_Y/0/1/0/all/0/1\">Young-chul Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_K/0/1/0/all/0/1\">Kwangjin Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeon_M/0/1/0/all/0/1\">Moongu Jeon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Seong-Whan Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pedrycz_W/0/1/0/all/0/1\">Witold Pedrycz</a>",
          "description": "In this paper, we propose a highly practical fully online multi-object\ntracking and segmentation (MOTS) method that uses instance segmentation results\nas an input. The proposed method is based on the Gaussian mixture probability\nhypothesis density (GMPHD) filter, a hierarchical data association (HDA), and a\nmask-based affinity fusion (MAF) model to achieve high-performance online\ntracking. The HDA consists of two associations: segment-to-track and\ntrack-to-track associations. One affinity, for position and motion, is computed\nby using the GMPHD filter, and the other affinity, for appearance is computed\nby using the responses from a single object tracker such as a kernalized\ncorrelation filter. These two affinities are simply fused by using a\nscore-level fusion method such as min-max normalization referred to as MAF. In\naddition, to reduce the number of false positive segments, we adopt mask\nIoU-based merging (mask merging). The proposed MOTS framework with the key\nmodules: HDA, MAF, and mask merging, is easily extensible to simultaneously\ntrack multiple types of objects with CPU only execution in parallel processing.\nIn addition, the developed framework only requires simple parameter tuning\nunlike many existing MOTS methods that need intensive hyperparameter\noptimization. In the experiments on the two popular MOTS datasets, the key\nmodules show some improvements. For instance, ID-switch decreases by more than\nhalf compared to a baseline method in the training sets. In conclusion, our\ntracker achieves state-of-the-art MOTS performance in the test sets.",
          "link": "http://arxiv.org/abs/2009.00100",
          "publishedOn": "2021-06-14T01:38:54.476Z",
          "wordCount": 708,
          "title": "Online Multi-Object Tracking and Segmentation with GMPHD Filter and Mask-based Affinity Fusion. (arXiv:2009.00100v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06427",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Biggio_L/0/1/0/all/0/1\">Luca Biggio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bendinelli_T/0/1/0/all/0/1\">Tommaso Bendinelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neitz_A/0/1/0/all/0/1\">Alexander Neitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lucchi_A/0/1/0/all/0/1\">Aurelien Lucchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parascandolo_G/0/1/0/all/0/1\">Giambattista Parascandolo</a>",
          "description": "Symbolic equations are at the core of scientific discovery. The task of\ndiscovering the underlying equation from a set of input-output pairs is called\nsymbolic regression. Traditionally, symbolic regression methods use\nhand-designed strategies that do not improve with experience. In this paper, we\nintroduce the first symbolic regression method that leverages large scale\npre-training. We procedurally generate an unbounded set of equations, and\nsimultaneously pre-train a Transformer to predict the symbolic equation from a\ncorresponding set of input-output-pairs. At test time, we query the model on a\nnew set of points and use its output to guide the search for the equation. We\nshow empirically that this approach can re-discover a set of well-known\nphysical equations, and that it improves over time with more data and compute.",
          "link": "http://arxiv.org/abs/2106.06427",
          "publishedOn": "2021-06-14T01:38:54.470Z",
          "wordCount": 559,
          "title": "Neural Symbolic Regression that Scales. (arXiv:2106.06427v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2010.04157",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Sitan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koehler_F/0/1/0/all/0/1\">Frederic Koehler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moitra_A/0/1/0/all/0/1\">Ankur Moitra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yau_M/0/1/0/all/0/1\">Morris Yau</a>",
          "description": "In this work we revisit two classic high-dimensional online learning\nproblems, namely linear regression and contextual bandits, from the perspective\nof adversarial robustness. Existing works in algorithmic robust statistics make\nstrong distributional assumptions that ensure that the input data is evenly\nspread out or comes from a nice generative model. Is it possible to achieve\nstrong robustness guarantees even without distributional assumptions\naltogether, where the sequence of tasks we are asked to solve is adaptively and\nadversarially chosen?\n\nWe answer this question in the affirmative for both linear regression and\ncontextual bandits. In fact our algorithms succeed where conventional methods\nfail. In particular we show strong lower bounds against Huber regression and\nmore generally any convex M-estimator. Our approach is based on a novel\nalternating minimization scheme that interleaves ordinary least-squares with a\nsimple convex program that finds the optimal reweighting of the distribution\nunder a spectral constraint. Our results obtain essentially optimal dependence\non the contamination level $\\eta$, reach the optimal breakdown point, and\nnaturally apply to infinite dimensional settings where the feature vectors are\nrepresented implicitly via a kernel map.",
          "link": "http://arxiv.org/abs/2010.04157",
          "publishedOn": "2021-06-14T01:38:54.453Z",
          "wordCount": 672,
          "title": "Online and Distribution-Free Robustness: Regression and Contextual Bandits with Huber Contamination. (arXiv:2010.04157v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06445",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dinh_T/0/1/0/all/0/1\">Tuan Dinh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Kangwook Lee</a>",
          "description": "Inspired by a new coded computation algorithm for invertible functions, we\npropose Coded-InvNet a new approach to design resilient prediction serving\nsystems that can gracefully handle stragglers or node failures. Coded-InvNet\nleverages recent findings in the deep learning literature such as invertible\nneural networks, Manifold Mixup, and domain translation algorithms, identifying\ninteresting research directions that span across machine learning and systems.\nOur experimental results show that Coded-InvNet can outperform existing\napproaches, especially when the compute resource overhead is as low as 10%. For\ninstance, without knowing which of the ten workers is going to fail, our\nalgorithm can design a backup task so that it can correctly recover the missing\nprediction result with an accuracy of 85.9%, significantly outperforming the\nprevious SOTA by 32.5%.",
          "link": "http://arxiv.org/abs/2106.06445",
          "publishedOn": "2021-06-14T01:38:54.446Z",
          "wordCount": 546,
          "title": "Coded-InvNet for Resilient Prediction Serving Systems. (arXiv:2106.06445v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2006.15327",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bar_A/0/1/0/all/0/1\">Amir Bar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Herzig_R/0/1/0/all/0/1\">Roei Herzig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaolong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rohrbach_A/0/1/0/all/0/1\">Anna Rohrbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chechik_G/0/1/0/all/0/1\">Gal Chechik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Darrell_T/0/1/0/all/0/1\">Trevor Darrell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Globerson_A/0/1/0/all/0/1\">Amir Globerson</a>",
          "description": "Videos of actions are complex signals containing rich compositional structure\nin space and time. Current video generation methods lack the ability to\ncondition the generation on multiple coordinated and potentially simultaneous\ntimed actions. To address this challenge, we propose to represent the actions\nin a graph structure called Action Graph and present the new ``Action Graph To\nVideo'' synthesis task. Our generative model for this task (AG2Vid)\ndisentangles motion and appearance features, and by incorporating a scheduling\nmechanism for actions facilitates a timely and coordinated video generation. We\ntrain and evaluate AG2Vid on the CATER and Something-Something V2 datasets, and\nshow that the resulting videos have better visual quality and semantic\nconsistency compared to baselines. Finally, our model demonstrates zero-shot\nabilities by synthesizing novel compositions of the learned actions. For code\nand pretrained models, see the project page https://roeiherz.github.io/AG2Video",
          "link": "http://arxiv.org/abs/2006.15327",
          "publishedOn": "2021-06-14T01:38:54.436Z",
          "wordCount": 631,
          "title": "Compositional Video Synthesis with Action Graphs. (arXiv:2006.15327v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.10618",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_S/0/1/0/all/0/1\">Sushant Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jabbari_S/0/1/0/all/0/1\">Shahin Jabbari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_C/0/1/0/all/0/1\">Chirag Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Upadhyay_S/0/1/0/all/0/1\">Sohini Upadhyay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhiwei Steven Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lakkaraju_H/0/1/0/all/0/1\">Himabindu Lakkaraju</a>",
          "description": "As machine learning black boxes are increasingly being deployed in critical\ndomains such as healthcare and criminal justice, there has been a growing\nemphasis on developing techniques for explaining these black boxes in a post\nhoc manner. In this work, we analyze two popular post hoc interpretation\ntechniques: SmoothGrad which is a gradient based method, and a variant of LIME\nwhich is a perturbation based method. More specifically, we derive explicit\nclosed form expressions for the explanations output by these two methods and\nshow that they both converge to the same explanation in expectation, i.e., when\nthe number of perturbed samples used by these methods is large. We then\nleverage this connection to establish other desirable properties, such as\nrobustness, for these techniques. We also derive finite sample complexity\nbounds for the number of perturbations required for these methods to converge\nto their expected explanation. Finally, we empirically validate our theory\nusing extensive experimentation on both synthetic and real world datasets.",
          "link": "http://arxiv.org/abs/2102.10618",
          "publishedOn": "2021-06-14T01:38:54.429Z",
          "wordCount": 649,
          "title": "Towards the Unification and Robustness of Perturbation and Gradient Based Explanations. (arXiv:2102.10618v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.08085",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yucheng Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sa_C/0/1/0/all/0/1\">Christopher De Sa</a>",
          "description": "Decentralization is a promising method of scaling up parallel machine\nlearning systems. In this paper, we provide a tight lower bound on the\niteration complexity for such methods in a stochastic non-convex setting. Our\nlower bound reveals a theoretical gap in known convergence rates of many\nexisting decentralized training algorithms, such as D-PSGD. We prove by\nconstruction this lower bound is tight and achievable. Motivated by our\ninsights, we further propose DeTAG, a practical gossip-style decentralized\nalgorithm that achieves the lower bound with only a logarithm gap. Empirically,\nwe compare DeTAG with other decentralized algorithms on image classification\ntasks, and we show DeTAG enjoys faster convergence compared to baselines,\nespecially on unshuffled data and in sparse networks.",
          "link": "http://arxiv.org/abs/2006.08085",
          "publishedOn": "2021-06-14T01:38:54.408Z",
          "wordCount": 574,
          "title": "Optimal Complexity in Decentralized Training. (arXiv:2006.08085v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06524",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Serie_E/0/1/0/all/0/1\">Emmanuel S&#xe9;ri&#xe9;</a>",
          "description": "Wax is what you put on a surfboard to avoid slipping. It is an essential tool\nto go surfing... We introduce WAX-ML a research-oriented Python library\nproviding tools to design powerful machine learning algorithms and feedback\nloops working on streaming data. It strives to complement JAX with tools\ndedicated to time series. WAX-ML makes JAX-based programs easy to use for\nend-users working with pandas and xarray for data manipulation. It provides a\nsimple mechanism for implementing feedback loops, allows the implementation of\nonline learning and reinforcement learning algorithms with functions, and makes\nthem easy to integrate by end-users working with the object-oriented\nreinforcement learning framework from the Gym library. It is released with an\nApache open-source license on GitHub at https://github.com/eserie/wax-ml.",
          "link": "http://arxiv.org/abs/2106.06524",
          "publishedOn": "2021-06-14T01:38:54.386Z",
          "wordCount": 560,
          "title": "WAX-ML: A Python library for machine learning and feedback loops on streaming data. (arXiv:2106.06524v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2002.04137",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zifan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jongho Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rekatsinas_T/0/1/0/all/0/1\">Theodoros Rekatsinas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tzamos_C/0/1/0/all/0/1\">Christos Tzamos</a>",
          "description": "We study the problem of robust mean estimation and introduce a novel Hamming\ndistance-based measure of distribution shift for coordinate-level corruptions.\nWe show that this measure yields adversary models that capture more realistic\ncorruptions than those used in prior works, and present an\ninformation-theoretic analysis of robust mean estimation in these settings. We\nshow that for structured distributions, methods that leverage the structure\nyield information theoretically more accurate mean estimation. We also focus on\npractical algorithms for robust mean estimation and study when data\ncleaning-inspired approaches that first fix corruptions in the input data and\nthen perform robust mean estimation can match the information theoretic bounds\nof our analysis. We finally demonstrate experimentally that this two-step\napproach outperforms structure-agnostic robust estimation and provides accurate\nmean estimation even for high-magnitude corruption.",
          "link": "http://arxiv.org/abs/2002.04137",
          "publishedOn": "2021-06-14T01:38:54.378Z",
          "wordCount": 624,
          "title": "On Robust Mean Estimation under Coordinate-level Corruption. (arXiv:2002.04137v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06401",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Belilovsky_E/0/1/0/all/0/1\">Eugene Belilovsky</a> (MILA), <a href=\"http://arxiv.org/find/cs/1/au:+Leconte_L/0/1/0/all/0/1\">Louis Leconte</a> (MLIA, CMAP), <a href=\"http://arxiv.org/find/cs/1/au:+Caccia_L/0/1/0/all/0/1\">Lucas Caccia</a> (MILA), <a href=\"http://arxiv.org/find/cs/1/au:+Eickenberg_M/0/1/0/all/0/1\">Michael Eickenberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oyallon_E/0/1/0/all/0/1\">Edouard Oyallon</a> (MLIA)",
          "description": "A commonly cited inefficiency of neural network training using\nback-propagation is the update locking problem: each layer must wait for the\nsignal to propagate through the full network before updating. Several\nalternatives that can alleviate this issue have been proposed. In this context,\nwe consider a simple alternative based on minimal feedback, which we call\nDecoupled Greedy Learning (DGL). It is based on a classic greedy relaxation of\nthe joint training objective, recently shown to be effective in the context of\nConvolutional Neural Networks (CNNs) on large-scale image classification. We\nconsider an optimization of this objective that permits us to decouple the\nlayer training, allowing for layers or modules in networks to be trained with a\npotentially linear parallelization. With the use of a replay buffer we show\nthat this approach can be extended to asynchronous settings, where modules can\noperate and continue to update with possibly large communication delays. To\naddress bandwidth and memory issues we propose an approach based on online\nvector quantization. This allows to drastically reduce the communication\nbandwidth between modules and required memory for replay buffers. We show\ntheoretically and empirically that this approach converges and compare it to\nthe sequential solvers. We demonstrate the effectiveness of DGL against\nalternative approaches on the CIFAR-10 dataset and on the large-scale ImageNet\ndataset.",
          "link": "http://arxiv.org/abs/2106.06401",
          "publishedOn": "2021-06-14T01:38:54.371Z",
          "wordCount": 672,
          "title": "Decoupled Greedy Learning of CNNs for Synchronous and Asynchronous Distributed Learning. (arXiv:2106.06401v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06510",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Stephenson_W/0/1/0/all/0/1\">William T. Stephenson</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ghosh_S/0/1/0/all/0/1\">Soumya Ghosh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nguyen_T/0/1/0/all/0/1\">Tin D. Nguyen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yurochkin_M/0/1/0/all/0/1\">Mikhail Yurochkin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Deshpande_S/0/1/0/all/0/1\">Sameer K. Deshpande</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Broderick_T/0/1/0/all/0/1\">Tamara Broderick</a>",
          "description": "Gaussian processes (GPs) are used to make medical and scientific decisions,\nincluding in cardiac care and monitoring of carbon dioxide emissions. But the\nchoice of GP kernel is often somewhat arbitrary. In particular, uncountably\nmany kernels typically align with qualitative prior knowledge (e.g. function\nsmoothness or stationarity). But in practice, data analysts choose among a\nhandful of convenient standard kernels (e.g. squared exponential). In the\npresent work, we ask: Would decisions made with a GP differ under other,\nqualitatively interchangeable kernels? We show how to formulate this\nsensitivity analysis as a constrained optimization problem over a\nfinite-dimensional space. We can then use standard optimizers to identify\nsubstantive changes in relevant decisions made with a GP. We demonstrate in\nboth synthetic and real-world examples that decisions made with a GP can\nexhibit substantial sensitivity to kernel choice, even when prior draws are\nqualitatively interchangeable to a user.",
          "link": "http://arxiv.org/abs/2106.06510",
          "publishedOn": "2021-06-14T01:38:54.364Z",
          "wordCount": 585,
          "title": "Measuring the sensitivity of Gaussian processes to kernel choice. (arXiv:2106.06510v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2006.12297",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Nitanda_A/0/1/0/all/0/1\">Atsushi Nitanda</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Suzuki_T/0/1/0/all/0/1\">Taiji Suzuki</a>",
          "description": "We analyze the convergence of the averaged stochastic gradient descent for\noverparameterized two-layer neural networks for regression problems. It was\nrecently found that a neural tangent kernel (NTK) plays an important role in\nshowing the global convergence of gradient-based methods under the NTK regime,\nwhere the learning dynamics for overparameterized neural networks can be almost\ncharacterized by that for the associated reproducing kernel Hilbert space\n(RKHS). However, there is still room for a convergence rate analysis in the NTK\nregime. In this study, we show that the averaged stochastic gradient descent\ncan achieve the minimax optimal convergence rate, with the global convergence\nguarantee, by exploiting the complexities of the target function and the RKHS\nassociated with the NTK. Moreover, we show that the target function specified\nby the NTK of a ReLU network can be learned at the optimal convergence rate\nthrough a smooth approximation of a ReLU network under certain conditions.",
          "link": "http://arxiv.org/abs/2006.12297",
          "publishedOn": "2021-06-14T01:38:54.357Z",
          "wordCount": 604,
          "title": "Optimal Rates for Averaged Stochastic Gradient Descent under Neural Tangent Kernel Regime. (arXiv:2006.12297v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1904.03116",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Souri_Y/0/1/0/all/0/1\">Yaser Souri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fayyaz_M/0/1/0/all/0/1\">Mohsen Fayyaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Minciullo_L/0/1/0/all/0/1\">Luca Minciullo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Francesca_G/0/1/0/all/0/1\">Gianpiero Francesca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gall_J/0/1/0/all/0/1\">Juergen Gall</a>",
          "description": "Action segmentation is the task of predicting the actions for each frame of a\nvideo. As obtaining the full annotation of videos for action segmentation is\nexpensive, weakly supervised approaches that can learn only from transcripts\nare appealing. In this paper, we propose a novel end-to-end approach for weakly\nsupervised action segmentation based on a two-branch neural network. The two\nbranches of our network predict two redundant but different representations for\naction segmentation and we propose a novel mutual consistency (MuCon) loss that\nenforces the consistency of the two redundant representations. Using the MuCon\nloss together with a loss for transcript prediction, our proposed approach\nachieves the accuracy of state-of-the-art approaches while being $14$ times\nfaster to train and $20$ times faster during inference. The MuCon loss proves\nbeneficial even in the fully supervised setting.",
          "link": "http://arxiv.org/abs/1904.03116",
          "publishedOn": "2021-06-14T01:38:54.351Z",
          "wordCount": 638,
          "title": "Fast Weakly Supervised Action Segmentation Using Mutual Consistency. (arXiv:1904.03116v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.03573",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_Y/0/1/0/all/0/1\">Yizi Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liu_M/0/1/0/all/0/1\">Meimei Liu</a>",
          "description": "Recent years have witnessed rapid developments on collaborative filtering\ntechniques for improving the performance of recommender systems due to the\ngrowing need of companies to help users discover new and relevant items.\nHowever, the majority of existing literature focuses on delivering items which\nmatch the user model learned from users' past preferences. A good\nrecommendation model is expected to recommend items that are known to enjoy and\nitems that are novel to try. In this work, we introduce an\nexploitation-exploration motivated variational auto-encoder (XploVAE) to\ncollaborative filtering. To facilitate personalized recommendations, we\nconstruct user-specific subgraphs, which contain the first-order proximity\ncapturing observed user-item interactions for exploitation and the high-order\nproximity for exploration. A hierarchical latent space model is utilized to\nlearn the personalized item embedding for a given user, along with the\npopulation distribution of all user subgraphs. Finally, experimental results on\nvarious real-world datasets clearly demonstrate the effectiveness of our\nproposed model on leveraging the exploitation and exploration recommendation\ntasks.",
          "link": "http://arxiv.org/abs/2006.03573",
          "publishedOn": "2021-06-14T01:38:54.335Z",
          "wordCount": 623,
          "title": "Exploration-Exploitation Motivated Variational Auto-Encoder for Recommender Systems. (arXiv:2006.03573v4 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06536",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jarboui_F/0/1/0/all/0/1\">Firas Jarboui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perchet_V/0/1/0/all/0/1\">Vianney Perchet</a>",
          "description": "We introduce a new procedure to neuralize unsupervised Hidden Markov Models\nin the continuous case. This provides higher flexibility to solve problems with\nunderlying latent variables. This approach is evaluated on both synthetic and\nreal data. On top of generating likely model parameters with comparable\nperformances to off-the-shelf neural architecture (LSTMs, GRUs,..), the\nobtained results are easily interpretable.",
          "link": "http://arxiv.org/abs/2106.06536",
          "publishedOn": "2021-06-14T01:38:54.329Z",
          "wordCount": 484,
          "title": "Unsupervised Neural Hidden Markov Models with a Continuous latent state space. (arXiv:2106.06536v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06515",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhiyuan/0/1/0/all/0/1\">Zhiyuan</a> (Jerry)Lin, <a href=\"http://arxiv.org/find/cs/1/au:+Sheng_H/0/1/0/all/0/1\">Hao Sheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goel_S/0/1/0/all/0/1\">Sharad Goel</a>",
          "description": "In settings ranging from weather forecasts to political prognostications to\nfinancial projections, probability estimates of future binary outcomes often\nevolve over time. For example, the estimated likelihood of rain on a specific\nday changes by the hour as new information becomes available. Given a\ncollection of such probability paths, we introduce a Bayesian framework --\nwhich we call the Gaussian latent information martingale, or GLIM -- for\nmodeling the structure of dynamic predictions over time. Suppose, for example,\nthat the likelihood of rain in a week is 50%, and consider two hypothetical\nscenarios. In the first, one expects the forecast is equally likely to become\neither 25% or 75% tomorrow; in the second, one expects the forecast to stay\nconstant for the next several days. A time-sensitive decision-maker might\nselect a course of action immediately in the latter scenario, but may postpone\ntheir decision in the former, knowing that new information is imminent. We\nmodel these trajectories by assuming predictions update according to a latent\nprocess of information flow, which is inferred from historical data. In\ncontrast to general methods for time series analysis, this approach preserves\nthe martingale structure of probability paths and better quantifies future\nuncertainties around probability paths. We show that GLIM outperforms three\npopular baseline methods, producing better estimated posterior probability path\ndistributions measured by three different metrics. By elucidating the dynamic\nstructure of predictions over time, we hope to help individuals make more\ninformed choices.",
          "link": "http://arxiv.org/abs/2106.06515",
          "publishedOn": "2021-06-14T01:38:54.322Z",
          "wordCount": 671,
          "title": "Probability Paths and the Structure of Predictions over Time. (arXiv:2106.06515v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06498",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Scrugli_M/0/1/0/all/0/1\">Matteo Antonio Scrugli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Loi_D/0/1/0/all/0/1\">Daniela Loi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raffo_L/0/1/0/all/0/1\">Luigi Raffo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meloni_P/0/1/0/all/0/1\">Paolo Meloni</a>",
          "description": "The Internet of Medical Things (IoMT) paradigm is becoming mainstream in\nmultiple clinical trials and healthcare procedures. It relies on novel very\naccurate and compact sensing devices and communication infrastructures, opening\npreviously unmatched possibilities of implementing data collection and\ncontinuous patient monitoring. Nevertheless, to fully exploit the potential of\nthis technology, some steps forwards are needed. First, the edge-computing\nparadigm must be added to the picture. A certain level of near-sensor\nprocessing has to be enabled, to improve the scalability, portability,\nreliability, responsiveness of the IoMT nodes. Second, novel, increasingly\naccurate, data analysis algorithms, such as those based on artificial\nintelligence and Deep Learning, must be exploited. To reach these objectives,\ndesigners, programmers of IoMT nodes, have to face challenging optimization\ntasks, in order to execute fairly complex computing tasks on low-power wearable\nand portable processing systems, with tight power and battery lifetime budgets.\nIn this work, we explore the implementation of cognitive data analysis\nalgorithm on resource-constrained computing platforms. To minimize power\nconsumption, we add an adaptivity layer that dynamically manages the hardware\nand software configuration of the device to adapt it at runtime to the required\noperating mode. We have assessed our approach on a use-case using a\nconvolutional neural network to classify electrocardiogram (ECG) traces on a\nlow-power microcontroller. Our experimental results show that adapting the node\nsetup to the workload at runtime can save up to 50% power consumption and a\nquantized neural network reaches an accuracy value higher than 98% for\narrhythmia disorders detection on MIT-BIH Arrhythmia dataset.",
          "link": "http://arxiv.org/abs/2106.06498",
          "publishedOn": "2021-06-14T01:38:54.306Z",
          "wordCount": 700,
          "title": "An adaptive cognitive sensor node for ECG monitoring in the Internet of Medical Things. (arXiv:2106.06498v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2006.04988",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Voynov_A/0/1/0/all/0/1\">Andrey Voynov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morozov_S/0/1/0/all/0/1\">Stanislav Morozov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Babenko_A/0/1/0/all/0/1\">Artem Babenko</a>",
          "description": "The recent rise of unsupervised and self-supervised learning has dramatically\nreduced the dependency on labeled data, providing effective image\nrepresentations for transfer to downstream vision tasks. Furthermore, recent\nworks employed these representations in a fully unsupervised setup for image\nclassification, reducing the need for human labels on the fine-tuning stage as\nwell. This work demonstrates that large-scale unsupervised models can also\nperform a more challenging object segmentation task, requiring neither\npixel-level nor image-level labeling. Namely, we show that recent unsupervised\nGANs allow to differentiate between foreground/background pixels, providing\nhigh-quality saliency masks. By extensive comparison on standard benchmarks, we\noutperform existing unsupervised alternatives for object segmentation,\nachieving new state-of-the-art.",
          "link": "http://arxiv.org/abs/2006.04988",
          "publishedOn": "2021-06-14T01:38:54.298Z",
          "wordCount": 568,
          "title": "Object Segmentation Without Labels with Large-Scale Generative Models. (arXiv:2006.04988v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06523",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Citron_R/0/1/0/all/0/1\">Robert I. Citron</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Jenniskens_P/0/1/0/all/0/1\">Peter Jenniskens</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Watkins_C/0/1/0/all/0/1\">Christopher Watkins</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Sinha_S/0/1/0/all/0/1\">Sravanthi Sinha</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Shah_A/0/1/0/all/0/1\">Amar Shah</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Raissi_C/0/1/0/all/0/1\">Chedy Raissi</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Devillepoix_H/0/1/0/all/0/1\">Hadrien Devillepoix</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Albers_J/0/1/0/all/0/1\">Jim Albers</a>",
          "description": "The recovery of freshly fallen meteorites from tracked and triangulated\nmeteors is critical to determining their source asteroid families. However,\nlocating meteorite fragments in strewn fields remains a challenge with very few\nmeteorites being recovered from the meteors triangulated in past and ongoing\nmeteor camera networks. We examined if locating meteorites can be automated\nusing machine learning and an autonomous drone. Drones can be programmed to fly\na grid search pattern and take systematic pictures of the ground over a large\nsurvey area. Those images can be analyzed using a machine learning classifier\nto identify meteorites in the field among many other features. Here, we\ndescribe a proof-of-concept meteorite classifier that deploys off-line a\ncombination of different convolution neural networks to recognize meteorites\nfrom images taken by drones in the field. The system was implemented in a\nconceptual drone setup and tested in the suspected strewn field of a recent\nmeteorite fall near Walker Lake, Nevada.",
          "link": "http://arxiv.org/abs/2106.06523",
          "publishedOn": "2021-06-14T01:38:54.290Z",
          "wordCount": 620,
          "title": "Recovery of Meteorites Using an Autonomous Drone and Machine Learning. (arXiv:2106.06523v1 [astro-ph.EP])"
        },
        {
          "id": "http://arxiv.org/abs/1909.11294",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Luo_S/0/1/0/all/0/1\">Simon Luo</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Azizi_L/0/1/0/all/0/1\">Lamiae Azizi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sugiyama_M/0/1/0/all/0/1\">Mahito Sugiyama</a>",
          "description": "We present a novel blind source separation (BSS) method, called information\ngeometric blind source separation (IGBSS). Our formulation is based on the\nlog-linear model equipped with a hierarchically structured sample space, which\nhas theoretical guarantees to uniquely recover a set of source signals by\nminimizing the KL divergence from a set of mixed signals. Source signals,\nreceived signals, and mixing matrices are realized as different layers in our\nhierarchical sample space. Our empirical results have demonstrated on images\nand time series data that our approach is superior to well established\ntechniques and is able to separate signals with complex interactions.",
          "link": "http://arxiv.org/abs/1909.11294",
          "publishedOn": "2021-06-14T01:38:54.282Z",
          "wordCount": 575,
          "title": "Hierarchical Probabilistic Model for Blind Source Separation via Legendre Transformation. (arXiv:1909.11294v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.13300",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ryou_W/0/1/0/all/0/1\">Wonryong Ryou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiayu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balunovic_M/0/1/0/all/0/1\">Mislav Balunovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_G/0/1/0/all/0/1\">Gagandeep Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dan_A/0/1/0/all/0/1\">Andrei Dan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vechev_M/0/1/0/all/0/1\">Martin Vechev</a>",
          "description": "We present a scalable and precise verifier for recurrent neural networks,\ncalled Prover based on two novel ideas: (i) a method to compute a set of\npolyhedral abstractions for the non-convex and nonlinear recurrent update\nfunctions by combining sampling, optimization, and Fermat's theorem, and (ii) a\ngradient descent based algorithm for abstraction refinement guided by the\ncertification problem that combines multiple abstractions for each neuron.\nUsing Prover, we present the first study of certifying a non-trivial use case\nof recurrent neural networks, namely speech classification. To achieve this, we\nadditionally develop custom abstractions for the non-linear speech\npreprocessing pipeline. Our evaluation shows that Prover successfully verifies\nseveral challenging recurrent models in computer vision, speech, and motion\nsensor data classification beyond the reach of prior work.",
          "link": "http://arxiv.org/abs/2005.13300",
          "publishedOn": "2021-06-14T01:38:54.275Z",
          "wordCount": 609,
          "title": "Scalable Polyhedral Verification of Recurrent Neural Networks. (arXiv:2005.13300v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06499",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Javed_Z/0/1/0/all/0/1\">Zaynah Javed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brown_D/0/1/0/all/0/1\">Daniel S. Brown</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1\">Satvik Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jerry Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balakrishna_A/0/1/0/all/0/1\">Ashwin Balakrishna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petrik_M/0/1/0/all/0/1\">Marek Petrik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dragan_A/0/1/0/all/0/1\">Anca D. Dragan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldberg_K/0/1/0/all/0/1\">Ken Goldberg</a>",
          "description": "The difficulty in specifying rewards for many real-world problems has led to\nan increased focus on learning rewards from human feedback, such as\ndemonstrations. However, there are often many different reward functions that\nexplain the human feedback, leaving agents with uncertainty over what the true\nreward function is. While most policy optimization approaches handle this\nuncertainty by optimizing for expected performance, many applications demand\nrisk-averse behavior. We derive a novel policy gradient-style robust\noptimization approach, PG-BROIL, that optimizes a soft-robust objective that\nbalances expected performance and risk. To the best of our knowledge, PG-BROIL\nis the first policy optimization algorithm robust to a distribution of reward\nhypotheses which can scale to continuous MDPs. Results suggest that PG-BROIL\ncan produce a family of behaviors ranging from risk-neutral to risk-averse and\noutperforms state-of-the-art imitation learning algorithms when learning from\nambiguous demonstrations by hedging against uncertainty, rather than seeking to\nuniquely identify the demonstrator's reward function.",
          "link": "http://arxiv.org/abs/2106.06499",
          "publishedOn": "2021-06-14T01:38:54.267Z",
          "wordCount": 601,
          "title": "Policy Gradient Bayesian Robust Optimization for Imitation Learning. (arXiv:2106.06499v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06468",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Junchen Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lindenbaum_O/0/1/0/all/0/1\">Ofir Lindenbaum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kluger_Y/0/1/0/all/0/1\">Yuval Kluger</a>",
          "description": "Despite the enormous success of neural networks, they are still hard to\ninterpret and often overfit when applied to low-sample-size (LSS) datasets. To\ntackle these obstacles, we propose a framework for training locally sparse\nneural networks where the local sparsity is learned via a sample-specific\ngating mechanism that identifies the subset of most relevant features for each\nmeasurement. The sample-specific sparsity is predicted via a \\textit{gating}\nnetwork, which is trained in tandem with the \\textit{prediction} network. By\nlearning these subsets and weights of a prediction model, we obtain an\ninterpretable neural network that can handle LSS data and can remove nuisance\nvariables, which are irrelevant for the supervised learning task. Using both\nsynthetic and real-world datasets, we demonstrate that our method outperforms\nstate-of-the-art models when predicting the target function with far fewer\nfeatures per instance.",
          "link": "http://arxiv.org/abs/2106.06468",
          "publishedOn": "2021-06-14T01:38:54.260Z",
          "wordCount": 557,
          "title": "Locally Sparse Networks for Interpretable Predictions. (arXiv:2106.06468v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06333",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yifei Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yezhen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">Wenzhen Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reed_C/0/1/0/all/0/1\">Colorado J. Reed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Che_T/0/1/0/all/0/1\">Tong Che</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dongsheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keutzer_K/0/1/0/all/0/1\">Kurt Keutzer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Han Zhao</a>",
          "description": "The main challenge for domain generalization (DG) is to overcome the\npotential distributional shift between multiple training domains and unseen\ntest domains. One popular class of DG algorithms aims to learn representations\nthat have an invariant causal relation across the training domains. However,\ncertain features, called \\emph{pseudo-invariant features}, may be invariant in\nthe training domain but not the test domain and can substantially decreases the\nperformance of existing algorithms. To address this issue, we propose a novel\nalgorithm, called Invariant Information Bottleneck (IIB), that learns a\nminimally sufficient representation that is invariant across training and\ntesting domains. By minimizing the mutual information between the\nrepresentation and inputs, IIB alleviates its reliance on pseudo-invariant\nfeatures, which is desirable for DG. To verify the effectiveness of the IIB\nprinciple, we conduct extensive experiments on large-scale DG benchmarks. The\nresults show that IIB outperforms invariant learning baseline (e.g. IRM) by an\naverage of 2.8\\% and 3.8\\% accuracy over two evaluation metrics.",
          "link": "http://arxiv.org/abs/2106.06333",
          "publishedOn": "2021-06-14T01:38:54.253Z",
          "wordCount": 596,
          "title": "Invariant Information Bottleneck for Domain Generalization. (arXiv:2106.06333v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06338",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Malezieux_B/0/1/0/all/0/1\">Beno&#xee;t Mal&#xe9;zieux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moreau_T/0/1/0/all/0/1\">Thomas Moreau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kowalski_M/0/1/0/all/0/1\">Matthieu Kowalski</a>",
          "description": "Inverse problems consist in recovering a signal given noisy observations. One\nclassical resolution approach is to leverage sparsity and integrate prior\nknowledge of the signal to the reconstruction algorithm to get a plausible\nsolution. Still, this prior might not be sufficiently adapted to the data. In\nthis work, we study Dictionary and Prior learning from degraded measurements as\na bi-level problem, and we take advantage of unrolled algorithms to solve\napproximate formulations of Synthesis and Analysis. We provide an empirical and\ntheoretical analysis of automatic differentiation for Dictionary Learning to\nunderstand better the pros and cons of unrolling in this context. We find that\nunrolled algorithms speed up the recovery process for a small number of\niterations by improving the gradient estimation. Then we compare Analysis and\nSynthesis by evaluating the performance of unrolled algorithms for inverse\nproblems, without access to any ground truth data for several classes of\ndictionaries and priors. While Analysis can achieve good results,Synthesis is\nmore robust and performs better. Finally, we illustrate our method on pattern\nand structure learning tasks from degraded measurements.",
          "link": "http://arxiv.org/abs/2106.06338",
          "publishedOn": "2021-06-14T01:38:54.244Z",
          "wordCount": 617,
          "title": "Dictionary and prior learning with unrolled algorithms for unsupervised inverse problems. (arXiv:2106.06338v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06430",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wolf_L/0/1/0/all/0/1\">Laura M. Wolf</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Baum_M/0/1/0/all/0/1\">Marcus Baum</a>",
          "description": "Herding is a technique to sequentially generate deterministic samples from a\nprobability distribution. In this work, we propose a continuous herded Gibbs\nsampler, that combines kernel herding on continuous densities with Gibbs\nsampling. Our algorithm allows for deterministically sampling from\nhigh-dimensional multivariate probability densities, without directly sampling\nfrom the joint density. Experiments with Gaussian mixture densities indicate\nthat the L2 error decreases similarly to kernel herding, while the computation\ntime is significantly lower, i.e., linear in the number of dimensions.",
          "link": "http://arxiv.org/abs/2106.06430",
          "publishedOn": "2021-06-14T01:38:54.214Z",
          "wordCount": 512,
          "title": "Continuous Herded Gibbs Sampling. (arXiv:2106.06430v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06469",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1\">Songzhu Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yikai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wagner_H/0/1/0/all/0/1\">Hubert Wagner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goswami_M/0/1/0/all/0/1\">Mayank Goswami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chao Chen</a>",
          "description": "Deep neural networks are known to have security issues. One particular threat\nis the Trojan attack. It occurs when the attackers stealthily manipulate the\nmodel's behavior through Trojaned training samples, which can later be\nexploited.\n\nGuided by basic neuroscientific principles we discover subtle -- yet critical\n-- structural deviation characterizing Trojaned models. In our analysis we use\ntopological tools. They allow us to model high-order dependencies in the\nnetworks, robustly compare different networks, and localize structural\nabnormalities. One interesting observation is that Trojaned models develop\nshort-cuts from input to output layers.\n\nInspired by these observations, we devise a strategy for robust detection of\nTrojaned models. Compared to standard baselines it displays better performance\non multiple benchmarks.",
          "link": "http://arxiv.org/abs/2106.06469",
          "publishedOn": "2021-06-14T01:38:54.194Z",
          "wordCount": 542,
          "title": "Topological Detection of Trojaned Neural Networks. (arXiv:2106.06469v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06406",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lee_S/0/1/0/all/0/1\">Sang-gil Lee</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kim_H/0/1/0/all/0/1\">Heeseung Kim</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shin_C/0/1/0/all/0/1\">Chaehun Shin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tan_X/0/1/0/all/0/1\">Xu Tan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liu_C/0/1/0/all/0/1\">Chang Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Meng_Q/0/1/0/all/0/1\">Qi Meng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Qin_T/0/1/0/all/0/1\">Tao Qin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chen_W/0/1/0/all/0/1\">Wei Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yoon_S/0/1/0/all/0/1\">Sungroh Yoon</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liu_T/0/1/0/all/0/1\">Tie-Yan Liu</a>",
          "description": "Denoising diffusion probabilistic models have been recently proposed to\ngenerate high-quality samples by estimating the gradient of the data density.\nThe framework assumes the prior noise as a standard Gaussian distribution,\nwhereas the corresponding data distribution may be more complicated than the\nstandard Gaussian distribution, which potentially introduces inefficiency in\ndenoising the prior noise into the data sample because of the discrepancy\nbetween the data and the prior. In this paper, we propose PriorGrad to improve\nthe efficiency of the conditional diffusion model (for example, a vocoder using\na mel-spectrogram as the condition) by applying an adaptive prior derived from\nthe data statistics based on the conditional information. We formulate the\ntraining and sampling procedures of PriorGrad and demonstrate the advantages of\nan adaptive prior through a theoretical analysis. Focusing on the audio domain,\nwe consider the recently proposed diffusion-based audio generative models based\non both the spectral and time domains and show that PriorGrad achieves a faster\nconvergence leading to data and parameter efficiency and improved quality, and\nthereby demonstrating the efficiency of a data-driven adaptive prior.",
          "link": "http://arxiv.org/abs/2106.06406",
          "publishedOn": "2021-06-14T01:38:54.165Z",
          "wordCount": 644,
          "title": "PriorGrad: Improving Conditional Denoising Diffusion Models with Data-Driven Adaptive Prior. (arXiv:2106.06406v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06431",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rezaeifar_S/0/1/0/all/0/1\">Shideh Rezaeifar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dadashi_R/0/1/0/all/0/1\">Robert Dadashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vieillard_N/0/1/0/all/0/1\">Nino Vieillard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hussenot_L/0/1/0/all/0/1\">L&#xe9;onard Hussenot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bachem_O/0/1/0/all/0/1\">Olivier Bachem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pietquin_O/0/1/0/all/0/1\">Olivier Pietquin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geist_M/0/1/0/all/0/1\">Matthieu Geist</a>",
          "description": "Offline Reinforcement Learning (RL) aims at learning an optimal control from\na fixed dataset, without interactions with the system. An agent in this setting\nshould avoid selecting actions whose consequences cannot be predicted from the\ndata. This is the converse of exploration in RL, which favors such actions. We\nthus take inspiration from the literature on bonus-based exploration to design\na new offline RL agent. The core idea is to subtract a prediction-based\nexploration bonus from the reward, instead of adding it for exploration. This\nallows the policy to stay close to the support of the dataset. We connect this\napproach to a more common regularization of the learned policy towards the\ndata. Instantiated with a bonus based on the prediction error of a variational\nautoencoder, we show that our agent is competitive with the state of the art on\na set of continuous control locomotion and manipulation tasks.",
          "link": "http://arxiv.org/abs/2106.06431",
          "publishedOn": "2021-06-14T01:38:54.158Z",
          "wordCount": 574,
          "title": "Offline Reinforcement Learning as Anti-Exploration. (arXiv:2106.06431v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06345",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bunne_C/0/1/0/all/0/1\">Charlotte Bunne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Papaxanthos_L/0/1/0/all/0/1\">Laetitia Meng-Papaxanthos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krause_A/0/1/0/all/0/1\">Andreas Krause</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cuturi_M/0/1/0/all/0/1\">Marco Cuturi</a>",
          "description": "Consider a heterogeneous population of points evolving with time. While the\npopulation evolves, both in size and nature, we can observe it periodically,\nthrough snapshots taken at different timestamps. Each of these snapshots is\nformed by sampling points from the population at that time, and then creating\nfeatures to recover point clouds. While these snapshots describe the\npopulation's evolution on aggregate, they do not provide directly insights on\nindividual trajectories. This scenario is encountered in several applications,\nnotably single-cell genomics experiments, tracking of particles, or when\nstudying crowd motion. In this paper, we propose to model that dynamic as\nresulting from the celebrated Jordan-Kinderlehrer-Otto (JKO) proximal scheme.\nThe JKO scheme posits that the configuration taken by a population at time $t$\nis one that trades off a decrease w.r.t. an energy (the model we seek to learn)\npenalized by an optimal transport distance w.r.t. the previous configuration.\nTo that end, we propose JKOnet, a neural architecture that combines an energy\nmodel on measures, with (small) optimal displacements solved with input convex\nneural networks (ICNN). We demonstrate the applicability of our model to\nexplain and predict population dynamics.",
          "link": "http://arxiv.org/abs/2106.06345",
          "publishedOn": "2021-06-14T01:38:54.151Z",
          "wordCount": 610,
          "title": "JKOnet: Proximal Optimal Transport Modeling of Population Dynamics. (arXiv:2106.06345v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06153",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Teng_J/0/1/0/all/0/1\">Jiaye Teng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jianhao Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1\">Yang Yuan</a>",
          "description": "Generalization is one of the critical issues in machine learning. However,\ntraditional methods like uniform convergence are not powerful enough to fully\nexplain generalization because they may yield vacuous bounds even in\noverparameterized linear regression regimes. An alternative solution is to\nanalyze the generalization dynamics to derive algorithm-dependent bounds, e.g.,\nstability. Unfortunately, the stability-based bound is still far from\nexplaining the remarkable generalization ability of neural networks due to the\ncoarse-grained analysis of the signal and noise. Inspired by the observation\nthat neural networks show a slow convergence rate when fitting noise, we\npropose decomposing the excess risk dynamics and applying stability-based bound\nonly on the variance part (which measures how the model performs on pure\nnoise). We provide two applications for the framework, including a linear case\n(overparameterized linear regression with gradient descent) and a non-linear\ncase (matrix recovery with gradient flow). Under the decomposition framework,\nthe new bound accords better with the theoretical and empirical evidence\ncompared to the stability-based bound and uniform convergence bound.",
          "link": "http://arxiv.org/abs/2106.06153",
          "publishedOn": "2021-06-14T01:38:54.144Z",
          "wordCount": 598,
          "title": "Towards Understanding Generalization via Decomposing Excess Risk Dynamics. (arXiv:2106.06153v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06508",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Anand_N/0/1/0/all/0/1\">Nishanth Anand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Precup_D/0/1/0/all/0/1\">Doina Precup</a>",
          "description": "Temporal-Difference (TD) learning is a general and very useful tool for\nestimating the value function of a given policy, which in turn is required to\nfind good policies. Generally speaking, TD learning updates states whenever\nthey are visited. When the agent lands in a state, its value can be used to\ncompute the TD-error, which is then propagated to other states. However, it may\nbe interesting, when computing updates, to take into account other information\nthan whether a state is visited or not. For example, some states might be more\nimportant than others (such as states which are frequently seen in a successful\ntrajectory). Or, some states might have unreliable value estimates (for\nexample, due to partial observability or lack of data), making their values\nless desirable as targets. We propose an approach to re-weighting states used\nin TD updates, both when they are the input and when they provide the target\nfor the update. We prove that our approach converges with linear function\napproximation and illustrate its desirable empirical behaviour compared to\nother TD-style methods.",
          "link": "http://arxiv.org/abs/2106.06508",
          "publishedOn": "2021-06-14T01:38:54.137Z",
          "wordCount": 603,
          "title": "Preferential Temporal Difference Learning. (arXiv:2106.06508v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06530",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Damian_A/0/1/0/all/0/1\">Alex Damian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1\">Tengyu Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jason Lee</a>",
          "description": "In overparametrized models, the noise in stochastic gradient descent (SGD)\nimplicitly regularizes the optimization trajectory and determines which local\nminimum SGD converges to. Motivated by empirical studies that demonstrate that\ntraining with noisy labels improves generalization, we study the implicit\nregularization effect of SGD with label noise. We show that SGD with label\nnoise converges to a stationary point of a regularized loss $L(\\theta) +\\lambda\nR(\\theta)$, where $L(\\theta)$ is the training loss, $\\lambda$ is an effective\nregularization parameter depending on the step size, strength of the label\nnoise, and the batch size, and $R(\\theta)$ is an explicit regularizer that\npenalizes sharp minimizers. Our analysis uncovers an additional regularization\neffect of large learning rates beyond the linear scaling rule that penalizes\nlarge eigenvalues of the Hessian more than small ones. We also prove extensions\nto classification with general loss functions, SGD with momentum, and SGD with\ngeneral noise covariance, significantly strengthening the prior work of Blanc\net al. to global convergence and large learning rates and of HaoChen et al. to\ngeneral models.",
          "link": "http://arxiv.org/abs/2106.06530",
          "publishedOn": "2021-06-14T01:38:54.117Z",
          "wordCount": 620,
          "title": "Label Noise SGD Provably Prefers Flat Global Minimizers. (arXiv:2106.06530v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06307",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nazir_U/0/1/0/all/0/1\">Usman Nazir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">He Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taj_M/0/1/0/all/0/1\">Murtaza Taj</a>",
          "description": "In this survey paper, we analyze image based graph neural networks and\npropose a three-step classification approach. We first convert the image into\nsuperpixels using the Quickshift algorithm so as to reduce 30% of the input\ndata. The superpixels are subsequently used to generate a region adjacency\ngraph. Finally, the graph is passed through a state-of-art graph convolutional\nneural network to get classification scores. We also analyze the spatial and\nspectral convolution filtering techniques in graph neural networks.\nSpectral-based models perform better than spatial-based models and classical\nCNN with lesser compute cost.",
          "link": "http://arxiv.org/abs/2106.06307",
          "publishedOn": "2021-06-14T01:38:54.108Z",
          "wordCount": 522,
          "title": "Survey of Image Based Graph Neural Networks. (arXiv:2106.06307v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06410",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chapman_A/0/1/0/all/0/1\">Adriane Chapman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_G/0/1/0/all/0/1\">Guihua Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hall_D/0/1/0/all/0/1\">Dame Wendy Hall</a>",
          "description": "Supervised machine learning has several drawbacks that make it difficult to\nuse in many situations. Drawbacks include: heavy reliance on massive training\ndata, limited generalizability and poor expressiveness of high-level semantics.\nLow-shot Learning attempts to address these drawbacks. Low-shot learning allows\nthe model to obtain good predictive power with very little or no training data,\nwhere structured knowledge plays a key role as a high-level semantic\nrepresentation of human. This article will review the fundamental factors of\nlow-shot learning technologies, with a focus on the operation of structured\nknowledge under different low-shot conditions. We also introduce other\ntechniques relevant to low-shot learning. Finally, we point out the limitations\nof low-shot learning, the prospects and gaps of industrial applications, and\nfuture research directions.",
          "link": "http://arxiv.org/abs/2106.06410",
          "publishedOn": "2021-06-14T01:38:54.102Z",
          "wordCount": 573,
          "title": "What Can Knowledge Bring to Machine Learning? -- A Survey of Low-shot Learning for Structured Data. (arXiv:2106.06410v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06356",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_Q/0/1/0/all/0/1\">Quan Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Modiri_A/0/1/0/all/0/1\">Arghavan Modiri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garnett_R/0/1/0/all/0/1\">Roman Garnett</a>",
          "description": "Active search is a learning paradigm where we seek to identify as many\nmembers of a rare, valuable class as possible given a labeling budget. Previous\nwork on active search has assumed access to a faithful (and expensive) oracle\nreporting experimental results. However, some settings offer access to cheaper\nsurrogates such as computational simulation that may aid in the search. We\npropose a model of multifidelity active search, as well as a novel,\ncomputationally efficient policy for this setting that is motivated by\nstate-of-the-art classical policies. Our policy is nonmyopic and budget aware,\nallowing for a dynamic tradeoff between exploration and exploitation. We\nevaluate the performance of our solution on real-world datasets and demonstrate\nsignificantly better performance than natural benchmarks.",
          "link": "http://arxiv.org/abs/2106.06356",
          "publishedOn": "2021-06-14T01:38:54.095Z",
          "wordCount": 539,
          "title": "Nonmyopic Multifidelity Active Search. (arXiv:2106.06356v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06189",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chen_X/0/1/0/all/0/1\">Xiaohui Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Han_X/0/1/0/all/0/1\">Xu Han</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hu_J/0/1/0/all/0/1\">Jiajing Hu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ruiz_F/0/1/0/all/0/1\">Francisco J. R. Ruiz</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liu_L/0/1/0/all/0/1\">Liping Liu</a>",
          "description": "A graph generative model defines a distribution over graphs. One type of\ngenerative model is constructed by autoregressive neural networks, which\nsequentially add nodes and edges to generate a graph. However, the likelihood\nof a graph under the autoregressive model is intractable, as there are numerous\nsequences leading to the given graph; this makes maximum likelihood estimation\nchallenging. Instead, in this work we derive the exact joint probability over\nthe graph and the node ordering of the sequential process. From the joint, we\napproximately marginalize out the node orderings and compute a lower bound on\nthe log-likelihood using variational inference. We train graph generative\nmodels by maximizing this bound, without using the ad-hoc node orderings of\nprevious methods. Our experiments show that the log-likelihood bound is\nsignificantly tighter than the bound of previous schemes. Moreover, the models\nfitted with the proposed algorithm can generate high-quality graphs that match\nthe structures of target graphs not seen during training. We have made our code\npublicly available at\n\\hyperref[https://github.com/tufts-ml/graph-generation-vi]{https://github.com/tufts-ml/graph-generation-vi}.",
          "link": "http://arxiv.org/abs/2106.06189",
          "publishedOn": "2021-06-14T01:38:54.088Z",
          "wordCount": 614,
          "title": "Order Matters: Probabilistic Modeling of Node Sequence for Graph Generation. (arXiv:2106.06189v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06312",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhaomin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qinbin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_B/0/1/0/all/0/1\">Bingsheng He</a>",
          "description": "As the privacy of machine learning has drawn increasing attention, federated\nlearning is introduced to enable collaborative learning without revealing raw\ndata. Notably, \\textit{vertical federated learning} (VFL), where parties share\nthe same set of samples but only hold partial features, has a wide range of\nreal-world applications. However, existing studies in VFL rarely study the\n``record linkage'' process. They either design algorithms assuming the data\nfrom different parties have been linked or use simple linkage methods like\nexact-linkage or top1-linkage. These approaches are unsuitable for many\napplications, such as the GPS location and noisy titles requiring fuzzy\nmatching. In this paper, we design a novel similarity-based VFL framework,\nFedSim, which is suitable for more real-world applications and achieves higher\nperformance on traditional VFL tasks. Moreover, we theoretically analyze the\nprivacy risk caused by sharing similarities. Our experiments on three synthetic\ndatasets and five real-world datasets with various similarity metrics show that\nFedSim consistently outperforms other state-of-the-art baselines.",
          "link": "http://arxiv.org/abs/2106.06312",
          "publishedOn": "2021-06-14T01:38:54.068Z",
          "wordCount": 584,
          "title": "Exploiting Record Similarity for Practical Vertical Federated Learning. (arXiv:2106.06312v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06452",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wen_C/0/1/0/all/0/1\">Chuan Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jierui Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_J/0/1/0/all/0/1\">Jianing Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yang Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jayaraman_D/0/1/0/all/0/1\">Dinesh Jayaraman</a>",
          "description": "Imitation learning trains control policies by mimicking pre-recorded expert\ndemonstrations. In partially observable settings, imitation policies must rely\non observation histories, but many seemingly paradoxical results show better\nperformance for policies that only access the most recent observation. Recent\nsolutions ranging from causal graph learning to deep information bottlenecks\nhave shown promising results, but failed to scale to realistic settings such as\nvisual imitation. We propose a solution that outperforms these prior approaches\nby upweighting demonstration keyframes corresponding to expert action\nchangepoints. This simple approach easily scales to complex visual imitation\nsettings. Our experimental results demonstrate consistent performance\nimprovements over all baselines on image-based Gym MuJoCo continuous control\ntasks. Finally, on the CARLA photorealistic vision-based urban driving\nsimulator, we resolve a long-standing issue in behavioral cloning for driving\nby demonstrating effective imitation from observation histories. Supplementary\nmaterials and code at: \\url{https://tinyurl.com/imitation-keyframes}.",
          "link": "http://arxiv.org/abs/2106.06452",
          "publishedOn": "2021-06-14T01:38:54.061Z",
          "wordCount": 570,
          "title": "Keyframe-Focused Visual Imitation Learning. (arXiv:2106.06452v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06012",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Laakom_F/0/1/0/all/0/1\">Firas Laakom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raitoharju_J/0/1/0/all/0/1\">Jenni Raitoharju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iosifidis_A/0/1/0/all/0/1\">Alexandros Iosifidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gabbouj_M/0/1/0/all/0/1\">Moncef Gabbouj</a>",
          "description": "Neural networks are composed of multiple layers arranged in a hierarchical\nstructure jointly trained with a gradient-based optimization, where the errors\nare back-propagated from the last layer back to the first one. At each\noptimization step, neurons at a given layer receive feedback from neurons\nbelonging to higher layers of the hierarchy. In this paper, we propose to\ncomplement this traditional 'between-layer' feedback with additional\n'within-layer' feedback to encourage diversity of the activations within the\nsame layer. To this end, we measure the pairwise similarity between the outputs\nof the neurons and use it to model the layer's overall diversity. By penalizing\nsimilarities and promoting diversity, we encourage each neuron to learn a\ndistinctive representation and, thus, to enrich the data representation learned\nwithin the layer and to increase the total capacity of the model. We\ntheoretically study how the within-layer activation diversity affects the\ngeneralization performance of a neural network and prove that increasing the\ndiversity of hidden activations reduces the estimation error. In addition to\nthe theoretical guarantees, we present an empirical study on three datasets\nconfirming that the proposed approach enhances the performance of\nstate-of-the-art neural network models and decreases the generalization gap.",
          "link": "http://arxiv.org/abs/2106.06012",
          "publishedOn": "2021-06-14T01:38:54.054Z",
          "wordCount": 628,
          "title": "Within-layer Diversity Reduces Generalization Gap. (arXiv:2106.06012v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06297",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hombaiah_S/0/1/0/all/0/1\">Spurthi Amba Hombaiah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mingyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bendersky_M/0/1/0/all/0/1\">Michael Bendersky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Najork_M/0/1/0/all/0/1\">Marc Najork</a>",
          "description": "The content on the web is in a constant state of flux. New entities, issues,\nand ideas continuously emerge, while the semantics of the existing conversation\ntopics gradually shift. In recent years, pre-trained language models like BERT\ngreatly improved the state-of-the-art for a large spectrum of content\nunderstanding tasks. Therefore, in this paper, we aim to study how these\nlanguage models can be adapted to better handle continuously evolving web\ncontent. In our study, we first analyze the evolution of 2013 - 2019 Twitter\ndata, and unequivocally confirm that a BERT model trained on past tweets would\nheavily deteriorate when directly applied to data from later years. Then, we\ninvestigate two possible sources of the deterioration: the semantic shift of\nexisting tokens and the sub-optimal or failed understanding of new tokens. To\nthis end, we both explore two different vocabulary composition methods, as well\nas propose three sampling methods which help in efficient incremental training\nfor BERT-like models. Compared to a new model trained from scratch offline, our\nincremental training (a) reduces the training costs, (b) achieves better\nperformance on evolving content, and (c) is suitable for online deployment. The\nsuperiority of our methods is validated using two downstream tasks. We\ndemonstrate significant improvements when incrementally evolving the model from\na particular base year, on the task of Country Hashtag Prediction, as well as\non the OffensEval 2019 task.",
          "link": "http://arxiv.org/abs/2106.06297",
          "publishedOn": "2021-06-14T01:38:54.047Z",
          "wordCount": 666,
          "title": "Dynamic Language Models for Continuously Evolving Content. (arXiv:2106.06297v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06321",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bana_T/0/1/0/all/0/1\">Tejas Bana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Loya_J/0/1/0/all/0/1\">Jatan Loya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulkarni_S/0/1/0/all/0/1\">Siddhant Kulkarni</a>",
          "description": "Studies involving colourising images has been garnering researchers' keen\nattention over time, assisted by significant advances in various Machine\nLearning techniques and compute power availability. Traditionally, colourising\nimages have been an intricate task that gave a substantial degree of freedom\nduring the assignment of chromatic information. In our proposed method, we\nattempt to colourise images using Vision Transformer - Inception - Generative\nAdversarial Network (ViT-I-GAN), which has an Inception-v3 fusion embedding in\nthe generator. For a stable and robust network, we have used Vision Transformer\n(ViT) as the discriminator. We trained the model on the Unsplash and the COCO\ndataset for demonstrating the improvement made by the Inception-v3 embedding.\nWe have compared the results between ViT-GANs with and without Inception-v3\nembedding.",
          "link": "http://arxiv.org/abs/2106.06321",
          "publishedOn": "2021-06-14T01:38:54.040Z",
          "wordCount": 547,
          "title": "ViT-Inception-GAN for Image Colourising. (arXiv:2106.06321v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06218",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yun_S/0/1/0/all/0/1\">Seongjun Yun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeong_M/0/1/0/all/0/1\">Minbyul Jeong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoo_S/0/1/0/all/0/1\">Sungdong Yoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Seunghun Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_S/0/1/0/all/0/1\">Sean S. Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_R/0/1/0/all/0/1\">Raehyun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_J/0/1/0/all/0/1\">Jaewoo Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyunwoo J. Kim</a>",
          "description": "Graph Neural Networks (GNNs) have been widely applied to various fields due\nto their powerful representations of graph-structured data. Despite the success\nof GNNs, most existing GNNs are designed to learn node representations on the\nfixed and homogeneous graphs. The limitations especially become problematic\nwhen learning representations on a misspecified graph or a heterogeneous graph\nthat consists of various types of nodes and edges. To address this limitations,\nwe propose Graph Transformer Networks (GTNs) that are capable of generating new\ngraph structures, which preclude noisy connections and include useful\nconnections (e.g., meta-paths) for tasks, while learning effective node\nrepresentations on the new graphs in an end-to-end fashion. We further propose\nenhanced version of GTNs, Fast Graph Transformer Networks (FastGTNs), that\nimprove scalability of graph transformations. Compared to GTNs, FastGTNs are\n230x faster and use 100x less memory while allowing the identical graph\ntransformations as GTNs. In addition, we extend graph transformations to the\nsemantic proximity of nodes allowing non-local operations beyond meta-paths.\nExtensive experiments on both homogeneous graphs and heterogeneous graphs show\nthat GTNs and FastGTNs with non-local operations achieve the state-of-the-art\nperformance for node classification tasks. The code is available:\nhttps://github.com/seongjunyun/Graph_Transformer_Networks",
          "link": "http://arxiv.org/abs/2106.06218",
          "publishedOn": "2021-06-14T01:38:54.033Z",
          "wordCount": 647,
          "title": "Graph Transformer Networks: Learning Meta-path Graphs to Improve GNNs. (arXiv:2106.06218v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06261",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hosp_B/0/1/0/all/0/1\">Benedikt Hosp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_M/0/1/0/all/0/1\">Myat Su Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haddawy_p/0/1/0/all/0/1\">peter Haddawy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watcharporas_R/0/1/0/all/0/1\">Ratthapoom Watcharporas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sa_ngasoonsong_p/0/1/0/all/0/1\">paphon Sa-ngasoonsong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kasneci_E/0/1/0/all/0/1\">Enkelejda Kasneci</a>",
          "description": "During arthroscopic surgeries, surgeons are faced with challenges like\ncognitive re-projection of the 2D screen output into the 3D operating site or\nnavigation through highly similar tissue. Training of these cognitive processes\ntakes much time and effort for young surgeons, but is necessary and crucial for\ntheir education. In this study we want to show how to recognize states of\nconfusion of young surgeons during an arthroscopic surgery, by looking at their\neye and head movements and feeding them to a machine learning model. With an\naccuracy of over 94\\% and detection speed of 0.039 seconds, our model is a step\ntowards online diagnostic and training systems for the perceptual-cognitive\nprocesses of surgeons during arthroscopic surgeries.",
          "link": "http://arxiv.org/abs/2106.06261",
          "publishedOn": "2021-06-14T01:38:54.010Z",
          "wordCount": 558,
          "title": "States of confusion: Eye and Head tracking reveal surgeons' confusion during arthroscopic surgery. (arXiv:2106.06261v1 [cs.HC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06385",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Manduchi_L/0/1/0/all/0/1\">Laura Manduchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chin_Cheong_K/0/1/0/all/0/1\">Kieran Chin-Cheong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Michel_H/0/1/0/all/0/1\">Holger Michel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wellmann_S/0/1/0/all/0/1\">Sven Wellmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogt_J/0/1/0/all/0/1\">Julia E. Vogt</a>",
          "description": "Constrained clustering has gained significant attention in the field of\nmachine learning as it can leverage prior information on a growing amount of\nonly partially labeled data. Following recent advances in deep generative\nmodels, we propose a novel framework for constrained clustering that is\nintuitive, interpretable, and can be trained efficiently in the framework of\nstochastic gradient variational inference. By explicitly integrating domain\nknowledge in the form of probabilistic relations, our proposed model (DC-GMM)\nuncovers the underlying distribution of data conditioned on prior clustering\npreferences, expressed as pairwise constraints. These constraints guide the\nclustering process towards a desirable partition of the data by indicating\nwhich samples should or should not belong to the same cluster. We provide\nextensive experiments to demonstrate that DC-GMM shows superior clustering\nperformances and robustness compared to state-of-the-art deep constrained\nclustering methods on a wide range of data sets. We further demonstrate the\nusefulness of our approach on two challenging real-world applications.",
          "link": "http://arxiv.org/abs/2106.06385",
          "publishedOn": "2021-06-14T01:38:54.003Z",
          "wordCount": 582,
          "title": "Deep Conditional Gaussian Mixture Model for Constrained Clustering. (arXiv:2106.06385v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06257",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Arango_S/0/1/0/all/0/1\">Sebastian Pineda Arango</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jomaa_H/0/1/0/all/0/1\">Hadi S. Jomaa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wistuba_M/0/1/0/all/0/1\">Martin Wistuba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grabocka_J/0/1/0/all/0/1\">Josif Grabocka</a>",
          "description": "Hyperparameter optimization (HPO) is a core problem for the machine learning\ncommunity and remains largely unsolved due to the significant computational\nresources required to evaluate hyperparameter configurations. As a result, a\nseries of recent related works have focused on the direction of transfer\nlearning for quickly fine-tuning hyperparameters on a dataset. Unfortunately,\nthe community does not have a common large-scale benchmark for comparing HPO\nalgorithms. Instead, the de facto practice consists of empirical protocols on\narbitrary small-scale meta-datasets that vary inconsistently across\npublications, making reproducibility a challenge. To resolve this major\nbottleneck and enable a fair and fast comparison of black-box HPO methods on a\nlevel playing field, we propose HPO-B, a new large-scale benchmark in the form\nof a collection of meta-datasets. Our benchmark is assembled and preprocessed\nfrom the OpenML repository and consists of 176 search spaces (algorithms)\nevaluated sparsely on 196 datasets with a total of 6.4 million hyperparameter\nevaluations. For ensuring reproducibility on our benchmark, we detail explicit\nexperimental protocols, splits, and evaluation measures for comparing methods\nfor both non-transfer, as well as, transfer learning HPO.",
          "link": "http://arxiv.org/abs/2106.06257",
          "publishedOn": "2021-06-14T01:38:53.995Z",
          "wordCount": 612,
          "title": "HPO-B: A Large-Scale Reproducible Benchmark for Black-Box HPO based on OpenML. (arXiv:2106.06257v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06251",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Akiyama_S/0/1/0/all/0/1\">Shunta Akiyama</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Suzuki_T/0/1/0/all/0/1\">Taiji Suzuki</a>",
          "description": "Deep learning empirically achieves high performance in many applications, but\nits training dynamics has not been fully understood theoretically. In this\npaper, we explore theoretical analysis on training two-layer ReLU neural\nnetworks in a teacher-student regression model, in which a student network\nlearns an unknown teacher network through its outputs. We show that with a\nspecific regularization and sufficient over-parameterization, the student\nnetwork can identify the parameters of the teacher network with high\nprobability via gradient descent with a norm dependent stepsize even though the\nobjective function is highly non-convex. The key theoretical tool is the\nmeasure representation of the neural networks and a novel application of a dual\ncertificate argument for sparse estimation on a measure space. We analyze the\nglobal minima and global convergence property in the measure space.",
          "link": "http://arxiv.org/abs/2106.06251",
          "publishedOn": "2021-06-14T01:38:53.985Z",
          "wordCount": 570,
          "title": "On Learnability via Gradient Method for Two-Layer ReLU Neural Networks in Teacher-Student Setting. (arXiv:2106.06251v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06235",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gurel_N/0/1/0/all/0/1\">Nezihe Merve G&#xfc;rel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_X/0/1/0/all/0/1\">Xiangyu Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rimanic_L/0/1/0/all/0/1\">Luka Rimanic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Ce Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>",
          "description": "Despite the great successes achieved by deep neural networks (DNNs), recent\nstudies show that they are vulnerable against adversarial examples, which aim\nto mislead DNNs by adding small adversarial perturbations. Several defenses\nhave been proposed against such attacks, while many of them have been\nadaptively attacked. In this work, we aim to enhance the ML robustness from a\ndifferent perspective by leveraging domain knowledge: We propose a Knowledge\nEnhanced Machine Learning Pipeline (KEMLP) to integrate domain knowledge (i.e.,\nlogic relationships among different predictions) into a probabilistic graphical\nmodel via first-order logic rules. In particular, we develop KEMLP by\nintegrating a diverse set of weak auxiliary models based on their logical\nrelationships to the main DNN model that performs the target task.\nTheoretically, we provide convergence results and prove that, under mild\nconditions, the prediction of KEMLP is more robust than that of the main DNN\nmodel. Empirically, we take road sign recognition as an example and leverage\nthe relationships between road signs and their shapes and contents as domain\nknowledge. We show that compared with adversarial training and other baselines,\nKEMLP achieves higher robustness against physical attacks, $\\mathcal{L}_p$\nbounded attacks, unforeseen attacks, and natural corruptions under both\nwhitebox and blackbox settings, while still maintaining high clean accuracy.",
          "link": "http://arxiv.org/abs/2106.06235",
          "publishedOn": "2021-06-14T01:38:53.979Z",
          "wordCount": 649,
          "title": "Knowledge Enhanced Machine Learning Pipeline against Diverse Adversarial Attacks. (arXiv:2106.06235v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06216",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Waldis_A/0/1/0/all/0/1\">Andreas Waldis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mazzola_L/0/1/0/all/0/1\">Luca Mazzola</a>",
          "description": "Entity Recognition (ER) within a text is a fundamental exercise in Natural\nLanguage Processing, enabling further depending tasks such as Knowledge\nExtraction, Text Summarisation, or Keyphrase Extraction. An entity consists of\nsingle words or of a consecutive sequence of terms, constituting the basic\nbuilding blocks for communication. Mainstream ER approaches are mainly limited\nto flat structures, concentrating on the outermost entities while ignoring the\ninner ones. This paper introduces a partly-layered network architecture that\ndeals with the complexity of overlapping and nested cases. The proposed\narchitecture consists of two parts: (1) a shared Sequence Layer and (2) a\nstacked component with multiple Tagging Layers. The adoption of such an\narchitecture has the advantage of preventing overfit to a specific word-length,\nthus maintaining performance for longer entities despite their lower frequency.\nTo verify the proposed architecture's effectiveness, we train and evaluate this\narchitecture to recognise two kinds of entities - Concepts (CR) and Named\nEntities (NER). Our approach achieves state-of-the-art NER performances, while\nit outperforms previous CR approaches. Considering these promising results, we\nsee the possibility to evolve the architecture for other cases such as the\nextraction of events or the detection of argumentative components.",
          "link": "http://arxiv.org/abs/2106.06216",
          "publishedOn": "2021-06-14T01:38:53.958Z",
          "wordCount": 635,
          "title": "Nested and Balanced Entity Recognition using Multi-Task Learning. (arXiv:2106.06216v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06308",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Choo_D/0/1/0/all/0/1\">Davin Choo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+dOrsi_T/0/1/0/all/0/1\">Tommaso d&#x27;Orsi</a>",
          "description": "We study the problem of sparse tensor principal component analysis: given a\ntensor $\\pmb Y = \\pmb W + \\lambda x^{\\otimes p}$ with $\\pmb W \\in\n\\otimes^p\\mathbb{R}^n$ having i.i.d. Gaussian entries, the goal is to recover\nthe $k$-sparse unit vector $x \\in \\mathbb{R}^n$. The model captures both sparse\nPCA (in its Wigner form) and tensor PCA.\n\nFor the highly sparse regime of $k \\leq \\sqrt{n}$, we present a family of\nalgorithms that smoothly interpolates between a simple polynomial-time\nalgorithm and the exponential-time exhaustive search algorithm. For any $1 \\leq\nt \\leq k$, our algorithms recovers the sparse vector for signal-to-noise ratio\n$\\lambda \\geq \\tilde{\\mathcal{O}} (\\sqrt{t} \\cdot (k/t)^{p/2})$ in time\n$\\tilde{\\mathcal{O}}(n^{p+t})$, capturing the state-of-the-art guarantees for\nthe matrix settings (in both the polynomial-time and sub-exponential time\nregimes).\n\nOur results naturally extend to the case of $r$ distinct $k$-sparse signals\nwith disjoint supports, with guarantees that are independent of the number of\nspikes. Even in the restricted case of sparse PCA, known algorithms only\nrecover the sparse vectors for $\\lambda \\geq \\tilde{\\mathcal{O}}(k \\cdot r)$\nwhile our algorithms require $\\lambda \\geq \\tilde{\\mathcal{O}}(k)$.\n\nFinally, by analyzing the low-degree likelihood ratio, we complement these\nalgorithmic results with rigorous evidence illustrating the trade-offs between\nsignal-to-noise ratio and running time. This lower bound captures the known\nlower bounds for both sparse PCA and tensor PCA. In this general model, we\nobserve a more intricate three-way trade-off between the number of samples $n$,\nthe sparsity $k$, and the tensor power $p$.",
          "link": "http://arxiv.org/abs/2106.06308",
          "publishedOn": "2021-06-14T01:38:53.951Z",
          "wordCount": 680,
          "title": "The Complexity of Sparse Tensor PCA. (arXiv:2106.06308v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06237",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zhou_C/0/1/0/all/0/1\">Chenhong Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_F/0/1/0/all/0/1\">Feng Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gong_C/0/1/0/all/0/1\">Chen Gong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_T/0/1/0/all/0/1\">Tongliang Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Han_B/0/1/0/all/0/1\">Bo Han</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cheung_W/0/1/0/all/0/1\">William Cheung</a>",
          "description": "In semantic segmentation, we aim to train a pixel-level classifier to assign\ncategory labels to all pixels in an image, where labeled training images and\nunlabeled test images are from the same distribution and share the same label\nset. However, in an open world, the unlabeled test images probably contain\nunknown categories and have different distributions from the labeled images.\nHence, in this paper, we consider a new, more realistic, and more challenging\nproblem setting where the pixel-level classifier has to be trained with labeled\nimages and unlabeled open-world images -- we name it open world semantic\nsegmentation (OSS). In OSS, the trained classifier is expected to identify\nunknown-class pixels and classify known-class pixels well. To solve OSS, we\nfirst investigate which distribution that unknown-class pixels obey. Then,\nmotivated by the goodness-of-fit test, we use statistical measurements to show\nhow a pixel fits the distribution of an unknown class and select highly-fitted\npixels to form the unknown region in each image. Eventually, we propose an\nend-to-end learning framework, known-region-aware domain alignment (KRADA), to\ndistinguish unknown classes while aligning distributions of known classes in\nlabeled and unlabeled open-world images. The effectiveness of KRADA has been\nverified on two synthetic tasks and one COVID-19 segmentation task.",
          "link": "http://arxiv.org/abs/2106.06237",
          "publishedOn": "2021-06-14T01:38:53.944Z",
          "wordCount": 698,
          "title": "KRADA: Known-region-aware Domain Alignment for Open World Semantic Segmentation. (arXiv:2106.06237v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06298",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kanaan_G/0/1/0/all/0/1\">Georges Kanaan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_K/0/1/0/all/0/1\">Kai Wen Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fenaux_L/0/1/0/all/0/1\">Lucas Fenaux</a>",
          "description": "We propose a novel approach to lifelong learning, introducing a compact\nencapsulated support structure which endows a network with the capability to\nexpand its capacity as needed to learn new tasks while preventing the loss of\nlearned tasks. This is achieved by splitting neurons with high semantic drift\nand constructing an adjacent network to encode the new tasks at hand. We call\nthis the Plastic Support Structure (PSS), it is a compact structure to learn\nnew tasks that cannot be efficiently encoded in the existing structure of the\nnetwork. We validate the PSS on public datasets against existing lifelong\nlearning architectures, showing it performs similarly to them but without prior\nknowledge of the task and in some cases with fewer parameters and in a more\nunderstandable fashion where the PSS is an encapsulated container for specific\nfeatures related to specific tasks, thus making it an ideal \"add-on\" solution\nfor endowing a network to learn more tasks.",
          "link": "http://arxiv.org/abs/2106.06298",
          "publishedOn": "2021-06-14T01:38:53.937Z",
          "wordCount": 583,
          "title": "A Novel Approach to Lifelong Learning: The Plastic Support Structure. (arXiv:2106.06298v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06369",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yan_S/0/1/0/all/0/1\">Shengchao Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Welschehold_T/0/1/0/all/0/1\">Tim Welschehold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buscher_D/0/1/0/all/0/1\">Daniel B&#xfc;scher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burgard_W/0/1/0/all/0/1\">Wolfram Burgard</a>",
          "description": "The transition from today's mostly human-driven traffic to a purely automated\none will be a gradual evolution, with the effect that we will likely experience\nmixed traffic in the near future. Connected and automated vehicles can benefit\nhuman-driven ones and the whole traffic system in different ways, for example\nby improving collision avoidance and reducing traffic waves. Many studies have\nbeen carried out to improve intersection management, a significant bottleneck\nin traffic, with intelligent traffic signals or exclusively automated vehicles.\nHowever, the problem of how to improve mixed traffic at unsignalized\nintersections has received less attention. In this paper, we propose a novel\napproach to optimizing traffic flow at intersections in mixed traffic\nsituations using deep reinforcement learning. Our reinforcement learning agent\nlearns a policy for a centralized controller to let connected autonomous\nvehicles at unsignalized intersections give up their right of way and yield to\nother vehicles to optimize traffic flow. We implemented our approach and tested\nit in the traffic simulator SUMO based on simulated and real traffic data. The\nexperimental evaluation demonstrates that our method significantly improves\ntraffic flow through unsignalized intersections in mixed traffic settings and\nalso provides better performance on a wide range of traffic situations compared\nto the state-of-the-art traffic signal controller for the corresponding\nsignalized intersection.",
          "link": "http://arxiv.org/abs/2106.06369",
          "publishedOn": "2021-06-14T01:38:53.931Z",
          "wordCount": 646,
          "title": "Courteous Behavior of Automated Vehicles at Unsignalized Intersections via Reinforcement Learning. (arXiv:2106.06369v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06420",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Al_Kaabi_K/0/1/0/all/0/1\">Karrar Al-Kaabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monsefi_R/0/1/0/all/0/1\">Reza Monsefi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zabihzadeh_D/0/1/0/all/0/1\">Davood Zabihzadeh</a>",
          "description": "Metric learning algorithms aim to learn a distance function that brings the\nsemantically similar data items together and keeps dissimilar ones at a\ndistance. The traditional Mahalanobis distance learning is equivalent to find a\nlinear projection. In contrast, Deep Metric Learning (DML) methods are proposed\nthat automatically extract features from data and learn a non-linear\ntransformation from input space to a semantically embedding space. Recently,\nmany DML methods are proposed focused to enhance the discrimination power of\nthe learned metric by providing novel sampling strategies or loss functions.\nThis approach is very helpful when both the training and test examples are\ncoming from the same set of categories. However, it is less effective in many\napplications of DML such as image retrieval and person-reidentification. Here,\nthe DML should learn general semantic concepts from observed classes and employ\nthem to rank or identify objects from unseen categories. Neglecting the\ngeneralization ability of the learned representation and just emphasizing to\nlearn a more discriminative embedding on the observed classes may lead to the\noverfitting problem. To address this limitation, we propose a framework to\nenhance the generalization power of existing DML methods in a Zero-Shot\nLearning (ZSL) setting by general yet discriminative representation learning\nand employing a class adversarial neural network. To learn a more general\nrepresentation, we propose to employ feature maps of intermediate layers in a\ndeep neural network and enhance their discrimination power through an attention\nmechanism. Besides, a class adversarial network is utilized to enforce the deep\nmodel to seek class invariant features for the DML task. We evaluate our work\non widely used machine vision datasets in a ZSL setting.",
          "link": "http://arxiv.org/abs/2106.06420",
          "publishedOn": "2021-06-14T01:38:53.913Z",
          "wordCount": 744,
          "title": "A Framework to Enhance Generalization of Deep Metric Learning methods using General Discriminative Feature Learning and Class Adversarial Neural Networks. (arXiv:2106.06420v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06326",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chi_H/0/1/0/all/0/1\">Haoang Chi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Feng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1\">Wenjing Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_L/0/1/0/all/0/1\">Long Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tongliang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1\">Bo Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheung_W/0/1/0/all/0/1\">William K. Cheung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwok_J/0/1/0/all/0/1\">James T. Kwok</a>",
          "description": "In few-shot domain adaptation (FDA), classifiers for the target domain are\ntrained with accessible labeled data in the source domain (SD) and few labeled\ndata in the target domain (TD). However, data usually contain private\ninformation in the current era, e.g., data distributed on personal phones.\nThus, the private information will be leaked if we directly access data in SD\nto train a target-domain classifier (required by FDA methods). In this paper,\nto thoroughly prevent the privacy leakage in SD, we consider a very challenging\nproblem setting, where the classifier for the TD has to be trained using few\nlabeled target data and a well-trained SD classifier, named few-shot hypothesis\nadaptation (FHA). In FHA, we cannot access data in SD, as a result, the private\ninformation in SD will be protected well. To this end, we propose a target\norientated hypothesis adaptation network (TOHAN) to solve the FHA problem,\nwhere we generate highly-compatible unlabeled data (i.e., an intermediate\ndomain) to help train a target-domain classifier. TOHAN maintains two deep\nnetworks simultaneously, where one focuses on learning an intermediate domain\nand the other takes care of the intermediate-to-target distributional\nadaptation and the target-risk minimization. Experimental results show that\nTOHAN outperforms competitive baselines significantly.",
          "link": "http://arxiv.org/abs/2106.06326",
          "publishedOn": "2021-06-14T01:38:53.904Z",
          "wordCount": 635,
          "title": "TOHAN: A One-step Approach towards Few-shot Hypothesis Adaptation. (arXiv:2106.06326v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06317",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schubert_F/0/1/0/all/0/1\">Frederik Schubert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eimer_T/0/1/0/all/0/1\">Theresa Eimer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosenhahn_B/0/1/0/all/0/1\">Bodo Rosenhahn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lindauer_M/0/1/0/all/0/1\">Marius Lindauer</a>",
          "description": "The use of Reinforcement Learning (RL) agents in practical applications\nrequires the consideration of suboptimal outcomes, depending on the familiarity\nof the agent with its environment. This is especially important in\nsafety-critical environments, where errors can lead to high costs or damage. In\ndistributional RL, the risk-sensitivity can be controlled via different\ndistortion measures of the estimated return distribution. However, these\ndistortion functions require an estimate of the risk level, which is difficult\nto obtain and depends on the current state. In this work, we demonstrate the\nsuboptimality of a static risk level estimation and propose a method to\ndynamically select risk levels at each environment step. Our method ARA\n(Automatic Risk Adaptation) estimates the appropriate risk level in both known\nand unknown environments using a Random Network Distillation error. We show\nreduced failure rates by up to a factor of 7 and improved generalization\nperformance by up to 14% compared to both risk-aware and risk-agnostic agents\nin several locomotion environments.",
          "link": "http://arxiv.org/abs/2106.06317",
          "publishedOn": "2021-06-14T01:38:53.898Z",
          "wordCount": 583,
          "title": "Automatic Risk Adaptation in Distributional Reinforcement Learning. (arXiv:2106.06317v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06232",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_J/0/1/0/all/0/1\">Jiajun Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1\">Changnan Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yue Huang</a>",
          "description": "Deep Q Network (DQN) firstly kicked the door of deep reinforcement learning\n(DRL) via combining deep learning (DL) with reinforcement learning (RL), which\nhas noticed that the distribution of the acquired data would change during the\ntraining process. DQN found this property might cause instability for training,\nso it proposed effective methods to handle the downside of the property.\nInstead of focusing on the unfavourable aspects, we find it critical for RL to\nease the gap between the estimated data distribution and the ground truth data\ndistribution while supervised learning (SL) fails to do so. From this new\nperspective, we extend the basic paradigm of RL called the Generalized Policy\nIteration (GPI) into a more generalized version, which is called the\nGeneralized Data Distribution Iteration (GDI). We see massive RL algorithms and\ntechniques can be unified into the GDI paradigm, which can be considered as one\nof the special cases of GDI. We provide theoretical proof of why GDI is better\nthan GPI and how it works. Several practical algorithms based on GDI have been\nproposed to verify the effectiveness and extensiveness of it. Empirical\nexperiments prove our state-of-the-art (SOTA) performance on Arcade Learning\nEnvironment (ALE), wherein our algorithm has achieved 9620.98% mean human\nnormalized score (HNS), 1146.39% median HNS and 22 human world record\nbreakthroughs (HWRB) using only 200 training frames. Our work aims to lead the\nRL research to step into the journey of conquering the human world records and\nseek real superhuman agents on both performance and efficiency.",
          "link": "http://arxiv.org/abs/2106.06232",
          "publishedOn": "2021-06-14T01:38:53.890Z",
          "wordCount": 687,
          "title": "GDI: Rethinking What Makes Reinforcement Learning Different From Supervised Learning. (arXiv:2106.06232v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06245",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Tran_B/0/1/0/all/0/1\">Ba-Hien Tran</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rossi_S/0/1/0/all/0/1\">Simone Rossi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Milios_D/0/1/0/all/0/1\">Dimitrios Milios</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Michiardi_P/0/1/0/all/0/1\">Pietro Michiardi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bonilla_E/0/1/0/all/0/1\">Edwin V. Bonilla</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Filippone_M/0/1/0/all/0/1\">Maurizio Filippone</a>",
          "description": "We develop a novel method for carrying out model selection for Bayesian\nautoencoders (BAEs) by means of prior hyper-parameter optimization. Inspired by\nthe common practice of type-II maximum likelihood optimization and its\nequivalence to Kullback-Leibler divergence minimization, we propose to optimize\nthe distributional sliced-Wasserstein distance (DSWD) between the output of the\nautoencoder and the empirical data distribution. The advantages of this\nformulation are that we can estimate the DSWD based on samples and handle\nhigh-dimensional problems. We carry out posterior estimation of the BAE\nparameters via stochastic gradient Hamiltonian Monte Carlo and turn our BAE\ninto a generative model by fitting a flexible Dirichlet mixture model in the\nlatent space. Consequently, we obtain a powerful alternative to variational\nautoencoders, which are the preferred choice in modern applications of\nautoencoders for representation learning with uncertainty. We evaluate our\napproach qualitatively and quantitatively using a vast experimental campaign on\na number of unsupervised learning tasks and show that, in small-data regimes\nwhere priors matter, our approach provides state-of-the-art results,\noutperforming multiple competitive baselines.",
          "link": "http://arxiv.org/abs/2106.06245",
          "publishedOn": "2021-06-14T01:38:53.884Z",
          "wordCount": 597,
          "title": "Model Selection for Bayesian Autoencoders. (arXiv:2106.06245v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06300",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Plassier_V/0/1/0/all/0/1\">Vincent Plassier</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vono_M/0/1/0/all/0/1\">Maxime Vono</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Durmus_A/0/1/0/all/0/1\">Alain Durmus</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Moulines_E/0/1/0/all/0/1\">Eric Moulines</a>",
          "description": "Performing reliable Bayesian inference on a big data scale is becoming a\nkeystone in the modern era of machine learning. A workhorse class of methods to\nachieve this task are Markov chain Monte Carlo (MCMC) algorithms and their\ndesign to handle distributed datasets has been the subject of many works.\nHowever, existing methods are not completely either reliable or computationally\nefficient. In this paper, we propose to fill this gap in the case where the\ndataset is partitioned and stored on computing nodes within a cluster under a\nmaster/slaves architecture. We derive a user-friendly centralised distributed\nMCMC algorithm with provable scaling in high-dimensional settings. We\nillustrate the relevance of the proposed methodology on both synthetic and real\ndata experiments.",
          "link": "http://arxiv.org/abs/2106.06300",
          "publishedOn": "2021-06-14T01:38:53.866Z",
          "wordCount": 564,
          "title": "DG-LMC: A Turn-key and Scalable Synchronous Distributed MCMC Algorithm. (arXiv:2106.06300v1 [stat.ME])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06239",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Amani_S/0/1/0/all/0/1\">Sanae Amani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thrampoulidis_C/0/1/0/all/0/1\">Christos Thrampoulidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Lin F. Yang</a>",
          "description": "Safety in reinforcement learning has become increasingly important in recent\nyears. Yet, existing solutions either fail to strictly avoid choosing unsafe\nactions, which may lead to catastrophic results in safety-critical systems, or\nfail to provide regret guarantees for settings where safety constraints need to\nbe learned. In this paper, we address both problems by first modeling safety as\nan unknown linear cost function of states and actions, which must always fall\nbelow a certain threshold. We then present algorithms, termed SLUCB-QVI and\nRSLUCB-QVI, for episodic Markov decision processes (MDPs) with linear function\napproximation. We show that SLUCB-QVI and RSLUCB-QVI, while with \\emph{no\nsafety violation}, achieve a\n$\\tilde{\\mathcal{O}}\\left(\\kappa\\sqrt{d^3H^3T}\\right)$ regret, nearly matching\nthat of state-of-the-art unsafe algorithms, where $H$ is the duration of each\nepisode, $d$ is the dimension of the feature mapping, $\\kappa$ is a constant\ncharacterizing the safety constraints, and $T$ is the total number of action\nplays. We further present numerical simulations that corroborate our\ntheoretical findings.",
          "link": "http://arxiv.org/abs/2106.06239",
          "publishedOn": "2021-06-14T01:38:53.859Z",
          "wordCount": 585,
          "title": "Safe Reinforcement Learning with Linear Function Approximation. (arXiv:2106.06239v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06273",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Junshan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_K/0/1/0/all/0/1\">Kunqing Xie</a>",
          "description": "With the rapid growth of traffic sensors deployed, a massive amount of\ntraffic flow data are collected, revealing the long-term evolution of traffic\nflows and the gradual expansion of traffic networks. How to accurately\nforecasting these traffic flow attracts the attention of researchers as it is\nof great significance for improving the efficiency of transportation systems.\nHowever, existing methods mainly focus on the spatial-temporal correlation of\nstatic networks, leaving the problem of efficiently learning models on networks\nwith expansion and evolving patterns less studied. To tackle this problem, we\npropose a Streaming Traffic Flow Forecasting Framework, TrafficStream, based on\nGraph Neural Networks (GNNs) and Continual Learning (CL), achieving accurate\npredictions and high efficiency. Firstly, we design a traffic pattern fusion\nmethod, cleverly integrating the new patterns that emerged during the long-term\nperiod into the model. A JS-divergence-based algorithm is proposed to mine new\ntraffic patterns. Secondly, we introduce CL to consolidate the knowledge\nlearned previously and transfer them to the current model. Specifically, we\nadopt two strategies: historical data replay and parameter smoothing. We\nconstruct a streaming traffic dataset to verify the efficiency and\neffectiveness of our model. Extensive experiments demonstrate its excellent\npotential to extract traffic patterns with high efficiency on long-term\nstreaming network scene. The source code is available at\nhttps://github.com/AprLie/TrafficStream.",
          "link": "http://arxiv.org/abs/2106.06273",
          "publishedOn": "2021-06-14T01:38:53.853Z",
          "wordCount": 653,
          "title": "TrafficStream: A Streaming Traffic Flow Forecasting Framework Based on Graph Neural Networks and Continual Learning. (arXiv:2106.06273v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06199",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Amid_E/0/1/0/all/0/1\">Ehsan Amid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anil_R/0/1/0/all/0/1\">Rohan Anil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Warmuth_M/0/1/0/all/0/1\">Manfred K. Warmuth</a>",
          "description": "We study a local loss construction approach for optimizing neural networks.\nWe start by motivating the problem as minimizing a squared loss between the\npre-activations of each layer and a local target, plus a regularizer term on\nthe weights. The targets are chosen so that the first gradient descent step on\nthe local objectives recovers vanilla BackProp, while the exact solution to\neach problem results in a preconditioned gradient update. We improve the local\nloss construction by forming a Bregman divergence in each layer tailored to the\ntransfer function which keeps the local problem convex w.r.t. the weights. The\ngeneralized local problem is again solved iteratively by taking small gradient\ndescent steps on the weights, for which the first step recovers BackProp. We\nrun several ablations and show that our construction consistently improves\nconvergence, reducing the gap between first-order and second-order methods.",
          "link": "http://arxiv.org/abs/2106.06199",
          "publishedOn": "2021-06-14T01:38:53.845Z",
          "wordCount": 563,
          "title": "LocoProp: Enhancing BackProp via Local Loss Optimization. (arXiv:2106.06199v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06033",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mallen_A/0/1/0/all/0/1\">Alex Mallen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lange_H/0/1/0/all/0/1\">Henning Lange</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kutz_J/0/1/0/all/0/1\">J. Nathan Kutz</a>",
          "description": "Probabilistic forecasting of complex phenomena is paramount to various\nscientific disciplines and applications. Despite the generality and importance\nof the problem, general mathematical techniques that allow for stable long-term\nforecasts with calibrated uncertainty measures are lacking. For most time\nseries models, the difficulty of obtaining accurate probabilistic future time\nstep predictions increases with the prediction horizon. In this paper, we\nintroduce a surprisingly simple approach that characterizes time-varying\ndistributions and enables reasonably accurate predictions thousands of\ntimesteps into the future. This technique, which we call Deep Probabilistic\nKoopman (DPK), is based on recent advances in linear Koopman operator theory,\nand does not require time stepping for future time predictions. Koopman models\nalso tend to have a small parameter footprint (often less than 10,000\nparameters). We demonstrate the long-term forecasting performance of these\nmodels on a diversity of domains, including electricity demand forecasting,\natmospheric chemistry, and neuroscience. For electricity demand modeling, our\ndomain-agnostic technique outperforms all of 177 domain-specific competitors in\nthe most recent Global Energy Forecasting Competition.",
          "link": "http://arxiv.org/abs/2106.06033",
          "publishedOn": "2021-06-14T01:38:53.839Z",
          "wordCount": 601,
          "title": "Deep Probabilistic Koopman: Long-term time-series forecasting under periodic uncertainties. (arXiv:2106.06033v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06210",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ko_J/0/1/0/all/0/1\">Jihoon Ko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwon_T/0/1/0/all/0/1\">Taehyung Kwon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_K/0/1/0/all/0/1\">Kijung Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Juho Lee</a>",
          "description": "Graph neural networks (GNNs) are one of the most popular approaches to using\ndeep learning on graph-structured data, and they have shown state-of-the-art\nperformances on a variety of tasks. However, according to a recent study, a\ncareful choice of pooling functions, which are used for the aggregation or\nreadout operation in GNNs, is crucial for enabling GNNs to extrapolate. Without\nthe ideal combination of pooling functions, which varies across tasks, GNNs\ncompletely fail to generalize to out-of-distribution data, while the number of\npossible combinations grows exponentially with the number of layers. In this\npaper, we present GNP, a $L^p$ norm-like pooling function that is trainable\nend-to-end for any given task. Notably, GNP generalizes most of the widely-used\npooling functions. We verify experimentally that simply replacing all pooling\nfunctions with GNP enables GNNs to extrapolate well on many node-level,\ngraph-level, and set-related tasks; and GNP sometimes performs even better than\noptimal combinations of existing pooling functions.",
          "link": "http://arxiv.org/abs/2106.06210",
          "publishedOn": "2021-06-14T01:38:53.832Z",
          "wordCount": 580,
          "title": "Learning to Pool in Graph Neural Networks for Extrapolation. (arXiv:2106.06210v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06170",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1\">Yunhao Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rowland_M/0/1/0/all/0/1\">Mark Rowland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Munos_R/0/1/0/all/0/1\">R&#xe9;mi Munos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valko_M/0/1/0/all/0/1\">Michal Valko</a>",
          "description": "In practical reinforcement learning (RL), the discount factor used for\nestimating value functions often differs from that used for defining the\nevaluation objective. In this work, we study the effect that this discrepancy\nof discount factors has during learning, and discover a family of objectives\nthat interpolate value functions of two distinct discount factors. Our analysis\nsuggests new ways for estimating value functions and performing policy\noptimization updates, which demonstrate empirical performance gains. This\nframework also leads to new insights on commonly-used deep RL heuristic\nmodifications to policy optimization algorithms.",
          "link": "http://arxiv.org/abs/2106.06170",
          "publishedOn": "2021-06-14T01:38:53.813Z",
          "wordCount": 518,
          "title": "Taylor Expansion of Discount Factors. (arXiv:2106.06170v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06041",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yoon_J/0/1/0/all/0/1\">Jongmin Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1\">Sung Ju Hwang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Juho Lee</a>",
          "description": "While adversarial training is considered as a standard defense method against\nadversarial attacks for image classifiers, adversarial purification, which\npurifies attacked images into clean images with a standalone purification\nmodel, has shown promises as an alternative defense method. Recently, an\nEnergy-Based Model (EBM) trained with Markov-Chain Monte-Carlo (MCMC) has been\nhighlighted as a purification model, where an attacked image is purified by\nrunning a long Markov-chain using the gradients of the EBM. Yet, the\npracticality of the adversarial purification using an EBM remains questionable\nbecause the number of MCMC steps required for such purification is too large.\nIn this paper, we propose a novel adversarial purification method based on an\nEBM trained with Denoising Score-Matching (DSM). We show that an EBM trained\nwith DSM can quickly purify attacked images within a few steps. We further\nintroduce a simple yet effective randomized purification scheme that injects\nrandom noises into images before purification. This process screens the\nadversarial perturbations imposed on images by the random noises and brings the\nimages to the regime where the EBM can denoise well. We show that our\npurification method is robust against various attacks and demonstrate its\nstate-of-the-art performances.",
          "link": "http://arxiv.org/abs/2106.06041",
          "publishedOn": "2021-06-14T01:38:53.806Z",
          "wordCount": 620,
          "title": "Adversarial purification with Score-based generative models. (arXiv:2106.06041v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06110",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qureshi_S/0/1/0/all/0/1\">Syed Arbaaz Qureshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehta_S/0/1/0/all/0/1\">Sonu Mehta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhagwan_R/0/1/0/all/0/1\">Ranjita Bhagwan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_R/0/1/0/all/0/1\">Rahul Kumar</a>",
          "description": "In recent times, it has been shown that one can use code as data to aid\nvarious applications such as automatic commit message generation, automatic\ngeneration of pull request descriptions and automatic program repair. Take for\ninstance the problem of commit message generation. Treating source code as a\nsequence of tokens, state of the art techniques generate commit messages using\nneural machine translation models. However, they tend to ignore the syntactic\nstructure of programming languages.\n\nPrevious work, i.e., code2seq has used structural information from Abstract\nSyntax Tree (AST) to represent source code and they use it to automatically\ngenerate method names. In this paper, we elaborate upon this state of the art\napproach and modify it to represent source code edits. We determine the effect\nof using such syntactic structure for the problem of classifying code edits.\nInspired by the code2seq approach, we evaluate how using structural information\nfrom AST, i.e., paths between AST leaf nodes can help with the task of code\nedit classification on two datasets of fine-grained syntactic edits.\n\nOur experiments shows that attempts of adding syntactic structure does not\nresult in any improvements over less sophisticated methods. The results suggest\nthat techniques such as code2seq, while promising, have a long way to go before\nthey can be generically applied to learning code edit representations. We hope\nthat these results will benefit other researchers and inspire them to work\nfurther on this problem.",
          "link": "http://arxiv.org/abs/2106.06110",
          "publishedOn": "2021-06-14T01:38:53.684Z",
          "wordCount": 666,
          "title": "Assessing the Effectiveness of Syntactic Structure to Learn Code Edit Representations. (arXiv:2106.06110v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06097",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lyu_Y/0/1/0/all/0/1\">Yueming Lyu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tsang_I/0/1/0/all/0/1\">Ivor Tsang</a>",
          "description": "Recent studies show a close connection between neural networks (NN) and\nkernel methods. However, most of these analyses (e.g., NTK) focus on the\ninfluence of (infinite) width instead of the depth of NN models. There remains\na gap between theory and practical network designs that benefit from the depth.\nThis paper first proposes a novel kernel family named Neural Optimization\nKernel (NOK). Our kernel is defined as the inner product between two $T$-step\nupdated functionals in RKHS w.r.t. a regularized optimization problem.\nTheoretically, we proved the monotonic descent property of our update rule for\nboth convex and non-convex problems, and a $O(1/T)$ convergence rate of our\nupdates for convex problems. Moreover, we propose a data-dependent structured\napproximation of our NOK, which builds the connection between training deep NNs\nand kernel methods associated with NOK. The resultant computational graph is a\nResNet-type finite width NN. Our structured approximation preserved the\nmonotonic descent property and $O(1/T)$ convergence rate. Namely, a $T$-layer\nNN performs $T$-step monotonic descent updates. Notably, we show our\n$T$-layered structured NN with ReLU maintains a $O(1/T)$ convergence rate\nw.r.t. a convex regularized problem, which explains the success of ReLU on\ntraining deep NN from a NN architecture optimization perspective. For the\nunsupervised learning and the shared parameter case, we show the equivalence of\ntraining structured NN with GD and performing functional gradient descent in\nRKHS associated with a fixed (data-dependent) NOK at an infinity-width regime.\nFor finite NOKs, we prove generalization bounds. Remarkably, we show that\noverparameterized deep NN (NOK) can increase the expressive power to reduce\nempirical risk and reduce the generalization bound at the same time. Extensive\nexperiments verify the robustness of our structured NOK blocks.",
          "link": "http://arxiv.org/abs/2106.06097",
          "publishedOn": "2021-06-14T01:38:53.677Z",
          "wordCount": 713,
          "title": "Neural Optimization Kernel: Towards Robust Deep Learning. (arXiv:2106.06097v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06167",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_L/0/1/0/all/0/1\">Liwei Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xuanhao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yan Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_K/0/1/0/all/0/1\">Kai Zheng</a>",
          "description": "Monitoring complex systems results in massive multivariate time series data,\nand anomaly detection of these data is very important to maintain the normal\noperation of the systems. Despite the recent emergence of a large number of\nanomaly detection algorithms for multivariate time series, most of them ignore\nthe correlation modeling among multivariate, which can often lead to poor\nanomaly detection results. In this work, we propose a novel anomaly detection\nmodel for multivariate time series with \\underline{HI}gh-order\n\\underline{F}eature \\underline{I}nteractions (HIFI). More specifically, HIFI\nbuilds multivariate feature interaction graph automatically and uses the graph\nconvolutional neural network to achieve high-order feature interactions, in\nwhich the long-term temporal dependencies are modeled by attention mechanisms\nand a variational encoding technique is utilized to improve the model\nperformance and robustness. Extensive experiments on three publicly available\ndatasets demonstrate the superiority of our framework compared with\nstate-of-the-art approaches.",
          "link": "http://arxiv.org/abs/2106.06167",
          "publishedOn": "2021-06-14T01:38:53.651Z",
          "wordCount": 577,
          "title": "HIFI: Anomaly Detection for Multivariate Time Series with High-order Feature Interactions. (arXiv:2106.06167v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06159",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gan_Y/0/1/0/all/0/1\">Yanhai Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1\">Xinghui Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Huiyu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_F/0/1/0/all/0/1\">Feng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1\">Junyu Dong</a>",
          "description": "Clustering is one of the fundamental tasks in computer vision and pattern\nrecognition. Recently, deep clustering methods (algorithms based on deep\nlearning) have attracted wide attention with their impressive performance. Most\nof these algorithms combine deep unsupervised representation learning and\nstandard clustering together. However, the separation of representation\nlearning and clustering will lead to suboptimal solutions because the two-stage\nstrategy prevents representation learning from adapting to subsequent tasks\n(e.g., clustering according to specific cues). To overcome this issue, efforts\nhave been made in the dynamic adaption of representation and cluster\nassignment, whereas current state-of-the-art methods suffer from heuristically\nconstructed objectives with representation and cluster assignment alternatively\noptimized. To further standardize the clustering problem, we audaciously\nformulate the objective of clustering as finding a precise feature as the cue\nfor cluster assignment. Based on this, we propose a general-purpose deep\nclustering framework which radically integrates representation learning and\nclustering into a single pipeline for the first time. The proposed framework\nexploits the powerful ability of recently developed generative models for\nlearning intrinsic features, and imposes an entropy minimization on the\ndistribution of the cluster assignment by a dedicated variational algorithm.\nExperimental results show that the performance of the proposed method is\nsuperior, or at least comparable to, the state-of-the-art methods on the\nhandwritten digit recognition, fashion recognition, face recognition and object\nrecognition benchmark datasets.",
          "link": "http://arxiv.org/abs/2106.06159",
          "publishedOn": "2021-06-14T01:38:53.629Z",
          "wordCount": 659,
          "title": "Learning the Precise Feature for Cluster Assignment. (arXiv:2106.06159v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06162",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Saehoon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sungwoong Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Juho Lee</a>",
          "description": "Unsupervised representation learning has recently received lots of interest\ndue to its powerful generalizability through effectively leveraging large-scale\nunlabeled data. There are two prevalent approaches for this, contrastive\nlearning and generative pre-training, where the former learns representations\nfrom instance-wise discrimination tasks and the latter learns them from\nestimating the likelihood. These seemingly orthogonal approaches have their own\nstrengths and weaknesses. Contrastive learning tends to extract semantic\ninformation and discards details irrelevant for classifying objects, making the\nrepresentations effective for discriminative tasks while degrading robustness\nto out-of-distribution data. On the other hand, the generative pre-training\ndirectly estimates the data distribution, so the representations tend to be\nrobust but not optimal for discriminative tasks. In this paper, we show that we\ncould achieve the best of both worlds by a hybrid training scheme.\nSpecifically, we demonstrated that a transformer-based encoder-decoder\narchitecture trained with both contrastive and generative losses can learn\nhighly discriminative and robust representations without hurting the generative\nperformance. We extensively validate our approach on various tasks.",
          "link": "http://arxiv.org/abs/2106.06162",
          "publishedOn": "2021-06-14T01:38:53.620Z",
          "wordCount": 589,
          "title": "Hybrid Generative-Contrastive Representation Learning. (arXiv:2106.06162v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06134",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yao Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaorui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_N/0/1/0/all/0/1\">Neil Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jiliang Tang</a>",
          "description": "Graph neural networks (GNNs) have shown great prowess in learning\nrepresentations suitable for numerous graph-based machine learning tasks. When\napplied to semi-supervised node classification, GNNs are widely believed to\nwork well due to the homophily assumption (``like attracts like''), and fail to\ngeneralize to heterophilous graphs where dissimilar nodes connect. Recent works\ndesign new architectures to overcome such heterophily-related limitations,\nciting poor baseline performance and new architecture improvements on a few\nheterophilous graph benchmark datasets as evidence for this notion. In our\nexperiments, we empirically find that standard graph convolutional networks\n(GCNs) can actually achieve better performance than such carefully designed\nmethods on some commonly used heterophilous graphs. This motivates us to\nreconsider whether homophily is truly necessary for good GNN performance. We\nfind that this claim is not quite true, and in fact, GCNs can achieve strong\nperformance on heterophilous graphs under certain conditions. Our work\ncarefully characterizes these conditions, and provides supporting theoretical\nunderstanding and empirical observations. Finally, we examine existing\nheterophilous graphs benchmarks and reconcile how the GCN (under)performs on\nthem based on this understanding.",
          "link": "http://arxiv.org/abs/2106.06134",
          "publishedOn": "2021-06-14T01:38:53.614Z",
          "wordCount": 606,
          "title": "Is Homophily a Necessity for Graph Neural Networks?. (arXiv:2106.06134v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06147",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abdelnour_J/0/1/0/all/0/1\">Jerome Abdelnour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rouat_J/0/1/0/all/0/1\">Jean Rouat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salvi_G/0/1/0/all/0/1\">Giampiero Salvi</a>",
          "description": "The goal of the Acoustic Question Answering (AQA) task is to answer a\nfree-form text question about the content of an acoustic scene. It was inspired\nby the Visual Question Answering (VQA) task. In this paper, based on the\npreviously introduced CLEAR dataset, we propose a new benchmark for AQA that\nemphasizes the specific challenges of acoustic inputs, e.g. variable duration\nscenes. We also introduce NAAQA, a neural architecture that leverages specific\nproperties of acoustic inputs. The usage of time and frequency 1D convolutions\nto process 2D spectro-temporal representations of acoustic content shows\npromising results and enables reductions in model complexity. NAAQA achieves\n91.6% of accuracy on the AQA task with about 7 times fewer parameters than the\npreviously explored VQA model. We provide a detailed analysis of the results\nfor the different question types. The effectiveness of coordinate maps in this\nacoustic context was also studied and we show that time coordinate maps augment\ntemporal localization capabilities which enhance performance of the network by\nabout 17 percentage points.",
          "link": "http://arxiv.org/abs/2106.06147",
          "publishedOn": "2021-06-14T01:38:53.607Z",
          "wordCount": 622,
          "title": "NAAQA: A Neural Architecture for Acoustic Question Answering. (arXiv:2106.06147v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06168",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xuanli He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nassar_I/0/1/0/all/0/1\">Islam Nassar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiros_J/0/1/0/all/0/1\">Jamie Kiros</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haffari_G/0/1/0/all/0/1\">Gholamreza Haffari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Norouzi_M/0/1/0/all/0/1\">Mohammad Norouzi</a>",
          "description": "Semi-Supervised Learning (SSL) has seen success in many application domains,\nbut this success often hinges on the availability of task-specific unlabeled\ndata. Knowledge distillation (KD) has enabled compressing deep networks and\nensembles, achieving the best results when distilling knowledge on fresh\ntask-specific unlabeled examples. However, task-specific unlabeled data can be\nchallenging to find. We present a general framework called \"generate, annotate,\nand learn (GAL)\" that uses unconditional generative models to synthesize\nin-domain unlabeled data, helping advance SSL and KD on different tasks. To\nobtain strong task-specific generative models, we adopt generic generative\nmodels, pretrained on open-domain data, and fine-tune them on inputs from\nspecific tasks. Then, we use existing classifiers to annotate generated\nunlabeled examples with soft pseudo labels, which are used for additional\ntraining. When self-training is combined with samples generated from\nGPT2-large, fine-tuned on the inputs of each GLUE task, we outperform a strong\nRoBERTa-large baseline on the GLUE benchmark. Moreover, KD on GPT-2 samples\nyields a new state-of-the-art for 6-layer transformers on the GLUE leaderboard.\nFinally, self-training with GAL offers significant gains on image\nclassification on CIFAR-10 and four tabular tasks from the UCI repository",
          "link": "http://arxiv.org/abs/2106.06168",
          "publishedOn": "2021-06-14T01:38:53.601Z",
          "wordCount": 625,
          "title": "Generate, Annotate, and Learn: Generative Models Advance Self-Training and Knowledge Distillation. (arXiv:2106.06168v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06135",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zha_D/0/1/0/all/0/1\">Daochen Zha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1\">Jingru Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1\">Wenye Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Sheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lian_X/0/1/0/all/0/1\">Xiangru Lian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xia Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Ji Liu</a>",
          "description": "Games are abstractions of the real world, where artificial agents learn to\ncompete and cooperate with other agents. While significant achievements have\nbeen made in various perfect- and imperfect-information games, DouDizhu (a.k.a.\nFighting the Landlord), a three-player card game, is still unsolved. DouDizhu\nis a very challenging domain with competition, collaboration, imperfect\ninformation, large state space, and particularly a massive set of possible\nactions where the legal actions vary significantly from turn to turn.\nUnfortunately, modern reinforcement learning algorithms mainly focus on simple\nand small action spaces, and not surprisingly, are shown not to make\nsatisfactory progress in DouDizhu. In this work, we propose a conceptually\nsimple yet effective DouDizhu AI system, namely DouZero, which enhances\ntraditional Monte-Carlo methods with deep neural networks, action encoding, and\nparallel actors. Starting from scratch in a single server with four GPUs,\nDouZero outperformed all the existing DouDizhu AI programs in days of training\nand was ranked the first in the Botzone leaderboard among 344 AI agents.\nThrough building DouZero, we show that classic Monte-Carlo methods can be made\nto deliver strong results in a hard domain with a complex action space. The\ncode and an online demo are released at https://github.com/kwai/DouZero with\nthe hope that this insight could motivate future work.",
          "link": "http://arxiv.org/abs/2106.06135",
          "publishedOn": "2021-06-14T01:38:53.582Z",
          "wordCount": 649,
          "title": "DouZero: Mastering DouDizhu with Self-Play Deep Reinforcement Learning. (arXiv:2106.06135v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06151",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kuroyanagi_I/0/1/0/all/0/1\">Ibuki Kuroyanagi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hayashi_T/0/1/0/all/0/1\">Tomoki Hayashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takeda_K/0/1/0/all/0/1\">Kazuya Takeda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Toda_T/0/1/0/all/0/1\">Tomoki Toda</a>",
          "description": "An anomalous sound detection system to detect unknown anomalous sounds\nusually needs to be built using only normal sound data. Moreover, it is\ndesirable to improve the system by effectively using a small amount of\nanomalous sound data, which will be accumulated through the system's operation.\nAs one of the methods to meet these requirements, we focus on a binary\nclassification model that is developed by using not only normal data but also\noutlier data in the other domains as pseudo-anomalous sound data, which can be\neasily updated by using anomalous data. In this paper, we implement a new loss\nfunction based on metric learning to learn the distance relationship from each\nclass centroid in feature space for the binary classification model. The\nproposed multi-task learning of the binary classification and the metric\nlearning makes it possible to build the feature space where the within-class\nvariance is minimized and the between-class variance is maximized while keeping\nnormal and anomalous classes linearly separable. We also investigate the\neffectiveness of additionally using anomalous sound data for further improving\nthe binary classification model. Our results showed that multi-task learning\nusing binary classification and metric learning to consider the distance from\neach class centroid in the feature space is effective, and performance can be\nsignificantly improved by using even a small amount of anomalous data during\ntraining.",
          "link": "http://arxiv.org/abs/2106.06151",
          "publishedOn": "2021-06-14T01:38:53.576Z",
          "wordCount": 670,
          "title": "Anomalous Sound Detection Using a Binary Classification Model and Class Centroids. (arXiv:2106.06151v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06158",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gad_A/0/1/0/all/0/1\">Ahmed Fawzy Gad</a>",
          "description": "This paper introduces PyGAD, an open-source easy-to-use Python library for\nbuilding the genetic algorithm. PyGAD supports a wide range of parameters to\ngive the user control over everything in its life cycle. This includes, but is\nnot limited to, population, gene value range, gene data type, parent selection,\ncrossover, and mutation. PyGAD is designed as a general-purpose optimization\nlibrary that allows the user to customize the fitness function. Its usage\nconsists of 3 main steps: build the fitness function, create an instance of the\npygad.GA class, and calling the pygad.GA.run() method. The library supports\ntraining deep learning models created either with PyGAD itself or with\nframeworks like Keras and PyTorch. Given its stable state, PyGAD is also in\nactive development to respond to the user's requested features and enhancement\nreceived on GitHub https://github.com/ahmedfgad/GeneticAlgorithmPython. PyGAD\ncomes with documentation https://pygad.readthedocs.io for further details and\nexamples.",
          "link": "http://arxiv.org/abs/2106.06158",
          "publishedOn": "2021-06-14T01:38:53.569Z",
          "wordCount": 587,
          "title": "PyGAD: An Intuitive Genetic Algorithm Python Library. (arXiv:2106.06158v1 [cs.NE])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06139",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moore_K/0/1/0/all/0/1\">Kristen Moore</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_S/0/1/0/all/0/1\">Shenjun Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1\">Zhen He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rudolf_T/0/1/0/all/0/1\">Torsten Rudolf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fisher_N/0/1/0/all/0/1\">Nils Fisher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Victor_B/0/1/0/all/0/1\">Brandon Victor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jindal_N/0/1/0/all/0/1\">Neha Jindal</a>",
          "description": "In this paper we present the results of our experiments in training and\ndeploying a self-supervised retrieval-based chatbot trained with contrastive\nlearning for assisting customer support agents. In contrast to most existing\nresearch papers in this area where the focus is on solving just one component\nof a deployable chatbot, we present an end-to-end set of solutions to take the\nreader from an unlabelled chatlogs to a deployed chatbot. This set of solutions\nincludes creating a self-supervised dataset and a weakly labelled dataset from\nchatlogs, as well as a systematic approach to selecting a fixed list of canned\nresponses. We present a hierarchical-based RNN architecture for the response\nselection model, chosen for its ability to cache intermediate utterance\nembeddings, which helped to meet deployment inference speed requirements. We\ncompare the performance of this architecture across 3 different learning\nobjectives: self-supervised contrastive learning, binary classification, and\nmulti-class classification. We find that using a self-supervised contrastive\nlearning model outperforms training the binary and multi-class classification\nmodels on a weakly labelled dataset. Our results validate that the\nself-supervised contrastive learning approach can be effectively used for a\nreal-world chatbot scenario.",
          "link": "http://arxiv.org/abs/2106.06139",
          "publishedOn": "2021-06-14T01:38:53.562Z",
          "wordCount": 624,
          "title": "A comprehensive solution to retrieval-based chatbot construction. (arXiv:2106.06139v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06142",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhai_R/0/1/0/all/0/1\">Runtian Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dan_C/0/1/0/all/0/1\">Chen Dan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolter_J/0/1/0/all/0/1\">J. Zico Kolter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ravikumar_P/0/1/0/all/0/1\">Pradeep Ravikumar</a>",
          "description": "Many machine learning tasks involve subpopulation shift where the testing\ndata distribution is a subpopulation of the training distribution. For such\nsettings, a line of recent work has proposed the use of a variant of empirical\nrisk minimization(ERM) known as distributionally robust optimization (DRO). In\nthis work, we apply DRO to real, large-scale tasks with subpopulation shift,\nand observe that DRO performs relatively poorly, and moreover has severe\ninstability. We identify one direct cause of this phenomenon: sensitivity of\nDRO to outliers in the datasets. To resolve this issue, we propose the\nframework of DORO, for Distributional and Outlier Robust Optimization. At the\ncore of this approach is a refined risk function which prevents DRO from\noverfitting to potential outliers. We instantiate DORO for the Cressie-Read\nfamily of R\\'enyi divergence, and delve into two specific instances of this\nfamily: CVaR and $\\chi^2$-DRO. We theoretically prove the effectiveness of the\nproposed method, and empirically show that DORO improves the performance and\nstability of DRO with experiments on large modern datasets, thereby positively\naddressing the open question raised by Hashimoto et al., 2018.",
          "link": "http://arxiv.org/abs/2106.06142",
          "publishedOn": "2021-06-14T01:38:53.554Z",
          "wordCount": 614,
          "title": "DORO: Distributional and Outlier Robust Optimization. (arXiv:2106.06142v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06095",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ament_S/0/1/0/all/0/1\">Sebastian Ament</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gomes_C/0/1/0/all/0/1\">Carla Gomes</a>",
          "description": "Sparse Bayesian Learning (SBL) is a powerful framework for attaining sparsity\nin probabilistic models. Herein, we propose a coordinate ascent algorithm for\nSBL termed Relevance Matching Pursuit (RMP) and show that, as its noise\nvariance parameter goes to zero, RMP exhibits a surprising connection to\nStepwise Regression. Further, we derive novel guarantees for Stepwise\nRegression algorithms, which also shed light on RMP. Our guarantees for Forward\nRegression improve on deterministic and probabilistic results for Orthogonal\nMatching Pursuit with noise. Our analysis of Backward Regression on determined\nsystems culminates in a bound on the residual of the optimal solution to the\nsubset selection problem that, if satisfied, guarantees the optimality of the\nresult. To our knowledge, this bound is the first that can be computed in\npolynomial time and depends chiefly on the smallest singular value of the\nmatrix. We report numerical experiments using a variety of feature selection\nalgorithms. Notably, RMP and its limiting variant are both efficient and\nmaintain strong performance with correlated features.",
          "link": "http://arxiv.org/abs/2106.06095",
          "publishedOn": "2021-06-14T01:38:53.536Z",
          "wordCount": 600,
          "title": "Sparse Bayesian Learning via Stepwise Regression. (arXiv:2106.06095v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06048",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ferianc_M/0/1/0/all/0/1\">Martin Ferianc</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Que_Z/0/1/0/all/0/1\">Zhiqiang Que</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_H/0/1/0/all/0/1\">Hongxiang Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luk_W/0/1/0/all/0/1\">Wayne Luk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodrigues_M/0/1/0/all/0/1\">Miguel Rodrigues</a>",
          "description": "Neural networks have demonstrated their great performance in a wide range of\ntasks. Especially in time-series analysis, recurrent architectures based on\nlong-short term memory (LSTM) cells have manifested excellent capability to\nmodel time dependencies in real-world data. However, standard recurrent\narchitectures cannot estimate their uncertainty which is essential for\nsafety-critical applications such as in medicine. In contrast, Bayesian\nrecurrent neural networks (RNNs) are able to provide uncertainty estimation\nwith improved accuracy. Nonetheless, Bayesian RNNs are computationally and\nmemory demanding, which limits their practicality despite their advantages. To\naddress this issue, we propose an FPGA-based hardware design to accelerate\nBayesian LSTM-based RNNs. To further improve the overall algorithmic-hardware\nperformance, a co-design framework is proposed to explore the most optimal\nalgorithmic-hardware configurations for Bayesian RNNs. We conduct extensive\nexperiments on health-related tasks to demonstrate the improvement of our\ndesign and the effectiveness of our framework. Compared with GPU\nimplementation, our FPGA-based design can achieve up to 10 times speedup with\nnearly 106 times higher energy efficiency. To the best of our knowledge, this\nis the first work targeting the acceleration of Bayesian RNNs on FPGAs.",
          "link": "http://arxiv.org/abs/2106.06048",
          "publishedOn": "2021-06-14T01:38:53.529Z",
          "wordCount": 621,
          "title": "High-Performance FPGA-based Accelerator for Bayesian Recurrent Neural Networks. (arXiv:2106.06048v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06129",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vasu_P/0/1/0/all/0/1\">Pavan Kumar Anasosalu Vasu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saxena_S/0/1/0/all/0/1\">Shreyas Saxena</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuzel_O/0/1/0/all/0/1\">Oncel Tuzel</a>",
          "description": "Recent works have shown that deep neural networks benefit from multi-task\nlearning by learning a shared representation across several related tasks.\nHowever, performance of such systems depend on relative weighting between\nvarious losses involved during training. Prior works on loss weighting schemes\nassume that instances are equally easy or hard for all tasks. In order to break\nthis assumption, we let the training process dictate the optimal weighting of\ntasks for every instance in the dataset. More specifically, we equip every\ninstance in the dataset with a set of learnable parameters (instance-level task\nparameters) where the cardinality is equal to the number of tasks learned by\nthe model. These parameters model the weighting of each task for an instance.\nThey are updated by gradient descent and do not require hand-crafted rules. We\nconduct extensive experiments on SURREAL and CityScapes datasets, for human\nshape and pose estimation, depth estimation and semantic segmentation tasks. In\nthese tasks, our approach outperforms recent dynamic loss weighting approaches,\ne.g. reducing surface estimation errors by 8.97% on SURREAL. When applied to\ndatasets where one or more tasks can have noisy annotations, the proposed\nmethod learns to prioritize learning from clean labels for a given task, e.g.\nreducing surface estimation errors by up to 60%. We also show that we can\nreliably detect corrupt labels for a given task as a by-product from learned\ninstance-level task parameters.",
          "link": "http://arxiv.org/abs/2106.06129",
          "publishedOn": "2021-06-14T01:38:53.522Z",
          "wordCount": 665,
          "title": "Instance-Level Task Parameters: A Robust Multi-task Weighting Framework. (arXiv:2106.06129v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06098",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_G/0/1/0/all/0/1\">Guanya Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azizzadenesheli_K/0/1/0/all/0/1\">Kamyar Azizzadenesheli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chung_S/0/1/0/all/0/1\">Soon-Jo Chung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yue_Y/0/1/0/all/0/1\">Yisong Yue</a>",
          "description": "We present an online multi-task learning approach for adaptive nonlinear\ncontrol, which we call Online Meta-Adaptive Control (OMAC). The goal is to\ncontrol a nonlinear system subject to adversarial disturbance and unknown\n$\\textit{environment-dependent}$ nonlinear dynamics, under the assumption that\nthe environment-dependent dynamics can be well captured with some shared\nrepresentation. Our approach is motivated by robot control, where a robotic\nsystem encounters a sequence of new environmental conditions that it must\nquickly adapt to. A key emphasis is to integrate online representation learning\nwith established methods from control theory, in order to arrive at a unified\nframework that yields both control-theoretic and learning-theoretic guarantees.\nWe provide instantiations of our approach under varying conditions, leading to\nthe first non-asymptotic end-to-end convergence guarantee for multi-task\nadaptive nonlinear control. OMAC can also be integrated with deep\nrepresentation learning. Experiments show that OMAC significantly outperforms\nconventional adaptive control approaches which do not learn the shared\nrepresentation.",
          "link": "http://arxiv.org/abs/2106.06098",
          "publishedOn": "2021-06-14T01:38:53.516Z",
          "wordCount": 586,
          "title": "Meta-Adaptive Nonlinear Control: Theory and Algorithms. (arXiv:2106.06098v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06127",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ryu_M/0/1/0/all/0/1\">Minseok Ryu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1\">Kibaek Kim</a>",
          "description": "Differential privacy (DP) techniques can be applied to the federated learning\nmodel to protect data privacy against inference attacks to communication among\nthe learning agents. The DP techniques, however, hinder achieving a greater\nlearning performance while ensuring strong data privacy. In this paper we\ndevelop a DP inexact alternating direction method of multipliers algorithm that\nsolves a sequence of trust-region subproblems with the objective perturbation\nby random noises generated from a Laplace distribution. We show that our\nalgorithm provides $\\bar{\\epsilon}$-DP for every iteration and\n$\\mathcal{O}(1/T)$ rate of convergence in expectation, where $T$ is the number\nof iterations. Using MNIST and FEMNIST datasets for the image classification,\nwe demonstrate that our algorithm reduces the testing error by at most $22\\%$\ncompared with the existing DP algorithm, while achieving the same level of data\nprivacy. The numerical experiment also shows that our algorithm converges\nfaster than the existing algorithm.",
          "link": "http://arxiv.org/abs/2106.06127",
          "publishedOn": "2021-06-14T01:38:53.509Z",
          "wordCount": 571,
          "title": "Differentially Private Federated Learning via Inexact ADMM. (arXiv:2106.06127v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06143",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ma_F/0/1/0/all/0/1\">Fanhe Ma</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_F/0/1/0/all/0/1\">Faen Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ben_S/0/1/0/all/0/1\">Shenglan Ben</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Qin_S/0/1/0/all/0/1\">Shuxin Qin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhou_P/0/1/0/all/0/1\">Pengcheng Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhou_C/0/1/0/all/0/1\">Changsheng Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_F/0/1/0/all/0/1\">Fengyi Xu</a>",
          "description": "In this paper, we are interested in building a domain knowledge based deep\nlearning framework to solve the chiller plants energy optimization problems.\nCompared to the hotspot applications of deep learning (e.g. image\nclassification and NLP), it is difficult to collect enormous data for deep\nnetwork training in real-world physical systems. Most existing methods reduce\nthe complex systems into linear model to facilitate the training on small\nsamples. To tackle the small sample size problem, this paper considers domain\nknowledge in the structure and loss design of deep network to build a nonlinear\nmodel with lower redundancy function space. Specifically, the energy\nconsumption estimation of most chillers can be physically viewed as an\ninput-output monotonic problem. Thus, we can design a Neural Network with\nmonotonic constraints to mimic the physical behavior of the system. We verify\nthe proposed method in a cooling system of a data center, experimental results\nshow the superiority of our framework in energy optimization compared to the\nexisting ones.",
          "link": "http://arxiv.org/abs/2106.06143",
          "publishedOn": "2021-06-14T01:38:53.487Z",
          "wordCount": 613,
          "title": "Monotonic Neural Network: combining Deep Learning with Domain Knowledge for Chiller Plants Energy Optimization. (arXiv:2106.06143v1 [eess.SP])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06126",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swaminathan_R/0/1/0/all/0/1\">Rupak Vignesh Swaminathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parthasarathi_S/0/1/0/all/0/1\">Sree Hari Krishnan Parthasarathi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_C/0/1/0/all/0/1\">Chunchuan Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mouchtaris_A/0/1/0/all/0/1\">Athanasios Mouchtaris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kunzmann_S/0/1/0/all/0/1\">Siegfried Kunzmann</a>",
          "description": "We present results from Alexa speech teams on semi-supervised learning (SSL)\nof acoustic models (AM) with experiments spanning over 3000 hours of GPU time,\nmaking our study one of the largest of its kind. We discuss SSL for AMs in a\nsmall footprint setting, showing that a smaller capacity model trained with 1\nmillion hours of unsupervised data can outperform a baseline supervised system\nby 14.3% word error rate reduction (WERR). When increasing the supervised data\nto seven-fold, our gains diminish to 7.1% WERR; to improve SSL efficiency at\nlarger supervised data regimes, we employ a step-wise distillation into a\nsmaller model, obtaining a WERR of 14.4%. We then switch to SSL using larger\nstudent models in low data regimes; while learning efficiency with unsupervised\ndata is higher, student models may outperform teacher models in such a setting.\nWe develop a theoretical sketch to explain this behavior.",
          "link": "http://arxiv.org/abs/2106.06126",
          "publishedOn": "2021-06-14T01:38:53.478Z",
          "wordCount": 588,
          "title": "Exploiting Large-scale Teacher-Student Training for On-device Acoustic Models. (arXiv:2106.06126v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06056",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiawei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Linyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Huichen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaolu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shuang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>",
          "description": "Boundary based blackbox attack has been recognized as practical and\neffective, given that an attacker only needs to access the final model\nprediction. However, the query efficiency of it is in general high especially\nfor high dimensional image data. In this paper, we show that such efficiency\nhighly depends on the scale at which the attack is applied, and attacking at\nthe optimal scale significantly improves the efficiency. In particular, we\npropose a theoretical framework to analyze and show three key characteristics\nto improve the query efficiency. We prove that there exists an optimal scale\nfor projective gradient estimation. Our framework also explains the\nsatisfactory performance achieved by existing boundary black-box attacks. Based\non our theoretical framework, we propose Progressive-Scale enabled projective\nBoundary Attack (PSBA) to improve the query efficiency via progressive scaling\ntechniques. In particular, we employ Progressive-GAN to optimize the scale of\nprojections, which we call PSBA-PGAN. We evaluate our approach on both spatial\nand frequency scales. Extensive experiments on MNIST, CIFAR-10, CelebA, and\nImageNet against different models including a real-world face recognition API\nshow that PSBA-PGAN significantly outperforms existing baseline attacks in\nterms of query efficiency and attack success rate. We also observe relatively\nstable optimal scales for different models and datasets. The code is publicly\navailable at https://github.com/AI-secure/PSBA.",
          "link": "http://arxiv.org/abs/2106.06056",
          "publishedOn": "2021-06-14T01:38:53.470Z",
          "wordCount": 656,
          "title": "Progressive-Scale Boundary Blackbox Attack via Projective Gradient Estimation. (arXiv:2106.06056v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06080",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abnar_S/0/1/0/all/0/1\">Samira Abnar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berg_R/0/1/0/all/0/1\">Rianne van den Berg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghiasi_G/0/1/0/all/0/1\">Golnaz Ghiasi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dehghani_M/0/1/0/all/0/1\">Mostafa Dehghani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalchbrenner_N/0/1/0/all/0/1\">Nal Kalchbrenner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sedghi_H/0/1/0/all/0/1\">Hanie Sedghi</a>",
          "description": "We focus on the problem of domain adaptation when the goal is shifting the\nmodel towards the target distribution, rather than learning domain invariant\nrepresentations. It has been shown that under the following two assumptions:\n(a) access to samples from intermediate distributions, and (b) samples being\nannotated with the amount of change from the source distribution, self-training\ncan be successfully applied on gradually shifted samples to adapt the model\ntoward the target distribution. We hypothesize having (a) is enough to enable\niterative self-training to slowly adapt the model to the target distribution,\nby making use of an implicit curriculum. In the case where (a) does not hold,\nwe observe that iterative self-training falls short. We propose GIFT, a method\nthat creates virtual samples from intermediate distributions by interpolating\nrepresentations of examples from source and target domains. We evaluate an\niterative-self-training method on datasets with natural distribution shifts,\nand show that when applied on top of other domain adaptation methods, it\nimproves the performance of the model on the target dataset. We run an analysis\non a synthetic dataset to show that in the presence of (a)\niterative-self-training naturally forms a curriculum of samples. Furthermore,\nwe show that when (a) does not hold, GIFT performs better than iterative\nself-training.",
          "link": "http://arxiv.org/abs/2106.06080",
          "publishedOn": "2021-06-14T01:38:53.460Z",
          "wordCount": 646,
          "title": "Gradual Domain Adaptation in the Wild:When Intermediate Distributions are Absent. (arXiv:2106.06080v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06044",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Song_G/0/1/0/all/0/1\">Ganlin Song</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Xu_R/0/1/0/all/0/1\">Ruitu Xu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lafferty_J/0/1/0/all/0/1\">John Lafferty</a>",
          "description": "Stochastic gradient descent with backpropagation is the workhorse of\nartificial neural networks. It has long been recognized that backpropagation\nfails to be a biologically plausible algorithm. Fundamentally, it is a\nnon-local procedure -- updating one neuron's synaptic weights requires\nknowledge of synaptic weights or receptive fields of downstream neurons. This\nlimits the use of artificial neural networks as a tool for understanding the\nbiological principles of information processing in the brain. Lillicrap et al.\n(2016) propose a more biologically plausible \"feedback alignment\" algorithm\nthat uses random and fixed backpropagation weights, and show promising\nsimulations. In this paper we study the mathematical properties of the feedback\nalignment procedure by analyzing convergence and alignment for two-layer\nnetworks under squared error loss. In the overparameterized setting, we prove\nthat the error converges to zero exponentially fast, and also that\nregularization is necessary in order for the parameters to become aligned with\nthe random backpropagation weights. Simulations are given that are consistent\nwith this analysis and suggest further generalizations. These results\ncontribute to our understanding of how biologically plausible algorithms might\ncarry out weight learning in a manner different from Hebbian learning, with\nperformance that is comparable with the full non-local backpropagation\nalgorithm.",
          "link": "http://arxiv.org/abs/2106.06044",
          "publishedOn": "2021-06-14T01:38:53.451Z",
          "wordCount": 632,
          "title": "Convergence and Alignment of Gradient Descentwith Random Back propagation Weights. (arXiv:2106.06044v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06067",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brausse_F/0/1/0/all/0/1\">Franz Brau&#xdf;e</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khasidashvili_Z/0/1/0/all/0/1\">Zurab Khasidashvili</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korovin_K/0/1/0/all/0/1\">Konstantin Korovin</a>",
          "description": "Application domains of Bayesian optimization include optimizing black-box\n\nfunctions or very complex functions. The functions we are interested in\ndescribe\n\ncomplex real-world systems applied in industrial settings. Even though\n\nthey do have explicit representations, standard optimization\n\ntechniques fail to provide validated solutions and correctness\n\nguarantees for them.\n\nIn this paper we present a combination of Bayesian optimisation and SMT-based\nconstraint solving to achieve safe and stable solutions with optimality\nguarantees.",
          "link": "http://arxiv.org/abs/2106.06067",
          "publishedOn": "2021-06-14T01:38:53.444Z",
          "wordCount": 495,
          "title": "Bayesian Optimisation with Formal Guarantees. (arXiv:2106.06067v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05997",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sena_L/0/1/0/all/0/1\">Luiz Sena</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xidan Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alves_E/0/1/0/all/0/1\">Erickson Alves</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bessa_I/0/1/0/all/0/1\">Iury Bessa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manino_E/0/1/0/all/0/1\">Edoardo Manino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cordeiro_L/0/1/0/all/0/1\">Lucas Cordeiro</a>",
          "description": "Artificial Neural Networks (ANNs) are being deployed on an increasing number\nof safety-critical applications, including autonomous cars and medical\ndiagnosis. However, concerns about their reliability have been raised due to\ntheir black-box nature and apparent fragility to adversarial attacks. Here, we\ndevelop and evaluate a symbolic verification framework using incremental model\nchecking (IMC) and satisfiability modulo theories (SMT) to check for\nvulnerabilities in ANNs. More specifically, we propose several ANN-related\noptimizations for IMC, including invariant inference via interval analysis and\nthe discretization of non-linear activation functions. With this, we can\nprovide guarantees on the safe behavior of ANNs implemented both in\nfloating-point and fixed-point (quantized) arithmetic. In this regard, our\nverification approach was able to verify and produce adversarial examples for\n52 test cases spanning image classification and general machine learning\napplications. For small- to medium-sized ANN, our approach completes most of\nits verification runs in minutes. Moreover, in contrast to most\nstate-of-the-art methods, our approach is not restricted to specific choices of\nactivation functions or non-quantized representations.",
          "link": "http://arxiv.org/abs/2106.05997",
          "publishedOn": "2021-06-14T01:38:53.425Z",
          "wordCount": 605,
          "title": "Verifying Quantized Neural Networks using SMT-Based Model Checking. (arXiv:2106.05997v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06123",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhou_Z/0/1/0/all/0/1\">Zhiyong Zhou</a>",
          "description": "Over the past decades, many individual nonconvex methods have been proposed\nto achieve better sparse recovery performance in various scenarios. However,\nhow to construct a valid nonconvex regularization function remains open in\npractice. In this paper, we fill in this gap by presenting a unified framework\nfor constructing the nonconvex regularization based on the probability density\nfunction. Meanwhile, a new nonconvex sparse recovery method constructed via the\nWeibull distribution is studied.",
          "link": "http://arxiv.org/abs/2106.06123",
          "publishedOn": "2021-06-14T01:38:53.417Z",
          "wordCount": 496,
          "title": "A Unified Framework for Constructing Nonconvex Regularizations. (arXiv:2106.06123v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06042",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Oh_J/0/1/0/all/0/1\">Jaehoon Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sangmook Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yun_S/0/1/0/all/0/1\">Se-Young Yun</a>",
          "description": "Federated learning has evolved to improve a single global model under data\nheterogeneity (as a curse) or to develop multiple personalized models using\ndata heterogeneity (as a blessing). However, there has been little research\nconsidering both directions simultaneously. In this paper, we first investigate\nthe relationship between them by analyzing Federated Averaging at the client\nlevel and determine that a better federated global model performance does not\nconstantly improve personalization. To elucidate the cause of this\npersonalization performance degradation problem, we decompose the entire\nnetwork into the body (i.e., extractor), related to universality, and the head\n(i.e., classifier), related to personalization. We then point out that this\nproblem stems from training the head. Based on this observation, we propose a\nnovel federated learning algorithm, coined as FedBABU, which updates only the\nbody of the model during federated training (i.e., the head is randomly\ninitialized and never updated), and the head is fine-tuned for personalization\nduring the evaluation process. Extensive experiments show consistent\nperformance improvements and an efficient personalization of FedBABU.",
          "link": "http://arxiv.org/abs/2106.06042",
          "publishedOn": "2021-06-14T01:38:53.411Z",
          "wordCount": 603,
          "title": "FedBABU: Towards Enhanced Representation for Federated Image Classification. (arXiv:2106.06042v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06092",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Becdelievre_J/0/1/0/all/0/1\">Jean de Becdelievre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kroo_I/0/1/0/all/0/1\">Ilan Kroo</a>",
          "description": "The design of complex engineering systems leads to solving very large\noptimization problems involving different disciplines. Strategies allowing\ndisciplines to optimize in parallel by providing sub-objectives and splitting\nthe problem into smaller parts, such as Collaborative Optimization, are\npromising solutions.However, most of them have slow convergence which reduces\ntheir practical use. Earlier efforts to fasten convergence by learning\nsurrogate models have not yet succeeded at sufficiently improving the\ncompetitiveness of these strategies.This paper shows that, in the case of\nCollaborative Optimization, faster and more reliable convergence can be\nobtained by solving an interesting instance of binary classification: on top of\nthe target label, the training data of one of the two classes contains the\ndistance to the decision boundary and its derivative. Leveraging this\ninformation, we propose to train a neural network with an asymmetric loss\nfunction, a structure that guarantees Lipshitz continuity, and a regularization\ntowards respecting basic distance function properties. The approach is\ndemonstrated on a toy learning example, and then applied to a multidisciplinary\naircraft design problem.",
          "link": "http://arxiv.org/abs/2106.06092",
          "publishedOn": "2021-06-14T01:38:53.405Z",
          "wordCount": 607,
          "title": "Collaborative Multidisciplinary Design Optimization with Neural Networks. (arXiv:2106.06092v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06124",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wetzel_S/0/1/0/all/0/1\">Sebastian J. Wetzel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Melko_R/0/1/0/all/0/1\">Roger G. Melko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tamblyn_I/0/1/0/all/0/1\">Isaac Tamblyn</a>",
          "description": "Twin neural network regression (TNNR) is a semi-supervised regression\nalgorithm, it can be trained on unlabelled data points as long as other,\nlabelled anchor data points, are present. TNNR is trained to predict\ndifferences between the target values of two different data points rather than\nthe targets themselves. By ensembling predicted differences between the targets\nof an unseen data point and all training data points, it is possible to obtain\na very accurate prediction for the original regression problem. Since any loop\nof predicted differences should sum to zero, loops can be supplied to the\ntraining data, even if the data points themselves within loops are unlabelled.\nSemi-supervised training improves TNNR performance, which is already state of\nthe art, significantly.",
          "link": "http://arxiv.org/abs/2106.06124",
          "publishedOn": "2021-06-14T01:38:53.397Z",
          "wordCount": 546,
          "title": "Twin Neural Network Regression is a Semi-Supervised Regression Algorithm. (arXiv:2106.06124v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06054",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Biswas_S/0/1/0/all/0/1\">Sumon Biswas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajan_H/0/1/0/all/0/1\">Hridesh Rajan</a>",
          "description": "In recent years, many incidents have been reported where machine learning\nmodels exhibited discrimination among people based on race, sex, age, etc.\nResearch has been conducted to measure and mitigate unfairness in machine\nlearning models. For a machine learning task, it is a common practice to build\na pipeline that includes an ordered set of data preprocessing stages followed\nby a classifier. However, most of the research on fairness has considered a\nsingle classifier based prediction task. What are the fairness impacts of the\npreprocessing stages in machine learning pipeline? Furthermore, studies showed\nthat often the root cause of unfairness is ingrained in the data itself, rather\nthan the model. But no research has been conducted to measure the unfairness\ncaused by a specific transformation made in the data preprocessing stage. In\nthis paper, we introduced the causal method of fairness to reason about the\nfairness impact of data preprocessing stages in ML pipeline. We leveraged\nexisting metrics to define the fairness measures of the stages. Then we\nconducted a detailed fairness evaluation of the preprocessing stages in 37\npipelines collected from three different sources. Our results show that certain\ndata transformers are causing the model to exhibit unfairness. We identified a\nnumber of fairness patterns in several categories of data transformers.\nFinally, we showed how the local fairness of a preprocessing stage composes in\nthe global fairness of the pipeline. We used the fairness composition to choose\nappropriate downstream transformer that mitigates unfairness in the machine\nlearning pipeline.",
          "link": "http://arxiv.org/abs/2106.06054",
          "publishedOn": "2021-06-14T01:38:53.376Z",
          "wordCount": 714,
          "title": "Fair Preprocessing: Towards Understanding Compositional Fairness of Data Transformers in Machine Learning Pipeline. (arXiv:2106.06054v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06057",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schneider_J/0/1/0/all/0/1\">Johannes Schneider</a>",
          "description": "The data distribution commonly evolves over time leading to problems such as\nconcept drift that often decrease classifier performance. We seek to predict\nunseen data (and their labels) allowing us to tackle challenges due to a\nnon-constant data distribution in a \\emph{proactive} manner rather than\ndetecting and reacting to already existing changes that might already have led\nto errors. To this end, we learn a domain transformer in an unsupervised manner\nthat allows generating data of unseen domains. Our approach first matches\nindependently learned latent representations of two given domains obtained from\nan auto-encoder using a Cycle-GAN. In turn, a transformation of the original\nsamples can be learned that can be applied iteratively to extrapolate to unseen\ndomains. Our evaluation on CNNs on image data confirms the usefulness of the\napproach. It also achieves very good results on the well-known problem of\nunsupervised domain adaption, where labels but not samples have to be\npredicted.",
          "link": "http://arxiv.org/abs/2106.06057",
          "publishedOn": "2021-06-14T01:38:53.369Z",
          "wordCount": 576,
          "title": "Domain Transformer: Predicting Samples of Unseen, Future Domains. (arXiv:2106.06057v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06079",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_E/0/1/0/all/0/1\">Eric Hans Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eriksson_D/0/1/0/all/0/1\">David Eriksson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perrone_V/0/1/0/all/0/1\">Valerio Perrone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seeger_M/0/1/0/all/0/1\">Matthias Seeger</a>",
          "description": "Bayesian optimization (BO) is a popular method for optimizing\nexpensive-to-evaluate black-box functions. BO budgets are typically given in\niterations, which implicitly assumes each evaluation has the same cost. In\nfact, in many BO applications, evaluation costs vary significantly in different\nregions of the search space. In hyperparameter optimization, the time spent on\nneural network training increases with layer size; in clinical trials, the\nmonetary cost of drug compounds vary; and in optimal control, control actions\nhave differing complexities. Cost-constrained BO measures convergence with\nalternative cost metrics such as time, money, or energy, for which the sample\nefficiency of standard BO methods is ill-suited. For cost-constrained BO, cost\nefficiency is far more important than sample efficiency. In this paper, we\nformulate cost-constrained BO as a constrained Markov decision process (CMDP),\nand develop an efficient rollout approximation to the optimal CMDP policy that\ntakes both the cost and future iterations into account. We validate our method\non a collection of hyperparameter optimization problems as well as a sensor set\nselection application.",
          "link": "http://arxiv.org/abs/2106.06079",
          "publishedOn": "2021-06-14T01:38:53.361Z",
          "wordCount": 603,
          "title": "A Nonmyopic Approach to Cost-Constrained Bayesian Optimization. (arXiv:2106.06079v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06114",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tjandrasuwita_M/0/1/0/all/0/1\">Megan Tjandrasuwita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jennifer J. Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kennedy_A/0/1/0/all/0/1\">Ann Kennedy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhuri_S/0/1/0/all/0/1\">Swarat Chaudhuri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yue_Y/0/1/0/all/0/1\">Yisong Yue</a>",
          "description": "Hand-annotated data can vary due to factors such as subjective differences,\nintra-rater variability, and differing annotator expertise. We study\nannotations from different experts who labelled the same behavior classes on a\nset of animal behavior videos, and observe a variation in annotation styles. We\npropose a new method using program synthesis to help interpret annotation\ndifferences for behavior analysis. Our model selects relevant trajectory\nfeatures and learns a temporal filter as part of a program, which corresponds\nto estimated importance an annotator places on that feature at each timestamp.\nOur experiments on a dataset from behavioral neuroscience demonstrate that\ncompared to baseline approaches, our method is more accurate at capturing\nannotator labels and learns interpretable temporal filters. We believe that our\nmethod can lead to greater reproducibility of behavior annotations used in\nscientific studies. We plan to release our code.",
          "link": "http://arxiv.org/abs/2106.06114",
          "publishedOn": "2021-06-14T01:38:53.354Z",
          "wordCount": 583,
          "title": "Interpreting Expert Annotation Differences in Animal Behavior. (arXiv:2106.06114v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06049",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+P_D/0/1/0/all/0/1\">Deepak P</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sundaram_S/0/1/0/all/0/1\">Sowmya S Sundaram</a>",
          "description": "Pervasiveness of tracking devices and enhanced availability of spatially\nlocated data has deepened interest in using them for various policy\ninterventions, through computational data analysis tasks such as spatial hot\nspot detection. In this paper, we consider, for the first time to our best\nknowledge, fairness in detecting spatial hot spots. We motivate the need for\nensuring fairness through statistical parity over the collective population\ncovered across chosen hot spots. We then characterize the task of identifying a\ndiverse set of solutions in the noteworthiness-fairness trade-off spectrum, to\nempower the user to choose a trade-off justified by the policy domain. Being a\nnovel task formulation, we also develop a suite of evaluation metrics for fair\nhot spots, motivated by the need to evaluate pertinent aspects of the task. We\nillustrate the computational infeasibility of identifying fair hot spots using\nnaive and/or direct approaches and devise a method, codenamed {\\it FiSH}, for\nefficiently identifying high-quality, fair and diverse sets of spatial hot\nspots. FiSH traverses the tree-structured search space using heuristics that\nguide it towards identifying effective and fair sets of spatial hot spots.\nThrough an extensive empirical analysis over a real-world dataset from the\ndomain of human development, we illustrate that FiSH generates high-quality\nsolutions at fast response times.",
          "link": "http://arxiv.org/abs/2106.06049",
          "publishedOn": "2021-06-14T01:38:53.347Z",
          "wordCount": 626,
          "title": "FiSH: Fair Spatial Hotspots. (arXiv:2106.06049v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06061",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Harrold_D/0/1/0/all/0/1\">Daniel J. B. Harrold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1\">Jun Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1\">Zhong Fan</a>",
          "description": "As the world seeks to become more sustainable, intelligent solutions are\nneeded to increase the penetration of renewable energy. In this paper, the\nmodel-free deep reinforcement learning algorithm Rainbow Deep Q-Networks is\nused to control a battery in a small microgrid to perform energy arbitrage and\nmore efficiently utilise solar and wind energy sources. The grid operates with\nits own demand and renewable generation based on a dataset collected at Keele\nUniversity, as well as using dynamic energy pricing from a real wholesale\nenergy market. Four scenarios are tested including using demand and price\nforecasting produced with local weather data. The algorithm and its\nsubcomponents are evaluated against two continuous control benchmarks with\nRainbow able to outperform all other method. This research shows the importance\nof using the distributional approach for reinforcement learning when working\nwith complex environments and reward functions, as well as how it can be used\nto visualise and contextualise the agent's behaviour for real-world\napplications.",
          "link": "http://arxiv.org/abs/2106.06061",
          "publishedOn": "2021-06-14T01:38:53.339Z",
          "wordCount": 607,
          "title": "Data-driven battery operation for energy arbitrage using rainbow deep reinforcement learning. (arXiv:2106.06061v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06075",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Barazandeh_B/0/1/0/all/0/1\">Babak Barazandeh</a>, <a href=\"http://arxiv.org/find/math/1/au:+Huang_T/0/1/0/all/0/1\">Tianjian Huang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Michailidis_G/0/1/0/all/0/1\">George Michailidis</a>",
          "description": "Min-max saddle point games have recently been intensely studied, due to their\nwide range of applications, including training Generative Adversarial\nNetworks~(GANs). However, most of the recent efforts for solving them are\nlimited to special regimes such as convex-concave games. Further, it is\ncustomarily assumed that the underlying optimization problem is solved either\nby a single machine or in the case of multiple machines connected in\ncentralized fashion, wherein each one communicates with a central node. The\nlatter approach becomes challenging, when the underlying communications network\nhas low bandwidth. In addition, privacy considerations may dictate that certain\nnodes can communicate with a subset of other nodes. Hence, it is of interest to\ndevelop methods that solve min-max games in a decentralized manner. To that\nend, we develop a decentralized adaptive momentum (ADAM)-type algorithm for\nsolving min-max optimization problem under the condition that the objective\nfunction satisfies a Minty Variational Inequality condition, which is a\ngeneralization to convex-concave case. The proposed method overcomes\nshortcomings of recent non-adaptive gradient-based decentralized algorithms for\nmin-max optimization problems that do not perform well in practice and require\ncareful tuning. In this paper, we obtain non-asymptotic rates of convergence of\nthe proposed algorithm (coined DADAM$^3$) for finding a (stochastic)\nfirst-order Nash equilibrium point and subsequently evaluate its performance on\ntraining GANs. The extensive empirical evaluation shows that DADAM$^3$\noutperforms recently developed methods, including decentralized optimistic\nstochastic gradient for solving such min-max problems.",
          "link": "http://arxiv.org/abs/2106.06075",
          "publishedOn": "2021-06-14T01:38:53.331Z",
          "wordCount": 678,
          "title": "A Decentralized Adaptive Momentum Method for Solving a Class of Min-Max Optimization Problems. (arXiv:2106.06075v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05996",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qian_H/0/1/0/all/0/1\">Haifeng Qian</a>",
          "description": "It is a known phenomenon that adversarial robustness comes at a cost to\nnatural accuracy. To improve this trade-off, this paper proposes an ensemble\napproach that divides a complex robust-classification task into simpler\nsubtasks. Specifically, fractal divide derives multiple training sets from the\ntraining data, and fractal aggregation combines inference outputs from multiple\nclassifiers that are trained on those sets. The resulting ensemble classifiers\nhave a unique property that ensures robustness for an input if certain\ndon't-care conditions are met. The new techniques are evaluated on MNIST and\nFashion-MNIST, with no adversarial training. The MNIST classifier has 99%\nnatural accuracy, 70% measured robustness and 36.9% provable robustness, within\nL2 distance of 2. The Fashion-MNIST classifier has 90% natural accuracy, 54.5%\nmeasured robustness and 28.2% provable robustness, within L2 distance of 1.5.\nBoth results are new state of the art, and we also present new state-of-the-art\nbinary results on challenging label-pairs.",
          "link": "http://arxiv.org/abs/2106.05996",
          "publishedOn": "2021-06-14T01:38:53.306Z",
          "wordCount": 568,
          "title": "An Ensemble Approach Towards Adversarial Robustness. (arXiv:2106.05996v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06038",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chowdhury_J/0/1/0/all/0/1\">Jishnu Ray Chowdhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caragea_C/0/1/0/all/0/1\">Cornelia Caragea</a>",
          "description": "Recursive Neural Networks (RvNNs), which compose sequences according to their\nunderlying hierarchical syntactic structure, have performed well in several\nnatural language processing tasks compared to similar models without structural\nbiases. However, traditional RvNNs are incapable of inducing the latent\nstructure in a plain text sequence on their own. Several extensions have been\nproposed to overcome this limitation. Nevertheless, these extensions tend to\nrely on surrogate gradients or reinforcement learning at the cost of higher\nbias or variance. In this work, we propose Continuous Recursive Neural Network\n(CRvNN) as a backpropagation-friendly alternative to address the aforementioned\nlimitations. This is done by incorporating a continuous relaxation to the\ninduced structure. We demonstrate that CRvNN achieves strong performance in\nchallenging synthetic tasks such as logical inference and ListOps. We also show\nthat CRvNN performs comparably or better than prior latent structure models on\nreal-world tasks such as sentiment analysis and natural language inference.",
          "link": "http://arxiv.org/abs/2106.06038",
          "publishedOn": "2021-06-14T01:38:53.299Z",
          "wordCount": 589,
          "title": "Modeling Hierarchical Structures with Continuous Recursive Neural Networks. (arXiv:2106.06038v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06047",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qu_L/0/1/0/all/0/1\">Liangqiong Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yuyin Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1\">Paul Pu Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1\">Yingda Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Feifei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1\">Li Fei-Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adeli_E/0/1/0/all/0/1\">Ehsan Adeli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubin_D/0/1/0/all/0/1\">Daniel Rubin</a>",
          "description": "Federated learning is an emerging research paradigm enabling collaborative\ntraining of machine learning models among different organizations while keeping\ndata private at each institution. Despite recent progress, there remain\nfundamental challenges such as lack of convergence and potential for\ncatastrophic forgetting in federated learning across real-world heterogeneous\ndevices. In this paper, we demonstrate that attention-based architectures\n(e.g., Transformers) are fairly robust to distribution shifts and hence improve\nfederated learning over heterogeneous data. Concretely, we conduct the first\nrigorous empirical investigation of different neural architectures across a\nrange of federated algorithms, real-world benchmarks, and heterogeneous data\nsplits. Our experiments show that simply replacing convolutional networks with\nTransformers can greatly reduce catastrophic forgetting of previous devices,\naccelerate convergence, and reach a better global model, especially when\ndealing with heterogeneous data. We will release our code and pretrained models\nat https://github.com/Liangqiong/ViT-FL-main to encourage future exploration in\nrobust architectures as an alternative to current research efforts on the\noptimization front.",
          "link": "http://arxiv.org/abs/2106.06047",
          "publishedOn": "2021-06-14T01:38:53.293Z",
          "wordCount": 602,
          "title": "Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning. (arXiv:2106.06047v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05992",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1\">Shengyang Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1\">Jiaxin Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilson_A/0/1/0/all/0/1\">Andrew Gordon Wilson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grosse_R/0/1/0/all/0/1\">Roger Grosse</a>",
          "description": "We introduce a new scalable variational Gaussian process approximation which\nprovides a high fidelity approximation while retaining general applicability.\nWe propose the harmonic kernel decomposition (HKD), which uses Fourier series\nto decompose a kernel as a sum of orthogonal kernels. Our variational\napproximation exploits this orthogonality to enable a large number of inducing\npoints at a low computational cost. We demonstrate that, on a range of\nregression and classification problems, our approach can exploit input space\nsymmetries such as translations and reflections, and it significantly\noutperforms standard variational methods in scalability and accuracy. Notably,\nour approach achieves state-of-the-art results on CIFAR-10 among pure GP\nmodels.",
          "link": "http://arxiv.org/abs/2106.05992",
          "publishedOn": "2021-06-14T01:38:53.275Z",
          "wordCount": 539,
          "title": "Scalable Variational Gaussian Processes via Harmonic Kernel Decomposition. (arXiv:2106.05992v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06009",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Coppens_Y/0/1/0/all/0/1\">Youri Coppens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steckelmacher_D/0/1/0/all/0/1\">Denis Steckelmacher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jonker_C/0/1/0/all/0/1\">Catholijn M. Jonker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nowe_A/0/1/0/all/0/1\">Ann Now&#xe9;</a>",
          "description": "Today's advanced Reinforcement Learning algorithms produce black-box\npolicies, that are often difficult to interpret and trust for a person. We\nintroduce a policy distilling algorithm, building on the CN2 rule mining\nalgorithm, that distills the policy into a rule-based decision system. At the\ncore of our approach is the fact that an RL process does not just learn a\npolicy, a mapping from states to actions, but also produces extra\nmeta-information, such as action values indicating the quality of alternative\nactions. This meta-information can indicate whether more than one action is\nnear-optimal for a certain state. We extend CN2 to make it able to leverage\nknowledge about equally-good actions to distill the policy into fewer rules,\nincreasing its interpretability by a person. Then, to ensure that the rules\nexplain a valid, non-degenerate policy, we introduce a refinement algorithm\nthat fine-tunes the rules to obtain good performance when executed in the\nenvironment. We demonstrate the applicability of our algorithm on the Mario AI\nbenchmark, a complex task that requires modern reinforcement learning\nalgorithms including neural networks. The explanations we produce capture the\nlearned policy in only a few rules, that allow a person to understand what the\nblack-box agent learned. Source code:\nhttps://gitlab.ai.vub.ac.be/yocoppen/svcn2",
          "link": "http://arxiv.org/abs/2106.06009",
          "publishedOn": "2021-06-14T01:38:53.269Z",
          "wordCount": 672,
          "title": "Synthesising Reinforcement Learning Policies through Set-Valued Inductive Rule Learning. (arXiv:2106.06009v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06046",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kumar_M/0/1/0/all/0/1\">Mohit Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moser_B/0/1/0/all/0/1\">Bernhard A. Moser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fischer_L/0/1/0/all/0/1\">Lukas Fischer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freudenthaler_B/0/1/0/all/0/1\">Bernhard Freudenthaler</a>",
          "description": "Guidelines and principles of trustworthy AI should be adhered to in practice\nduring the development of AI systems. This work suggests a novel information\ntheoretic trustworthy AI framework based on the hypothesis that information\ntheory enables taking into account the ethical AI principles during the\ndevelopment of machine learning and deep learning models via providing a way to\nstudy and optimize the inherent tradeoffs between trustworthy AI principles. A\nunified approach to \"privacy-preserving interpretable and transferable\nlearning\" is presented via introducing the information theoretic measures for\nprivacy-leakage, interpretability, and transferability. A technique based on\nvariational optimization, employing conditionally deep autoencoders, is\ndeveloped for practically calculating the defined information theoretic\nmeasures for privacy-leakage, interpretability, and transferability.",
          "link": "http://arxiv.org/abs/2106.06046",
          "publishedOn": "2021-06-14T01:38:53.262Z",
          "wordCount": 570,
          "title": "Information Theoretic Evaluation of Privacy-Leakage, Interpretability, and Transferability for a Novel Trustworthy AI Framework. (arXiv:2106.06046v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06010",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Homssi_B/0/1/0/all/0/1\">Bassel Al Homssi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Al_Hourani_A/0/1/0/all/0/1\">Akram Al-Hourani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krusevac_Z/0/1/0/all/0/1\">Zarko Krusevac</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rowe_W/0/1/0/all/0/1\">Wayne S T Rowe</a>",
          "description": "Spectrum scarcity has surfaced as a prominent concern in wireless radio\ncommunications with the emergence of new technologies over the past few years.\nAs a result, there is growing need for better understanding of the spectrum\noccupancy with newly emerging access technologies supporting the Internet of\nThings. In this paper, we present a framework to capture and model the traffic\nbehavior of short-time spectrum occupancy for IoT applications in the shared\nbands to determine the existing interference. The proposed capturing method\nutilizes a software defined radio to monitor the short bursts of IoT\ntransmissions by capturing the time series data which is converted to power\nspectral density to extract the observed occupancy. Furthermore, we propose the\nuse of an unsupervised machine learning technique to enhance conventionally\nimplemented energy detection methods. Our experimental results show that the\ntemporal and frequency behavior of the spectrum can be well-captured using the\ncombination of two models, namely, semi-Markov chains and a\nPoisson-distribution arrival rate. We conduct an extensive measurement campaign\nin different urban environments and incorporate the spatial effect on the IoT\nshared spectrum.",
          "link": "http://arxiv.org/abs/2106.06010",
          "publishedOn": "2021-06-14T01:38:53.255Z",
          "wordCount": 617,
          "title": "Machine Learning Framework for Sensing and Modeling Interference in IoT Frequency Bands. (arXiv:2106.06010v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06027",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1\">Mingkang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tianlong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhangyang Wang</a>",
          "description": "Sparse adversarial attacks can fool deep neural networks (DNNs) by only\nperturbing a few pixels (regularized by l_0 norm). Recent efforts combine it\nwith another l_infty imperceptible on the perturbation magnitudes. The\nresultant sparse and imperceptible attacks are practically relevant, and\nindicate an even higher vulnerability of DNNs that we usually imagined.\nHowever, such attacks are more challenging to generate due to the optimization\ndifficulty by coupling the l_0 regularizer and box constraints with a\nnon-convex objective. In this paper, we address this challenge by proposing a\nhomotopy algorithm, to jointly tackle the sparsity and the perturbation bound\nin one unified framework. Each iteration, the main step of our algorithm is to\noptimize an l_0-regularized adversarial loss, by leveraging the nonmonotone\nAccelerated Proximal Gradient Method (nmAPG) for nonconvex programming; it is\nfollowed by an l_0 change control step, and an optional post-attack step\ndesigned to escape bad local minima. We also extend the algorithm to handling\nthe structural sparsity regularizer. We extensively examine the effectiveness\nof our proposed homotopy attack for both targeted and non-targeted attack\nscenarios, on CIFAR-10 and ImageNet datasets. Compared to state-of-the-art\nmethods, our homotopy attack leads to significantly fewer perturbations, e.g.,\nreducing 42.91% on CIFAR-10 and 75.03% on ImageNet (average case, targeted\nattack), at similar maximal perturbation magnitudes, when still achieving 100%\nattack success rates. Our codes are available at:\nhttps://github.com/VITA-Group/SparseADV_Homotopy.",
          "link": "http://arxiv.org/abs/2106.06027",
          "publishedOn": "2021-06-14T01:38:53.248Z",
          "wordCount": 662,
          "title": "Sparse and Imperceptible Adversarial Attack via a Homotopy Algorithm. (arXiv:2106.06027v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06011",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yibo Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haidi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1\">Yiming Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shunyao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1\">Mingliang Xu</a>",
          "description": "With the development of deep learning, the single super-resolution image\nreconstruction network models are becoming more and more complex. Small changes\nin hyperparameters of the models have a greater impact on model performance. In\nthe existing works, experts have gradually explored a set of optimal model\nparameters based on empirical values or performing brute-force search. In this\npaper, we introduce a new super-resolution image reconstruction generative\nadversarial network framework, and a Bayesian optimization method used to\noptimizing the hyperparameters of the generator and discriminator. The\ngenerator is made by self-calibrated convolution, and discriminator is made by\nconvolution lays. We have defined the hyperparameters such as the number of\nnetwork layers and the number of neurons. Our method adopts Bayesian\noptimization as a optimization policy of GAN in our model. Not only can find\nthe optimal hyperparameter solution automatically, but also can construct a\nsuper-resolution image reconstruction network, reducing the manual workload.\nExperiments show that Bayesian optimization can search the optimal solution\nearlier than the other two optimization algorithms.",
          "link": "http://arxiv.org/abs/2106.06011",
          "publishedOn": "2021-06-14T01:38:53.238Z",
          "wordCount": 619,
          "title": "A self-adapting super-resolution structures framework for automatic design of GAN. (arXiv:2106.06011v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06020",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weiler_M/0/1/0/all/0/1\">Maurice Weiler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Forre_P/0/1/0/all/0/1\">Patrick Forr&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verlinde_E/0/1/0/all/0/1\">Erik Verlinde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1\">Max Welling</a>",
          "description": "Motivated by the vast success of deep convolutional networks, there is a\ngreat interest in generalizing convolutions to non-Euclidean manifolds. A major\ncomplication in comparison to flat spaces is that it is unclear in which\nalignment a convolution kernel should be applied on a manifold. The underlying\nreason for this ambiguity is that general manifolds do not come with a\ncanonical choice of reference frames (gauge). Kernels and features therefore\nhave to be expressed relative to arbitrary coordinates. We argue that the\nparticular choice of coordinatization should not affect a network's inference\n-- it should be coordinate independent. A simultaneous demand for coordinate\nindependence and weight sharing is shown to result in a requirement on the\nnetwork to be equivariant under local gauge transformations (changes of local\nreference frames). The ambiguity of reference frames depends thereby on the\nG-structure of the manifold, such that the necessary level of gauge\nequivariance is prescribed by the corresponding structure group G. Coordinate\nindependent convolutions are proven to be equivariant w.r.t. those isometries\nthat are symmetries of the G-structure. The resulting theory is formulated in a\ncoordinate free fashion in terms of fiber bundles. To exemplify the design of\ncoordinate independent convolutions, we implement a convolutional network on\nthe M\\\"obius strip. The generality of our differential geometric formulation of\nconvolutional networks is demonstrated by an extensive literature review which\nexplains a large number of Euclidean CNNs, spherical CNNs and CNNs on general\nsurfaces as specific instances of coordinate independent convolutions.",
          "link": "http://arxiv.org/abs/2106.06020",
          "publishedOn": "2021-06-14T01:38:53.228Z",
          "wordCount": 710,
          "title": "Coordinate Independent Convolutional Networks -- Isometry and Gauge Equivariant Convolutions on Riemannian Manifolds. (arXiv:2106.06020v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06091",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alwani_M/0/1/0/all/0/1\">Manoj Alwani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madhavan_V/0/1/0/all/0/1\">Vashisht Madhavan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yang Wang</a>",
          "description": "Deep learning has become an increasingly popular and powerful option for\nmodern pattern recognition systems. However, many deep neural networks have\nmillions to billions of parameters, making them untenable for real-world\napplications with constraints on memory or latency. As a result, powerful\nnetwork compression techniques are a must for the widespread adoption of deep\nlearning. We present DECORE, a reinforcement learning approach to automate the\nnetwork compression process. Using a simple policy gradient method to learn\nwhich neurons or channels to keep or remove, we are able to achieve compression\nrates 3x to 5x greater than contemporary approaches. In contrast with other\narchitecture search methods, DECORE is simple and quick to train, requiring\nonly a few hours of training on 1 GPU. When applied to standard network\narchitectures on different datasets, our approach achieves 11x to 103x\ncompression on different architectures while maintaining accuracies similar to\nthose of the original, large networks.",
          "link": "http://arxiv.org/abs/2106.06091",
          "publishedOn": "2021-06-14T01:38:53.217Z",
          "wordCount": 574,
          "title": "DECORE: Deep Compression with Reinforcement Learning. (arXiv:2106.06091v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05974",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Riquelme_C/0/1/0/all/0/1\">Carlos Riquelme</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Puigcerver_J/0/1/0/all/0/1\">Joan Puigcerver</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mustafa_B/0/1/0/all/0/1\">Basil Mustafa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neumann_M/0/1/0/all/0/1\">Maxim Neumann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jenatton_R/0/1/0/all/0/1\">Rodolphe Jenatton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pinto_A/0/1/0/all/0/1\">Andr&#xe9; Susano Pinto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keysers_D/0/1/0/all/0/1\">Daniel Keysers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Houlsby_N/0/1/0/all/0/1\">Neil Houlsby</a>",
          "description": "Sparsely-gated Mixture of Experts networks (MoEs) have demonstrated excellent\nscalability in Natural Language Processing. In Computer Vision, however, almost\nall performant networks are \"dense\", that is, every input is processed by every\nparameter. We present a Vision MoE (V-MoE), a sparse version of the Vision\nTransformer, that is scalable and competitive with the largest dense networks.\nWhen applied to image recognition, V-MoE matches the performance of\nstate-of-the-art networks, while requiring as little as half of the compute at\ninference time. Further, we propose an extension to the routing algorithm that\ncan prioritize subsets of each input across the entire batch, leading to\nadaptive per-image compute. This allows V-MoE to trade-off performance and\ncompute smoothly at test-time. Finally, we demonstrate the potential of V-MoE\nto scale vision models, and train a 15B parameter model that attains 90.35% on\nImageNet.",
          "link": "http://arxiv.org/abs/2106.05974",
          "publishedOn": "2021-06-14T01:38:53.189Z",
          "wordCount": 589,
          "title": "Scaling Vision with Sparse Mixture of Experts. (arXiv:2106.05974v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06130",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fang_X/0/1/0/all/0/1\">Xiaomin Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lihang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_J/0/1/0/all/0/1\">Jieqiong Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1\">Donglong He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shanzhuo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jingbo Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Fan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Hua Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haifeng Wang</a>",
          "description": "Effective molecular representation learning is of great importance to\nfacilitate molecular property prediction, which is a fundamental task for the\ndrug and material industry. Recent advances in graph neural networks (GNNs)\nhave shown great promise in applying GNNs for molecular representation\nlearning. Moreover, a few recent studies have also demonstrated successful\napplications of self-supervised learning methods to pre-train the GNNs to\novercome the problem of insufficient labeled molecules. However, existing GNNs\nand pre-training strategies usually treat molecules as topological graph data\nwithout fully utilizing the molecular geometry information. Whereas, the\nthree-dimensional (3D) spatial structure of a molecule, a.k.a molecular\ngeometry, is one of the most critical factors for determining molecular\nphysical, chemical, and biological properties. To this end, we propose a novel\nGeometry Enhanced Molecular representation learning method (GEM) for Chemical\nRepresentation Learning (ChemRL). At first, we design a geometry-based GNN\narchitecture that simultaneously models atoms, bonds, and bond angles in a\nmolecule. To be specific, we devised double graphs for a molecule: The first\none encodes the atom-bond relations; The second one encodes bond-angle\nrelations. Moreover, on top of the devised GNN architecture, we propose several\nnovel geometry-level self-supervised learning strategies to learn spatial\nknowledge by utilizing the local and global molecular 3D structures. We compare\nChemRL-GEM with various state-of-the-art (SOTA) baselines on different\nmolecular benchmarks and exhibit that ChemRL-GEM can significantly outperform\nall baselines in both regression and classification tasks. For example, the\nexperimental results show an overall improvement of $8.8\\%$ on average compared\nto SOTA baselines on the regression tasks, demonstrating the superiority of the\nproposed method.",
          "link": "http://arxiv.org/abs/2106.06130",
          "publishedOn": "2021-06-14T01:38:53.181Z",
          "wordCount": 705,
          "title": "ChemRL-GEM: Geometry Enhanced Molecular Representation Learning for Property Prediction. (arXiv:2106.06130v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06090",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1\">Lingfei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_K/0/1/0/all/0/1\">Kai Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1\">Xiaojie Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_H/0/1/0/all/0/1\">Hanning Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shucheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pei_J/0/1/0/all/0/1\">Jian Pei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_B/0/1/0/all/0/1\">Bo Long</a>",
          "description": "Deep learning has become the dominant approach in coping with various tasks\nin Natural LanguageProcessing (NLP). Although text inputs are typically\nrepresented as a sequence of tokens, there isa rich variety of NLP problems\nthat can be best expressed with a graph structure. As a result, thereis a surge\nof interests in developing new deep learning techniques on graphs for a large\nnumberof NLP tasks. In this survey, we present a comprehensive overview onGraph\nNeural Networks(GNNs) for Natural Language Processing. We propose a new\ntaxonomy of GNNs for NLP, whichsystematically organizes existing research of\nGNNs for NLP along three axes: graph construction,graph representation\nlearning, and graph based encoder-decoder models. We further introducea large\nnumber of NLP applications that are exploiting the power of GNNs and summarize\nthecorresponding benchmark datasets, evaluation metrics, and open-source codes.\nFinally, we discussvarious outstanding challenges for making the full use of\nGNNs for NLP as well as future researchdirections. To the best of our\nknowledge, this is the first comprehensive overview of Graph NeuralNetworks for\nNatural Language Processing.",
          "link": "http://arxiv.org/abs/2106.06090",
          "publishedOn": "2021-06-14T01:38:53.155Z",
          "wordCount": 614,
          "title": "Graph Neural Networks for Natural Language Processing: A Survey. (arXiv:2106.06090v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06165",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1\">Ziwei Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiwei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1\">Lei Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Philip S. Yu</a>",
          "description": "The sequential patterns within the user interactions are pivotal for\nrepresenting the user's preference and capturing latent relationships among\nitems. The recent advancements of sequence modeling by Transformers advocate\nthe community to devise more effective encoders for the sequential\nrecommendation. Most existing sequential methods assume users are\ndeterministic. However, item-item transitions might fluctuate significantly in\nseveral item aspects and exhibit randomness of user interests. This\n\\textit{stochastic characteristics} brings up a solid demand to include\nuncertainties in representing sequences and items. Additionally, modeling\nsequences and items with uncertainties expands users' and items' interaction\nspaces, thus further alleviating cold-start problems.\n\nIn this work, we propose a Distribution-based Transformer for Sequential\nRecommendation (DT4SR), which injects uncertainties into sequential modeling.\nWe use Elliptical Gaussian distributions to describe items and sequences with\nuncertainty. We describe the uncertainty in items and sequences as Elliptical\nGaussian distribution. And we adopt Wasserstein distance to measure the\nsimilarity between distributions. We devise two novel Trans-formers for\nmodeling mean and covariance, which guarantees the positive-definite property\nof distributions. The proposed method significantly outperforms the\nstate-of-the-art methods. The experiments on three benchmark datasets also\ndemonstrate its effectiveness in alleviating cold-start issues. The code is\navailable inhttps://github.com/DyGRec/DT4SR.",
          "link": "http://arxiv.org/abs/2106.06165",
          "publishedOn": "2021-06-14T01:38:53.118Z",
          "wordCount": 631,
          "title": "Modeling Sequences as Distributions with Uncertainty for Sequential Recommendation. (arXiv:2106.06165v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05545",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Guo_Y/0/1/0/all/0/1\">Yibo Guo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_H/0/1/0/all/0/1\">Haidi Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fan_Y/0/1/0/all/0/1\">Yiming Fan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_S/0/1/0/all/0/1\">Shunyao Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_M/0/1/0/all/0/1\">Mingliang Xu</a>",
          "description": "With the effective application of deep learning in computer vision,\nbreakthroughs have been made in the research of super-resolution images\nreconstruction. However, many researches have pointed out that the\ninsufficiency of the neural network extraction on image features may bring the\ndeteriorating of newly reconstructed image. On the other hand, the generated\npictures are sometimes too artificial because of over-smoothing. In order to\nsolve the above problems, we propose a novel self-calibrated convolutional\ngenerative adversarial networks. The generator consists of feature extraction\nand image reconstruction. Feature extraction uses self-calibrated convolutions,\nwhich contains four portions, and each portion has specific functions. It can\nnot only expand the range of receptive fields, but also obtain long-range\nspatial and inter-channel dependencies. Then image reconstruction is performed,\nand finally a super-resolution image is reconstructed. We have conducted\nthorough experiments on different datasets including set5, set14 and BSD100\nunder the SSIM evaluation method. The experimental results prove the\neffectiveness of the proposed network.",
          "link": "http://arxiv.org/abs/2106.05545",
          "publishedOn": "2021-06-11T22:07:42.030Z",
          "wordCount": 607,
          "title": "Super-Resolution Image Reconstruction Based on Self-Calibrated Convolutional GAN. (arXiv:2106.05545v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05915",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Kamal_U/0/1/0/all/0/1\">Uday Kamal</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zunaed_M/0/1/0/all/0/1\">Mohammad Zunaed</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nizam_N/0/1/0/all/0/1\">Nusrat Binta Nizam</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hasan_T/0/1/0/all/0/1\">Taufiq Hasan</a>",
          "description": "Thoracic disease detection from chest radiographs using deep learning methods\nhas been an active area of research in the last decade. Most previous methods\nattempt to focus on the diseased organs of the image by identifying spatial\nregions responsible for significant contributions to the model's prediction. In\ncontrast, expert radiologists first locate the prominent anatomical structures\nbefore determining if those regions are anomalous. Therefore, integrating\nanatomical knowledge within deep learning models could bring substantial\nimprovement in automatic disease classification. This work proposes an\nanatomy-aware attention-based architecture named Anatomy X-Net, that\nprioritizes the spatial features guided by the pre-identified anatomy regions.\nWe leverage a semi-supervised learning method using the JSRT dataset containing\norgan-level annotation to obtain the anatomical segmentation masks (for lungs\nand heart) for the NIH and CheXpert datasets. The proposed Anatomy X-Net uses\nthe pre-trained DenseNet-121 as the backbone network with two corresponding\nstructured modules, the Anatomy Aware Attention (AAA) and Probabilistic\nWeighted Average Pooling (PWAP), in a cohesive framework for anatomical\nattention learning. Our proposed method sets new state-of-the-art performance\non the official NIH test set with an AUC score of 0.8439, proving the efficacy\nof utilizing the anatomy segmentation knowledge to improve the thoracic disease\nclassification. Furthermore, the Anatomy X-Net yields an averaged AUC of 0.9020\non the Stanford CheXpert dataset, improving on existing methods that\ndemonstrate the generalizability of the proposed framework.",
          "link": "http://arxiv.org/abs/2106.05915",
          "publishedOn": "2021-06-11T22:07:42.006Z",
          "wordCount": 679,
          "title": "Anatomy X-Net: A Semi-Supervised Anatomy Aware Convolutional Neural Network for Thoracic Disease Classification. (arXiv:2106.05915v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05933",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lai_C/0/1/0/all/0/1\">Cheng-I Jeff Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Alexander H. Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1\">Shiyu Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_Y/0/1/0/all/0/1\">Yi-Lun Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chuang_Y/0/1/0/all/0/1\">Yung-Sung Chuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_K/0/1/0/all/0/1\">Kaizhi Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khurana_S/0/1/0/all/0/1\">Sameer Khurana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cox_D/0/1/0/all/0/1\">David Cox</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glass_J/0/1/0/all/0/1\">James Glass</a>",
          "description": "Recent work on speech self-supervised learning (speech SSL) demonstrated the\nbenefits of scale in learning rich and transferable representations for\nAutomatic Speech Recognition (ASR) with limited parallel data. It is then\nnatural to investigate the existence of sparse and transferrable subnetworks in\npre-trained speech SSL models that can achieve even better low-resource ASR\nperformance. However, directly applying widely adopted pruning methods such as\nthe Lottery Ticket Hypothesis (LTH) is suboptimal in the computational cost\nneeded. Moreover, contrary to what LTH predicts, the discovered subnetworks\nyield minimal performance gain compared to the original dense network. In this\nwork, we propose Prune-Adjust- Re-Prune (PARP), which discovers and finetunes\nsubnetworks for much better ASR performance, while only requiring a single\ndownstream finetuning run. PARP is inspired by our surprising observation that\nsubnetworks pruned for pre-training tasks only needed to be slightly adjusted\nto achieve a sizeable performance boost in downstream ASR tasks. Extensive\nexperiments on low-resource English and multi-lingual ASR show (1) sparse\nsubnetworks exist in pre-trained speech SSL, and (2) the computational\nadvantage and performance gain of PARP over baseline pruning methods. On the\n10min Librispeech split without LM decoding, PARP discovers subnetworks from\nwav2vec 2.0 with an absolute 10.9%/12.6% WER decrease compared to the full\nmodel. We demonstrate PARP mitigates performance degradation in cross-lingual\nmask transfer, and investigate the possibility of discovering a single\nsubnetwork for 10 spoken languages in one run.",
          "link": "http://arxiv.org/abs/2106.05933",
          "publishedOn": "2021-06-11T01:42:18.059Z",
          "wordCount": 686,
          "title": "PARP: Prune, Adjust and Re-Prune for Self-Supervised Speech Recognition. (arXiv:2106.05933v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05852",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Adiga_D/0/1/0/all/0/1\">Devaraja Adiga</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kumar_R/0/1/0/all/0/1\">Rishabh Kumar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Krishna_A/0/1/0/all/0/1\">Amrith Krishna</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jyothi_P/0/1/0/all/0/1\">Preethi Jyothi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ramakrishnan_G/0/1/0/all/0/1\">Ganesh Ramakrishnan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Goyal_P/0/1/0/all/0/1\">Pawan Goyal</a>",
          "description": "Automatic speech recognition (ASR) in Sanskrit is interesting, owing to the\nvarious linguistic peculiarities present in the language. The Sanskrit language\nis lexically productive, undergoes euphonic assimilation of phones at the word\nboundaries and exhibits variations in spelling conventions and in\npronunciations. In this work, we propose the first large scale study of\nautomatic speech recognition (ASR) in Sanskrit, with an emphasis on the impact\nof unit selection in Sanskrit ASR. In this work, we release a 78 hour ASR\ndataset for Sanskrit, which faithfully captures several of the linguistic\ncharacteristics expressed by the language. We investigate the role of different\nacoustic model and language model units in ASR systems for Sanskrit. We also\npropose a new modelling unit, inspired by the syllable level unit selection,\nthat captures character sequences from one vowel in the word to the next vowel.\nWe also highlight the importance of choosing graphemic representations for\nSanskrit and show the impact of this choice on word error rates (WER). Finally,\nwe extend these insights from Sanskrit ASR for building ASR systems in two\nother Indic languages, Gujarati and Telugu. For both these languages, our\nexperimental results show that the use of phonetic based graphemic\nrepresentations in ASR results in performance improvements as compared to ASR\nsystems that use native scripts.",
          "link": "http://arxiv.org/abs/2106.05852",
          "publishedOn": "2021-06-11T01:42:18.053Z",
          "wordCount": 685,
          "title": "Automatic Speech Recognition in Sanskrit: A New Speech Corpus and Modelling Insights. (arXiv:2106.05852v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05967",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gansbeke_W/0/1/0/all/0/1\">Wouter Van Gansbeke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vandenhende_S/0/1/0/all/0/1\">Simon Vandenhende</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Georgoulis_S/0/1/0/all/0/1\">Stamatios Georgoulis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1\">Luc Van Gool</a>",
          "description": "Contrastive self-supervised learning has outperformed supervised pretraining\non many downstream tasks like segmentation and object detection. However,\ncurrent methods are still primarily applied to curated datasets like ImageNet.\nIn this paper, we first study how biases in the dataset affect existing\nmethods. Our results show that current contrastive approaches work surprisingly\nwell across: (i) object- versus scene-centric, (ii) uniform versus long-tailed\nand (iii) general versus domain-specific datasets. Second, given the generality\nof the approach, we try to realize further gains with minor modifications. We\nshow that learning additional invariances -- through the use of multi-scale\ncropping, stronger augmentations and nearest neighbors -- improves the\nrepresentations. Finally, we observe that MoCo learns spatially structured\nrepresentations when trained with a multi-crop strategy. The representations\ncan be used for semantic segment retrieval and video instance segmentation\nwithout finetuning. Moreover, the results are on par with specialized models.\nWe hope this work will serve as a useful study for other researchers. The code\nand models will be available at\nhttps://github.com/wvangansbeke/Revisiting-Contrastive-SSL.",
          "link": "http://arxiv.org/abs/2106.05967",
          "publishedOn": "2021-06-11T01:42:18.047Z",
          "wordCount": 617,
          "title": "Revisiting Contrastive Methods for Unsupervised Learning of Visual Representations. (arXiv:2106.05967v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05945",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Stanton_S/0/1/0/all/0/1\">Samuel Stanton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Izmailov_P/0/1/0/all/0/1\">Pavel Izmailov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kirichenko_P/0/1/0/all/0/1\">Polina Kirichenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alemi_A/0/1/0/all/0/1\">Alexander A. Alemi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilson_A/0/1/0/all/0/1\">Andrew Gordon Wilson</a>",
          "description": "Knowledge distillation is a popular technique for training a small student\nnetwork to emulate a larger teacher model, such as an ensemble of networks. We\nshow that while knowledge distillation can improve student generalization, it\ndoes not typically work as it is commonly understood: there often remains a\nsurprisingly large discrepancy between the predictive distributions of the\nteacher and the student, even in cases when the student has the capacity to\nperfectly match the teacher. We identify difficulties in optimization as a key\nreason for why the student is unable to match the teacher. We also show how the\ndetails of the dataset used for distillation play a role in how closely the\nstudent matches the teacher -- and that more closely matching the teacher\nparadoxically does not always lead to better student generalization.",
          "link": "http://arxiv.org/abs/2106.05945",
          "publishedOn": "2021-06-11T01:42:18.029Z",
          "wordCount": 561,
          "title": "Does Knowledge Distillation Really Work?. (arXiv:2106.05945v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05923",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bano_S/0/1/0/all/0/1\">Sophia Bano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Casella_A/0/1/0/all/0/1\">Alessandro Casella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasconcelos_F/0/1/0/all/0/1\">Francisco Vasconcelos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moccia_S/0/1/0/all/0/1\">Sara Moccia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Attilakos_G/0/1/0/all/0/1\">George Attilakos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wimalasundera_R/0/1/0/all/0/1\">Ruwan Wimalasundera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+David_A/0/1/0/all/0/1\">Anna L. David</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paladini_D/0/1/0/all/0/1\">Dario Paladini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deprest_J/0/1/0/all/0/1\">Jan Deprest</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mattos_L/0/1/0/all/0/1\">Leonardo S. Mattos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stoyanov_D/0/1/0/all/0/1\">Danail Stoyanov</a>",
          "description": "Fetoscopy laser photocoagulation is a widely used procedure for the treatment\nof Twin-to-Twin Transfusion Syndrome (TTTS), that occur in mono-chorionic\nmultiple pregnancies due to placental vascular anastomoses. This procedure is\nparticularly challenging due to limited field of view, poor manoeuvrability of\nthe fetoscope, poor visibility due to fluid turbidity, variability in light\nsource, and unusual position of the placenta. This may lead to increased\nprocedural time and incomplete ablation, resulting in persistent TTTS.\nComputer-assisted intervention may help overcome these challenges by expanding\nthe fetoscopic field of view through video mosaicking and providing better\nvisualization of the vessel network. However, the research and development in\nthis domain remain limited due to unavailability of high-quality data to encode\nthe intra- and inter-procedure variability. Through the Fetoscopic Placental\nVessel Segmentation and Registration (FetReg) challenge, we present a\nlarge-scale multi-centre dataset for the development of generalized and robust\nsemantic segmentation and video mosaicking algorithms for the fetal environment\nwith a focus on creating drift-free mosaics from long duration fetoscopy\nvideos. In this paper, we provide an overview of the FetReg dataset, challenge\ntasks, evaluation metrics and baseline methods for both segmentation and\nregistration. Baseline methods results on the FetReg dataset shows that our\ndataset poses interesting challenges, which can be modelled and competed for\nthrough our crowd-sourcing initiative of the FetReg challenge.",
          "link": "http://arxiv.org/abs/2106.05923",
          "publishedOn": "2021-06-11T01:42:18.023Z",
          "wordCount": 682,
          "title": "FetReg: Placental Vessel Segmentation and Registration in Fetoscopy Challenge Dataset. (arXiv:2106.05923v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2002.05273",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Li_X/0/1/0/all/0/1\">Xiaoyu Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhuang_Z/0/1/0/all/0/1\">Zhenxun Zhuang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Orabona_F/0/1/0/all/0/1\">Francesco Orabona</a>",
          "description": "Stochastic Gradient Descent (SGD) is a popular tool in training large-scale\nmachine learning models. Its performance, however, is highly variable,\ndepending crucially on the choice of the step sizes. Accordingly, a variety of\nstrategies for tuning the step sizes have been proposed, ranging from\ncoordinate-wise approaches (a.k.a. ``adaptive'' step sizes) to sophisticated\nheuristics to change the step size in each iteration. In this paper, we study\ntwo step size schedules whose power has been repeatedly confirmed in practice:\nthe exponential and the cosine step sizes. For the first time, we provide\ntheoretical support for them proving convergence rates for smooth non-convex\nfunctions, with and without the Polyak-\\L{}ojasiewicz (PL) condition. Moreover,\nwe show the surprising property that these two strategies are \\emph{adaptive}\nto the noise level in the stochastic gradients of PL functions. That is,\ncontrary to polynomial step sizes, they achieve almost optimal performance\nwithout needing to know the noise level nor tuning their hyperparameters based\non it. Finally, we conduct a fair and comprehensive empirical evaluation of\nreal-world datasets with deep learning architectures. Results show that, even\nif only requiring at most two hyperparameters to tune, these two strategies\nbest or match the performance of various finely-tuned state-of-the-art\nstrategies.",
          "link": "http://arxiv.org/abs/2002.05273",
          "publishedOn": "2021-06-11T01:42:18.017Z",
          "wordCount": 671,
          "title": "A Second look at Exponential and Cosine Step Sizes: Simplicity, Adaptivity, and Performance. (arXiv:2002.05273v4 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05836",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gu_F/0/1/0/all/0/1\">Fuqiang Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sng_W/0/1/0/all/0/1\">Weicong Sng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xuke Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1\">Fangwen Yu</a>",
          "description": "The advantages of event-sensing over conventional sensors (e.g., higher\ndynamic range, lower time latency, and lower power consumption) have spurred\nresearch into machine learning for event data. Unsurprisingly, deep learning\nhas emerged as a competitive methodology for learning with event sensors; in\ntypical setups, discrete and asynchronous events are first converted into\nframe-like tensors on which standard deep networks can be applied. However,\nover-fitting remains a challenge, particularly since event datasets remain\nsmall relative to conventional datasets (e.g., ImageNet). In this paper, we\nintroduce EventDrop, a new method for augmenting asynchronous event data to\nimprove the generalization of deep models. By dropping events selected with\nvarious strategies, we are able to increase the diversity of training data\n(e.g., to simulate various levels of occlusion). From a practical perspective,\nEventDrop is simple to implement and computationally low-cost. Experiments on\ntwo event datasets (N-Caltech101 and N-Cars) demonstrate that EventDrop can\nsignificantly improve the generalization performance across a variety of deep\nnetworks.",
          "link": "http://arxiv.org/abs/2106.05836",
          "publishedOn": "2021-06-11T01:42:18.010Z",
          "wordCount": 587,
          "title": "EventDrop: data augmentation for event-based learning. (arXiv:2106.05836v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2007.13040",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yao_H/0/1/0/all/0/1\">Huaxiu Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1\">Longkai Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Linjun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1\">Ying Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_L/0/1/0/all/0/1\">Li Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1\">James Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Junzhou Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhenhui Li</a>",
          "description": "Meta-learning has proven to be a powerful paradigm for transferring the\nknowledge from previous tasks to facilitate the learning of a novel task.\nCurrent dominant algorithms train a well-generalized model initialization which\nis adapted to each task via the support set. The crux lies in optimizing the\ngeneralization capability of the initialization, which is measured by the\nperformance of the adapted model on the query set of each task. Unfortunately,\nthis generalization measure, evidenced by empirical results, pushes the\ninitialization to overfit the meta-training tasks, which significantly impairs\nthe generalization and adaptation to novel tasks. To address this issue, we\nactively augment a meta-training task with \"more data\" when evaluating the\ngeneralization. Concretely, we propose two task augmentation methods, including\nMetaMix and Channel Shuffle. MetaMix linearly combines features and labels of\nsamples from both the support and query sets. For each class of samples,\nChannel Shuffle randomly replaces a subset of their channels with the\ncorresponding ones from a different class. Theoretical studies show how task\naugmentation improves the generalization of meta-learning. Moreover, both\nMetaMix and Channel Shuffle outperform state-of-the-art results by a large\nmargin across many datasets and are compatible with existing meta-learning\nalgorithms.",
          "link": "http://arxiv.org/abs/2007.13040",
          "publishedOn": "2021-06-11T01:42:17.993Z",
          "wordCount": 674,
          "title": "Improving Generalization in Meta-learning via Task Augmentation. (arXiv:2007.13040v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1901.11351",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tsuchiya_T/0/1/0/all/0/1\">Taira Tsuchiya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Charoenphakdee_N/0/1/0/all/0/1\">Nontawat Charoenphakdee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sato_I/0/1/0/all/0/1\">Issei Sato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masashi Sugiyama</a>",
          "description": "Ordinal regression is aimed at predicting an ordinal class label. In this\npaper, we consider its semi-supervised formulation, in which we have unlabeled\ndata along with ordinal-labeled data to train an ordinal regressor. There are\nseveral metrics to evaluate the performance of ordinal regression, such as the\nmean absolute error, mean zero-one error, and mean squared error. However, the\nexisting studies do not take the evaluation metric into account, have a\nrestriction on the model choice, and have no theoretical guarantee. To overcome\nthese problems, we propose a novel generic framework for semi-supervised\nordinal regression based on the empirical risk minimization principle that is\napplicable to optimizing all of the metrics mentioned above. Besides, our\nframework has flexible choices of models, surrogate losses, and optimization\nalgorithms without the common geometric assumption on unlabeled data such as\nthe cluster assumption or manifold assumption. We further provide an estimation\nerror bound to show that our risk estimator is consistent. Finally, we conduct\nexperiments to show the usefulness of our framework.",
          "link": "http://arxiv.org/abs/1901.11351",
          "publishedOn": "2021-06-11T01:42:17.987Z",
          "wordCount": 640,
          "title": "Semi-Supervised Ordinal Regression Based on Empirical Risk Minimization. (arXiv:1901.11351v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.07593",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_V/0/1/0/all/0/1\">Vu Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_T/0/1/0/all/0/1\">Tam Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamada_M/0/1/0/all/0/1\">Makoto Yamada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Osborne_M/0/1/0/all/0/1\">Michael A Osborne</a>",
          "description": "Neural architecture search (NAS) automates the design of deep neural\nnetworks. One of the main challenges in searching complex and non-continuous\narchitectures is to compare the similarity of networks that the conventional\nEuclidean metric may fail to capture. Optimal transport (OT) is resilient to\nsuch complex structure by considering the minimal cost for transporting a\nnetwork into another. However, the OT is generally not negative definite which\nmay limit its ability to build the positive-definite kernels required in many\nkernel-dependent frameworks. Building upon tree-Wasserstein (TW), which is a\nnegative definite variant of OT, we develop a novel discrepancy for neural\narchitectures, and demonstrate it within a Gaussian process surrogate model for\nthe sequential NAS settings. Furthermore, we derive a novel parallel NAS, using\nquality k-determinantal point process on the GP posterior, to select diverse\nand high-performing architectures from a discrete set of candidates.\nEmpirically, we demonstrate that our TW-based approaches outperform other\nbaselines in both sequential and parallel NAS.",
          "link": "http://arxiv.org/abs/2006.07593",
          "publishedOn": "2021-06-11T01:42:17.982Z",
          "wordCount": 644,
          "title": "Optimal Transport Kernels for Sequential and Parallel Neural Architecture Search. (arXiv:2006.07593v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2003.13827",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Forcen_J/0/1/0/all/0/1\">J.I.Forcen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pagola_M/0/1/0/all/0/1\">Miguel Pagola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barrenechea_E/0/1/0/all/0/1\">Edurne Barrenechea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bustince_H/0/1/0/all/0/1\">Humberto Bustince</a>",
          "description": "Image search can be tackled using deep features from pre-trained\nConvolutional Neural Networks (CNN). The feature map from the last\nconvolutional layer of a CNN encodes descriptive information from which a\ndiscriminative global descriptor can be obtained. We propose a new\nrepresentation of co-occurrences from deep convolutional features to extract\nadditional relevant information from this last convolutional layer. Combining\nthis co-occurrence map with the feature map, we achieve an improved image\nrepresentation. We present two different methods to get the co-occurrence\nrepresentation, the first one based on direct aggregation of activations, and\nthe second one, based on a trainable co-occurrence representation. The image\ndescriptors derived from our methodology improve the performance in very\nwell-known image retrieval datasets as we prove in the experiments.",
          "link": "http://arxiv.org/abs/2003.13827",
          "publishedOn": "2021-06-11T01:42:17.976Z",
          "wordCount": 592,
          "title": "Co-occurrence of deep convolutional features for image search. (arXiv:2003.13827v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.12560",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Filos_A/0/1/0/all/0/1\">Angelos Filos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyle_C/0/1/0/all/0/1\">Clare Lyle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gal_Y/0/1/0/all/0/1\">Yarin Gal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1\">Sergey Levine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaques_N/0/1/0/all/0/1\">Natasha Jaques</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farquhar_G/0/1/0/all/0/1\">Gregory Farquhar</a>",
          "description": "We study reinforcement learning (RL) with no-reward demonstrations, a setting\nin which an RL agent has access to additional data from the interaction of\nother agents with the same environment. However, it has no access to the\nrewards or goals of these agents, and their objectives and levels of expertise\nmay vary widely. These assumptions are common in multi-agent settings, such as\nautonomous driving. To effectively use this data, we turn to the framework of\nsuccessor features. This allows us to disentangle shared features and dynamics\nof the environment from agent-specific rewards and policies. We propose a\nmulti-task inverse reinforcement learning (IRL) algorithm, called \\emph{inverse\ntemporal difference learning} (ITD), that learns shared state features,\nalongside per-agent successor features and preference vectors, purely from\ndemonstrations without reward labels. We further show how to seamlessly\nintegrate ITD with learning from online environment interactions, arriving at a\nnovel algorithm for reinforcement learning with demonstrations, called $\\Psi\n\\Phi$-learning (pronounced `Sci-Fi'). We provide empirical evidence for the\neffectiveness of $\\Psi \\Phi$-learning as a method for improving RL, IRL,\nimitation, and few-shot transfer, and derive worst-case bounds for its\nperformance in zero-shot transfer to new tasks.",
          "link": "http://arxiv.org/abs/2102.12560",
          "publishedOn": "2021-06-11T01:42:17.970Z",
          "wordCount": 673,
          "title": "PsiPhi-Learning: Reinforcement Learning with Demonstrations using Successor Features and Inverse Temporal Difference Learning. (arXiv:2102.12560v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05929",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tripathi_A/0/1/0/all/0/1\">Arpan Tripathi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rakkunedeth_A/0/1/0/all/0/1\">Abhilash Rakkunedeth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panicker_M/0/1/0/all/0/1\">Mahesh Raveendranatha Panicker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jack Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boora_N/0/1/0/all/0/1\">Naveenjyote Boora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaremko_J/0/1/0/all/0/1\">Jacob Jaremko</a>",
          "description": "Ultrasound examination for detecting fractures is ideally suited for\nEmergency Departments (ED) as it is relatively fast, safe (from ionizing\nradiation), has dynamic imaging capability and is easily portable. High\ninterobserver variability in manual assessment of ultrasound scans has piqued\nresearch interest in automatic assessment techniques using Deep Learning (DL).\nMost DL techniques are supervised and are trained on large numbers of labeled\ndata which is expensive and requires many hours of careful annotation by\nexperts. In this paper, we propose an unsupervised, domain specific transporter\nframework to identify relevant keypoints from wrist ultrasound scans. Our\nframework provides a concise geometric representation highlighting regions with\nhigh structural variation in a 3D ultrasound (3DUS) sequence. We also\nincorporate domain specific information represented by instantaneous local\nphase (LP) which detects bone features from 3DUS. We validate the technique on\n3DUS videos obtained from 30 subjects. Each ultrasound scan was independently\nassessed by three readers to identify fractures along with the corresponding\nx-ray. Saliency of keypoints detected in the image\\ are compared against manual\nassessment based on distance from relevant features.The transporter neural\nnetwork was able to accurately detect 180 out of 250 bone regions sampled from\nwrist ultrasound videos. We expect this technique to increase the applicability\nof ultrasound in fracture detection.",
          "link": "http://arxiv.org/abs/2106.05929",
          "publishedOn": "2021-06-11T01:42:17.964Z",
          "wordCount": 646,
          "title": "Domain Specific Transporter Framework to Detect Fractures in Ultrasound. (arXiv:2106.05929v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2003.05554",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Loper_J/0/1/0/all/0/1\">Jackson Loper</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Blei_D/0/1/0/all/0/1\">David Blei</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cunningham_J/0/1/0/all/0/1\">John P. Cunningham</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Paninski_L/0/1/0/all/0/1\">Liam Paninski</a>",
          "description": "Gaussian Processes (GPs) provide powerful probabilistic frameworks for\ninterpolation, forecasting, and smoothing, but have been hampered by\ncomputational scaling issues. Here we investigate data sampled on one dimension\n(e.g., a scalar or vector time series sampled at arbitrarily-spaced intervals),\nfor which state-space models are popular due to their linearly-scaling\ncomputational costs. It has long been conjectured that state-space models are\ngeneral, able to approximate any one-dimensional GP. We provide the first\ngeneral proof of this conjecture, showing that any stationary GP on one\ndimension with vector-valued observations governed by a Lebesgue-integrable\ncontinuous kernel can be approximated to any desired precision using a\nspecifically-chosen state-space model: the Latent Exponentially Generated (LEG)\nfamily. This new family offers several advantages compared to the general\nstate-space model: it is always stable (no unbounded growth), the covariance\ncan be computed in closed form, and its parameter space is unconstrained\n(allowing straightforward estimation via gradient descent). The theorem's proof\nalso draws connections to Spectral Mixture Kernels, providing insight about\nthis popular family of kernels. We develop parallelized algorithms for\nperforming inference and learning in the LEG model, test the algorithm on real\nand synthetic data, and demonstrate scaling to datasets with billions of\nsamples.",
          "link": "http://arxiv.org/abs/2003.05554",
          "publishedOn": "2021-06-11T01:42:17.950Z",
          "wordCount": 677,
          "title": "Linear-time inference for Gaussian Processes on one dimension. (arXiv:2003.05554v4 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.03240",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Murphy_K/0/1/0/all/0/1\">Kieran A. Murphy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jampani_V/0/1/0/all/0/1\">Varun Jampani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramalingam_S/0/1/0/all/0/1\">Srikumar Ramalingam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Makadia_A/0/1/0/all/0/1\">Ameesh Makadia</a>",
          "description": "Representational learning forms the backbone of most deep learning\napplications, and the value of a learned representation is intimately tied to\nits information content regarding different factors of variation. Finding good\nrepresentations depends on the nature of supervision and the learning\nalgorithm. We propose a novel algorithm that relies on a weak form of\nsupervision where the data is partitioned into sets according to certain\ninactive factors of variation. Our key insight is that by seeking approximate\ncorrespondence between elements of different sets, we learn strong\nrepresentations that exclude the inactive factors of variation and isolate the\nactive factors which vary within all sets. We demonstrate that the method can\nwork in a semi-supervised scenario, and that a portion of the unsupervised data\ncan belong to a different domain entirely. Further control over the content of\nthe learned representations is possible by folding in data augmentation to\nsuppress nuisance factors. We outperform competing baselines on the challenging\nproblem of synthetic-to-real object pose transfer.",
          "link": "http://arxiv.org/abs/2103.03240",
          "publishedOn": "2021-06-11T01:42:17.944Z",
          "wordCount": 628,
          "title": "Learn your ABCs: Approximate Bijective Correspondence for isolating factors of variation. (arXiv:2103.03240v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.01062",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zintgraf_L/0/1/0/all/0/1\">Luisa Zintgraf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_L/0/1/0/all/0/1\">Leo Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1\">Cong Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Igl_M/0/1/0/all/0/1\">Maximilian Igl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hartikainen_K/0/1/0/all/0/1\">Kristian Hartikainen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hofmann_K/0/1/0/all/0/1\">Katja Hofmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Whiteson_S/0/1/0/all/0/1\">Shimon Whiteson</a>",
          "description": "To rapidly learn a new task, it is often essential for agents to explore\nefficiently -- especially when performance matters from the first timestep. One\nway to learn such behaviour is via meta-learning. Many existing methods however\nrely on dense rewards for meta-training, and can fail catastrophically if the\nrewards are sparse. Without a suitable reward signal, the need for exploration\nduring meta-training is exacerbated. To address this, we propose HyperX, which\nuses novel reward bonuses for meta-training to explore in approximate\nhyper-state space (where hyper-states represent the environment state and the\nagent's task belief). We show empirically that HyperX meta-learns better\ntask-exploration and adapts more successfully to new tasks than existing\nmethods.",
          "link": "http://arxiv.org/abs/2010.01062",
          "publishedOn": "2021-06-11T01:42:17.939Z",
          "wordCount": 605,
          "title": "Exploration in Approximate Hyper-State Space for Meta Reinforcement Learning. (arXiv:2010.01062v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05870",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Patel_K/0/1/0/all/0/1\">Kanil Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beluch_W/0/1/0/all/0/1\">William Beluch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rambach_K/0/1/0/all/0/1\">Kilian Rambach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cozma_A/0/1/0/all/0/1\">Adriana-Eliza Cozma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfeiffer_M/0/1/0/all/0/1\">Michael Pfeiffer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1\">Bin Yang</a>",
          "description": "Deep learning (DL) has recently attracted increasing interest to improve\nobject type classification for automotive radar.In addition to high accuracy,\nit is crucial for decision making in autonomous vehicles to evaluate the\nreliability of the predictions; however, decisions of DL networks are\nnon-transparent. Current DL research has investigated how uncertainties of\npredictions can be quantified, and in this article, we evaluate the potential\nof these methods for safe, automotive radar perception. In particular we\nevaluate how uncertainty quantification can support radar perception under (1)\ndomain shift, (2) corruptions of input signals, and (3) in the presence of\nunknown objects. We find that in agreement with phenomena observed in the\nliterature,deep radar classifiers are overly confident, even in their wrong\npredictions. This raises concerns about the use of the confidence values for\ndecision making under uncertainty, as the model fails to notify when it cannot\nhandle an unknown situation. Accurate confidence values would allow optimal\nintegration of multiple information sources, e.g. via sensor fusion. We show\nthat by applying state-of-the-art post-hoc uncertainty calibration, the quality\nof confidence measures can be significantly improved,thereby partially\nresolving the over-confidence problem. Our investigation shows that further\nresearch into training and calibrating DL networks is necessary and offers\ngreat potential for safe automotive object classification with radar sensors.",
          "link": "http://arxiv.org/abs/2106.05870",
          "publishedOn": "2021-06-11T01:42:17.933Z",
          "wordCount": 661,
          "title": "Investigation of Uncertainty of Deep Learning-based Object Classification on Radar Spectra. (arXiv:2106.05870v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2007.01903",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Biggs_M/0/1/0/all/0/1\">Max Biggs</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sun_W/0/1/0/all/0/1\">Wei Sun</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ettl_M/0/1/0/all/0/1\">Markus Ettl</a>",
          "description": "Data-driven pricing strategies are becoming increasingly common, where\ncustomers are offered a personalized price based on features that are\npredictive of their valuation of a product. It is desirable for this pricing\npolicy to be simple and interpretable, so it can be verified, checked for\nfairness, and easily implemented. However, efforts to incorporate machine\nlearning into a pricing framework often lead to complex pricing policies which\nare not interpretable, resulting in slow adoption in practice. We present a\ncustomized, prescriptive tree-based algorithm that distills knowledge from a\ncomplex black-box machine learning algorithm, segments customers with similar\nvaluations and prescribes prices in such a way that maximizes revenue while\nmaintaining interpretability. We quantify the regret of a resulting policy and\ndemonstrate its efficacy in applications with both synthetic and real-world\ndatasets.",
          "link": "http://arxiv.org/abs/2007.01903",
          "publishedOn": "2021-06-11T01:42:17.928Z",
          "wordCount": 576,
          "title": "Model Distillation for Revenue Optimization: Interpretable Personalized Pricing. (arXiv:2007.01903v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.05530",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ali_R/0/1/0/all/0/1\">Ramy E. Ali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+So_J/0/1/0/all/0/1\">Jinhyun So</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Avestimehr_A/0/1/0/all/0/1\">A. Salman Avestimehr</a>",
          "description": "Outsourcing neural network inference tasks to an untrusted cloud raises data\nprivacy and integrity concerns. To address these challenges, several\nprivacy-preserving and verifiable inference techniques have been proposed based\non replacing the non-polynomial activation functions such as the rectified\nlinear unit (ReLU) function with polynomial activation functions. Such\ntechniques usually require polynomials with integer coefficients or polynomials\nover finite fields. Motivated by such requirements, several works proposed\nreplacing the ReLU activation function with the square activation function. In\nthis work, we empirically show that the square function is not the best\ndegree-$2$ polynomial that can replace the ReLU function even when restricting\nthe polynomials to have integer coefficients. We instead propose a degree-$2$\npolynomial activation function with a first order term and empirically show\nthat it can lead to much better models. Our experiments on the CIFAR-$10$ and\nCIFAR-$100$ datasets on various architectures show that our proposed activation\nfunction improves the test accuracy by up to $9.4\\%$ compared to the square\nfunction.",
          "link": "http://arxiv.org/abs/2011.05530",
          "publishedOn": "2021-06-11T01:42:17.907Z",
          "wordCount": 631,
          "title": "On Polynomial Approximations for Privacy-Preserving and Verifiable ReLU Networks. (arXiv:2011.05530v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05961",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_W/0/1/0/all/0/1\">Weijian Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gould_S/0/1/0/all/0/1\">Stephen Gould</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1\">Liang Zheng</a>",
          "description": "Understanding classifier decision under novel environments is central to the\ncommunity, and a common practice is evaluating it on labeled test sets.\nHowever, in real-world testing, image annotations are difficult and expensive\nto obtain, especially when the test environment is changing. A natural question\nthen arises: given a trained classifier, can we evaluate its accuracy on\nvarying unlabeled test sets? In this work, we train semantic classification and\nrotation prediction in a multi-task way. On a series of datasets, we report an\ninteresting finding, i.e., the semantic classification accuracy exhibits a\nstrong linear relationship with the accuracy of the rotation prediction task\n(Pearson's Correlation r > 0.88). This finding allows us to utilize linear\nregression to estimate classifier performance from the accuracy of rotation\nprediction which can be obtained on the test set through the freely generated\nrotation labels.",
          "link": "http://arxiv.org/abs/2106.05961",
          "publishedOn": "2021-06-11T01:42:17.901Z",
          "wordCount": 586,
          "title": "What Does Rotation Prediction Tell Us about Classifier Accuracy under Varying Testing Environments?. (arXiv:2106.05961v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05934",
          "author": "<a href=\"http://arxiv.org/find/hep-lat/1/au:+Albergo_M/0/1/0/all/0/1\">Michael S. Albergo</a>, <a href=\"http://arxiv.org/find/hep-lat/1/au:+Kanwar_G/0/1/0/all/0/1\">Gurtej Kanwar</a>, <a href=\"http://arxiv.org/find/hep-lat/1/au:+Racaniere_S/0/1/0/all/0/1\">S&#xe9;bastien Racani&#xe8;re</a>, <a href=\"http://arxiv.org/find/hep-lat/1/au:+Rezende_D/0/1/0/all/0/1\">Danilo J. Rezende</a>, <a href=\"http://arxiv.org/find/hep-lat/1/au:+Urban_J/0/1/0/all/0/1\">Julian M. Urban</a>, <a href=\"http://arxiv.org/find/hep-lat/1/au:+Boyda_D/0/1/0/all/0/1\">Denis Boyda</a>, <a href=\"http://arxiv.org/find/hep-lat/1/au:+Cranmer_K/0/1/0/all/0/1\">Kyle Cranmer</a>, <a href=\"http://arxiv.org/find/hep-lat/1/au:+Hackett_D/0/1/0/all/0/1\">Daniel C. Hackett</a>, <a href=\"http://arxiv.org/find/hep-lat/1/au:+Shanahan_P/0/1/0/all/0/1\">Phiala E. Shanahan</a>",
          "description": "Algorithms based on normalizing flows are emerging as promising machine\nlearning approaches to sampling complicated probability distributions in a way\nthat can be made asymptotically exact. In the context of lattice field theory,\nproof-of-principle studies have demonstrated the effectiveness of this approach\nfor scalar theories, gauge theories, and statistical systems. This work\ndevelops approaches that enable flow-based sampling of theories with dynamical\nfermions, which is necessary for the technique to be applied to lattice field\ntheory studies of the Standard Model of particle physics and many condensed\nmatter systems. As a practical demonstration, these methods are applied to the\nsampling of field configurations for a two-dimensional theory of massless\nstaggered fermions coupled to a scalar field via a Yukawa interaction.",
          "link": "http://arxiv.org/abs/2106.05934",
          "publishedOn": "2021-06-11T01:42:17.895Z",
          "wordCount": 579,
          "title": "Flow-based sampling for fermionic lattice field theories. (arXiv:2106.05934v1 [hep-lat])"
        },
        {
          "id": "http://arxiv.org/abs/2012.01744",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Dedieu_A/0/1/0/all/0/1\">Antoine Dedieu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lazaro_Gredilla_M/0/1/0/all/0/1\">Miguel L&#xe1;zaro-Gredilla</a>, <a href=\"http://arxiv.org/find/stat/1/au:+George_D/0/1/0/all/0/1\">Dileep George</a>",
          "description": "We consider the problem of learning the underlying graph of a sparse Ising\nmodel with $p$ nodes from $n$ i.i.d. samples. The most recent and best\nperforming approaches combine an empirical loss (the logistic regression loss\nor the interaction screening loss) with a regularizer (an L1 penalty or an L1\nconstraint). This results in a convex problem that can be solved separately for\neach node of the graph. In this work, we leverage the cardinality constraint L0\nnorm, which is known to properly induce sparsity, and further combine it with\nan L2 norm to better model the non-zero coefficients. We show that our proposed\nestimators achieve an improved sample complexity, both (a) theoretically, by\nreaching new state-of-the-art upper bounds for recovery guarantees, and (b)\nempirically, by showing sharper phase transitions between poor and full\nrecovery for graph topologies studied in the literature, when compared to their\nL1-based state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2012.01744",
          "publishedOn": "2021-06-11T01:42:17.884Z",
          "wordCount": 603,
          "title": "Sample-Efficient L0-L2 Constrained Structure Learning of Sparse Ising Models. (arXiv:2012.01744v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05799",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Groll_A/0/1/0/all/0/1\">Andreas Groll</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hvattum_L/0/1/0/all/0/1\">Lars Magnus Hvattum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ley_C/0/1/0/all/0/1\">Christophe Ley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Popp_F/0/1/0/all/0/1\">Franziska Popp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schauberger_G/0/1/0/all/0/1\">Gunther Schauberger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eetvelde_H/0/1/0/all/0/1\">Hans Van Eetvelde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeileis_A/0/1/0/all/0/1\">Achim Zeileis</a>",
          "description": "Three state-of-the-art statistical ranking methods for forecasting football\nmatches are combined with several other predictors in a hybrid machine learning\nmodel. Namely an ability estimate for every team based on historic matches; an\nability estimate for every team based on bookmaker consensus; average\nplus-minus player ratings based on their individual performances in their home\nclubs and national teams; and further team covariates (e.g., market value, team\nstructure) and country-specific socio-economic factors (population, GDP). The\nproposed combined approach is used for learning the number of goals scored in\nthe matches from the four previous UEFA EUROs 2004-2016 and then applied to\ncurrent information to forecast the upcoming UEFA EURO 2020. Based on the\nresulting estimates, the tournament is simulated repeatedly and winning\nprobabilities are obtained for all teams. A random forest model favors the\ncurrent World Champion France with a winning probability of 14.8% before\nEngland (13.5%) and Spain (12.3%). Additionally, we provide survival\nprobabilities for all teams and at all tournament stages.",
          "link": "http://arxiv.org/abs/2106.05799",
          "publishedOn": "2021-06-11T01:42:17.870Z",
          "wordCount": 621,
          "title": "Hybrid Machine Learning Forecasts for the UEFA EURO 2020. (arXiv:2106.05799v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05907",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Minghao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jian_P/0/1/0/all/0/1\">Pingcheng Jian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Huazhe Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaolong Wang</a>",
          "description": "We address the problem of solving complex bimanual robot manipulation tasks\non multiple objects with sparse rewards. Such complex tasks can be decomposed\ninto sub-tasks that are accomplishable by different robots concurrently or\nsequentially for better efficiency. While previous reinforcement learning\napproaches primarily focus on modeling the compositionality of sub-tasks, two\nfundamental issues are largely ignored particularly when learning cooperative\nstrategies for two robots: (i) domination, i.e., one robot may try to solve a\ntask by itself and leaves the other idle; (ii) conflict, i.e., one robot can\neasily interrupt another's workspace when executing different sub-tasks\nsimultaneously. To tackle these two issues, we propose a novel technique called\ndisentangled attention, which provides an intrinsic regularization for two\nrobots to focus on separate sub-tasks and objects. We evaluate our method on\nfour bimanual manipulation tasks. Experimental results show that our proposed\nintrinsic regularization successfully avoids domination and reduces conflicts\nfor the policies, which leads to significantly more effective cooperative\nstrategies than all the baselines. Our project page with videos is at\nhttps://mehooz.github.io/bimanual-attention.",
          "link": "http://arxiv.org/abs/2106.05907",
          "publishedOn": "2021-06-11T01:42:17.864Z",
          "wordCount": 608,
          "title": "Disentangled Attention as Intrinsic Regularization for Bimanual Multi-Object Manipulation. (arXiv:2106.05907v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10056",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1\">Zhuangdi Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_J/0/1/0/all/0/1\">Junyuan Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jiayu Zhou</a>",
          "description": "Federated Learning (FL) is a decentralized machine-learning paradigm, in\nwhich a global server iteratively averages the model parameters of local users\nwithout accessing their data. User heterogeneity has imposed significant\nchallenges to FL, which can incur drifted global models that are slow to\nconverge. Knowledge Distillation has recently emerged to tackle this issue, by\nrefining the server model using aggregated knowledge from heterogeneous users,\nother than directly averaging their model parameters. This approach, however,\ndepends on a proxy dataset, making it impractical unless such a prerequisite is\nsatisfied. Moreover, the ensemble knowledge is not fully utilized to guide\nlocal model learning, which may in turn affect the quality of the aggregated\nmodel. Inspired by the prior art, we propose a data-free knowledge\ndistillation} approach to address heterogeneous FL, where the server learns a\nlightweight generator to ensemble user information in a data-free manner, which\nis then broadcasted to users, regulating local training using the learned\nknowledge as an inductive bias. Empirical studies powered by theoretical\nimplications show that, our approach facilitates FL with better generalization\nperformance using fewer communication rounds, compared with the\nstate-of-the-art.",
          "link": "http://arxiv.org/abs/2105.10056",
          "publishedOn": "2021-06-11T01:42:17.859Z",
          "wordCount": 651,
          "title": "Data-Free Knowledge Distillation for Heterogeneous Federated Learning. (arXiv:2105.10056v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05844",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jadon_S/0/1/0/all/0/1\">Shruti Jadon</a>",
          "description": "Image Segmentation has been an active field of research as it has a wide\nrange of applications, ranging from automated disease detection to self-driving\ncars. In recent years, various research papers proposed different loss\nfunctions used in case of biased data, sparse segmentation, and unbalanced\ndataset. In this paper, we introduce SemSegLoss, a python package consisting of\nsome of the well-known loss functions widely used for image segmentation. It is\ndeveloped with the intent to help researchers in the development of novel loss\nfunctions and perform an extensive set of experiments on model architectures\nfor various applications. The ease-of-use and flexibility of the presented\npackage have allowed reducing the development time and increased evaluation\nstrategies of machine learning models for semantic segmentation. Furthermore,\ndifferent applications that use image segmentation can use SemSegLoss because\nof the generality of its functions. This wide range of applications will lead\nto the development and growth of AI across all industries.",
          "link": "http://arxiv.org/abs/2106.05844",
          "publishedOn": "2021-06-11T01:42:17.853Z",
          "wordCount": 605,
          "title": "SemSegLoss: A python package of loss functions for semantic segmentation. (arXiv:2106.05844v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.09430",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Seo_Y/0/1/0/all/0/1\">Younggyo Seo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lili Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1\">Jinwoo Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Honglak Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1\">Pieter Abbeel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Kimin Lee</a>",
          "description": "Recent exploration methods have proven to be a recipe for improving\nsample-efficiency in deep reinforcement learning (RL). However, efficient\nexploration in high-dimensional observation spaces still remains a challenge.\nThis paper presents Random Encoders for Efficient Exploration (RE3), an\nexploration method that utilizes state entropy as an intrinsic reward. In order\nto estimate state entropy in environments with high-dimensional observations,\nwe utilize a k-nearest neighbor entropy estimator in the low-dimensional\nrepresentation space of a convolutional encoder. In particular, we find that\nthe state entropy can be estimated in a stable and compute-efficient manner by\nutilizing a randomly initialized encoder, which is fixed throughout training.\nOur experiments show that RE3 significantly improves the sample-efficiency of\nboth model-free and model-based RL methods on locomotion and navigation tasks\nfrom DeepMind Control Suite and MiniGrid benchmarks. We also show that RE3\nallows learning diverse behaviors without extrinsic rewards, effectively\nimproving sample-efficiency in downstream tasks. Source code and videos are\navailable at https://sites.google.com/view/re3-rl.",
          "link": "http://arxiv.org/abs/2102.09430",
          "publishedOn": "2021-06-11T01:42:17.847Z",
          "wordCount": 635,
          "title": "State Entropy Maximization with Random Encoders for Efficient Exploration. (arXiv:2102.09430v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05814",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1\">Song Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xia He</a>",
          "description": "Feature selection is an important part of building a machine learning model.\nBy eliminating redundant or misleading features from data, the machine learning\nmodel can achieve better performance while reducing the demand on com-puting\nresources. Metaheuristic algorithms are mostly used to implement feature\nselection such as swarm intelligence algorithms and evolutionary algorithms.\nHowever, they suffer from the disadvantage of relative complexity and slowness.\nIn this paper, a concise method is proposed for universal feature selection.\nThe proposed method uses a fusion of the filter method and the wrapper method,\nrather than a combination of them. In the method, one-hoting encoding is used\nto preprocess the dataset, and random forest is utilized as the classifier. The\nproposed method uses normalized frequencies to assign a value to each feature,\nwhich will be used to find the optimal feature subset. Furthermore, we propose\na novel approach to exploit the outputs of mutual information, which allows for\na better starting point for the experiments. Two real-world dataset in the\nfield of intrusion detection were used to evaluate the proposed method. The\nevaluation results show that the proposed method outperformed several\nstate-of-the-art related works in terms of accuracy, precision, recall, F-score\nand AUC.",
          "link": "http://arxiv.org/abs/2106.05814",
          "publishedOn": "2021-06-11T01:42:17.840Z",
          "wordCount": 630,
          "title": "A concise method for feature selection via normalized frequencies. (arXiv:2106.05814v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05860",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Challu_C/0/1/0/all/0/1\">Cristian Challu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Olivares_K/0/1/0/all/0/1\">Kin G. Olivares</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Welter_G/0/1/0/all/0/1\">Gus Welter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dubrawski_A/0/1/0/all/0/1\">Artur Dubrawski</a>",
          "description": "Neural forecasting has shown significant improvements in the accuracy of\nlarge-scale systems, yet predicting extremely long horizons remains a\nchallenging task. Two common problems are the volatility of the predictions and\ntheir computational complexity; we addressed them by incorporating smoothness\nregularization and mixed data sampling techniques to a well-performing\nmulti-layer perceptron based architecture (NBEATS). We validate our proposed\nmethod, DMIDAS, on high-frequency healthcare and electricity price data with\nlong forecasting horizons (~1000 timestamps) where we improve the prediction\naccuracy by 5% over state-of-the-art models, reducing the number of parameters\nof NBEATS by nearly 70%.",
          "link": "http://arxiv.org/abs/2106.05860",
          "publishedOn": "2021-06-11T01:42:17.824Z",
          "wordCount": 532,
          "title": "DMIDAS: Deep Mixed Data Sampling Regression for Long Multi-Horizon Time Series Forecasting. (arXiv:2106.05860v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2006.06721",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Grosse_K/0/1/0/all/0/1\">Kathrin Grosse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_T/0/1/0/all/0/1\">Taesung Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biggio_B/0/1/0/all/0/1\">Battista Biggio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_Y/0/1/0/all/0/1\">Youngja Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Backes_M/0/1/0/all/0/1\">Michael Backes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Molloy_I/0/1/0/all/0/1\">Ian Molloy</a>",
          "description": "Backdoor attacks aim to mislead machine-learning models to output an\nattacker-specified class when presented a specific trigger at test time. These\nattacks require poisoning the training data or compromising the learning\nalgorithm, e.g., by injecting poisoning samples containing the trigger into the\ntraining set, along with the desired class label. Despite the increasing number\nof studies on backdoor attacks and defenses, the underlying factors affecting\nthe success of backdoor attacks, along with their impact on the learning\nalgorithm, are not yet well understood. In this work, we aim to shed light on\nthis issue. In particular, we unveil that backdoor attacks work by inducing a\nsmoother decision function around the triggered samples -- a phenomenon which\nwe refer to as \\textit{backdoor smoothing}. We quantify backdoor smoothing by\ndefining a measure that evaluates the uncertainty associated to the predictions\nof a classifier around the input samples.\n\nOur experiments show that smoothness increases when the trigger is added to\nthe input samples, and that the phenomenon is more pronounced for more\nsuccessful attacks.\n\nHowever, our experiments also show that patterns fulfilling backdoor\nsmoothing can be crafted\n\neven without poisoning the training data.\n\nAlthough our measure may not be directly exploited as a defense mechanism, it\nunveils an important phenomenon which may pave the way towards understanding\nthe limitations of current defenses that rely on a smooth decision output for\nbackdoors.",
          "link": "http://arxiv.org/abs/2006.06721",
          "publishedOn": "2021-06-11T01:42:17.818Z",
          "wordCount": 719,
          "title": "Backdoor Smoothing: Demystifying Backdoor Attacks on Deep Neural Networks. (arXiv:2006.06721v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05824",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wagner_P/0/1/0/all/0/1\">P.-R. Wagner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marelli_S/0/1/0/all/0/1\">S. Marelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papaioannou_I/0/1/0/all/0/1\">I. Papaioannou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Straub_D/0/1/0/all/0/1\">D. Straub</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sudret_B/0/1/0/all/0/1\">B. Sudret</a>",
          "description": "Estimating the probability of rare failure events is an essential step in the\nreliability assessment of engineering systems. Computing this failure\nprobability for complex non-linear systems is challenging, and has recently\nspurred the development of active-learning reliability methods. These methods\napproximate the limit-state function (LSF) using surrogate models trained with\na sequentially enriched set of model evaluations. A recently proposed method\ncalled stochastic spectral embedding (SSE) aims to improve the local\napproximation accuracy of global, spectral surrogate modelling techniques by\nsequentially embedding local residual expansions in subdomains of the input\nspace. In this work we apply SSE to the LSF, giving rise to a stochastic\nspectral embedding-based reliability (SSER) method. The resulting partition of\nthe input space decomposes the failure probability into a set of\neasy-to-compute domain-wise failure probabilities. We propose a set of\nmodifications that tailor the algorithm to efficiently solve rare event\nestimation problems. These modifications include specialized refinement domain\nselection, partitioning and enrichment strategies. We showcase the algorithm\nperformance on four benchmark problems of various dimensionality and complexity\nin the LSF.",
          "link": "http://arxiv.org/abs/2106.05824",
          "publishedOn": "2021-06-11T01:42:17.811Z",
          "wordCount": 612,
          "title": "Rare event estimation using stochastic spectral embedding. (arXiv:2106.05824v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05966",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jimuyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ohn_Bar_E/0/1/0/all/0/1\">Eshed Ohn-Bar</a>",
          "description": "When in a new situation or geographical location, human drivers have an\nextraordinary ability to watch others and learn maneuvers that they themselves\nmay have never performed. In contrast, existing techniques for learning to\ndrive preclude such a possibility as they assume direct access to an\ninstrumented ego-vehicle with fully known observations and expert driver\nactions. However, such measurements cannot be directly accessed for the non-ego\nvehicles when learning by watching others. Therefore, in an application where\ndata is regarded as a highly valuable asset, current approaches completely\ndiscard the vast portion of the training data that can be potentially obtained\nthrough indirect observation of surrounding vehicles. Motivated by this key\ninsight, we propose the Learning by Watching (LbW) framework which enables\nlearning a driving policy without requiring full knowledge of neither the state\nnor expert actions. To increase its data, i.e., with new perspectives and\nmaneuvers, LbW makes use of the demonstrations of other vehicles in a given\nscene by (1) transforming the ego-vehicle's observations to their points of\nview, and (2) inferring their expert actions. Our LbW agent learns more robust\ndriving policies while enabling data-efficient learning, including quick\nadaptation of the policy to rare and novel scenarios. In particular, LbW drives\nrobustly even with a fraction of available driving data required by existing\nmethods, achieving an average success rate of 92% on the original CARLA\nbenchmark with only 30 minutes of total driving data and 82% with only 10\nminutes.",
          "link": "http://arxiv.org/abs/2106.05966",
          "publishedOn": "2021-06-11T01:42:17.806Z",
          "wordCount": 673,
          "title": "Learning by Watching. (arXiv:2106.05966v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2101.05186",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hoedt_P/0/1/0/all/0/1\">Pieter-Jan Hoedt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kratzert_F/0/1/0/all/0/1\">Frederik Kratzert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klotz_D/0/1/0/all/0/1\">Daniel Klotz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Halmich_C/0/1/0/all/0/1\">Christina Halmich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holzleitner_M/0/1/0/all/0/1\">Markus Holzleitner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nearing_G/0/1/0/all/0/1\">Grey Nearing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hochreiter_S/0/1/0/all/0/1\">Sepp Hochreiter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klambauer_G/0/1/0/all/0/1\">G&#xfc;nter Klambauer</a>",
          "description": "The success of Convolutional Neural Networks (CNNs) in computer vision is\nmainly driven by their strong inductive bias, which is strong enough to allow\nCNNs to solve vision-related tasks with random weights, meaning without\nlearning. Similarly, Long Short-Term Memory (LSTM) has a strong inductive bias\ntowards storing information over time. However, many real-world systems are\ngoverned by conservation laws, which lead to the redistribution of particular\nquantities -- e.g. in physical and economical systems. Our novel\nMass-Conserving LSTM (MC-LSTM) adheres to these conservation laws by extending\nthe inductive bias of LSTM to model the redistribution of those stored\nquantities. MC-LSTMs set a new state-of-the-art for neural arithmetic units at\nlearning arithmetic operations, such as addition tasks, which have a strong\nconservation law, as the sum is constant over time. Further, MC-LSTM is applied\nto traffic forecasting, modelling a pendulum, and a large benchmark dataset in\nhydrology, where it sets a new state-of-the-art for predicting peak flows. In\nthe hydrology example, we show that MC-LSTM states correlate with real-world\nprocesses and are therefore interpretable.",
          "link": "http://arxiv.org/abs/2101.05186",
          "publishedOn": "2021-06-11T01:42:17.800Z",
          "wordCount": 649,
          "title": "MC-LSTM: Mass-Conserving LSTM. (arXiv:2101.05186v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05856",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Kuznetsov_M/0/1/0/all/0/1\">Maksim Kuznetsov</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Polykovskiy_D/0/1/0/all/0/1\">Daniil Polykovskiy</a>",
          "description": "We propose a hierarchical normalizing flow model for generating molecular\ngraphs. The model produces new molecular structures from a single-node graph by\nrecursively splitting every node into two. All operations are invertible and\ncan be used as plug-and-play modules. The hierarchical nature of the latent\ncodes allows for precise changes in the resulting graph: perturbations in the\ntop layer cause global structural changes, while perturbations in the\nconsequent layers change the resulting molecule marginally. The proposed model\noutperforms existing generative graph models on the distribution learning task.\nWe also show successful experiments on global and constrained optimization of\nchemical properties using latent codes of the model.",
          "link": "http://arxiv.org/abs/2106.05856",
          "publishedOn": "2021-06-11T01:42:17.781Z",
          "wordCount": 532,
          "title": "MolGrow: A Graph Normalizing Flow for Hierarchical Molecular Generation. (arXiv:2106.05856v1 [physics.chem-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05958",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Gorbunov_E/0/1/0/all/0/1\">Eduard Gorbunov</a>, <a href=\"http://arxiv.org/find/math/1/au:+Danilova_M/0/1/0/all/0/1\">Marina Danilova</a>, <a href=\"http://arxiv.org/find/math/1/au:+Shibaev_I/0/1/0/all/0/1\">Innokentiy Shibaev</a>, <a href=\"http://arxiv.org/find/math/1/au:+Dvurechensky_P/0/1/0/all/0/1\">Pavel Dvurechensky</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gasnikov_A/0/1/0/all/0/1\">Alexander Gasnikov</a>",
          "description": "Thanks to their practical efficiency and random nature of the data,\nstochastic first-order methods are standard for training large-scale machine\nlearning models. Random behavior may cause a particular run of an algorithm to\nresult in a highly suboptimal objective value, whereas theoretical guarantees\nare usually proved for the expectation of the objective value. Thus, it is\nessential to theoretically guarantee that algorithms provide small objective\nresidual with high probability. Existing methods for non-smooth stochastic\nconvex optimization have complexity bounds with the dependence on the\nconfidence level that is either negative-power or logarithmic but under an\nadditional assumption of sub-Gaussian (light-tailed) noise distribution that\nmay not hold in practice, e.g., in several NLP tasks. In our paper, we resolve\nthis issue and derive the first high-probability convergence results with\nlogarithmic dependence on the confidence level for non-smooth convex stochastic\noptimization problems with non-sub-Gaussian (heavy-tailed) noise. To derive our\nresults, we propose novel stepsize rules for two stochastic methods with\ngradient clipping. Moreover, our analysis works for generalized smooth\nobjectives with H\\\"older-continuous gradients, and for both methods, we provide\nan extension for strongly convex problems. Finally, our results imply that the\nfirst (accelerated) method we consider also has optimal iteration and oracle\ncomplexity in all the regimes, and the second one is optimal in the non-smooth\nsetting.",
          "link": "http://arxiv.org/abs/2106.05958",
          "publishedOn": "2021-06-11T01:42:17.775Z",
          "wordCount": 667,
          "title": "Near-Optimal High Probability Complexity Bounds for Non-Smooth Stochastic Optimization with Heavy-Tailed Noise. (arXiv:2106.05958v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05886",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyunjik Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rainforth_T/0/1/0/all/0/1\">Tom Rainforth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teh_Y/0/1/0/all/0/1\">Yee Whye Teh</a>",
          "description": "Subsampling is used in convolutional neural networks (CNNs) in the form of\npooling or strided convolutions, to reduce the spatial dimensions of feature\nmaps and to allow the receptive fields to grow exponentially with depth.\nHowever, it is known that such subsampling operations are not translation\nequivariant, unlike convolutions that are translation equivariant. Here, we\nfirst introduce translation equivariant subsampling/upsampling layers that can\nbe used to construct exact translation equivariant CNNs. We then generalise\nthese layers beyond translations to general groups, thus proposing group\nequivariant subsampling/upsampling. We use these layers to construct group\nequivariant autoencoders (GAEs) that allow us to learn low-dimensional\nequivariant representations. We empirically verify on images that the\nrepresentations are indeed equivariant to input translations and rotations, and\nthus generalise well to unseen positions and orientations. We further use GAEs\nin models that learn object-centric representations on multi-object datasets,\nand show improved data efficiency and decomposition compared to non-equivariant\nbaselines.",
          "link": "http://arxiv.org/abs/2106.05886",
          "publishedOn": "2021-06-11T01:42:17.769Z",
          "wordCount": 572,
          "title": "Group Equivariant Subsampling. (arXiv:2106.05886v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2012.02177",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Duzceker_A/0/1/0/all/0/1\">Arda D&#xfc;z&#xe7;eker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galliani_S/0/1/0/all/0/1\">Silvano Galliani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogel_C/0/1/0/all/0/1\">Christoph Vogel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Speciale_P/0/1/0/all/0/1\">Pablo Speciale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dusmanu_M/0/1/0/all/0/1\">Mihai Dusmanu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pollefeys_M/0/1/0/all/0/1\">Marc Pollefeys</a>",
          "description": "We propose an online multi-view depth prediction approach on posed video\nstreams, where the scene geometry information computed in the previous time\nsteps is propagated to the current time step in an efficient and geometrically\nplausible way. The backbone of our approach is a real-time capable, lightweight\nencoder-decoder that relies on cost volumes computed from pairs of images. We\nextend it by placing a ConvLSTM cell at the bottleneck layer, which compresses\nan arbitrary amount of past information in its states. The novelty lies in\npropagating the hidden state of the cell by accounting for the viewpoint\nchanges between time steps. At a given time step, we warp the previous hidden\nstate into the current camera plane using the previous depth prediction. Our\nextension brings only a small overhead of computation time and memory\nconsumption, while improving the depth predictions significantly. As a result,\nwe outperform the existing state-of-the-art multi-view stereo methods on most\nof the evaluated metrics in hundreds of indoor scenes while maintaining a\nreal-time performance. Code available:\nhttps://github.com/ardaduz/deep-video-mvs",
          "link": "http://arxiv.org/abs/2012.02177",
          "publishedOn": "2021-06-11T01:42:17.757Z",
          "wordCount": 645,
          "title": "DeepVideoMVS: Multi-View Stereo on Video with Recurrent Spatio-Temporal Fusion. (arXiv:2012.02177v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1906.11667",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kotyan_S/0/1/0/all/0/1\">Shashank Kotyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vargas_D/0/1/0/all/0/1\">Danilo Vasconcellos Vargas</a>",
          "description": "Neural networks are prone to misclassify slightly modified input images.\nRecently, many defences have been proposed, but none have improved the\nrobustness of neural networks consistently. Here, we propose to use adversarial\nattacks as a function evaluation to search for neural architectures that can\nresist such attacks automatically. Experiments on neural architecture search\nalgorithms from the literature show that although accurate, they are not able\nto find robust architectures. A significant reason for this lies in their\nlimited search space. By creating a novel neural architecture search with\noptions for dense layers to connect with convolution layers and vice-versa as\nwell as the addition of concatenation layers in the search, we were able to\nevolve an architecture that is inherently accurate on adversarial samples.\nInterestingly, this inherent robustness of the evolved architecture rivals\nstate-of-the-art defences such as adversarial training while being trained only\non the non-adversarial samples. Moreover, the evolved architecture makes use of\nsome peculiar traits which might be useful for developing even more robust\nones. Thus, the results here confirm that more robust architectures exist as\nwell as opens up a new realm of feasibilities for the development and\nexploration of neural networks.\n\nCode available at this http URL",
          "link": "http://arxiv.org/abs/1906.11667",
          "publishedOn": "2021-06-11T01:42:17.751Z",
          "wordCount": null,
          "title": "Evolving Robust Neural Architectures to Defend from Adversarial Attacks. (arXiv:1906.11667v3 [cs.NE] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05316",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mozaffari_M/0/1/0/all/0/1\">M. Hamed Mozaffari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tay_L/0/1/0/all/0/1\">Li-Lin Tay</a>",
          "description": "Recently, the combination of robust one-dimensional convolutional neural\nnetworks (1-D CNNs) and Raman spectroscopy has shown great promise in rapid\nidentification of unknown substances with good accuracy. Using this technique,\nresearchers can recognize a pure compound and distinguish it from unknown\nsubstances in a mixture. The novelty of this approach is that the trained\nneural network operates automatically without any pre- or post-processing of\ndata. Some studies have attempted to extend this technique to the\nclassification of pure compounds in an unknown mixture. However, the\napplication of 1-D CNNs has typically been restricted to binary classifications\nof pure compounds. Here we will highlight a new approach in spectral\nrecognition and quantification of chemical components in a multicomponent\nmixture. Two 1-D CNN models, RaMixNet I and II, have been developed for this\npurpose. The former is for rapid classification of components in a mixture\nwhile the latter is for quantitative determination of those constituents. In\nthe proposed method, there is no limit to the number of compounds in a mixture.\nA data augmentation method is also introduced by adding random baselines to the\nRaman spectra. The experimental results revealed that the classification\naccuracy of RaMixNet I and II is 100% for analysis of unknown test mixtures; at\nthe same time, the RaMixNet II model may achieve a regression accuracy of 88%\nfor the quantification of each component.",
          "link": "http://arxiv.org/abs/2106.05316",
          "publishedOn": "2021-06-11T01:42:17.739Z",
          "wordCount": null,
          "title": "Raman spectral analysis of mixtures with one-dimensional convolutional neural network. (arXiv:2106.05316v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2104.11014",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hong_M/0/1/0/all/0/1\">Min-Fong Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hao-Yun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Min-Hung Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yu-Syuan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuo_H/0/1/0/all/0/1\">Hsien-Kai Kuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsai_Y/0/1/0/all/0/1\">Yi-Min Tsai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hung-Jen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jou_K/0/1/0/all/0/1\">Kevin Jou</a>",
          "description": "Network spaces have been known as a critical factor in both handcrafted\nnetwork designs or defining search spaces for Neural Architecture Search (NAS).\nHowever, an effective space involves tremendous prior knowledge and/or manual\neffort, and additional constraints are required to discover efficiency-aware\narchitectures. In this paper, we define a new problem, Network Space Search\n(NSS), as searching for favorable network spaces instead of a single\narchitecture. We propose an NSS method to directly search for efficient-aware\nnetwork spaces automatically, reducing the manual effort and immense cost in\ndiscovering satisfactory ones. The resultant network spaces, named Elite\nSpaces, are discovered from Expanded Search Space with minimal human expertise\nimposed. The Pareto-efficient Elite Spaces are aligned with the Pareto front\nunder various complexity constraints and can be further served as NAS search\nspaces, benefiting differentiable NAS approaches (e.g. In CIFAR-100, an\naveragely 2.3% lower error rate and 3.7% closer to target constraint than the\nbaseline with around 90% fewer samples required to find satisfactory networks).\nMoreover, our NSS approach is capable of searching for superior spaces in\nfuture unexplored spaces, revealing great potential in searching for network\nspaces automatically.",
          "link": "http://arxiv.org/abs/2104.11014",
          "publishedOn": "2021-06-11T01:42:17.738Z",
          "wordCount": null,
          "title": "Network Space Search for Pareto-Efficient Spaces. (arXiv:2104.11014v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.05855",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chourasia_R/0/1/0/all/0/1\">Rishav Chourasia</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ye_J/0/1/0/all/0/1\">Jiayuan Ye</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shokri_R/0/1/0/all/0/1\">Reza Shokri</a>",
          "description": "What is the information leakage of an iterative learning algorithm about its\ntraining data, when the internal state of the algorithm is \\emph{not}\nobservable? How much is the contribution of each specific training epoch to the\nfinal leakage? We study this problem for noisy gradient descent algorithms, and\nmodel the \\emph{dynamics} of R\\'enyi differential privacy loss throughout the\ntraining process. Our analysis traces a provably tight bound on the R\\'enyi\ndivergence between the pair of probability distributions over parameters of\nmodels with neighboring datasets. We prove that the privacy loss converges\nexponentially fast, for smooth and strongly convex loss functions, which is a\nsignificant improvement over composition theorems. For Lipschitz, smooth, and\nstrongly convex loss functions, we prove optimal utility for differential\nprivacy algorithms with a small gradient complexity.",
          "link": "http://arxiv.org/abs/2102.05855",
          "publishedOn": "2021-06-11T01:42:17.737Z",
          "wordCount": null,
          "title": "Differential Privacy Dynamics of Langevin Diffusion and Noisy Gradient Descent. (arXiv:2102.05855v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.03785",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mochaourab_R/0/1/0/all/0/1\">Rami Mochaourab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sinha_S/0/1/0/all/0/1\">Sugandh Sinha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Greenstein_S/0/1/0/all/0/1\">Stanley Greenstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papapetrou_P/0/1/0/all/0/1\">Panagiotis Papapetrou</a>",
          "description": "We consider counterfactual explanations for private support vector machines\n(SVM), where the privacy mechanism that publicly releases the classifier\nguarantees differential privacy. While privacy preservation is essential when\ndealing with sensitive data, there is a consequent degradation in the\nclassification accuracy due to the introduced perturbations in the classifier\nweights. For such classifiers, counterfactual explanations need to be robust\nagainst the uncertainties in the SVM weights in order to ensure, with high\nconfidence, that the classification of the data instance to be explained is\ndifferent than its explanation. We model the uncertainties in the SVM weights\nthrough a random vector, and formulate the explanation problem as an\noptimization problem with probabilistic constraint. Subsequently, we\ncharacterize the problem's deterministic equivalent and study its solution. For\nlinear SVMs, the problem is a convex second-order cone program. For non-linear\nSVMs, the problem is non-convex. Thus, we propose a sub-optimal solution that\nis based on the bisection method. The results show that, contrary to non-robust\nexplanations, the quality of explanations from the robust solution degrades\nwith increasing privacy in order to guarantee a prespecified confidence level\nfor correct classifications.",
          "link": "http://arxiv.org/abs/2102.03785",
          "publishedOn": "2021-06-11T01:42:17.735Z",
          "wordCount": null,
          "title": "Robust Explanations for Private Support Vector Machines. (arXiv:2102.03785v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05903",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Botelho_A/0/1/0/all/0/1\">Austin Botelho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vidgen_B/0/1/0/all/0/1\">Bertie Vidgen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hale_S/0/1/0/all/0/1\">Scott A. Hale</a>",
          "description": "Accurate detection and classification of online hate is a difficult task.\nImplicit hate is particularly challenging as such content tends to have unusual\nsyntax, polysemic words, and fewer markers of prejudice (e.g., slurs). This\nproblem is heightened with multimodal content, such as memes (combinations of\ntext and images), as they are often harder to decipher than unimodal content\n(e.g., text alone). This paper evaluates the role of semantic and multimodal\ncontext for detecting implicit and explicit hate. We show that both text- and\nvisual- enrichment improves model performance, with the multimodal model\n(0.771) outperforming other models' F1 scores (0.544, 0.737, and 0.754). While\nthe unimodal-text context-aware (transformer) model was the most accurate on\nthe subtask of implicit hate detection, the multimodal model outperformed it\noverall because of a lower propensity towards false positives. We find that all\nmodels perform better on content with full annotator agreement and that\nmultimodal models are best at classifying the content where annotators\ndisagree. To conduct these investigations, we undertook high-quality annotation\nof a sample of 5,000 multimodal entries. Tweets were annotated for primary\ncategory, modality, and strategy. We make this corpus, along with the codebook,\ncode, and final model, freely available.",
          "link": "http://arxiv.org/abs/2106.05903",
          "publishedOn": "2021-06-11T01:42:17.734Z",
          "wordCount": null,
          "title": "Deciphering Implicit Hate: Evaluating Automated Detection Algorithms for Multimodal Hate. (arXiv:2106.05903v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2103.02695",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ge_S/0/1/0/all/0/1\">Songwei Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singla_V/0/1/0/all/0/1\">Vasu Singla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basri_R/0/1/0/all/0/1\">Ronen Basri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jacobs_D/0/1/0/all/0/1\">David Jacobs</a>",
          "description": "Shift invariance is a critical property of CNNs that improves performance on\nclassification. However, we show that invariance to circular shifts can also\nlead to greater sensitivity to adversarial attacks. We first characterize the\nmargin between classes when a shift-invariant linear classifier is used. We\nshow that the margin can only depend on the DC component of the signals. Then,\nusing results about infinitely wide networks, we show that in some simple\ncases, fully connected and shift-invariant neural networks produce linear\ndecision boundaries. Using this, we prove that shift invariance in neural\nnetworks produces adversarial examples for the simple case of two classes, each\nconsisting of a single image with a black or white dot on a gray background.\nThis is more than a curiosity; we show empirically that with real datasets and\nrealistic architectures, shift invariance reduces adversarial robustness.\nFinally, we describe initial experiments using synthetic data to probe the\nsource of this connection.",
          "link": "http://arxiv.org/abs/2103.02695",
          "publishedOn": "2021-06-11T01:42:17.733Z",
          "wordCount": null,
          "title": "Shift Invariance Can Reduce Adversarial Robustness. (arXiv:2103.02695v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.02357",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_L/0/1/0/all/0/1\">Liang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1\">Yujie Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zhipeng Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_W/0/1/0/all/0/1\">Wei Pan</a>",
          "description": "This paper presents a deep reinforcement learning (DRL) algorithm for\norientation estimation using inertial sensors combined with magnetometer. The\nLyapunov method in control theory is employed to prove the convergence of\norientation estimation errors. Based on the theoretical results, the estimator\ngains and a Lyapunov function are parametrized by deep neural networks and\nlearned from samples. The DRL estimator is compared with three well-known\norientation estimation methods on both numerical simulations and real datasets\ncollected from commercially available sensors. The results show that the\nproposed algorithm is superior for arbitrary estimation initialization and can\nadapt to very large angular velocities for which other algorithms can be hardly\napplicable. To the best of our knowledge, this is the first DRL-based\norientation estimation method with estimation error boundedness guarantee.",
          "link": "http://arxiv.org/abs/2103.02357",
          "publishedOn": "2021-06-11T01:42:17.732Z",
          "wordCount": null,
          "title": "Reinforcement Learning for Orientation Estimation Using Inertial Sensors with Performance Guarantee. (arXiv:2103.02357v2 [cs.RO] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05937",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Balunovic_M/0/1/0/all/0/1\">Mislav Balunovi&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruoss_A/0/1/0/all/0/1\">Anian Ruoss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vechev_M/0/1/0/all/0/1\">Martin Vechev</a>",
          "description": "Fair representation learning is an attractive approach that promises fairness\nof downstream predictors by encoding sensitive data. Unfortunately, recent work\nhas shown that strong adversarial predictors can still exhibit unfairness by\nrecovering sensitive attributes from these representations. In this work, we\npresent Fair Normalizing Flows (FNF), a new approach offering more rigorous\nfairness guarantees for learned representations. Specifically, we consider a\npractical setting where we can estimate the probability density for sensitive\ngroups. The key idea is to model the encoder as a normalizing flow trained to\nminimize the statistical distance between the latent representations of\ndifferent groups. The main advantage of FNF is that its exact likelihood\ncomputation allows us to obtain guarantees on the maximum unfairness of any\npotentially adversarial downstream predictor. We experimentally demonstrate the\neffectiveness of FNF in enforcing various group fairness notions, as well as\nother attractive properties such as interpretability and transfer learning, on\na variety of challenging real-world datasets.",
          "link": "http://arxiv.org/abs/2106.05937",
          "publishedOn": "2021-06-11T01:42:17.731Z",
          "wordCount": 572,
          "title": "Fair Normalizing Flows. (arXiv:2106.05937v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05390",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hurtado_J/0/1/0/all/0/1\">Julio Hurtado</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raymond_Saez_A/0/1/0/all/0/1\">Alain Raymond-Saez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soto_A/0/1/0/all/0/1\">Alvaro Soto</a>",
          "description": "When learning tasks over time, artificial neural networks suffer from a\nproblem known as Catastrophic Forgetting (CF). This happens when the weights of\na network are overwritten during the training of a new task causing forgetting\nof old information. To address this issue, we propose MetA Reusable Knowledge\nor MARK, a new method that fosters weight reusability instead of overwriting\nwhen learning a new task. Specifically, MARK keeps a set of shared weights\namong tasks. We envision these shared weights as a common Knowledge Base (KB)\nthat is not only used to learn new tasks, but also enriched with new knowledge\nas the model learns new tasks. Key components behind MARK are two-fold. On the\none hand, a metalearning approach provides the key mechanism to incrementally\nenrich the KB with new knowledge and to foster weight reusability among tasks.\nOn the other hand, a set of trainable masks provides the key mechanism to\nselectively choose from the KB relevant weights to solve each task. By using\nMARK, we achieve state of the art results in several popular benchmarks,\nsurpassing the best performing methods in terms of average accuracy by over 10%\non the 20-Split-MiniImageNet dataset, while achieving almost zero forgetfulness\nusing 55% of the number of parameters. Furthermore, an ablation study provides\nevidence that, indeed, MARK is learning reusable knowledge that is selectively\nused by each task.",
          "link": "http://arxiv.org/abs/2106.05390",
          "publishedOn": "2021-06-11T01:42:17.725Z",
          "wordCount": null,
          "title": "Optimizing Reusable Knowledge for Continual Learning via Metalearning. (arXiv:2106.05390v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05932",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ji_Z/0/1/0/all/0/1\">Ziwei Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Justin D. Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Telgarsky_M/0/1/0/all/0/1\">Matus Telgarsky</a>",
          "description": "This work studies the behavior of neural networks trained with the logistic\nloss via gradient descent on binary classification data where the underlying\ndata distribution is general, and the (optimal) Bayes risk is not necessarily\nzero. In this setting, it is shown that gradient descent with early stopping\nachieves population risk arbitrarily close to optimal in terms of not just\nlogistic and misclassification losses, but also in terms of calibration,\nmeaning the sigmoid mapping of its outputs approximates the true underlying\nconditional distribution arbitrarily finely. Moreover, the necessary iteration,\nsample, and architectural complexities of this analysis all scale naturally\nwith a certain complexity measure of the true conditional model. Lastly, while\nit is not shown that early stopping is necessary, it is shown that any\nunivariate classifier satisfying a local interpolation property is necessarily\ninconsistent.",
          "link": "http://arxiv.org/abs/2106.05932",
          "publishedOn": "2021-06-11T01:42:17.724Z",
          "wordCount": null,
          "title": "Early-stopped neural networks are consistent. (arXiv:2106.05932v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2101.07597",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chengyi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1\">Yao Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumatani_K/0/1/0/all/0/1\">Kenichi Kumatani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shujie Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_M/0/1/0/all/0/1\">Michael Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuedong Huang</a>",
          "description": "In this paper, we propose a unified pre-training approach called UniSpeech to\nlearn speech representations with both unlabeled and labeled data, in which\nsupervised phonetic CTC learning and phonetically-aware contrastive\nself-supervised learning are conducted in a multi-task learning manner. The\nresultant representations can capture information more correlated with phonetic\nstructures and improve the generalization across languages and domains. We\nevaluate the effectiveness of UniSpeech for cross-lingual representation\nlearning on public CommonVoice corpus. The results show that UniSpeech\noutperforms self-supervised pretraining and supervised transfer learning for\nspeech recognition by a maximum of 13.4% and 17.8% relative phone error rate\nreductions respectively (averaged over all testing languages). The\ntransferability of UniSpeech is also demonstrated on a domain-shift speech\nrecognition task, i.e., a relative word error rate reduction of 6% against the\nprevious approach.",
          "link": "http://arxiv.org/abs/2101.07597",
          "publishedOn": "2021-06-11T01:42:17.724Z",
          "wordCount": null,
          "title": "UniSpeech: Unified Speech Representation Learning with Labeled and Unlabeled Data. (arXiv:2101.07597v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.07188",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wan_X/0/1/0/all/0/1\">Xingchen Wan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nguyen_V/0/1/0/all/0/1\">Vu Nguyen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ha_H/0/1/0/all/0/1\">Huong Ha</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ru_B/0/1/0/all/0/1\">Binxin Ru</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lu_C/0/1/0/all/0/1\">Cong Lu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Osborne_M/0/1/0/all/0/1\">Michael A. Osborne</a>",
          "description": "High-dimensional black-box optimisation remains an important yet notoriously\nchallenging problem. Despite the success of Bayesian optimisation methods on\ncontinuous domains, domains that are categorical, or that mix continuous and\ncategorical variables, remain challenging. We propose a novel solution -- we\ncombine local optimisation with a tailored kernel design, effectively handling\nhigh-dimensional categorical and mixed search spaces, whilst retaining sample\nefficiency. We further derive convergence guarantee for the proposed approach.\nFinally, we demonstrate empirically that our method outperforms the current\nbaselines on a variety of synthetic and real-world tasks in terms of\nperformance, computational costs, or both.",
          "link": "http://arxiv.org/abs/2102.07188",
          "publishedOn": "2021-06-11T01:42:17.723Z",
          "wordCount": null,
          "title": "Think Global and Act Local: Bayesian Optimisation over High-Dimensional Categorical and Mixed Search Spaces. (arXiv:2102.07188v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05848",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Haitao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Changjun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1\">Xiaomo Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xudong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shuhua Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaofang Wang</a>",
          "description": "The demand of probabilistic time series forecasting has been recently raised\nin various dynamic system scenarios, for example, system identification and\nprognostic and health management of machines. To this end, we combine the\nadvances in both deep generative models and state space model (SSM) to come up\nwith a novel, data-driven deep probabilistic sequence model. Specially, we\nfollow the popular encoder-decoder generative structure to build the recurrent\nneural networks (RNN) assisted variational sequence model on an augmented\nrecurrent input space, which could induce rich stochastic sequence dependency.\nBesides, in order to alleviate the issue of inconsistency between training and\npredicting as well as improving the mining of dynamic patterns, we (i) propose\nusing a hybrid output as input at next time step, which brings training and\npredicting into alignment; and (ii) further devise a generalized\nauto-regressive strategy that encodes all the historical dependencies at\ncurrent time step. Thereafter, we first investigate the methodological\ncharacteristics of the proposed deep probabilistic sequence model on toy cases,\nand then comprehensively demonstrate the superiority of our model against\nexisting deep probabilistic SSM models through extensive numerical experiments\non eight system identification benchmarks from various dynamic systems.\nFinally, we apply our sequence model to a real-world centrifugal compressor\nsensor data forecasting problem, and again verify its outstanding performance\nby quantifying the time series predictive distribution.",
          "link": "http://arxiv.org/abs/2106.05848",
          "publishedOn": "2021-06-11T01:42:17.716Z",
          "wordCount": 665,
          "title": "Deep Probabilistic Time Series Forecasting using Augmented Recurrent Input for Dynamic Systems. (arXiv:2106.05848v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.13203",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Grand_Clement_J/0/1/0/all/0/1\">Julien Grand-Cl&#xe9;ment</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kroer_C/0/1/0/all/0/1\">Christian Kroer</a>",
          "description": "We develop new parameter and scale-free algorithms for solving convex-concave\nsaddle-point problems. Our results are based on a new simple regret minimizer,\nthe Conic Blackwell Algorithm$^+$ (CBA$^+$), which attains $O(1/\\sqrt{T})$\naverage regret. Intuitively, our approach generalizes to other decision sets of\ninterest ideas from the Counterfactual Regret minimization (CFR$^+$) algorithm,\nwhich has very strong practical performance for solving sequential games on\nsimplexes. We show how to implement CBA$^+$ for the simplex, $\\ell_{p}$ norm\nballs, and ellipsoidal confidence regions in the simplex, and we present\nnumerical experiments for solving matrix games and distributionally robust\noptimization problems. Our empirical results show that CBA$^+$ is a simple\nalgorithm that outperforms state-of-the-art methods on synthetic data and real\ndata instances, without the need for any choice of step sizes or other\nalgorithmic parameters.",
          "link": "http://arxiv.org/abs/2105.13203",
          "publishedOn": "2021-06-11T01:42:17.710Z",
          "wordCount": 580,
          "title": "Conic Blackwell Algorithm: Parameter-Free Convex-Concave Saddle-Point Solving. (arXiv:2105.13203v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05822",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chelombiev_I/0/1/0/all/0/1\">Ivan Chelombiev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Justus_D/0/1/0/all/0/1\">Daniel Justus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Orr_D/0/1/0/all/0/1\">Douglas Orr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dietrich_A/0/1/0/all/0/1\">Anastasia Dietrich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gressmann_F/0/1/0/all/0/1\">Frithjof Gressmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koliousis_A/0/1/0/all/0/1\">Alexandros Koliousis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luschi_C/0/1/0/all/0/1\">Carlo Luschi</a>",
          "description": "Attention based language models have become a critical component in\nstate-of-the-art natural language processing systems. However, these models\nhave significant computational requirements, due to long training times, dense\noperations and large parameter count. In this work we demonstrate a set of\nmodifications to the structure of a Transformer layer, producing a more\nefficient architecture. First, we add a convolutional module to complement the\nself-attention module, decoupling the learning of local and global\ninteractions. Secondly, we rely on grouped transformations to reduce the\ncomputational cost of dense feed-forward layers and convolutions, while\npreserving the expressivity of the model. We apply the resulting architecture\nto language representation learning and demonstrate its superior performance\ncompared to BERT models of different scales. We further highlight its improved\nefficiency, both in terms of floating-point operations (FLOPs) and\ntime-to-train.",
          "link": "http://arxiv.org/abs/2106.05822",
          "publishedOn": "2021-06-11T01:42:17.704Z",
          "wordCount": 568,
          "title": "GroupBERT: Enhanced Transformer Architecture with Efficient Grouped Structures. (arXiv:2106.05822v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05810",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Poyiadzi_R/0/1/0/all/0/1\">Rafael Poyiadzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Renard_X/0/1/0/all/0/1\">Xavier Renard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laugel_T/0/1/0/all/0/1\">Thibault Laugel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santos_Rodriguez_R/0/1/0/all/0/1\">Raul Santos-Rodriguez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Detyniecki_M/0/1/0/all/0/1\">Marcin Detyniecki</a>",
          "description": "Local surrogate approaches for explaining machine learning model predictions\nhave appealing properties, such as being model-agnostic and flexible in their\nmodelling. Several methods exist that fit this description and share this goal.\nHowever, despite their shared overall procedure, they set out different\nobjectives, extract different information from the black-box, and consequently\nproduce diverse explanations, that are -- in general -- incomparable. In this\nwork we review the similarities and differences amongst multiple methods, with\na particular focus on what information they extract from the model, as this has\nlarge impact on the output: the explanation. We discuss the implications of the\nlack of agreement, and clarity, amongst the methods' objectives on the research\nand practice of explainability.",
          "link": "http://arxiv.org/abs/2106.05810",
          "publishedOn": "2021-06-11T01:42:17.690Z",
          "wordCount": 558,
          "title": "On the overlooked issue of defining explanation objectives for local-surrogate explainers. (arXiv:2106.05810v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2002.12301",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ito_R/0/1/0/all/0/1\">Rei Ito</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsukada_M/0/1/0/all/0/1\">Mineto Tsukada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matsutani_H/0/1/0/all/0/1\">Hiroki Matsutani</a>",
          "description": "Most edge AI focuses on prediction tasks on resource-limited edge devices\nwhile the training is done at server machines. However, retraining or\ncustomizing a model is required at edge devices as the model is becoming\noutdated due to environmental changes over time. To follow such a concept\ndrift, a neural-network based on-device learning approach is recently proposed,\nso that edge devices train incoming data at runtime to update their model. In\nthis case, since a training is done at distributed edge devices, the issue is\nthat only a limited amount of training data can be used for each edge device.\nTo address this issue, one approach is a cooperative learning or federated\nlearning, where edge devices exchange their trained results and update their\nmodel by using those collected from the other devices. In this paper, as an\non-device learning algorithm, we focus on OS-ELM (Online Sequential Extreme\nLearning Machine) to sequentially train a model based on recent samples and\ncombine it with autoencoder for anomaly detection. We extend it for an\non-device federated learning so that edge devices can exchange their trained\nresults and update their model by using those collected from the other edge\ndevices. This cooperative model update is one-shot while it can be repeatedly\napplied to synchronize their model. Our approach is evaluated with anomaly\ndetection tasks generated from a driving dataset of cars, a human activity\ndataset, and MNIST dataset. The results demonstrate that the proposed on-device\nfederated learning can produce a merged model by integrating trained results\nfrom multiple edge devices as accurately as traditional backpropagation based\nneural networks and a traditional federated learning approach with lower\ncomputation or communication cost.",
          "link": "http://arxiv.org/abs/2002.12301",
          "publishedOn": "2021-06-11T01:42:17.684Z",
          "wordCount": null,
          "title": "An On-Device Federated Learning Approach for Cooperative Anomaly Detection. (arXiv:2002.12301v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.11742",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Refinetti_M/0/1/0/all/0/1\">Maria Refinetti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldt_S/0/1/0/all/0/1\">Sebastian Goldt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krzakala_F/0/1/0/all/0/1\">Florent Krzakala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zdeborova_L/0/1/0/all/0/1\">Lenka Zdeborov&#xe1;</a>",
          "description": "A recent series of theoretical works showed that the dynamics of neural\nnetworks with a certain initialisation are well-captured by kernel methods.\nConcurrent empirical work demonstrated that kernel methods can come close to\nthe performance of neural networks on some image classification tasks. These\nresults raise the question of whether neural networks only learn successfully\nif kernels also learn successfully, despite neural networks being more\nexpressive. Here, we show theoretically that two-layer neural networks (2LNN)\nwith only a few hidden neurons can beat the performance of kernel learning on a\nsimple Gaussian mixture classification task. We study the high-dimensional\nlimit where the number of samples is linearly proportional to the input\ndimension, and show that while small 2LNN achieve near-optimal performance on\nthis task, lazy training approaches such as random features and kernel methods\ndo not. Our analysis is based on the derivation of a closed set of equations\nthat track the learning dynamics of the 2LNN and thus allow to extract the\nasymptotic performance of the network as a function of signal-to-noise ratio\nand other hyperparameters. We finally illustrate how over-parametrising the\nneural network leads to faster convergence, but does not improve its final\nperformance.",
          "link": "http://arxiv.org/abs/2102.11742",
          "publishedOn": "2021-06-11T01:42:17.683Z",
          "wordCount": null,
          "title": "Classifying high-dimensional Gaussian mixtures: Where kernel methods fail and neural networks succeed. (arXiv:2102.11742v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.05749",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cifka_O/0/1/0/all/0/1\">Ond&#x159;ej C&#xed;fka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ozerov_A/0/1/0/all/0/1\">Alexey Ozerov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simsekli_U/0/1/0/all/0/1\">Umut &#x15e;im&#x15f;ekli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Richard_G/0/1/0/all/0/1\">Ga&#xeb;l Richard</a>",
          "description": "Neural style transfer, allowing to apply the artistic style of one image to\nanother, has become one of the most widely showcased computer vision\napplications shortly after its introduction. In contrast, related tasks in the\nmusic audio domain remained, until recently, largely untackled. While several\nstyle conversion methods tailored to musical signals have been proposed, most\nlack the 'one-shot' capability of classical image style transfer algorithms. On\nthe other hand, the results of existing one-shot audio style transfer methods\non musical inputs are not as compelling. In this work, we are specifically\ninterested in the problem of one-shot timbre transfer. We present a novel\nmethod for this task, based on an extension of the vector-quantized variational\nautoencoder (VQ-VAE), along with a simple self-supervised learning strategy\ndesigned to obtain disentangled representations of timbre and pitch. We\nevaluate the method using a set of objective metrics and show that it is able\nto outperform selected baselines.",
          "link": "http://arxiv.org/abs/2102.05749",
          "publishedOn": "2021-06-11T01:42:17.682Z",
          "wordCount": null,
          "title": "Self-Supervised VQ-VAE for One-Shot Music Style Transfer. (arXiv:2102.05749v2 [cs.SD] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.10697",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+dAscoli_S/0/1/0/all/0/1\">St&#xe9;phane d&#x27;Ascoli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Touvron_H/0/1/0/all/0/1\">Hugo Touvron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leavitt_M/0/1/0/all/0/1\">Matthew Leavitt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morcos_A/0/1/0/all/0/1\">Ari Morcos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biroli_G/0/1/0/all/0/1\">Giulio Biroli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sagun_L/0/1/0/all/0/1\">Levent Sagun</a>",
          "description": "Convolutional architectures have proven extremely successful for vision\ntasks. Their hard inductive biases enable sample-efficient learning, but come\nat the cost of a potentially lower performance ceiling. Vision Transformers\n(ViTs) rely on more flexible self-attention layers, and have recently\noutperformed CNNs for image classification. However, they require costly\npre-training on large external datasets or distillation from pre-trained\nconvolutional networks. In this paper, we ask the following question: is it\npossible to combine the strengths of these two architectures while avoiding\ntheir respective limitations? To this end, we introduce gated positional\nself-attention (GPSA), a form of positional self-attention which can be\nequipped with a ``soft\" convolutional inductive bias. We initialise the GPSA\nlayers to mimic the locality of convolutional layers, then give each attention\nhead the freedom to escape locality by adjusting a gating parameter regulating\nthe attention paid to position versus content information. The resulting\nconvolutional-like ViT architecture, ConViT, outperforms the DeiT on ImageNet,\nwhile offering a much improved sample efficiency. We further investigate the\nrole of locality in learning by first quantifying how it is encouraged in\nvanilla self-attention layers, then analysing how it is escaped in GPSA layers.\nWe conclude by presenting various ablations to better understand the success of\nthe ConViT. Our code and models are released publicly at\nhttps://github.com/facebookresearch/convit.",
          "link": "http://arxiv.org/abs/2103.10697",
          "publishedOn": "2021-06-11T01:42:17.679Z",
          "wordCount": null,
          "title": "ConViT: Improving Vision Transformers with Soft Convolutional Inductive Biases. (arXiv:2103.10697v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.10424",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wolfe_C/0/1/0/all/0/1\">Cameron R. Wolfe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jingkang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chowdhury_A/0/1/0/all/0/1\">Arindam Chowdhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dun_C/0/1/0/all/0/1\">Chen Dun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bayer_A/0/1/0/all/0/1\">Artun Bayer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Segarra_S/0/1/0/all/0/1\">Santiago Segarra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kyrillidis_A/0/1/0/all/0/1\">Anastasios Kyrillidis</a>",
          "description": "The graph convolutional network (GCN) is a go-to solution for machine\nlearning on graphs, but its training is notoriously difficult to scale both in\nterms of graph size and the number of model parameters. Although some work has\nexplored training on large-scale graphs (e.g., GraphSAGE, ClusterGCN, etc.), we\npioneer efficient training of large-scale GCN models (i.e., ultra-wide,\noverparameterized models) with the proposal of a novel, distributed training\nframework. Our proposed training methodology, called GIST, disjointly\npartitions the parameters of a GCN model into several, smaller sub-GCNs that\nare trained independently and in parallel. In addition to being compatible with\nany GCN architecture, GIST improves model performance, scales to training on\narbitrarily large graphs, significantly decreases wall-clock training time, and\nenables the training of markedly overparameterized GCN models. Remarkably, with\nGIST, we train an astonishgly-wide 32,768-dimensional GraphSAGE model, which\nexceeds the capacity of a single GPU by a factor of 8X, to SOTA performance on\nthe Amazon2M dataset.",
          "link": "http://arxiv.org/abs/2102.10424",
          "publishedOn": "2021-06-11T01:42:17.677Z",
          "wordCount": null,
          "title": "GIST: Distributed Training for Large-Scale Graph Convolutional Networks. (arXiv:2102.10424v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.04035",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Townshend_R/0/1/0/all/0/1\">Raphael J.L. Townshend</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogele_M/0/1/0/all/0/1\">Martin V&#xf6;gele</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suriana_P/0/1/0/all/0/1\">Patricia Suriana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Derry_A/0/1/0/all/0/1\">Alexander Derry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Powers_A/0/1/0/all/0/1\">Alexander Powers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laloudakis_Y/0/1/0/all/0/1\">Yianni Laloudakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balachandar_S/0/1/0/all/0/1\">Sidhika Balachandar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jing_B/0/1/0/all/0/1\">Bowen Jing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anderson_B/0/1/0/all/0/1\">Brandon Anderson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eismann_S/0/1/0/all/0/1\">Stephan Eismann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kondor_R/0/1/0/all/0/1\">Risi Kondor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Altman_R/0/1/0/all/0/1\">Russ B. Altman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dror_R/0/1/0/all/0/1\">Ron O. Dror</a>",
          "description": "Computational methods that operate on three-dimensional molecular structure\nhave the potential to solve important questions in biology and chemistry. In\nparticular, deep neural networks have gained significant attention, but their\nwidespread adoption in the biomolecular domain has been limited by a lack of\neither systematic performance benchmarks or a unified toolkit for interacting\nwith molecular data. To address this, we present ATOM3D, a collection of both\nnovel and existing benchmark datasets spanning several key classes of\nbiomolecules. We implement several classes of three-dimensional molecular\nlearning methods for each of these tasks and show that they consistently\nimprove performance relative to methods based on one- and two-dimensional\nrepresentations. The specific choice of architecture proves to be critical for\nperformance, with three-dimensional convolutional networks excelling at tasks\ninvolving complex geometries, graph networks performing well on systems\nrequiring detailed positional information, and the more recently developed\nequivariant networks showing significant promise. Our results indicate that\nmany molecular problems stand to gain from three-dimensional molecular\nlearning, and that there is potential for improvement on many tasks which\nremain underexplored. To lower the barrier to entry and facilitate further\ndevelopments in the field, we also provide a comprehensive suite of tools for\ndataset processing, model training, and evaluation in our open-source atom3d\nPython package. All datasets are available for download from\nhttps://www.atom3d.ai .",
          "link": "http://arxiv.org/abs/2012.04035",
          "publishedOn": "2021-06-11T01:42:17.676Z",
          "wordCount": null,
          "title": "ATOM3D: Tasks On Molecules in Three Dimensions. (arXiv:2012.04035v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.05487",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rusch_T/0/1/0/all/0/1\">T. Konstantin Rusch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1\">Siddhartha Mishra</a>",
          "description": "The design of recurrent neural networks (RNNs) to accurately process\nsequential inputs with long-time dependencies is very challenging on account of\nthe exploding and vanishing gradient problem. To overcome this, we propose a\nnovel RNN architecture which is based on a structure preserving discretization\nof a Hamiltonian system of second-order ordinary differential equations that\nmodels networks of oscillators. The resulting RNN is fast, invertible (in\ntime), memory efficient and we derive rigorous bounds on the hidden state\ngradients to prove the mitigation of the exploding and vanishing gradient\nproblem. A suite of experiments are presented to demonstrate that the proposed\nRNN provides state of the art performance on a variety of learning tasks with\n(very) long-time dependencies.",
          "link": "http://arxiv.org/abs/2103.05487",
          "publishedOn": "2021-06-11T01:42:17.664Z",
          "wordCount": null,
          "title": "UnICORNN: A recurrent model for learning very long time dependencies. (arXiv:2103.05487v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.12692",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zou_D/0/1/0/all/0/1\">Difan Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jingfeng Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Braverman_V/0/1/0/all/0/1\">Vladimir Braverman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1\">Quanquan Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1\">Sham M. Kakade</a>",
          "description": "There is an increasing realization that algorithmic inductive biases are\ncentral in preventing overfitting; empirically, we often see a benign\noverfitting phenomenon in overparameterized settings for natural learning\nalgorithms, such as stochastic gradient descent (SGD), where little to no\nexplicit regularization has been employed. This work considers this issue in\narguably the most basic setting: constant-stepsize SGD (with iterate averaging)\nfor linear regression in the overparameterized regime. Our main result provides\na sharp excess risk bound, stated in terms of the full eigenspectrum of the\ndata covariance matrix, that reveals a bias-variance decomposition\ncharacterizing when generalization is possible: (i) the variance bound is\ncharacterized in terms of an effective dimension (specific for SGD) and (ii)\nthe bias bound provides a sharp geometric characterization in terms of the\nlocation of the initial iterate (and how it aligns with the data covariance\nmatrix). We reflect on a number of notable differences between the algorithmic\nregularization afforded by (unregularized) SGD in comparison to ordinary least\nsquares (minimum-norm interpolation) and ridge regression.",
          "link": "http://arxiv.org/abs/2103.12692",
          "publishedOn": "2021-06-11T01:42:17.627Z",
          "wordCount": null,
          "title": "Benign Overfitting of Constant-Stepsize SGD for Linear Regression. (arXiv:2103.12692v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03686",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Thanthrige_U/0/1/0/all/0/1\">Udaya S.K.P. Miriya Thanthrige</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jung_P/0/1/0/all/0/1\">Peter Jung</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sezgin_A/0/1/0/all/0/1\">Aydin Sezgin</a>",
          "description": "We address the detection of material defects, which are inside a layered\nmaterial structure using compressive sensing based multiple-output (MIMO)\nwireless radar. Here, the strong clutter due to the reflection of the layered\nstructure's surface often makes the detection of the defects challenging. Thus,\nsophisticated signal separation methods are required for improved defect\ndetection. In many scenarios, the number of defects that we are interested in\nis limited and the signaling response of the layered structure can be modeled\nas a low-rank structure. Therefore, we propose joint rank and sparsity\nminimization for defect detection. In particular, we propose a non-convex\napproach based on the iteratively reweighted nuclear and $\\ell_1-$norm (a\ndouble-reweighted approach) to obtain a higher accuracy compared to the\nconventional nuclear norm and $\\ell_1-$norm minimization. To this end, an\niterative algorithm is designed to estimate the low-rank and sparse\ncontributions. Further, we propose deep learning to learn the parameters of the\nalgorithm (i.e., algorithm unfolding) to improve the accuracy and the speed of\nconvergence of the algorithm. Our numerical results show that the proposed\napproach outperforms the conventional approaches in terms of mean square errors\nof the recovered low-rank and sparse components and the speed of convergence.",
          "link": "http://arxiv.org/abs/2106.03686",
          "publishedOn": "2021-06-11T01:42:17.627Z",
          "wordCount": null,
          "title": "Deep Unfolding of Iteratively Reweighted ADMM for Wireless RF Sensing. (arXiv:2106.03686v1 [eess.SP] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.06356",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nado_Z/0/1/0/all/0/1\">Zachary Nado</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gilmer_J/0/1/0/all/0/1\">Justin M. Gilmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shallue_C/0/1/0/all/0/1\">Christopher J. Shallue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anil_R/0/1/0/all/0/1\">Rohan Anil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dahl_G/0/1/0/all/0/1\">George E. Dahl</a>",
          "description": "Recently the LARS and LAMB optimizers have been proposed for training neural\nnetworks faster using large batch sizes. LARS and LAMB add layer-wise\nnormalization to the update rules of Heavy-ball momentum and Adam,\nrespectively, and have become popular in prominent benchmarks and deep learning\nlibraries. However, without fair comparisons to standard optimizers, it remains\nan open question whether LARS and LAMB have any benefit over traditional,\ngeneric algorithms. In this work we demonstrate that standard optimization\nalgorithms such as Nesterov momentum and Adam can match or exceed the results\nof LARS and LAMB at large batch sizes. Our results establish new, stronger\nbaselines for future comparisons at these batch sizes and shed light on the\ndifficulties of comparing optimizers for neural network training more\ngenerally.",
          "link": "http://arxiv.org/abs/2102.06356",
          "publishedOn": "2021-06-11T01:42:17.624Z",
          "wordCount": null,
          "title": "A Large Batch Optimizer Reality Check: Traditional, Generic Optimizers Suffice Across Batch Sizes. (arXiv:2102.06356v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.09082",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Zhan_X/0/1/0/all/0/1\">Xianghao Zhan</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Li_Y/0/1/0/all/0/1\">Yiheng Li</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Liu_Y/0/1/0/all/0/1\">Yuzhe Liu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Cecchi_N/0/1/0/all/0/1\">Nicholas J. Cecchi</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Raymond_S/0/1/0/all/0/1\">Samuel J. Raymond</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhou_Z/0/1/0/all/0/1\">Zhou Zhou</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Alizadeh_H/0/1/0/all/0/1\">Hossein Vahid Alizadeh</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ruan_J/0/1/0/all/0/1\">Jesse Ruan</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Barbat_S/0/1/0/all/0/1\">Saeed Barbat</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Tiernan_S/0/1/0/all/0/1\">Stephen Tiernan</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Gevaert_O/0/1/0/all/0/1\">Olivier Gevaert</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zeineh_M/0/1/0/all/0/1\">Michael M. Zeineh</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Grant_G/0/1/0/all/0/1\">Gerald A. Grant</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Camarillo_D/0/1/0/all/0/1\">David B. Camarillo</a>",
          "description": "Traumatic brain injury can be caused by head impacts, but many brain injury\nrisk estimation models are less accurate across the variety of impacts that\npatients may undergo. We investigated the spectral characteristics of different\nhead impact types with kinematics classification. Data was analyzed from 3,262\nhead impacts from lab reconstruction, American football, mixed martial arts,\nand publicly available car crash data. A random forest classifier with spectral\ndensities of linear acceleration and angular velocity was built to classify\nhead impact types (e.g., football), reaching a median accuracy of 96% over\n1,000 random partitions of training and test sets. To test the classifier on\ndata from different measurement devices, another 271 lab-reconstructed impacts\nwere obtained from 5 other instrumented mouthguards with the classifier\nreaching over 96% accuracy. The most important features in the classification\nincluded both low-frequency and high-frequency features, both linear\nacceleration features and angular velocity features. Different head impact\ntypes had different distributions of spectral densities in low-frequency and\nhigh-frequency ranges (e.g., the spectral densities of MMA impacts were higher\nin high-frequency range than in the low-frequency range). Finally, with the\nclassifier, type-specific, nearest-neighbor regression models were built for\n95th percentile maximum principal strain, 95th percentile maximum principal\nstrain in corpus callosum, and cumulative strain damage (15th percentile). This\nshowed a generally higher R2-value than baseline models. The classifier enables\na better understanding of the impact kinematics in different sports, and it can\nbe applied to evaluate the quality of impact-simulation systems and on-field\ndata augmentation. Key words: traumatic brain injury, head impacts,\nclassification, impact kinematics",
          "link": "http://arxiv.org/abs/2104.09082",
          "publishedOn": "2021-06-11T01:42:17.623Z",
          "wordCount": null,
          "title": "Classification of head impacts based on the spectral density of measurable kinematics. (arXiv:2104.09082v2 [q-bio.QM] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.12753",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gong_C/0/1/0/all/0/1\">Chengyue Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Dilin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Meng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandra_V/0/1/0/all/0/1\">Vikas Chandra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qiang Liu</a>",
          "description": "Vision transformer has demonstrated promising performance on challenging\ncomputer vision tasks. However, directly training the vision transformers may\nyield unstable and sub-optimal results. Recent works propose to improve the\nperformance of the vision transformers by modifying the transformer structures,\ne.g., incorporating convolution layers. In contrast, we investigate an\northogonal approach to stabilize the vision transformer training without\nmodifying the networks. We observe the instability of the training can be\nattributed to the significant similarity across the extracted patch\nrepresentations. More specifically, for deep vision transformers, the\nself-attention blocks tend to map different patches into similar latent\nrepresentations, yielding information loss and performance degradation. To\nalleviate this problem, in this work, we introduce novel loss functions in\nvision transformer training to explicitly encourage diversity across patch\nrepresentations for more discriminative feature extraction. We empirically show\nthat our proposed techniques stabilize the training and allow us to train wider\nand deeper vision transformers. We further show the diversified features\nsignificantly benefit the downstream tasks in transfer learning. For semantic\nsegmentation, we enhance the state-of-the-art (SOTA) results on Cityscapes and\nADE20k. Our code will be made publicly available soon.",
          "link": "http://arxiv.org/abs/2104.12753",
          "publishedOn": "2021-06-11T01:42:17.623Z",
          "wordCount": null,
          "title": "Vision Transformers with Patch Diversification. (arXiv:2104.12753v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.04938",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Kimin Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laskin_M/0/1/0/all/0/1\">Michael Laskin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivas_A/0/1/0/all/0/1\">Aravind Srinivas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1\">Pieter Abbeel</a>",
          "description": "Model-free deep reinforcement learning (RL) has been successful in a range of\nchallenging domains. However, there are some remaining issues, such as\nstabilizing the optimization of nonlinear function approximators, preventing\nerror propagation due to the Bellman backup in Q-learning, and efficient\nexploration. To mitigate these issues, we present SUNRISE, a simple unified\nensemble method, which is compatible with various off-policy RL algorithms.\nSUNRISE integrates three key ingredients: (a) bootstrap with random\ninitialization which improves the stability of the learning process by training\na diverse ensemble of agents, (b) weighted Bellman backups, which prevent error\npropagation in Q-learning by reweighing sample transitions based on uncertainty\nestimates from the ensembles, and (c) an inference method that selects actions\nusing highest upper-confidence bounds for efficient exploration. Our\nexperiments show that SUNRISE significantly improves the performance of\nexisting off-policy RL algorithms, such as Soft Actor-Critic and Rainbow DQN,\nfor both continuous and discrete control tasks on both low-dimensional and\nhigh-dimensional environments. Our training code is available at\nhttps://github.com/pokaxpoka/sunrise.",
          "link": "http://arxiv.org/abs/2007.04938",
          "publishedOn": "2021-06-11T01:42:17.622Z",
          "wordCount": null,
          "title": "SUNRISE: A Simple Unified Framework for Ensemble Learning in Deep Reinforcement Learning. (arXiv:2007.04938v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.00620",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Er_S/0/1/0/all/0/1\">Siawpeng Er</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shihao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tuo Zhao</a>",
          "description": "The global spread of COVID-19, the disease caused by the novel coronavirus\nSARS-CoV-2, has cast a significant threat to mankind. As the COVID-19 situation\ncontinues to evolve, predicting localized disease severity is crucial for\nadvanced resource allocation. This paper proposes a method named COURAGE\n(COUnty aggRegation mixup AuGmEntation) to generate a short-term prediction of\n2-week-ahead COVID-19 related deaths for each county in the United States,\nleveraging modern deep learning techniques. Specifically, our method adopts a\nself-attention model from Natural Language Processing, known as the transformer\nmodel, to capture both short-term and long-term dependencies within the time\nseries while enjoying computational efficiency. Our model fully utilizes\npublicly available information of COVID-19 related confirmed cases, deaths,\ncommunity mobility trends and demographic information, and can produce\nstate-level prediction as an aggregation of the corresponding county-level\npredictions. Our numerical experiments demonstrate that our model achieves the\nstate-of-the-art performance among the publicly available benchmark models.",
          "link": "http://arxiv.org/abs/2105.00620",
          "publishedOn": "2021-06-11T01:42:17.622Z",
          "wordCount": null,
          "title": "COUnty aggRegation mixup AuGmEntation (COURAGE) COVID-19 Prediction. (arXiv:2105.00620v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.13169",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiangjun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1\">Junxiao Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_P/0/1/0/all/0/1\">Penghui Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_P/0/1/0/all/0/1\">Peng Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1\">Zhenkun Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Weimin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pi_X/0/1/0/all/0/1\">Xiongjun Pi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jujie He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1\">Chao Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_H/0/1/0/all/0/1\">Haitao Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Q/0/1/0/all/0/1\">Quan Yuan</a>",
          "description": "AlphaStar, the AI that reaches GrandMaster level in StarCraft II, is a\nremarkable milestone demonstrating what deep reinforcement learning can achieve\nin complex Real-Time Strategy (RTS) games. However, the complexities of the\ngame, algorithms and systems, and especially the tremendous amount of\ncomputation needed are big obstacles for the community to conduct further\nresearch in this direction. We propose a deep reinforcement learning agent,\nStarCraft Commander (SCC). With order of magnitude less computation, it\ndemonstrates top human performance defeating GrandMaster players in test\nmatches and top professional players in a live event. Moreover, it shows strong\nrobustness to various human strategies and discovers novel strategies unseen\nfrom human plays. In this paper, we will share the key insights and\noptimizations on efficient imitation learning and reinforcement learning for\nStarCraft II full game.",
          "link": "http://arxiv.org/abs/2012.13169",
          "publishedOn": "2021-06-11T01:42:17.617Z",
          "wordCount": null,
          "title": "SCC: an efficient deep reinforcement learning agent mastering the game of StarCraft II. (arXiv:2012.13169v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14163",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Chewi_S/0/1/0/all/0/1\">Sinho Chewi</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gerber_P/0/1/0/all/0/1\">Patrik Gerber</a>, <a href=\"http://arxiv.org/find/math/1/au:+Lu_C/0/1/0/all/0/1\">Chen Lu</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gouic_T/0/1/0/all/0/1\">Thibaut Le Gouic</a>, <a href=\"http://arxiv.org/find/math/1/au:+Rigollet_P/0/1/0/all/0/1\">Philippe Rigollet</a>",
          "description": "We establish the first tight lower bound of $\\Omega(\\log\\log\\kappa)$ on the\nquery complexity of sampling from the class of strongly log-concave and\nlog-smooth distributions with condition number $\\kappa$ in one dimension.\nWhereas existing guarantees for MCMC-based algorithms scale polynomially in\n$\\kappa$, we introduce a novel algorithm based on rejection sampling that\ncloses this doubly exponential gap.",
          "link": "http://arxiv.org/abs/2105.14163",
          "publishedOn": "2021-06-11T01:42:17.617Z",
          "wordCount": null,
          "title": "The query complexity of sampling from strongly log-concave distributions in one dimension. (arXiv:2105.14163v2 [math.ST] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05819",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Suresh_S/0/1/0/all/0/1\">Susheel Suresh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Pan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_C/0/1/0/all/0/1\">Cong Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neville_J/0/1/0/all/0/1\">Jennifer Neville</a>",
          "description": "Self-supervised learning of graph neural networks (GNN) is in great need\nbecause of the widespread label scarcity issue in real-world graph/network\ndata. Graph contrastive learning (GCL), by training GNNs to maximize the\ncorrespondence between the representations of the same graph in its different\naugmented forms, may yield robust and transferable GNNs even without using\nlabels. However, GNNs trained by traditional GCL often risk capturing redundant\ngraph features and thus may be brittle and provide sub-par performance in\ndownstream tasks. Here, we propose a novel principle, termed adversarial-GCL\n(AD-GCL), which enables GNNs to avoid capturing redundant information during\nthe training by optimizing adversarial graph augmentation strategies used in\nGCL. We pair AD-GCL with theoretical explanations and design a practical\ninstantiation based on trainable edge-dropping graph augmentation. We\nexperimentally validate AD-GCL by comparing with the state-of-the-art GCL\nmethods and achieve performance gains of up-to $14\\%$ in unsupervised, $6\\%$ in\ntransfer, and $3\\%$ in semi-supervised learning settings overall with 18\ndifferent benchmark datasets for the tasks of molecule property regression and\nclassification, and social network classification.",
          "link": "http://arxiv.org/abs/2106.05819",
          "publishedOn": "2021-06-11T01:42:17.616Z",
          "wordCount": 600,
          "title": "Adversarial Graph Augmentation to Improve Graph Contrastive Learning. (arXiv:2106.05819v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2009.08435",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Youwei Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1\">Dong Huang</a>",
          "description": "Since the Lipschitz properties of CNN are widely considered to be related to\nadversarial robustness, we theoretically characterize the $\\ell_1$ norm and\n$\\ell_\\infty$ norm of 2D multi-channel convolutional layers and provide\nefficient methods to compute the exact $\\ell_1$ norm and $\\ell_\\infty$ norm.\nBased on our theorem, we propose a novel regularization method termed norm\ndecay, which can effectively reduce the norms of convolutional layers and\nfully-connected layers. Experiments show that norm-regularization methods,\nincluding norm decay, weight decay, and singular value clipping, can improve\ngeneralization of CNNs. However, they can slightly hurt adversarial robustness.\nObserving this unexpected phenomenon, we compute the norms of layers in the\nCNNs trained with three different adversarial training frameworks and\nsurprisingly find that adversarially robust CNNs have comparable or even larger\nlayer norms than their non-adversarially robust counterparts. Furthermore, we\nprove that under a mild assumption, adversarially robust classifiers can be\nachieved, and can have an arbitrarily large Lipschitz constant. For this\nreason, enforcing small norms on CNN layers may be neither necessary nor\neffective in achieving adversarial robustness. The code is available at\nhttps://github.com/youweiliang/norm_robustness.",
          "link": "http://arxiv.org/abs/2009.08435",
          "publishedOn": "2021-06-11T01:42:17.616Z",
          "wordCount": null,
          "title": "Large Norms of CNN Layers Do Not Hurt Adversarial Robustness. (arXiv:2009.08435v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.06489",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Mai_V/0/1/0/all/0/1\">Vien V. Mai</a>, <a href=\"http://arxiv.org/find/math/1/au:+Johansson_M/0/1/0/all/0/1\">Mikael Johansson</a>",
          "description": "Stochastic gradient algorithms are often unstable when applied to functions\nthat do not have Lipschitz-continuous and/or bounded gradients. Gradient\nclipping is a simple and effective technique to stabilize the training process\nfor problems that are prone to the exploding gradient problem. Despite its\nwidespread popularity, the convergence properties of the gradient clipping\nheuristic are poorly understood, especially for stochastic problems. This paper\nestablishes both qualitative and quantitative convergence results of the\nclipped stochastic (sub)gradient method (SGD) for non-smooth convex functions\nwith rapidly growing subgradients. Our analyses show that clipping enhances the\nstability of SGD and that the clipped SGD algorithm enjoys finite convergence\nrates in many cases. We also study the convergence of a clipped method with\nmomentum, which includes clipped SGD as a special case, for weakly convex\nproblems under standard assumptions. With a novel Lyapunov analysis, we show\nthat the proposed method achieves the best-known rate for the considered class\nof problems, demonstrating the effectiveness of clipped methods also in this\nregime. Numerical results confirm our theoretical developments.",
          "link": "http://arxiv.org/abs/2102.06489",
          "publishedOn": "2021-06-11T01:42:17.610Z",
          "wordCount": null,
          "title": "Stability and Convergence of Stochastic Gradient Clipping: Beyond Lipschitz Continuity and Smoothness. (arXiv:2102.06489v2 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05855",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Leung_R/0/1/0/all/0/1\">Raymond Leung</a>",
          "description": "In the literature, a large body of work advocates the use of log-ratio\ntransformation for multivariate statistical analysis of compositional data. In\ncontrast, few studies have looked at how data transformation changes the\nefficacy of machine learning classifiers within geoscience. This letter\npresents experiment results and empirical observations to further explore this\nissue. The objective is to study the effects of data transformation on geozone\nclassification performance when machine learning (ML) classifiers/estimators\nare trained using geochemical data. The training input consists of exploration\nhole assay samples obtained from a Pilbara iron-ore deposit in Western\nAustralia, and geozone labels assigned based on stratigraphic units, the\nabsence or presence and type of mineralization. The ML techniques considered\nare multinomial logistic regression, Gaussian na\\\"{i}ve Bayes, kNN, linear\nsupport vector classifier, RBF-SVM, gradient boosting and extreme GB, random\nforest (RF) and multi-layer perceptron (MLP). The transformations examined\ninclude isometric log-ratio (ILR), center log-ratio (CLR) coupled with\nprincipal component analysis (PCA) or independent component analysis (ICA), and\na manifold learning approach based on local linear embedding (LLE). The results\nreveal that different ML classifiers exhibit varying sensitivity to these\ntransformations, with some clearly more advantageous or deleterious than\nothers. Overall, the best performing candidate is ILR which is unsurprising\nconsidering the compositional nature of the data. The performance of pairwise\nlog-ratio (PWLR) transformation is better than ILR for ensemble and tree-based\nlearners such as boosting and RF; but worse for MLP, SVM and other classifiers.",
          "link": "http://arxiv.org/abs/2106.05855",
          "publishedOn": "2021-06-11T01:42:17.608Z",
          "wordCount": null,
          "title": "Empirical observations on the effects of data transformation in machine learning classification of geological domains. (arXiv:2106.05855v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05842",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Reddy_A/0/1/0/all/0/1\">Abbavaram Gowtham Reddy</a>",
          "description": "Causal reasoning is the main learning and explanation tool used by humans. AI\nsystems should possess causal reasoning capabilities to be deployed in the real\nworld with trust and reliability. Introducing the ideas of causality to machine\nlearning helps in providing better learning and explainable models.\nExplainability, causal disentanglement are some important aspects of any\nmachine learning model. Causal explanations are required to believe in a\nmodel's decision and causal disentanglement learning is important for transfer\nlearning applications. We exploit the ideas of causality to be used in deep\nlearning models to achieve better and causally explainable models that are\nuseful in fairness, disentangled representation, etc.",
          "link": "http://arxiv.org/abs/2106.05842",
          "publishedOn": "2021-06-11T01:42:17.603Z",
          "wordCount": null,
          "title": "Causality in Neural Networks -- An Extended Abstract. (arXiv:2106.05842v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05809",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pasa_L/0/1/0/all/0/1\">Luca Pasa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Navarin_N/0/1/0/all/0/1\">Nicol&#xf2; Navarin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erb_W/0/1/0/all/0/1\">Wolfgang Erb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sperduti_A/0/1/0/all/0/1\">Alessandro Sperduti</a>",
          "description": "Many neural networks for graphs are based on the graph convolution operator,\nproposed more than a decade ago. Since then, many alternative definitions have\nbeen proposed, that tend to add complexity (and non-linearity) to the model. In\nthis paper, we follow the opposite direction by proposing simple graph\nconvolution operators, that can be implemented in single-layer graph\nconvolutional networks. We show that our convolution operators are more\ntheoretically grounded than many proposals in literature, and exhibit\nstate-of-the-art predictive performance on the considered benchmark datasets.",
          "link": "http://arxiv.org/abs/2106.05809",
          "publishedOn": "2021-06-11T01:42:17.600Z",
          "wordCount": 501,
          "title": "Simple Graph Convolutional Networks. (arXiv:2106.05809v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2006.09668",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Tsuchiya_T/0/1/0/all/0/1\">Taira Tsuchiya</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Honda_J/0/1/0/all/0/1\">Junya Honda</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masashi Sugiyama</a>",
          "description": "We investigate finite stochastic partial monitoring, which is a general model\nfor sequential learning with limited feedback. While Thompson sampling is one\nof the most promising algorithms on a variety of online decision-making\nproblems, its properties for stochastic partial monitoring have not been\ntheoretically investigated, and the existing algorithm relies on a heuristic\napproximation of the posterior distribution. To mitigate these problems, we\npresent a novel Thompson-sampling-based algorithm, which enables us to exactly\nsample the target parameter from the posterior distribution. Besides, we prove\nthat the new algorithm achieves the logarithmic problem-dependent expected\npseudo-regret $\\mathrm{O}(\\log T)$ for a linearized variant of the problem with\nlocal observability. This result is the first regret bound of Thompson sampling\nfor partial monitoring, which also becomes the first logarithmic regret bound\nof Thompson sampling for linear bandits.",
          "link": "http://arxiv.org/abs/2006.09668",
          "publishedOn": "2021-06-11T01:42:17.588Z",
          "wordCount": null,
          "title": "Analysis and Design of Thompson Sampling for Stochastic Partial Monitoring. (arXiv:2006.09668v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.05379",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rossenbach_N/0/1/0/all/0/1\">Nick Rossenbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeineldeen_M/0/1/0/all/0/1\">Mohammad Zeineldeen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hilmes_B/0/1/0/all/0/1\">Benedikt Hilmes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schluter_R/0/1/0/all/0/1\">Ralf Schl&#xfc;ter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ney_H/0/1/0/all/0/1\">Hermann Ney</a>",
          "description": "Recent publications on automatic-speech-recognition (ASR) have a strong focus\non attention encoder-decoder (AED) architectures which work well for large\ndatasets, but tend to overfit when applied in low resource scenarios. One\nsolution to tackle this issue is to generate synthetic data with a trained\ntext-to-speech system (TTS) if additional text is available. This was\nsuccessfully applied in many publications with AED systems. We present a novel\napproach of silence correction in the data pre-processing for TTS systems which\nincreases the robustness when training on corpora targeted for ASR\napplications. In this work we do not only show the successful application of\nsynthetic data for AED systems, but also test the same method on a highly\noptimized state-of-the-art Hybrid ASR system and a competitive monophone based\nsystem using connectionist-temporal-classification (CTC). We show that for the\nlater systems the addition of synthetic data only has a minor effect, but they\nstill outperform the AED systems by a large margin on LibriSpeech-100h. We\nachieve a final word-error-rate of 3.3%/10.0% with a Hybrid system on the\nclean/noisy test-sets, surpassing any previous state-of-the-art systems that do\nnot include unlabeled audio data.",
          "link": "http://arxiv.org/abs/2104.05379",
          "publishedOn": "2021-06-11T01:42:17.515Z",
          "wordCount": null,
          "title": "Comparing the Benefit of Synthetic Training Data for Various Automatic Speech Recognition Architectures. (arXiv:2104.05379v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.08233",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Thanh Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luu_T/0/1/0/all/0/1\">Tung Luu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pham_T/0/1/0/all/0/1\">Trung Pham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rakhimkul_S/0/1/0/all/0/1\">Sanzhar Rakhimkul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoo_C/0/1/0/all/0/1\">Chang D. Yoo</a>",
          "description": "Model agnostic meta-learning (MAML) is a popular state-of-the-art\nmeta-learning algorithm that provides good weight initialization of a model\ngiven a variety of learning tasks. The model initialized by provided weight can\nbe fine-tuned to an unseen task despite only using a small amount of samples\nand within a few adaptation steps. MAML is simple and versatile but requires\ncostly learning rate tuning and careful design of the task distribution which\naffects its scalability and generalization. This paper proposes a more robust\nMAML based on an adaptive learning scheme and a prioritization task buffer(PTB)\nreferred to as Robust MAML (RMAML) for improving scalability of training\nprocess and alleviating the problem of distribution mismatch. RMAML uses\ngradient-based hyper-parameter optimization to automatically find the optimal\nlearning rate and uses the PTB to gradually adjust train-ing task distribution\ntoward testing task distribution over the course of training. Experimental\nresults on meta reinforcement learning environments demonstrate a substantial\nperformance gain as well as being less sensitive to hyper-parameter choice and\nrobust to distribution mismatch.",
          "link": "http://arxiv.org/abs/2103.08233",
          "publishedOn": "2021-06-11T01:42:17.500Z",
          "wordCount": null,
          "title": "Robust MAML: Prioritization task buffer with adaptive learning process for model-agnostic meta-learning. (arXiv:2103.08233v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.04298",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Vieting_P/0/1/0/all/0/1\">Peter Vieting</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Luscher_C/0/1/0/all/0/1\">Christoph L&#xfc;scher</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Michel_W/0/1/0/all/0/1\">Wilfried Michel</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Schluter_R/0/1/0/all/0/1\">Ralf Schl&#xfc;ter</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ney_H/0/1/0/all/0/1\">Hermann Ney</a>",
          "description": "Acoustic modeling of raw waveform and learning feature extractors as part of\nthe neural network classifier has been the goal of many studies in the area of\nautomatic speech recognition (ASR). Recently, one line of research has focused\non frameworks that can be pre-trained on audio-only data in an unsupervised\nfashion and aim at improving downstream ASR tasks. In this work, we investigate\nthe usefulness of one of these front-end frameworks, namely wav2vec, for hybrid\nASR systems. In addition to deploying a pre-trained feature extractor, we\nexplore how to make use of an existing acoustic model (AM) trained on the same\ntask with different features as well. Another neural front-end which is only\ntrained together with the supervised ASR loss as well as traditional Gammatone\nfeatures are applied for comparison. Moreover, it is shown that the AM can be\nretrofitted with i-vectors for speaker adaptation. Finally, the described\nfeatures are combined in order to further advance the performance. With the\nfinal best system, we obtain a relative improvement of 4% and 6% over our\nprevious best model on the LibriSpeech test-clean and test-other sets.",
          "link": "http://arxiv.org/abs/2104.04298",
          "publishedOn": "2021-06-11T01:42:17.494Z",
          "wordCount": null,
          "title": "Feature Replacement and Combination for Hybrid ASR Systems. (arXiv:2104.04298v2 [eess.AS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.06847",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pang_G/0/1/0/all/0/1\">Guansong Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hengel_A/0/1/0/all/0/1\">Anton van den Hengel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1\">Chunhua Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_L/0/1/0/all/0/1\">Longbing Cao</a>",
          "description": "We consider the problem of anomaly detection with a small set of partially\nlabeled anomaly examples and a large-scale unlabeled dataset. This is a common\nscenario in many important applications. Existing related methods either\nexclusively fit the limited anomaly examples that typically do not span the\nentire set of anomalies, or proceed with unsupervised learning from the\nunlabeled data. We propose here instead a deep reinforcement learning-based\napproach that enables an end-to-end optimization of the detection of both\nlabeled and unlabeled anomalies. This approach learns the known abnormality by\nautomatically interacting with an anomaly-biased simulation environment, while\ncontinuously extending the learned abnormality to novel classes of anomaly\n(i.e., unknown anomalies) by actively exploring possible anomalies in the\nunlabeled data. This is achieved by jointly optimizing the exploitation of the\nsmall labeled anomaly data and the exploration of the rare unlabeled anomalies.\nExtensive experiments on 48 real-world datasets show that our model\nsignificantly outperforms five state-of-the-art competing methods.",
          "link": "http://arxiv.org/abs/2009.06847",
          "publishedOn": "2021-06-11T01:42:17.293Z",
          "wordCount": 650,
          "title": "Toward Deep Supervised Anomaly Detection: Reinforcement Learning from Partially Labeled Anomaly Data. (arXiv:2009.06847v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.12428",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Refinetti_M/0/1/0/all/0/1\">Maria Refinetti</a>, <a href=\"http://arxiv.org/find/stat/1/au:+dAscoli_S/0/1/0/all/0/1\">St&#xe9;phane d&#x27;Ascoli</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ohana_R/0/1/0/all/0/1\">Ruben Ohana</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Goldt_S/0/1/0/all/0/1\">Sebastian Goldt</a>",
          "description": "Direct Feedback Alignment (DFA) is emerging as an efficient and biologically\nplausible alternative to the ubiquitous backpropagation algorithm for training\ndeep neural networks. Despite relying on random feedback weights for the\nbackward pass, DFA successfully trains state-of-the-art models such as\nTransformers. On the other hand, it notoriously fails to train convolutional\nnetworks. An understanding of the inner workings of DFA to explain these\ndiverging results remains elusive. Here, we propose a theory for the success of\nDFA. We first show that learning in shallow networks proceeds in two steps: an\nalignment phase, where the model adapts its weights to align the approximate\ngradient with the true gradient of the loss function, is followed by a\nmemorisation phase, where the model focuses on fitting the data. This two-step\nprocess has a degeneracy breaking effect: out of all the low-loss solutions in\nthe landscape, a network trained with DFA naturally converges to the solution\nwhich maximises gradient alignment. We also identify a key quantity underlying\nalignment in deep linear networks: the conditioning of the alignment matrices.\nThe latter enables a detailed understanding of the impact of data structure on\nalignment, and suggests a simple explanation for the well-known failure of DFA\nto train convolutional neural networks. Numerical experiments on MNIST and\nCIFAR10 clearly demonstrate degeneracy breaking in deep non-linear networks and\nshow that the align-then-memorise process occurs sequentially from the bottom\nlayers of the network to the top.",
          "link": "http://arxiv.org/abs/2011.12428",
          "publishedOn": "2021-06-11T01:42:17.287Z",
          "wordCount": 727,
          "title": "Align, then memorise: the dynamics of learning with feedback alignment. (arXiv:2011.12428v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05969",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1\">Zhengyi Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hachiuma_R/0/1/0/all/0/1\">Ryo Hachiuma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1\">Ye Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kitani_K/0/1/0/all/0/1\">Kris Kitani</a>",
          "description": "We propose a method for object-aware 3D egocentric pose estimation that\ntightly integrates kinematics modeling, dynamics modeling, and scene object\ninformation. Unlike prior kinematics or dynamics-based approaches where the two\ncomponents are used disjointly, we synergize the two approaches via\ndynamics-regulated training. At each timestep, a kinematic model is used to\nprovide a target pose using video evidence and simulation state. Then, a\nprelearned dynamics model attempts to mimic the kinematic pose in a physics\nsimulator. By comparing the pose instructed by the kinematic model against the\npose generated by the dynamics model, we can use their misalignment to further\nimprove the kinematic model. By factoring in the 6DoF pose of objects (e.g.,\nchairs, boxes) in the scene, we demonstrate for the first time, the ability to\nestimate physically-plausible 3D human-object interactions using a single\nwearable camera. We evaluate our egocentric pose estimation method in both\ncontrolled laboratory settings and real-world scenarios.",
          "link": "http://arxiv.org/abs/2106.05969",
          "publishedOn": "2021-06-11T01:42:17.275Z",
          "wordCount": 596,
          "title": "Dynamics-Regulated Kinematic Policy for Egocentric Pose Estimation. (arXiv:2106.05969v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05875",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Grinsztajn_N/0/1/0/all/0/1\">Nathan Grinsztajn</a> (Scool), <a href=\"http://arxiv.org/find/cs/1/au:+Leconte_L/0/1/0/all/0/1\">Louis Leconte</a> (MLIA, CMAP), <a href=\"http://arxiv.org/find/cs/1/au:+Preux_P/0/1/0/all/0/1\">Philippe Preux</a> (Scool), <a href=\"http://arxiv.org/find/cs/1/au:+Oyallon_E/0/1/0/all/0/1\">Edouard Oyallon</a> (MLIA)",
          "description": "We present a new approach for learning unsupervised node representations in\ncommunity graphs. We significantly extend the Interferometric Graph Transform\n(IGT) to community labeling: this non-linear operator iteratively extracts\nfeatures that take advantage of the graph topology through demodulation\noperations. An unsupervised feature extraction step cascades modulus\nnon-linearity with linear operators that aim at building relevant invariants\nfor community labeling. Via a simplified model, we show that the IGT\nconcentrates around the E-IGT: those two representations are related through\nsome ergodicity properties. Experiments on community labeling tasks show that\nthis unsupervised representation achieves performances at the level of the\nstate of the art on the standard and challenging datasets Cora, Citeseer,\nPubmed and WikiCS.",
          "link": "http://arxiv.org/abs/2106.05875",
          "publishedOn": "2021-06-11T01:42:17.212Z",
          "wordCount": 542,
          "title": "Interferometric Graph Transform for Community Labeling. (arXiv:2106.05875v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05731",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wen_H/0/1/0/all/0/1\">Hongwei Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_J/0/1/0/all/0/1\">Jingyi Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hang_H/0/1/0/all/0/1\">Hanyuan Hang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiabin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yisen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhouchen Lin</a>",
          "description": "As an important branch of weakly supervised learning, partial label learning\ndeals with data where each instance is assigned with a set of candidate labels,\nwhereas only one of them is true. Despite many methodology studies on learning\nfrom partial labels, there still lacks theoretical understandings of their risk\nconsistent properties under relatively weak assumptions, especially on the link\nbetween theoretical results and the empirical choice of parameters. In this\npaper, we propose a family of loss functions named \\textit{Leveraged Weighted}\n(LW) loss, which for the first time introduces the leverage parameter $\\beta$\nto consider the trade-off between losses on partial labels and non-partial\nones. From the theoretical side, we derive a generalized result of risk\nconsistency for the LW loss in learning from partial labels, based on which we\nprovide guidance to the choice of the leverage parameter $\\beta$. In\nexperiments, we verify the theoretical guidance, and show the high\neffectiveness of our proposed LW loss on both benchmark and real datasets\ncompared with other state-of-the-art partial label learning algorithms.",
          "link": "http://arxiv.org/abs/2106.05731",
          "publishedOn": "2021-06-11T01:42:17.207Z",
          "wordCount": 604,
          "title": "Leveraged Weighted Loss for Partial Label Learning. (arXiv:2106.05731v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05522",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_O/0/1/0/all/0/1\">Ou Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">Weiyao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1\">Yingjun Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Haixiang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_Q/0/1/0/all/0/1\">Qinghu Hou</a>",
          "description": "A common assumption in machine learning is that samples are independently and\nidentically distributed (i.i.d). However, the contributions of different\nsamples are not identical in training. Some samples are difficult to learn and\nsome samples are noisy. The unequal contributions of samples has a considerable\neffect on training performances. Studies focusing on unequal sample\ncontributions (e.g., easy, hard, noisy) in learning usually refer to these\ncontributions as robust machine learning (RML). Weighing and regularization are\ntwo common techniques in RML. Numerous learning algorithms have been proposed\nbut the strategies for dealing with easy/hard/noisy samples differ or even\ncontradict with different learning algorithms. For example, some strategies\ntake the hard samples first, whereas some strategies take easy first.\nConducting a clear comparison for existing RML algorithms in dealing with\ndifferent samples is difficult due to lack of a unified theoretical framework\nfor RML. This study attempts to construct a mathematical foundation for RML\nbased on the bias-variance trade-off theory. A series of definitions and\nproperties are presented and proved. Several classical learning algorithms are\nalso explained and compared. Improvements of existing methods are obtained\nbased on the comparison. A unified method that combines two classical learning\nstrategies is proposed.",
          "link": "http://arxiv.org/abs/2106.05522",
          "publishedOn": "2021-06-11T01:42:17.201Z",
          "wordCount": 631,
          "title": "A Mathematical Foundation for Robust Machine Learning based on Bias-Variance Trade-off. (arXiv:2106.05522v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05735",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Antonelli_M/0/1/0/all/0/1\">Michela Antonelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reinke_A/0/1/0/all/0/1\">Annika Reinke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bakas_S/0/1/0/all/0/1\">Spyridon Bakas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farahani_K/0/1/0/all/0/1\">Keyvan Farahani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+AnnetteKopp-Schneider/0/1/0/all/0/1\">AnnetteKopp-Schneider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Landman_B/0/1/0/all/0/1\">Bennett A. Landman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Litjens_G/0/1/0/all/0/1\">Geert Litjens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Menze_B/0/1/0/all/0/1\">Bjoern Menze</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ronneberger_O/0/1/0/all/0/1\">Olaf Ronneberger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Summers_R/0/1/0/all/0/1\">Ronald M.Summers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ginneken_B/0/1/0/all/0/1\">Bram van Ginneken</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bilello_M/0/1/0/all/0/1\">Michel Bilello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bilic_P/0/1/0/all/0/1\">Patrick Bilic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Christ_P/0/1/0/all/0/1\">Patrick F. Christ</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Do_R/0/1/0/all/0/1\">Richard K. G. Do</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gollub_M/0/1/0/all/0/1\">Marc J. Gollub</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heckers_S/0/1/0/all/0/1\">Stephan H. Heckers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huisman_H/0/1/0/all/0/1\">Henkjan Huisman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jarnagin_W/0/1/0/all/0/1\">William R. Jarnagin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McHugo_M/0/1/0/all/0/1\">Maureen K. McHugo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Napel_S/0/1/0/all/0/1\">Sandy Napel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pernicka_J/0/1/0/all/0/1\">Jennifer S. Goli Pernicka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rhode_K/0/1/0/all/0/1\">Kawal Rhode</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tobon_Gomez_C/0/1/0/all/0/1\">Catalina Tobon-Gomez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vorontsov_E/0/1/0/all/0/1\">Eugene Vorontsov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huisman_H/0/1/0/all/0/1\">Henkjan Huisman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meakin_J/0/1/0/all/0/1\">James A. Meakin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ourselin_S/0/1/0/all/0/1\">Sebastien Ourselin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wiesenfarth_M/0/1/0/all/0/1\">Manuel Wiesenfarth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arbelaez_P/0/1/0/all/0/1\">Pablo Arbelaez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bae_B/0/1/0/all/0/1\">Byeonguk Bae</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Sihong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daza_L/0/1/0/all/0/1\">Laura Daza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jianjiang Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_B/0/1/0/all/0/1\">Baochun He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Isensee_F/0/1/0/all/0/1\">Fabian Isensee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_Y/0/1/0/all/0/1\">Yuanfeng Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_F/0/1/0/all/0/1\">Fucang Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_N/0/1/0/all/0/1\">Namkug Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_I/0/1/0/all/0/1\">Ildoo Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Merhof_D/0/1/0/all/0/1\">Dorit Merhof</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pai_A/0/1/0/all/0/1\">Akshay Pai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_B/0/1/0/all/0/1\">Beomhee Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perslev_M/0/1/0/all/0/1\">Mathias Perslev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rezaiifar_R/0/1/0/all/0/1\">Ramin Rezaiifar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rippel_O/0/1/0/all/0/1\">Oliver Rippel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarasua_I/0/1/0/all/0/1\">Ignacio Sarasua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_W/0/1/0/all/0/1\">Wei Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Son_J/0/1/0/all/0/1\">Jaemin Son</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wachinger_C/0/1/0/all/0/1\">Christian Wachinger</a>, et al. (9 additional authors not shown)",
          "description": "International challenges have become the de facto standard for comparative\nassessment of image analysis algorithms given a specific task. Segmentation is\nso far the most widely investigated medical image processing task, but the\nvarious segmentation challenges have typically been organized in isolation,\nsuch that algorithm development was driven by the need to tackle a single\nspecific clinical problem. We hypothesized that a method capable of performing\nwell on multiple tasks will generalize well to a previously unseen task and\npotentially outperform a custom-designed solution. To investigate the\nhypothesis, we organized the Medical Segmentation Decathlon (MSD) - a\nbiomedical image analysis challenge, in which algorithms compete in a multitude\nof both tasks and modalities. The underlying data set was designed to explore\nthe axis of difficulties typically encountered when dealing with medical\nimages, such as small data sets, unbalanced labels, multi-site data and small\nobjects. The MSD challenge confirmed that algorithms with a consistent good\nperformance on a set of tasks preserved their good average performance on a\ndifferent set of previously unseen tasks. Moreover, by monitoring the MSD\nwinner for two years, we found that this algorithm continued generalizing well\nto a wide range of other clinical problems, further confirming our hypothesis.\nThree main conclusions can be drawn from this study: (1) state-of-the-art image\nsegmentation algorithms are mature, accurate, and generalize well when\nretrained on unseen tasks; (2) consistent algorithmic performance across\nmultiple tasks is a strong surrogate of algorithmic generalizability; (3) the\ntraining of accurate AI segmentation models is now commoditized to non AI\nexperts.",
          "link": "http://arxiv.org/abs/2106.05735",
          "publishedOn": "2021-06-11T01:42:17.184Z",
          "wordCount": 811,
          "title": "The Medical Segmentation Decathlon. (arXiv:2106.05735v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05526",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zha_D/0/1/0/all/0/1\">Daochen Zha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_K/0/1/0/all/0/1\">Kwei-Herng Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1\">Kaixiong Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xia Hu</a>",
          "description": "Supervised regression to demonstrations has been demonstrated to be a stable\nway to train deep policy networks. We are motivated to study how we can take\nfull advantage of supervised loss functions for stably training deep\nreinforcement learning agents. This is a challenging task because it is unclear\nhow the training data could be collected to enable policy improvement. In this\nwork, we propose Self-Supervised Reinforcement Learning (SSRL), a simple\nalgorithm that optimizes policies with purely supervised losses. We demonstrate\nthat, without policy gradient or value estimation, an iterative procedure of\n``labeling\" data and supervised regression is sufficient to drive stable policy\nimprovement. By selecting and imitating trajectories with high episodic\nrewards, SSRL is surprisingly competitive to contemporary algorithms with more\nstable performance and less running time, showing the potential of solving\nreinforcement learning with supervised learning techniques. The code is\navailable at https://github.com/daochenzha/SSRL",
          "link": "http://arxiv.org/abs/2106.05526",
          "publishedOn": "2021-06-11T01:42:17.166Z",
          "wordCount": 566,
          "title": "Simplifying Deep Reinforcement Learning via Self-Supervision. (arXiv:2106.05526v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05459",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kulikov_I/0/1/0/all/0/1\">Ilia Kulikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Welleck_S/0/1/0/all/0/1\">Sean Welleck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1\">Kyunghyun Cho</a>",
          "description": "Despite its wide use, recent studies have revealed unexpected and undesirable\nproperties of neural autoregressive sequence models trained with maximum\nlikelihood, such as an unreasonably high affinity to short sequences after\ntraining and to infinitely long sequences at decoding time. We propose to study\nthese phenomena by investigating how the modes, or local maxima, of a\ndistribution are maintained throughout the full learning chain of the\nground-truth, empirical, learned and decoding-induced distributions, via the\nnewly proposed mode recovery cost. We design a tractable testbed where we build\nthree types of ground-truth distributions: (1) an LSTM based structured\ndistribution, (2) an unstructured distribution where probability of a sequence\ndoes not depend on its content, and (3) a product of these two which we call a\nsemi-structured distribution. Our study reveals both expected and unexpected\nfindings. First, starting with data collection, mode recovery cost strongly\nrelies on the ground-truth distribution and is most costly with the\nsemi-structured distribution. Second, after learning, mode recovery cost from\nthe ground-truth distribution may increase or decrease compared to data\ncollection, with the largest cost degradation occurring with the\nsemi-structured ground-truth distribution. Finally, the ability of the\ndecoding-induced distribution to recover modes from the learned distribution is\nhighly impacted by the choices made earlier in the learning chain. We conclude\nthat future research must consider the entire learning chain in order to fully\nunderstand the potentials and perils and to further improve neural\nautoregressive sequence models.",
          "link": "http://arxiv.org/abs/2106.05459",
          "publishedOn": "2021-06-11T01:42:17.131Z",
          "wordCount": 673,
          "title": "Mode recovery in neural autoregressive sequence modeling. (arXiv:2106.05459v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05458",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xindi Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Limin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_W/0/1/0/all/0/1\">Wufeng Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yan Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shengfeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yuhao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1\">Shuangping Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shang_N/0/1/0/all/0/1\">Ning Shang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_D/0/1/0/all/0/1\">Dong Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_N/0/1/0/all/0/1\">Ning Gu</a>",
          "description": "The ultrasound (US) screening of the infant hip is vital for the early\ndiagnosis of developmental dysplasia of the hip (DDH). The US diagnosis of DDH\nrefers to measuring alpha and beta angles that quantify hip joint development.\nThese two angles are calculated from key anatomical landmarks and structures of\nthe hip. However, this measurement process is not trivial for sonographers and\nusually requires a thorough understanding of complex anatomical structures. In\nthis study, we propose a multi-task framework to learn the relationships among\nlandmarks and structures jointly and automatically evaluate DDH. Our multi-task\nnetworks are equipped with three novel modules. Firstly, we adopt Mask R-CNN as\nthe basic framework to detect and segment key anatomical structures and add one\nlandmark detection branch to form a new multi-task framework. Secondly, we\npropose a novel shape similarity loss to refine the incomplete anatomical\nstructure prediction robustly and accurately. Thirdly, we further incorporate\nthe landmark-structure consistent prior to ensure the consistency of the bony\nrim estimated from the segmented structure and the detected landmark. In our\nexperiments, 1,231 US images of the infant hip from 632 patients are collected,\nof which 247 images from 126 patients are tested. The average errors in alpha\nand beta angles are 2.221 degrees and 2.899 degrees. About 93% and 85%\nestimates of alpha and beta angles have errors less than 5 degrees,\nrespectively. Experimental results demonstrate that the proposed method can\naccurately and robustly realize the automatic evaluation of DDH, showing great\npotential for clinical application.",
          "link": "http://arxiv.org/abs/2106.05458",
          "publishedOn": "2021-06-11T01:42:17.107Z",
          "wordCount": 733,
          "title": "Joint Landmark and Structure Learning for Automatic Evaluation of Developmental Dysplasia of the Hip. (arXiv:2106.05458v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05542",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jung_E/0/1/0/all/0/1\">Eun-Soo Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Son_H/0/1/0/all/0/1\">HyeongGwan Son</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_K/0/1/0/all/0/1\">Kyusam Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yun_Y/0/1/0/all/0/1\">Yongkeun Yun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwon_S/0/1/0/all/0/1\">Soonhwan Kwon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Min Soo Kim</a>",
          "description": "We present a novel deep neural model for text detection in document images.\nFor robust text detection in noisy scanned documents, the advantages of\nmulti-task learning are adopted by adding an auxiliary task of text\nenhancement. Namely, our proposed model is designed to perform noise reduction\nand text region enhancement as well as text detection. Moreover, we enrich the\ntraining data for the model with synthesized document images that are fully\nlabeled for text detection and enhancement, thus overcome the insufficiency of\nlabeled document image data. For the effective exploitation of the synthetic\nand real data, the training process is separated in two phases. The first phase\nis training only synthetic data in a fully-supervised manner. Then real data\nwith only detection labels are added in the second phase. The enhancement task\nfor the real data is weakly-supervised with information from their detection\nlabels. Our methods are demonstrated in a real document dataset with\nperformances exceeding those of other text detection methods. Moreover,\nablations are conducted and the results confirm the effectiveness of the\nsynthetic data, auxiliary task, and weak-supervision. Whereas the existing text\ndetection studies mostly focus on the text in scenes, our proposed method is\noptimized to the applications for the text in scanned documents.",
          "link": "http://arxiv.org/abs/2106.05542",
          "publishedOn": "2021-06-11T01:42:17.101Z",
          "wordCount": 668,
          "title": "DUET: Detection Utilizing Enhancement for Text in Scanned or Captured Documents. (arXiv:2106.05542v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05968",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bulat_A/0/1/0/all/0/1\">Adrian Bulat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perez_Rua_J/0/1/0/all/0/1\">Juan-Manuel Perez-Rua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sudhakaran_S/0/1/0/all/0/1\">Swathikiran Sudhakaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martinez_B/0/1/0/all/0/1\">Brais Martinez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tzimiropoulos_G/0/1/0/all/0/1\">Georgios Tzimiropoulos</a>",
          "description": "This paper is on video recognition using Transformers. Very recent attempts\nin this area have demonstrated promising results in terms of recognition\naccuracy, yet they have been also shown to induce, in many cases, significant\ncomputational overheads due to the additional modelling of the temporal\ninformation. In this work, we propose a Video Transformer model the complexity\nof which scales linearly with the number of frames in the video sequence and\nhence induces \\textit{no overhead} compared to an image-based Transformer\nmodel. To achieve this, our model makes two approximations to the full\nspace-time attention used in Video Transformers: (a) It restricts time\nattention to a local temporal window and capitalizes on the Transformer's depth\nto obtain full temporal coverage of the video sequence. (b) It uses efficient\nspace-time mixing to attend \\textit{jointly} spatial and temporal locations\nwithout inducing any additional cost on top of a spatial-only attention model.\nWe also show how to integrate 2 very lightweight mechanisms for global\ntemporal-only attention which provide additional accuracy improvements at\nminimal computational cost. We demonstrate that our model produces very high\nrecognition accuracy on the most popular video recognition datasets while at\nthe same time being significantly more efficient than other Video Transformer\nmodels. Code will be made available.",
          "link": "http://arxiv.org/abs/2106.05968",
          "publishedOn": "2021-06-11T01:42:17.092Z",
          "wordCount": 643,
          "title": "Space-time Mixing Attention for Video Transformer. (arXiv:2106.05968v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05536",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Pfitzinger_J/0/1/0/all/0/1\">Johann Pfitzinger</a>",
          "description": "Adoption of deep neural networks in fields such as economics or finance has\nbeen constrained by the lack of interpretability of model outcomes. This paper\nproposes a generative neural network architecture - the parameter encoder\nneural network (PENN) - capable of estimating local posterior distributions for\nthe parameters of a regression model. The parameters fully explain predictions\nin terms of the inputs and permit visualization, interpretation and inference\nin the presence of complex heterogeneous effects and feature dependencies. The\nuse of Bayesian inference techniques offers an intuitive mechanism to\nregularize local parameter estimates towards a stable solution, and to reduce\nnoise-fitting in settings of limited data availability. The proposed neural\nnetwork is particularly well-suited to applications in economics and finance,\nwhere parameter inference plays an important role. An application to an asset\npricing problem demonstrates how the PENN can be used to explore nonlinear risk\ndynamics in financial markets, and to compare empirical nonlinear effects to\nbehavior posited by financial theory.",
          "link": "http://arxiv.org/abs/2106.05536",
          "publishedOn": "2021-06-11T01:42:17.086Z",
          "wordCount": 585,
          "title": "An Interpretable Neural Network for Parameter Inference. (arXiv:2106.05536v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05724",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Wang_T/0/1/0/all/0/1\">Tianyu Wang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Chen_N/0/1/0/all/0/1\">Ningyuan Chen</a>, <a href=\"http://arxiv.org/find/math/1/au:+Wang_C/0/1/0/all/0/1\">Chun Wang</a>",
          "description": "In prescriptive analytics, the decision-maker observes historical samples of\n$(X, Y)$, where $Y$ is the uncertain problem parameter and $X$ is the\nconcurrent covariate, without knowing the joint distribution. Given an\nadditional covariate observation $x$, the goal is to choose a decision $z$\nconditional on this observation to minimize the cost $\\mathbb{E}[c(z,Y)|X=x]$.\nThis paper proposes a new distributionally robust approach under Wasserstein\nambiguity sets, in which the nominal distribution of $Y|X=x$ is constructed\nbased on the Nadaraya-Watson kernel estimator concerning the historical data.\nWe show that the nominal distribution converges to the actual conditional\ndistribution under the Wasserstein distance. We establish the out-of-sample\nguarantees and the computational tractability of the framework. Through\nsynthetic and empirical experiments about the newsvendor problem and portfolio\noptimization, we demonstrate the strong performance and practical value of the\nproposed framework.",
          "link": "http://arxiv.org/abs/2106.05724",
          "publishedOn": "2021-06-11T01:42:17.081Z",
          "wordCount": 560,
          "title": "Distributionally Robust Prescriptive Analytics with Wasserstein Distance. (arXiv:2106.05724v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05527",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1\">Dongjun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_S/0/1/0/all/0/1\">Seungjae Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_K/0/1/0/all/0/1\">Kyungwoo Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_W/0/1/0/all/0/1\">Wanmo Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moon_I/0/1/0/all/0/1\">Il-Chul Moon</a>",
          "description": "Recent advance in score-based models incorporates the stochastic differential\nequation (SDE), which brings the state-of-the art performance on image\ngeneration tasks. This paper improves such score-based models by analyzing the\nmodel at the zero perturbation noise. In real datasets, the score function\ndiverges as the perturbation noise ($\\sigma$) decreases to zero, and this\nobservation leads an argument that the score estimation fails at $\\sigma=0$\nwith any neural network structure. Subsequently, we introduce Unbounded Noise\nConditional Score Network (UNCSN) that resolves the score diverging problem\nwith an easily applicable modification to any noise conditional score-based\nmodels. Additionally, we introduce a new type of SDE, so the exact log\nlikelihood can be calculated from the newly suggested SDE. On top of that, the\nassociated loss function mitigates the loss imbalance issue in a mini-batch,\nand we present a theoretic analysis on the proposed loss to uncover the behind\nmechanism of the data distribution modeling by the score-based models.",
          "link": "http://arxiv.org/abs/2106.05527",
          "publishedOn": "2021-06-11T01:42:17.062Z",
          "wordCount": 594,
          "title": "Score Matching Model for Unbounded Data Score. (arXiv:2106.05527v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05763",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Manduchi_L/0/1/0/all/0/1\">Laura Manduchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marcinkevics_R/0/1/0/all/0/1\">Ri&#x10d;ards Marcinkevi&#x10d;s</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Massi_M/0/1/0/all/0/1\">Michela C. Massi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gotta_V/0/1/0/all/0/1\">Verena Gotta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muller_T/0/1/0/all/0/1\">Timothy M&#xfc;ller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasella_F/0/1/0/all/0/1\">Flavio Vasella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neidert_M/0/1/0/all/0/1\">Marian C. Neidert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfister_M/0/1/0/all/0/1\">Marc Pfister</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogt_J/0/1/0/all/0/1\">Julia E. Vogt</a>",
          "description": "Survival analysis has gained significant attention in the medical domain and\nhas many far-reaching applications. Although a variety of machine learning\nmethods have been introduced for tackling time-to-event prediction in\nunstructured data with complex dependencies, clustering of survival data\nremains an under-explored problem. The latter is particularly helpful in\ndiscovering patient subpopulations whose survival is regulated by different\ngenerative mechanisms, a critical problem in precision medicine. To this end,\nwe introduce a novel probabilistic approach to cluster survival data in a\nvariational deep clustering setting. Our proposed method employs a deep\ngenerative model to uncover the underlying distribution of both the explanatory\nvariables and the potentially censored survival times. We compare our model to\nthe related work on survival clustering in comprehensive experiments on a range\nof synthetic, semi-synthetic, and real-world datasets. Our proposed method\nperforms better at identifying clusters and is competitive at predicting\nsurvival times in terms of the concordance index and relative absolute error.\nTo further demonstrate the usefulness of our approach, we show that our method\nidentifies meaningful clusters from an observational cohort of hemodialysis\npatients that are consistent with previous clinical findings.",
          "link": "http://arxiv.org/abs/2106.05763",
          "publishedOn": "2021-06-11T01:42:17.050Z",
          "wordCount": 628,
          "title": "A Deep Variational Approach to Clustering Survival Data. (arXiv:2106.05763v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05530",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jing_M/0/1/0/all/0/1\">Mingxuan Jing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Wenbing Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_F/0/1/0/all/0/1\">Fuchun Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xiaojian Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_T/0/1/0/all/0/1\">Tao Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_C/0/1/0/all/0/1\">Chuang Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>",
          "description": "It has been a challenge to learning skills for an agent from long-horizon\nunannotated demonstrations. Existing approaches like Hierarchical Imitation\nLearning(HIL) are prone to compounding errors or suboptimal solutions. In this\npaper, we propose Option-GAIL, a novel method to learn skills at long horizon.\nThe key idea of Option-GAIL is modeling the task hierarchy by options and train\nthe policy via generative adversarial optimization. In particular, we propose\nan Expectation-Maximization(EM)-style algorithm: an E-step that samples the\noptions of expert conditioned on the current learned policy, and an M-step that\nupdates the low- and high-level policies of agent simultaneously to minimize\nthe newly proposed option-occupancy measurement between the expert and the\nagent. We theoretically prove the convergence of the proposed algorithm.\nExperiments show that Option-GAIL outperforms other counterparts consistently\nacross a variety of tasks.",
          "link": "http://arxiv.org/abs/2106.05530",
          "publishedOn": "2021-06-11T01:42:17.043Z",
          "wordCount": 564,
          "title": "Adversarial Option-Aware Hierarchical Imitation Learning. (arXiv:2106.05530v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05625",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Loi_N/0/1/0/all/0/1\">Nicola Loi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borile_C/0/1/0/all/0/1\">Claudio Borile</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ucci_D/0/1/0/all/0/1\">Daniele Ucci</a>",
          "description": "The constant growth in the number of malware - software or code fragment\npotentially harmful for computers and information networks - and the use of\nsophisticated evasion and obfuscation techniques have seriously hindered\nclassic signature-based approaches. On the other hand, malware detection\nsystems based on machine learning techniques started offering a promising\nalternative to standard approaches, drastically reducing analysis time and\nturning out to be more robust against evasion and obfuscation techniques. In\nthis paper, we propose a malware taxonomic classification pipeline able to\nclassify Windows Portable Executable files (PEs). Given an input PE sample, it\nis first classified as either malicious or benign. If malicious, the pipeline\nfurther analyzes it in order to establish its threat type, family, and\nbehavior(s). We tested the proposed pipeline on the open source dataset EMBER,\ncontaining approximately 1 million PE samples, analyzed through static\nanalysis. Obtained malware detection results are comparable to other academic\nworks in the current state of art and, in addition, we provide an in-depth\nclassification of malicious samples. Models used in the pipeline provides\ninterpretable results which can help security analysts in better understanding\ndecisions taken by the automated pipeline.",
          "link": "http://arxiv.org/abs/2106.05625",
          "publishedOn": "2021-06-11T01:42:17.037Z",
          "wordCount": 636,
          "title": "Towards an Automated Pipeline for Detecting and Classifying Malware through Machine Learning. (arXiv:2106.05625v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05426",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Antonello_R/0/1/0/all/0/1\">Richard Antonello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turek_J/0/1/0/all/0/1\">Javier Turek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vo_V/0/1/0/all/0/1\">Vy Vo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huth_A/0/1/0/all/0/1\">Alexander Huth</a>",
          "description": "How related are the representations learned by neural language models,\ntranslation models, and language tagging tasks? We answer this question by\nadapting an encoder-decoder transfer learning method from computer vision to\ninvestigate the structure among 100 different feature spaces extracted from\nhidden representations of various networks trained on language tasks. This\nmethod reveals a low-dimensional structure where language models and\ntranslation models smoothly interpolate between word embeddings, syntactic and\nsemantic tasks, and future word embeddings. We call this low-dimensional\nstructure a language representation embedding because it encodes the\nrelationships between representations needed to process language for a variety\nof NLP tasks. We find that this representation embedding can predict how well\neach individual feature space maps to human brain responses to natural language\nstimuli recorded using fMRI. Additionally, we find that the principal dimension\nof this structure can be used to create a metric which highlights the brain's\nnatural language processing hierarchy. This suggests that the embedding\ncaptures some part of the brain's natural language representation structure.",
          "link": "http://arxiv.org/abs/2106.05426",
          "publishedOn": "2021-06-11T01:42:17.019Z",
          "wordCount": 611,
          "title": "Low-Dimensional Structure in the Space of Language Representations is Reflected in Brain Responses. (arXiv:2106.05426v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2006.16993",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1\">Kun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kpotufe_S/0/1/0/all/0/1\">Samory Kpotufe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feamster_N/0/1/0/all/0/1\">Nick Feamster</a>",
          "description": "Data representation plays a critical role in the performance of novelty\ndetection (or ``anomaly detection'') methods in machine learning. The data\nrepresentation of network traffic often determines the effectiveness of these\nmodels as much as the model itself. The wide range of novel events that network\noperators need to detect (e.g., attacks, malware, new applications, changes in\ntraffic demands) introduces the possibility for a broad range of possible\nmodels and data representations. In each scenario, practitioners must spend\nsignificant effort extracting and engineering features that are most predictive\nfor that situation or application. While anomaly detection is well-studied in\ncomputer networking, much existing work develops specific models that presume a\nparticular representation -- often IPFIX/NetFlow. Yet, other representations\nmay result in higher model accuracy, and the rise of programmable networks now\nmakes it more practical to explore a broader range of representations. To\nfacilitate such exploration, we develop a systematic framework, open-source\ntoolkit, and public Python library that makes it both possible and easy to\nextract and generate features from network traffic and perform and end-to-end\nevaluation of these representations across most prevalent modern novelty\ndetection models. We first develop and publicly release an open-source tool, an\naccompanying Python library (NetML), and end-to-end pipeline for novelty\ndetection in network traffic. Second, we apply this tool to five different\nnovelty detection problems in networking, across a range of scenarios from\nattack detection to novel device detection. Our findings general insights and\nguidelines concerning which features appear to be more appropriate for\nparticular situations.",
          "link": "http://arxiv.org/abs/2006.16993",
          "publishedOn": "2021-06-11T01:42:17.013Z",
          "wordCount": 714,
          "title": "Feature Extraction for Novelty Detection in Network Traffic. (arXiv:2006.16993v2 [cs.NI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05767",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Gijsbers_P/0/1/0/all/0/1\">Pieter Gijsbers</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pfisterer_F/0/1/0/all/0/1\">Florian Pfisterer</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rijn_J/0/1/0/all/0/1\">Jan N. van Rijn</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bischl_B/0/1/0/all/0/1\">Bernd Bischl</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vanschoren_J/0/1/0/all/0/1\">Joaquin Vanschoren</a>",
          "description": "Hyperparameter optimization in machine learning (ML) deals with the problem\nof empirically learning an optimal algorithm configuration from data, usually\nformulated as a black-box optimization problem. In this work, we propose a\nzero-shot method to meta-learn symbolic default hyperparameter configurations\nthat are expressed in terms of the properties of the dataset. This enables a\nmuch faster, but still data-dependent, configuration of the ML algorithm,\ncompared to standard hyperparameter optimization approaches. In the past,\nsymbolic and static default values have usually been obtained as hand-crafted\nheuristics. We propose an approach of learning such symbolic configurations as\nformulas of dataset properties from a large set of prior evaluations on\nmultiple datasets by optimizing over a grammar of expressions using an\nevolutionary algorithm. We evaluate our method on surrogate empirical\nperformance models as well as on real data across 6 ML algorithms on more than\n100 datasets and demonstrate that our method indeed finds viable symbolic\ndefaults.",
          "link": "http://arxiv.org/abs/2106.05767",
          "publishedOn": "2021-06-11T01:42:16.995Z",
          "wordCount": 600,
          "title": "Meta-Learning for Symbolic Hyperparameter Defaults. (arXiv:2106.05767v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05484",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tianhao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1\">Yi Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_M/0/1/0/all/0/1\">Ming Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1\">Ruoxi Jia</a>",
          "description": "High-quality data is critical to train performant Machine Learning (ML)\nmodels, highlighting the importance of Data Quality Management (DQM). Existing\nDQM schemes often cannot satisfactorily improve ML performance because, by\ndesign, they are oblivious to downstream ML tasks. Besides, they cannot handle\nvarious data quality issues (especially those caused by adversarial attacks)\nand have limited applications to only certain types of ML models. Recently,\ndata valuation approaches (e.g., based on the Shapley value) have been\nleveraged to perform DQM; yet, empirical studies have observed that their\nperformance varies considerably based on the underlying data and training\nprocess. In this paper, we propose a task-driven, multi-purpose, model-agnostic\nDQM framework, DataSifter, which is optimized towards a given downstream ML\ntask, capable of effectively removing data points with various defects, and\napplicable to diverse models. Specifically, we formulate DQM as an optimization\nproblem and devise a scalable algorithm to solve it. Furthermore, we propose a\ntheoretical framework for comparing the worst-case performance of different DQM\nstrategies. Remarkably, our results show that the popular strategy based on the\nShapley value may end up choosing the worst data subset in certain practical\nscenarios. Our evaluation shows that DataSifter achieves and most often\nsignificantly improves the state-of-the-art performance over a wide range of\nDQM tasks, including backdoor, poison, noisy/mislabel data detection, data\nsummarization, and data debiasing.",
          "link": "http://arxiv.org/abs/2106.05484",
          "publishedOn": "2021-06-11T01:42:16.989Z",
          "wordCount": 644,
          "title": "A Unified Framework for Task-Driven Data Quality Management. (arXiv:2106.05484v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05582",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ross_M/0/1/0/all/0/1\">Magnus Ross</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Smith_M/0/1/0/all/0/1\">Michael T. Smith</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Alvarez_M/0/1/0/all/0/1\">Mauricio A. &#xc1;lvarez</a>",
          "description": "This paper introduces a method for the nonparametric Bayesian learning of\nnonlinear operators, through the use of the Volterra series with kernels\nrepresented using Gaussian processes (GPs), which we term the nonparametric\nVolterra kernels model (NVKM). When the input function to the operator is\nunobserved and has a GP prior, the NVKM constitutes a powerful method for both\nsingle and multiple output regression, and can be viewed as a nonlinear and\nnonparametric latent force model. When the input function is observed, the NVKM\ncan be used to perform Bayesian system identification. We use recent advances\nin efficient sampling of explicit functions from GPs to map process\nrealisations through the Volterra series without resorting to numerical\nintegration, allowing scalability through doubly stochastic variational\ninference, and avoiding the need for Gaussian approximations of the output\nprocesses. We demonstrate the performance of the model for both multiple output\nregression and system identification using standard benchmarks.",
          "link": "http://arxiv.org/abs/2106.05582",
          "publishedOn": "2021-06-11T01:42:16.967Z",
          "wordCount": 583,
          "title": "Learning Nonparametric Volterra Kernels with Gaussian Processes. (arXiv:2106.05582v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05566",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Franceschi_J/0/1/0/all/0/1\">Jean-Yves Franceschi</a> (MLIA), <a href=\"http://arxiv.org/find/cs/1/au:+Bezenac_E/0/1/0/all/0/1\">Emmanuel de B&#xe9;zenac</a> (MLIA), <a href=\"http://arxiv.org/find/cs/1/au:+Ayed_I/0/1/0/all/0/1\">Ibrahim Ayed</a> (MLIA), <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Micka&#xeb;l Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lamprier_S/0/1/0/all/0/1\">Sylvain Lamprier</a> (MLIA), <a href=\"http://arxiv.org/find/cs/1/au:+Gallinari_P/0/1/0/all/0/1\">Patrick Gallinari</a> (MLIA)",
          "description": "Theoretical analyses for Generative Adversarial Networks (GANs) generally\nassume an arbitrarily large family of discriminators and do not consider the\ncharacteristics of the architectures used in practice. We show that this\nframework of analysis is too simplistic to properly analyze GAN training. To\ntackle this issue, we leverage the theory of infinite-width neural networks to\nmodel neural discriminator training for a wide range of adversarial losses via\nits Neural Tangent Kernel (NTK). Our analytical results show that GAN\ntrainability primarily depends on the discriminator's architecture. We further\nstudy the discriminator for specific architectures and losses, and highlight\nproperties providing a new understanding of GAN training. For example, we find\nthat GANs trained with the integral probability metric loss minimize the\nmaximum mean discrepancy with the NTK as kernel. Our conclusions demonstrate\nthe analysis opportunities provided by the proposed framework, which paves the\nway for better and more principled GAN models. We release a generic GAN\nanalysis toolkit based on our framework that supports the empirical part of our\nstudy.",
          "link": "http://arxiv.org/abs/2106.05566",
          "publishedOn": "2021-06-11T01:42:16.961Z",
          "wordCount": 615,
          "title": "A Neural Tangent Kernel Perspective of GANs. (arXiv:2106.05566v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05470",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_W/0/1/0/all/0/1\">Wei Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaorui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xiangyu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yao Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_N/0/1/0/all/0/1\">Neil Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jiliang Tang</a>",
          "description": "Graph self-supervised learning has gained increasing attention due to its\ncapacity to learn expressive node representations. Many pretext tasks, or loss\nfunctions have been designed from distinct perspectives. However, we observe\nthat different pretext tasks affect downstream tasks differently cross\ndatasets, which suggests that searching pretext tasks is crucial for graph\nself-supervised learning. Different from existing works focusing on designing\nsingle pretext tasks, this work aims to investigate how to automatically\nleverage multiple pretext tasks effectively. Nevertheless, evaluating\nrepresentations derived from multiple pretext tasks without direct access to\nground truth labels makes this problem challenging. To address this obstacle,\nwe make use of a key principle of many real-world graphs, i.e., homophily, or\nthe principle that ``like attracts like,'' as the guidance to effectively\nsearch various self-supervised pretext tasks. We provide theoretical\nunderstanding and empirical evidence to justify the flexibility of homophily in\nthis search task. Then we propose the AutoSSL framework which can automatically\nsearch over combinations of various self-supervised tasks. By evaluating the\nframework on 7 real-world datasets, our experimental results show that AutoSSL\ncan significantly boost the performance on downstream tasks including node\nclustering and node classification compared with training under individual\ntasks. Code will be released at https://github.com/ChandlerBang/AutoSSL.",
          "link": "http://arxiv.org/abs/2106.05470",
          "publishedOn": "2021-06-11T01:42:16.954Z",
          "wordCount": 630,
          "title": "Automated Self-Supervised Learning for Graphs. (arXiv:2106.05470v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05497",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zha_V/0/1/0/all/0/1\">Vincent Zha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiu_I/0/1/0/all/0/1\">Ivey Chiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guilbault_A/0/1/0/all/0/1\">Alexandre Guilbault</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tatis_J/0/1/0/all/0/1\">Jaime Tatis</a>",
          "description": "Slowly changing variables in a continuous state space constitute an important\ncategory of reinforcement learning and see its application in many domains,\nsuch as modeling a climate control system where temperature, humidity, etc.\nchange slowly over time. However, this subject is less addressed in recent\nstudies. Classical methods with certain variants, such as Dynamic Programming\nwith Tile Coding which discretizes the state space, fail to handle slowly\nchanging variables because those methods cannot capture the tiny changes in\neach transition step, as it is computationally expensive or impossible to\nestablish an extremely granular grid system. In this paper, we introduce a\nHyperspace Neighbor Penetration (HNP) approach that solves the problem. HNP\ncaptures in each transition step the state's partial \"penetration\" into its\nneighboring hyper-tiles in the gridded hyperspace, thus does not require the\ntransition to be inter-tile in order for the change to be captured. Therefore,\nHNP allows for a very coarse grid system, which makes the computation feasible.\nHNP assumes near linearity of the transition function in a local space, which\nis commonly satisfied. In summary, HNP can be orders of magnitude more\nefficient than classical method in handling slowly changing variables in\nreinforcement learning. We have made an industrial implementation of NHP with a\ngreat success.",
          "link": "http://arxiv.org/abs/2106.05497",
          "publishedOn": "2021-06-11T01:42:16.939Z",
          "wordCount": 661,
          "title": "Hyperspace Neighbor Penetration Approach to Dynamic Programming for Model-Based Reinforcement Learning Problems with Slowly Changing Variables in A Continuous State Space. (arXiv:2106.05497v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05741",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Drokin_I/0/1/0/all/0/1\">Ivan Drokin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ericheva_E/0/1/0/all/0/1\">Elena Ericheva</a>",
          "description": "This paper proposes novel end-to-end framework for detecting suspicious\npulmonary nodules in chest CT scans. The method core idea is a new nodule\nsegmentation architecture with a model-based feature projection block on\nthree-dimensional convolutions. This block acts as a preliminary feature\nextractor for a two-dimensional U-Net-like convolutional network. Using the\nproposed approach along with an axial, coronal, and sagittal projection\nanalysis makes it possible to abandon the widely used false positives reduction\nstep. The proposed method achieves SOTA on LUNA2016 with 0.959 average\nsensitivity, and 0.936 sensitivity if the false-positive level per scan is\n0.25. The paper describes the proposed approach and represents the experimental\nresults on LUNA2016 as well as ablation studies.",
          "link": "http://arxiv.org/abs/2106.05741",
          "publishedOn": "2021-06-11T01:42:16.904Z",
          "wordCount": 557,
          "title": "End-to-end lung nodule detection framework with model-based feature projection block. (arXiv:2106.05741v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05455",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_L/0/1/0/all/0/1\">Liang Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1\">Zijun Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yanqiao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jian Li</a>",
          "description": "We introduce a framework for learning from multiple generated graph views,\nnamed graph symbiosis learning (GraphSym). In GraphSym, graph neural networks\n(GNN) developed in multiple generated graph views can adaptively exchange\nparameters with each other and fuse information stored in linkage structures\nand node features. Specifically, we propose a novel adaptive exchange method to\niteratively substitute redundant channels in the weight matrix of one GNN with\ninformative channels of another GNN in a layer-by-layer manner. GraphSym does\nnot rely on specific methods to generate multiple graph views and GNN\narchitectures. Thus, existing GNNs can be seamlessly integrated into our\nframework. On 3 semi-supervised node classification datasets, GraphSym\noutperforms previous single-graph and multiple-graph GNNs without knowledge\ndistillation, and achieves new state-of-the-art results. We also conduct a\nseries of experiments on 15 public benchmarks, 8 popular GNN models, and 3\ngraph tasks -- node classification, graph classification, and edge prediction\n-- and show that GraphSym consistently achieves better performance than\nexisting popular GNNs by 1.9\\%$\\sim$3.9\\% on average and their ensembles.\nExtensive ablation studies and experiments on the few-shot setting also\ndemonstrate the effectiveness of GraphSym.",
          "link": "http://arxiv.org/abs/2106.05455",
          "publishedOn": "2021-06-11T01:42:16.896Z",
          "wordCount": 603,
          "title": "Graph Symbiosis Learning. (arXiv:2106.05455v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.06645",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Frohlich_C/0/1/0/all/0/1\">Christian Fr&#xf6;hlich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gessner_A/0/1/0/all/0/1\">Alexandra Gessner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hennig_P/0/1/0/all/0/1\">Philipp Hennig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1\">Bernhard Sch&#xf6;lkopf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arvanitidis_G/0/1/0/all/0/1\">Georgios Arvanitidis</a>",
          "description": "Riemannian manifolds provide a principled way to model nonlinear geometric\nstructure inherent in data. A Riemannian metric on said manifolds determines\ngeometry-aware shortest paths and provides the means to define statistical\nmodels accordingly. However, these operations are typically computationally\ndemanding. To ease this computational burden, we advocate probabilistic\nnumerical methods for Riemannian statistics. In particular, we focus on\nBayesian quadrature (BQ) to numerically compute integrals over normal laws on\nRiemannian manifolds learned from data. In this task, each function evaluation\nrelies on the solution of an expensive initial value problem. We show that by\nleveraging both prior knowledge and an active exploration scheme, BQ\nsignificantly reduces the number of required evaluations and thus outperforms\nMonte Carlo methods on a wide range of integration problems. As a concrete\napplication, we highlight the merits of adopting Riemannian geometry with our\nproposed framework on a nonlinear dataset from molecular dynamics.",
          "link": "http://arxiv.org/abs/2102.06645",
          "publishedOn": "2021-06-11T01:42:16.890Z",
          "wordCount": 603,
          "title": "Bayesian Quadrature on Riemannian Data Manifolds. (arXiv:2102.06645v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05569",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1\">Swaroop Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arunkumar_A/0/1/0/all/0/1\">Anjana Arunkumar</a>",
          "description": "Deep Learning's outstanding track record across several domains has stemmed\nfrom the use of error backpropagation (BP). Several studies, however, have\nshown that it is impossible to execute BP in a real brain. Also, BP still\nserves as an important and unsolved bottleneck for memory usage and speed. We\npropose a simple, novel algorithm, the Front-Contribution algorithm, as a\ncompact alternative to BP. The contributions of all weights with respect to the\nfinal layer weights are calculated before training commences and all the\ncontributions are appended to weights of the final layer, i.e., the effective\nfinal layer weights are a non-linear function of themselves. Our algorithm then\nessentially collapses the network, precluding the necessity for weight updation\nof all weights not in the final layer. This reduction in parameters results in\nlower memory usage and higher training speed. We show that our algorithm\nproduces the exact same output as BP, in contrast to several recently proposed\nalgorithms approximating BP. Our preliminary experiments demonstrate the\nefficacy of the proposed algorithm. Our work provides a foundation to\neffectively utilize these presently under-explored \"front contributions\", and\nserves to inspire the next generation of training algorithms.",
          "link": "http://arxiv.org/abs/2106.05569",
          "publishedOn": "2021-06-11T01:42:16.878Z",
          "wordCount": 621,
          "title": "Front Contribution instead of Back Propagation. (arXiv:2106.05569v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05506",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Druce_J/0/1/0/all/0/1\">Jeff Druce</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niehaus_J/0/1/0/all/0/1\">James Niehaus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moody_V/0/1/0/all/0/1\">Vanessa Moody</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jensen_D/0/1/0/all/0/1\">David Jensen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Littman_M/0/1/0/all/0/1\">Michael L. Littman</a>",
          "description": "The advances in artificial intelligence enabled by deep learning\narchitectures are undeniable. In several cases, deep neural network driven\nmodels have surpassed human level performance in benchmark autonomy tasks. The\nunderlying policies for these agents, however, are not easily interpretable. In\nfact, given their underlying deep models, it is impossible to directly\nunderstand the mapping from observations to actions for any reasonably complex\nagent. Producing this supporting technology to \"open the black box\" of these AI\nsystems, while not sacrificing performance, was the fundamental goal of the\nDARPA XAI program. In our journey through this program, we have several \"big\npicture\" takeaways: 1) Explanations need to be highly tailored to their\nscenario; 2) many seemingly high performing RL agents are extremely brittle and\nare not amendable to explanation; 3) causal models allow for rich explanations,\nbut how to present them isn't always straightforward; and 4) human subjects\nconjure fantastically wrong mental models for AIs, and these models are often\nhard to break. This paper discusses the origins of these takeaways, provides\namplifying information, and suggestions for future work.",
          "link": "http://arxiv.org/abs/2106.05506",
          "publishedOn": "2021-06-11T01:42:16.869Z",
          "wordCount": 622,
          "title": "Brittle AI, Causal Confusion, and Bad Mental Models: Challenges and Successes in the XAI Program. (arXiv:2106.05506v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05508",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jiankai Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yuanshun Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1\">Aonan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1\">Weihao Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1\">Junyuan Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chong Wang</a>",
          "description": "Vertical Federated Learning (vFL) allows multiple parties that own different\nattributes (e.g. features and labels) of the same data entity (e.g. a person)\nto jointly train a model. To prepare the training data, vFL needs to identify\nthe common data entities shared by all parties. It is usually achieved by\nPrivate Set Intersection (PSI) which identifies the intersection of training\nsamples from all parties by using personal identifiable information (e.g.\nemail) as sample IDs to align data instances. As a result, PSI would make\nsample IDs of the intersection visible to all parties, and therefore each party\ncan know that the data entities shown in the intersection also appear in the\nother parties, i.e. intersection membership. However, in many real-world\nprivacy-sensitive organizations, e.g. banks and hospitals, revealing membership\nof their data entities is prohibited. In this paper, we propose a vFL framework\nbased on Private Set Union (PSU) that allows each party to keep sensitive\nmembership information to itself. Instead of identifying the intersection of\nall training samples, our PSU protocol generates the union of samples as\ntraining instances. In addition, we propose strategies to generate synthetic\nfeatures and labels to handle samples that belong to the union but not the\nintersection. Through extensive experiments on two real-world datasets, we show\nour framework can protect the privacy of the intersection membership while\nmaintaining the model utility.",
          "link": "http://arxiv.org/abs/2106.05508",
          "publishedOn": "2021-06-11T01:42:16.852Z",
          "wordCount": 658,
          "title": "Vertical Federated Learning without Revealing Intersection Membership. (arXiv:2106.05508v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05492",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_E/0/1/0/all/0/1\">Eric Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trott_A/0/1/0/all/0/1\">Alexander R. Trott</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1\">Caiming Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1\">Stephan Zheng</a>",
          "description": "Multi-agent simulations provide a scalable environment for learning policies\nthat interact with rational agents. However, such policies may fail to\ngeneralize to the real-world where agents may differ from simulated\ncounterparts due to unmodeled irrationality and misspecified reward functions.\nWe introduce Epsilon-Robust Multi-Agent Simulation (ERMAS), a robust\noptimization framework for learning AI policies that are robust to such\nmultiagent sim-to-real gaps. While existing notions of multi-agent robustness\nconcern perturbations in the actions of agents, we address a novel robustness\nobjective concerning perturbations in the reward functions of agents. ERMAS\nprovides this robustness by anticipating suboptimal behaviors from other\nagents, formalized as the worst-case epsilon-equilibrium. We show empirically\nthat ERMAS yields robust policies for repeated bimatrix games and optimal\ntaxation problems in economic simulations. In particular, in the two-level RL\nproblem posed by the AI Economist (Zheng et al., 2020) ERMAS learns tax\npolicies that are robust to changes in agent risk aversion, improving social\nwelfare by up to 15% in complex spatiotemporal simulations.",
          "link": "http://arxiv.org/abs/2106.05492",
          "publishedOn": "2021-06-11T01:42:16.840Z",
          "wordCount": 593,
          "title": "ERMAS: Becoming Robust to Reward Function Sim-to-Real Gaps in Multi-Agent Simulations. (arXiv:2106.05492v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05384",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Sifan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perdikaris_P/0/1/0/all/0/1\">Paris Perdikaris</a>",
          "description": "Ordinary and partial differential equations (ODEs/PDEs) play a paramount role\nin analyzing and simulating complex dynamic processes across all corners of\nscience and engineering. In recent years machine learning tools are aspiring to\nintroduce new effective ways of simulating PDEs, however existing approaches\nare not able to reliably return stable and accurate predictions across long\ntemporal horizons. We aim to address this challenge by introducing an effective\nframework for learning infinite-dimensional operators that map random initial\nconditions to associated PDE solutions within a short time interval. Such\nlatent operators can be parametrized by deep neural networks that are trained\nin an entirely self-supervised manner without requiring any paired input-output\nobservations. Global long-time predictions across a range of initial conditions\ncan be then obtained by iteratively evaluating the trained model using each\nprediction as the initial condition for the next evaluation step. This\nintroduces a new approach to temporal domain decomposition that is shown to be\neffective in performing accurate long-time simulations for a wide range of\nparametric ODE and PDE systems, from wave propagation, to reaction-diffusion\ndynamics and stiff chemical kinetics, all at a fraction of the computational\ncost needed by classical numerical solvers.",
          "link": "http://arxiv.org/abs/2106.05384",
          "publishedOn": "2021-06-11T01:42:16.826Z",
          "wordCount": 625,
          "title": "Long-time integration of parametric evolution equations with physics-informed DeepONets. (arXiv:2106.05384v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05659",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vlontzos_A/0/1/0/all/0/1\">Athanasios Vlontzos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sutherland_G/0/1/0/all/0/1\">Gabriel Sutherland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganju_S/0/1/0/all/0/1\">Siddha Ganju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soboczenski_F/0/1/0/all/0/1\">Frank Soboczenski</a>",
          "description": "Future short or long-term space missions require a new generation of\nmonitoring and diagnostic systems due to communication impasses as well as\nlimitations in specialized crew and equipment. Machine learning supported\ndiagnostic systems present a viable solution for medical and technical\napplications. We discuss challenges and applicability of such systems in light\nof upcoming missions and outline an example use case for a next-generation\nmedical diagnostic system for future space operations. Additionally, we present\napproach recommendations and constraints for the successful generation and use\nof machine learning models aboard a spacecraft.",
          "link": "http://arxiv.org/abs/2106.05659",
          "publishedOn": "2021-06-11T01:42:16.811Z",
          "wordCount": 530,
          "title": "Next-Gen Machine Learning Supported Diagnostic Systems for Spacecraft. (arXiv:2106.05659v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05535",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vien_N/0/1/0/all/0/1\">Ngo Anh Vien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neumann_G/0/1/0/all/0/1\">Gerhard Neumann</a>",
          "description": "This paper proposes a differentiable robust LQR layer for reinforcement\nlearning and imitation learning under model uncertainty and stochastic\ndynamics. The robust LQR layer can exploit the advantages of robust optimal\ncontrol and model-free learning. It provides a new type of inductive bias for\nstochasticity and uncertainty modeling in control systems. In particular, we\npropose an efficient way to differentiate through a robust LQR optimization\nprogram by rewriting it as a convex program (i.e. semi-definite program) of the\nworst-case cost. Based on recent work on using convex optimization inside\nneural network layers, we develop a fully differentiable layer for optimizing\nthis worst-case cost, i.e. we compute the derivative of a performance measure\nw.r.t the model's unknown parameters, model uncertainty and stochasticity\nparameters. We demonstrate the proposed method on imitation learning and\napproximate dynamic programming on stochastic and uncertain domains. The\nexperiment results show that the proposed method can optimize robust policies\nunder uncertain situations, and are able to achieve a significantly better\nperformance than existing methods that do not model uncertainty directly.",
          "link": "http://arxiv.org/abs/2106.05535",
          "publishedOn": "2021-06-11T01:42:16.805Z",
          "wordCount": 589,
          "title": "Differentiable Robust LQR Layers. (arXiv:2106.05535v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05423",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chakrabarti_D/0/1/0/all/0/1\">Darshan Chakrabarti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dickerson_J/0/1/0/all/0/1\">John P. Dickerson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Esmaeili_S/0/1/0/all/0/1\">Seyed A. Esmaeili</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivasan_A/0/1/0/all/0/1\">Aravind Srinivasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsepenekas_L/0/1/0/all/0/1\">Leonidas Tsepenekas</a>",
          "description": "Clustering is a fundamental problem in unsupervised machine learning, and\nfair variants of it have recently received significant attention. In this work\nwe introduce a novel definition of fairness for clustering problems.\nSpecifically, in our model each point $j$ has a set of other points\n$\\mathcal{S}_j$ that it perceives as similar to itself, and it feels that it is\nfairly treated, if the quality of service it receives in the solution is\n$\\alpha$-close to that of the points in $\\mathcal{S}_j$. We begin our study by\nanswering questions regarding the structure of the problem, namely for what\nvalues of $\\alpha$ the problem is well-defined, and what the behavior of the\nPrice of Fairness (PoF) for it is. For the well-defined region of $\\alpha$, we\nprovide efficient and easily implementable approximation algorithms for the\n$k$-center objective, which in certain cases also enjoy bounded PoF guarantees.\nWe finally complement our analysis by an extensive suite of experiments that\nvalidates the effectiveness of our theoretical results.",
          "link": "http://arxiv.org/abs/2106.05423",
          "publishedOn": "2021-06-11T01:42:16.799Z",
          "wordCount": 598,
          "title": "A New Notion of Individually Fair Clustering: $\\alpha$-Equitable $k$-Center. (arXiv:2106.05423v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05449",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Daley_B/0/1/0/all/0/1\">Brett Daley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amato_C/0/1/0/all/0/1\">Christopher Amato</a>",
          "description": "Adam is an adaptive gradient method that has experienced widespread adoption\ndue to its fast and reliable training performance. Recent approaches have not\noffered significant improvement over Adam, often because they do not innovate\nupon one of its core features: normalization by the root mean square (RMS) of\nrecent gradients. However, as noted by Kingma and Ba (2015), any number of\n$L^p$ normalizations are possible, with the RMS corresponding to the specific\ncase of $p=2$. In our work, we theoretically and empirically characterize the\ninfluence of different $L^p$ norms on adaptive gradient methods for the first\ntime. We show mathematically how the choice of $p$ influences the size of the\nsteps taken, while leaving other desirable properties unaffected. We evaluate\nAdam with various $L^p$ norms on a suite of deep learning benchmarks, and find\nthat $p > 2$ consistently leads to improved learning speed and final\nperformance. The choices of $p=3$ or $p=6$ also match or outperform\nstate-of-the-art methods in all of our experiments.",
          "link": "http://arxiv.org/abs/2106.05449",
          "publishedOn": "2021-06-11T01:42:16.793Z",
          "wordCount": 636,
          "title": "Investigating Alternatives to the Root Mean Square for Adaptive Gradient Methods. (arXiv:2106.05449v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05445",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Jin_Q/0/1/0/all/0/1\">Qiujiang Jin</a>, <a href=\"http://arxiv.org/find/math/1/au:+Mokhtari_A/0/1/0/all/0/1\">Aryan Mokhtari</a>",
          "description": "In this paper, we study the application of quasi-Newton methods for solving\nempirical risk minimization (ERM) problems defined over a large dataset.\nTraditional deterministic and stochastic quasi-Newton methods can be executed\nto solve such problems; however, it is known that their global convergence rate\nmay not be better than first-order methods, and their local superlinear\nconvergence only appears towards the end of the learning process. In this\npaper, we use an adaptive sample size scheme that exploits the superlinear\nconvergence of quasi-Newton methods globally and throughout the entire learning\nprocess. The main idea of the proposed adaptive sample size algorithms is to\nstart with a small subset of data points and solve their corresponding ERM\nproblem within its statistical accuracy, and then enlarge the sample size\ngeometrically and use the optimal solution of the problem corresponding to the\nsmaller set as an initial point for solving the subsequent ERM problem with\nmore samples. We show that if the initial sample size is sufficiently large and\nwe use quasi-Newton methods to solve each subproblem, the subproblems can be\nsolved superlinearly fast (after at most three iterations), as we guarantee\nthat the iterates always stay within a neighborhood that quasi-Newton methods\nconverge superlinearly. Numerical experiments on various datasets confirm our\ntheoretical results and demonstrate the computational advantages of our method.",
          "link": "http://arxiv.org/abs/2106.05445",
          "publishedOn": "2021-06-11T01:42:16.785Z",
          "wordCount": 650,
          "title": "Exploiting Local Convergence of Quasi-Newton Methods Globally: Adaptive Sample Size Approach. (arXiv:2106.05445v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05468",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mugunthan_V/0/1/0/all/0/1\">Vaikkunth Mugunthan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_P/0/1/0/all/0/1\">Pawan Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kagal_L/0/1/0/all/0/1\">Lalana Kagal</a>",
          "description": "Vertical Federated Learning (VFL) refers to the collaborative training of a\nmodel on a dataset where the features of the dataset are split among multiple\ndata owners, while label information is owned by a single data owner. In this\npaper, we propose a novel method, Multi Vertical Federated Learning\n(Multi-VFL), to train VFL models when there are multiple data and label owners.\nOur approach is the first to consider the setting where $D$-data owners (across\nwhich features are distributed) and $K$-label owners (across which labels are\ndistributed) exist. This proposed configuration allows different entities to\ntrain and learn optimal models without having to share their data. Our\nframework makes use of split learning and adaptive federated optimizers to\nsolve this problem. For empirical evaluation, we run experiments on the MNIST\nand FashionMNIST datasets. Our results show that using adaptive optimizers for\nmodel aggregation fastens convergence and improves accuracy.",
          "link": "http://arxiv.org/abs/2106.05468",
          "publishedOn": "2021-06-11T01:42:16.770Z",
          "wordCount": 577,
          "title": "Multi-VFL: A Vertical Federated Learning System for Multiple Data and Label Owners. (arXiv:2106.05468v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05528",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zuxuan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weng_Z/0/1/0/all/0/1\">Zejia Weng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jingjing Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_G/0/1/0/all/0/1\">Guo-Jun Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yu-Gang Jiang</a>",
          "description": "Unsupervised domain adaptation (UDA) aims to transfer knowledge learned from\na fully-labeled source domain to a different unlabeled target domain. Most\nexisting UDA methods learn domain-invariant feature representations by\nminimizing feature distances across domains. In this work, we build upon\ncontrastive self-supervised learning to align features so as to reduce the\ndomain discrepancy between training and testing sets. Exploring the same set of\ncategories shared by both domains, we introduce a simple yet effective\nframework CDCL, for domain alignment. In particular, given an anchor image from\none domain, we minimize its distances to cross-domain samples from the same\nclass relative to those from different categories. Since target labels are\nunavailable, we use a clustering-based approach with carefully initialized\ncenters to produce pseudo labels. In addition, we demonstrate that CDCL is a\ngeneral framework and can be adapted to the data-free setting, where the source\ndata are unavailable during training, with minimal modification. We conduct\nexperiments on two widely used domain adaptation benchmarks, i.e., Office-31\nand VisDA-2017, and demonstrate that CDCL achieves state-of-the-art performance\non both datasets.",
          "link": "http://arxiv.org/abs/2106.05528",
          "publishedOn": "2021-06-11T01:42:16.743Z",
          "wordCount": 615,
          "title": "Cross-domain Contrastive Learning for Unsupervised Domain Adaptation. (arXiv:2106.05528v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.12245",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cohen_A/0/1/0/all/0/1\">Alain-Sam Cohen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cont_R/0/1/0/all/0/1\">Rama Cont</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rossier_A/0/1/0/all/0/1\">Alain Rossier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">Renyuan Xu</a>",
          "description": "Residual networks (ResNets) have displayed impressive results in pattern\nrecognition and, recently, have garnered considerable theoretical interest due\nto a perceived link with neural ordinary differential equations (neural ODEs).\nThis link relies on the convergence of network weights to a smooth function as\nthe number of layers increases. We investigate the properties of weights\ntrained by stochastic gradient descent and their scaling with network depth\nthrough detailed numerical experiments. We observe the existence of scaling\nregimes markedly different from those assumed in neural ODE literature.\nDepending on certain features of the network architecture, such as the\nsmoothness of the activation function, one may obtain an alternative ODE limit,\na stochastic differential equation or neither of these. These findings cast\ndoubts on the validity of the neural ODE model as an adequate asymptotic\ndescription of deep ResNets and point to an alternative class of differential\nequations as a better description of the deep network limit.",
          "link": "http://arxiv.org/abs/2105.12245",
          "publishedOn": "2021-06-11T01:42:16.722Z",
          "wordCount": 623,
          "title": "Scaling Properties of Deep Residual Networks. (arXiv:2105.12245v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.10513",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mehdiyev_N/0/1/0/all/0/1\">Nijat Mehdiyev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fettke_P/0/1/0/all/0/1\">Peter Fettke</a>",
          "description": "This study proposes an innovative explainable predictive quality analytics\nsolution to facilitate data-driven decision-making for process planning in\nmanufacturing by combining process mining, machine learning, and explainable\nartificial intelligence (XAI) methods. For this purpose, after integrating the\ntop-floor and shop-floor data obtained from various enterprise information\nsystems, a deep learning model was applied to predict the process outcomes.\nSince this study aims to operationalize the delivered predictive insights by\nembedding them into decision-making processes, it is essential to generate\nrelevant explanations for domain experts. To this end, two complementary local\npost-hoc explanation approaches, Shapley values and Individual Conditional\nExpectation (ICE) plots are adopted, which are expected to enhance the\ndecision-making capabilities by enabling experts to examine explanations from\ndifferent perspectives. After assessing the predictive strength of the applied\ndeep neural network with relevant binary classification evaluation measures, a\ndiscussion of the generated explanations is provided.",
          "link": "http://arxiv.org/abs/2009.10513",
          "publishedOn": "2021-06-11T01:42:16.716Z",
          "wordCount": 632,
          "title": "Local Post-Hoc Explanations for Predictive Process Monitoring in Manufacturing. (arXiv:2009.10513v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05397",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Stankewitz_B/0/1/0/all/0/1\">Bernhard Stankewitz</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mucke_N/0/1/0/all/0/1\">Nicole M&#xfc;cke</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rosasco_L/0/1/0/all/0/1\">Lorenzo Rosasco</a>",
          "description": "Optimization was recently shown to control the inductive bias in a learning\nprocess, a property referred to as implicit, or iterative regularization. The\nestimator obtained iteratively minimizing the training error can generalise\nwell with no need of further penalties or constraints. In this paper, we\ninvestigate this phenomenon in the context of linear models with smooth loss\nfunctions. In particular, we investigate and propose a proof technique\ncombining ideas from inexact optimization and probability theory, specifically\ngradient concentration. The proof is easy to follow and allows to obtain sharp\nlearning bounds. More generally, it highlights a way to develop optimization\nresults into learning guarantees.",
          "link": "http://arxiv.org/abs/2106.05397",
          "publishedOn": "2021-06-11T01:42:16.701Z",
          "wordCount": 536,
          "title": "From inexact optimization to learning via gradient concentration. (arXiv:2106.05397v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2101.08734",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dryden_N/0/1/0/all/0/1\">Nikoli Dryden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bohringer_R/0/1/0/all/0/1\">Roman B&#xf6;hringer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ben_Nun_T/0/1/0/all/0/1\">Tal Ben-Nun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoefler_T/0/1/0/all/0/1\">Torsten Hoefler</a>",
          "description": "I/O is emerging as a major bottleneck for machine learning training,\nespecially in distributed environments. Indeed, at large scale, I/O takes as\nmuch as 85% of training time. Addressing this I/O bottleneck necessitates\ncareful optimization, as optimal data ingestion pipelines differ between\nsystems, and require a delicate balance between access to local storage,\nexternal filesystems, and remote nodes. We introduce NoPFS, a machine learning\nI/O middleware, which provides a scalable, flexible, and easy-to-use solution\nto the I/O bottleneck. NoPFS uses clairvoyance: Given the seed generating the\nrandom access pattern for training with SGD, it can exactly predict when and\nwhere a sample will be accessed. We combine this with an analysis of access\npatterns and a performance model to provide distributed caching policies that\nadapt to different datasets and storage hierarchies. NoPFS reduces I/O times\nand improves end-to-end training by up to 5.4x on the ImageNet-1k,\nImageNet-22k, and CosmoFlow datasets.",
          "link": "http://arxiv.org/abs/2101.08734",
          "publishedOn": "2021-06-11T01:42:16.687Z",
          "wordCount": 617,
          "title": "Clairvoyant Prefetching for Distributed Machine Learning I/O. (arXiv:2101.08734v2 [cs.DC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05797",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Glasserman_P/0/1/0/all/0/1\">Paul Glasserman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_M/0/1/0/all/0/1\">Mike Li</a>",
          "description": "We study the behavior of linear discriminant functions for binary\nclassification in the infinite-imbalance limit, where the sample size of one\nclass grows without bound while the sample size of the other remains fixed. The\ncoefficients of the classifier minimize an expected loss specified through a\nweight function. We show that for a broad class of weight functions, the\nintercept diverges but the rest of the coefficient vector has a finite limit\nunder infinite imbalance, extending prior work on logistic regression. The\nlimit depends on the left tail of the weight function, for which we distinguish\nthree cases: bounded, asymptotically polynomial, and asymptotically\nexponential. The limiting coefficient vectors reflect robustness or\nconservatism properties in the sense that they optimize against certain\nworst-case alternatives. In the bounded and polynomial cases, the limit is\nequivalent to an implicit choice of upsampling distribution for the minority\nclass. We apply these ideas in a credit risk setting, with particular emphasis\non performance in the high-sensitivity and high-specificity regions.",
          "link": "http://arxiv.org/abs/2106.05797",
          "publishedOn": "2021-06-11T01:42:16.623Z",
          "wordCount": 589,
          "title": "Linear Classifiers Under Infinite Imbalance. (arXiv:2106.05797v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05964",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Celis_L/0/1/0/all/0/1\">L. Elisa Celis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehrotra_A/0/1/0/all/0/1\">Anay Mehrotra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vishnoi_N/0/1/0/all/0/1\">Nisheeth K. Vishnoi</a>",
          "description": "We study fair classification in the presence of an omniscient adversary that,\ngiven an $\\eta$, is allowed to choose an arbitrary $\\eta$-fraction of the\ntraining samples and arbitrarily perturb their protected attributes. The\nmotivation comes from settings in which protected attributes can be incorrect\ndue to strategic misreporting, malicious actors, or errors in imputation; and\nprior approaches that make stochastic or independence assumptions on errors may\nnot satisfy their guarantees in this adversarial setting. Our main contribution\nis an optimization framework to learn fair classifiers in this adversarial\nsetting that comes with provable guarantees on accuracy and fairness. Our\nframework works with multiple and non-binary protected attributes, is designed\nfor the large class of linear-fractional fairness metrics, and can also handle\nperturbations besides protected attributes. We prove near-tightness of our\nframework's guarantees for natural hypothesis classes: no algorithm can have\nsignificantly better accuracy and any algorithm with better fairness must have\nlower accuracy. Empirically, we evaluate the classifiers produced by our\nframework for statistical rate on real-world and synthetic datasets for a\nfamily of adversaries.",
          "link": "http://arxiv.org/abs/2106.05964",
          "publishedOn": "2021-06-11T01:42:16.618Z",
          "wordCount": 613,
          "title": "Fair Classification with Adversarial Perturbations. (arXiv:2106.05964v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05960",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+McDonald_T/0/1/0/all/0/1\">Thomas M. McDonald</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Alvarez_M/0/1/0/all/0/1\">Mauricio A. &#xc1;lvarez</a>",
          "description": "Effectively modeling phenomena present in highly nonlinear dynamical systems\nwhilst also accurately quantifying uncertainty is a challenging task, which\noften requires problem-specific techniques. We present a novel, domain-agnostic\napproach to tackling this problem, using compositions of physics-informed\nrandom features, derived from ordinary differential equations. The architecture\nof our model leverages recent advances in approximate inference for deep\nGaussian processes, such as layer-wise weight-space approximations which allow\nus to incorporate random Fourier features, and stochastic variational inference\nfor approximate Bayesian inference. We provide evidence that our model is\ncapable of capturing highly nonlinear behaviour in real-world multivariate time\nseries data. In addition, we find that our approach achieves comparable\nperformance to a number of other probabilistic models on benchmark regression\ntasks.",
          "link": "http://arxiv.org/abs/2106.05960",
          "publishedOn": "2021-06-11T01:42:16.613Z",
          "wordCount": 556,
          "title": "Compositional Modeling of Nonlinear Dynamical Systems with ODE-based Random Features. (arXiv:2106.05960v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05951",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Gandikota_V/0/1/0/all/0/1\">Venkata Gandikota</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mazumdar_A/0/1/0/all/0/1\">Arya Mazumdar</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pal_S/0/1/0/all/0/1\">Soumyabrata Pal</a>",
          "description": "Recovery of support of a sparse vector from simple measurements is a widely\nstudied problem, considered under the frameworks of compressed sensing, 1-bit\ncompressed sensing, and more general single index models. We consider\ngeneralizations of this problem: mixtures of linear regressions, and mixtures\nof linear classifiers, where the goal is to recover supports of multiple sparse\nvectors using only a small number of possibly noisy linear, and 1-bit\nmeasurements respectively. The key challenge is that the measurements from\ndifferent vectors are randomly mixed. Both of these problems were also\nextensively studied recently. In mixtures of linear classifiers, the\nobservations correspond to the side of queried hyperplane a random unknown\nvector lies in, whereas in mixtures of linear regressions we observe the\nprojection of a random unknown vector on the queried hyperplane. The primary\nstep in recovering the unknown vectors from the mixture is to first identify\nthe support of all the individual component vectors. In this work, we study the\nnumber of measurements sufficient for recovering the supports of all the\ncomponent vectors in a mixture in both these models. We provide algorithms that\nuse a number of measurements polynomial in $k, \\log n$ and quasi-polynomial in\n$\\ell$, to recover the support of all the $\\ell$ unknown vectors in the mixture\nwith high probability when each individual component is a $k$-sparse\n$n$-dimensional vector.",
          "link": "http://arxiv.org/abs/2106.05951",
          "publishedOn": "2021-06-11T01:42:16.597Z",
          "wordCount": 665,
          "title": "Support Recovery of Sparse Signals from a Mixture of Linear Measurements. (arXiv:2106.05951v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05891",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mao_J/0/1/0/all/0/1\">Jiayuan Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1\">Zhezheng Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_C/0/1/0/all/0/1\">Chuang Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1\">Joshua B. Tenenbaum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jiajun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaelbling_L/0/1/0/all/0/1\">Leslie Pack Kaelbling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ullman_T/0/1/0/all/0/1\">Tomer D. Ullman</a>",
          "description": "We present Temporal and Object Quantification Networks (TOQ-Nets), a new\nclass of neuro-symbolic networks with a structural bias that enables them to\nlearn to recognize complex relational-temporal events. This is done by\nincluding reasoning layers that implement finite-domain quantification over\nobjects and time. The structure allows them to generalize directly to input\ninstances with varying numbers of objects in temporal sequences of varying\nlengths. We evaluate TOQ-Nets on input domains that require recognizing\nevent-types in terms of complex temporal relational patterns. We demonstrate\nthat TOQ-Nets can generalize from small amounts of data to scenarios containing\nmore objects than were present during training and to temporal warpings of\ninput sequences.",
          "link": "http://arxiv.org/abs/2106.05891",
          "publishedOn": "2021-06-11T01:42:16.592Z",
          "wordCount": 558,
          "title": "Temporal and Object Quantification Networks. (arXiv:2106.05891v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05841",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_X/0/1/0/all/0/1\">Xiongshi Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Min Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Shaobo Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lei Wang</a>",
          "description": "Microarray gene expression data are often accompanied by a large number of\ngenes and a small number of samples. However, only a few of these genes are\nrelevant to cancer, resulting in signigicant gene selection challenges. Hence,\nwe propose a two-stage gene selection approach by combining extreme gradient\nboosting (XGBoost) and a multi-objective optimization genetic algorithm\n(XGBoost-MOGA) for cancer classification in microarray datasets. In the first\nstage, the genes are ranked use an ensemble-based feature selection using\nXGBoost. This stage can effectively remove irrelevant genes and yield a group\ncomprising the most relevant genes related to the class. In the second stage,\nXGBoost-MOGA searches for an optimal gene subset based on the most relevant\ngenes's group using a multi-objective optimization genetic algorithm. We\nperformed comprehensive experiments to compare XGBoost-MOGA with other\nstate-of-the-art feature selection methods using two well-known learning\nclassifiers on 13 publicly available microarray expression datasets. The\nexperimental results show that XGBoost-MOGA yields significantly better results\nthan previous state-of-the-art algorithms in terms of various evaluation\ncriteria, such as accuracy, F-score, precision, and recall.",
          "link": "http://arxiv.org/abs/2106.05841",
          "publishedOn": "2021-06-11T01:42:16.585Z",
          "wordCount": 607,
          "title": "Hybrid gene selection approach using XGBoost and multi-objective genetic algorithm for cancer classification. (arXiv:2106.05841v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05840",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Adnan_M/0/1/0/all/0/1\">Mian Arif Shams Adnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahmud_H/0/1/0/all/0/1\">H. M. Miraz Mahmud</a>",
          "description": "Unlike previous studies on mixture distributions, a bagging and boosting\nbased convexly combined mixture probabilistic model has been suggested. This\nmodel is a result of iteratively searching for obtaining the optimum\nprobabilistic model that provides the maximum p value.",
          "link": "http://arxiv.org/abs/2106.05840",
          "publishedOn": "2021-06-11T01:42:16.565Z",
          "wordCount": 474,
          "title": "A Bagging and Boosting Based Convexly Combined Optimum Mixture Probabilistic Model. (arXiv:2106.05840v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05825",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Samavatian_M/0/1/0/all/0/1\">Mohammad Hossein Samavatian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Majumdar_S/0/1/0/all/0/1\">Saikat Majumdar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barber_K/0/1/0/all/0/1\">Kristin Barber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teodorescu_R/0/1/0/all/0/1\">Radu Teodorescu</a>",
          "description": "DNNs are known to be vulnerable to so-called adversarial attacks, in which\ninputs are carefully manipulated to induce misclassification. Existing defenses\nare mostly software-based and come with high overheads or other limitations.\nThis paper presents HASI, a hardware-accelerated defense that uses a process we\ncall stochastic inference to detect adversarial inputs. HASI carefully injects\nnoise into the model at inference time and used the model's response to\ndifferentiate adversarial inputs from benign ones. We show an adversarial\ndetection rate of average 87% which exceeds the detection rate of the\nstate-of-the-art approaches, with a much lower overhead. We demonstrate a\nsoftware/hardware-accelerated co-design, which reduces the performance impact\nof stochastic inference to 1.58X-2X relative to the unprotected baseline,\ncompared to 14X-20X overhead for a software-only GPU implementation.",
          "link": "http://arxiv.org/abs/2106.05825",
          "publishedOn": "2021-06-11T01:42:16.525Z",
          "wordCount": 565,
          "title": "HASI: Hardware-Accelerated Stochastic Inference, A Defense Against Adversarial Machine Learning Attacks. (arXiv:2106.05825v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05872",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Servia_Rodriguez_S/0/1/0/all/0/1\">Sandra Servia-Rodriguez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mascolo_C/0/1/0/all/0/1\">Cecilia Mascolo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwon_Y/0/1/0/all/0/1\">Young D. Kwon</a>",
          "description": "Despite much research targeted at enabling conventional machine learning\nmodels to continually learn tasks and data distributions sequentially without\nforgetting the knowledge acquired, little effort has been devoted to account\nfor more realistic situations where learning some tasks accurately might be\nmore critical than forgetting previous ones. In this paper we propose a\nBayesian inference based framework to continually learn a set of real-world,\nsensing-based analysis tasks that can be tuned to prioritize the remembering of\npreviously learned tasks or the learning of new ones. Our experiments prove the\nrobustness and reliability of the learned models to adapt to the changing\nsensing environment, and show the suitability of using uncertainty of the\npredictions to assess their reliability.",
          "link": "http://arxiv.org/abs/2106.05872",
          "publishedOn": "2021-06-11T01:42:16.483Z",
          "wordCount": 550,
          "title": "Knowing when we do not know: Bayesian continual learning for sensing-based analysis tasks. (arXiv:2106.05872v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05480",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1\">Yin Tat Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_R/0/1/0/all/0/1\">Ruoqi Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_K/0/1/0/all/0/1\">Kevin Tian</a>",
          "description": "We give lower bounds on the performance of two of the most popular sampling\nmethods in practice, the Metropolis-adjusted Langevin algorithm (MALA) and\nmulti-step Hamiltonian Monte Carlo (HMC) with a leapfrog integrator, when\napplied to well-conditioned distributions. Our main result is a nearly-tight\nlower bound of $\\widetilde{\\Omega}(\\kappa d)$ on the mixing time of MALA from\nan exponentially warm start, matching a line of algorithmic results up to\nlogarithmic factors and answering an open question of Chewi et. al. We also\nshow that a polynomial dependence on dimension is necessary for the relaxation\ntime of HMC under any number of leapfrog steps, and bound the gains achievable\nby changing the step count. Our HMC analysis draws upon a novel connection\nbetween leapfrog integration and Chebyshev polynomials, which may be of\nindependent interest.",
          "link": "http://arxiv.org/abs/2106.05480",
          "publishedOn": "2021-06-11T01:42:16.450Z",
          "wordCount": 585,
          "title": "Lower Bounds on Metropolized Sampling Methods for Well-Conditioned Distributions. (arXiv:2106.05480v1 [cs.DS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05610",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dhulipala_L/0/1/0/all/0/1\">Laxman Dhulipala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eisenstat_D/0/1/0/all/0/1\">David Eisenstat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lacki_J/0/1/0/all/0/1\">Jakub &#x141;&#x105;cki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mirrokni_V/0/1/0/all/0/1\">Vahab Mirrokni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1\">Jessica Shi</a>",
          "description": "We study the widely used hierarchical agglomerative clustering (HAC)\nalgorithm on edge-weighted graphs. We define an algorithmic framework for\nhierarchical agglomerative graph clustering that provides the first efficient\n$\\tilde{O}(m)$ time exact algorithms for classic linkage measures, such as\ncomplete- and WPGMA-linkage, as well as other measures. Furthermore, for\naverage-linkage, arguably the most popular variant of HAC, we provide an\nalgorithm that runs in $\\tilde{O}(n\\sqrt{m})$ time. For this variant, this is\nthe first exact algorithm that runs in subquadratic time, as long as\n$m=n^{2-\\epsilon}$ for some constant $\\epsilon > 0$. We complement this result\nwith a simple $\\epsilon$-close approximation algorithm for average-linkage in\nour framework that runs in $\\tilde{O}(m)$ time. As an application of our\nalgorithms, we consider clustering points in a metric space by first using\n$k$-NN to generate a graph from the point set, and then running our algorithms\non the resulting weighted graph. We validate the performance of our algorithms\non publicly available datasets, and show that our approach can speed up\nclustering of point datasets by a factor of 20.7--76.5x.",
          "link": "http://arxiv.org/abs/2106.05610",
          "publishedOn": "2021-06-11T01:42:16.367Z",
          "wordCount": 628,
          "title": "Hierarchical Agglomerative Graph Clustering in Nearly-Linear Time. (arXiv:2106.05610v1 [cs.DS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05478",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Koo_H/0/1/0/all/0/1\">Hyungjoon Koo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Soyeon Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_D/0/1/0/all/0/1\">Daejin Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1\">Taesoo Kim</a>",
          "description": "A wide range of binary analysis applications, such as bug discovery, malware\nanalysis and code clone detection, require recovery of contextual meanings on a\nbinary code. Recently, binary analysis techniques based on machine learning\nhave been proposed to automatically reconstruct the code representation of a\nbinary instead of manually crafting specifics of the analysis algorithm.\nHowever, the existing approaches utilizing machine learning are still\nspecialized to solve one domain of problems, rendering recreation of models for\ndifferent types of binary analysis. In this paper, we propose DeepSemantic\nutilizing BERT in producing the semantic-aware code representation of a binary\ncode.\n\nTo this end, we introduce well-balanced instruction normalization that holds\nrich information for each of instructions yet minimizing an out-of-vocabulary\n(OOV) problem. DeepSemantic has been carefully designed based on our study with\nlarge swaths of binaries. Besides, DeepSemantic leverages the essence of the\nBERT architecture into re-purposing a pre-trained generic model that is readily\navailable as a one-time processing, followed by quickly applying specific\ndownstream tasks with a fine-tuning process. We demonstrate DeepSemantic with\ntwo downstream tasks, namely, binary similarity comparison and compiler\nprovenance (i.e., compiler and optimization level) prediction. Our experimental\nresults show that the binary similarity model outperforms two state-of-the-art\nbinary similarity tools, DeepBinDiff and SAFE, 49.84% and 15.83% on average,\nrespectively.",
          "link": "http://arxiv.org/abs/2106.05478",
          "publishedOn": "2021-06-11T01:42:16.336Z",
          "wordCount": 642,
          "title": "Semantic-aware Binary Code Representation with BERT. (arXiv:2106.05478v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05648",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Grillotti_L/0/1/0/all/0/1\">Luca Grillotti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cully_A/0/1/0/all/0/1\">Antoine Cully</a>",
          "description": "Quality-Diversity algorithms refer to a class of evolutionary algorithms\ndesigned to find a collection of diverse and high-performing solutions to a\ngiven problem. In robotics, such algorithms can be used for generating a\ncollection of controllers covering most of the possible behaviours of a robot.\nTo do so, these algorithms associate a behavioural descriptor to each of these\nbehaviours. Each behavioural descriptor is used for estimating the novelty of\none behaviour compared to the others. In most existing algorithms, the\nbehavioural descriptor needs to be hand-coded, thus requiring prior knowledge\nabout the task to solve. In this paper, we introduce: Autonomous Robots\nRealising their Abilities, an algorithm that uses a dimensionality reduction\ntechnique to automatically learn behavioural descriptors based on raw sensory\ndata. The performance of this algorithm is assessed on three robotic tasks in\nsimulation. The experimental results show that it performs similarly to\ntraditional hand-coded approaches without the requirement to provide any\nhand-coded behavioural descriptor. In the collection of diverse and\nhigh-performing solutions, it also manages to find behaviours that are novel\nwith respect to more features than its hand-coded baselines. Finally, we\nintroduce a variant of the algorithm which is robust to the dimensionality of\nthe behavioural descriptor space.",
          "link": "http://arxiv.org/abs/2106.05648",
          "publishedOn": "2021-06-11T01:42:16.320Z",
          "wordCount": 633,
          "title": "Unsupervised Behaviour Discovery with Quality-Diversity Optimisation. (arXiv:2106.05648v1 [cs.NE])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05408",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Boes_W/0/1/0/all/0/1\">Wim Boes</a>, <a href=\"http://arxiv.org/find/eess/1/au:+hamme_H/0/1/0/all/0/1\">Hugo Van hamme</a>",
          "description": "We study the merit of transfer learning for two sound recognition problems,\ni.e., audio tagging and sound event detection. Employing feature fusion, we\nadapt a baseline system utilizing only spectral acoustic inputs to also make\nuse of pretrained auditory and visual features, extracted from networks built\nfor different tasks and trained with external data. We perform experiments with\nthese modified models on an audiovisual multi-label data set, of which the\ntraining partition contains a large number of unlabeled samples and a smaller\namount of clips with weak annotations, indicating the clip-level presence of 10\nsound categories without specifying the temporal boundaries of the active\nauditory events. For clip-based audio tagging, this transfer learning method\ngrants marked improvements. Addition of the visual modality on top of audio\nalso proves to be advantageous in this context. When it comes to generating\ntranscriptions of audio recordings, the benefit of pretrained features depends\non the requested temporal resolution: for coarse-grained sound event detection,\ntheir utility remains notable. But when more fine-grained predictions are\nrequired, performance gains are strongly reduced due to a mismatch between the\nproblem at hand and the goals of the models from which the pretrained vectors\nwere obtained.",
          "link": "http://arxiv.org/abs/2106.05408",
          "publishedOn": "2021-06-11T01:42:16.315Z",
          "wordCount": 642,
          "title": "Audiovisual transfer learning for audio tagging and sound event detection. (arXiv:2106.05408v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05658",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Xu_T/0/1/0/all/0/1\">Tianlin Xu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Acciaio_B/0/1/0/all/0/1\">Beatrice Acciaio</a>",
          "description": "Causal Optimal Transport (COT) results from imposing a temporal causality\nconstraint on classic optimal transport problems, which naturally generates a\nnew concept of distances between distributions on path spaces. The first\napplication of the COT theory for sequential learning was given in Xu et al.\n(2020), where COT-GAN was introduced as an adversarial algorithm to train\nimplicit generative models optimized for producing sequential data. Relying on\nXu et al. (2020), the contribution of the present paper is twofold. First, we\ndevelop a conditional version of COT-GAN suitable for sequence prediction. This\nmeans that the dataset is now used in order to learn how a sequence will evolve\ngiven the observation of its past evolution. Second, we improve on the\nconvergence results by working with modifications of the empirical measures via\na specific type of quantization due to Backhoff et al. (2020). The resulting\nquantized conditional COT-GAN algorithm is illustrated with an application for\nvideo prediction.",
          "link": "http://arxiv.org/abs/2106.05658",
          "publishedOn": "2021-06-11T01:42:16.309Z",
          "wordCount": 585,
          "title": "Quantized Conditional COT-GAN for Video Prediction. (arXiv:2106.05658v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05515",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1\">Yu Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mei_S/0/1/0/all/0/1\">Song Mei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Huan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1\">Caiming Xiong</a>",
          "description": "Estimating the data uncertainty in regression tasks is often done by learning\na quantile function or a prediction interval of the true label conditioned on\nthe input. It is frequently observed that quantile regression -- a vanilla\nalgorithm for learning quantiles with asymptotic guarantees -- tends to\n\\emph{under-cover} than the desired coverage level in reality. While various\nfixes have been proposed, a more fundamental understanding of why this\nunder-coverage bias happens in the first place remains elusive.\n\nIn this paper, we present a rigorous theoretical study on the coverage of\nuncertainty estimation algorithms in learning quantiles. We prove that quantile\nregression suffers from an inherent under-coverage bias, in a vanilla setting\nwhere we learn a realizable linear quantile function and there is more data\nthan parameters. More quantitatively, for $\\alpha>0.5$ and small $d/n$, the\n$\\alpha$-quantile learned by quantile regression roughly achieves coverage\n$\\alpha - (\\alpha-1/2)\\cdot d/n$ regardless of the noise distribution, where\n$d$ is the input dimension and $n$ is the number of training data. Our theory\nreveals that this under-coverage bias stems from a certain high-dimensional\nparameter estimation error that is not implied by existing theories on quantile\nregression. Experiments on simulated and real data verify our theory and\nfurther illustrate the effect of various factors such as sample size and model\ncapacity on the under-coverage bias in more practical setups.",
          "link": "http://arxiv.org/abs/2106.05515",
          "publishedOn": "2021-06-11T01:42:16.303Z",
          "wordCount": 655,
          "title": "Understanding the Under-Coverage Bias in Uncertainty Estimation. (arXiv:2106.05515v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05667",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mialon_G/0/1/0/all/0/1\">Gr&#xe9;goire Mialon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Dexiong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Selosse_M/0/1/0/all/0/1\">Margot Selosse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mairal_J/0/1/0/all/0/1\">Julien Mairal</a>",
          "description": "We show that viewing graphs as sets of node features and incorporating\nstructural and positional information into a transformer architecture is able\nto outperform representations learned with classical graph neural networks\n(GNNs). Our model, GraphiT, encodes such information by (i) leveraging relative\npositional encoding strategies in self-attention scores based on positive\ndefinite kernels on graphs, and (ii) enumerating and encoding local\nsub-structures such as paths of short length. We thoroughly evaluate these two\nideas on many classification and regression tasks, demonstrating the\neffectiveness of each of them independently, as well as their combination. In\naddition to performing well on standard benchmarks, our model also admits\nnatural visualization mechanisms for interpreting graph motifs explaining the\npredictions, making it a potentially strong candidate for scientific\napplications where interpretation is important. Code available at\nhttps://github.com/inria-thoth/GraphiT.",
          "link": "http://arxiv.org/abs/2106.05667",
          "publishedOn": "2021-06-11T01:42:16.289Z",
          "wordCount": 553,
          "title": "GraphiT: Encoding Graph Structure in Transformers. (arXiv:2106.05667v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05587",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Hu_W/0/1/0/all/0/1\">Wei-Fan Hu</a>, <a href=\"http://arxiv.org/find/math/1/au:+Lin_T/0/1/0/all/0/1\">Te-Sheng Lin</a>, <a href=\"http://arxiv.org/find/math/1/au:+Lai_M/0/1/0/all/0/1\">Ming-Chih Lai</a>",
          "description": "In this paper, a new Discontinuity Capturing Shallow Neural Network (DCSNN)\nfor approximating $d$-dimensional piecewise continuous functions and for\nsolving elliptic interface problems is developed. There are three novel\nfeatures in the present network; namely, (i) jump discontinuity is captured\nsharply, (ii) it is completely shallow consisting of only one hidden layer,\n(iii) it is completely mesh-free for solving partial differential equations\n(PDEs). We first continuously extend the $d$-dimensional piecewise continuous\nfunction in $(d+1)$-dimensional space by augmenting one coordinate variable to\nlabel the pieces of discontinuous function, and then construct a shallow neural\nnetwork to express this new augmented function. Since only one hidden layer is\nemployed, the number of training parameters (weights and biases) scales\nlinearly with the dimension and the neurons used in the hidden layer. For\nsolving elliptic interface equations, the network is trained by minimizing the\nmean squared error loss that consists of the residual of governing equation,\nboundary condition, and the interface jump conditions. We perform a series of\nnumerical tests to compare the accuracy and efficiency of the present network.\nOur DCSNN model is comparably efficient due to only moderate number of\nparameters needed to be trained (a few hundreds of parameters used throughout\nall numerical examples here), and the result shows better accuracy (and less\nparameters) than other method using piecewise deep neural network in\nliterature. We also compare the results obtained by the traditional grid-based\nimmersed interface method (IIM) which is designed particularly for elliptic\ninterface problems. Again, the present results show better accuracy than the\nones obtained by IIM. We conclude by solving a six-dimensional problem to show\nthe capability of the present network for high-dimensional applications.",
          "link": "http://arxiv.org/abs/2106.05587",
          "publishedOn": "2021-06-11T01:42:16.284Z",
          "wordCount": 707,
          "title": "A Discontinuity Capturing Shallow Neural Network for Elliptic Interface Problems. (arXiv:2106.05587v1 [math.NA])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05373",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Podobas_A/0/1/0/all/0/1\">Artur Podobas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Svedin_M/0/1/0/all/0/1\">Martin Svedin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chien_S/0/1/0/all/0/1\">Steven W. D. Chien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_I/0/1/0/all/0/1\">Ivy B. Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ravichandran_N/0/1/0/all/0/1\">Naresh Balaji Ravichandran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Herman_P/0/1/0/all/0/1\">Pawel Herman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lansner_A/0/1/0/all/0/1\">Anders Lansner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Markidis_S/0/1/0/all/0/1\">Stefano Markidis</a>",
          "description": "The modern deep learning method based on backpropagation has surged in\npopularity and has been used in multiple domains and application areas. At the\nsame time, there are other -- less-known -- machine learning algorithms with a\nmature and solid theoretical foundation whose performance remains unexplored.\nOne such example is the brain-like Bayesian Confidence Propagation Neural\nNetwork (BCPNN). In this paper, we introduce StreamBrain -- a framework that\nallows neural networks based on BCPNN to be practically deployed in\nHigh-Performance Computing systems. StreamBrain is a domain-specific language\n(DSL), similar in concept to existing machine learning (ML) frameworks, and\nsupports backends for CPUs, GPUs, and even FPGAs. We empirically demonstrate\nthat StreamBrain can train the well-known ML benchmark dataset MNIST within\nseconds, and we are the first to demonstrate BCPNN on STL-10 size networks. We\nalso show how StreamBrain can be used to train with custom floating-point\nformats and illustrate the impact of using different bfloat variations on BCPNN\nusing FPGAs.",
          "link": "http://arxiv.org/abs/2106.05373",
          "publishedOn": "2021-06-11T01:42:16.277Z",
          "wordCount": 641,
          "title": "StreamBrain: An HPC Framework for Brain-like Neural Networks on CPUs, GPUs and FPGAs. (arXiv:2106.05373v1 [cs.DC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05332",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mern_J/0/1/0/all/0/1\">John Mern</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hatch_K/0/1/0/all/0/1\">Kyle Hatch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silva_R/0/1/0/all/0/1\">Ryan Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brush_J/0/1/0/all/0/1\">Jeff Brush</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kochenderfer_M/0/1/0/all/0/1\">Mykel J. Kochenderfer</a>",
          "description": "Defending computer networks from cyber attack requires coordinating actions\nacross multiple nodes based on imperfect indicators of compromise while\nminimizing disruptions to network operations. Advanced attacks can progress\nwith few observable signals over several months before execution. The resulting\nsequential decision problem has large observation and action spaces and a long\ntime-horizon, making it difficult to solve with existing methods. In this work,\nwe present techniques to scale deep reinforcement learning to solve the cyber\nsecurity orchestration problem for large industrial control networks. We\npropose a novel attention-based neural architecture with size complexity that\nis invariant to the size of the network under protection. A pre-training\ncurriculum is presented to overcome early exploration difficulty. Experiments\nshow in that the proposed approaches greatly improve both the learning sample\ncomplexity and converged policy performance over baseline methods in\nsimulation.",
          "link": "http://arxiv.org/abs/2106.05332",
          "publishedOn": "2021-06-11T01:42:16.271Z",
          "wordCount": 582,
          "title": "Reinforcement Learning for Industrial Control Network Cyber Security Orchestration. (arXiv:2106.05332v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05335",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jafarnia_Jahromi_M/0/1/0/all/0/1\">Mehdi Jafarnia-Jahromi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Liyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_R/0/1/0/all/0/1\">Rahul Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1\">Haipeng Luo</a>",
          "description": "We consider the problem of online reinforcement learning for the Stochastic\nShortest Path (SSP) problem modeled as an unknown MDP with an absorbing state.\nWe propose PSRL-SSP, a simple posterior sampling-based reinforcement learning\nalgorithm for the SSP problem. The algorithm operates in epochs. At the\nbeginning of each epoch, a sample is drawn from the posterior distribution on\nthe unknown model dynamics, and the optimal policy with respect to the drawn\nsample is followed during that epoch. An epoch completes if either the number\nof visits to the goal state in the current epoch exceeds that of the previous\nepoch, or the number of visits to any of the state-action pairs is doubled. We\nestablish a Bayesian regret bound of $O(B_\\star S\\sqrt{AK})$, where $B_\\star$\nis an upper bound on the expected cost of the optimal policy, $S$ is the size\nof the state space, $A$ is the size of the action space, and $K$ is the number\nof episodes. The algorithm only requires the knowledge of the prior\ndistribution, and has no hyper-parameters to tune. It is the first such\nposterior sampling algorithm and outperforms numerically previously proposed\noptimism-based algorithms.",
          "link": "http://arxiv.org/abs/2106.05335",
          "publishedOn": "2021-06-11T01:42:16.266Z",
          "wordCount": 617,
          "title": "Online Learning for Stochastic Shortest Path Model via Posterior Sampling. (arXiv:2106.05335v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05665",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_A/0/1/0/all/0/1\">Anurag Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nambi_A/0/1/0/all/0/1\">Akshay Nambi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1\">Aditya Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+YVS_H/0/1/0/all/0/1\">Harish YVS</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganu_T/0/1/0/all/0/1\">Tanuja Ganu</a>",
          "description": "Executing computer vision models on streaming visual data, or streaming\nperception is an emerging problem, with applications in self-driving, embodied\nagents, and augmented/virtual reality. The development of such systems is\nlargely governed by the accuracy and latency of the processing pipeline. While\npast work has proposed numerous approximate execution frameworks, their\ndecision functions solely focus on optimizing latency, accuracy, or energy,\netc. This results in sub-optimum decisions, affecting the overall system\nperformance. We argue that the streaming perception systems should holistically\nmaximize the overall system performance (i.e., considering both accuracy and\nlatency simultaneously). To this end, we describe a new approach based on deep\nreinforcement learning to learn these tradeoffs at runtime for streaming\nperception. This tradeoff optimization is formulated as a novel deep contextual\nbandit problem and we design a new reward function that holistically integrates\nlatency and accuracy into a single metric. We show that our agent can learn a\ncompetitive policy across multiple decision dimensions, which outperforms\nstate-of-the-art policies on public datasets.",
          "link": "http://arxiv.org/abs/2106.05665",
          "publishedOn": "2021-06-11T01:42:16.259Z",
          "wordCount": 604,
          "title": "Adaptive Streaming Perception using Deep Reinforcement Learning. (arXiv:2106.05665v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05410",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hojjati_H/0/1/0/all/0/1\">Hadi Hojjati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Armanfard_N/0/1/0/all/0/1\">Narges Armanfard</a>",
          "description": "Semi-supervised anomaly detection, which aims to detect anomalies from normal\nsamples using a model that is solely trained on normal data, has been an active\nfield of research in the past decade. With recent advancements in deep\nlearning, particularly generative adversarial networks and autoencoders,\nresearchers have designed efficient deep anomaly detection methods. Existing\nworks commonly use neural networks such as an autoencoder to map the data into\na new representation that is easier to work with and then apply an anomaly\ndetection algorithm. In this paper, we propose a method, DASVDD, that jointly\nlearns the parameters of an autoencoder while minimizing the volume of an\nenclosing hyper-sphere on its latent representation. We propose a customized\nanomaly score which is a combination of autoencoder's reconstruction error and\ndistance of the lower-dimensional representation of a sample from the center of\nthe enclosing hyper-sphere. Minimizing this anomaly score on the normal data\nduring training aids us in learning the underlying distribution of normal data.\nIncluding the reconstruction error in the anomaly score ensures that DASVDD\ndoes not suffer from the common hyper-sphere collapse issue since the proposed\nDASVDD model does not converge to the trivial solution of mapping all inputs to\na constant point in the latent representation. Experimental evaluations on\nseveral benchmark datasets from different domains show that the proposed method\noutperforms most of the commonly used state-of-the-art anomaly detection\nalgorithms while maintaining robust and accurate performance across different\nanomaly classes.",
          "link": "http://arxiv.org/abs/2106.05410",
          "publishedOn": "2021-06-11T01:42:16.215Z",
          "wordCount": 667,
          "title": "DASVDD: Deep Autoencoding Support Vector Data Descriptor for Anomaly Detection. (arXiv:2106.05410v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05378",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moradipari_A/0/1/0/all/0/1\">Ahmadreza Moradipari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbasi_Yadkori_Y/0/1/0/all/0/1\">Yasin Abbasi-Yadkori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alizadeh_M/0/1/0/all/0/1\">Mahnoosh Alizadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghavamzadeh_M/0/1/0/all/0/1\">Mohammad Ghavamzadeh</a>",
          "description": "We study two model selection settings in stochastic linear bandits (LB). In\nthe first setting, the reward parameter of the LB problem is arbitrarily\nselected from $M$ models represented as (possibly) overlapping balls in\n$\\mathbb R^d$. However, the agent only has access to misspecified models, i.e.,\nestimates of the centers and radii of the balls. We refer to this setting as\nparameter selection. In the second setting, which we refer to as feature\nselection, the expected reward of the LB problem is in the linear span of at\nleast one of $M$ feature maps (models). For each setting, we develop and\nanalyze an algorithm that is based on a reduction from bandits to\nfull-information problems. This allows us to obtain regret bounds that are not\nworse (up to a $\\sqrt{\\log M}$ factor) than the case where the true model is\nknown. Our parameter selection algorithm is OFUL-style and the one for feature\nselection is based on the SquareCB algorithm. We also show that the regret of\nour parameter selection algorithm scales logarithmically with model\nmisspecification.",
          "link": "http://arxiv.org/abs/2106.05378",
          "publishedOn": "2021-06-11T01:42:16.201Z",
          "wordCount": 598,
          "title": "Parameter and Feature Selection in Stochastic Linear Bandits. (arXiv:2106.05378v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05367",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Arvanitidis_G/0/1/0/all/0/1\">Georgios Arvanitidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_Duque_M/0/1/0/all/0/1\">Miguel Gonz&#xe1;lez-Duque</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pouplin_A/0/1/0/all/0/1\">Alison Pouplin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalatzis_D/0/1/0/all/0/1\">Dimitris Kalatzis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hauberg_S/0/1/0/all/0/1\">S&#xf8;ren Hauberg</a>",
          "description": "Latent space geometry has shown itself to provide a rich and rigorous\nframework for interacting with the latent variables of deep generative models.\nThe existing theory, however, relies on the decoder being a Gaussian\ndistribution as its simple reparametrization allows us to interpret the\ngenerating process as a random projection of a deterministic manifold.\nConsequently, this approach breaks down when applied to decoders that are not\nas easily reparametrized. We here propose to use the Fisher-Rao metric\nassociated with the space of decoder distributions as a reference metric, which\nwe pull back to the latent space. We show that we can achieve meaningful latent\ngeometries for a wide range of decoder distributions for which the previous\ntheory was not applicable, opening the door to `black box' latent geometries.",
          "link": "http://arxiv.org/abs/2106.05367",
          "publishedOn": "2021-06-11T01:42:16.188Z",
          "wordCount": 550,
          "title": "Pulling back information geometry. (arXiv:2106.05367v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.06700",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jovanovic_N/0/1/0/all/0/1\">Nikola Jovanovi&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balunovic_M/0/1/0/all/0/1\">Mislav Balunovi&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baader_M/0/1/0/all/0/1\">Maximilian Baader</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vechev_M/0/1/0/all/0/1\">Martin Vechev</a>",
          "description": "Certified defenses based on convex relaxations are an established technique\nfor training provably robust models. The key component is the choice of\nrelaxation, varying from simple intervals to tight polyhedra. Paradoxically,\nhowever, training with tighter relaxations can often lead to worse certified\nrobustness. The poor understanding of this paradox has forced recent\nstate-of-the-art certified defenses to focus on designing various heuristics in\norder to mitigate its effects. In contrast, in this paper we study the\nunderlying causes and show that tightness alone may not be the determining\nfactor. Concretely, we identify two key properties of relaxations that impact\ntraining dynamics: continuity and sensitivity. Our extensive experimental\nevaluation demonstrates that these two factors, observed alongside tightness,\nexplain the drop in certified robustness for popular relaxations. Further, we\ninvestigate the possibility of designing and training with relaxations that are\ntight, continuous and not sensitive. We believe the insights of this work can\nhelp drive the principled discovery of new and effective certified defense\nmechanisms.",
          "link": "http://arxiv.org/abs/2102.06700",
          "publishedOn": "2021-06-11T01:42:16.173Z",
          "wordCount": 617,
          "title": "Certified Defenses: Why Tighter Relaxations May Hurt Training. (arXiv:2102.06700v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05359",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Santanam_T/0/1/0/all/0/1\">Tejas Santanam</a>, <a href=\"http://arxiv.org/find/math/1/au:+Trasatti_A/0/1/0/all/0/1\">Anthony Trasatti</a>, <a href=\"http://arxiv.org/find/math/1/au:+Hentenryck_P/0/1/0/all/0/1\">Pascal Van Hentenryck</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhang_H/0/1/0/all/0/1\">Hanyu Zhang</a>",
          "description": "Many special events, including sport games and concerts, often cause surges\nin demand and congestion for transit systems. Therefore, it is important for\ntransit providers to understand their impact on disruptions, delays, and fare\nrevenues. This paper proposes a suite of data-driven techniques that exploit\nAutomated Fare Collection (AFC) data for evaluating, anticipating, and managing\nthe performance of transit systems during recurring congestion peaks due to\nspecial events. This includes an extensive analysis of ridership of the two\nmajor stadiums in downtown Atlanta using rail data from the Metropolitan\nAtlanta Rapid Transit Authority (MARTA). The paper first highlights the\nridership predictability at the aggregate level for each station on both event\nand non-event days. It then presents an unsupervised machine-learning model to\ncluster passengers and identify which train they are boarding. The model makes\nit possible to evaluate system performance in terms of fundamental metrics such\nas the passenger load per train and the wait times of riders. The paper also\npresents linear regression and random forest models for predicting ridership\nthat are used in combination with historical throughput analysis to forecast\ndemand. Finally, simulations are performed that showcase the potential\nimprovements to wait times and demand matching by leveraging proposed\ntechniques to optimize train frequencies based on forecasted demand.",
          "link": "http://arxiv.org/abs/2106.05359",
          "publishedOn": "2021-06-11T01:42:16.167Z",
          "wordCount": 652,
          "title": "Public Transit for Special Events: Ridership Prediction and Train Optimization. (arXiv:2106.05359v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05325",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Strong_C/0/1/0/all/0/1\">Christopher A. Strong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Katz_S/0/1/0/all/0/1\">Sydney M. Katz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Corso_A/0/1/0/all/0/1\">Anthony L. Corso</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kochenderfer_M/0/1/0/all/0/1\">Mykel J. Kochenderfer</a>",
          "description": "Deep neural networks often lack the safety and robustness guarantees needed\nto be deployed in safety critical systems. Formal verification techniques can\nbe used to prove input-output safety properties of networks, but when\nproperties are difficult to specify, we rely on the solution to various\noptimization problems. In this work, we present an algorithm called ZoPE that\nsolves optimization problems over the output of feedforward ReLU networks with\nlow-dimensional inputs. The algorithm eagerly splits the input space, bounding\nthe objective using zonotope propagation at each step, and improves\ncomputational efficiency compared to existing mixed integer programming\napproaches. We demonstrate how to formulate and solve three types of\noptimization problems: (i) minimization of any convex function over the output\nspace, (ii) minimization of a convex function over the output of two networks\nin series with an adversarial perturbation in the layer between them, and (iii)\nmaximization of the difference in output between two networks. Using ZoPE, we\nobserve a $25\\times$ speedup on property 1 of the ACAS Xu neural network\nverification benchmark and an $85\\times$ speedup on a set of linear\noptimization problems. We demonstrate the versatility of the optimizer in\nanalyzing networks by projecting onto the range of a generative adversarial\nnetwork and visualizing the differences between a compressed and uncompressed\nnetwork.",
          "link": "http://arxiv.org/abs/2106.05325",
          "publishedOn": "2021-06-11T01:42:16.161Z",
          "wordCount": 659,
          "title": "ZoPE: A Fast Optimizer for ReLU Networks with Low-Dimensional Inputs. (arXiv:2106.05325v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05532",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1\">Swaroop Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arunkumar_A/0/1/0/all/0/1\">Anjana Arunkumar</a>",
          "description": "Models that top leaderboards often perform unsatisfactorily when deployed in\nreal world applications; this has necessitated rigorous and expensive\npre-deployment model testing. A hitherto unexplored facet of model performance\nis: Are our leaderboards doing equitable evaluation? In this paper, we\nintroduce a task-agnostic method to probe leaderboards by weighting samples\nbased on their `difficulty' level. We find that leaderboards can be\nadversarially attacked and top performing models may not always be the best\nmodels. We subsequently propose alternate evaluation metrics. Our experiments\non 10 models show changes in model ranking and an overall reduction in\npreviously reported performance -- thus rectifying the overestimation of AI\nsystems' capabilities. Inspired by behavioral testing principles, we further\ndevelop a prototype of a visual analytics tool that enables leaderboard\nrevamping through customization, based on an end user's focus area. This helps\nusers analyze models' strengths and weaknesses, and guides them in the\nselection of a model best suited for their application scenario. In a user\nstudy, members of various commercial product development teams, covering 5\nfocus areas, find that our prototype reduces pre-deployment development and\ntesting effort by 41% on average.",
          "link": "http://arxiv.org/abs/2106.05532",
          "publishedOn": "2021-06-11T01:42:16.155Z",
          "wordCount": 632,
          "title": "How Robust are Model Rankings: A Leaderboard Customization Approach for Equitable Evaluation. (arXiv:2106.05532v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05400",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Bagherian_D/0/1/0/all/0/1\">Dawna Bagherian</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Gornet_J/0/1/0/all/0/1\">James Gornet</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Bernstein_J/0/1/0/all/0/1\">Jeremy Bernstein</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ni_Y/0/1/0/all/0/1\">Yu-Li Ni</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Yue_Y/0/1/0/all/0/1\">Yisong Yue</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Meister_M/0/1/0/all/0/1\">Markus Meister</a>",
          "description": "We study the problem of sparse nonlinear model recovery of high dimensional\ncompositional functions. Our study is motivated by emerging opportunities in\nneuroscience to recover fine-grained models of biological neural circuits using\ncollected measurement data. Guided by available domain knowledge in\nneuroscience, we explore conditions under which one can recover the underlying\nbiological circuit that generated the training data. Our results suggest\ninsights of both theoretical and practical interests. Most notably, we find\nthat a sign constraint on the weights is a necessary condition for system\nrecovery, which we establish both theoretically with an identifiability\nguarantee and empirically on simulated biological circuits. We conclude with a\ncase study on retinal ganglion cell circuits using data collected from mouse\nretina, showcasing the practical potential of this approach.",
          "link": "http://arxiv.org/abs/2106.05400",
          "publishedOn": "2021-06-11T01:42:16.150Z",
          "wordCount": 578,
          "title": "Fine-Grained System Identification of Nonlinear Neural Circuits. (arXiv:2106.05400v1 [q-bio.QM])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05429",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weiss_J/0/1/0/all/0/1\">Jakob Weiss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Navab_N/0/1/0/all/0/1\">Nassir Navab</a>",
          "description": "Volume Rendering is an important technique for visualizing three-dimensional\nscalar data grids and is commonly employed for scientific and medical image\ndata. Direct Volume Rendering (DVR) is a well established and efficient\nrendering algorithm for volumetric data. Neural rendering uses deep neural\nnetworks to solve inverse rendering tasks and applies techniques similar to\nDVR. However, it has not been demonstrated successfully for the rendering of\nscientific volume data.\n\nIn this work, we introduce Deep Direct Volume Rendering (DeepDVR), a\ngeneralization of DVR that allows for the integration of deep neural networks\ninto the DVR algorithm. We conceptualize the rendering in a latent color space,\nthus enabling the use of deep architectures to learn implicit mappings for\nfeature extraction and classification, replacing explicit feature design and\nhand-crafted transfer functions. Our generalization serves to derive novel\nvolume rendering architectures that can be trained end-to-end directly from\nexamples in image space, obviating the need to manually define and fine-tune\nmultidimensional transfer functions while providing superior classification\nstrength. We further introduce a novel stepsize annealing scheme to accelerate\nthe training of DeepDVR models and validate its effectiveness in a set of\nexperiments. We validate our architectures on two example use cases: (1)\nlearning an optimized rendering from manually adjusted reference images for a\nsingle volume and (2) learning advanced visualization concepts like shading and\nsemantic colorization that generalize to unseen volume data.\n\nWe find that deep volume rendering architectures with explicit modeling of\nthe DVR pipeline effectively enable end-to-end learning of scientific volume\nrendering tasks from target images.",
          "link": "http://arxiv.org/abs/2106.05429",
          "publishedOn": "2021-06-11T01:42:16.133Z",
          "wordCount": 681,
          "title": "Deep Direct Volume Rendering: Learning Visual Feature Mappings From Exemplary Images. (arXiv:2106.05429v1 [cs.GR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05387",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Murugesan_K/0/1/0/all/0/1\">Keerthiram Murugesan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhury_S/0/1/0/all/0/1\">Subhajit Chaudhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Talamadupula_K/0/1/0/all/0/1\">Kartik Talamadupula</a>",
          "description": "Text-based games (TBGs) have become a popular proving ground for the\ndemonstration of learning-based agents that make decisions in quasi real-world\nsettings. The crux of the problem for a reinforcement learning agent in such\nTBGs is identifying the objects in the world, and those objects' relations with\nthat world. While the recent use of text-based resources for increasing an\nagent's knowledge and improving its generalization have shown promise, we posit\nin this paper that there is much yet to be learned from visual representations\nof these same worlds. Specifically, we propose to retrieve images that\nrepresent specific instances of text observations from the world and train our\nagents on such images. This improves the agent's overall understanding of the\ngame 'scene' and objects' relationships to the world around them, and the\nvariety of visual representations on offer allow the agent to generate a better\ngeneralization of a relationship. We show that incorporating such images\nimproves the performance of agents in various TBG settings.",
          "link": "http://arxiv.org/abs/2106.05387",
          "publishedOn": "2021-06-11T01:42:16.116Z",
          "wordCount": 598,
          "title": "Eye of the Beholder: Improved Relation Generalization for Text-based Reinforcement Learning Agents. (arXiv:2106.05387v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.01601",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tolstikhin_I/0/1/0/all/0/1\">Ilya Tolstikhin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Houlsby_N/0/1/0/all/0/1\">Neil Houlsby</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolesnikov_A/0/1/0/all/0/1\">Alexander Kolesnikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beyer_L/0/1/0/all/0/1\">Lucas Beyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_X/0/1/0/all/0/1\">Xiaohua Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Unterthiner_T/0/1/0/all/0/1\">Thomas Unterthiner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yung_J/0/1/0/all/0/1\">Jessica Yung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steiner_A/0/1/0/all/0/1\">Andreas Steiner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keysers_D/0/1/0/all/0/1\">Daniel Keysers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uszkoreit_J/0/1/0/all/0/1\">Jakob Uszkoreit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lucic_M/0/1/0/all/0/1\">Mario Lucic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dosovitskiy_A/0/1/0/all/0/1\">Alexey Dosovitskiy</a>",
          "description": "Convolutional Neural Networks (CNNs) are the go-to model for computer vision.\nRecently, attention-based networks, such as the Vision Transformer, have also\nbecome popular. In this paper we show that while convolutions and attention are\nboth sufficient for good performance, neither of them are necessary. We present\nMLP-Mixer, an architecture based exclusively on multi-layer perceptrons (MLPs).\nMLP-Mixer contains two types of layers: one with MLPs applied independently to\nimage patches (i.e. \"mixing\" the per-location features), and one with MLPs\napplied across patches (i.e. \"mixing\" spatial information). When trained on\nlarge datasets, or with modern regularization schemes, MLP-Mixer attains\ncompetitive scores on image classification benchmarks, with pre-training and\ninference cost comparable to state-of-the-art models. We hope that these\nresults spark further research beyond the realms of well established CNNs and\nTransformers.",
          "link": "http://arxiv.org/abs/2105.01601",
          "publishedOn": "2021-06-11T01:42:16.111Z",
          "wordCount": 641,
          "title": "MLP-Mixer: An all-MLP Architecture for Vision. (arXiv:2105.01601v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05418",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gerace_F/0/1/0/all/0/1\">Federica Gerace</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saglietti_L/0/1/0/all/0/1\">Luca Saglietti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mannelli_S/0/1/0/all/0/1\">Stefano Sarao Mannelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saxe_A/0/1/0/all/0/1\">Andrew Saxe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zdeborova_L/0/1/0/all/0/1\">Lenka Zdeborov&#xe1;</a>",
          "description": "Transfer learning can significantly improve the sample efficiency of neural\nnetworks, by exploiting the relatedness between a data-scarce target task and a\ndata-abundant source task. Despite years of successful applications, transfer\nlearning practice often relies on ad-hoc solutions, while theoretical\nunderstanding of these procedures is still limited. In the present work, we\nre-think a solvable model of synthetic data as a framework for modeling\ncorrelation between data-sets. This setup allows for an analytic\ncharacterization of the generalization performance obtained when transferring\nthe learned feature map from the source to the target task. Focusing on the\nproblem of training two-layer networks in a binary classification setting, we\nshow that our model can capture a range of salient features of transfer\nlearning with real data. Moreover, by exploiting parametric control over the\ncorrelation between the two data-sets, we systematically investigate under\nwhich conditions the transfer of features is beneficial for generalization.",
          "link": "http://arxiv.org/abs/2106.05418",
          "publishedOn": "2021-06-11T01:42:16.103Z",
          "wordCount": 588,
          "title": "Probing transfer learning with a model of synthetic correlated datasets. (arXiv:2106.05418v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05495",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Stosic_D/0/1/0/all/0/1\">Dusan Stosic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stosic_D/0/1/0/all/0/1\">Darko Stosic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ludermir_T/0/1/0/all/0/1\">Teresa B. Ludermir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stosic_B/0/1/0/all/0/1\">Borko Stosic</a>",
          "description": "Distance metric learning has attracted a lot of interest for solving machine\nlearning and pattern recognition problems over the last decades. In this work\nwe present a simple approach based on concepts from statistical physics to\nlearn optimal distance metric for a given problem. We formulate the task as a\ntypical statistical physics problem: distances between patterns represent\nconstituents of a physical system and the objective function corresponds to\nenergy. Then we express the problem as a minimization of the free energy of a\ncomplex system, which is equivalent to distance metric learning. Much like for\nmany problems in physics, we propose an approach based on Metropolis Monte\nCarlo to find the best distance metric. This provides a natural way to learn\nthe distance metric, where the learning process can be intuitively seen as\nstretching and rotating the metric space until some heuristic is satisfied. Our\nproposed method can handle a wide variety of constraints including those with\nspurious local minima. The approach works surprisingly well with stochastic\nnearest neighbors from neighborhood component analysis (NCA). Experimental\nresults on artificial and real-world data sets reveal a clear superiority over\na number of state-of-the-art distance metric learning methods for nearest\nneighbors classification.",
          "link": "http://arxiv.org/abs/2106.05495",
          "publishedOn": "2021-06-11T01:42:16.089Z",
          "wordCount": 627,
          "title": "Distance Metric Learning through Minimization of the Free Energy. (arXiv:2106.05495v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05386",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1\">Jianyuan Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhibo Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samaras_D/0/1/0/all/0/1\">Dimitris Samaras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Fusheng Wang</a>",
          "description": "Artificial intelligence has transformed the practice of drug discovery in the\npast decade. Various artificial intelligence techniques have been used in a\nwide range of applications. In this perspective, we present major applications\nof AI in drug discovery and discuss the relevant AI techniques, covering most\nrecent progress in AI-driven drug discovery. We expect that the perspective\nwill serve as a guide for researchers who are interested in working at this\nintersected area of artificial intelligence and drug discovery. We also provide\na GitHub repository summarizing the surveyed papers as a learning resource,\nwhich will be regularly updated.",
          "link": "http://arxiv.org/abs/2106.05386",
          "publishedOn": "2021-06-11T01:42:16.072Z",
          "wordCount": 523,
          "title": "Artificial Intelligence in Drug Discovery:Applications and Techniques. (arXiv:2106.05386v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.03334",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kim_W/0/1/0/all/0/1\">Wonjae Kim</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Son_B/0/1/0/all/0/1\">Bokyung Son</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kim_I/0/1/0/all/0/1\">Ildoo Kim</a>",
          "description": "Vision-and-Language Pre-training (VLP) has improved performance on various\njoint vision-and-language downstream tasks. Current approaches to VLP heavily\nrely on image feature extraction processes, most of which involve region\nsupervision (e.g., object detection) and the convolutional architecture (e.g.,\nResNet). Although disregarded in the literature, we find it problematic in\nterms of both (1) efficiency/speed, that simply extracting input features\nrequires much more computation than the multimodal interaction steps; and (2)\nexpressive power, as it is upper bounded to the expressive power of the visual\nembedder and its predefined visual vocabulary. In this paper, we present a\nminimal VLP model, Vision-and-Language Transformer (ViLT), monolithic in the\nsense that the processing of visual inputs is drastically simplified to just\nthe same convolution-free manner that we process textual inputs. We show that\nViLT is up to tens of times faster than previous VLP models, yet with\ncompetitive or better downstream task performance. Our code and pre-trained\nweights are available at https://github.com/dandelin/vilt.",
          "link": "http://arxiv.org/abs/2102.03334",
          "publishedOn": "2021-06-11T01:42:16.066Z",
          "wordCount": 607,
          "title": "ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision. (arXiv:2102.03334v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.02649",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Padovani_K/0/1/0/all/0/1\">Kleber Padovani</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Xavier_R/0/1/0/all/0/1\">Roberto Xavier</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Carvalho_A/0/1/0/all/0/1\">Andre Carvalho</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Reali_A/0/1/0/all/0/1\">Anna Reali</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Chateau_A/0/1/0/all/0/1\">Annie Chateau</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Alves_R/0/1/0/all/0/1\">Ronnie Alves</a>",
          "description": "The use of reinforcement learning has proven to be very promising for solving\ncomplex activities without human supervision during their learning process.\nHowever, their successful applications are predominantly focused on fictional\nand entertainment problems - such as games. Based on the above, this work aims\nto shed light on the application of reinforcement learning to solve this\nrelevant real-world problem, the genome assembly. By expanding the only\napproach found in the literature that addresses this problem, we carefully\nexplored the aspects of intelligent agent learning, performed by the Q-learning\nalgorithm, to understand its suitability to be applied in scenarios whose\ncharacteristics are more similar to those faced by real genome projects. The\nimprovements proposed here include changing the previously proposed reward\nsystem and including state space exploration optimization strategies based on\ndynamic pruning and mutual collaboration with evolutionary computing. These\ninvestigations were tried on 23 new environments with larger inputs than those\nused previously. All these environments are freely available on the internet\nfor the evolution of this research by the scientific community. The results\nsuggest consistent performance progress using the proposed improvements,\nhowever, they also demonstrate the limitations of them, especially related to\nthe high dimensionality of state and action spaces. We also present, later, the\npaths that can be traced to tackle genome assembly efficiently in real\nscenarios considering recent, successfully reinforcement learning applications\n- including deep reinforcement learning - from other domains dealing with\nhigh-dimensional inputs.",
          "link": "http://arxiv.org/abs/2102.02649",
          "publishedOn": "2021-06-11T01:42:15.993Z",
          "wordCount": 694,
          "title": "A step towards a reinforcement learning de novo genome assembler. (arXiv:2102.02649v2 [q-bio.GN] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.07018",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Stadler_T/0/1/0/all/0/1\">Theresa Stadler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oprisanu_B/0/1/0/all/0/1\">Bristena Oprisanu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Troncoso_C/0/1/0/all/0/1\">Carmela Troncoso</a>",
          "description": "Synthetic data has been advertised as a silver-bullet solution to\nprivacy-preserving data publishing that addresses the shortcomings of\ntraditional anonymisation techniques. The promise is that synthetic data drawn\nfrom generative models preserves the statistical properties of the original\ndataset but, at the same time, provides perfect protection against privacy\nattacks. In this work, we present the first quantitative evaluation of the\nprivacy gain of synthetic data publishing and compare it to that of previous\nanonymisation techniques.\n\nOur evaluation of a wide range of state-of-the-art generative models\ndemonstrates that synthetic data either does not prevent inference attacks or\ndoes not retain data utility. In other words, we empirically show that\nsynthetic data suffers from the same limitations as traditional anonymisation\ntechniques.\n\nFurthermore, we find that, in contrast to traditional anonymisation, the\nprivacy-utility tradeoff of synthetic data publishing is hard to predict.\nBecause it is impossible to predict what signals a synthetic dataset will\npreserve and what information will be lost, synthetic data leads to a highly\nvariable privacy gain and unpredictable utility loss. In summary, we find that\nsynthetic data is far from the holy grail of privacy-preserving data\npublishing.",
          "link": "http://arxiv.org/abs/2011.07018",
          "publishedOn": "2021-06-11T01:42:15.982Z",
          "wordCount": 653,
          "title": "Synthetic Data -- Anonymisation Groundhog Day. (arXiv:2011.07018v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05858",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1\">Zhuo Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hao Wang</a>",
          "description": "The wide adoption of smart meters makes residential load data available and\nthus improves the understanding of the energy consumption behavior. Many\nexisting studies have focused on smart-meter data analysis, but the drivers of\nenergy consumption behaviors are not well understood. This paper aims to\ncharacterize and estimate users' load patterns based on their demographic and\nsocioeconomic information. We adopt the symbolic aggregate approximation (SAX)\nmethod to process the load data and use the K-Means method to extract key load\npatterns. We develop a deep neural network (DNN) to analyze the relationship\nbetween users' load patterns and their demographic and socioeconomic features.\nUsing real-world load data, we validate our framework and demonstrate the\nconnections between load patterns and household demographic and socioeconomic\nfeatures. We also take two regression models as benchmarks for comparisons.",
          "link": "http://arxiv.org/abs/2106.05858",
          "publishedOn": "2021-06-11T01:42:15.934Z",
          "wordCount": 569,
          "title": "Characterizing Residential Load Patterns by Household Demographic and Socioeconomic Factors. (arXiv:2106.05858v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05931",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Vahdat_A/0/1/0/all/0/1\">Arash Vahdat</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kreis_K/0/1/0/all/0/1\">Karsten Kreis</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kautz_J/0/1/0/all/0/1\">Jan Kautz</a>",
          "description": "Score-based generative models (SGMs) have recently demonstrated impressive\nresults in terms of both sample quality and distribution coverage. However,\nthey are usually applied directly in data space and often require thousands of\nnetwork evaluations for sampling. Here, we propose the Latent Score-based\nGenerative Model (LSGM), a novel approach that trains SGMs in a latent space,\nrelying on the variational autoencoder framework. Moving from data to latent\nspace allows us to train more expressive generative models, apply SGMs to\nnon-continuous data, and learn smoother SGMs in a smaller space, resulting in\nfewer network evaluations and faster sampling. To enable training LSGMs\nend-to-end in a scalable and stable manner, we (i) introduce a new\nscore-matching objective suitable to the LSGM setting, (ii) propose a novel\nparameterization of the score function that allows SGM to focus on the mismatch\nof the target distribution with respect to a simple Normal one, and (iii)\nanalytically derive multiple techniques for variance reduction of the training\nobjective. LSGM obtains a state-of-the-art FID score of 2.10 on CIFAR-10,\noutperforming all existing generative results on this dataset. On\nCelebA-HQ-256, LSGM is on a par with previous SGMs in sample quality while\noutperforming them in sampling time by two orders of magnitude. In modeling\nbinary images, LSGM achieves state-of-the-art likelihood on the binarized\nOMNIGLOT dataset.",
          "link": "http://arxiv.org/abs/2106.05931",
          "publishedOn": "2021-06-11T01:42:15.927Z",
          "wordCount": 637,
          "title": "Score-based Generative Modeling in Latent Space. (arXiv:2106.05931v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05850",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wang_J/0/1/0/all/0/1\">Jiayi Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wong_R/0/1/0/all/0/1\">Raymond K. W. Wong</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mao_X/0/1/0/all/0/1\">Xiaojun Mao</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chan_K/0/1/0/all/0/1\">Kwun Chuen Gary Chan</a>",
          "description": "In this paper, we propose a novel method for matrix completion under general\nnon-uniform missing structures. By controlling an upper bound of a novel\nbalancing error, we construct weights that can actively adjust for the\nnon-uniformity in the empirical risk without explicitly modeling the\nobservation probabilities, and can be computed efficiently via convex\noptimization. The recovered matrix based on the proposed weighted empirical\nrisk enjoys appealing theoretical guarantees. In particular, the proposed\nmethod achieves a stronger guarantee than existing work in terms of the scaling\nwith respect to the observation probabilities, under asymptotically\nheterogeneous missing settings (where entry-wise observation probabilities can\nbe of different orders). These settings can be regarded as a better theoretical\nmodel of missing patterns with highly varying probabilities. We also provide a\nnew minimax lower bound under a class of heterogeneous settings. Numerical\nexperiments are also provided to demonstrate the effectiveness of the proposed\nmethod.",
          "link": "http://arxiv.org/abs/2106.05850",
          "publishedOn": "2021-06-11T01:42:15.900Z",
          "wordCount": 597,
          "title": "Matrix Completion with Model-free Weighting. (arXiv:2106.05850v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05863",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meng_X/0/1/0/all/0/1\">Xuhui Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Liu Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_Z/0/1/0/all/0/1\">Zhiping Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferrandis_J/0/1/0/all/0/1\">Jose del Aguila Ferrandis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karniadakis_G/0/1/0/all/0/1\">George Em Karniadakis</a>",
          "description": "We develop a new Bayesian framework based on deep neural networks to be able\nto extrapolate in space-time using historical data and to quantify\nuncertainties arising from both noisy and gappy data in physical problems.\nSpecifically, the proposed approach has two stages: (1) prior learning and (2)\nposterior estimation. At the first stage, we employ the physics-informed\nGenerative Adversarial Networks (PI-GAN) to learn a functional prior either\nfrom a prescribed function distribution, e.g., Gaussian process, or from\nhistorical data and physics. At the second stage, we employ the Hamiltonian\nMonte Carlo (HMC) method to estimate the posterior in the latent space of\nPI-GANs. In addition, we use two different approaches to encode the physics:\n(1) automatic differentiation, used in the physics-informed neural networks\n(PINNs) for scenarios with explicitly known partial differential equations\n(PDEs), and (2) operator regression using the deep operator network (DeepONet)\nfor PDE-agnostic scenarios. We then test the proposed method for (1)\nmeta-learning for one-dimensional regression, and forward/inverse PDE problems\n(combined with PINNs); (2) PDE-agnostic physical problems (combined with\nDeepONet), e.g., fractional diffusion as well as saturated stochastic\n(100-dimensional) flows in heterogeneous porous media; and (3) spatial-temporal\nregression problems, i.e., inference of a marine riser displacement field. The\nresults demonstrate that the proposed approach can provide accurate predictions\nas well as uncertainty quantification given very limited scattered and noisy\ndata, since historical data could be available to provide informative priors.\nIn summary, the proposed method is capable of learning flexible functional\npriors, and can be extended to big data problems using stochastic HMC or\nnormalizing flows since the latent space is generally characterized as low\ndimensional.",
          "link": "http://arxiv.org/abs/2106.05863",
          "publishedOn": "2021-06-11T01:42:15.894Z",
          "wordCount": 698,
          "title": "Learning Functional Priors and Posteriors from Data and Physics. (arXiv:2106.05863v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2104.13621",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ginart_A/0/1/0/all/0/1\">Antonio Ginart</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Martin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1\">James Zou</a>",
          "description": "Post-deployment monitoring of the performance of ML systems is critical for\nensuring reliability, especially as new user inputs can differ from the\ntraining distribution. Here we propose a novel approach, MLDemon, for ML\nDEployment MONitoring. MLDemon integrates both unlabeled features and a small\namount of on-demand labeled examples over time to produce a real-time estimate\nof the ML model's current performance on a given data stream. Subject to budget\nconstraints, MLDemon decides when to acquire additional, potentially costly,\nsupervised labels to verify the model. On temporal datasets with diverse\ndistribution drifts and models, MLDemon substantially outperforms existing\nmonitoring approaches. Moreover, we provide theoretical analysis to show that\nMLDemon is minimax rate optimal up to logarithmic factors and is provably\nrobust against broad distribution drifts whereas prior approaches are not.",
          "link": "http://arxiv.org/abs/2104.13621",
          "publishedOn": "2021-06-11T01:42:15.883Z",
          "wordCount": 598,
          "title": "MLDemon: Deployment Monitoring for Machine Learning Systems. (arXiv:2104.13621v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05701",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiying Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuzhao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1\">Xi Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_R/0/1/0/all/0/1\">Runiu Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_S/0/1/0/all/0/1\">Shu-Tao Xia</a>",
          "description": "HyperGraph Convolutional Neural Networks (HGCNNs) have demonstrated their\npotential in modeling high-order relations preserved in graph structured data.\nHowever, most existing convolution filters are localized and determined by the\npre-defined initial hypergraph topology, neglecting to explore implicit and\nlong-ange relations in real-world data. In this paper, we propose the first\nlearning-based method tailored for constructing adaptive hypergraph structure,\ntermed HypERgrAph Laplacian aDaptor (HERALD), which serves as a generic\nplug-in-play module for improving the representational power of HGCNNs.\nSpecifically, HERALD adaptively optimizes the adjacency relationship between\nhypernodes and hyperedges in an end-to-end manner and thus the task-aware\nhypergraph is learned. Furthermore, HERALD employs the self-attention mechanism\nto capture the non-local paired-nodes relation. Extensive experiments on\nvarious popular hypergraph datasets for node classification and graph\nclassification tasks demonstrate that our approach obtains consistent and\nconsiderable performance enhancement, proving its effectiveness and\ngeneralization ability.",
          "link": "http://arxiv.org/abs/2106.05701",
          "publishedOn": "2021-06-11T01:42:15.867Z",
          "wordCount": 567,
          "title": "Learnable Hypergraph Laplacian for Hypergraph Learning. (arXiv:2106.05701v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05838",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Meng_C/0/1/0/all/0/1\">Cheng Meng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ke_Y/0/1/0/all/0/1\">Yuan Ke</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_J/0/1/0/all/0/1\">Jingyi Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_M/0/1/0/all/0/1\">Mengrui Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhong_W/0/1/0/all/0/1\">Wenxuan Zhong</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ma_P/0/1/0/all/0/1\">Ping Ma</a>",
          "description": "This paper studies the estimation of large-scale optimal transport maps\n(OTM), which is a well-known challenging problem owing to the curse of\ndimensionality. Existing literature approximates the large-scale OTM by a\nseries of one-dimensional OTM problems through iterative random projection.\nSuch methods, however, suffer from slow or none convergence in practice due to\nthe nature of randomly selected projection directions. Instead, we propose an\nestimation method of large-scale OTM by combining the idea of projection\npursuit regression and sufficient dimension reduction. The proposed method,\nnamed projection pursuit Monge map (PPMM), adaptively selects the most\n``informative'' projection direction in each iteration. We theoretically show\nthe proposed dimension reduction method can consistently estimate the most\n``informative'' projection direction in each iteration. Furthermore, the PPMM\nalgorithm weakly convergences to the target large-scale OTM in a reasonable\nnumber of steps. Empirically, PPMM is computationally easy and converges fast.\nWe assess its finite sample performance through the applications of Wasserstein\ndistance estimation and generative models.",
          "link": "http://arxiv.org/abs/2106.05838",
          "publishedOn": "2021-06-11T01:42:15.861Z",
          "wordCount": 629,
          "title": "Large-scale optimal transport map estimation using projection pursuit. (arXiv:2106.05838v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2009.07601",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Smith_A/0/1/0/all/0/1\">Alistair W. R. Smith</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Gray_J/0/1/0/all/0/1\">Johnnie Gray</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Kim_M/0/1/0/all/0/1\">M. S. Kim</a>",
          "description": "We use a meta-learning neural-network approach to analyse data from a\nmeasured quantum state. Once our neural network has been trained it can be used\nto efficiently sample measurements of the state in measurement bases not\ncontained in the training data. These samples can be used calculate expectation\nvalues and other useful quantities. We refer to this process as \"state sample\ntomography\". We encode the state's measurement outcome distributions using an\nefficiently parameterized generative neural network. This allows each stage in\nthe tomography process to be performed efficiently even for large systems. Our\nscheme is demonstrated on recent IBM Quantum devices, producing a model for a\n6-qubit state's measurement outcomes with a predictive accuracy (classical\nfidelity) > 95% for all test cases using only 100 random measurement settings\nas opposed to the 729 settings required for standard full tomography using\nlocal measurements. This reduction in the required number of measurements\nscales favourably, with training data in 200 measurement settings yielding a\npredictive accuracy > 92% for a 10 qubit state where 59,049 settings are\ntypically required for full local measurement-based quantum state tomography. A\nreduction in number of measurements by a factor, in this case, of almost 600\ncould allow for estimations of expectation values and state fidelities in\npracticable times on current quantum devices.",
          "link": "http://arxiv.org/abs/2009.07601",
          "publishedOn": "2021-06-11T01:42:15.855Z",
          "wordCount": 669,
          "title": "Efficient Quantum State Sample Tomography with Basis-dependent Neural-networks. (arXiv:2009.07601v3 [quant-ph] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.14313",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kloss_A/0/1/0/all/0/1\">Alina Kloss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martius_G/0/1/0/all/0/1\">Georg Martius</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bohg_J/0/1/0/all/0/1\">Jeannette Bohg</a>",
          "description": "In many robotic applications, it is crucial to maintain a belief about the\nstate of a system, which serves as input for planning and decision making and\nprovides feedback during task execution. Bayesian Filtering algorithms address\nthis state estimation problem, but they require models of process dynamics and\nsensory observations and the respective noise characteristics of these models.\nRecently, multiple works have demonstrated that these models can be learned by\nend-to-end training through differentiable versions of recursive filtering\nalgorithms. In this work, we investigate the advantages of differentiable\nfilters (DFs) over both unstructured learning approaches and manually-tuned\nfiltering algorithms, and provide practical guidance to researchers interested\nin applying such differentiable filters. For this, we implement DFs with four\ndifferent underlying filtering algorithms and compare them in extensive\nexperiments. Specifically, we (i) evaluate different implementation choices and\ntraining approaches, (ii) investigate how well complex models of uncertainty\ncan be learned in DFs, (iii) evaluate the effect of end-to-end training through\nDFs and (iv) compare the DFs among each other and to unstructured LSTM models.",
          "link": "http://arxiv.org/abs/2012.14313",
          "publishedOn": "2021-06-11T01:42:15.846Z",
          "wordCount": 628,
          "title": "How to Train Your Differentiable Filter. (arXiv:2012.14313v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05859",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wong_J/0/1/0/all/0/1\">Justin Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Damjakob_D/0/1/0/all/0/1\">Dominik Damjakob</a>",
          "description": "We explore the usage of meta-learning to derive the causal direction between\nvariables by optimizing over a measure of distribution simplicity. We\nincorporate a stochastic graph representation which includes latent variables\nand allows for more generalizability and graph structure expression. Our model\nis able to learn causal direction indicators for complex graph structures\ndespite effects of latent confounders. Further, we explore robustness of our\nmethod with respect to violations of our distributional assumptions and data\nscarcity. Our model is particularly robust to modest data scarcity, but is less\nrobust to distributional changes. By interpreting the model predictions as\nstochastic events, we propose a simple ensemble method classifier to reduce the\noutcome variability as an average of biased events. This methodology\ndemonstrates ability to infer the existence as well as the direction of a\ncausal relationship between data distributions.",
          "link": "http://arxiv.org/abs/2106.05859",
          "publishedOn": "2021-06-11T01:42:15.820Z",
          "wordCount": 563,
          "title": "A Meta Learning Approach to Discerning Causal Graph Structure. (arXiv:2106.05859v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2104.11353",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1\">Avik Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_L/0/1/0/all/0/1\">Lawrence Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brown_D/0/1/0/all/0/1\">Daniel S. Brown</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dragan_A/0/1/0/all/0/1\">Anca D. Dragan</a>",
          "description": "Many robotics domains use some form of nonconvex model predictive control\n(MPC) for planning, which sets a reduced time horizon, performs trajectory\noptimization, and replans at every step. The actual task typically requires a\nmuch longer horizon than is computationally tractable, and is specified via a\ncost function that cumulates over that full horizon. For instance, an\nautonomous car may have a cost function that makes a desired trade-off between\nefficiency, safety, and obeying traffic laws. In this work, we challenge the\ncommon assumption that the cost we optimize using MPC should be the same as the\nground truth cost for the task (plus a terminal cost). MPC solvers can suffer\nfrom short planning horizons, local optima, incorrect dynamics models, and,\nimportantly, fail to account for future replanning ability. Thus, we propose\nthat in many tasks it could be beneficial to purposefully choose a different\ncost function for MPC to optimize: one that results in the MPC rollout having\nlow ground truth cost, rather than the MPC planned trajectory. We formalize\nthis as an optimal cost design problem, and propose a zeroth-order\noptimization-based approach that enables us to design optimal costs for an MPC\nplanning robot in continuous MDPs. We test our approach in an autonomous\ndriving domain where we find costs different from the ground truth that\nimplicitly compensate for replanning, short horizon, incorrect dynamics models,\nand local minima issues. As an example, the learned cost incentivizes MPC to\ndelay its decision until later, implicitly accounting for the fact that it will\nget more information in the future and be able to make a better decision. Code\nand videos available at https://sites.google.com/berkeley.edu/ocd-mpc/.",
          "link": "http://arxiv.org/abs/2104.11353",
          "publishedOn": "2021-06-11T01:42:15.808Z",
          "wordCount": 752,
          "title": "Optimal Cost Design for Model Predictive Control. (arXiv:2104.11353v2 [cs.RO] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05802",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yifan Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Haobin Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1\">Zongqing Lu</a>",
          "description": "In multi-agent reinforcement learning, the inherent non-stationarity of the\nenvironment caused by other agents' actions posed significant difficulties for\nan agent to learn a good policy independently. One way to deal with\nnon-stationarity is agent modeling, by which the agent takes into consideration\nthe influence of other agents' policies. Most existing work relies on\npredicting other agents' actions or goals, or discriminating between their\npolicies. However, such modeling fails to capture the similarities and\ndifferences between policies simultaneously and thus cannot provide useful\ninformation when generalizing to unseen policies. To address this, we propose a\ngeneral method to learn representations of other agents' policies via the\njoint-action distributions sampled in interactions. The similarities and\ndifferences between policies are naturally captured by the policy distance\ninferred from the joint-action distributions and deliberately reflected in the\nlearned representations. Agents conditioned on the policy representations can\nwell generalize to unseen agents. We empirically demonstrate that our method\noutperforms existing work in multi-agent tasks when facing unseen agents.",
          "link": "http://arxiv.org/abs/2106.05802",
          "publishedOn": "2021-06-11T01:42:15.802Z",
          "wordCount": 597,
          "title": "Informative Policy Representations in Multi-Agent Reinforcement Learning via Joint-Action Distributions. (arXiv:2106.05802v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.03835",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_R/0/1/0/all/0/1\">Ruian Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morris_Q/0/1/0/all/0/1\">Quaid Morris</a>",
          "description": "Smooth dynamics interrupted by discontinuities are known as hybrid systems\nand arise commonly in nature. Latent ODEs allow for powerful representation of\nirregularly sampled time series but are not designed to capture trajectories\narising from hybrid systems. Here, we propose the Latent Segmented ODE\n(LatSegODE), which uses Latent ODEs to perform reconstruction and changepoint\ndetection within hybrid trajectories featuring jump discontinuities and\nswitching dynamical modes. Where it is possible to train a Latent ODE on the\nsmooth dynamical flows between discontinuities, we apply the pruned exact\nlinear time (PELT) algorithm to detect changepoints where latent dynamics\nrestart, thereby maximizing the joint probability of a piece-wise continuous\nlatent dynamical representation. We propose usage of the marginal likelihood as\na score function for PELT, circumventing the need for model complexity-based\npenalization. The LatSegODE outperforms baselines in reconstructive and\nsegmentation tasks including synthetic data sets of sine waves, Lotka Volterra\ndynamics, and UCI Character Trajectories.",
          "link": "http://arxiv.org/abs/2105.03835",
          "publishedOn": "2021-06-11T01:42:15.796Z",
          "wordCount": 594,
          "title": "Segmenting Hybrid Trajectories using Latent ODEs. (arXiv:2105.03835v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05795",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+dAscoli_S/0/1/0/all/0/1\">St&#xe9;phane d&#x27;Ascoli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sagun_L/0/1/0/all/0/1\">Levent Sagun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biroli_G/0/1/0/all/0/1\">Giulio Biroli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morcos_A/0/1/0/all/0/1\">Ari Morcos</a>",
          "description": "Vision Transformers (ViT) have recently emerged as a powerful alternative to\nconvolutional networks (CNNs). Although hybrid models attempt to bridge the gap\nbetween these two architectures, the self-attention layers they rely on induce\na strong computational bottleneck, especially at large spatial resolutions. In\nthis work, we explore the idea of reducing the time spent training these layers\nby initializing them as convolutional layers. This enables us to transition\nsmoothly from any pre-trained CNN to its functionally identical hybrid model,\ncalled Transformed CNN (T-CNN). With only 50 epochs of fine-tuning, the\nresulting T-CNNs demonstrate significant performance gains over the CNN (+2.2%\ntop-1 on ImageNet-1k for a ResNet50-RS) as well as substantially improved\nrobustness (+11% top-1 on ImageNet-C). We analyze the representations learnt by\nthe T-CNN, providing deeper insights into the fruitful interplay between\nconvolutions and self-attention. Finally, we experiment initializing the T-CNN\nfrom a partially trained CNN, and find that it reaches better performance than\nthe corresponding hybrid model trained from scratch, while reducing training\ntime.",
          "link": "http://arxiv.org/abs/2106.05795",
          "publishedOn": "2021-06-11T01:42:15.790Z",
          "wordCount": 588,
          "title": "Transformed CNNs: recasting pre-trained convolutional layers with self-attention. (arXiv:2106.05795v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05834",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sorba_O/0/1/0/all/0/1\">Olivier Sorba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geissler_C/0/1/0/all/0/1\">C Geissler</a>",
          "description": "The aim of the present study is to detect abrupt trend changes in the mean of\na multidimensional sequential signal. Directly inspired by papers of Fernhead\nand Liu ([4] and [5]), this work describes the signal in a hierarchical manner\n: the change dates of a time segmentation process trigger the renewal of a\npiece-wise constant emission law. Bayesian posterior information on the change\ndates and emission parameters is obtained. These estimations can be revised\nonline, i.e. as new data arrive. This paper proposes explicit formulations\ncorresponding to various emission laws, as well as a generalization to the case\nwhere only partially observed data are available. Practical applications\ninclude the returns of partially observed multi-asset investment strategies,\nwhen only scant prior knowledge of the movers of the returns is at hand,\nlimited to some statistical assumptions. This situation is different from the\nstudy of trend changes in the returns of individual assets, where fundamental\nexogenous information (news, earnings announcements, controversies, etc.) can\nbe used.",
          "link": "http://arxiv.org/abs/2106.05834",
          "publishedOn": "2021-06-11T01:42:15.773Z",
          "wordCount": 594,
          "title": "Online Bayesian inference for multiple changepoints and risk assessment. (arXiv:2106.05834v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.08259",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_B/0/1/0/all/0/1\">Bo Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bilen_H/0/1/0/all/0/1\">Hakan Bilen</a>",
          "description": "In many machine learning problems, large-scale datasets have become the\nde-facto standard to train state-of-the-art deep networks at the price of heavy\ncomputation load. In this paper, we focus on condensing large training sets\ninto significantly smaller synthetic sets which can be used to train deep\nneural networks from scratch with minimum drop in performance. Inspired from\nthe recent training set synthesis methods, we propose Differentiable Siamese\nAugmentation that enables effective use of data augmentation to synthesize more\ninformative synthetic images and thus achieves better performance when training\nnetworks with augmentations. Experiments on multiple image classification\nbenchmarks demonstrate that the proposed method obtains substantial gains over\nthe state-of-the-art, 7% improvements on CIFAR10 and CIFAR100 datasets. We show\nwith only less than 1% data that our method achieves 99.6%, 94.9%, 88.5%, 71.5%\nrelative performance on MNIST, FashionMNIST, SVHN, CIFAR10 respectively. We\nalso explore the use of our method in continual learning and neural\narchitecture search, and show promising results.",
          "link": "http://arxiv.org/abs/2102.08259",
          "publishedOn": "2021-06-11T01:42:15.768Z",
          "wordCount": 615,
          "title": "Dataset Condensation with Differentiable Siamese Augmentation. (arXiv:2102.08259v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02029",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhan_R/0/1/0/all/0/1\">Ruohan Zhan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hadad_V/0/1/0/all/0/1\">Vitor Hadad</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hirshberg_D/0/1/0/all/0/1\">David A. Hirshberg</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Athey_S/0/1/0/all/0/1\">Susan Athey</a>",
          "description": "It has become increasingly common for data to be collected adaptively, for\nexample using contextual bandits. Historical data of this type can be used to\nevaluate other treatment assignment policies to guide future innovation or\nexperiments. However, policy evaluation is challenging if the target policy\ndiffers from the one used to collect data, and popular estimators, including\ndoubly robust (DR) estimators, can be plagued by bias, excessive variance, or\nboth. In particular, when the pattern of treatment assignment in the collected\ndata looks little like the pattern generated by the policy to be evaluated, the\nimportance weights used in DR estimators explode, leading to excessive\nvariance.\n\nIn this paper, we improve the DR estimator by adaptively weighting\nobservations to control its variance. We show that a t-statistic based on our\nimproved estimator is asymptotically normal under certain conditions, allowing\nus to form confidence intervals and test hypotheses. Using synthetic data and\npublic benchmarks, we provide empirical evidence for our estimator's improved\naccuracy and inferential properties relative to existing alternatives.",
          "link": "http://arxiv.org/abs/2106.02029",
          "publishedOn": "2021-06-11T01:42:15.762Z",
          "wordCount": 622,
          "title": "Off-Policy Evaluation via Adaptive Weighting with Data from Contextual Bandits. (arXiv:2106.02029v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05748",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ren_C/0/1/0/all/0/1\">Chao Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dulay_J/0/1/0/all/0/1\">Justin Dulay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rolwes_G/0/1/0/all/0/1\">Gregory Rolwes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pauli_D/0/1/0/all/0/1\">Duke Pauli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shakoor_N/0/1/0/all/0/1\">Nadia Shakoor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stylianou_A/0/1/0/all/0/1\">Abby Stylianou</a>",
          "description": "Automated high throughput plant phenotyping involves leveraging sensors, such\nas RGB, thermal and hyperspectral cameras (among others), to make large scale\nand rapid measurements of the physical properties of plants for the purpose of\nbetter understanding the difference between crops and facilitating rapid plant\nbreeding programs. One of the most basic phenotyping tasks is to determine the\ncultivar, or species, in a particular sensor product. This simple phenotype can\nbe used to detect errors in planting and to learn the most differentiating\nfeatures between cultivars. It is also a challenging visual recognition task,\nas a large number of highly related crops are grown simultaneously, leading to\na classification problem with low inter-class variance. In this paper, we\nintroduce the Sorghum-100 dataset, a large dataset of RGB imagery of sorghum\ncaptured by a state-of-the-art gantry system, a multi-resolution network\narchitecture that learns both global and fine-grained features on the crops,\nand a new global pooling strategy called Dynamic Outlier Pooling which\noutperforms standard global pooling strategies on this task.",
          "link": "http://arxiv.org/abs/2106.05748",
          "publishedOn": "2021-06-11T01:42:15.756Z",
          "wordCount": 607,
          "title": "Multi-resolution Outlier Pooling for Sorghum Classification. (arXiv:2106.05748v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05722",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Fresca_S/0/1/0/all/0/1\">Stefania Fresca</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Manzoni_A/0/1/0/all/0/1\">Andrea Manzoni</a>",
          "description": "Simulating fluid flows in different virtual scenarios is of key importance in\nengineering applications. However, high-fidelity, full-order models relying,\ne.g., on the finite element method, are unaffordable whenever fluid flows must\nbe simulated in almost real-time. Reduced order models (ROMs) relying, e.g., on\nproper orthogonal decomposition (POD) provide reliable approximations to\nparameter-dependent fluid dynamics problems in rapid times. However, they might\nrequire expensive hyper-reduction strategies for handling parameterized\nnonlinear terms, and enriched reduced spaces (or Petrov-Galerkin projections)\nif a mixed velocity-pressure formulation is considered, possibly hampering the\nevaluation of reliable solutions in real-time. Dealing with fluid-structure\ninteractions entails even higher difficulties. The proposed deep learning\n(DL)-based ROMs overcome all these limitations by learning in a non-intrusive\nway both the nonlinear trial manifold and the reduced dynamics. To do so, they\nrely on deep neural networks, after performing a former dimensionality\nreduction through POD enhancing their training times substantially. The\nresulting POD-DL-ROMs are shown to provide accurate results in almost real-time\nfor the flow around a cylinder benchmark, the fluid-structure interaction\nbetween an elastic beam attached to a fixed, rigid block and a laminar\nincompressible flow, and the blood flow in a cerebral aneurysm.",
          "link": "http://arxiv.org/abs/2106.05722",
          "publishedOn": "2021-06-11T01:42:15.750Z",
          "wordCount": 641,
          "title": "Real-time simulation of parameter-dependent fluid flows through deep learning-based reduced order models. (arXiv:2106.05722v1 [physics.flu-dyn])"
        },
        {
          "id": "http://arxiv.org/abs/2103.04847",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gisslen_L/0/1/0/all/0/1\">Linus Gissl&#xe9;n</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eakins_A/0/1/0/all/0/1\">Andy Eakins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gordillo_C/0/1/0/all/0/1\">Camilo Gordillo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bergdahl_J/0/1/0/all/0/1\">Joakim Bergdahl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tollmar_K/0/1/0/all/0/1\">Konrad Tollmar</a>",
          "description": "We present a new approach ARLPCG: Adversarial Reinforcement Learning for\nProcedural Content Generation, which procedurally generates and tests\npreviously unseen environments with an auxiliary input as a control variable.\nTraining RL agents over novel environments is a notoriously difficult task. One\npopular approach is to procedurally generate different environments to increase\nthe generalizability of the trained agents. ARLPCG instead deploys an\nadversarial model with one PCG RL agent (called Generator) and one solving RL\nagent (called Solver). The Generator receives a reward signal based on the\nSolver's performance, which encourages the environment design to be challenging\nbut not impossible. To further drive diversity and control of the environment\ngeneration, we propose using auxiliary inputs for the Generator. The benefit is\ntwo-fold: Firstly, the Solver achieves better generalization through the\nGenerator's generated challenges. Secondly, the trained Generator can be used\nas a creator of novel environments that, together with the Solver, can be shown\nto be solvable. We create two types of 3D environments to validate our model,\nrepresenting two popular game genres: a third-person platformer and a racing\ngame. In these cases, we shows that ARLPCG has a significantly better solve\nratio, and that the auxiliary inputs renders the levels creation controllable\nto a certain degree. For a video compilation of the results please visit\nhttps://youtu.be/z7q2PtVsT0I.",
          "link": "http://arxiv.org/abs/2103.04847",
          "publishedOn": "2021-06-11T01:42:15.733Z",
          "wordCount": 680,
          "title": "Adversarial Reinforcement Learning for Procedural Content Generation. (arXiv:2103.04847v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05737",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Guo_Y/0/1/0/all/0/1\">Yang Guo</a>, <a href=\"http://arxiv.org/find/math/1/au:+Anwar_T/0/1/0/all/0/1\">Tarique Anwar</a>, <a href=\"http://arxiv.org/find/math/1/au:+Yang_J/0/1/0/all/0/1\">Jian Yang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Wu_J/0/1/0/all/0/1\">Jia Wu</a>",
          "description": "With the rising demand of smart mobility, ride-hailing service is getting\npopular in the urban regions. These services maintain a system for serving the\nincoming trip requests by dispatching available vehicles to the pickup points.\nAs the process should be socially and economically profitable, the task of\nvehicle dispatching is highly challenging, specially due to the time-varying\ntravel demands and traffic conditions. Due to the uneven distribution of travel\ndemands, many idle vehicles could be generated during the operation in\ndifferent subareas. Most of the existing works on vehicle dispatching system,\ndesigned static relocation centers to relocate idle vehicles. However, as\ntraffic conditions and demand distribution dynamically change over time, the\nstatic solution can not fit the evolving situations. In this paper, we propose\na dynamic future demand aware vehicle dispatching system. It can dynamically\nsearch the relocation centers considering both travel demand and traffic\nconditions. We evaluate the system on real-world dataset, and compare with the\nexisting state-of-the-art methods in our experiments in terms of several\nstandard evaluation metrics and operation time. Through our experiments, we\ndemonstrate that the proposed system significantly improves the serving ratio\nand with a very small increase in operation cost.",
          "link": "http://arxiv.org/abs/2106.05737",
          "publishedOn": "2021-06-11T01:42:15.726Z",
          "wordCount": 636,
          "title": "dFDA-VeD: A Dynamic Future Demand Aware Vehicle Dispatching System. (arXiv:2106.05737v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05586",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Nabarro_S/0/1/0/all/0/1\">Seth Nabarro</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ganev_S/0/1/0/all/0/1\">Stoil Ganev</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Garriga_Alonso_A/0/1/0/all/0/1\">Adri&#xe0; Garriga-Alonso</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fortuin_V/0/1/0/all/0/1\">Vincent Fortuin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wilk_M/0/1/0/all/0/1\">Mark van der Wilk</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Aitchison_L/0/1/0/all/0/1\">Laurence Aitchison</a>",
          "description": "Data augmentation is a highly effective approach for improving performance in\ndeep neural networks. The standard view is that it creates an enlarged dataset\nby adding synthetic data, which raises a problem when combining it with\nBayesian inference: how much data are we really conditioning on? This question\nis particularly relevant to recent observations linking data augmentation to\nthe cold posterior effect. We investigate various principled ways of finding a\nlog-likelihood for augmented datasets. Our approach prescribes augmenting the\nsame underlying image multiple times, both at test and train-time, and\naveraging either the logits or the predictive probabilities. Empirically, we\nobserve the best performance with averaging probabilities. While there are\ninteractions with the cold posterior effect, neither averaging logits or\naveraging probabilities eliminates it.",
          "link": "http://arxiv.org/abs/2106.05586",
          "publishedOn": "2021-06-11T01:42:15.721Z",
          "wordCount": 564,
          "title": "Data augmentation in Bayesian neural networks and the cold posterior effect. (arXiv:2106.05586v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05565",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lang_Q/0/1/0/all/0/1\">Quanjun Lang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lu_F/0/1/0/all/0/1\">Fei Lu</a>",
          "description": "We study the identifiability of the interaction kernels in mean-field\nequations for intreacting particle systems. The key is to identify function\nspaces on which a probabilistic loss functional has a unique minimizer. We\nprove that identifiability holds on any subspace of two reproducing kernel\nHilbert spaces (RKHS), whose reproducing kernels are intrinsic to the system\nand are data-adaptive. Furthermore, identifiability holds on two ambient L2\nspaces if and only if the integral operators associated with the reproducing\nkernels are strictly positive. Thus, the inverse problem is ill-posed in\ngeneral. We also discuss the implications of identifiability in computational\npractice.",
          "link": "http://arxiv.org/abs/2106.05565",
          "publishedOn": "2021-06-11T01:42:15.715Z",
          "wordCount": 530,
          "title": "Identifiability of interaction kernels in mean-field equations of interacting particles. (arXiv:2106.05565v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2102.05020",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Zhan_X/0/1/0/all/0/1\">Xianghao Zhan</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Li_Y/0/1/0/all/0/1\">Yiheng Li</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Liu_Y/0/1/0/all/0/1\">Yuzhe Liu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Domel_A/0/1/0/all/0/1\">August G. Domel</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Alizadeh_H/0/1/0/all/0/1\">Hossein Vahid Alizadeh</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Zhou_Z/0/1/0/all/0/1\">Zhou Zhou</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Cecchi_N/0/1/0/all/0/1\">Nicholas J. Cecchi</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Raymond_S/0/1/0/all/0/1\">Samuel J. Raymond</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Tiernan_S/0/1/0/all/0/1\">Stephen Tiernan</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Ruan_J/0/1/0/all/0/1\">Jesse Ruan</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Barbat_S/0/1/0/all/0/1\">Saeed Barbat</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Gevaert_O/0/1/0/all/0/1\">Olivier Gevaert</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Zeineh_M/0/1/0/all/0/1\">Michael M. Zeineh</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Grant_G/0/1/0/all/0/1\">Gerald A. Grant</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Camarillo_D/0/1/0/all/0/1\">David B. Camarillo</a>",
          "description": "Brain tissue deformation resulting from head impacts is primarily caused by\nrotation and can lead to traumatic brain injury. To quantify brain injury risk\nbased on measurements of kinematics on the head, finite element (FE) models and\nvarious brain injury criteria based on different factors of these kinematics\nhave been developed, but the contribution of different kinematic factors has\nnot been comprehensively analyzed across different types of head impacts in a\ndata-driven manner. To better design brain injury criteria, the predictive\npower of rotational kinematics factors, which are different in 1) the\nderivative order (angular velocity, angular acceleration, angular jerk), 2) the\ndirection and 3) the power (e.g., square-rooted, squared, cubic) of the angular\nvelocity, were analyzed based on different datasets including laboratory\nimpacts, American football, mixed martial arts (MMA), NHTSA automobile\ncrashworthiness tests and NASCAR crash events. Ordinary least squares\nregressions were built from kinematics factors to the 95\\% maximum principal\nstrain (MPS95), and we compared zero-order correlation coefficients, structure\ncoefficients, commonality analysis, and dominance analysis. The angular\nacceleration, the magnitude, and the first power factors showed the highest\npredictive power for the majority of impacts including laboratory impacts,\nAmerican football impacts, with few exceptions (angular velocity for MMA and\nNASCAR impacts). The predictive power of rotational kinematics in three\ndirections (x: posterior-to-anterior, y: left-to-right, z:\nsuperior-to-inferior) of kinematics varied with different sports and types of\nhead impacts.",
          "link": "http://arxiv.org/abs/2102.05020",
          "publishedOn": "2021-06-11T01:42:15.710Z",
          "wordCount": 729,
          "title": "Predictive Factors of Kinematics in Traumatic Brain Injury from Head Impacts Based on Statistical Interpretation. (arXiv:2102.05020v3 [physics.bio-ph] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.00259",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Norouzi_S/0/1/0/all/0/1\">Sajad Norouzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_K/0/1/0/all/0/1\">Keyi Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yanshuai Cao</a>",
          "description": "Training datasets for semantic parsing are typically small due to the higher\nexpertise required for annotation than most other NLP tasks. As a result,\nmodels for this application usually need additional prior knowledge to be built\ninto the architecture or algorithm. The increased dependency on human experts\nhinders automation and raises the development and maintenance costs in\npractice. This work investigates whether a generic transformer-based seq2seq\nmodel can achieve competitive performance with minimal code-generation-specific\ninductive bias design. By exploiting a relatively sizeable monolingual corpus\nof the target programming language, which is cheap to mine from the web, we\nachieved 81.03% exact match accuracy on Django and 32.57 BLEU score on CoNaLa.\nBoth are SOTA to the best of our knowledge. This positive evidence highlights a\npotentially easier path toward building accurate semantic parsers in practice.",
          "link": "http://arxiv.org/abs/2101.00259",
          "publishedOn": "2021-06-11T01:42:15.694Z",
          "wordCount": 599,
          "title": "Code Generation from Natural Language with Less Prior and More Monolingual Data. (arXiv:2101.00259v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05476",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xingyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_K/0/1/0/all/0/1\">Kun Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Sibo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zengfeng Huang</a>",
          "description": "Node embedding learns a low-dimensional representation for each node in the\ngraph. Recent progress on node embedding shows that proximity matrix\nfactorization methods gain superb performance and scale to large graphs with\nmillions of nodes. Existing approaches first define a proximity matrix and then\nlearn the embeddings that fit the proximity by matrix factorization. Most\nexisting matrix factorization methods adopt the same proximity for different\ntasks, while it is observed that different tasks and datasets may require\ndifferent proximity, limiting their representation power.\n\nMotivated by this, we propose {\\em Lemane}, a framework with trainable\nproximity measures, which can be learned to best suit the datasets and tasks at\nhand automatically. Our method is end-to-end, which incorporates differentiable\nSVD in the pipeline so that the parameters can be trained via backpropagation.\nHowever, this learning process is still expensive on large graphs. To improve\nthe scalability, we train proximity measures only on carefully subsampled\ngraphs, and then apply standard proximity matrix factorization on the original\ngraph using the learned proximity. Note that, computing the learned proximities\nfor each pair is still expensive for large graphs, and existing techniques for\ncomputing proximities are not applicable to the learned proximities. Thus, we\npresent generalized push techniques to make our solution scalable to large\ngraphs with millions of nodes. Extensive experiments show that our proposed\nsolution outperforms existing solutions on both link prediction and node\nclassification tasks on almost all datasets.",
          "link": "http://arxiv.org/abs/2106.05476",
          "publishedOn": "2021-06-11T01:42:15.690Z",
          "wordCount": 667,
          "title": "Learning Based Proximity Matrix Factorization for Node Embedding. (arXiv:2106.05476v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2010.14535",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sukthanker_R/0/1/0/all/0/1\">Rhea Sanjay Sukthanker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhiwu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Suryansh Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Endsjo_E/0/1/0/all/0/1\">Erik Goron Endsjo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1\">Luc Van Gool</a>",
          "description": "In this paper, we propose a new neural architecture search (NAS) problem of\nSymmetric Positive Definite (SPD) manifold networks, aiming to automate the\ndesign of SPD neural architectures. To address this problem, we first introduce\na geometrically rich and diverse SPD neural architecture search space for an\nefficient SPD cell design. Further, we model our new NAS problem with a\none-shot training process of a single supernet. Based on the supernet modeling,\nwe exploit a differentiable NAS algorithm on our relaxed continuous search\nspace for SPD neural architecture search. Statistical evaluation of our method\non drone, action, and emotion recognition tasks mostly provides better results\nthan the state-of-the-art SPD networks and traditional NAS algorithms.\nEmpirical results show that our algorithm excels in discovering better\nperforming SPD network design and provides models that are more than three\ntimes lighter than searched by the state-of-the-art NAS algorithms.",
          "link": "http://arxiv.org/abs/2010.14535",
          "publishedOn": "2021-06-11T01:42:15.678Z",
          "wordCount": 637,
          "title": "Neural Architecture Search of SPD Manifold Networks. (arXiv:2010.14535v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.08399",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liutkus_A/0/1/0/all/0/1\">Antoine Liutkus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cifka_O/0/1/0/all/0/1\">Ond&#x159;ej C&#xed;fka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shih-Lun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simsekli_U/0/1/0/all/0/1\">Umut &#x15e;im&#x15f;ekli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yi-Hsuan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Richard_G/0/1/0/all/0/1\">Ga&#xeb;l Richard</a>",
          "description": "Recent advances in Transformer models allow for unprecedented sequence\nlengths, due to linear space and time complexity. In the meantime, relative\npositional encoding (RPE) was proposed as beneficial for classical Transformers\nand consists in exploiting lags instead of absolute positions for inference.\nStill, RPE is not available for the recent linear-variants of the Transformer,\nbecause it requires the explicit computation of the attention matrix, which is\nprecisely what is avoided by such methods. In this paper, we bridge this gap\nand present Stochastic Positional Encoding as a way to generate PE that can be\nused as a replacement to the classical additive (sinusoidal) PE and provably\nbehaves like RPE. The main theoretical contribution is to make a connection\nbetween positional encoding and cross-covariance structures of correlated\nGaussian processes. We illustrate the performance of our approach on the\nLong-Range Arena benchmark and on music generation.",
          "link": "http://arxiv.org/abs/2105.08399",
          "publishedOn": "2021-06-11T01:42:15.672Z",
          "wordCount": 630,
          "title": "Relative Positional Encoding for Transformers with Linear Complexity. (arXiv:2105.08399v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05490",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Dreifuerst_R/0/1/0/all/0/1\">Ryan Dreifuerst</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Heath_R/0/1/0/all/0/1\">Robert W. Heath Jr</a>",
          "description": "The detection and estimation of sinusoids is a fundamental signal processing\ntask for many applications related to sensing and communications. While\nalgorithms have been proposed for this setting, quantization is a critical, but\noften ignored modeling effect. In wireless communications, estimation with low\nresolution data converters is relevant for reduced power consumption in\nwideband receivers. Similarly, low resolution sampling in imaging and spectrum\nsensing allows for efficient data collection. In this work, we propose\nSignalNet, a neural network architecture that detects the number of sinusoids\nand estimates their parameters from quantized in-phase and quadrature samples.\nWe incorporate signal reconstruction internally as domain knowledge within the\nnetwork to enhance learning and surpass traditional algorithms in mean squared\nerror and Chamfer error. We introduce a worst-case learning threshold for\ncomparing the results of our network relative to the underlying data\ndistributions. This threshold provides insight into why neural networks tend to\noutperform traditional methods and into the learned relationships between the\ninput and output distributions. In simulation, we find that our algorithm is\nalways able to surpass the threshold for three-bit data but often cannot exceed\nthe threshold for one-bit data. We use the learning threshold to explain, in\nthe one-bit case, how our estimators learn to minimize the distributional loss,\nrather than learn features from the data.",
          "link": "http://arxiv.org/abs/2106.05490",
          "publishedOn": "2021-06-11T01:42:15.655Z",
          "wordCount": 655,
          "title": "SignalNet: A Low Resolution Sinusoid Decomposition and Estimation Network. (arXiv:2106.05490v1 [eess.SP])"
        },
        {
          "id": "http://arxiv.org/abs/2012.05329",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ulmer_D/0/1/0/all/0/1\">Dennis Ulmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cina_G/0/1/0/all/0/1\">Giovanni Cin&#xe0;</a>",
          "description": "A crucial requirement for reliable deployment of deep learning models for\nsafety-critical applications is the ability to identify out-of-distribution\n(OOD) data points, samples which differ from the training data and on which a\nmodel might underperform. Previous work has attempted to tackle this problem\nusing uncertainty estimation techniques. However, there is empirical evidence\nthat a large family of these techniques do not detect OOD reliably in\nclassification tasks.\n\nThis paper gives a theoretical explanation for said experimental findings and\nillustrates it on synthetic data. We prove that such techniques are not able to\nreliably identify OOD samples in a classification setting, since their level of\nconfidence is generalized to unseen areas of the feature space. This result\nstems from the interplay between the representation of ReLU networks as\npiece-wise affine transformations, the saturating nature of activation\nfunctions like softmax, and the most widely-used uncertainty metrics.",
          "link": "http://arxiv.org/abs/2012.05329",
          "publishedOn": "2021-06-11T01:42:15.649Z",
          "wordCount": 622,
          "title": "Know Your Limits: Uncertainty Estimation with ReLU Classifiers Fails at Reliable OOD Detection. (arXiv:2012.05329v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.00355",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yatong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jialu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>",
          "description": "Machine learning systems are often used in settings where individuals adapt\ntheir features to obtain a desired outcome. In such settings, strategic\nbehavior leads to a sharp loss in model performance in deployment. In this\nwork, we aim to address this problem by learning classifiers that encourage\ndecision subjects to change their features in a way that leads to improvement\nin both predicted \\emph{and} true outcome. We frame the dynamics of prediction\nand adaptation as a two-stage game, and characterize optimal strategies for the\nmodel designer and its decision subjects. In benchmarks on simulated and\nreal-world datasets, we find that classifiers trained using our method maintain\nthe accuracy of existing approaches while inducing higher levels of improvement\nand less manipulation.",
          "link": "http://arxiv.org/abs/2011.00355",
          "publishedOn": "2021-06-11T01:42:15.643Z",
          "wordCount": 579,
          "title": "Linear Classifiers that Encourage Constructive Adaptation. (arXiv:2011.00355v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05710",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Dupuis_B/0/1/0/all/0/1\">Benjamin Dupuis</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Jacot_A/0/1/0/all/0/1\">Arthur Jacot</a>",
          "description": "We study the SIMP method with a density field generated by a fully-connected\nneural network, taking the coordinates as inputs. In the large width limit, we\nshow that the use of DNNs leads to a filtering effect similar to traditional\nfiltering techniques for SIMP, with a filter described by the Neural Tangent\nKernel (NTK). This filter is however not invariant under translation, leading\nto visual artifacts and non-optimal shapes. We propose two embeddings of the\ninput coordinates, which lead to (approximate) spatial invariance of the NTK\nand of the filter. We empirically confirm our theoretical observations and\nstudy how the filter size is affected by the architecture of the network. Our\nsolution can easily be applied to any other coordinates-based generation\nmethod.",
          "link": "http://arxiv.org/abs/2106.05710",
          "publishedOn": "2021-06-11T01:42:15.638Z",
          "wordCount": 547,
          "title": "DNN-Based Topology Optimisation: Spatial Invariance and Neural Tangent Kernel. (arXiv:2106.05710v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05876",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moreau_H/0/1/0/all/0/1\">Hugues Moreau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vassilev_A/0/1/0/all/0/1\">Andr&#xe9;a Vassilev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Liming Chen</a>",
          "description": "In Transport Mode Detection, a great diversity of methodologies exist\naccording to the choice made on sensors, preprocessing, model used, etc. In\nthis domain, the comparisons between each option are not always complete.\nExperiments on a public, real-life dataset are led here to evaluate carefully\neach of the choices that were made, with a specific emphasis on data fusion\nmethods. Our most surprising finding is that none of the methods we implemented\nfrom the literature is better than a simple late fusion. Two important\ndecisions are the choice of a sensor and the choice of a representation for the\ndata: we found that using 2D convolutions on spectrograms with a logarithmic\naxis for the frequencies was better than 1-dimensional temporal\nrepresentations.",
          "link": "http://arxiv.org/abs/2106.05876",
          "publishedOn": "2021-06-11T01:42:15.632Z",
          "wordCount": 570,
          "title": "Data Fusion for Deep Learning on Transport Mode Detection: A Case Study. (arXiv:2106.05876v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05727",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Grupen_N/0/1/0/all/0/1\">Niko A. Grupen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Selman_B/0/1/0/all/0/1\">Bart Selman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Daniel D. Lee</a>",
          "description": "We study fairness through the lens of cooperative multi-agent learning. Our\nwork is motivated by empirical evidence that naive maximization of team reward\nyields unfair outcomes for individual team members. To address fairness in\nmulti-agent contexts, we introduce team fairness, a group-based fairness\nmeasure for multi-agent learning. We then incorporate team fairness into policy\noptimization -- introducing Fairness through Equivariance (Fair-E), a novel\nlearning strategy that achieves provably fair reward distributions. We then\nintroduce Fairness through Equivariance Regularization (Fair-ER) as a\nsoft-constraint version of Fair-E and show that Fair-ER reaches higher levels\nof utility than Fair-E and fairer outcomes than policies with no equivariance.\nFinally, we investigate the fairness-utility trade-off in multi-agent settings.",
          "link": "http://arxiv.org/abs/2106.05727",
          "publishedOn": "2021-06-11T01:42:15.617Z",
          "wordCount": 549,
          "title": "Fairness for Cooperative Multi-Agent Learning with Equivariant Policies. (arXiv:2106.05727v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05657",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kotyan_S/0/1/0/all/0/1\">Shashank Kotyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vargas_D/0/1/0/all/0/1\">Danilo Vasconcellos Vargas</a>",
          "description": "Adversarial algorithms have shown to be effective against neural networks for\na variety of tasks. Some adversarial algorithms perturb all the pixels in the\nimage minimally for the image classification task in image classification. In\ncontrast, some algorithms perturb few pixels strongly. However, very little\ninformation is available regarding why these adversarial samples so diverse\nfrom each other exist. Recently, Vargas et al. showed that the existence of\nthese adversarial samples might be due to conflicting saliency within the\nneural network. We test this hypothesis of conflicting saliency by analysing\nthe Saliency Maps (SM) and Gradient-weighted Class Activation Maps (Grad-CAM)\nof original and few different types of adversarial samples. We also analyse how\ndifferent adversarial samples distort the attention of the neural network\ncompared to original samples. We show that in the case of Pixel Attack,\nperturbed pixels either calls the network attention to themselves or divert the\nattention from them. Simultaneously, the Projected Gradient Descent Attack\nperturbs pixels so that intermediate layers inside the neural network lose\nattention for the correct class. We also show that both attacks affect the\nsaliency map and activation maps differently. Thus, shedding light on why some\ndefences successful against some attacks remain vulnerable against other\nattacks. We hope that this analysis will improve understanding of the existence\nand the effect of adversarial samples and enable the community to develop more\nrobust neural networks.",
          "link": "http://arxiv.org/abs/2106.05657",
          "publishedOn": "2021-06-11T01:42:15.600Z",
          "wordCount": 675,
          "title": "Deep neural network loses attention to adversarial images. (arXiv:2106.05657v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05738",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Cui_J/0/1/0/all/0/1\">Jingyi Cui</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hang_H/0/1/0/all/0/1\">Hanyuan Hang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1\">Yisen Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lin_Z/0/1/0/all/0/1\">Zhouchen Lin</a>",
          "description": "In this paper, we propose a density estimation algorithm called\n\\textit{Gradient Boosting Histogram Transform} (GBHT), where we adopt the\n\\textit{Negative Log Likelihood} as the loss function to make the boosting\nprocedure available for the unsupervised tasks. From a learning theory\nviewpoint, we first prove fast convergence rates for GBHT with the smoothness\nassumption that the underlying density function lies in the space\n$C^{0,\\alpha}$. Then when the target density function lies in spaces\n$C^{1,\\alpha}$, we present an upper bound for GBHT which is smaller than the\nlower bound of its corresponding base learner, in the sense of convergence\nrates. To the best of our knowledge, we make the first attempt to theoretically\nexplain why boosting can enhance the performance of its base learners for\ndensity estimation problems. In experiments, we not only conduct performance\ncomparisons with the widely used KDE, but also apply GBHT to anomaly detection\nto showcase a further application of GBHT.",
          "link": "http://arxiv.org/abs/2106.05738",
          "publishedOn": "2021-06-11T01:42:15.594Z",
          "wordCount": 592,
          "title": "GBHT: Gradient Boosting Histogram Transform for Density Estimation. (arXiv:2106.05738v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05680",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Salinas_D/0/1/0/all/0/1\">David Salinas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perrone_V/0/1/0/all/0/1\">Valerio Perrone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cruchant_O/0/1/0/all/0/1\">Olivier Cruchant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Archambeau_C/0/1/0/all/0/1\">Cedric Archambeau</a>",
          "description": "In addition to the best model architecture and hyperparameters, a full AutoML\nsolution requires selecting appropriate hardware automatically. This can be\nframed as a multi-objective optimization problem: there is not a single best\nhardware configuration but a set of optimal ones achieving different trade-offs\nbetween cost and runtime. In practice, some choices may be overly costly or\ntake days to train. To lift this burden, we adopt a multi-objective approach\nthat selects and adapts the hardware configuration automatically alongside\nneural architectures and their hyperparameters. Our method builds on Hyperband\nand extends it in two ways. First, we replace the stopping rule used in\nHyperband by a non-dominated sorting rule to preemptively stop unpromising\nconfigurations. Second, we leverage hyperparameter evaluations from related\ntasks via transfer learning by building a probabilistic estimate of the Pareto\nfront that finds promising configurations more efficiently than random search.\nWe show in extensive NAS and HPO experiments that both ingredients bring\nsignificant speed-ups and cost savings, with little to no impact on accuracy.\nIn three benchmarks where hardware is selected in addition to hyperparameters,\nwe obtain runtime and cost reductions of at least 5.8x and 8.8x, respectively.\nFurthermore, when applying our multi-objective method to the tuning of\nhyperparameters only, we obtain a 10\\% improvement in runtime while maintaining\nthe same accuracy on two popular NAS benchmarks.",
          "link": "http://arxiv.org/abs/2106.05680",
          "publishedOn": "2021-06-11T01:42:15.589Z",
          "wordCount": 646,
          "title": "A multi-objective perspective on jointly tuning hardware and hyperparameters. (arXiv:2106.05680v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05391",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kose_O/0/1/0/all/0/1\">&#xd6;yk&#xfc; Deniz K&#xf6;se</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yanning Shen</a>",
          "description": "Node representation learning has demonstrated its effectiveness for various\napplications on graphs. Particularly, recent developments in contrastive\nlearning have led to promising results in unsupervised node representation\nlearning for a number of tasks. Despite the success of graph contrastive\nlearning and consequent growing interest, fairness is largely under-explored in\nthe field. To this end, this study addresses fairness issues in graph\ncontrastive learning with fairness-aware graph augmentation designs, through\nadaptive feature masking and edge deletion. In the study, different fairness\nnotions on graphs are introduced, which serve as guidelines for the proposed\ngraph augmentations. Furthermore, theoretical analysis is provided to\nquantitatively prove that the proposed feature masking approach can reduce\nintrinsic bias. Experimental results on real social networks are presented to\ndemonstrate that the proposed augmentations can enhance fairness in terms of\nstatistical parity and equal opportunity, while providing comparable\nclassification accuracy to state-of-the-art contrastive methods for node\nclassification.",
          "link": "http://arxiv.org/abs/2106.05391",
          "publishedOn": "2021-06-11T01:42:15.583Z",
          "wordCount": 571,
          "title": "Fairness-Aware Node Representation Learning. (arXiv:2106.05391v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05402",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chelarescu_P/0/1/0/all/0/1\">Paul Chelarescu</a>",
          "description": "Within the framework of Multi-Agent Reinforcement Learning, Social Learning\nis a new class of algorithms that enables agents to reshape the reward function\nof other agents with the goal of promoting cooperation and achieving higher\nglobal rewards in mixed-motive games. However, this new modification allows\nagents unprecedented access to each other's learning process, which can\ndrastically increase the risk of manipulation when an agent does not realize it\nis being deceived into adopting policies which are not actually in its own best\ninterest. This research review introduces the problem statement, defines key\nconcepts, critically evaluates existing evidence and addresses open problems\nthat should be addressed in future research.",
          "link": "http://arxiv.org/abs/2106.05402",
          "publishedOn": "2021-06-11T01:42:15.567Z",
          "wordCount": 528,
          "title": "Deception in Social Learning: A Multi-Agent Reinforcement Learning Perspective. (arXiv:2106.05402v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05597",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kervadec_C/0/1/0/all/0/1\">Corentin Kervadec</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolf_C/0/1/0/all/0/1\">Christian Wolf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Antipov_G/0/1/0/all/0/1\">Grigory Antipov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baccouche_M/0/1/0/all/0/1\">Moez Baccouche</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nadri_M/0/1/0/all/0/1\">Madiha Nadri</a>",
          "description": "Methods for Visual Question Anwering (VQA) are notorious for leveraging\ndataset biases rather than performing reasoning, hindering generalization. It\nhas been recently shown that better reasoning patterns emerge in attention\nlayers of a state-of-the-art VQA model when they are trained on perfect\n(oracle) visual inputs. This provides evidence that deep neural networks can\nlearn to reason when training conditions are favorable enough. However,\ntransferring this learned knowledge to deployable models is a challenge, as\nmuch of it is lost during the transfer. We propose a method for knowledge\ntransfer based on a regularization term in our loss function, supervising the\nsequence of required reasoning operations. We provide a theoretical analysis\nbased on PAC-learning, showing that such program prediction can lead to\ndecreased sample complexity under mild hypotheses. We also demonstrate the\neffectiveness of this approach experimentally on the GQA dataset and show its\ncomplementarity to BERT-like self-supervised pre-training.",
          "link": "http://arxiv.org/abs/2106.05597",
          "publishedOn": "2021-06-11T01:42:15.561Z",
          "wordCount": 584,
          "title": "Supervising the Transfer of Reasoning Patterns in VQA. (arXiv:2106.05597v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05472",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Chen_Z/0/1/0/all/0/1\">Zengjing Chen</a>, <a href=\"http://arxiv.org/find/math/1/au:+Epstein_L/0/1/0/all/0/1\">Larry G. Epstein</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhang_G/0/1/0/all/0/1\">Guodong Zhang</a>",
          "description": "This paper establishes a central limit theorem under the assumption that\nconditional variances can vary in a largely unstructured history-dependent way\nacross experiments subject only to the restriction that they lie in a fixed\ninterval. Limits take a novel and tractable form, and are expressed in terms of\noscillating Brownian motion. A second contribution is application of this\nresult to a class of multi-armed bandit problems where the decision-maker is\nloss averse.",
          "link": "http://arxiv.org/abs/2106.05472",
          "publishedOn": "2021-06-11T01:42:15.555Z",
          "wordCount": 505,
          "title": "A Central Limit Theorem, Loss Aversion and Multi-Armed Bandits. (arXiv:2106.05472v1 [math.PR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05608",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hong_J/0/1/0/all/0/1\">Joey Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kveton_B/0/1/0/all/0/1\">Branislav Kveton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaheer_M/0/1/0/all/0/1\">Manzil Zaheer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghavamzadeh_M/0/1/0/all/0/1\">Mohammad Ghavamzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boutilier_C/0/1/0/all/0/1\">Craig Boutilier</a>",
          "description": "We study Thompson sampling (TS) in online decision-making problems where the\nuncertain environment is sampled from a mixture distribution. This is relevant\nto multi-task settings, where a learning agent is faced with different classes\nof problems. We incorporate this structure in a natural way by initializing TS\nwith a mixture prior -- dubbed MixTS -- and develop a novel, general technique\nfor analyzing the regret of TS with such priors. We apply this technique to\nderive Bayes regret bounds for MixTS in both linear bandits and tabular Markov\ndecision processes (MDPs). Our regret bounds reflect the structure of the\nproblem and depend on the number of components and confidence width of each\ncomponent of the prior. Finally, we demonstrate the empirical effectiveness of\nMixTS in both synthetic and real-world experiments.",
          "link": "http://arxiv.org/abs/2106.05608",
          "publishedOn": "2021-06-11T01:42:15.550Z",
          "wordCount": 565,
          "title": "Thompson Sampling with a Mixture Prior. (arXiv:2106.05608v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05345",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gunasekaran_J/0/1/0/all/0/1\">Jashwant Raj Gunasekaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_C/0/1/0/all/0/1\">Cyan Subhra Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thinakaran_P/0/1/0/all/0/1\">Prashanth Thinakaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kandemir_M/0/1/0/all/0/1\">Mahmut Taylan Kandemir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_C/0/1/0/all/0/1\">Chita R. Das</a>",
          "description": "With a growing demand for adopting ML models for a varietyof application\nservices, it is vital that the frameworks servingthese models are capable of\ndelivering highly accurate predic-tions with minimal latency along with reduced\ndeploymentcosts in a public cloud environment. Despite high latency,prior works\nin this domain are crucially limited by the accu-racy offered by individual\nmodels. Intuitively, model ensem-bling can address the accuracy gap by\nintelligently combiningdifferent models in parallel. However, selecting the\nappro-priate models dynamically at runtime to meet the desiredaccuracy with low\nlatency at minimal deployment cost is anontrivial problem. Towards this, we\nproposeCocktail, a costeffective ensembling-based model serving\nframework.Cock-tailcomprises of two key components: (i) a dynamic\nmodelselection framework, which reduces the number of modelsin the ensemble,\nwhile satisfying the accuracy and latencyrequirements; (ii) an adaptive\nresource management (RM)framework that employs a distributed proactive\nautoscalingpolicy combined with importance sampling, to efficiently allo-cate\nresources for the models. The RM framework leveragestransient virtual machine\n(VM) instances to reduce the de-ployment cost in a public cloud. A prototype\nimplementationofCocktailon the AWS EC2 platform and exhaustive evalua-tions\nusing a variety of workloads demonstrate thatCocktailcan reduce deployment cost\nby 1.45x, while providing 2xreduction in latency and satisfying the target\naccuracy for upto 96% of the requests, when compared to\nstate-of-the-artmodel-serving frameworks.",
          "link": "http://arxiv.org/abs/2106.05345",
          "publishedOn": "2021-06-11T01:42:15.545Z",
          "wordCount": 661,
          "title": "Cocktail: Leveraging Ensemble Learning for Optimized Model Serving in Public Cloud. (arXiv:2106.05345v1 [cs.DC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05285",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Krause_C/0/1/0/all/0/1\">Claudius Krause</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Shih_D/0/1/0/all/0/1\">David Shih</a>",
          "description": "We introduce CaloFlow, a fast detector simulation framework based on\nnormalizing flows. For the first time, we demonstrate that normalizing flows\ncan reproduce many-channel calorimeter showers with extremely high fidelity,\nproviding a fresh alternative to computationally expensive GEANT4 simulations,\nas well as other state-of-the-art fast simulation frameworks based on GANs and\nVAEs. Besides the usual histograms of physical features and images of\ncalorimeter showers, we introduce a new metric for judging the quality of\ngenerative modeling: the performance of a classifier trained to differentiate\nreal from generated images. We show that GAN-generated images can be identified\nby the classifier with 100% accuracy, while images generated from CaloFlow are\nable to fool the classifier much of the time. More broadly, normalizing flows\noffer several advantages compared to other state-of-the-art approaches (GANs\nand VAEs), including: tractable likelihoods; stable and convergent training;\nand principled model selection. Normalizing flows also provide a bijective\nmapping between data and the latent space, which could have other applications\nbeyond simulation, for example, to detector unfolding.",
          "link": "http://arxiv.org/abs/2106.05285",
          "publishedOn": "2021-06-11T01:42:15.530Z",
          "wordCount": 629,
          "title": "CaloFlow: Fast and Accurate Generation of Calorimeter Showers with Normalizing Flows. (arXiv:2106.05285v1 [physics.ins-det])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05317",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Day_B/0/1/0/all/0/1\">Ben Day</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vinas_R/0/1/0/all/0/1\">Ramon Vi&#xf1;as</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simidjievski_N/0/1/0/all/0/1\">Nikola Simidjievski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lio_P/0/1/0/all/0/1\">Pietro Li&#xf2;</a>",
          "description": "Polythetic classifications, based on shared patterns of features that need\nneither be universal nor constant among members of a class, are common in the\nnatural world and greatly outnumber monothetic classifications over a set of\nfeatures. We show that threshold meta-learners require an embedding dimension\nthat is exponential in the number of features to emulate these functions. In\ncontrast, attentional classifiers are polythetic by default and able to solve\nthese problems with a linear embedding dimension. However, we find that in the\npresence of task-irrelevant features, inherent to meta-learning problems,\nattentional models are susceptible to misclassification. To address this\nchallenge, we further propose a self-attention feature-selection mechanism that\nadaptively dilutes non-discriminative features. We demonstrate the\neffectiveness of our approach in meta-learning Boolean functions, and synthetic\nand real-world few-shot learning tasks.",
          "link": "http://arxiv.org/abs/2106.05317",
          "publishedOn": "2021-06-11T01:42:15.524Z",
          "wordCount": 559,
          "title": "Attentional meta-learners are polythetic classifiers. (arXiv:2106.05317v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05319",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hwang_U/0/1/0/all/0/1\">Uiwon Hwang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Heeseung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_D/0/1/0/all/0/1\">Dahuin Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jang_H/0/1/0/all/0/1\">Hyemi Jang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hyungyu Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1\">Sungroh Yoon</a>",
          "description": "Generative adversarial networks (GANs) with clustered latent spaces can\nperform conditional generation in a completely unsupervised manner. However,\nthe salient attributes of unlabeled data in the real-world are mostly\nimbalanced. Existing unsupervised conditional GANs cannot properly cluster the\nattributes in their latent spaces because they assume uniform distributions of\nthe attributes. To address this problem, we theoretically derive Stein latent\noptimization that provides reparameterizable gradient estimations of the latent\ndistribution parameters assuming a Gaussian mixture prior in a continuous\nlatent space. Structurally, we introduce an encoder network and a novel\ncontrastive loss to help generated data from a single mixture component to\nrepresent a single attribute. We confirm that the proposed method, named Stein\nLatent Optimization for GANs (SLOGAN), successfully learns the balanced or\nimbalanced attributes and performs unsupervised tasks such as unsupervised\nconditional generation, unconditional generation, and cluster assignment even\nin the absence of information of the attributes (e.g. the imbalance ratio).\nMoreover, we demonstrate that the attributes to be learned can be manipulated\nusing a small amount of probe data.",
          "link": "http://arxiv.org/abs/2106.05319",
          "publishedOn": "2021-06-11T01:42:15.512Z",
          "wordCount": 599,
          "title": "Stein Latent Optimization for GANs. (arXiv:2106.05319v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05275",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ross_B/0/1/0/all/0/1\">Brendan Leigh Ross</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cresswell_J/0/1/0/all/0/1\">Jesse C. Cresswell</a>",
          "description": "Normalizing flows are generative models that provide tractable density\nestimation by transforming a simple base distribution into a complex target\ndistribution. However, this technique cannot directly model data supported on\nan unknown low-dimensional manifold, a common occurrence in real-world domains\nsuch as image data. Recent attempts to remedy this limitation have introduced\ngeometric complications that defeat a central benefit of normalizing flows:\nexact density estimation. We recover this benefit with Conformal Embedding\nFlows, a framework for designing flows that learn manifolds with tractable\ndensities. We argue that composing a standard flow with a trainable conformal\nembedding is the most natural way to model manifold-supported data. To this\nend, we present a series of conformal building blocks and apply them in\nexperiments with real-world and synthetic data to demonstrate that flows can\nmodel manifold-supported distributions without sacrificing tractable\nlikelihoods.",
          "link": "http://arxiv.org/abs/2106.05275",
          "publishedOn": "2021-06-11T01:42:15.507Z",
          "wordCount": 568,
          "title": "Tractable Density Estimation on Learned Manifolds with Conformal Embedding Flows. (arXiv:2106.05275v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03142",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_R/0/1/0/all/0/1\">Rongye Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mo_Z/0/1/0/all/0/1\">Zhaobin Mo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1\">Kuang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Di_X/0/1/0/all/0/1\">Xuan Di</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_Q/0/1/0/all/0/1\">Qiang Du</a>",
          "description": "Traffic state estimation (TSE) bifurcates into two main categories,\nmodel-driven and data-driven (e.g., machine learning, ML) approaches, while\neach suffers from either deficient physics or small data. To mitigate these\nlimitations, recent studies introduced hybrid methods, such as physics-informed\ndeep learning (PIDL), which contains both model-driven and data-driven\ncomponents. This paper contributes an improved paradigm, called\nphysics-informed deep learning with a fundamental diagram learner (PIDL+FDL),\nwhich integrates ML terms into the model-driven component to learn a functional\nform of a fundamental diagram (FD), i.e., a mapping from traffic density to\nflow or velocity. The proposed PIDL+FDL has the advantages of performing the\nTSE learning, model parameter discovery, and FD discovery simultaneously. This\npaper focuses on highway TSE with observed data from loop detectors, using\ntraffic density or velocity as traffic variables. We demonstrate the use of\nPIDL+FDL to solve popular first-order and second-order traffic flow models and\nreconstruct the FD relation as well as model parameters that are outside the FD\nterm. We then evaluate the PIDL+FDL-based TSE using the Next Generation\nSIMulation (NGSIM) dataset. The experimental results show the superiority of\nthe PIDL+FDL in terms of improved estimation accuracy and data efficiency over\nadvanced baseline TSE methods, and additionally, the capacity to properly learn\nthe unknown underlying FD relation.",
          "link": "http://arxiv.org/abs/2106.03142",
          "publishedOn": "2021-06-11T01:42:15.502Z",
          "wordCount": 671,
          "title": "A Physics-Informed Deep Learning Paradigm for Traffic State Estimation and Fundamental Diagram Discovery. (arXiv:2106.03142v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.00349",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Eriksson_D/0/1/0/all/0/1\">David Eriksson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jankowiak_M/0/1/0/all/0/1\">Martin Jankowiak</a>",
          "description": "Bayesian optimization (BO) is a powerful paradigm for efficient optimization\nof black-box objective functions. High-dimensional BO presents a particular\nchallenge, in part because the curse of dimensionality makes it difficult to\ndefine -- as well as do inference over -- a suitable class of surrogate models.\nWe argue that Gaussian process surrogate models defined on sparse axis-aligned\nsubspaces offer an attractive compromise between flexibility and parsimony. We\ndemonstrate that our approach, which relies on Hamiltonian Monte Carlo for\ninference, can rapidly identify sparse subspaces relevant to modeling the\nunknown objective function, enabling sample-efficient high-dimensional BO. In\nan extensive suite of experiments comparing to existing methods for\nhigh-dimensional BO we demonstrate that our algorithm, Sparse Axis-Aligned\nSubspace BO (SAASBO), achieves excellent performance on several synthetic and\nreal-world problems without the need to set problem-specific hyperparameters.",
          "link": "http://arxiv.org/abs/2103.00349",
          "publishedOn": "2021-06-11T01:42:15.438Z",
          "wordCount": 590,
          "title": "High-Dimensional Bayesian Optimization with Sparse Axis-Aligned Subspaces. (arXiv:2103.00349v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.03469",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schiff_Y/0/1/0/all/0/1\">Yair Schiff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quanz_B/0/1/0/all/0/1\">Brian Quanz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_P/0/1/0/all/0/1\">Payel Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1\">Pin-Yu Chen</a>",
          "description": "The field of Deep Learning is rich with empirical evidence of human-like\nperformance on a variety of regression, classification, and control tasks.\nHowever, despite these successes, the field lacks strong theoretical error\nbounds and consistent measures of network generalization and learned\ninvariances. In this work, we introduce two new measures, the Gi-score and\nPal-score, that capture a deep neural network's generalization capabilities.\nInspired by the Gini coefficient and Palma ratio, measures of income\ninequality, our statistics are robust measures of a network's invariance to\nperturbations that accurately predict generalization gaps, i.e., the difference\nbetween accuracy on training and test sets.",
          "link": "http://arxiv.org/abs/2104.03469",
          "publishedOn": "2021-06-11T01:42:15.433Z",
          "wordCount": 567,
          "title": "Gi and Pal Scores: Deep Neural Network Generalization Statistics. (arXiv:2104.03469v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.14651",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Watson_D/0/1/0/all/0/1\">David Watson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gultchin_L/0/1/0/all/0/1\">Limor Gultchin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taly_A/0/1/0/all/0/1\">Ankur Taly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Floridi_L/0/1/0/all/0/1\">Luciano Floridi</a>",
          "description": "Necessity and sufficiency are the building blocks of all successful\nexplanations. Yet despite their importance, these notions have been\nconceptually underdeveloped and inconsistently applied in explainable\nartificial intelligence (XAI), a fast-growing research area that is so far\nlacking in firm theoretical foundations. Building on work in logic,\nprobability, and causality, we establish the central role of necessity and\nsufficiency in XAI, unifying seemingly disparate methods in a single formal\nframework. We provide a sound and complete algorithm for computing explanatory\nfactors with respect to a given context, and demonstrate its flexibility and\ncompetitive performance against state of the art alternatives on various tasks.",
          "link": "http://arxiv.org/abs/2103.14651",
          "publishedOn": "2021-06-11T01:42:15.426Z",
          "wordCount": 574,
          "title": "Local Explanations via Necessity and Sufficiency: Unifying Theory and Practice. (arXiv:2103.14651v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05846",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bice_N/0/1/0/all/0/1\">Noah Bice</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fakhreddine_M/0/1/0/all/0/1\">Mohamad Fakhreddine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Ruiqi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1\">Dan Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kabat_C/0/1/0/all/0/1\">Christopher Kabat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Myers_P/0/1/0/all/0/1\">Pamela Myers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papanikolaou_N/0/1/0/all/0/1\">Niko Papanikolaou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kirby_N/0/1/0/all/0/1\">Neil Kirby</a>",
          "description": "Volumetric modulated arc therapy planning is a challenging problem in\nhigh-dimensional, non-convex optimization. Traditionally, heuristics such as\nfluence-map-optimization-informed segment initialization use locally optimal\nsolutions to begin the search of the full arc therapy plan space from a\nreasonable starting point. These routines facilitate arc therapy optimization\nsuch that clinically satisfactory radiation treatment plans can be created in\nabout 10 minutes. However, current optimization algorithms favor solutions near\ntheir initialization point and are slower than necessary due to plan\noverparameterization. In this work, arc therapy overparameterization is\naddressed by reducing the effective dimension of treatment plans with\nunsupervised deep learning. An optimization engine is then built based on\nlow-dimensional arc representations which facilitates faster planning times.",
          "link": "http://arxiv.org/abs/2106.05846",
          "publishedOn": "2021-06-11T01:42:15.396Z",
          "wordCount": 540,
          "title": "Latent Space Arc Therapy Optimization. (arXiv:2106.05846v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2010.02974",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_T/0/1/0/all/0/1\">Tarun Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahajan_A/0/1/0/all/0/1\">Anuj Mahajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1\">Bei Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bohmer_W/0/1/0/all/0/1\">Wendelin B&#xf6;hmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Whiteson_S/0/1/0/all/0/1\">Shimon Whiteson</a>",
          "description": "VDN and QMIX are two popular value-based algorithms for cooperative MARL that\nlearn a centralized action value function as a monotonic mixing of per-agent\nutilities. While this enables easy decentralization of the learned policy, the\nrestricted joint action value function can prevent them from solving tasks that\nrequire significant coordination between agents at a given timestep. We show\nthat this problem can be overcome by improving the joint exploration of all\nagents during training. Specifically, we propose a novel MARL approach called\nUniversal Value Exploration (UneVEn) that learns a set of related tasks\nsimultaneously with a linear decomposition of universal successor features.\nWith the policies of already solved related tasks, the joint exploration\nprocess of all agents can be improved to help them achieve better coordination.\nEmpirical results on a set of exploration games, challenging cooperative\npredator-prey tasks requiring significant coordination among agents, and\nStarCraft II micromanagement benchmarks show that UneVEn can solve tasks where\nother state-of-the-art MARL methods fail.",
          "link": "http://arxiv.org/abs/2010.02974",
          "publishedOn": "2021-06-11T01:42:15.390Z",
          "wordCount": 638,
          "title": "UneVEn: Universal Value Exploration for Multi-Agent Reinforcement Learning. (arXiv:2010.02974v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2003.09671",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Geiger_B/0/1/0/all/0/1\">Bernhard C. Geiger</a>",
          "description": "We review the current literature concerned with information plane analyses of\nneural network classifiers. While the underlying information bottleneck theory\nand the claim that information-theoretic compression is causally linked to\ngeneralization are plausible, empirical evidence was found to be both\nsupporting and conflicting. We review this evidence together with a detailed\nanalysis of how the respective information quantities were estimated. Our\nsurvey suggests that compression visualized in information planes is not\nnecessarily information-theoretic, but is rather often compatible with\ngeometric compression of the latent representations. This insight gives the\ninformation plane a renewed justification.\n\nAside from this, we shed light on the problem of estimating mutual\ninformation in deterministic neural networks and its consequences.\nSpecifically, we argue that even in feed-forward neural networks the data\nprocessing inequality need not hold for estimates of mutual information.\nSimilarly, while a fitting phase, in which the mutual information between the\nlatent representation and the target increases, is necessary (but not\nsufficient) for good classification performance, depending on the specifics of\nmutual information estimation such a fitting phase need not be visible in the\ninformation plane.",
          "link": "http://arxiv.org/abs/2003.09671",
          "publishedOn": "2021-06-11T01:42:15.384Z",
          "wordCount": 682,
          "title": "On Information Plane Analyses of Neural Network Classifiers -- A Review. (arXiv:2003.09671v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.13105",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Seongbin Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1\">Gyuwan Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_S/0/1/0/all/0/1\">Seongjin Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sangmin Lee</a>",
          "description": "End-to-end approaches open a new way for more accurate and efficient spoken\nlanguage understanding (SLU) systems by alleviating the drawbacks of\ntraditional pipeline systems. Previous works exploit textual information for an\nSLU model via pre-training with automatic speech recognition or fine-tuning\nwith knowledge distillation. To utilize textual information more effectively,\nthis work proposes a two-stage textual knowledge distillation method that\nmatches utterance-level representations and predicted logits of two modalities\nduring pre-training and fine-tuning, sequentially. We use vq-wav2vec BERT as a\nspeech encoder because it captures general and rich features. Furthermore, we\nimprove the performance, especially in a low-resource scenario, with data\naugmentation methods by randomly masking spans of discrete audio tokens and\ncontextualized hidden representations. Consequently, we push the\nstate-of-the-art on the Fluent Speech Commands, achieving 99.7% test accuracy\nin the full dataset setting and 99.5% in the 10% subset setting. Throughout the\nablation studies, we empirically verify that all used methods are crucial to\nthe final performance, providing the best practice for spoken language\nunderstanding. Code is available at https://github.com/clovaai/textual-kd-slu.",
          "link": "http://arxiv.org/abs/2010.13105",
          "publishedOn": "2021-06-11T01:42:15.378Z",
          "wordCount": 649,
          "title": "Two-stage Textual Knowledge Distillation for End-to-End Spoken Language Understanding. (arXiv:2010.13105v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2002.08405",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sharma_N/0/1/0/all/0/1\">Nihal Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basu_S/0/1/0/all/0/1\">Soumya Basu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shanmugam_K/0/1/0/all/0/1\">Karthikeyan Shanmugam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shakkottai_S/0/1/0/all/0/1\">Sanjay Shakkottai</a>",
          "description": "We study a variant of the multi-armed bandit problem where side information\nin the form of bounds on the mean of each arm is provided. We develop the novel\nnon-optimistic Global Under-Explore (GLUE) algorithm which uses the provided\nmean bounds (across all the arms) to infer pseudo-variances for each arm, which\nin turn decide the rate of exploration for the arms. We analyze the regret of\nGLUE and prove regret upper bounds that are never worse than that of the\nstandard UCB algorithm. Furthermore, we show that GLUE improves upon regret\nguarantees that exists in literature for structured bandit problems (both\ntheoretically and empirically). Finally, we study the practical setting of\nlearning adaptive interventions using prior data that has been confounded by\nunrecorded variables that affect rewards. We show that mean bounds can be\ninferred naturally from such logs and can thus be used to improve the learning\nprocess. We validate our findings through semi-synthetic experiments on data\nderived from real data sets.",
          "link": "http://arxiv.org/abs/2002.08405",
          "publishedOn": "2021-06-11T01:42:15.373Z",
          "wordCount": 642,
          "title": "On Under-exploration in Bandits with Mean Bounds from Confounded Data. (arXiv:2002.08405v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05466",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Hie_B/0/1/0/all/0/1\">Brian L. Hie</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Yang_K/0/1/0/all/0/1\">Kevin K. Yang</a>",
          "description": "Machine-learning models that learn from data to predict how protein sequence\nencodes function are emerging as a useful protein engineering tool. However,\nwhen using these models to suggest new protein designs, one must deal with the\nvast combinatorial complexity of protein sequences. Here, we review how to use\na sequence-to-function machine-learning surrogate model to select sequences for\nexperimental measurement. First, we discuss how to select sequences through a\nsingle round of machine-learning optimization. Then, we discuss sequential\noptimization, where the goal is to discover optimized sequences and improve the\nmodel across multiple rounds of training, optimization, and experimental\nmeasurement.",
          "link": "http://arxiv.org/abs/2106.05466",
          "publishedOn": "2021-06-11T01:42:15.346Z",
          "wordCount": 529,
          "title": "Adaptive machine learning for protein engineering. (arXiv:2106.05466v1 [q-bio.QM])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05956",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lubana_E/0/1/0/all/0/1\">Ekdeep Singh Lubana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dick_R/0/1/0/all/0/1\">Robert P. Dick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tanaka_H/0/1/0/all/0/1\">Hidenori Tanaka</a>",
          "description": "Inspired by BatchNorm, there has been an explosion of normalization layers in\ndeep learning. Recent works have identified a multitude of beneficial\nproperties in BatchNorm to explain its success. However, given the pursuit of\nalternative normalization techniques, these properties need to be generalized\nso that any given layer's success/failure can be accurately predicted. In this\nwork, we take a first step towards this goal by extending known properties of\nBatchNorm in randomly initialized deep neural networks (DNNs) to nine recently\nproposed normalization layers. Our primary findings follow: (i) Similar to\nBatchNorm, activations-based normalization layers can avoid exploding\nactivations in ResNets; (ii) Use of GroupNorm ensures rank of activations is at\nleast $\\Omega(\\sqrt{\\frac{\\text{width}}{\\text{Group Size}}})$, thus explaining\nwhy LayerNorm witnesses slow optimization speed; (iii) Small group sizes result\nin large gradient norm in earlier layers, hence justifying training instability\nissues in Instance Normalization and illustrating a speed-stability tradeoff in\nGroupNorm. Overall, our analysis reveals several general mechanisms that\nexplain the success of normalization techniques in deep learning, providing us\nwith a compass to systematically explore the vast design space of DNN\nnormalization layers.",
          "link": "http://arxiv.org/abs/2106.05956",
          "publishedOn": "2021-06-11T01:42:15.336Z",
          "wordCount": 619,
          "title": "Beyond BatchNorm: Towards a General Understanding of Normalization in Deep Learning. (arXiv:2106.05956v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05864",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Neary_C/0/1/0/all/0/1\">Cyrus Neary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verginis_C/0/1/0/all/0/1\">Christos Verginis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cubuktepe_M/0/1/0/all/0/1\">Murat Cubuktepe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Topcu_U/0/1/0/all/0/1\">Ufuk Topcu</a>",
          "description": "We propose a novel framework for verifiable and compositional reinforcement\nlearning (RL) in which a collection of RL sub-systems, each of which learns to\naccomplish a separate sub-task, are composed to achieve an overall task. The\nframework consists of a high-level model, represented as a parametric Markov\ndecision process (pMDP) which is used to plan and to analyze compositions of\nsub-systems, and of the collection of low-level sub-systems themselves. By\ndefining interfaces between the sub-systems, the framework enables automatic\ndecompositons of task specifications, e.g., reach a target set of states with a\nprobability of at least 0.95, into individual sub-task specifications, i.e.\nachieve the sub-system's exit conditions with at least some minimum\nprobability, given that its entry conditions are met. This in turn allows for\nthe independent training and testing of the sub-systems; if they each learn a\npolicy satisfying the appropriate sub-task specification, then their\ncomposition is guaranteed to satisfy the overall task specification.\nConversely, if the sub-task specifications cannot all be satisfied by the\nlearned policies, we present a method, formulated as the problem of finding an\noptimal set of parameters in the pMDP, to automatically update the sub-task\nspecifications to account for the observed shortcomings. The result is an\niterative procedure for defining sub-task specifications, and for training the\nsub-systems to meet them. As an additional benefit, this procedure allows for\nparticularly challenging or important components of an overall task to be\ndetermined automatically, and focused on, during training. Experimental results\ndemonstrate the presented framework's novel capabilities.",
          "link": "http://arxiv.org/abs/2106.05864",
          "publishedOn": "2021-06-11T01:42:15.284Z",
          "wordCount": 675,
          "title": "Verifiable and Compositional Reinforcement Learning Systems. (arXiv:2106.05864v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05784",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schuster_T/0/1/0/all/0/1\">Tal Schuster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalyan_A/0/1/0/all/0/1\">Ashwin Kalyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Polozov_O/0/1/0/all/0/1\">Oleksandr Polozov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalai_A/0/1/0/all/0/1\">Adam Tauman Kalai</a>",
          "description": "We introduce a new type of programming challenge called programming puzzles,\nas an objective and comprehensive evaluation of program synthesis, and release\nan open-source dataset of Python Programming Puzzles (P3). Each puzzle is\ndefined by a short Python program $f$, and the goal is to find an input $x$\nwhich makes $f$ output \"True\". The puzzles are objective in that each one is\nspecified entirely by the source code of its verifier $f$, so evaluating $f(x)$\nis all that is needed to test a candidate solution $x$. They do not require an\nanswer key or input/output examples, nor do they depend on natural language\nunderstanding. The dataset is comprehensive in that it spans problems of a\nrange of difficulties and domains, ranging from trivial string manipulation\nproblems that are immediately obvious to human programmers (but not necessarily\nto AI), to classic programming puzzles (e.g., Towers of Hanoi), to\ninterview/competitive-programming problems (e.g., dynamic programming), to\nlongstanding open problems in algorithms and mathematics (e.g., factoring). The\nobjective nature of P3 readily supports self-supervised bootstrapping. We\ndevelop baseline enumerative program synthesis and GPT-3 solvers that are\ncapable of solving easy puzzles -- even without access to any reference\nsolutions -- by learning from their own past solutions. Based on a small user\nstudy, we find puzzle difficulty to correlate between human programmers and the\nbaseline AI solvers.",
          "link": "http://arxiv.org/abs/2106.05784",
          "publishedOn": "2021-06-11T01:42:15.273Z",
          "wordCount": 661,
          "title": "Programming Puzzles. (arXiv:2106.05784v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05424",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Babay_A/0/1/0/all/0/1\">Amy Babay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dinitz_M/0/1/0/all/0/1\">Michael Dinitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sambaturu_P/0/1/0/all/0/1\">Prathyush Sambaturu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivasan_A/0/1/0/all/0/1\">Aravind Srinivasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsepenekas_L/0/1/0/all/0/1\">Leonidas Tsepenekas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vullikanti_A/0/1/0/all/0/1\">Anil Vullikanti</a>",
          "description": "Graph cut problems form a fundamental problem type in combinatorial\noptimization, and are a central object of study in both theory and practice. In\naddition, the study of fairness in Algorithmic Design and Machine Learning has\nrecently received significant attention, with many different notions proposed\nand analyzed in a variety of contexts. In this paper we initiate the study of\nfairness for graph cut problems by giving the first fair definitions for them,\nand subsequently we demonstrate appropriate algorithmic techniques that yield a\nrigorous theoretical analysis. Specifically, we incorporate two different\ndefinitions of fairness, namely demographic and probabilistic individual\nfairness, in a particular cut problem modeling disaster containment scenarios.\nOur results include a variety of approximation algorithms with provable\ntheoretical guarantees.",
          "link": "http://arxiv.org/abs/2106.05424",
          "publishedOn": "2021-06-11T01:42:15.267Z",
          "wordCount": 554,
          "title": "Fair Disaster Containment via Graph-Cut Problems. (arXiv:2106.05424v1 [cs.DS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05409",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wolczyk_M/0/1/0/all/0/1\">Maciej Wo&#x142;czyk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wojcik_B/0/1/0/all/0/1\">Bartosz W&#xf3;jcik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balazy_K/0/1/0/all/0/1\">Klaudia Ba&#x142;azy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Podolak_I/0/1/0/all/0/1\">Igor Podolak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tabor_J/0/1/0/all/0/1\">Jacek Tabor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smieja_M/0/1/0/all/0/1\">Marek &#x15a;mieja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trzcinski_T/0/1/0/all/0/1\">Tomasz Trzci&#x144;ski</a>",
          "description": "The problem of reducing processing time of large deep learning models is a\nfundamental challenge in many real-world applications. Early exit methods\nstrive towards this goal by attaching additional Internal Classifiers (ICs) to\nintermediate layers of a neural network. ICs can quickly return predictions for\neasy examples and, as a result, reduce the average inference time of the whole\nmodel. However, if a particular IC does not decide to return an answer early,\nits predictions are discarded, with its computations effectively being wasted.\nTo solve this issue, we introduce Zero Time Waste (ZTW), a novel approach in\nwhich each IC reuses predictions returned by its predecessors by (1) adding\ndirect connections between ICs and (2) combining previous outputs in an\nensemble-like manner. We conduct extensive experiments across various datasets\nand architectures to demonstrate that ZTW achieves a significantly better\naccuracy vs. inference time trade-off than other recently proposed early exit\nmethods.",
          "link": "http://arxiv.org/abs/2106.05409",
          "publishedOn": "2021-06-11T01:42:15.251Z",
          "wordCount": 584,
          "title": "Zero Time Waste: Recycling Predictions in Early Exit Neural Networks. (arXiv:2106.05409v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05609",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fey_M/0/1/0/all/0/1\">Matthias Fey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lenssen_J/0/1/0/all/0/1\">Jan E. Lenssen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weichert_F/0/1/0/all/0/1\">Frank Weichert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leskovec_J/0/1/0/all/0/1\">Jure Leskovec</a>",
          "description": "We present GNNAutoScale (GAS), a framework for scaling arbitrary\nmessage-passing GNNs to large graphs. GAS prunes entire sub-trees of the\ncomputation graph by utilizing historical embeddings from prior training\niterations, leading to constant GPU memory consumption in respect to input node\nsize without dropping any data. While existing solutions weaken the expressive\npower of message passing due to sub-sampling of edges or non-trainable\npropagations, our approach is provably able to maintain the expressive power of\nthe original GNN. We achieve this by providing approximation error bounds of\nhistorical embeddings and show how to tighten them in practice. Empirically, we\nshow that the practical realization of our framework, PyGAS, an easy-to-use\nextension for PyTorch Geometric, is both fast and memory-efficient, learns\nexpressive node representations, closely resembles the performance of their\nnon-scaling counterparts, and reaches state-of-the-art performance on\nlarge-scale graphs.",
          "link": "http://arxiv.org/abs/2106.05609",
          "publishedOn": "2021-06-11T01:42:15.228Z",
          "wordCount": 575,
          "title": "GNNAutoScale: Scalable and Expressive Graph Neural Networks via Historical Embeddings. (arXiv:2106.05609v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05549",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rosenzweig_J/0/1/0/all/0/1\">Julia Rosenzweig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brito_E/0/1/0/all/0/1\">Eduardo Brito</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kobialka_H/0/1/0/all/0/1\">Hans-Ulrich Kobialka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akila_M/0/1/0/all/0/1\">Maram Akila</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidt_N/0/1/0/all/0/1\">Nico M. Schmidt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schlicht_P/0/1/0/all/0/1\">Peter Schlicht</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schneider_J/0/1/0/all/0/1\">Jan David Schneider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huger_F/0/1/0/all/0/1\">Fabian H&#xfc;ger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rottmann_M/0/1/0/all/0/1\">Matthias Rottmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Houben_S/0/1/0/all/0/1\">Sebastian Houben</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wirtz_T/0/1/0/all/0/1\">Tim Wirtz</a>",
          "description": "Many machine learning applications can benefit from simulated data for\nsystematic validation - in particular if real-life data is difficult to obtain\nor annotate. However, since simulations are prone to domain shift w.r.t.\nreal-life data, it is crucial to verify the transferability of the obtained\nresults. We propose a novel framework consisting of a generative label-to-image\nsynthesis model together with different transferability measures to inspect to\nwhat extent we can transfer testing results of semantic segmentation models\nfrom synthetic data to equivalent real-life data. With slight modifications,\nour approach is extendable to, e.g., general multi-class classification tasks.\nGrounded on the transferability analysis, our approach additionally allows for\nextensive testing by incorporating controlled simulations. We validate our\napproach empirically on a semantic segmentation task on driving scenes.\nTransferability is tested using correlation analysis of IoU and a learned\ndiscriminator. Although the latter can distinguish between real-life and\nsynthetic tests, in the former we observe surprisingly strong correlations of\n0.7 for both cars and pedestrians.",
          "link": "http://arxiv.org/abs/2106.05549",
          "publishedOn": "2021-06-11T01:42:15.218Z",
          "wordCount": 642,
          "title": "Validation of Simulation-Based Testing: Bypassing Domain Shift with Label-to-Image Synthesis. (arXiv:2106.05549v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05739",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Domingo_Enrich_C/0/1/0/all/0/1\">Carles Domingo-Enrich</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mroueh_Y/0/1/0/all/0/1\">Youssef Mroueh</a>",
          "description": "Several works in implicit and explicit generative modeling empirically\nobserved that feature-learning discriminators outperform fixed-kernel\ndiscriminators in terms of the sample quality of the models. We provide\nseparation results between probability metrics with fixed-kernel and\nfeature-learning discriminators using the function classes $\\mathcal{F}_2$ and\n$\\mathcal{F}_1$ respectively, which were developed to study overparametrized\ntwo-layer neural networks. In particular, we construct pairs of distributions\nover hyper-spheres that can not be discriminated by fixed kernel\n$(\\mathcal{F}_2)$ integral probability metric (IPM) and Stein discrepancy (SD)\nin high dimensions, but that can be discriminated by their feature learning\n($\\mathcal{F}_1$) counterparts. To further study the separation we provide\nlinks between the $\\mathcal{F}_1$ and $\\mathcal{F}_2$ IPMs with sliced\nWasserstein distances. Our work suggests that fixed-kernel discriminators\nperform worse than their feature learning counterparts because their\ncorresponding metrics are weaker.",
          "link": "http://arxiv.org/abs/2106.05739",
          "publishedOn": "2021-06-11T01:42:15.197Z",
          "wordCount": 569,
          "title": "Separation Results between Fixed-Kernel and Feature-Learning Probability Metrics. (arXiv:2106.05739v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2102.11533",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Baek_J/0/1/0/all/0/1\">Jinheon Baek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_M/0/1/0/all/0/1\">Minki Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1\">Sung Ju Hwang</a>",
          "description": "Graph neural networks have been widely used on modeling graph data, achieving\nimpressive results on node classification and link prediction tasks. Yet,\nobtaining an accurate representation for a graph further requires a pooling\nfunction that maps a set of node representations into a compact form. A simple\nsum or average over all node representations considers all node features\nequally without consideration of their task relevance, and any structural\ndependencies among them. Recently proposed hierarchical graph pooling methods,\non the other hand, may yield the same representation for two different graphs\nthat are distinguished by the Weisfeiler-Lehman test, as they suboptimally\npreserve information from the node features. To tackle these limitations of\nexisting graph pooling methods, we first formulate the graph pooling problem as\na multiset encoding problem with auxiliary information about the graph\nstructure, and propose a Graph Multiset Transformer (GMT) which is a multi-head\nattention based global pooling layer that captures the interaction between\nnodes according to their structural dependencies. We show that GMT satisfies\nboth injectiveness and permutation invariance, such that it is at most as\npowerful as the Weisfeiler-Lehman graph isomorphism test. Moreover, our methods\ncan be easily extended to the previous node clustering approaches for\nhierarchical graph pooling. Our experimental results show that GMT\nsignificantly outperforms state-of-the-art graph pooling methods on graph\nclassification benchmarks with high memory and time efficiency, and obtains\neven larger performance gain on graph reconstruction and generation tasks.",
          "link": "http://arxiv.org/abs/2102.11533",
          "publishedOn": "2021-06-11T01:42:15.191Z",
          "wordCount": 701,
          "title": "Accurate Learning of Graph Representations with Graph Multiset Pooling. (arXiv:2102.11533v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.14061",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Harada_S/0/1/0/all/0/1\">Shonosuke Harada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kashima_H/0/1/0/all/0/1\">Hisashi Kashima</a>",
          "description": "Outcome estimation of treatments for target individuals is an important\nfoundation for decision making based on causal relations. Most existing outcome\nestimation methods deal with binary or multiple-choice treatments; however, in\nsome applications, the number of treatments can be significantly large, while\nthe treatments themselves have rich information. In this study, we considered\none important instance of such cases: the outcome estimation problem of\ngraph-structured treatments such as drugs. Owing to the large number of\npossible treatments, the counterfactual nature of observational data that\nappears in conventional treatment effect estimation becomes more of a concern\nfor this problem. Our proposed method, GraphITE (pronounced \"graphite\") learns\nthe representations of graph-structured treatments using graph neural networks\nwhile mitigating observation biases using Hilbert-Schmidt Independence\nCriterion regularization, which increases the independence of the\nrepresentations of the targets and treatments. Experiments on two real-world\ndatasets show that GraphITE outperforms baselines, especially in cases with a\nlarge number of treatments.",
          "link": "http://arxiv.org/abs/2009.14061",
          "publishedOn": "2021-06-11T01:42:15.171Z",
          "wordCount": 604,
          "title": "GraphITE: Estimating Individual Effects of Graph-structured Treatments. (arXiv:2009.14061v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05682",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Oh_Y/0/1/0/all/0/1\">Youngtaek Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1\">Dong-Jin Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kweon_I/0/1/0/all/0/1\">In So Kweon</a>",
          "description": "The capability of the traditional semi-supervised learning (SSL) methods is\nfar from real-world application since they do not consider (1) class imbalance\nand (2) class distribution mismatch between labeled and unlabeled data. This\npaper addresses such a relatively under-explored problem, imbalanced\nsemi-supervised learning, where heavily biased pseudo-labels can harm the model\nperformance. Interestingly, we find that the semantic pseudo-labels from a\nsimilarity-based classifier in feature space and the traditional pseudo-labels\nfrom the linear classifier show the complementary property. To this end, we\npropose a general pseudo-labeling framework to address the bias motivated by\nthis observation. The key idea is to class-adaptively blend the semantic\npseudo-label to the linear one, depending on the current pseudo-label\ndistribution. Thereby, the increased semantic pseudo-label component suppresses\nthe false positives in the majority classes and vice versa. We term the novel\npseudo-labeling framework for imbalanced SSL as Distribution-Aware\nSemantics-Oriented (DASO) Pseudo-label. Extensive evaluation on CIFAR10/100-LT\nand STL10-LT shows that DASO consistently outperforms both recently proposed\nre-balancing methods for label and pseudo-label. Moreover, we demonstrate that\ntypical SSL algorithms can effectively benefit from unlabeled data with DASO,\nespecially when (1) class imbalance and (2) class distribution mismatch exist\nand even on recent real-world Semi-Aves benchmark.",
          "link": "http://arxiv.org/abs/2106.05682",
          "publishedOn": "2021-06-11T01:42:15.076Z",
          "wordCount": 638,
          "title": "Distribution-Aware Semantics-Oriented Pseudo-label for Imbalanced Semi-Supervised Learning. (arXiv:2106.05682v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05304",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Goyal_A/0/1/0/all/0/1\">Ankit Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Law_H/0/1/0/all/0/1\">Hei Law</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bowei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Newell_A/0/1/0/all/0/1\">Alejandro Newell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1\">Jia Deng</a>",
          "description": "Processing point cloud data is an important component of many real-world\nsystems. As such, a wide variety of point-based approaches have been proposed,\nreporting steady benchmark improvements over time. We study the key ingredients\nof this progress and uncover two critical results. First, we find that\nauxiliary factors like different evaluation schemes, data augmentation\nstrategies, and loss functions, which are independent of the model\narchitecture, make a large difference in performance. The differences are large\nenough that they obscure the effect of architecture. When these factors are\ncontrolled for, PointNet++, a relatively older network, performs competitively\nwith recent methods. Second, a very simple projection-based method, which we\nrefer to as SimpleView, performs surprisingly well. It achieves on par or\nbetter results than sophisticated state-of-the-art methods on ModelNet40 while\nbeing half the size of PointNet++. It also outperforms state-of-the-art methods\non ScanObjectNN, a real-world point cloud benchmark, and demonstrates better\ncross-dataset generalization. Code is available at\nhttps://github.com/princeton-vl/SimpleView.",
          "link": "http://arxiv.org/abs/2106.05304",
          "publishedOn": "2021-06-11T01:42:15.047Z",
          "wordCount": 605,
          "title": "Revisiting Point Cloud Shape Classification with a Simple and Effective Baseline. (arXiv:2106.05304v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05303",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Crabbe_J/0/1/0/all/0/1\">Jonathan Crabb&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schaar_M/0/1/0/all/0/1\">Mihaela van der Schaar</a>",
          "description": "How can we explain the predictions of a machine learning model? When the data\nis structured as a multivariate time series, this question induces additional\ndifficulties such as the necessity for the explanation to embody the time\ndependency and the large number of inputs. To address these challenges, we\npropose dynamic masks (Dynamask). This method produces instance-wise importance\nscores for each feature at each time step by fitting a perturbation mask to the\ninput sequence. In order to incorporate the time dependency of the data,\nDynamask studies the effects of dynamic perturbation operators. In order to\ntackle the large number of inputs, we propose a scheme to make the feature\nselection parsimonious (to select no more feature than necessary) and legible\n(a notion that we detail by making a parallel with information theory). With\nsynthetic and real-world data, we demonstrate that the dynamic underpinning of\nDynamask, together with its parsimony, offer a neat improvement in the\nidentification of feature importance over time. The modularity of Dynamask\nmakes it ideal as a plug-in to increase the transparency of a wide range of\nmachine learning models in areas such as medicine and finance, where time\nseries are abundant.",
          "link": "http://arxiv.org/abs/2106.05303",
          "publishedOn": "2021-06-11T01:42:15.041Z",
          "wordCount": 635,
          "title": "Explaining Time Series Predictions with Dynamic Masks. (arXiv:2106.05303v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05306",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yifei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_T/0/1/0/all/0/1\">Tao Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1\">Kui Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jie Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matusik_W/0/1/0/all/0/1\">Wojciech Matusik</a>",
          "description": "Cloth simulation has wide applications including computer animation, garment\ndesign, and robot-assisted dressing. In this work, we present a differentiable\ncloth simulator whose additional gradient information facilitates cloth-related\napplications. Our differentiable simulator extends the state-of-the-art cloth\nsimulator based on Projective Dynamics and with dry frictional contact governed\nby the Signorini-Coulomb law. We derive gradients with contact in this forward\nsimulation framework and speed up the computation with Jacobi iteration\ninspired by previous differentiable simulation work. To our best knowledge, we\npresent the first differentiable cloth simulator with the Coulomb law of\nfriction. We demonstrate the efficacy of our simulator in various applications,\nincluding system identification, manipulation, inverse design, and a\nreal-to-sim task. Many of our applications have not been demonstrated in\nprevious differentiable cloth simulators. The gradient information from our\nsimulator enables efficient gradient-based task solvers from which we observe a\nsubstantial speedup over standard gradient-free methods.",
          "link": "http://arxiv.org/abs/2106.05306",
          "publishedOn": "2021-06-11T01:42:15.007Z",
          "wordCount": 574,
          "title": "DiffCloth: Differentiable Cloth Simulation with Dry Frictional Contact. (arXiv:2106.05306v1 [cs.GR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01981",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Oreshkin_B/0/1/0/all/0/1\">Boris N. Oreshkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bocquelet_F/0/1/0/all/0/1\">Florent Bocquelet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harvey_F/0/1/0/all/0/1\">F&#xe9;lix G. Harvey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raitt_B/0/1/0/all/0/1\">Bay Raitt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laflamme_D/0/1/0/all/0/1\">Dominic Laflamme</a>",
          "description": "Our work focuses on the development of a learnable neural representation of\nhuman pose for advanced AI assisted animation tooling. Specifically, we tackle\nthe problem of constructing a full static human pose based on sparse and\nvariable user inputs (e.g. locations and/or orientations of a subset of body\njoints). To solve this problem, we propose a novel neural architecture that\ncombines residual connections with prototype encoding of a partially specified\npose to create a new complete pose from the learned latent space. We show that\nour architecture outperforms a baseline based on Transformer, both in terms of\naccuracy and computational efficiency. Additionally, we develop a user\ninterface to integrate our neural model in Unity, a real-time 3D development\nplatform. Furthermore, we introduce two new datasets representing the static\nhuman pose modeling problem, based on high-quality human motion capture data,\nwhich will be released publicly along with model code.",
          "link": "http://arxiv.org/abs/2106.01981",
          "publishedOn": "2021-06-10T22:40:40.687Z",
          "wordCount": 609,
          "title": "ProtoRes: Proto-Residual Architecture for Deep Modeling of Human Pose. (arXiv:2106.01981v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05009",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bucher_J/0/1/0/all/0/1\">Julian B&#xfc;cher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faber_F/0/1/0/all/0/1\">Fynn Faber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muir_D/0/1/0/all/0/1\">Dylan R. Muir</a>",
          "description": "Neuromorphic neural network processors, in the form of compute-in-memory\ncrossbar arrays of memristors, or in the form of subthreshold analog and\nmixed-signal ASICs, promise enormous advantages in compute density and energy\nefficiency for NN-based ML tasks. However, these technologies are prone to\ncomputational non-idealities, due to process variation and intrinsic device\nphysics. This degrades the task performance of networks deployed to the\nprocessor, by introducing parameter noise into the deployed model. While it is\npossible to calibrate each device, or train networks individually for each\nprocessor, these approaches are expensive and impractical for commercial\ndeployment. Alternative methods are therefore needed to train networks that are\ninherently robust against parameter variation, as a consequence of network\narchitecture and parameters. We present a new adversarial network optimisation\nalgorithm that attacks network parameters during training, and promotes robust\nperformance during inference in the face of parameter variation. Our approach\nintroduces a regularization term penalising the susceptibility of a network to\nweight perturbation. We compare against previous approaches for producing\nparameter insensitivity such as dropout, weight smoothing and introducing\nparameter noise during training. We show that our approach produces models that\nare more robust to targeted parameter variation, and equally robust to random\nparameter variation. Our approach finds minima in flatter locations in the\nweight-loss landscape compared with other approaches, highlighting that the\nnetworks found by our technique are less sensitive to parameter perturbation.\nOur work provides an approach to deploy neural network architectures to\ninference devices that suffer from computational non-idealities, with minimal\nloss of performance. ...",
          "link": "http://arxiv.org/abs/2106.05009",
          "publishedOn": "2021-06-10T01:56:49.632Z",
          "wordCount": 676,
          "title": "Network insensitivity to parameter noise via adversarial regularization. (arXiv:2106.05009v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2006.08573",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zaidi_S/0/1/0/all/0/1\">Sheheryar Zaidi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zela_A/0/1/0/all/0/1\">Arber Zela</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elsken_T/0/1/0/all/0/1\">Thomas Elsken</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holmes_C/0/1/0/all/0/1\">Chris Holmes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hutter_F/0/1/0/all/0/1\">Frank Hutter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teh_Y/0/1/0/all/0/1\">Yee Whye Teh</a>",
          "description": "Ensembles of neural networks achieve superior performance compared to\nstand-alone networks in terms of accuracy, uncertainty calibration and\nrobustness to dataset shift. \\emph{Deep ensembles}, a state-of-the-art method\nfor uncertainty estimation, only ensemble random initializations of a\n\\emph{fixed} architecture. Instead, we propose two methods for automatically\nconstructing ensembles with \\emph{varying} architectures, which implicitly\ntrade-off individual architectures' strengths against the ensemble's diversity\nand exploit architectural variation as a source of diversity. On a variety of\nclassification tasks and modern architecture search spaces, we show that the\nresulting ensembles outperform deep ensembles not only in terms of accuracy but\nalso uncertainty calibration and robustness to dataset shift. Our further\nanalysis and ablation studies provide evidence of higher ensemble diversity due\nto architectural variation, resulting in ensembles that can outperform deep\nensembles, even when having weaker average base learners.",
          "link": "http://arxiv.org/abs/2006.08573",
          "publishedOn": "2021-06-10T01:56:49.616Z",
          "wordCount": 624,
          "title": "Neural Ensemble Search for Uncertainty Estimation and Dataset Shift. (arXiv:2006.08573v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05091",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Kimin Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_L/0/1/0/all/0/1\">Laura Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1\">Pieter Abbeel</a>",
          "description": "Conveying complex objectives to reinforcement learning (RL) agents can often\nbe difficult, involving meticulous design of reward functions that are\nsufficiently informative yet easy enough to provide. Human-in-the-loop RL\nmethods allow practitioners to instead interactively teach agents through\ntailored feedback; however, such approaches have been challenging to scale\nsince human feedback is very expensive. In this work, we aim to make this\nprocess more sample- and feedback-efficient. We present an off-policy,\ninteractive RL algorithm that capitalizes on the strengths of both feedback and\noff-policy learning. Specifically, we learn a reward model by actively querying\na teacher's preferences between two clips of behavior and use it to train an\nagent. To enable off-policy learning, we relabel all the agent's past\nexperience when its reward model changes. We additionally show that\npre-training our agents with unsupervised exploration substantially increases\nthe mileage of its queries. We demonstrate that our approach is capable of\nlearning tasks of higher complexity than previously considered by\nhuman-in-the-loop methods, including a variety of locomotion and robotic\nmanipulation skills. We also show that our method is able to utilize real-time\nhuman feedback to effectively prevent reward exploitation and learn new\nbehaviors that are difficult to specify with standard reward functions.",
          "link": "http://arxiv.org/abs/2106.05091",
          "publishedOn": "2021-06-10T01:56:49.610Z",
          "wordCount": 649,
          "title": "PEBBLE: Feedback-Efficient Interactive Reinforcement Learning via Relabeling Experience and Unsupervised Pre-training. (arXiv:2106.05091v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2003.01176",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nagpal_C/0/1/0/all/0/1\">Chirag Nagpal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xinyu Rachel Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dubrawski_A/0/1/0/all/0/1\">Artur Dubrawski</a>",
          "description": "We describe a new approach to estimating relative risks in time-to-event\nprediction problems with censored data in a fully parametric manner. Our\napproach does not require making strong assumptions of constant proportional\nhazard of the underlying survival distribution, as required by the\nCox-proportional hazard model. By jointly learning deep nonlinear\nrepresentations of the input covariates, we demonstrate the benefits of our\napproach when used to estimate survival risks through extensive experimentation\non multiple real world datasets with different levels of censoring. We further\ndemonstrate advantages of our model in the competing risks scenario. To the\nbest of our knowledge, this is the first work involving fully parametric\nestimation of survival times with competing risks in the presence of censoring.",
          "link": "http://arxiv.org/abs/2003.01176",
          "publishedOn": "2021-06-10T01:56:49.592Z",
          "wordCount": 626,
          "title": "Deep Survival Machines: Fully Parametric Survival Regression and Representation Learning for Censored Data with Competing Risks. (arXiv:2003.01176v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05042",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Park_M/0/1/0/all/0/1\">Mijung Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vinaroz_M/0/1/0/all/0/1\">Margarita Vinaroz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Charusaie_M/0/1/0/all/0/1\">Mohammad-Amin Charusaie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harder_F/0/1/0/all/0/1\">Frederik Harder</a>",
          "description": "Kernel mean embedding is a useful tool to compare probability measures.\nDespite its usefulness, kernel mean embedding considers infinite-dimensional\nfeatures, which are challenging to handle in the context of differentially\nprivate data generation. A recent work proposes to approximate the kernel mean\nembedding of data distribution using finite-dimensional random features, where\nthe sensitivity of the features becomes analytically tractable. More\nimportantly, this approach significantly reduces the privacy cost, compared to\nother known privatization methods (e.g., DP-SGD), as the approximate kernel\nmean embedding of the data distribution is privatized only once and can then be\nrepeatedly used during training of a generator without incurring any further\nprivacy cost. However, the required number of random features is excessively\nhigh, often ten thousand to a hundred thousand, which worsens the sensitivity\nof the approximate kernel mean embedding. To improve the sensitivity, we\npropose to replace random features with Hermite polynomial features. Unlike the\nrandom features, the Hermite polynomial features are ordered, where the\nfeatures at the low orders contain more information on the distribution than\nthose at the high orders. Hence, a relatively low order of Hermite polynomial\nfeatures can more accurately approximate the mean embedding of the data\ndistribution compared to a significantly higher number of random features. As a\nresult, using the Hermite polynomial features, we significantly improve the\nprivacy-accuracy trade-off, reflected in the high quality and diversity of the\ngenerated data, when tested on several heterogeneous tabular datasets, as well\nas several image benchmark datasets.",
          "link": "http://arxiv.org/abs/2106.05042",
          "publishedOn": "2021-06-10T01:56:49.585Z",
          "wordCount": 679,
          "title": "Polynomial magic! Hermite polynomials for private data generation. (arXiv:2106.05042v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04970",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xin Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_T/0/1/0/all/0/1\">Tao Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Houfeng Wang</a>",
          "description": "In this paper, we propose Shallow Aggressive Decoding (SAD) to improve the\nonline inference efficiency of the Transformer for instantaneous Grammatical\nError Correction (GEC). SAD optimizes the online inference efficiency for GEC\nby two innovations: 1) it aggressively decodes as many tokens as possible in\nparallel instead of always decoding only one token in each step to improve\ncomputational parallelism; 2) it uses a shallow decoder instead of the\nconventional Transformer architecture with balanced encoder-decoder depth to\nreduce the computational cost during inference. Experiments in both English and\nChinese GEC benchmarks show that aggressive decoding could yield the same\npredictions as greedy decoding but with a significant speedup for online\ninference. Its combination with the shallow decoder could offer an even higher\nonline inference speedup over the powerful Transformer baseline without quality\nloss. Not only does our approach allow a single model to achieve the\nstate-of-the-art results in English GEC benchmarks: 66.4 F0.5 in the CoNLL-14\nand 72.9 F0.5 in the BEA-19 test set with an almost 10x online inference\nspeedup over the Transformer-big model, but also it is easily adapted to other\nlanguages. Our code is available at\nhttps://github.com/AutoTemp/Shallow-Aggressive-Decoding.",
          "link": "http://arxiv.org/abs/2106.04970",
          "publishedOn": "2021-06-10T01:56:49.569Z",
          "wordCount": 627,
          "title": "Instantaneous Grammatical Error Correction with Shallow Aggressive Decoding. (arXiv:2106.04970v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2010.13632",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bodin_E/0/1/0/all/0/1\">Erik Bodin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dai_Z/0/1/0/all/0/1\">Zhenwen Dai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Campbell_N/0/1/0/all/0/1\">Neill D. F. Campbell</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ek_C/0/1/0/all/0/1\">Carl Henrik Ek</a>",
          "description": "We present a novel approach to Bayesian inference and general Bayesian\ncomputation that is defined through a sequential decision loop. Our method\ndefines a recursive partitioning of the sample space. It neither relies on\ngradients nor requires any problem-specific tuning, and is asymptotically exact\nfor any density function with a bounded domain. The output is an approximation\nto the whole density function including the normalisation constant, via\npartitions organised in efficient data structures. Such approximations may be\nused for evidence estimation or fast posterior sampling, but also as building\nblocks to treat a larger class of estimation problems. The algorithm shows\ncompetitive performance to recent state-of-the-art methods on synthetic and\nreal-world problems including parameter inference for gravitational-wave\nphysics.",
          "link": "http://arxiv.org/abs/2010.13632",
          "publishedOn": "2021-06-10T01:56:49.562Z",
          "wordCount": 572,
          "title": "Black-box density function estimation using recursive partitioning. (arXiv:2010.13632v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04975",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Qian_Y/0/1/0/all/0/1\">Yang Qian</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Wang_X/0/1/0/all/0/1\">Xinbiao Wang</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Du_Y/0/1/0/all/0/1\">Yuxuan Du</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Wu_X/0/1/0/all/0/1\">Xingyao Wu</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>",
          "description": "The core of quantum machine learning is to devise quantum models with good\ntrainability and low generalization error bound than their classical\ncounterparts to ensure better reliability and interpretability. Recent studies\nconfirmed that quantum neural networks (QNNs) have the ability to achieve this\ngoal on specific datasets. With this regard, it is of great importance to\nunderstand whether these advantages are still preserved on real-world tasks.\nThrough systematic numerical experiments, we empirically observe that current\nQNNs fail to provide any benefit over classical learning models. Concretely,\nour results deliver two key messages. First, QNNs suffer from the severely\nlimited effective model capacity, which incurs poor generalization on\nreal-world datasets. Second, the trainability of QNNs is insensitive to\nregularization techniques, which sharply contrasts with the classical scenario.\nThese empirical results force us to rethink the role of current QNNs and to\ndesign novel protocols for solving real-world problems with quantum advantages.",
          "link": "http://arxiv.org/abs/2106.04975",
          "publishedOn": "2021-06-10T01:56:49.556Z",
          "wordCount": 574,
          "title": "The dilemma of quantum neural networks. (arXiv:2106.04975v1 [quant-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04776",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luan_L/0/1/0/all/0/1\">Lele Luan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Hao Sun</a>",
          "description": "Distilling analytical models from data has the potential to advance our\nunderstanding and prediction of nonlinear dynamics. Although discovery of\ngoverning equations based on observed system states (e.g., trajectory time\nseries) has revealed success in a wide range of nonlinear dynamics, uncovering\nthe closed-form equations directly from raw videos still remains an open\nchallenge. To this end, we introduce a novel end-to-end unsupervised deep\nlearning framework to uncover the mathematical structure of equations that\ngoverns the dynamics of moving objects in videos. Such an architecture consists\nof (1) an encoder-decoder network that learns low-dimensional spatial/pixel\ncoordinates of the moving object, (2) a learnable Spatial-Physical\nTransformation component that creates mapping between the extracted\nspatial/pixel coordinates and the latent physical states of dynamics, and (3) a\nnumerical integrator-based sparse regression module that uncovers the\nparsimonious closed-form governing equations of learned physical states and,\nmeanwhile, serves as a constraint to the autoencoder. The efficacy of the\nproposed method is demonstrated by uncovering the governing equations of a\nvariety of nonlinear dynamical systems depicted by moving objects in videos.\nThe resulting computational framework enables discovery of parsimonious\ninterpretable model in a flexible and accessible sensing environment where only\nvideos are available.",
          "link": "http://arxiv.org/abs/2106.04776",
          "publishedOn": "2021-06-10T01:56:49.550Z",
          "wordCount": 635,
          "title": "Uncovering Closed-form Governing Equations of Nonlinear Dynamics from Videos. (arXiv:2106.04776v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05057",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Celikkanat_A/0/1/0/all/0/1\">Abdulkadir Celikkanat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yanning Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malliaros_F/0/1/0/all/0/1\">Fragkiskos D. Malliaros</a>",
          "description": "Learning representations of nodes in a low dimensional space is a crucial\ntask with numerous interesting applications in network analysis, including link\nprediction, node classification, and visualization. Two popular approaches for\nthis problem are matrix factorization and random walk-based models. In this\npaper, we aim to bring together the best of both worlds, towards learning node\nrepresentations. In particular, we propose a weighted matrix factorization\nmodel that encodes random walk-based information about nodes of the network.\nThe benefit of this novel formulation is that it enables us to utilize kernel\nfunctions without realizing the exact proximity matrix so that it enhances the\nexpressiveness of existing matrix decomposition methods with kernels and\nalleviates their computational complexities. We extend the approach with a\nmultiple kernel learning formulation that provides the flexibility of learning\nthe kernel as the linear combination of a dictionary of kernels in data-driven\nfashion. We perform an empirical evaluation on real-world networks, showing\nthat the proposed model outperforms baseline node embedding algorithms in\ndownstream machine learning tasks.",
          "link": "http://arxiv.org/abs/2106.05057",
          "publishedOn": "2021-06-10T01:56:49.528Z",
          "wordCount": 618,
          "title": "Multiple Kernel Representation Learning on Networks. (arXiv:2106.05057v1 [cs.SI])"
        },
        {
          "id": "http://arxiv.org/abs/2006.04088",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ghosh_A/0/1/0/all/0/1\">Avishek Ghosh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chung_J/0/1/0/all/0/1\">Jichan Chung</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yin_D/0/1/0/all/0/1\">Dong Yin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ramchandran_K/0/1/0/all/0/1\">Kannan Ramchandran</a>",
          "description": "We address the problem of federated learning (FL) where users are distributed\nand partitioned into clusters. This setup captures settings where different\ngroups of users have their own objectives (learning tasks) but by aggregating\ntheir data with others in the same cluster (same learning task), they can\nleverage the strength in numbers in order to perform more efficient federated\nlearning. For this new framework of clustered federated learning, we propose\nthe Iterative Federated Clustering Algorithm (IFCA), which alternately\nestimates the cluster identities of the users and optimizes model parameters\nfor the user clusters via gradient descent. We analyze the convergence rate of\nthis algorithm first in a linear model with squared loss and then for generic\nstrongly convex and smooth loss functions. We show that in both settings, with\ngood initialization, IFCA is guaranteed to converge, and discuss the optimality\nof the statistical error rate. In particular, for the linear model with two\nclusters, we can guarantee that our algorithm converges as long as the\ninitialization is slightly better than random. When the clustering structure is\nambiguous, we propose to train the models by combining IFCA with the weight\nsharing technique in multi-task learning. In the experiments, we show that our\nalgorithm can succeed even if we relax the requirements on initialization with\nrandom initialization and multiple restarts. We also present experimental\nresults showing that our algorithm is efficient in non-convex problems such as\nneural networks. We demonstrate the benefits of IFCA over the baselines on\nseveral clustered FL benchmarks.",
          "link": "http://arxiv.org/abs/2006.04088",
          "publishedOn": "2021-06-10T01:56:49.522Z",
          "wordCount": 700,
          "title": "An Efficient Framework for Clustered Federated Learning. (arXiv:2006.04088v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04887",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1\">Tengyang Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Langford_J/0/1/0/all/0/1\">John Langford</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mineiro_P/0/1/0/all/0/1\">Paul Mineiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Momennejad_I/0/1/0/all/0/1\">Ida Momennejad</a>",
          "description": "Consider a prosthetic arm, learning to adapt to its user's control signals.\nWe propose Interaction-Grounded Learning for this novel setting, in which a\nlearner's goal is to interact with the environment with no grounding or\nexplicit reward to optimize its policies. Such a problem evades common RL\nsolutions which require an explicit reward. The learning agent observes a\nmultidimensional context vector, takes an action, and then observes a\nmultidimensional feedback vector. This multidimensional feedback vector has no\nexplicit reward information. In order to succeed, the algorithm must learn how\nto evaluate the feedback vector to discover a latent reward signal, with which\nit can ground its policies without supervision. We show that in an\nInteraction-Grounded Learning setting, with certain natural assumptions, a\nlearner can discover the latent reward and ground its policy for successful\ninteraction. We provide theoretical guarantees and a proof-of-concept empirical\nevaluation to demonstrate the effectiveness of our proposed approach.",
          "link": "http://arxiv.org/abs/2106.04887",
          "publishedOn": "2021-06-10T01:56:49.517Z",
          "wordCount": 578,
          "title": "Interaction-Grounded Learning. (arXiv:2106.04887v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04684",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Folke_T/0/1/0/all/0/1\">Tomas Folke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Scott Cheng-Hsin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anderson_S/0/1/0/all/0/1\">Sean Anderson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shafto_P/0/1/0/all/0/1\">Patrick Shafto</a>",
          "description": "Limited expert time is a key bottleneck in medical imaging. Due to advances\nin image classification, AI can now serve as decision-support for medical\nexperts, with the potential for great gains in radiologist productivity and, by\nextension, public health. However, these gains are contingent on building and\nmaintaining experts' trust in the AI agents. Explainable AI may build such\ntrust by helping medical experts to understand the AI decision processes behind\ndiagnostic judgements. Here we introduce and evaluate explanations based on\nBayesian Teaching, a formal account of explanation rooted in the cognitive\nscience of human learning. We find that medical experts exposed to explanations\ngenerated by Bayesian Teaching successfully predict the AI's diagnostic\ndecisions and are more likely to certify the AI for cases when the AI is\ncorrect than when it is wrong, indicating appropriate trust. These results show\nthat Explainable AI can be used to support human-AI collaboration in medical\nimaging.",
          "link": "http://arxiv.org/abs/2106.04684",
          "publishedOn": "2021-06-10T01:56:49.506Z",
          "wordCount": 609,
          "title": "Explainable AI for medical imaging: Explaining pneumothorax diagnoses with Bayesian Teaching. (arXiv:2106.04684v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04835",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zichuan Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jing Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1\">Bowen Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiaodong He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1\">Tengyu Ma</a>",
          "description": "Recent work (Takanobu et al., 2020) proposed the system-wise evaluation on\ndialog systems and found that improvement on individual components (e.g., NLU,\npolicy) in prior work may not necessarily bring benefit to pipeline systems in\nsystem-wise evaluation. To improve the system-wise performance, in this paper,\nwe propose new joint system-wise optimization techniques for the pipeline\ndialog system. First, we propose a new data augmentation approach which\nautomates the labeling process for NLU training. Second, we propose a novel\nstochastic policy parameterization with Poisson distribution that enables\nbetter exploration and offers a principled way to compute policy gradient.\nThird, we propose a reward bonus to help policy explore successful dialogs. Our\napproaches outperform the competitive pipeline systems from Takanobu et al.\n(2020) by big margins of 12% success rate in automatic system-wise evaluation\nand of 16% success rate in human evaluation on the standard multi-domain\nbenchmark dataset MultiWOZ 2.1, and also outperform the recent state-of-the-art\nend-to-end trained model from DSTC9.",
          "link": "http://arxiv.org/abs/2106.04835",
          "publishedOn": "2021-06-10T01:56:49.489Z",
          "wordCount": 594,
          "title": "Joint System-Wise Optimization for Pipeline Goal-Oriented Dialog System. (arXiv:2106.04835v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04881",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Camuto_A/0/1/0/all/0/1\">Alexander Camuto</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Deligiannidis_G/0/1/0/all/0/1\">George Deligiannidis</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Erdogdu_M/0/1/0/all/0/1\">Murat A. Erdogdu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gurbuzbalaban_M/0/1/0/all/0/1\">Mert G&#xfc;rb&#xfc;zbalaban</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Simsekli_U/0/1/0/all/0/1\">Umut &#x15e;im&#x15f;ekli</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhu_L/0/1/0/all/0/1\">Lingjiong Zhu</a>",
          "description": "Understanding generalization in deep learning has been one of the major\nchallenges in statistical learning theory over the last decade. While recent\nwork has illustrated that the dataset and the training algorithm must be taken\ninto account in order to obtain meaningful generalization bounds, it is still\ntheoretically not clear which properties of the data and the algorithm\ndetermine the generalization performance. In this study, we approach this\nproblem from a dynamical systems theory perspective and represent stochastic\noptimization algorithms as random iterated function systems (IFS). Well studied\nin the dynamical systems literature, under mild assumptions, such IFSs can be\nshown to be ergodic with an invariant measure that is often supported on sets\nwith a fractal structure. As our main contribution, we prove that the\ngeneralization error of a stochastic optimization algorithm can be bounded\nbased on the `complexity' of the fractal structure that underlies its invariant\nmeasure. Leveraging results from dynamical systems theory, we show that the\ngeneralization error can be explicitly linked to the choice of the algorithm\n(e.g., stochastic gradient descent -- SGD), algorithm hyperparameters (e.g.,\nstep-size, batch-size), and the geometry of the problem (e.g., Hessian of the\nloss). We further specialize our results to specific problems (e.g.,\nlinear/logistic regression, one hidden-layered neural networks) and algorithms\n(e.g., SGD and preconditioned variants), and obtain analytical estimates for\nour bound.For modern neural networks, we develop an efficient algorithm to\ncompute the developed bound and support our theory with various experiments on\nneural networks.",
          "link": "http://arxiv.org/abs/2106.04881",
          "publishedOn": "2021-06-10T01:56:49.483Z",
          "wordCount": 686,
          "title": "Fractal Structure and Generalization Properties of Stochastic Optimization Algorithms. (arXiv:2106.04881v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04700",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Putta_S/0/1/0/all/0/1\">Sudeep Raja Putta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_S/0/1/0/all/0/1\">Shipra Agrawal</a>",
          "description": "We consider the Scale-Free Adversarial Multi Armed Bandit(MAB) problem, where\nthe player only knows the number of arms $n$ and not the scale or magnitude of\nthe losses. It sees bandit feedback about the loss vectors $l_1,\\dots, l_T \\in\n\\mathbb{R}^n$. The goal is to bound its regret as a function of $n$ and\n$l_1,\\dots, l_T$. We design a Follow The Regularized Leader(FTRL) algorithm,\nwhich comes with the first scale-free regret guarantee for MAB. It uses the log\nbarrier regularizer, the importance weighted estimator, an adaptive learning\nrate, and an adaptive exploration parameter. In the analysis, we introduce a\nsimple, unifying technique for obtaining regret inequalities for FTRL and\nOnline Mirror Descent(OMD) on the probability simplex using Potential Functions\nand Mixed Bregmans. We also develop a new technique for obtaining local-norm\nlower bounds for Bregman Divergences, which are crucial in bandit regret\nbounds. These tools could be of independent interest.",
          "link": "http://arxiv.org/abs/2106.04700",
          "publishedOn": "2021-06-10T01:56:49.478Z",
          "wordCount": 571,
          "title": "Scale Free Adversarial Multi Armed Bandits. (arXiv:2106.04700v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04927",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Runzhong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hua_Z/0/1/0/all/0/1\">Zhigang Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Gan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiayi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Junchi Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_F/0/1/0/all/0/1\">Feng Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shuang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jun Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiaokang Yang</a>",
          "description": "Combinatorial Optimization (CO) has been a long-standing challenging research\ntopic featured by its NP-hard nature. Traditionally such problems are\napproximately solved with heuristic algorithms which are usually fast but may\nsacrifice the solution quality. Currently, machine learning for combinatorial\noptimization (MLCO) has become a trending research topic, but most existing\nMLCO methods treat CO as a single-level optimization by directly learning the\nend-to-end solutions, which are hard to scale up and mostly limited by the\ncapacity of ML models given the high complexity of CO. In this paper, we\npropose a hybrid approach to combine the best of the two worlds, in which a\nbi-level framework is developed with an upper-level learning method to optimize\nthe graph (e.g. add, delete or modify edges in a graph), fused with a\nlower-level heuristic algorithm solving on the optimized graph. Such a bi-level\napproach simplifies the learning on the original hard CO and can effectively\nmitigate the demand for model capacity. The experiments and results on several\npopular CO problems like Directed Acyclic Graph scheduling, Graph Edit Distance\nand Hamiltonian Cycle Problem show its effectiveness over manually designed\nheuristics and single-level learning methods.",
          "link": "http://arxiv.org/abs/2106.04927",
          "publishedOn": "2021-06-10T01:56:49.472Z",
          "wordCount": 634,
          "title": "A Bi-Level Framework for Learning to Solve Combinatorial Optimization on Graphs. (arXiv:2106.04927v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04935",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meftah_S/0/1/0/all/0/1\">Sara Meftah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Semmar_N/0/1/0/all/0/1\">Nasredine Semmar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tamaazousti_Y/0/1/0/all/0/1\">Youssef Tamaazousti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Essafi_H/0/1/0/all/0/1\">Hassane Essafi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sadat_F/0/1/0/all/0/1\">Fatiha Sadat</a>",
          "description": "Neural Transfer Learning (TL) is becoming ubiquitous in Natural Language\nProcessing (NLP), thanks to its high performance on many tasks, especially in\nlow-resourced scenarios. Notably, TL is widely used for neural domain\nadaptation to transfer valuable knowledge from high-resource to low-resource\ndomains. In the standard fine-tuning scheme of TL, a model is initially\npre-trained on a source domain and subsequently fine-tuned on a target domain\nand, therefore, source and target domains are trained using the same\narchitecture. In this paper, we show through interpretation methods that such\nscheme, despite its efficiency, is suffering from a main limitation. Indeed,\nalthough capable of adapting to new domains, pre-trained neurons struggle with\nlearning certain patterns that are specific to the target domain. Moreover, we\nshed light on the hidden negative transfer occurring despite the high\nrelatedness between source and target domains, which may mitigate the final\ngain brought by transfer learning. To address these problems, we propose to\naugment the pre-trained model with normalised, weighted and randomly\ninitialised units that foster a better adaptation while maintaining the\nvaluable source knowledge. We show that our approach exhibits significant\nimprovements to the standard fine-tuning scheme for neural domain adaptation\nfrom the news domain to the social media domain on four NLP tasks:\npart-of-speech tagging, chunking, named entity recognition and morphosyntactic\ntagging.",
          "link": "http://arxiv.org/abs/2106.04935",
          "publishedOn": "2021-06-10T01:56:49.467Z",
          "wordCount": 657,
          "title": "Neural Supervised Domain Adaptation by Augmenting Pre-trained Models with Random Units. (arXiv:2106.04935v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04985",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Korbak_T/0/1/0/all/0/1\">Tomasz Korbak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elsahar_H/0/1/0/all/0/1\">Hady Elsahar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dymetman_M/0/1/0/all/0/1\">Marc Dymetman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kruszewski_G/0/1/0/all/0/1\">Germ&#xe1;n Kruszewski</a>",
          "description": "Neural language models can be successfully trained on source code, leading to\napplications such as code completion. However, their versatile autoregressive\nself-supervision objective overlooks important global sequence-level features\nthat are present in the data such as syntactic correctness or compilability. In\nthis work, we pose the problem of learning to generate compilable code as\nconstraint satisfaction. We define an Energy-Based Model (EBM) representing a\npre-trained generative model with an imposed constraint of generating only\ncompilable sequences. We then use the KL-Adaptive Distributional Policy\nGradient algorithm (Khalifa et al., 2021) to train a generative model\napproximating the EBM. We conduct experiments showing that our proposed\napproach is able to improve compilability rates without sacrificing diversity\nand complexity of the generated samples.",
          "link": "http://arxiv.org/abs/2106.04985",
          "publishedOn": "2021-06-10T01:56:49.455Z",
          "wordCount": 578,
          "title": "Energy-Based Models for Code Generation under Compilability Constraints. (arXiv:2106.04985v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2010.11038",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jinke He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suau_M/0/1/0/all/0/1\">Miguel Suau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oliehoek_F/0/1/0/all/0/1\">Frans A. Oliehoek</a>",
          "description": "How can we plan efficiently in real time to control an agent in a complex\nenvironment that may involve many other agents? While existing sample-based\nplanners have enjoyed empirical success in large POMDPs, their performance\nheavily relies on a fast simulator. However, real-world scenarios are complex\nin nature and their simulators are often computationally demanding, which\nseverely limits the performance of online planners. In this work, we propose\ninfluence-augmented online planning, a principled method to transform a\nfactored simulator of the entire environment into a local simulator that\nsamples only the state variables that are most relevant to the observation and\nreward of the planning agent and captures the incoming influence from the rest\nof the environment using machine learning methods. Our main experimental\nresults show that planning on this less accurate but much faster local\nsimulator with POMCP leads to higher real-time planning performance than\nplanning on the simulator that models the entire environment.",
          "link": "http://arxiv.org/abs/2010.11038",
          "publishedOn": "2021-06-10T01:56:49.428Z",
          "wordCount": 619,
          "title": "Influence-Augmented Online Planning for Complex Environments. (arXiv:2010.11038v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04690",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hong_S/0/1/0/all/0/1\">Sanghyun Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carlini_N/0/1/0/all/0/1\">Nicholas Carlini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurakin_A/0/1/0/all/0/1\">Alexey Kurakin</a>",
          "description": "Deep neural networks (DNNs), while accurate, are expensive to train. Many\npractitioners, therefore, outsource the training process to third parties or\nuse pre-trained DNNs. This practice makes DNNs vulnerable to $backdoor$\n$attacks$: the third party who trains the model may act maliciously to inject\nhidden behaviors into the otherwise accurate model. Until now, the mechanism to\ninject backdoors has been limited to $poisoning$.\n\nWe argue that such a supply-chain attacker has more attack techniques\navailable. To study this hypothesis, we introduce a handcrafted attack that\ndirectly manipulates the parameters of a pre-trained model to inject backdoors.\nOur handcrafted attacker has more degrees of freedom in manipulating model\nparameters than poisoning. This makes it difficult for a defender to identify\nor remove the manipulations with straightforward methods, such as statistical\nanalysis, adding random noises to model parameters, or clipping their values\nwithin a certain range. Further, our attacker can combine the handcrafting\nprocess with additional techniques, $e.g.$, jointly optimizing a trigger\npattern, to inject backdoors into complex networks effectively$-$the\nmeet-in-the-middle attack.\n\nIn evaluations, our handcrafted backdoors remain effective across four\ndatasets and four network architectures with a success rate above 96%. Our\nbackdoored models are resilient to both parameter-level backdoor removal\ntechniques and can evade existing defenses by slightly changing the backdoor\nattack configurations. Moreover, we demonstrate the feasibility of suppressing\nunwanted behaviors otherwise caused by poisoning. Our results suggest that\nfurther research is needed for understanding the complete space of supply-chain\nbackdoor attacks.",
          "link": "http://arxiv.org/abs/2106.04690",
          "publishedOn": "2021-06-10T01:56:49.413Z",
          "wordCount": 674,
          "title": "Handcrafted Backdoors in Deep Neural Networks. (arXiv:2106.04690v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05010",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Futami_F/0/1/0/all/0/1\">Futoshi Futami</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Iwata_T/0/1/0/all/0/1\">Tomoharu Iwata</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ueda_N/0/1/0/all/0/1\">Naonori Ueda</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sato_I/0/1/0/all/0/1\">Issei Sato</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masashi Sugiyama</a>",
          "description": "Bayesian model averaging, obtained as the expectation of a likelihood\nfunction by a posterior distribution, has been widely used for prediction,\nevaluation of uncertainty, and model selection. Various approaches have been\ndeveloped to efficiently capture the information in the posterior distribution;\none such approach is the optimization of a set of models simultaneously with\ninteraction to ensure the diversity of the individual models in the same way as\nensemble learning. A representative approach is particle variational inference\n(PVI), which uses an ensemble of models as an empirical approximation for the\nposterior distribution. PVI iteratively updates each model with a repulsion\nforce to ensure the diversity of the optimized models. However, despite its\npromising performance, a theoretical understanding of this repulsion and its\nassociation with the generalization ability remains unclear. In this paper, we\ntackle this problem in light of PAC-Bayesian analysis. First, we provide a new\nsecond-order Jensen inequality, which has the repulsion term based on the loss\nfunction. Thanks to the repulsion term, it is tighter than the standard Jensen\ninequality. Then, we derive a novel generalization error bound and show that it\ncan be reduced by enhancing the diversity of models. Finally, we derive a new\nPVI that optimizes the generalization error bound directly. Numerical\nexperiments demonstrate that the performance of the proposed PVI compares\nfavorably with existing methods in the experiment.",
          "link": "http://arxiv.org/abs/2106.05010",
          "publishedOn": "2021-06-10T01:56:49.406Z",
          "wordCount": 664,
          "title": "Loss function based second-order Jensen inequality and its application to particle variational inference. (arXiv:2106.05010v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04972",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pearce_T/0/1/0/all/0/1\">Tim Pearce</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brintrup_A/0/1/0/all/0/1\">Alexandra Brintrup</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jun Zhu</a>",
          "description": "It is often remarked that neural networks fail to increase their uncertainty\nwhen predicting on data far from the training distribution. Yet naively using\nsoftmax confidence as a proxy for uncertainty achieves modest success in tasks\nexclusively testing for this, e.g., out-of-distribution (OOD) detection. This\npaper investigates this contradiction, identifying two implicit biases that do\nencourage softmax confidence to correlate with epistemic uncertainty: 1)\nApproximately optimal decision boundary structure, and 2) Filtering effects of\ndeep networks. It describes why low-dimensional intuitions about softmax\nconfidence are misleading. Diagnostic experiments quantify reasons softmax\nconfidence can fail, finding that extrapolations are less to blame than overlap\nbetween training and OOD data in final-layer representations.\nPre-trained/fine-tuned networks reduce this overlap.",
          "link": "http://arxiv.org/abs/2106.04972",
          "publishedOn": "2021-06-10T01:56:49.400Z",
          "wordCount": 541,
          "title": "Understanding Softmax Confidence and Uncertainty. (arXiv:2106.04972v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05068",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jarboui_F/0/1/0/all/0/1\">Firas Jarboui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perchet_V/0/1/0/all/0/1\">Vianney Perchet</a>",
          "description": "The objective of offline RL is to learn optimal policies when a fixed\nexploratory demonstrations data-set is available and sampling additional\nobservations is impossible (typically if this operation is either costly or\nrises ethical questions). In order to solve this problem, off the shelf\napproaches require a properly defined cost function (or its evaluation on the\nprovided data-set), which are seldom available in practice. To circumvent this\nissue, a reasonable alternative is to query an expert for few optimal\ndemonstrations in addition to the exploratory data-set. The objective is then\nto learn an optimal policy w.r.t. the expert's latent cost function. Current\nsolutions either solve a behaviour cloning problem (which does not leverage the\nexploratory data) or a reinforced imitation learning problem (using a fixed\ncost function that discriminates available exploratory trajectories from expert\nones). Inspired by the success of IRL techniques in achieving state of the art\nimitation performances in online settings, we exploit GAN based data\naugmentation procedures to construct the first offline IRL algorithm. The\nobtained policies outperformed the aforementioned solutions on multiple OpenAI\ngym environments.",
          "link": "http://arxiv.org/abs/2106.05068",
          "publishedOn": "2021-06-10T01:56:49.393Z",
          "wordCount": 591,
          "title": "Offline Inverse Reinforcement Learning. (arXiv:2106.05068v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05001",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_M/0/1/0/all/0/1\">Mi Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1\">Fei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_D/0/1/0/all/0/1\">Dapeng Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yifan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1\">Jian Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jiashi Feng</a>",
          "description": "A central challenge in training classification models in the real-world\nfederated system is learning with non-IID data. To cope with this, most of the\nexisting works involve enforcing regularization in local optimization or\nimproving the model aggregation scheme at the server. Other works also share\npublic datasets or synthesized samples to supplement the training of\nunder-represented classes or introduce a certain level of personalization.\nThough effective, they lack a deep understanding of how the data heterogeneity\naffects each layer of a deep classification model. In this paper, we bridge\nthis gap by performing an experimental analysis of the representations learned\nby different layers. Our observations are surprising: (1) there exists a\ngreater bias in the classifier than other layers, and (2) the classification\nperformance can be significantly improved by post-calibrating the classifier\nafter federated training. Motivated by the above findings, we propose a novel\nand simple algorithm called Classifier Calibration with Virtual Representations\n(CCVR), which adjusts the classifier using virtual representations sampled from\nan approximated gaussian mixture model. Experimental results demonstrate that\nCCVR achieves state-of-the-art performance on popular federated learning\nbenchmarks including CIFAR-10, CIFAR-100, and CINIC-10. We hope that our simple\nyet effective method can shed some light on the future research of federated\nlearning with non-IID data.",
          "link": "http://arxiv.org/abs/2106.05001",
          "publishedOn": "2021-06-10T01:56:49.387Z",
          "wordCount": 666,
          "title": "No Fear of Heterogeneity: Classifier Calibration for Federated Learning with Non-IID Data. (arXiv:2106.05001v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04993",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yinan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Boyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miao_C/0/1/0/all/0/1\">Chunyan Miao</a>",
          "description": "Proper initialization is crucial to the optimization and the generalization\nof neural networks. However, most existing neural recommendation systems\ninitialize the user and item embeddings randomly. In this work, we propose a\nnew initialization scheme for user and item embeddings called Laplacian\nEigenmaps with Popularity-based Regularization for Isolated Data (LEPORID).\nLEPORID endows the embeddings with information regarding multi-scale\nneighborhood structures on the data manifold and performs adaptive\nregularization to compensate for high embedding variance on the tail of the\ndata distribution. Exploiting matrix sparsity, LEPORID embeddings can be\ncomputed efficiently. We evaluate LEPORID in a wide range of neural\nrecommendation models. In contrast to the recent surprising finding that the\nsimple K-nearest-neighbor (KNN) method often outperforms neural recommendation\nsystems, we show that existing neural systems initialized with LEPORID often\nperform on par or better than KNN. To maximize the effects of the\ninitialization, we propose the Dual-Loss Residual Recommendation (DLR2)\nnetwork, which, when initialized with LEPORID, substantially outperforms both\ntraditional and state-of-the-art neural recommender systems.",
          "link": "http://arxiv.org/abs/2106.04993",
          "publishedOn": "2021-06-10T01:56:49.382Z",
          "wordCount": 597,
          "title": "Initialization Matters: Regularizing Manifold-informed Initialization for Neural Recommendation Systems. (arXiv:2106.04993v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04990",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Venkataramanan_S/0/1/0/all/0/1\">Shashanka Venkataramanan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Psomas_B/0/1/0/all/0/1\">Bill Psomas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Avrithis_Y/0/1/0/all/0/1\">Yannis Avrithis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kijak_E/0/1/0/all/0/1\">Ewa Kijak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amsaleg_L/0/1/0/all/0/1\">Laurent Amsaleg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karantzalos_K/0/1/0/all/0/1\">Konstantinos Karantzalos</a>",
          "description": "Metric learning involves learning a discriminative representation such that\nembeddings of similar classes are encouraged to be close, while embeddings of\ndissimilar classes are pushed far apart. State-of-the-art methods focus mostly\non sophisticated loss functions or mining strategies. On the one hand, metric\nlearning losses consider two or more examples at a time. On the other hand,\nmodern data augmentation methods for classification consider two or more\nexamples at a time. The combination of the two ideas is under-studied.\n\nIn this work, we aim to bridge this gap and improve representations using\nmixup, which is a powerful data augmentation approach interpolating two or more\nexamples and corresponding target labels at a time. This task is challenging\nbecause, unlike classification, the loss functions used in metric learning are\nnot additive over examples, so the idea of interpolating target labels is not\nstraightforward. To the best of our knowledge, we are the first to investigate\nmixing examples and target labels for deep metric learning. We develop a\ngeneralized formulation that encompasses existing metric learning loss\nfunctions and modify it to accommodate for mixup, introducing Metric Mix, or\nMetrix. We show that mixing inputs, intermediate representations or embeddings\nalong with target labels significantly improves representations and outperforms\nstate-of-the-art metric learning methods on four benchmark datasets.",
          "link": "http://arxiv.org/abs/2106.04990",
          "publishedOn": "2021-06-10T01:56:49.375Z",
          "wordCount": 651,
          "title": "It Takes Two to Tango: Mixup for Deep Metric Learning. (arXiv:2106.04990v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2012.12109",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xia_M/0/1/0/all/0/1\">Menghan Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1\">Chu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_T/0/1/0/all/0/1\">Tien-Tsin Wong</a>",
          "description": "As a generic modeling tool, Convolutional Neural Networks (CNNs) have been\nwidely employed in image generation and translation tasks. However, when fed\nwith a flat input, current CNN models may fail to generate vivid results due to\nthe spatially shared convolution kernels. We call it the flatness degradation\nof CNNs. Unfortunately, such degradation is the greatest obstacles to generate\na spatially-variant output from a flat input, which has been barely discussed\nin the previous literature. To tackle this problem, we propose a model agnostic\nsolution, i.e. Noise Incentive Block (NIB), which serves as a generic plug-in\nfor any CNN generation model. The key idea is to break the flat input condition\nwhile keeping the intactness of the original information. Specifically, the NIB\nperturbs the input data symmetrically with a noise map and reassembles them in\nthe feature domain as driven by the objective function. Extensive experiments\nshow that existing CNN models equipped with NIB survive from the flatness\ndegradation and are able to generate visually better results with richer\ndetails in some specific image generation tasks given flat inputs, e.g.\nsemantic image synthesis, data-hidden image generation, and deep neural\ndithering.",
          "link": "http://arxiv.org/abs/2012.12109",
          "publishedOn": "2021-06-10T01:56:49.370Z",
          "wordCount": 650,
          "title": "Enhance Convolutional Neural Networks with Noise Incentive Block. (arXiv:2012.12109v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05022",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Laskaridis_S/0/1/0/all/0/1\">Stefanos Laskaridis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kouris_A/0/1/0/all/0/1\">Alexandros Kouris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lane_N/0/1/0/all/0/1\">Nicholas D. Lane</a>",
          "description": "DNNs are becoming less and less over-parametrised due to recent advances in\nefficient model design, through careful hand-crafted or NAS-based methods.\nRelying on the fact that not all inputs require the same amount of computation\nto yield a confident prediction, adaptive inference is gaining attention as a\nprominent approach for pushing the limits of efficient deployment.\nParticularly, early-exit networks comprise an emerging direction for tailoring\nthe computation depth of each input sample at runtime, offering complementary\nperformance gains to other efficiency optimisations. In this paper, we\ndecompose the design methodology of early-exit networks to its key components\nand survey the recent advances in each one of them. We also position\nearly-exiting against other efficient inference solutions and provide our\ninsights on the current challenges and most promising future directions for\nresearch in the field.",
          "link": "http://arxiv.org/abs/2106.05022",
          "publishedOn": "2021-06-10T01:56:49.352Z",
          "wordCount": 577,
          "title": "Adaptive Inference through Early-Exit Networks: Design, Challenges and Directions. (arXiv:2106.05022v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05012",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fellows_M/0/1/0/all/0/1\">Matthew Fellows</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hartikainen_K/0/1/0/all/0/1\">Kristian Hartikainen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Whiteson_S/0/1/0/all/0/1\">Shimon Whiteson</a>",
          "description": "We introduce a novel perspective on Bayesian reinforcement learning (RL);\nwhereas existing approaches infer a posterior over the transition distribution\nor Q-function, we characterise the uncertainty in the Bellman operator. Our\nBayesian Bellman operator (BBO) framework is motivated by the insight that when\nbootstrapping is introduced, model-free approaches actually infer a posterior\nover Bellman operators, not value functions. In this paper, we use BBO to\nprovide a rigorous theoretical analysis of model-free Bayesian RL to better\nunderstand its relationshipto established frequentist RL methodologies. We\nprove that Bayesian solutions are consistent with frequentist RL solutions,\neven when approximate inference isused, and derive conditions for which\nconvergence properties hold. Empirically, we demonstrate that algorithms\nderived from the BBO framework have sophisticated deep exploration properties\nthat enable them to solve continuous control tasks at which state-of-the-art\nregularised actor-critic algorithms fail catastrophically",
          "link": "http://arxiv.org/abs/2106.05012",
          "publishedOn": "2021-06-10T01:56:49.342Z",
          "wordCount": 550,
          "title": "Bayesian Bellman Operators. (arXiv:2106.05012v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2012.04830",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaoqing Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hu_Y/0/1/0/all/0/1\">Yan Hu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fang_J/0/1/0/all/0/1\">Jiansheng Fang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_Y/0/1/0/all/0/1\">Yanwu Xu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Higashita_R/0/1/0/all/0/1\">Risa Higashita</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_J/0/1/0/all/0/1\">Jiang Liu</a>",
          "description": "Cataract is one of the leading causes of reversible visual impairment and\nblindness globally. Over the years, researchers have achieved significant\nprogress in developing state-of-the-art artificial intelligence techniques for\nautomatic cataract classification and grading, helping clinicians prevent and\ntreat cataract in time. This paper provides a comprehensive survey of recent\nadvances in machine learning for cataract classification and grading based on\nophthalmic images. We summarize existing literature from two research\ndirections: conventional machine learning techniques and deep learning\ntechniques. This paper also provides insights into existing works of both\nmerits and limitations. In addition, we discuss several challenges of automatic\ncataract classification and grading based on machine learning techniques and\npresent possible solutions to these challenges for future research.",
          "link": "http://arxiv.org/abs/2012.04830",
          "publishedOn": "2021-06-10T01:56:49.317Z",
          "wordCount": 597,
          "title": "Machine Learning for Cataract Classification and Grading on Ophthalmic Imaging Modalities: A Survey. (arXiv:2012.04830v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05264",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Arandjelovic_R/0/1/0/all/0/1\">Relja Arandjelovi&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zisserman_A/0/1/0/all/0/1\">Andrew Zisserman</a>",
          "description": "Neural radiance fields (NeRF) methods have demonstrated impressive novel view\nsynthesis performance. The core approach is to render individual rays by\nquerying a neural network at points sampled along the ray to obtain the density\nand colour of the sampled points, and integrating this information using the\nrendering equation. Since dense sampling is computationally prohibitive, a\ncommon solution is to perform coarse-to-fine sampling.\n\nIn this work we address a clear limitation of the vanilla coarse-to-fine\napproach -- that it is based on a heuristic and not trained end-to-end for the\ntask at hand. We introduce a differentiable module that learns to propose\nsamples and their importance for the fine network, and consider and compare\nmultiple alternatives for its neural architecture. Training the proposal module\nfrom scratch can be unstable due to lack of supervision, so an effective\npre-training strategy is also put forward. The approach, named `NeRF in detail'\n(NeRF-ID), achieves superior view synthesis quality over NeRF and the\nstate-of-the-art on the synthetic Blender benchmark and on par or better\nperformance on the real LLFF-NeRF scenes. Furthermore, by leveraging the\npredicted sample importance, a 25% saving in computation can be achieved\nwithout significantly sacrificing the rendering quality.",
          "link": "http://arxiv.org/abs/2106.05264",
          "publishedOn": "2021-06-10T01:56:49.293Z",
          "wordCount": 632,
          "title": "NeRF in detail: Learning to sample for view synthesis. (arXiv:2106.05264v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04757",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ozdayi_M/0/1/0/all/0/1\">Mustafa Safa Ozdayi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kantarcioglu_M/0/1/0/all/0/1\">Murat Kantarcioglu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iyer_R/0/1/0/all/0/1\">Rishabh Iyer</a>",
          "description": "Prior studies have shown that, training machine learning models via empirical\nloss minimization to maximize a utility metric (e.g., accuracy), might yield\nmodels that make discriminatory predictions. To alleviate this issue, we\ndevelop a new training algorithm, named BiFair, which jointly minimizes for a\nutility, and a fairness loss of interest. Crucially, we do so without directly\nmodifying the training objective, e.g., by adding regularization terms. Rather,\nwe learn a set of weights on the training dataset, such that, training on the\nweighted dataset ensures both good utility, and fairness. The dataset weights\nare learned in concurrence to the model training, which is done by solving a\nbilevel optimization problem using a held-out validation dataset. Overall, this\napproach yields models with better fairness-utility trade-offs. Particularly,\nwe compare our algorithm with three other state-of-the-art fair training\nalgorithms over three real-world datasets, and demonstrate that, BiFair\nconsistently performs better, i.e., we reach to better values of a given\nfairness metric under same, or higher accuracy. Further, our algorithm is\nscalable. It is applicable both to simple models, such as logistic regression,\nas well as more complex models, such as deep neural networks, as evidenced by\nour experimental analysis.",
          "link": "http://arxiv.org/abs/2106.04757",
          "publishedOn": "2021-06-10T01:56:49.114Z",
          "wordCount": 621,
          "title": "BiFair: Training Fair Models with Bilevel Optimization. (arXiv:2106.04757v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04795",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Huiyuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1\">Wei Lin</a>",
          "description": "Overparametrized neural networks, where the number of active parameters is\nlarger than the sample size, prove remarkably effective in modern deep learning\npractice. From the classical perspective, however, much fewer parameters are\nsufficient for optimal estimation and prediction, whereas overparametrization\ncan be harmful even in the presence of explicit regularization. To reconcile\nthis conflict, we present a generalization theory for overparametrized ReLU\nnetworks by incorporating an explicit regularizer based on the scaled variation\nnorm. Interestingly, this regularizer is equivalent to the ridge from the angle\nof gradient-based optimization, but is similar to the group lasso in terms of\ncontrolling model complexity. By exploiting this ridge-lasso duality, we show\nthat overparametrization is generally harmless to two-layer ReLU networks. In\nparticular, the overparametrized estimators are minimax optimal up to a\nlogarithmic factor. By contrast, we show that overparametrized random feature\nmodels suffer from the curse of dimensionality and thus are suboptimal.",
          "link": "http://arxiv.org/abs/2106.04795",
          "publishedOn": "2021-06-10T01:56:49.108Z",
          "wordCount": 581,
          "title": "Harmless Overparametrization in Two-layer Neural Networks. (arXiv:2106.04795v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04759",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Spiridonoff_A/0/1/0/all/0/1\">Artin Spiridonoff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Olshevsky_A/0/1/0/all/0/1\">Alex Olshevsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paschalidis_I/0/1/0/all/0/1\">Ioannis Ch. Paschalidis</a>",
          "description": "We consider speeding up stochastic gradient descent (SGD) by parallelizing it\nacross multiple workers. We assume the same data set is shared among $N$\nworkers, who can take SGD steps and coordinate with a central server. While it\nis possible to obtain a linear reduction in the variance by averaging all the\nstochastic gradients at every step, this requires a lot of communication\nbetween the workers and the server, which can dramatically reduce the gains\nfrom parallelism. The Local SGD method, proposed and analyzed in the earlier\nliterature, suggests machines should make many local steps between such\ncommunications. While the initial analysis of Local SGD showed it needs $\\Omega\n( \\sqrt{T} )$ communications for $T$ local gradient steps in order for the\nerror to scale proportionately to $1/(NT)$, this has been successively improved\nin a string of papers, with the state-of-the-art requiring $\\Omega \\left( N\n\\left( \\mbox{ polynomial in log } (T) \\right) \\right)$ communications. In this\npaper, we suggest a Local SGD scheme that communicates less overall by\ncommunicating less frequently as the number of iterations grows. Our analysis\nshows that this can achieve an error that scales as $1/(NT)$ with a number of\ncommunications that is completely independent of $T$. In particular, we show\nthat $\\Omega(N)$ communications are sufficient. Empirical evidence suggests\nthis bound is close to tight as we further show that $\\sqrt{N}$ or $N^{3/4}$\ncommunications fail to achieve linear speed-up in simulations. Moreover, we\nshow that under mild assumptions, the main of which is twice differentiability\non any neighborhood of the optimal solution, one-shot averaging which only uses\na single round of communication can also achieve the optimal convergence rate\nasymptotically.",
          "link": "http://arxiv.org/abs/2106.04759",
          "publishedOn": "2021-06-10T01:56:49.103Z",
          "wordCount": 723,
          "title": "Communication-efficient SGD: From Local SGD to One-Shot Averaging. (arXiv:2106.04759v1 [cs.DC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05150",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zengfeng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shengzhong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xi_C/0/1/0/all/0/1\">Chong Xi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1\">Min Zhou</a>",
          "description": "Scalability of graph neural networks remains one of the major challenges in\ngraph machine learning. Since the representation of a node is computed by\nrecursively aggregating and transforming representation vectors of its\nneighboring nodes from previous layers, the receptive fields grow\nexponentially, which makes standard stochastic optimization techniques\nineffective. Various approaches have been proposed to alleviate this issue,\ne.g., sampling-based methods and techniques based on pre-computation of graph\nfilters.\n\nIn this paper, we take a different approach and propose to use graph\ncoarsening for scalable training of GNNs, which is generic, extremely simple\nand has sublinear memory and time costs during training. We present extensive\ntheoretical analysis on the effect of using coarsening operations and provides\nuseful guidance on the choice of coarsening methods. Interestingly, our\ntheoretical analysis shows that coarsening can also be considered as a type of\nregularization and may improve the generalization. Finally, empirical results\non real world datasets show that, simply applying off-the-shelf coarsening\nmethods, we can reduce the number of nodes by up to a factor of ten without\ncausing a noticeable downgrade in classification accuracy.",
          "link": "http://arxiv.org/abs/2106.05150",
          "publishedOn": "2021-06-10T01:56:49.048Z",
          "wordCount": 616,
          "title": "Scaling Up Graph Neural Networks Via Graph Coarsening. (arXiv:2106.05150v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2010.03957",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Geneva_N/0/1/0/all/0/1\">Nicholas Geneva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zabaras_N/0/1/0/all/0/1\">Nicholas Zabaras</a>",
          "description": "Transformers are widely used in natural language processing due to their\nability to model longer-term dependencies in text. Although these models\nachieve state-of-the-art performance for many language related tasks, their\napplicability outside of the natural language processing field has been\nminimal. In this work, we propose the use of transformer models for the\nprediction of dynamical systems representative of physical phenomena. The use\nof Koopman based embeddings provide a unique and powerful method for projecting\nany dynamical system into a vector representation which can then be predicted\nby a transformer model. The proposed model is able to accurately predict\nvarious dynamical systems and outperform classical methods that are commonly\nused in the scientific machine learning literature.",
          "link": "http://arxiv.org/abs/2010.03957",
          "publishedOn": "2021-06-10T01:56:49.042Z",
          "wordCount": 596,
          "title": "Transformers for Modeling Physical Systems. (arXiv:2010.03957v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.03110",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sontakke_S/0/1/0/all/0/1\">Sumedh A. Sontakke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehrjou_A/0/1/0/all/0/1\">Arash Mehrjou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Itti_L/0/1/0/all/0/1\">Laurent Itti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1\">Bernhard Sch&#xf6;lkopf</a>",
          "description": "Animals exhibit an innate ability to learn regularities of the world through\ninteraction. By performing experiments in their environment, they are able to\ndiscern the causal factors of variation and infer how they affect the world's\ndynamics. Inspired by this, we attempt to equip reinforcement learning agents\nwith the ability to perform experiments that facilitate a categorization of the\nrolled-out trajectories, and to subsequently infer the causal factors of the\nenvironment in a hierarchical manner. We introduce {\\em causal curiosity}, a\nnovel intrinsic reward, and show that it allows our agents to learn optimal\nsequences of actions and discover causal factors in the dynamics of the\nenvironment. The learned behavior allows the agents to infer a binary quantized\nrepresentation for the ground-truth causal factors in every environment.\nAdditionally, we find that these experimental behaviors are semantically\nmeaningful (e.g., our agents learn to lift blocks to categorize them by\nweight), and are learnt in a self-supervised manner with approximately 2.5\ntimes less data than conventional supervised planners. We show that these\nbehaviors can be re-purposed and fine-tuned (e.g., from lifting to pushing or\nother downstream tasks). Finally, we show that the knowledge of causal factor\nrepresentations aids zero-shot learning for more complex tasks. Visit\nhttps://sites.google.com/usc.edu/causal-curiosity/home for website.",
          "link": "http://arxiv.org/abs/2010.03110",
          "publishedOn": "2021-06-10T01:56:49.034Z",
          "wordCount": 691,
          "title": "Causal Curiosity: RL Agents Discovering Self-supervised Experiments for Causal Representation Learning. (arXiv:2010.03110v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1905.13308",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Livezey_J/0/1/0/all/0/1\">Jesse A. Livezey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_A/0/1/0/all/0/1\">Ahyeon Hwang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeung_J/0/1/0/all/0/1\">Jacob Yeung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bouchard_K/0/1/0/all/0/1\">Kristofer E. Bouchard</a>",
          "description": "Hierarchy and compositionality are common latent properties in many natural\nand scientific datasets. Determining when a deep network's hidden activations\nrepresent hierarchy and compositionality is important both for understanding\ndeep representation learning and for applying deep networks in domains where\ninterpretability is crucial. However, current benchmark machine learning\ndatasets either have little hierarchical or compositional structure, or the\nstructure is not known. This gap impedes precise analysis of a network's\nrepresentations and thus hinders development of new methods that can learn such\nproperties. To address this gap, we developed a new benchmark dataset with\nknown hierarchical and compositional structure. The Hangul Fonts Dataset (HFD)\nis comprised of 35 fonts from the Korean writing system (Hangul), each with\n11,172 blocks (syllables) composed from the product of initial consonant,\nmedial vowel, and final consonant glyphs. All blocks can be grouped into a few\ngeometric types which induces a hierarchy across blocks. In addition, each\nblock is composed of individual glyphs with rotations, translations, scalings,\nand naturalistic style variation across fonts. We find that both shallow and\ndeep unsupervised methods only show modest evidence of hierarchy and\ncompositionality in their representations of the HFD compared to supervised\ndeep networks. Supervised deep network representations contain structure\nrelated to the geometrical hierarchy of the characters, but the compositional\nstructure of the data is not evident. Thus, HFD enables the identification of\nshortcomings in existing methods, a critical first step toward developing new\nmachine learning algorithms to extract hierarchical and compositional structure\nin the context of naturalistic variability.",
          "link": "http://arxiv.org/abs/1905.13308",
          "publishedOn": "2021-06-10T01:56:49.028Z",
          "wordCount": 732,
          "title": "Hangul Fonts Dataset: a Hierarchical and Compositional Dataset for Investigating Learned Representations. (arXiv:1905.13308v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05087",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yanchao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_R/0/1/0/all/0/1\">Ruijie Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yongyuan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Furong Huang</a>",
          "description": "Evaluating the worst-case performance of a reinforcement learning (RL) agent\nunder the strongest/optimal adversarial perturbations on state observations\n(within some constraints) is crucial for understanding the robustness of RL\nagents. However, finding the optimal adversary is challenging, in terms of both\nwhether we can find the optimal attack and how efficiently we can find it.\nExisting works on adversarial RL either use heuristics-based methods that may\nnot find the strongest adversary, or directly train an RL-based adversary by\ntreating the agent as a part of the environment, which can find the optimal\nadversary but may become intractable in a large state space. In this paper, we\npropose a novel attacking algorithm which has an RL-based \"director\" searching\nfor the optimal policy perturbation, and an \"actor\" crafting state\nperturbations following the directions from the director (i.e. the actor\nexecutes targeted attacks). Our proposed algorithm, PA-AD, is theoretically\noptimal against an RL agent and significantly improves the efficiency compared\nwith prior RL-based works in environments with large or pixel state spaces.\nEmpirical results show that our proposed PA-AD universally outperforms\nstate-of-the-art attacking methods in a wide range of environments. Our method\ncan be easily applied to any RL algorithms to evaluate and improve their\nrobustness.",
          "link": "http://arxiv.org/abs/2106.05087",
          "publishedOn": "2021-06-10T01:56:49.022Z",
          "wordCount": null,
          "title": "Who Is the Strongest Enemy? Towards Optimal and Efficient Evasion Attacks in Deep RL. (arXiv:2106.05087v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2006.10259",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Gao_R/0/1/0/all/0/1\">Ruiqi Gao</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Xie_J/0/1/0/all/0/1\">Jianwen Xie</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Wei_X/0/1/0/all/0/1\">Xue-Xin Wei</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhu_S/0/1/0/all/0/1\">Song-Chun Zhu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Wu_Y/0/1/0/all/0/1\">Ying Nian Wu</a>",
          "description": "Understanding how grid cells perform path integration calculations remains a\nfundamental problem. In this paper, we conduct theoretical analysis of a\ngeneral representation model of path integration by grid cells, where the 2D\nself-position is encoded as a higher dimensional vector, and the 2D self-motion\nis represented by a general transformation of the vector. We identify two\nconditions on the transformation. One is a group representation condition that\nis necessary for path integration. The other is an isotropic scaling condition\nthat ensures locally conformal embedding, so that the error in the vector\nrepresentation translates proportionally to the error in the 2D self-position.\nThen we investigate the simplest transformation, i.e., the linear\ntransformation, uncover its explicit algebraic and geometric structure as\nmatrix Lie group of rotation, and establish the connection between the\nisotropic scaling condition and hexagon grid patterns of grid cells under the\nlinear transformation. Finally, with our optimization-based approach, we manage\nto learn hexagon grid patterns that share similar properties of the grid cells\nin the rodent brain. The learned model is capable of accurate long distance\npath integration.",
          "link": "http://arxiv.org/abs/2006.10259",
          "publishedOn": "2021-06-10T01:56:49.022Z",
          "wordCount": null,
          "title": "On Path Integration of Grid Cells: Group Representation and Isotropic Scaling. (arXiv:2006.10259v5 [q-bio.NC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1804.06679",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Amjad_R/0/1/0/all/0/1\">Rana Ali Amjad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1\">Kairen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geiger_B/0/1/0/all/0/1\">Bernhard C. Geiger</a>",
          "description": "In this work, we investigate the use of three information-theoretic\nquantities -- entropy, mutual information with the class variable, and a class\nselectivity measure based on Kullback-Leibler divergence -- to understand and\nstudy the behavior of already trained fully-connected feed-forward neural\nnetworks. We analyze the connection between these information-theoretic\nquantities and classification performance on the test set by cumulatively\nablating neurons in networks trained on MNIST, FashionMNIST, and CIFAR-10. Our\nresults parallel those recently published by Morcos et al., indicating that\nclass selectivity is not a good indicator for classification performance.\nHowever, looking at individual layers separately, both mutual information and\nclass selectivity are positively correlated with classification performance, at\nleast for networks with ReLU activation functions. We provide explanations for\nthis phenomenon and conclude that it is ill-advised to compare the proposed\ninformation-theoretic quantities across layers. Furthermore, we show that\ncumulative ablation of neurons with ascending or descending\ninformation-theoretic quantities can be used to formulate hypotheses regarding\nthe joint behavior of multiple neurons, such as redundancy and synergy, with\ncomparably low computational cost. We also draw connections to the information\nbottleneck theory for neural networks.",
          "link": "http://arxiv.org/abs/1804.06679",
          "publishedOn": "2021-06-10T01:56:49.008Z",
          "wordCount": 698,
          "title": "Understanding Neural Networks and Individual Neuron Importance via Information-Ordered Cumulative Ablation. (arXiv:1804.06679v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1912.00009",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shiyuan Li</a>",
          "description": "Spike-timing dependent plasticity (STDP) which observed in the brain has\nproven to be important in biological learning. On the other hand, artificial\nneural networks use a different way to learn, such as Back-Propagation or\nContrastive Hebbian Learning. In this work, we propose a new framework called\nmstdp that learn almost the same way biological learning use, it only uses STDP\nrules for supervised and unsupervised learning and don' t need a global loss or\nother supervise information. The framework works like an auto-encoder by making\neach input neuron also an output neuron. It can make predictions or generate\npatterns in one model without additional configuration. We also brought a new\niterative inference method using momentum to make the framework more efficient,\nwhich can be used in training and testing phases. Finally, we verified our\nframework on MNIST dataset for classification and generation task.",
          "link": "http://arxiv.org/abs/1912.00009",
          "publishedOn": "2021-06-10T01:56:48.992Z",
          "wordCount": 606,
          "title": "MSTDP: A More Biologically Plausible Learning. (arXiv:1912.00009v2 [cs.NE] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04938",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1\">Boxi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_H/0/1/0/all/0/1\">Heng Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Li Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jindong Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Shuai Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhifeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_D/0/1/0/all/0/1\">Deng Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiaofei He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wei Liu</a>",
          "description": "It is well known that adversarial attacks can fool deep neural networks with\nimperceptible perturbations. Although adversarial training significantly\nimproves model robustness, failure cases of defense still broadly exist. In\nthis work, we find that the adversarial attacks can also be vulnerable to small\nperturbations. Namely, on adversarially-trained models, perturbing adversarial\nexamples with a small random noise may invalidate their misled predictions.\nAfter carefully examining state-of-the-art attacks of various kinds, we find\nthat all these attacks have this deficiency to different extents. Enlightened\nby this finding, we propose to counter attacks by crafting more effective\ndefensive perturbations. Our defensive perturbations leverage the advantage\nthat adversarial training endows the ground-truth class with smaller local\nLipschitzness. By simultaneously attacking all the classes, the misled\npredictions with larger Lipschitzness can be flipped into correct ones. We\nverify our defensive perturbation with both empirical experiments and\ntheoretical analyses on a linear model. On CIFAR10, it boosts the\nstate-of-the-art model from 66.16% to 72.66% against the four attacks of\nAutoAttack, including 71.76% to 83.30% against the Square attack. On ImageNet,\nthe top-1 robust accuracy of FastAT is improved from 33.18% to 38.54% under the\n100-step PGD attack.",
          "link": "http://arxiv.org/abs/2106.04938",
          "publishedOn": "2021-06-10T01:56:48.984Z",
          "wordCount": 627,
          "title": "Attacking Adversarial Attacks as A Defense. (arXiv:2106.04938v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2008.03130",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Demir_C/0/1/0/all/0/1\">Caglar Demir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ngomo_A/0/1/0/all/0/1\">Axel-Cyrille Ngonga Ngomo</a>",
          "description": "In this paper, we study the problem of learning continuous vector\nrepresentations of knowledge graphs for predicting missing links. We present a\nnew approach called ConEx, which infers missing links by leveraging the\ncomposition of a 2D convolution with a Hermitian inner product of\ncomplex-valued embedding vectors. We evaluate ConEx against state-of-the-art\napproaches on the WN18RR, FB15K-237, KINSHIP and UMLS benchmark datasets. Our\nexperimental results show that ConEx achieves a performance superior to that of\nstate-of-the-art approaches such as RotatE, QuatE and TuckER on the link\nprediction task on all datasets while requiring at least 8 times fewer\nparameters. We ensure the reproducibility of our results by providing an\nopen-source implementation which includes the training, evaluation scripts\nalong with pre-trained models at https://github.com/conex-kge/ConEx.",
          "link": "http://arxiv.org/abs/2008.03130",
          "publishedOn": "2021-06-10T01:56:48.979Z",
          "wordCount": 587,
          "title": "Convolutional Complex Knowledge Graph Embeddings. (arXiv:2008.03130v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.10472",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wortsman_M/0/1/0/all/0/1\">Mitchell Wortsman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Horton_M/0/1/0/all/0/1\">Maxwell Horton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guestrin_C/0/1/0/all/0/1\">Carlos Guestrin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farhadi_A/0/1/0/all/0/1\">Ali Farhadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rastegari_M/0/1/0/all/0/1\">Mohammad Rastegari</a>",
          "description": "Recent observations have advanced our understanding of the neural network\noptimization landscape, revealing the existence of (1) paths of high accuracy\ncontaining diverse solutions and (2) wider minima offering improved\nperformance. Previous methods observing diverse paths require multiple training\nruns. In contrast we aim to leverage both property (1) and (2) with a single\nmethod and in a single training run. With a similar computational cost as\ntraining one model, we learn lines, curves, and simplexes of high-accuracy\nneural networks. These neural network subspaces contain diverse solutions that\ncan be ensembled, approaching the ensemble performance of independently trained\nnetworks without the training cost. Moreover, using the subspace midpoint\nboosts accuracy, calibration, and robustness to label noise, outperforming\nStochastic Weight Averaging.",
          "link": "http://arxiv.org/abs/2102.10472",
          "publishedOn": "2021-06-10T01:56:48.969Z",
          "wordCount": null,
          "title": "Learning Neural Network Subspaces. (arXiv:2102.10472v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04939",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nikzad_Khasmakhi_N/0/1/0/all/0/1\">Narjes Nikzad-Khasmakhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feizi_Derakhshi_M/0/1/0/all/0/1\">Mohammad-Reza Feizi-Derakhshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asgari_Chenaghlu_M/0/1/0/all/0/1\">Meysam Asgari-Chenaghlu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balafar_M/0/1/0/all/0/1\">Mohammad-Ali Balafar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feizi_Derakhshi_A/0/1/0/all/0/1\">Ali-Reza Feizi-Derakhshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahkar_Farshi_T/0/1/0/all/0/1\">Taymaz Rahkar-Farshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramezani_M/0/1/0/all/0/1\">Majid Ramezani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jahanbakhsh_Nagadeh_Z/0/1/0/all/0/1\">Zoleikha Jahanbakhsh-Nagadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zafarani_Moattar_E/0/1/0/all/0/1\">Elnaz Zafarani-Moattar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranjbar_Khadivi_M/0/1/0/all/0/1\">Mehrdad Ranjbar-Khadivi</a>",
          "description": "Background: Keyword extraction is a popular research topic in the field of\nnatural language processing. Keywords are terms that describe the most relevant\ninformation in a document. The main problem that researchers are facing is how\nto efficiently and accurately extract the core keywords from a document.\nHowever, previous keyword extraction approaches have utilized the text and\ngraph features, there is the lack of models that can properly learn and combine\nthese features in a best way.\n\nMethods: In this paper, we develop a multimodal Key-phrase extraction\napproach, namely Phraseformer, using transformer and graph embedding\ntechniques. In Phraseformer, each keyword candidate is presented by a vector\nwhich is the concatenation of the text and structure learning representations.\nPhraseformer takes the advantages of recent researches such as BERT and ExEm to\npreserve both representations. Also, the Phraseformer treats the key-phrase\nextraction task as a sequence labeling problem solved using classification\ntask.\n\nResults: We analyze the performance of Phraseformer on three datasets\nincluding Inspec, SemEval2010 and SemEval 2017 by F1-score. Also, we\ninvestigate the performance of different classifiers on Phraseformer method\nover Inspec dataset. Experimental results demonstrate the effectiveness of\nPhraseformer method over the three datasets used. Additionally, the Random\nForest classifier gain the highest F1-score among all classifiers.\n\nConclusions: Due to the fact that the combination of BERT and ExEm is more\nmeaningful and can better represent the semantic of words. Hence, Phraseformer\nsignificantly outperforms single-modality methods.",
          "link": "http://arxiv.org/abs/2106.04939",
          "publishedOn": "2021-06-10T01:56:48.967Z",
          "wordCount": null,
          "title": "Phraseformer: Multimodal Key-phrase Extraction using Transformer and Graph Embedding. (arXiv:2106.04939v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05200",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Gresele_L/0/1/0/all/0/1\">Luigi Gresele</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kugelgen_J/0/1/0/all/0/1\">Julius von K&#xfc;gelgen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Stimper_V/0/1/0/all/0/1\">Vincent Stimper</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Scholkopf_B/0/1/0/all/0/1\">Bernhard Sch&#xf6;lkopf</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Besserve_M/0/1/0/all/0/1\">Michel Besserve</a>",
          "description": "Independent component analysis provides a principled framework for\nunsupervised representation learning, with solid theory on the identifiability\nof the latent code that generated the data, given only observations of mixtures\nthereof. Unfortunately, when the mixing is nonlinear, the model is provably\nnonidentifiable, since statistical independence alone does not sufficiently\nconstrain the problem. Identifiability can be recovered in settings where\nadditional, typically observed variables are included in the generative\nprocess. We investigate an alternative path and consider instead including\nassumptions reflecting the principle of independent causal mechanisms exploited\nin the field of causality. Specifically, our approach is motivated by thinking\nof each source as independently influencing the mixing process. This gives rise\nto a framework which we term independent mechanism analysis. We provide\ntheoretical and empirical evidence that our approach circumvents a number of\nnonidentifiability issues arising in nonlinear blind source separation.",
          "link": "http://arxiv.org/abs/2106.05200",
          "publishedOn": "2021-06-10T01:56:48.966Z",
          "wordCount": null,
          "title": "Independent mechanism analysis, a new concept?. (arXiv:2106.05200v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2101.05917",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Du_T/0/1/0/all/0/1\">Tao Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1\">Kui Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_P/0/1/0/all/0/1\">Pingchuan Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wah_S/0/1/0/all/0/1\">Sebastien Wah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spielberg_A/0/1/0/all/0/1\">Andrew Spielberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rus_D/0/1/0/all/0/1\">Daniela Rus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matusik_W/0/1/0/all/0/1\">Wojciech Matusik</a>",
          "description": "We present a novel, fast differentiable simulator for soft-body learning and\ncontrol applications. Existing differentiable soft-body simulators can be\nclassified into two categories based on their time integration methods:\nSimulators using explicit time-stepping scheme require tiny time steps to avoid\nnumerical instabilities in gradient computation, and simulators using implicit\ntime integration typically compute gradients by employing the adjoint method\nand solving the expensive linearized dynamics. Inspired by Projective Dynamics\n(PD), we present Differentiable Projective Dynamics (DiffPD), an efficient\ndifferentiable soft-body simulator based on PD with implicit time integration.\nThe key idea in DiffPD is to speed up backpropagation by exploiting the\nprefactorized Cholesky decomposition in forward PD simulation. In terms of\ncontact handling, DiffPD supports two types of contacts: a penalty-based model\ndescribing contact and friction forces and a complementarity-based model\nenforcing non-penetration conditions and static friction. We evaluate the\nperformance of DiffPD and observe it is 4-19 times faster compared to the\nstandard Newton's method in various applications including system\nidentification, inverse design problems, trajectory optimization, and\nclosed-loop control. We also apply DiffPD in a real-to-sim example with contact\nand collisions and show its capability of reconstructing a digital twin of\nreal-world scenes.",
          "link": "http://arxiv.org/abs/2101.05917",
          "publishedOn": "2021-06-10T01:56:48.966Z",
          "wordCount": null,
          "title": "DiffPD: Differentiable Projective Dynamics. (arXiv:2101.05917v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04995",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Banerjee_T/0/1/0/all/0/1\">Tamali Banerjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+V_R/0/1/0/all/0/1\">Rudra Murthy V</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharyya_P/0/1/0/all/0/1\">Pushpak Bhattacharyya</a>",
          "description": "Recent advances in Unsupervised Neural Machine Translation (UNMT) have\nminimized the gap between supervised and unsupervised machine translation\nperformance for closely related language pairs. However, the situation is very\ndifferent for distant language pairs. Lack of lexical overlap and low syntactic\nsimilarities such as between English and Indo-Aryan languages leads to poor\ntranslation quality in existing UNMT systems. In this paper, we show that\ninitializing the embedding layer of UNMT models with cross-lingual embeddings\nshows significant improvements in BLEU score over existing approaches with\nembeddings randomly initialized. Further, static embeddings (freezing the\nembedding layer weights) lead to better gains compared to updating the\nembedding layer weights during training (non-static). We experimented using\nMasked Sequence to Sequence (MASS) and Denoising Autoencoder (DAE) UNMT\napproaches for three distant language pairs. The proposed cross-lingual\nembedding initialization yields BLEU score improvement of as much as ten times\nover the baseline for English-Hindi, English-Bengali, and English-Gujarati. Our\nanalysis shows the importance of cross-lingual embedding, comparisons between\napproaches, and the scope of improvements in these systems.",
          "link": "http://arxiv.org/abs/2106.04995",
          "publishedOn": "2021-06-10T01:56:48.964Z",
          "wordCount": null,
          "title": "Crosslingual Embeddings are Essential in UNMT for Distant Languages: An English to IndoAryan Case Study. (arXiv:2106.04995v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04958",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiangyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_H/0/1/0/all/0/1\">Hangtian Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1\">Ying Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yaodong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yujing Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yingfeng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1\">Changjie Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Zhipeng Hu</a>",
          "description": "Measuring and promoting policy diversity is critical for solving games with\nstrong non-transitive dynamics where strategic cycles exist, and there is no\nconsistent winner (e.g., Rock-Paper-Scissors). With that in mind, maintaining a\npool of diverse policies via open-ended learning is an attractive solution,\nwhich can generate auto-curricula to avoid being exploited. However, in\nconventional open-ended learning algorithms, there are no widely accepted\ndefinitions for diversity, making it hard to construct and evaluate the diverse\npolicies. In this work, we summarize previous concepts of diversity and work\ntowards offering a unified measure of diversity in multi-agent open-ended\nlearning to include all elements in Markov games, based on both Behavioral\nDiversity (BD) and Response Diversity (RD). At the trajectory distribution\nlevel, we re-define BD in the state-action space as the discrepancies of\noccupancy measures. For the reward dynamics, we propose RD to characterize\ndiversity through the responses of policies when encountering different\nopponents. We also show that many current diversity measures fall in one of the\ncategories of BD or RD but not both. With this unified diversity measure, we\ndesign the corresponding diversity-promoting objective and population\neffectivity when seeking the best responses in open-ended learning. We validate\nour methods in both relatively simple games like matrix game, non-transitive\nmixture model, and the complex \\textit{Google Research Football} environment.\nThe population found by our methods reveals the lowest exploitability, highest\npopulation effectivity in matrix game and non-transitive mixture model, as well\nas the largest goal difference when interacting with opponents of various\nlevels in \\textit{Google Research Football}.",
          "link": "http://arxiv.org/abs/2106.04958",
          "publishedOn": "2021-06-10T01:56:48.959Z",
          "wordCount": 732,
          "title": "Unifying Behavioral and Response Diversity for Open-ended Learning in Zero-sum Games. (arXiv:2106.04958v1 [cs.MA])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05232",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kurri_G/0/1/0/all/0/1\">Gowtham R. Kurri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sypherd_T/0/1/0/all/0/1\">Tyler Sypherd</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sankar_L/0/1/0/all/0/1\">Lalitha Sankar</a>",
          "description": "We introduce a tunable GAN, called $\\alpha$-GAN, parameterized by $\\alpha \\in\n(0,\\infty]$, which interpolates between various $f$-GANs and Integral\nProbability Metric based GANs (under constrained discriminator set). We\nconstruct $\\alpha$-GAN using a supervised loss function, namely, $\\alpha$-loss,\nwhich is a tunable loss function capturing several canonical losses. We show\nthat $\\alpha$-GAN is intimately related to the Arimoto divergence, which was\nfirst proposed by \\\"{O}sterriecher (1996), and later studied by Liese and Vajda\n(2006). We posit that the holistic understanding that $\\alpha$-GAN introduces\nwill have practical benefits of addressing both the issues of vanishing\ngradients and mode collapse.",
          "link": "http://arxiv.org/abs/2106.05232",
          "publishedOn": "2021-06-10T01:56:48.954Z",
          "wordCount": 536,
          "title": "Realizing GANs via a Tunable Loss Function. (arXiv:2106.05232v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04982",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cesari_T/0/1/0/all/0/1\">Tommaso R. Cesari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vecchia_R/0/1/0/all/0/1\">Riccardo Della Vecchia</a>",
          "description": "In this preliminary (and unpolished) version of the paper, we study an\nasynchronous online learning setting with a network of agents. At each time\nstep, some of the agents are activated, requested to make a prediction, and pay\nthe corresponding loss. Some feedback is then revealed to these agents and is\nlater propagated through the network. We consider the case of full, bandit, and\nsemi-bandit feedback. In particular, we construct a reduction to delayed\nsingle-agent learning that applies to both the full and the bandit feedback\ncase and allows to obtain regret guarantees for both settings. We complement\nthese results with a near-matching lower bound.",
          "link": "http://arxiv.org/abs/2106.04982",
          "publishedOn": "2021-06-10T01:56:48.939Z",
          "wordCount": 523,
          "title": "Cooperative Online Learning. (arXiv:2106.04982v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2101.02404",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Krock_M/0/1/0/all/0/1\">Mitchell Krock</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kleiber_W/0/1/0/all/0/1\">William Kleiber</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hammerling_D/0/1/0/all/0/1\">Dorit Hammerling</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Becker_S/0/1/0/all/0/1\">Stephen Becker</a>",
          "description": "We propose a new modeling framework for highly-multivariate spatial processes\nthat synthesizes ideas from recent multiscale and spectral approaches with\ngraphical models. The basis graphical lasso writes a univariate Gaussian\nprocess as a linear combination of basis functions weighted with entries of a\nGaussian graphical vector whose graph is estimated from optimizing an $\\ell_1$\npenalized likelihood. This paper extends the setting to a multivariate Gaussian\nprocess where the basis functions are weighted with Gaussian graphical vectors.\nWe motivate a model where the basis functions represent different levels of\nresolution and the graphical vectors for each level are assumed to be\nindependent. Using an orthogonal basis grants linear complexity and memory\nusage in the number of spatial locations, the number of basis functions, and\nthe number of realizations. An additional fusion penalty encourages a\nparsimonious conditional independence structure in the multilevel graphical\nmodel. We illustrate our method on a large climate ensemble from the National\nCenter for Atmospheric Research's Community Atmosphere Model that involves 40\nspatial processes.",
          "link": "http://arxiv.org/abs/2101.02404",
          "publishedOn": "2021-06-10T01:56:48.934Z",
          "wordCount": 618,
          "title": "Modeling massive highly-multivariate nonstationary spatial data with the basis graphical lasso. (arXiv:2101.02404v2 [stat.ME] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.02511",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kreutzer_J/0/1/0/all/0/1\">Julia Kreutzer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riezler_S/0/1/0/all/0/1\">Stefan Riezler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lawrence_C/0/1/0/all/0/1\">Carolin Lawrence</a>",
          "description": "Large volumes of interaction logs can be collected from NLP systems that are\ndeployed in the real world. How can this wealth of information be leveraged?\nUsing such interaction logs in an offline reinforcement learning (RL) setting\nis a promising approach. However, due to the nature of NLP tasks and the\nconstraints of production systems, a series of challenges arise. We present a\nconcise overview of these challenges and discuss possible solutions.",
          "link": "http://arxiv.org/abs/2011.02511",
          "publishedOn": "2021-06-10T01:56:48.929Z",
          "wordCount": 577,
          "title": "Offline Reinforcement Learning from Human Feedback in Real-World Sequence-to-Sequence Tasks. (arXiv:2011.02511v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05222",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Heidarzadeh_A/0/1/0/all/0/1\">Anoosheh Heidarzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Esmati_N/0/1/0/all/0/1\">Nahid Esmati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sprintson_A/0/1/0/all/0/1\">Alex Sprintson</a>",
          "description": "This paper considers the single-server Private Linear Transformation (PLT)\nproblem with individual privacy guarantees. In this problem, there is a user\nthat wishes to obtain $L$ independent linear combinations of a $D$-subset of\nmessages belonging to a dataset of $K$ messages stored on a single server. The\ngoal is to minimize the download cost while keeping the identity of each\nmessage required for the computation individually private. The individual\nprivacy requirement ensures that the identity of each individual message\nrequired for the computation is kept private. This is in contrast to the\nstricter notion of joint privacy that protects the entire set of identities of\nall messages used for the computation, including the correlations between these\nidentities. The notion of individual privacy captures a broad set of practical\napplications. For example, such notion is relevant when the dataset contains\ninformation about individuals, each of them requires privacy guarantees for\ntheir data access patterns. We focus on the setting in which the required\nlinear transformation is associated with a maximum distance separable (MDS)\nmatrix. In particular, we require that the matrix of coefficients pertaining to\nthe required linear combinations is the generator matrix of an MDS code. We\nestablish lower and upper bounds on the capacity of PLT with individual\nprivacy, where the capacity is defined as the supremum of all achievable\ndownload rates. We show that our bounds are tight under certain conditions.",
          "link": "http://arxiv.org/abs/2106.05222",
          "publishedOn": "2021-06-10T01:56:48.924Z",
          "wordCount": 678,
          "title": "Single-Server Private Linear Transformation: The Individual Privacy Case. (arXiv:2106.05222v1 [cs.IT])"
        },
        {
          "id": "http://arxiv.org/abs/2006.14378",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kratsios_A/0/1/0/all/0/1\">Anastasis Kratsios</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zamanlooy_B/0/1/0/all/0/1\">Behnoosh Zamanlooy</a>",
          "description": "Most $L^p$-type universal approximation theorems guarantee that a given\nmachine learning model class $\\mathscr{F}\\subseteq\nC(\\mathbb{R}^d,\\mathbb{R}^D)$ is dense in\n$L^p_{\\mu}(\\mathbb{R}^d,\\mathbb{R}^D)$ for any suitable finite Borel measure\n$\\mu$ on $\\mathbb{R}^d$. Unfortunately, this means that the model's\napproximation quality can rapidly degenerate outside some compact subset of\n$\\mathbb{R}^d$, as any such measure is largely concentrated on some bounded\nsubset of $\\mathbb{R}^d$. This paper proposes a generic solution to this\napproximation theoretic problem by introducing a canonical transformation which\n\"upgrades $\\mathscr{F}$'s approximation property\" in the following sense. The\ntransformed model class, denoted by $\\mathscr{F}\\text{-tope}$, is shown to be\ndense in $L^p_{\\mu,\\text{strict}}(\\mathbb{R}^d,\\mathbb{R}^D)$ which is a\ntopological space whose elements are locally $p$-integrable functions and whose\ntopology is much finer than usual norm topology on\n$L^p_{\\mu}(\\mathbb{R}^d,\\mathbb{R}^D)$; here $\\mu$ is any suitable\n$\\sigma$-finite Borel measure $\\mu$ on $\\mathbb{R}^d$. Next, we show that if\n$\\mathscr{F}$ is any family of analytic functions then there is always a strict\n\"gap\" between $\\mathscr{F}\\text{-tope}$'s expressibility and that of\n$\\mathscr{F}$, since we find that $\\mathscr{F}$ can never dense in\n$L^p_{\\mu,\\text{strict}}(\\mathbb{R}^d,\\mathbb{R}^D)$. In the general case,\nwhere $\\mathscr{F}$ may contain non-analytic functions, we provide an abstract\nform of these results guaranteeing that there always exists some function space\nin which $\\mathscr{F}\\text{-tope}$ is dense but $\\mathscr{F}$ is not, while,\nthe converse is never possible. Applications to feedforward networks,\nconvolutional neural networks, and polynomial bases are explored.",
          "link": "http://arxiv.org/abs/2006.14378",
          "publishedOn": "2021-06-10T01:56:48.918Z",
          "wordCount": 717,
          "title": "A Canonical Transform for Strengthening the Local $L^p$-Type Universal Approximation Property. (arXiv:2006.14378v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05214",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Marimont_S/0/1/0/all/0/1\">Sergio Naval Marimont</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tarroni_G/0/1/0/all/0/1\">Giacomo Tarroni</a>",
          "description": "We propose a novel unsupervised out-of-distribution detection method for\nmedical images based on implicit fields image representations. In our approach,\nan auto-decoder feed-forward neural network learns the distribution of healthy\nimages in the form of a mapping between spatial coordinates and probabilities\nover a proxy for tissue types. At inference time, the learnt distribution is\nused to retrieve, from a given test image, a restoration, i.e. an image\nmaximally consistent with the input one but belonging to the healthy\ndistribution. Anomalies are localized using the voxel-wise probability\npredicted by our model for the restored image. We tested our approach in the\ntask of unsupervised localization of gliomas on brain MR images and compared it\nto several other VAE-based anomaly detection methods. Results show that the\nproposed technique substantially outperforms them (average DICE 0.640 vs 0.518\nfor the best performing VAE-based alternative) while also requiring\nconsiderably less computing time.",
          "link": "http://arxiv.org/abs/2106.05214",
          "publishedOn": "2021-06-10T01:56:48.912Z",
          "wordCount": 603,
          "title": "Implicit field learning for unsupervised anomaly detection in medical images. (arXiv:2106.05214v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2006.14222",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Andreis_B/0/1/0/all/0/1\">Bruno Andreis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1\">A. Tuan Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Seanie Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Juho Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_E/0/1/0/all/0/1\">Eunho Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1\">Sung Ju Hwang</a>",
          "description": "Current machine learning algorithms are designed to work with huge volumes of\nhigh dimensional data such as images. However, these algorithms are being\nincreasingly deployed to resource constrained systems such as mobile devices\nand embedded systems. Even in cases where large computing infrastructure is\navailable, the size of each data instance, as well as datasets, can be a\nbottleneck in data transfer across communication channels. Also, there is a\nhuge incentive both in energy and monetary terms in reducing both the\ncomputational and memory requirements of these algorithms. For nonparametric\nmodels that require to leverage the stored training data at inference time, the\nincreased cost in memory and computation could be even more problematic. In\nthis work, we aim to reduce the volume of data these algorithms must process\nthrough an end-to-end two-stage neural subset selection model. We first\nefficiently obtain a subset of candidate elements by sampling a mask from a\nconditionally independent Bernoulli distribution, and then autoregressivley\nconstruct a subset consisting of the most task relevant elements via sampling\nthe elements from a conditional Categorical distribution. We validate our\nmethod on set reconstruction and classification tasks with feature selection as\nwell as the selection of representative samples from a given dataset, on which\nour method outperforms relevant baselines. We also show in our experiments that\nour method enhances scalability of nonparametric models such as Neural\nProcesses.",
          "link": "http://arxiv.org/abs/2006.14222",
          "publishedOn": "2021-06-10T01:56:48.893Z",
          "wordCount": 712,
          "title": "Stochastic Subset Selection for Efficient Training and Inference of Neural Networks. (arXiv:2006.14222v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.01419",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Seungyul Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sung_Y/0/1/0/all/0/1\">Youngchul Sung</a>",
          "description": "In this paper, sample-aware policy entropy regularization is proposed to\nenhance the conventional policy entropy regularization for better exploration.\nExploiting the sample distribution obtainable from the replay buffer, the\nproposed sample-aware entropy regularization maximizes the entropy of the\nweighted sum of the policy action distribution and the sample action\ndistribution from the replay buffer for sample-efficient exploration. A\npractical algorithm named diversity actor-critic (DAC) is developed by applying\npolicy iteration to the objective function with the proposed sample-aware\nentropy regularization. Numerical results show that DAC significantly\noutperforms existing recent algorithms for reinforcement learning.",
          "link": "http://arxiv.org/abs/2006.01419",
          "publishedOn": "2021-06-10T01:56:48.887Z",
          "wordCount": 561,
          "title": "Diversity Actor-Critic: Sample-Aware Entropy Regularization for Sample-Efficient Exploration. (arXiv:2006.01419v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.01721",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Si_Q/0/1/0/all/0/1\">Qingyi Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yuanxin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_P/0/1/0/all/0/1\">Peng Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zheng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiangnan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Weiping Wang</a>",
          "description": "Zero-shot intent detection (ZSID) aims to deal with the continuously emerging\nintents without annotated training data. However, existing ZSID systems suffer\nfrom two limitations: 1) They are not good at modeling the relationship between\nseen and unseen intents. 2) They cannot effectively recognize unseen intents\nunder the generalized intent detection (GZSID) setting. A critical problem\nbehind these limitations is that the representations of unseen intents cannot\nbe learned in the training stage. To address this problem, we propose a novel\nframework that utilizes unseen class labels to learn Class-Transductive Intent\nRepresentations (CTIR). Specifically, we allow the model to predict unseen\nintents during training, with the corresponding label names serving as input\nutterances. On this basis, we introduce a multi-task learning objective, which\nencourages the model to learn the distinctions among intents, and a similarity\nscorer, which estimates the connections among intents more accurately. CTIR is\neasy to implement and can be integrated with existing methods. Experiments on\ntwo real-world datasets show that CTIR brings considerable improvement to the\nbaseline systems.",
          "link": "http://arxiv.org/abs/2012.01721",
          "publishedOn": "2021-06-10T01:56:48.882Z",
          "wordCount": 636,
          "title": "Learning Class-Transductive Intent Representations for Zero-shot Intent Detection. (arXiv:2012.01721v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05241",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Falck_F/0/1/0/all/0/1\">Fabian Falck</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_H/0/1/0/all/0/1\">Haoting Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Willetts_M/0/1/0/all/0/1\">Matthew Willetts</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nicholson_G/0/1/0/all/0/1\">George Nicholson</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yau_C/0/1/0/all/0/1\">Christopher Yau</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Holmes_C/0/1/0/all/0/1\">Christopher C Holmes</a>",
          "description": "Work in deep clustering focuses on finding a single partition of data.\nHowever, high-dimensional data, such as images, typically feature multiple\ninteresting characteristics one could cluster over. For example, images of\nobjects against a background could be clustered over the shape of the object\nand separately by the colour of the background. In this paper, we introduce\nMulti-Facet Clustering Variational Autoencoders (MFCVAE), a novel class of\nvariational autoencoders with a hierarchy of latent variables, each with a\nMixture-of-Gaussians prior, that learns multiple clusterings simultaneously,\nand is trained fully unsupervised and end-to-end. MFCVAE uses a\nprogressively-trained ladder architecture which leads to highly stable\nperformance. We provide novel theoretical results for optimising the ELBO\nanalytically with respect to the categorical variational posterior\ndistribution, and corrects earlier influential theoretical work. On image\nbenchmarks, we demonstrate that our approach separates out and clusters over\ndifferent aspects of the data in a disentangled manner. We also show other\nadvantages of our model: the compositionality of its latent space and that it\nprovides controlled generation of samples.",
          "link": "http://arxiv.org/abs/2106.05241",
          "publishedOn": "2021-06-10T01:56:48.866Z",
          "wordCount": 616,
          "title": "Multi-Facet Clustering Variational Autoencoders. (arXiv:2106.05241v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05143",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roy_B/0/1/0/all/0/1\">Bruno Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poulin_P/0/1/0/all/0/1\">Pierre Poulin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paquette_E/0/1/0/all/0/1\">Eric Paquette</a>",
          "description": "We present a novel up-resing technique for generating high-resolution liquids\nbased on scene flow estimation using deep neural networks. Our approach infers\nand synthesizes small- and large-scale details solely from a low-resolution\nparticle-based liquid simulation. The proposed network leverages neighborhood\ncontributions to encode inherent liquid properties throughout convolutions. We\nalso propose a particle-based approach to interpolate between liquids generated\nfrom varying simulation discretizations using a state-of-the-art bidirectional\noptical flow solver method for fluids in addition to a novel key-event\ntopological alignment constraint. In conjunction with the neighborhood\ncontributions, our loss formulation allows the inference model throughout\nepochs to reward important differences in regard to significant gaps in\nsimulation discretizations. Even when applied in an untested simulation setup,\nour approach is able to generate plausible high-resolution details. Using this\ninterpolation approach and the predicted displacements, our approach combines\nthe input liquid properties with the predicted motion to infer semi-Lagrangian\nadvection. We furthermore showcase how the proposed interpolation approach can\nfacilitate generating large simulation datasets with a subset of initial\ncondition parameters.",
          "link": "http://arxiv.org/abs/2106.05143",
          "publishedOn": "2021-06-10T01:56:48.860Z",
          "wordCount": 615,
          "title": "Neural UpFlow: A Scene Flow Learning Approach to Increase the Apparent Resolution of Particle-Based Liquids. (arXiv:2106.05143v1 [cs.GR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05230",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Barbero_Gomez_J/0/1/0/all/0/1\">Javier Barbero-G&#xf3;mez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gutierrez_P/0/1/0/all/0/1\">Pedro-Antonio Guti&#xe9;rrez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vargas_V/0/1/0/all/0/1\">V&#xed;ctor-Manuel Vargas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vallejo_Casas_J/0/1/0/all/0/1\">Juan-Antonio Vallejo-Casas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hervas_Martinez_C/0/1/0/all/0/1\">C&#xe9;sar Herv&#xe1;s-Mart&#xed;nez</a>",
          "description": "3D image scans are an assessment tool for neurological damage in Parkinson's\ndisease (PD) patients. This diagnosis process can be automatized to help\nmedical staff through Decision Support Systems (DSSs), and Convolutional Neural\nNetworks (CNNs) are good candidates, because they are effective when applied to\nspatial data. This paper proposes a 3D CNN ordinal model for assessing the\nlevel or neurological damage in PD patients. Given that CNNs need large\ndatasets to achieve acceptable performance, a data augmentation method is\nadapted to work with spatial data. We consider the Ordinal Graph-based\nOversampling via Shortest Paths (OGO-SP) method, which applies a gamma\nprobability distribution for inter-class data generation. A modification of\nOGO-SP is proposed, the OGO-SP-$\\beta$ algorithm, which applies the beta\ndistribution for generating synthetic samples in the inter-class region, a\nbetter suited distribution when compared to gamma. The evaluation of the\ndifferent methods is based on a novel 3D image dataset provided by the Hospital\nUniversitario 'Reina Sof\\'ia' (C\\'ordoba, Spain). We show how the ordinal\nmethodology improves the performance with respect to the nominal one, and how\nOGO-SP-$\\beta$ yields better performance than OGO-SP.",
          "link": "http://arxiv.org/abs/2106.05230",
          "publishedOn": "2021-06-10T01:56:48.845Z",
          "wordCount": 645,
          "title": "An ordinal CNN approach for the assessment of neurological damage in Parkinson's disease patients. (arXiv:2106.05230v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05187",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yifan_W/0/1/0/all/0/1\">Wang Yifan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahmann_L/0/1/0/all/0/1\">Lukas Rahmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sorkine_Hornung_O/0/1/0/all/0/1\">Olga Sorkine-Hornung</a>",
          "description": "We present implicit displacement fields, a novel representation for detailed\n3D geometry. Inspired by a classic surface deformation technique, displacement\nmapping, our method represents a complex surface as a smooth base surface plus\na displacement along the base's normal directions, resulting in a\nfrequency-based shape decomposition, where the high frequency signal is\nconstrained geometrically by the low frequency signal. Importantly, this\ndisentanglement is unsupervised thanks to a tailored architectural design that\nhas an innate frequency hierarchy by construction. We explore implicit\ndisplacement field surface reconstruction and detail transfer and demonstrate\nsuperior representational power, training stability and generalizability.",
          "link": "http://arxiv.org/abs/2106.05187",
          "publishedOn": "2021-06-10T01:56:48.839Z",
          "wordCount": 539,
          "title": "Geometry-Consistent Neural Shape Representation with Implicit Displacement Fields. (arXiv:2106.05187v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05251",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shujian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1\">Xinjie Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Bo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1\">Mingyuan Zhou</a>",
          "description": "Attention-based neural networks have achieved state-of-the-art results on a\nwide range of tasks. Most such models use deterministic attention while\nstochastic attention is less explored due to the optimization difficulties or\ncomplicated model design. This paper introduces Bayesian attention belief\nnetworks, which construct a decoder network by modeling unnormalized attention\nweights with a hierarchy of gamma distributions, and an encoder network by\nstacking Weibull distributions with a deterministic-upward-stochastic-downward\nstructure to approximate the posterior. The resulting auto-encoding networks\ncan be optimized in a differentiable way with a variational lower bound. It is\nsimple to convert any models with deterministic attention, including pretrained\nones, to the proposed Bayesian attention belief networks. On a variety of\nlanguage understanding tasks, we show that our method outperforms deterministic\nattention and state-of-the-art stochastic attention in accuracy, uncertainty\nestimation, generalization across domains, and robustness to adversarial\nattacks. We further demonstrate the general applicability of our method on\nneural machine translation and visual question answering, showing great\npotential of incorporating our method into various attention-related tasks.",
          "link": "http://arxiv.org/abs/2106.05251",
          "publishedOn": "2021-06-10T01:56:48.833Z",
          "wordCount": 596,
          "title": "Bayesian Attention Belief Networks. (arXiv:2106.05251v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05114",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Daudel_K/0/1/0/all/0/1\">Kam&#xe9;lia Daudel</a>, <a href=\"http://arxiv.org/find/math/1/au:+Douc_R/0/1/0/all/0/1\">Randal Douc</a>",
          "description": "This paper focuses on $\\alpha$-divergence minimisation methods for\nVariational Inference. More precisely, we are interested in algorithms\noptimising the mixture weights of any given mixture model, without any\ninformation on the underlying distribution of its mixture components\nparameters. The Power Descent, defined for all $\\alpha \\neq 1$, is one such\nalgorithm and we establish in our work the full proof of its convergence\ntowards the optimal mixture weights when $\\alpha <1$. Since the\n$\\alpha$-divergence recovers the widely-used forward Kullback-Leibler when\n$\\alpha \\to 1$, we then extend the Power Descent to the case $\\alpha = 1$ and\nshow that we obtain an Entropic Mirror Descent. This leads us to investigate\nthe link between Power Descent and Entropic Mirror Descent: first-order\napproximations allow us to introduce the Renyi Descent, a novel algorithm for\nwhich we prove an $O(1/N)$ convergence rate. Lastly, we compare numerically the\nbehavior of the unbiased Power Descent and of the biased Renyi Descent and we\ndiscuss the potential advantages of one algorithm over the other.",
          "link": "http://arxiv.org/abs/2106.05114",
          "publishedOn": "2021-06-10T01:56:48.828Z",
          "wordCount": 590,
          "title": "Mixture weights optimisation for Alpha-Divergence Variational Inference. (arXiv:2106.05114v1 [math.ST])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05102",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kalia_M/0/1/0/all/0/1\">Manu Kalia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brunton_S/0/1/0/all/0/1\">Steven L. Brunton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meijer_H/0/1/0/all/0/1\">Hil G.E. Meijer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brune_C/0/1/0/all/0/1\">Christoph Brune</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kutz_J/0/1/0/all/0/1\">J. Nathan Kutz</a>",
          "description": "Complex systems manifest a small number of instabilities and bifurcations\nthat are canonical in nature, resulting in universal pattern forming\ncharacteristics as a function of some parametric dependence. Such parametric\ninstabilities are mathematically characterized by their universal un-foldings,\nor normal form dynamics, whereby a parsimonious model can be used to represent\nthe dynamics. Although center manifold theory guarantees the existence of such\nlow-dimensional normal forms, finding them has remained a long standing\nchallenge. In this work, we introduce deep learning autoencoders to discover\ncoordinate transformations that capture the underlying parametric dependence of\na dynamical system in terms of its canonical normal form, allowing for a simple\nrepresentation of the parametric dependence and bifurcation structure. The\nautoencoder constrains the latent variable to adhere to a given normal form,\nthus allowing it to learn the appropriate coordinate transformation. We\ndemonstrate the method on a number of example problems, showing that it can\ncapture a diverse set of normal forms associated with Hopf, pitchfork,\ntranscritical and/or saddle node bifurcations. This method shows how normal\nforms can be leveraged as canonical and universal building blocks in deep\nlearning approaches for model discovery and reduced-order modeling.",
          "link": "http://arxiv.org/abs/2106.05102",
          "publishedOn": "2021-06-10T01:56:48.822Z",
          "wordCount": 639,
          "title": "Learning normal form autoencoders for data-driven discovery of universal,parameter-dependent governing equations. (arXiv:2106.05102v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2006.04710",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kim_H/0/1/0/all/0/1\">Hyunjik Kim</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Papamakarios_G/0/1/0/all/0/1\">George Papamakarios</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mnih_A/0/1/0/all/0/1\">Andriy Mnih</a>",
          "description": "Lipschitz constants of neural networks have been explored in various contexts\nin deep learning, such as provable adversarial robustness, estimating\nWasserstein distance, stabilising training of GANs, and formulating invertible\nneural networks. Such works have focused on bounding the Lipschitz constant of\nfully connected or convolutional networks, composed of linear maps and\npointwise non-linearities. In this paper, we investigate the Lipschitz constant\nof self-attention, a non-linear neural network module widely used in sequence\nmodelling. We prove that the standard dot-product self-attention is not\nLipschitz for unbounded input domain, and propose an alternative L2\nself-attention that is Lipschitz. We derive an upper bound on the Lipschitz\nconstant of L2 self-attention and provide empirical evidence for its asymptotic\ntightness. To demonstrate the practical relevance of our theoretical work, we\nformulate invertible self-attention and use it in a Transformer-based\narchitecture for a character-level language modelling task.",
          "link": "http://arxiv.org/abs/2006.04710",
          "publishedOn": "2021-06-10T01:56:48.808Z",
          "wordCount": 579,
          "title": "The Lipschitz Constant of Self-Attention. (arXiv:2006.04710v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05165",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cayci_S/0/1/0/all/0/1\">Semih Cayci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yilin Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eryilmaz_A/0/1/0/all/0/1\">Atilla Eryilmaz</a>",
          "description": "In a wide variety of applications including online advertising, contractual\nhiring, and wireless scheduling, the controller is constrained by a stringent\nbudget constraint on the available resources, which are consumed in a random\namount by each action, and a stochastic feasibility constraint that may impose\nimportant operational limitations on decision-making. In this work, we consider\na general model to address such problems, where each action returns a random\nreward, cost, and penalty from an unknown joint distribution, and the\ndecision-maker aims to maximize the total reward under a budget constraint $B$\non the total cost and a stochastic constraint on the time-average penalty. We\npropose a novel low-complexity algorithm based on Lyapunov optimization\nmethodology, named ${\\tt LyOn}$, and prove that it achieves $O(\\sqrt{B\\log B})$\nregret and $O(\\log B/B)$ constraint-violation. The low computational cost and\nsharp performance bounds of ${\\tt LyOn}$ suggest that Lyapunov-based algorithm\ndesign methodology can be effective in solving constrained bandit optimization\nproblems.",
          "link": "http://arxiv.org/abs/2106.05165",
          "publishedOn": "2021-06-10T01:56:48.802Z",
          "wordCount": 590,
          "title": "A Lyapunov-Based Methodology for Constrained Optimization with Bandit Feedback. (arXiv:2106.05165v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05209",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1\">Shuxuan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alvarez_J/0/1/0/all/0/1\">Jose M. Alvarez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salzmann_M/0/1/0/all/0/1\">Mathieu Salzmann</a>",
          "description": "Knowledge distillation constitutes a simple yet effective way to improve the\nperformance of a compact student network by exploiting the knowledge of a more\npowerful teacher. Nevertheless, the knowledge distillation literature remains\nlimited to the scenario where the student and the teacher tackle the same task.\nHere, we investigate the problem of transferring knowledge not only across\narchitectures but also across tasks. To this end, we study the case of object\ndetection and, instead of following the standard detector-to-detector\ndistillation approach, introduce a classifier-to-detector knowledge transfer\nframework. In particular, we propose strategies to exploit the classification\nteacher to improve both the detector's recognition accuracy and localization\nperformance. Our experiments on several detectors with different backbones\ndemonstrate the effectiveness of our approach, allowing us to outperform the\nstate-of-the-art detector-to-detector distillation methods.",
          "link": "http://arxiv.org/abs/2106.05209",
          "publishedOn": "2021-06-10T01:56:48.796Z",
          "wordCount": 562,
          "title": "Distilling Image Classifiers in Object Detectors. (arXiv:2106.05209v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05233",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Walter_B/0/1/0/all/0/1\">Benjamin Walter</a>",
          "description": "Image classification is considered, and a hierarchical max-pooling model with\nadditional local pooling is introduced. Here the additional local pooling\nenables the hierachical model to combine parts of the image which have a\nvariable relative distance towards each other. Various convolutional neural\nnetwork image classifiers are introduced and compared in view of their rate of\nconvergence. The finite sample size performance of the estimates is analyzed by\napplying them to simulated and real data.",
          "link": "http://arxiv.org/abs/2106.05233",
          "publishedOn": "2021-06-10T01:56:48.791Z",
          "wordCount": 529,
          "title": "Analysis of convolutional neural network image classifiers in a hierarchical max-pooling model with additional local pooling. (arXiv:2106.05233v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2009.04861",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abeyrathna_K/0/1/0/all/0/1\">K. Darshana Abeyrathna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhattarai_B/0/1/0/all/0/1\">Bimal Bhattarai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goodwin_M/0/1/0/all/0/1\">Morten Goodwin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gorji_S/0/1/0/all/0/1\">Saeed Gorji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Granmo_O/0/1/0/all/0/1\">Ole-Christoffer Granmo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_L/0/1/0/all/0/1\">Lei Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saha_R/0/1/0/all/0/1\">Rupsa Saha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yadav_R/0/1/0/all/0/1\">Rohan K. Yadav</a>",
          "description": "Using logical clauses to represent patterns, Tsetlin Machines (TMs) have\nrecently obtained competitive performance in terms of accuracy, memory\nfootprint, energy, and learning speed on several benchmarks. Each TM clause\nvotes for or against a particular class, with classification resolved using a\nmajority vote. While the evaluation of clauses is fast, being based on binary\noperators, the voting makes it necessary to synchronize the clause evaluation,\nimpeding parallelization. In this paper, we propose a novel scheme for\ndesynchronizing the evaluation of clauses, eliminating the voting bottleneck.\nIn brief, every clause runs in its own thread for massive native parallelism.\nFor each training example, we keep track of the class votes obtained from the\nclauses in local voting tallies. The local voting tallies allow us to detach\nthe processing of each clause from the rest of the clauses, supporting\ndecentralized learning. This means that the TM most of the time will operate on\noutdated voting tallies. We evaluated the proposed parallelization across\ndiverse learning tasks and it turns out that our decentralized TM learning\nalgorithm copes well with working on outdated data, resulting in no significant\nloss in learning accuracy. Furthermore, we show that the proposed approach\nprovides up to 50 times faster learning. Finally, learning time is almost\nconstant for reasonable clause amounts (employing from 20 to 7,000 clauses on a\nTesla V100 GPU). For sufficiently large clause numbers, computation time\nincreases approximately proportionally. Our parallel and asynchronous\narchitecture thus allows processing of massive datasets and operating with more\nclauses for higher accuracy.",
          "link": "http://arxiv.org/abs/2009.04861",
          "publishedOn": "2021-06-10T01:56:48.782Z",
          "wordCount": 750,
          "title": "Massively Parallel and Asynchronous Tsetlin Machine Architecture Supporting Almost Constant-Time Scaling. (arXiv:2009.04861v4 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.07063",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Coulombe_P/0/1/0/all/0/1\">Philippe Goulet Coulombe</a>",
          "description": "It is notoriously difficult to build a bad Random Forest (RF). Concurrently,\nRF blatantly overfits in-sample without any apparent consequence out-of-sample.\nStandard arguments, like the classic bias-variance trade-off or double descent,\ncannot rationalize this paradox. I propose a new explanation: bootstrap\naggregation and model perturbation as implemented by RF automatically prune a\nlatent \"true\" tree. More generally, randomized ensembles of greedily optimized\nlearners implicitly perform optimal early stopping out-of-sample. So there is\nno need to tune the stopping point. By construction, novel variants of Boosting\nand MARS are also eligible for automatic tuning. I empirically demonstrate the\nproperty, with simulated and real data, by reporting that these new completely\noverfitting ensembles perform similarly to their tuned counterparts -- or\nbetter.",
          "link": "http://arxiv.org/abs/2008.07063",
          "publishedOn": "2021-06-10T01:56:48.766Z",
          "wordCount": 594,
          "title": "To Bag is to Prune. (arXiv:2008.07063v4 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.02810",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pluss_M/0/1/0/all/0/1\">Michel Pl&#xfc;ss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neukom_L/0/1/0/all/0/1\">Lukas Neukom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scheller_C/0/1/0/all/0/1\">Christian Scheller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogel_M/0/1/0/all/0/1\">Manfred Vogel</a>",
          "description": "We present the Swiss Parliaments Corpus (SPC), an automatically aligned Swiss\nGerman speech to Standard German text corpus. This first version of the corpus\nis based on publicly available data of the Bernese cantonal parliament and\nconsists of 293 hours of data. It was created using a novel forced sentence\nalignment procedure and an alignment quality estimator, which can be used to\ntrade off corpus size and quality. We trained Automatic Speech Recognition\n(ASR) models as baselines on different subsets of the data and achieved a Word\nError Rate (WER) of 0.278 and a BLEU score of 0.586 on the SPC test set. The\ncorpus is freely available for download.",
          "link": "http://arxiv.org/abs/2010.02810",
          "publishedOn": "2021-06-10T01:56:48.761Z",
          "wordCount": 581,
          "title": "Swiss Parliaments Corpus, an Automatically Aligned Swiss German Speech to Standard German Text Corpus. (arXiv:2010.02810v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.10412",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rahman_A/0/1/0/all/0/1\">Arrasy Rahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hopner_N/0/1/0/all/0/1\">Niklas H&#xf6;pner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Christianos_F/0/1/0/all/0/1\">Filippos Christianos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Albrecht_S/0/1/0/all/0/1\">Stefano V. Albrecht</a>",
          "description": "Ad hoc teamwork is the challenging problem of designing an autonomous agent\nwhich can adapt quickly to collaborate with teammates without prior\ncoordination mechanisms, including joint training. Prior work in this area has\nfocused on closed teams in which the number of agents is fixed. In this work,\nwe consider open teams by allowing agents with different fixed policies to\nenter and leave the environment without prior notification. Our solution builds\non graph neural networks to learn agent models and joint-action value models\nunder varying team compositions. We contribute a novel action-value computation\nthat integrates the agent model and joint-action value model to produce\naction-value estimates. We empirically demonstrate that our approach\nsuccessfully models the effects other agents have on the learner, leading to\npolicies that robustly adapt to dynamic team compositions and significantly\noutperform several alternative methods.",
          "link": "http://arxiv.org/abs/2006.10412",
          "publishedOn": "2021-06-10T01:56:48.755Z",
          "wordCount": 634,
          "title": "Towards Open Ad Hoc Teamwork Using Graph-based Policy Learning. (arXiv:2006.10412v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05093",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Du_C/0/1/0/all/0/1\">Cunxiao Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1\">Zhaopeng Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jing Jiang</a>",
          "description": "We propose a new training objective named order-agnostic cross entropy (OaXE)\nfor fully non-autoregressive translation (NAT) models. OaXE improves the\nstandard cross-entropy loss to ameliorate the effect of word reordering, which\nis a common source of the critical multimodality problem in NAT. Concretely,\nOaXE removes the penalty for word order errors, and computes the cross entropy\nloss based on the best possible alignment between model predictions and target\ntokens. Since the log loss is very sensitive to invalid references, we leverage\ncross entropy initialization and loss truncation to ensure the model focuses on\na good part of the search space. Extensive experiments on major WMT benchmarks\nshow that OaXE substantially improves translation performance, setting new\nstate of the art for fully NAT models. Further analyses show that OaXE\nalleviates the multimodality problem by reducing token repetitions and\nincreasing prediction confidence. Our code, data, and trained models are\navailable at https://github.com/tencent-ailab/ICML21_OAXE.",
          "link": "http://arxiv.org/abs/2106.05093",
          "publishedOn": "2021-06-10T01:56:48.750Z",
          "wordCount": 590,
          "title": "Order-Agnostic Cross Entropy for Non-Autoregressive Machine Translation. (arXiv:2106.05093v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05203",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Richtarik_P/0/1/0/all/0/1\">Peter Richt&#xe1;rik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sokolov_I/0/1/0/all/0/1\">Igor Sokolov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fatkhullin_I/0/1/0/all/0/1\">Ilyas Fatkhullin</a>",
          "description": "Error feedback (EF), also known as error compensation, is an immensely\npopular convergence stabilization mechanism in the context of distributed\ntraining of supervised machine learning models enhanced by the use of\ncontractive communication compression mechanisms, such as Top-$k$. First\nproposed by Seide et al (2014) as a heuristic, EF resisted any theoretical\nunderstanding until recently [Stich et al., 2018, Alistarh et al., 2018].\nHowever, all existing analyses either i) apply to the single node setting only,\nii) rely on very strong and often unreasonable assumptions, such global\nboundedness of the gradients, or iterate-dependent assumptions that cannot be\nchecked a-priori and may not hold in practice, or iii) circumvent these issues\nvia the introduction of additional unbiased compressors, which increase the\ncommunication cost. In this work we fix all these deficiencies by proposing and\nanalyzing a new EF mechanism, which we call EF21, which consistently and\nsubstantially outperforms EF in practice. Our theoretical analysis relies on\nstandard assumptions only, works in the distributed heterogeneous data setting,\nand leads to better and more meaningful rates. In particular, we prove that\nEF21 enjoys a fast $O(1/T)$ convergence rate for smooth nonconvex problems,\nbeating the previous bound of $O(1/T^{2/3})$, which was shown a bounded\ngradients assumption. We further improve this to a fast linear rate for PL\nfunctions, which is the first linear convergence result for an EF-type method\nnot relying on unbiased compressors. Since EF has a large number of\napplications where it reigns supreme, we believe that our 2021 variant, EF21,\ncan a large impact on the practice of communication efficient distributed\nlearning.",
          "link": "http://arxiv.org/abs/2106.05203",
          "publishedOn": "2021-06-10T01:56:48.744Z",
          "wordCount": 711,
          "title": "EF21: A New, Simpler, Theoretically Better, and Practically Faster Error Feedback. (arXiv:2106.05203v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03787",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Geist_M/0/1/0/all/0/1\">Matthieu Geist</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perolat_J/0/1/0/all/0/1\">Julien P&#xe9;rolat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lauriere_M/0/1/0/all/0/1\">Mathieu Lauri&#xe8;re</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elie_R/0/1/0/all/0/1\">Romuald Elie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perrin_S/0/1/0/all/0/1\">Sarah Perrin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bachem_O/0/1/0/all/0/1\">Olivier Bachem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Munos_R/0/1/0/all/0/1\">R&#xe9;mi Munos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pietquin_O/0/1/0/all/0/1\">Olivier Pietquin</a>",
          "description": "Concave Utility Reinforcement Learning (CURL) extends RL from linear to\nconcave utilities in the occupancy measure induced by the agent's policy. This\nencompasses not only RL but also imitation learning and exploration, among\nothers. Yet, this more general paradigm invalidates the classical Bellman\nequations, and calls for new algorithms. Mean-field Games (MFGs) are a\ncontinuous approximation of many-agent RL. They consider the limit case of a\ncontinuous distribution of identical agents, anonymous with symmetric\ninterests, and reduce the problem to the study of a single representative agent\nin interaction with the full population. Our core contribution consists in\nshowing that CURL is a subclass of MFGs. We think this important to bridge\ntogether both communities. It also allows to shed light on aspects of both\nfields: we show the equivalence between concavity in CURL and monotonicity in\nthe associated MFG, between optimality conditions in CURL and Nash equilibrium\nin MFG, or that Fictitious Play (FP) for this class of MFGs is simply\nFrank-Wolfe, bringing the first convergence rate for discrete-time FP for MFGs.\nWe also experimentally demonstrate that, using algorithms recently introduced\nfor solving MFGs, we can address the CURL problem more efficiently.",
          "link": "http://arxiv.org/abs/2106.03787",
          "publishedOn": "2021-06-10T01:56:48.730Z",
          "wordCount": 645,
          "title": "Concave Utility Reinforcement Learning: the Mean-field Game viewpoint. (arXiv:2106.03787v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05142",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yeche_H/0/1/0/all/0/1\">Hugo Y&#xe8;che</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dresdner_G/0/1/0/all/0/1\">Gideon Dresdner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Locatello_F/0/1/0/all/0/1\">Francesco Locatello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huser_M/0/1/0/all/0/1\">Matthias H&#xfc;ser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ratsch_G/0/1/0/all/0/1\">Gunnar R&#xe4;tsch</a>",
          "description": "Intensive care units (ICU) are increasingly looking towards machine learning\nfor methods to provide online monitoring of critically ill patients. In machine\nlearning, online monitoring is often formulated as a supervised learning\nproblem. Recently, contrastive learning approaches have demonstrated promising\nimprovements over competitive supervised benchmarks. These methods rely on\nwell-understood data augmentation techniques developed for image data which do\nnot apply to online monitoring. In this work, we overcome this limitation by\nsupplementing time-series data augmentation techniques with a novel contrastive\nlearning objective which we call neighborhood contrastive learning (NCL). Our\nobjective explicitly groups together contiguous time segments from each patient\nwhile maintaining state-specific information. Our experiments demonstrate a\nmarked improvement over existing work applying contrastive methods to medical\ntime-series.",
          "link": "http://arxiv.org/abs/2106.05142",
          "publishedOn": "2021-06-10T01:56:48.724Z",
          "wordCount": 549,
          "title": "Neighborhood Contrastive Learning Applied to Online Patient Monitoring. (arXiv:2106.05142v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2011.11844",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Takahashi_N/0/1/0/all/0/1\">Naoya Takahashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitsufuji_Y/0/1/0/all/0/1\">Yuki Mitsufuji</a>",
          "description": "Tasks that involve high-resolution dense prediction require a modeling of\nboth local and global patterns in a large input field. Although the local and\nglobal structures often depend on each other and their simultaneous modeling is\nimportant, many convolutional neural network (CNN)-based approaches interchange\nrepresentations in different resolutions only a few times. In this paper, we\nclaim the importance of a dense simultaneous modeling of multiresolution\nrepresentation and propose a novel CNN architecture called densely connected\nmultidilated DenseNet (D3Net). D3Net involves a novel multidilated convolution\nthat has different dilation factors in a single layer to model different\nresolutions simultaneously. By combining the multidilated convolution with the\nDenseNet architecture, D3Net incorporates multiresolution learning with an\nexponentially growing receptive field in almost all layers, while avoiding the\naliasing problem that occurs when we naively incorporate the dilated\nconvolution in DenseNet. Experiments on the image semantic segmentation task\nusing Cityscapes and the audio source separation task using MUSDB18 show that\nthe proposed method has superior performance over state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2011.11844",
          "publishedOn": "2021-06-10T01:56:48.719Z",
          "wordCount": 636,
          "title": "Densely connected multidilated convolutional networks for dense prediction tasks. (arXiv:2011.11844v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05126",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hottung_A/0/1/0/all/0/1\">Andr&#xe9; Hottung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwon_Y/0/1/0/all/0/1\">Yeong-Dae Kwon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tierney_K/0/1/0/all/0/1\">Kevin Tierney</a>",
          "description": "Recently numerous machine learning based methods for combinatorial\noptimization problems have been proposed that learn to construct solutions in a\nsequential decision process via reinforcement learning. While these methods can\nbe easily combined with search strategies like sampling and beam search, it is\nnot straightforward to integrate them into a high-level search procedure\noffering strong search guidance. Bello et al. (2016) propose active search,\nwhich adjusts the weights of a (trained) model with respect to a single\ninstance at test time using reinforcement learning. While active search is\nsimple to implement, it is not competitive with state-of-the-art methods\nbecause adjusting all model weights for each test instance is very time and\nmemory intensive. Instead of updating all model weights, we propose and\nevaluate three efficient active search strategies that only update a subset of\nparameters during the search. The proposed methods offer a simple way to\nsignificantly improve the search performance of a given model and outperform\nstate-of-the-art machine learning based methods on combinatorial problems, even\nsurpassing the well-known heuristic solver LKH3 on the capacitated vehicle\nrouting problem. Finally, we show that (efficient) active search enables\nlearned models to effectively solve instances that are much larger than those\nseen during training.",
          "link": "http://arxiv.org/abs/2106.05126",
          "publishedOn": "2021-06-10T01:56:48.710Z",
          "wordCount": 631,
          "title": "Efficient Active Search for Combinatorial Optimization Problems. (arXiv:2106.05126v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2101.08578",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Pata_J/0/1/0/all/0/1\">Joosep Pata</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Duarte_J/0/1/0/all/0/1\">Javier Duarte</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Vlimant_J/0/1/0/all/0/1\">Jean-Roch Vlimant</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Pierini_M/0/1/0/all/0/1\">Maurizio Pierini</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Spiropulu_M/0/1/0/all/0/1\">Maria Spiropulu</a>",
          "description": "In general-purpose particle detectors, the particle-flow algorithm may be\nused to reconstruct a comprehensive particle-level view of the event by\ncombining information from the calorimeters and the trackers, significantly\nimproving the detector resolution for jets and the missing transverse momentum.\nIn view of the planned high-luminosity upgrade of the CERN Large Hadron\nCollider (LHC), it is necessary to revisit existing reconstruction algorithms\nand ensure that both the physics and computational performance are sufficient\nin an environment with many simultaneous proton-proton interactions (pileup).\nMachine learning may offer a prospect for computationally efficient event\nreconstruction that is well-suited to heterogeneous computing platforms, while\nsignificantly improving the reconstruction quality over rule-based algorithms\nfor granular detectors. We introduce MLPF, a novel, end-to-end trainable,\nmachine-learned particle-flow algorithm based on parallelizable,\ncomputationally efficient, and scalable graph neural networks optimized using a\nmulti-task objective on simulated events. We report the physics and\ncomputational performance of the MLPF algorithm on a Monte Carlo dataset of top\nquark-antiquark pairs produced in proton-proton collisions in conditions\nsimilar to those expected for the high-luminosity LHC. The MLPF algorithm\nimproves the physics response with respect to a rule-based benchmark algorithm\nand demonstrates computationally scalable particle-flow reconstruction in a\nhigh-pileup environment.",
          "link": "http://arxiv.org/abs/2101.08578",
          "publishedOn": "2021-06-10T01:56:48.701Z",
          "wordCount": null,
          "title": "MLPF: Efficient machine-learned particle-flow reconstruction using graph neural networks. (arXiv:2101.08578v3 [physics.data-an] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.11884",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Tran_T/0/1/0/all/0/1\">Trang H. Tran</a>, <a href=\"http://arxiv.org/find/math/1/au:+Nguyen_L/0/1/0/all/0/1\">Lam M. Nguyen</a>, <a href=\"http://arxiv.org/find/math/1/au:+Tran_Dinh_Q/0/1/0/all/0/1\">Quoc Tran-Dinh</a>",
          "description": "We combine two advanced ideas widely used in optimization for machine\nlearning: shuffling strategy and momentum technique to develop a novel\nshuffling gradient-based method with momentum, coined Shuffling Momentum\nGradient (SMG), for non-convex finite-sum optimization problems. While our\nmethod is inspired by momentum techniques, its update is fundamentally\ndifferent from existing momentum-based methods. We establish state-of-the-art\nconvergence rates of SMG for any shuffling strategy using either constant or\ndiminishing learning rate under standard assumptions (i.e.$L$-smoothness and\nbounded variance). When the shuffling strategy is fixed, we develop another new\nalgorithm that is similar to existing momentum methods, and prove the same\nconvergence rates for this algorithm under the $L$-smoothness and bounded\ngradient assumptions. We demonstrate our algorithms via numerical simulations\non standard datasets and compare them with existing shuffling methods. Our\ntests have shown encouraging performance of the new algorithms.",
          "link": "http://arxiv.org/abs/2011.11884",
          "publishedOn": "2021-06-10T01:56:48.698Z",
          "wordCount": 608,
          "title": "SMG: A Shuffling Gradient-Based Method with Momentum. (arXiv:2011.11884v3 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05245",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Macgregor_P/0/1/0/all/0/1\">Peter Macgregor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">He Sun</a>",
          "description": "Local graph clustering is an important algorithmic technique for analysing\nmassive graphs, and has been widely applied in many research fields of data\nscience. While the objective of most (local) graph clustering algorithms is to\nfind a vertex set of low conductance, there has been a sequence of recent\nstudies that highlight the importance of the inter-connection between clusters\nwhen analysing real-world datasets. Following this line of research, in this\nwork we study local algorithms for finding a pair of vertex sets defined with\nrespect to their inter-connection and their relationship with the rest of the\ngraph. The key to our analysis is a new reduction technique that relates the\nstructure of multiple sets to a single vertex set in the reduced graph. Among\nmany potential applications, we show that our algorithms successfully recover\ndensely connected clusters in the Interstate Disputes Dataset and the US\nMigration Dataset.",
          "link": "http://arxiv.org/abs/2106.05245",
          "publishedOn": "2021-06-10T01:56:48.691Z",
          "wordCount": 590,
          "title": "Local Algorithms for Finding Densely Connected Clusters. (arXiv:2106.05245v1 [cs.DS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05139",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1\">Mina Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srivatsa_P/0/1/0/all/0/1\">P Srivatsa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rane_A/0/1/0/all/0/1\">Advait Rane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chenniappa_S/0/1/0/all/0/1\">Shriram Chenniappa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anand_R/0/1/0/all/0/1\">Rishabh Anand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ozair_S/0/1/0/all/0/1\">Sherjil Ozair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maes_P/0/1/0/all/0/1\">Pattie Maes</a>",
          "description": "Data-efficiency and generalization are key challenges in deep learning and\ndeep reinforcement learning as many models are trained on large-scale,\ndomain-specific, and expensive-to-label datasets. Self-supervised models\ntrained on large-scale uncurated datasets have shown successful transfer to\ndiverse settings. We investigate using pretrained image representations and\nspatio-temporal attention for state representation learning in Atari. We also\nexplore fine-tuning pretrained representations with self-supervised techniques,\ni.e., contrastive predictive coding, spatio-temporal contrastive learning, and\naugmentations. Our results show that pretrained representations are at par with\nstate-of-the-art self-supervised methods trained on domain-specific data.\nPretrained representations, thus, yield data and compute-efficient state\nrepresentations. https://github.com/PAL-ML/PEARL_v1",
          "link": "http://arxiv.org/abs/2106.05139",
          "publishedOn": "2021-06-10T01:56:48.681Z",
          "wordCount": 526,
          "title": "Pretrained Encoders are All You Need. (arXiv:2106.05139v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05237",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Beyer_L/0/1/0/all/0/1\">Lucas Beyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_X/0/1/0/all/0/1\">Xiaohua Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Royer_A/0/1/0/all/0/1\">Am&#xe9;lie Royer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Markeeva_L/0/1/0/all/0/1\">Larisa Markeeva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anil_R/0/1/0/all/0/1\">Rohan Anil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolesnikov_A/0/1/0/all/0/1\">Alexander Kolesnikov</a>",
          "description": "There is a growing discrepancy in computer vision between large-scale models\nthat achieve state-of-the-art performance and models that are affordable in\npractical applications. In this paper we address this issue and significantly\nbridge the gap between these two types of models. Throughout our empirical\ninvestigation we do not aim to necessarily propose a new method, but strive to\nidentify a robust and effective recipe for making state-of-the-art large scale\nmodels affordable in practice. We demonstrate that, when performed correctly,\nknowledge distillation can be a powerful tool for reducing the size of large\nmodels without compromising their performance. In particular, we uncover that\nthere are certain implicit design choices, which may drastically affect the\neffectiveness of distillation. Our key contribution is the explicit\nidentification of these design choices, which were not previously articulated\nin the literature. We back up our findings by a comprehensive empirical study,\ndemonstrate compelling results on a wide range of vision datasets and, in\nparticular, obtain a state-of-the-art ResNet-50 model for ImageNet, which\nachieves 82.8\\% top-1 accuracy.",
          "link": "http://arxiv.org/abs/2106.05237",
          "publishedOn": "2021-06-10T01:56:48.664Z",
          "wordCount": 623,
          "title": "Knowledge distillation: A good teacher is patient and consistent. (arXiv:2106.05237v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05152",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Peng_L/0/1/0/all/0/1\">Le Peng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liang_H/0/1/0/all/0/1\">Hengyue Liang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_T/0/1/0/all/0/1\">Taihui Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sun_J/0/1/0/all/0/1\">Ju Sun</a>",
          "description": "Transfer learning (TL) with deep convolutional neural networks (DCNNs) has\nproved successful in medical image classification (MIC). However, the current\npractice is puzzling, as MIC typically relies only on low- and/or mid-level\nfeatures that are learned in the bottom layers of DCNNs. Following this\nintuition, we question the current strategies of TL in MIC. In this paper, we\nperform careful experimental comparisons between shallow and deep networks for\nclassification on two chest x-ray datasets, using different TL strategies. We\nfind that deep models are not always favorable, and finetuning truncated deep\nmodels almost always yields the best performance, especially in data-poor\nregimes.\n\nProject webpage:\nhttps://github.com/sun-umn/Transfer-Learning-in-Medical-Imaging\n\nKeywords: Transfer learning, Medical image classification, Feature hierarchy,\nMedical imaging, Evaluation metrics, Imbalanced data",
          "link": "http://arxiv.org/abs/2106.05152",
          "publishedOn": "2021-06-10T01:56:48.658Z",
          "wordCount": 567,
          "title": "Rethink Transfer Learning in Medical Image Classification. (arXiv:2106.05152v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03790",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1\">Ningyuan Chen</a>",
          "description": "In many online learning or multi-armed bandit problems, the taken actions or\npulled arms are ordinal and required to be monotone over time. Examples include\ndynamic pricing, in which the firms use markup pricing policies to please early\nadopters and deter strategic waiting, and clinical trials, in which the dose\nallocation usually follows the dose escalation principle to prevent dose\nlimiting toxicities. We consider the continuum-armed bandit problem when the\narm sequence is required to be monotone. We show that when the unknown\nobjective function is Lipschitz continuous, the regret is $O(T)$. When in\naddition the objective function is unimodal or quasiconcave, the regret is\n$\\tilde O(T^{3/4})$ under the proposed algorithm, which is also shown to be the\noptimal rate. This deviates from the optimal rate $\\tilde O(T^{2/3})$ in the\ncontinuous-armed bandit literature and demonstrates the cost to the learning\nefficiency brought by the monotonicity requirement.",
          "link": "http://arxiv.org/abs/2106.03790",
          "publishedOn": "2021-06-10T01:56:48.652Z",
          "wordCount": 582,
          "title": "Multi-armed Bandit Requiring Monotone Arm Sequences. (arXiv:2106.03790v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.06986",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1\">Xuebin Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1\">Bingxin Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Junbin Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu Guang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lio_P/0/1/0/all/0/1\">Pietro Lio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Ming Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Montufar_G/0/1/0/all/0/1\">Guido Montufar</a>",
          "description": "This paper presents a new approach for assembling graph neural networks based\non framelet transforms. The latter provides a multi-scale representation for\ngraph-structured data. We decompose an input graph into low-pass and high-pass\nfrequencies coefficients for network training, which then defines a\nframelet-based graph convolution. The framelet decomposition naturally induces\na graph pooling strategy by aggregating the graph feature into low-pass and\nhigh-pass spectra, which considers both the feature values and geometry of the\ngraph data and conserves the total information. The graph neural networks with\nthe proposed framelet convolution and pooling achieve state-of-the-art\nperformance in many node and graph prediction tasks. Moreover, we propose\nshrinkage as a new activation for the framelet convolution, which thresholds\nhigh-frequency information at different scales. Compared to ReLU, shrinkage\nactivation improves model performance on denoising and signal compression:\nnoises in both node and structure can be significantly reduced by accurately\ncutting off the high-pass coefficients from framelet decomposition, and the\nsignal can be compressed to less than half its original size with\nwell-preserved prediction performance.",
          "link": "http://arxiv.org/abs/2102.06986",
          "publishedOn": "2021-06-10T01:56:48.638Z",
          "wordCount": 656,
          "title": "How Framelets Enhance Graph Neural Networks. (arXiv:2102.06986v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05234",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ying_C/0/1/0/all/0/1\">Chengxuan Ying</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_T/0/1/0/all/0/1\">Tianle Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1\">Shengjie Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1\">Shuxin Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ke_G/0/1/0/all/0/1\">Guolin Ke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1\">Di He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yanming Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tie-Yan Liu</a>",
          "description": "The Transformer architecture has become a dominant choice in many domains,\nsuch as natural language processing and computer vision. Yet, it has not\nachieved competitive performance on popular leaderboards of graph-level\nprediction compared to mainstream GNN variants. Therefore, it remains a mystery\nhow Transformers could perform well for graph representation learning. In this\npaper, we solve this mystery by presenting Graphormer, which is built upon the\nstandard Transformer architecture, and could attain excellent results on a\nbroad range of graph representation learning tasks, especially on the recent\nOGB Large-Scale Challenge. Our key insight to utilizing Transformer in the\ngraph is the necessity of effectively encoding the structural information of a\ngraph into the model. To this end, we propose several simple yet effective\nstructural encoding methods to help Graphormer better model graph-structured\ndata. Besides, we mathematically characterize the expressive power of\nGraphormer and exhibit that with our ways of encoding the structural\ninformation of graphs, many popular GNN variants could be covered as the\nspecial cases of Graphormer.",
          "link": "http://arxiv.org/abs/2106.05234",
          "publishedOn": "2021-06-10T01:56:48.632Z",
          "wordCount": 603,
          "title": "Do Transformers Really Perform Bad for Graph Representation?. (arXiv:2106.05234v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05127",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1\">Hanyu Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Peizhao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hongfu Liu</a>",
          "description": "In this paper, we focus on the fairness issues regarding unsupervised outlier\ndetection. Traditional algorithms, without a specific design for algorithmic\nfairness, could implicitly encode and propagate statistical bias in data and\nraise societal concerns. To correct such unfairness and deliver a fair set of\npotential outlier candidates, we propose Deep Clustering based Fair Outlier\nDetection (DCFOD) that learns a good representation for utility maximization\nwhile enforcing the learnable representation to be subgroup-invariant on the\nsensitive attribute. Considering the coupled and reciprocal nature between\nclustering and outlier detection, we leverage deep clustering to discover the\nintrinsic cluster structure and out-of-structure instances. Meanwhile, an\nadversarial training erases the sensitive pattern for instances for fairness\nadaptation. Technically, we propose an instance-level weighted representation\nlearning strategy to enhance the joint deep clustering and outlier detection,\nwhere the dynamic weight module re-emphasizes contributions of likely-inliers\nwhile mitigating the negative impact from outliers. Demonstrated by experiments\non eight datasets comparing to 17 outlier detection algorithms, our DCFOD\nmethod consistently achieves superior performance on both the outlier detection\nvalidity and two types of fairness notions in outlier detection.",
          "link": "http://arxiv.org/abs/2106.05127",
          "publishedOn": "2021-06-10T01:56:48.627Z",
          "wordCount": 609,
          "title": "Deep Clustering based Fair Outlier Detection. (arXiv:2106.05127v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2006.12135",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Madaan_D/0/1/0/all/0/1\">Divyam Madaan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1\">Jinwoo Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1\">Sung Ju Hwang</a>",
          "description": "Adversarial learning has emerged as one of the successful techniques to\ncircumvent the susceptibility of existing methods against adversarial\nperturbations. However, the majority of existing defense methods are tailored\nto defend against a single category of adversarial perturbation (e.g.\n$\\ell_\\infty$-attack). In safety-critical applications, this makes these\nmethods extraneous as the attacker can adopt diverse adversaries to deceive the\nsystem. Moreover, training on multiple perturbations simultaneously\nsignificantly increases the computational overhead during training. To address\nthese challenges, we propose a novel meta-learning framework that explicitly\nlearns to generate noise to improve the model's robustness against multiple\ntypes of attacks. Its key component is Meta Noise Generator (MNG) that outputs\noptimal noise to stochastically perturb a given sample, such that it helps\nlower the error on diverse adversarial perturbations. By utilizing samples\ngenerated by MNG, we train a model by enforcing the label consistency across\nmultiple perturbations. We validate the robustness of models trained by our\nscheme on various datasets and against a wide variety of perturbations,\ndemonstrating that it significantly outperforms the baselines across multiple\nperturbations with a marginal computational cost.",
          "link": "http://arxiv.org/abs/2006.12135",
          "publishedOn": "2021-06-10T01:56:48.619Z",
          "wordCount": 657,
          "title": "Learning to Generate Noise for Multi-Attack Robustness. (arXiv:2006.12135v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.07491",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hou_W/0/1/0/all/0/1\">Wenxin Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jindong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1\">Xu Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1\">Tao Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shinozaki_T/0/1/0/all/0/1\">Takahiro Shinozaki</a>",
          "description": "End-to-end automatic speech recognition (ASR) can achieve promising\nperformance with large-scale training data. However, it is known that domain\nmismatch between training and testing data often leads to a degradation of\nrecognition accuracy. In this work, we focus on the unsupervised domain\nadaptation for ASR and propose CMatch, a Character-level distribution matching\nmethod to perform fine-grained adaptation between each character in two\ndomains. First, to obtain labels for the features belonging to each character,\nwe achieve frame-level label assignment using the Connectionist Temporal\nClassification (CTC) pseudo labels. Then, we match the character-level\ndistributions using Maximum Mean Discrepancy. We train our algorithm using the\nself-training technique. Experiments on the Libri-Adapt dataset show that our\nproposed approach achieves 14.39% and 16.50% relative Word Error Rate (WER)\nreduction on both cross-device and cross-environment ASR. We also\ncomprehensively analyze the different strategies for frame-level label\nassignment and Transformer adaptations.",
          "link": "http://arxiv.org/abs/2104.07491",
          "publishedOn": "2021-06-10T01:56:48.613Z",
          "wordCount": 628,
          "title": "Cross-domain Speech Recognition with Unsupervised Character-level Distribution Matching. (arXiv:2104.07491v3 [cs.SD] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.12033",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jinhee Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Haeri Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_Y/0/1/0/all/0/1\">Youngkyu Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chung_H/0/1/0/all/0/1\">Hye Won Chung</a>",
          "description": "Despite remarkable performance in producing realistic samples, Generative\nAdversarial Networks (GANs) often produce low-quality samples near low-density\nregions of the data manifold, especially for samples with minor features. Many\ntechniques have been developed to improve the quality of generated samples,\neither by post-processing generated samples or by pre-processing the empirical\ndata distribution, but at the cost of reduced diversity. To promote diversity\nin sample generation without degrading the overall quality, we propose a simple\nyet effective method to diagnose and emphasize underrepresented samples during\ntraining of a GAN. The main idea is to use the statistics of the discrepancy\nbetween the data distribution and the model distribution at each data instance.\nBased on the observation that the underrepresented samples have a high average\ndiscrepancy or high variability in discrepancy, we propose a method to\nemphasize those samples during training of a GAN. Our experimental results\ndemonstrate that the proposed method improves GAN performance on various\ndatasets, and it is especially effective in improving the quality and diversity\nof generated samples with minor features.",
          "link": "http://arxiv.org/abs/2102.12033",
          "publishedOn": "2021-06-10T01:56:48.606Z",
          "wordCount": 628,
          "title": "Self-Diagnosing GAN: Diagnosing Underrepresented Samples in Generative Adversarial Networks. (arXiv:2102.12033v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2004.00101",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1\">Doyeon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chung_H/0/1/0/all/0/1\">Hye Won Chung</a>",
          "description": "We consider crowdsourced labeling under a $d$-type worker-task specialization\nmodel, where each worker and task is associated with one particular type among\na finite set of types and a worker provides a more reliable answer to tasks of\nthe matched type than to tasks of unmatched types. We design an inference\nalgorithm that recovers binary task labels (up to any given recovery accuracy)\nby using worker clustering, worker skill estimation and weighted majority\nvoting. The designed inference algorithm does not require any information about\nworker/task types, and achieves any targeted recovery accuracy with the best\nknown performance (minimum number of queries per task).",
          "link": "http://arxiv.org/abs/2004.00101",
          "publishedOn": "2021-06-10T01:56:48.577Z",
          "wordCount": 571,
          "title": "Crowdsourced Labeling for Worker-Task Specialization Model. (arXiv:2004.00101v2 [cs.HC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05239",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sarkar_T/0/1/0/all/0/1\">Tushar Sarkar</a>",
          "description": "Neural networks have proved to be very robust at processing unstructured data\nlike images, text, videos, and audio. However, it has been observed that their\nperformance is not up to the mark in tabular data; hence tree-based models are\npreferred in such scenarios. A popular model for tabular data is boosted trees,\na highly efficacious and extensively used machine learning method, and it also\nprovides good interpretability compared to neural networks. In this paper, we\ndescribe a novel architecture XBNet, which tries to combine tree-based models\nwith that of neural networks to create a robust architecture trained by using a\nnovel optimization technique, Boosted Gradient Descent for Tabular Data which\nincreases its interpretability and performance.",
          "link": "http://arxiv.org/abs/2106.05239",
          "publishedOn": "2021-06-10T01:56:48.571Z",
          "wordCount": 530,
          "title": "XBNet : An Extremely Boosted Neural Network. (arXiv:2106.05239v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2009.05683",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yixi Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tople_S/0/1/0/all/0/1\">Shruti Tople</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_S/0/1/0/all/0/1\">Sumit Mukherjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferres_J/0/1/0/all/0/1\">Juan Lavista Ferres</a>",
          "description": "In this work, we formally study the membership privacy risk of generative\nmodels and propose a membership privacy estimation framework. We formulate the\nmembership privacy risk as a statistical divergence between training samples\nand hold-out samples, and propose sample-based methods to estimate this\ndivergence. Unlike previous works, our proposed metric and estimators make\nrealistic and flexible assumptions. First, we offer a generalizable metric as\nan alternative to accuracy for imbalanced datasets. Second, our estimators are\ncapable of estimating the membership privacy risk given any scalar or vector\nvalued attributes from the learned model, while prior work require access to\nspecific attributes. This allows our framework to provide data-driven\ncertificates for trained generative models in terms of membership privacy risk.\nFinally, we show a connection to differential privacy, which allows our\nproposed estimators to be used to understand the privacy budget 'epsilon'\nneeded for differentially private generative models. We demonstrate the utility\nof our framework through experimental demonstrations on different generative\nmodels using various model attributes yielding some new insights about\nmembership leakage and vulnerabilities of models.",
          "link": "http://arxiv.org/abs/2009.05683",
          "publishedOn": "2021-06-10T01:56:48.512Z",
          "wordCount": 653,
          "title": "MACE: A Flexible Framework for Membership Privacy Estimation in Generative Models. (arXiv:2009.05683v3 [cs.CR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09632",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dessi_D/0/1/0/all/0/1\">Danilo Dessi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Helaoui_R/0/1/0/all/0/1\">Rim Helaoui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1\">Vivek Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Recupero_D/0/1/0/all/0/1\">Diego Reforgiato Recupero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riboni_D/0/1/0/all/0/1\">Daniele Riboni</a>",
          "description": "Today, we are seeing an ever-increasing number of clinical notes that contain\nclinical results, images, and textual descriptions of patient's health state.\nAll these data can be analyzed and employed to cater novel services that can\nhelp people and domain experts with their common healthcare tasks. However,\nmany technologies such as Deep Learning and tools like Word Embeddings have\nstarted to be investigated only recently, and many challenges remain open when\nit comes to healthcare domain applications. To address these challenges, we\npropose the use of Deep Learning and Word Embeddings for identifying sixteen\nmorbidity types within textual descriptions of clinical records. For this\npurpose, we have used a Deep Learning model based on Bidirectional Long-Short\nTerm Memory (LSTM) layers which can exploit state-of-the-art vector\nrepresentations of data such as Word Embeddings. We have employed pre-trained\nWord Embeddings namely GloVe and Word2Vec, and our own Word Embeddings trained\non the target domain. Furthermore, we have compared the performances of the\ndeep learning approaches against the traditional tf-idf using Support Vector\nMachine and Multilayer perceptron (our baselines). From the obtained results it\nseems that the latter outperforms the combination of Deep Learning approaches\nusing any word embeddings. Our preliminary results indicate that there are\nspecific features that make the dataset biased in favour of traditional machine\nlearning approaches.",
          "link": "http://arxiv.org/abs/2105.09632",
          "publishedOn": "2021-06-10T01:56:48.496Z",
          "wordCount": 711,
          "title": "TF-IDF vs Word Embeddings for Morbidity Identification in Clinical Notes: An Initial Study. (arXiv:2105.09632v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.09769",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Goerigk_M/0/1/0/all/0/1\">Marc Goerigk</a>, <a href=\"http://arxiv.org/find/math/1/au:+Kurtz_J/0/1/0/all/0/1\">Jannis Kurtz</a>",
          "description": "Robust optimization has been established as a leading methodology to approach\ndecision problems under uncertainty. To derive a robust optimization model, a\ncentral ingredient is to identify a suitable model for uncertainty, which is\ncalled the uncertainty set, containing all scenarios against which we wish to\nprotect. An ongoing challenge in the recent literature is to derive uncertainty\nsets from given historical data.\n\nIn this paper we use an unsupervised deep learning method to construct\nnon-convex uncertainty sets from data, which have a more complex structure than\nthe typically considered sets. We prove that most of the classical uncertainty\nclasses are special cases of our derived sets and that optimizing over it is\nstrongly NP-hard. Nevertheless we show that the trained neural networks can be\nintegrated into a robust optimization model by formulating the adversarial\nproblem as a convex quadratic mixed-integer program. This allows us to derive\nrobust solutions through an iterative scenario generation process. We prove\nthat our class of uncertainty sets contains In extensive computational\nexperiments, we compare this approach to a similar approach, which derives\nuncertainty sets by kernel-based support vector clustering. We find that\nuncertainty sets derived by the unsupervised deep learning method can give a\nbetter description of data, leading to robust solutions that often outperform\nthe comparison method both with respect to objective value and feasibility.",
          "link": "http://arxiv.org/abs/2011.09769",
          "publishedOn": "2021-06-10T01:56:48.472Z",
          "wordCount": 663,
          "title": "Data-Driven Robust Optimization using Unsupervised Deep Learning. (arXiv:2011.09769v2 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04986",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1\">Tai-Yu Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faye_S/0/1/0/all/0/1\">S&#xe9;bastien Faye</a>",
          "description": "Public charging station occupancy prediction plays key importance in\ndeveloping a smart charging strategy to reduce electric vehicle (EV) operator\nand user inconvenience. However, existing studies are mainly based on\nconventional econometric or time series methodologies with limited accuracy. We\npropose a new mixed long short-term memory neural network incorporating both\nhistorical charging state sequences and time-related features for multistep\ndiscrete charging occupancy state prediction. Unlike the existing LSTM\nnetworks, the proposed model separates different types of features and handles\nthem differently with mixed neural network architecture. The model is compared\nto a number of state-of-the-art machine learning and deep learning approaches\nbased on the EV charging data obtained from the open data portal of the city of\nDundee, UK. The results show that the proposed method produces very accurate\npredictions (99.99% and 81.87% for 1 step (10 minutes) and 6 step (1 hour)\nahead, respectively, and outperforms the benchmark approaches significantly\n(+22.4% for one-step-ahead prediction and +6.2% for 6 steps ahead). A\nsensitivity analysis is conducted to evaluate the impact of the model\nparameters on prediction accuracy.",
          "link": "http://arxiv.org/abs/2106.04986",
          "publishedOn": "2021-06-10T01:56:48.443Z",
          "wordCount": 611,
          "title": "Multistep Electric Vehicle Charging Station Occupancy Prediction using Mixed LSTM Neural Networks. (arXiv:2106.04986v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04944",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dervovic_D/0/1/0/all/0/1\">Danial Dervovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hassanzadeh_P/0/1/0/all/0/1\">Parisa Hassanzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Assefa_S/0/1/0/all/0/1\">Samuel Assefa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reddy_P/0/1/0/all/0/1\">Prashant Reddy</a>",
          "description": "We consider a problem wherein jobs arrive at random times and assume random\nvalues. Upon each job arrival, the decision-maker must decide immediately\nwhether or not to accept the job and gain the value on offer as a reward, with\nthe constraint that they may only accept at most $n$ jobs over some reference\ntime period. The decision-maker only has access to $M$ independent realisations\nof the job arrival process. We propose an algorithm, Non-Parametric Sequential\nAllocation (NPSA), for solving this problem. Moreover, we prove that the\nexpected reward returned by the NPSA algorithm converges in probability to\noptimality as $M$ grows large. We demonstrate the effectiveness of the\nalgorithm empirically on synthetic data and on public fraud-detection datasets,\nfrom where the motivation for this work is derived.",
          "link": "http://arxiv.org/abs/2106.04944",
          "publishedOn": "2021-06-10T01:56:48.438Z",
          "wordCount": 571,
          "title": "Non-Parametric Stochastic Sequential Assignment With Random Arrival Times. (arXiv:2106.04944v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2012.07463",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_D/0/1/0/all/0/1\">Demi Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rush_A/0/1/0/all/0/1\">Alexander M. Rush</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Yoon Kim</a>",
          "description": "While task-specific finetuning of pretrained networks has led to significant\nempirical advances in NLP, the large size of networks makes finetuning\ndifficult to deploy in multi-task, memory-constrained settings. We propose diff\npruning as a simple approach to enable parameter-efficient transfer learning\nwithin the pretrain-finetune framework. This approach views finetuning as\nlearning a task-specific diff vector that is applied on top of the pretrained\nparameter vector, which remains fixed and is shared across different tasks. The\ndiff vector is adaptively pruned during training with a differentiable\napproximation to the L0-norm penalty to encourage sparsity. Diff pruning\nbecomes parameter-efficient as the number of tasks increases, as it requires\nstoring only the nonzero positions and weights of the diff vector for each\ntask, while the cost of storing the shared pretrained model remains constant.\nIt further does not require access to all tasks during training, which makes it\nattractive in settings where tasks arrive in stream or the set of tasks is\nunknown. We find that models finetuned with diff pruning can match the\nperformance of fully finetuned baselines on the GLUE benchmark while only\nmodifying 0.5% of the pretrained model's parameters per task.",
          "link": "http://arxiv.org/abs/2012.07463",
          "publishedOn": "2021-06-10T01:56:48.432Z",
          "wordCount": 647,
          "title": "Parameter-Efficient Transfer Learning with Diff Pruning. (arXiv:2012.07463v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03181",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Inoue_K/0/1/0/all/0/1\">Katsuma Inoue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ohara_S/0/1/0/all/0/1\">Soh Ohara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuniyoshi_Y/0/1/0/all/0/1\">Yasuo Kuniyoshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakajima_K/0/1/0/all/0/1\">Kohei Nakajima</a>",
          "description": "Language is an outcome of our complex and dynamic human-interactions and the\ntechnique of natural language processing (NLP) is hence built on human\nlinguistic activities. Bidirectional Encoder Representations from Transformers\n(BERT) has recently gained its popularity by establishing the state-of-the-art\nscores in several NLP benchmarks. A Lite BERT (ALBERT) is literally\ncharacterized as a lightweight version of BERT, in which the number of BERT\nparameters is reduced by repeatedly applying the same neural network called\nTransformer's encoder layer. By pre-training the parameters with a massive\namount of natural language data, ALBERT can convert input sentences into\nversatile high-dimensional vectors potentially capable of solving multiple NLP\ntasks. In that sense, ALBERT can be regarded as a well-designed\nhigh-dimensional dynamical system whose operator is the Transformer's encoder,\nand essential structures of human language are thus expected to be encapsulated\nin its dynamics. In this study, we investigated the embedded properties of\nALBERT to reveal how NLP tasks are effectively solved by exploiting its\ndynamics. We thereby aimed to explore the nature of human language from the\ndynamical expressions of the NLP model. Our short-term analysis clarified that\nthe pre-trained model stably yields trajectories with higher dimensionality,\nwhich would enhance the expressive capacity required for NLP tasks. Also, our\nlong-term analysis revealed that ALBERT intrinsically shows transient chaos, a\ntypical nonlinear phenomenon showing chaotic dynamics only in its transient,\nand the pre-trained ALBERT model tends to produce the chaotic trajectory for a\nsignificantly longer time period compared to a randomly-initialized one. Our\nresults imply that local chaoticity would contribute to improving NLP\nperformance, uncovering a novel aspect in the role of chaotic dynamics in human\nlanguage behaviors.",
          "link": "http://arxiv.org/abs/2106.03181",
          "publishedOn": "2021-06-10T01:56:48.417Z",
          "wordCount": 731,
          "title": "Transient Chaos in BERT. (arXiv:2106.03181v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05223",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meng_C/0/1/0/all/0/1\">Chuizheng Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rambhatla_S/0/1/0/all/0/1\">Sirisha Rambhatla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yan Liu</a>",
          "description": "Vast amount of data generated from networks of sensors, wearables, and the\nInternet of Things (IoT) devices underscores the need for advanced modeling\ntechniques that leverage the spatio-temporal structure of decentralized data\ndue to the need for edge computation and licensing (data access) issues. While\nfederated learning (FL) has emerged as a framework for model training without\nrequiring direct data sharing and exchange, effectively modeling the complex\nspatio-temporal dependencies to improve forecasting capabilities still remains\nan open problem. On the other hand, state-of-the-art spatio-temporal\nforecasting models assume unfettered access to the data, neglecting constraints\non data sharing. To bridge this gap, we propose a federated spatio-temporal\nmodel -- Cross-Node Federated Graph Neural Network (CNFGNN) -- which explicitly\nencodes the underlying graph structure using graph neural network (GNN)-based\narchitecture under the constraint of cross-node federated learning, which\nrequires that data in a network of nodes is generated locally on each node and\nremains decentralized. CNFGNN operates by disentangling the temporal dynamics\nmodeling on devices and spatial dynamics on the server, utilizing alternating\noptimization to reduce the communication cost, facilitating computations on the\nedge devices. Experiments on the traffic flow forecasting task show that CNFGNN\nachieves the best forecasting performance in both transductive and inductive\nlearning settings with no extra computation cost on edge devices, while\nincurring modest communication cost.",
          "link": "http://arxiv.org/abs/2106.05223",
          "publishedOn": "2021-06-10T01:56:48.411Z",
          "wordCount": 663,
          "title": "Cross-Node Federated Graph Neural Network for Spatio-Temporal Data Modeling. (arXiv:2106.05223v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05110",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Eimer_T/0/1/0/all/0/1\">Theresa Eimer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biedenkapp_A/0/1/0/all/0/1\">Andr&#xe9; Biedenkapp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hutter_F/0/1/0/all/0/1\">Frank Hutter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lindauer_M/0/1/0/all/0/1\">Marius Lindauer</a>",
          "description": "Reinforcement learning (RL) has made a lot of advances for solving a single\nproblem in a given environment; but learning policies that generalize to unseen\nvariations of a problem remains challenging. To improve sample efficiency for\nlearning on such instances of a problem domain, we present Self-Paced Context\nEvaluation (SPaCE). Based on self-paced learning, \\spc automatically generates\n\\task curricula online with little computational overhead. To this end, SPaCE\nleverages information contained in state values during training to accelerate\nand improve training performance as well as generalization capabilities to new\ninstances from the same problem domain. Nevertheless, SPaCE is independent of\nthe problem domain at hand and can be applied on top of any RL agent with\nstate-value function approximation. We demonstrate SPaCE's ability to speed up\nlearning of different value-based RL agents on two environments, showing better\ngeneralization capabilities and up to 10x faster learning compared to naive\napproaches such as round robin or SPDRL, as the closest state-of-the-art\napproach.",
          "link": "http://arxiv.org/abs/2106.05110",
          "publishedOn": "2021-06-10T01:56:48.405Z",
          "wordCount": 582,
          "title": "Self-Paced Context Evaluation for Contextual Reinforcement Learning. (arXiv:2106.05110v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.03786",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Chen_Y/0/1/0/all/0/1\">Yu-Wen Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hung_K/0/1/0/all/0/1\">Kuo-Hsuan Hung</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chuang_S/0/1/0/all/0/1\">Shang-Yi Chuang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sherman_J/0/1/0/all/0/1\">Jonathan Sherman</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huang_W/0/1/0/all/0/1\">Wen-Chin Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lu_X/0/1/0/all/0/1\">Xugang Lu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tsao_Y/0/1/0/all/0/1\">Yu Tsao</a>",
          "description": "Synthesized speech from articulatory movements can have real-world use for\npatients with vocal cord disorders, situations requiring silent speech, or in\nhigh-noise environments. In this work, we present EMA2S, an end-to-end\nmultimodal articulatory-to-speech system that directly converts articulatory\nmovements to speech signals. We use a neural-network-based vocoder combined\nwith multimodal joint-training, incorporating spectrogram, mel-spectrogram, and\ndeep features. The experimental results confirm that the multimodal approach of\nEMA2S outperforms the baseline system in terms of both objective evaluation and\nsubjective evaluation metrics. Moreover, results demonstrate that joint\nmel-spectrogram and deep feature loss training can effectively improve system\nperformance.",
          "link": "http://arxiv.org/abs/2102.03786",
          "publishedOn": "2021-06-10T01:56:48.400Z",
          "wordCount": 559,
          "title": "EMA2S: An End-to-End Multimodal Articulatory-to-Speech System. (arXiv:2102.03786v2 [eess.AS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.11654",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Nguyen_Q/0/1/0/all/0/1\">Quynh Nguyen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mondelli_M/0/1/0/all/0/1\">Marco Mondelli</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Montufar_G/0/1/0/all/0/1\">Guido Montufar</a>",
          "description": "A recent line of work has analyzed the theoretical properties of deep neural\nnetworks via the Neural Tangent Kernel (NTK). In particular, the smallest\neigenvalue of the NTK has been related to the memorization capacity, the global\nconvergence of gradient descent algorithms and the generalization of deep nets.\nHowever, existing results either provide bounds in the two-layer setting or\nassume that the spectrum of the NTK matrices is bounded away from 0 for\nmulti-layer networks. In this paper, we provide tight bounds on the smallest\neigenvalue of NTK matrices for deep ReLU nets, both in the limiting case of\ninfinite widths and for finite widths. In the finite-width setting, the network\narchitectures we consider are fairly general: we require the existence of a\nwide layer with roughly order of $N$ neurons, $N$ being the number of data\nsamples; and the scaling of the remaining layer widths is arbitrary (up to\nlogarithmic factors). To obtain our results, we analyze various quantities of\nindependent interest: we give lower bounds on the smallest singular value of\nhidden feature matrices, and upper bounds on the Lipschitz constant of\ninput-output feature maps.",
          "link": "http://arxiv.org/abs/2012.11654",
          "publishedOn": "2021-06-10T01:56:48.376Z",
          "wordCount": 656,
          "title": "Tight Bounds on the Smallest Eigenvalue of the Neural Tangent Kernel for Deep ReLU Networks. (arXiv:2012.11654v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05037",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Apicella_A/0/1/0/all/0/1\">Andrea Apicella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Isgro_F/0/1/0/all/0/1\">Francesco Isgr&#xf2;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prevete_R/0/1/0/all/0/1\">Roberto Prevete</a>",
          "description": "Nowadays, it is growing interest to make Machine Learning (ML) systems more\nunderstandable and trusting to general users. Thus, generating explanations for\nML system behaviours that are understandable to human beings is a central\nscientific and technological issue addressed by the rapidly growing research\narea of eXplainable Artificial Intelligence (XAI). Recently, it is becoming\nmore and more evident that new directions to create better explanations should\ntake into account what a good explanation is to a human user, and consequently,\ndevelop XAI solutions able to provide user-centred explanations. This paper\nsuggests taking advantage of developing an XAI general approach that allows\nproducing explanations for an ML system behaviour in terms of different and\nuser-selected input features, i.e., explanations composed of input properties\nthat the human user can select according to his background knowledge and goals.\nTo this end, we propose an XAI general approach which is able: 1) to construct\nexplanations in terms of input features that represent more salient and\nunderstandable input properties for a user, which we call here Middle-Level\ninput Features (MLFs), 2) to be applied to different types of MLFs. We\nexperimentally tested our approach on two different datasets and using three\ndifferent types of MLFs. The results seem encouraging.",
          "link": "http://arxiv.org/abs/2106.05037",
          "publishedOn": "2021-06-10T01:56:48.368Z",
          "wordCount": 650,
          "title": "A general approach for Explanations in terms of Middle Level Features. (arXiv:2106.05037v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05206",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Deyo_S/0/1/0/all/0/1\">Sean Deyo</a>, <a href=\"http://arxiv.org/find/math/1/au:+Elser_V/0/1/0/all/0/1\">Veit Elser</a>",
          "description": "Iterative projection methods may become trapped at non-solutions when the\nconstraint sets are nonconvex. Two kinds of parameters are available to help\navoid this behavior and this study gives examples of both. The first kind of\nparameter, called a hyperparameter, includes any kind of parameter that appears\nin the definition of the iteration rule itself. The second kind comprises\nmetric parameters in the definition of the constraint sets, a feature that\narises when the problem to be solved has two or more kinds of variables.\nThrough examples we show the importance of properly tuning both kinds of\nparameters and offer heuristic interpretations of the observed behavior.",
          "link": "http://arxiv.org/abs/2106.05206",
          "publishedOn": "2021-06-10T01:56:48.307Z",
          "wordCount": 530,
          "title": "Avoiding Traps in Nonconvex Problems. (arXiv:2106.05206v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2011.07248",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Keller_T/0/1/0/all/0/1\">T. Anderson Keller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peters_J/0/1/0/all/0/1\">Jorn W.T. Peters</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaini_P/0/1/0/all/0/1\">Priyank Jaini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoogeboom_E/0/1/0/all/0/1\">Emiel Hoogeboom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Forre_P/0/1/0/all/0/1\">Patrick Forr&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1\">Max Welling</a>",
          "description": "Efficient gradient computation of the Jacobian determinant term is a core\nproblem in many machine learning settings, and especially so in the normalizing\nflow framework. Most proposed flow models therefore either restrict to a\nfunction class with easy evaluation of the Jacobian determinant, or an\nefficient estimator thereof. However, these restrictions limit the performance\nof such density models, frequently requiring significant depth to reach desired\nperformance levels. In this work, we propose Self Normalizing Flows, a flexible\nframework for training normalizing flows by replacing expensive terms in the\ngradient by learned approximate inverses at each layer. This reduces the\ncomputational complexity of each layer's exact update from $\\mathcal{O}(D^3)$\nto $\\mathcal{O}(D^2)$, allowing for the training of flow architectures which\nwere otherwise computationally infeasible, while also providing efficient\nsampling. We show experimentally that such models are remarkably stable and\noptimize to similar data likelihood values as their exact gradient\ncounterparts, while training more quickly and surpassing the performance of\nfunctionally constrained counterparts.",
          "link": "http://arxiv.org/abs/2011.07248",
          "publishedOn": "2021-06-10T01:56:48.302Z",
          "wordCount": 625,
          "title": "Self Normalizing Flows. (arXiv:2011.07248v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05106",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sahay_A/0/1/0/all/0/1\">Atul Sahay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_I/0/1/0/all/0/1\">Imon Mukherjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arya_K/0/1/0/all/0/1\">Kavi Arya</a>",
          "description": "A user's eyes provide means for Human Computer Interaction (HCI) research as\nan important modal. The time to time scientific explorations of the eye has\nalready seen an upsurge of the benefits in HCI applications from gaze\nestimation to the measure of attentiveness of a user looking at a screen for a\ngiven time period. The eye tracking system as an assisting, interactive tool\ncan be incorporated by physically disabled individuals, fitted best for those\nwho have eyes as only a limited set of communication. The threefold objective\nof this paper is - 1. To introduce a neural network based architecture to\npredict users' gaze at 9 positions displayed in the 11.31{\\deg} visual range on\nthe screen, through a low resolution based system such as a webcam in real time\nby learning various aspects of eyes as an ocular feature set. 2.A collection of\ncoarsely supervised feature set obtained in real time which is also validated\nthrough the user case study presented in the paper for 21 individuals ( 17 men\nand 4 women ) from whom a 35k set of instances was derived with an accuracy\nscore of 82.36% and f1_score of 82.2% and 3.A detailed study over applicability\nand underlying challenges of such systems. The experimental results verify the\nfeasibility and validity of the proposed eye gaze tracking model.",
          "link": "http://arxiv.org/abs/2106.05106",
          "publishedOn": "2021-06-10T01:56:48.297Z",
          "wordCount": 674,
          "title": "An Efficient Point of Gaze Estimator for Low-Resolution Imaging Systems Using Extracted Ocular Features Based Neural Architecture. (arXiv:2106.05106v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05220",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Heidarzadeh_A/0/1/0/all/0/1\">Anoosheh Heidarzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Esmati_N/0/1/0/all/0/1\">Nahid Esmati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sprintson_A/0/1/0/all/0/1\">Alex Sprintson</a>",
          "description": "This paper introduces the problem of Private Linear Transformation (PLT)\nwhich generalizes the problems of private information retrieval and private\nlinear computation. The PLT problem includes one or more remote server(s)\nstoring (identical copies of) $K$ messages and a user who wants to compute $L$\nindependent linear combinations of a $D$-subset of messages. The objective of\nthe user is to perform the computation by downloading minimum possible amount\nof information from the server(s), while protecting the identities of the $D$\nmessages required for the computation. In this work, we focus on the\nsingle-server setting of the PLT problem when the identities of the $D$\nmessages required for the computation must be protected jointly. We consider\ntwo different models, depending on whether the coefficient matrix of the\nrequired $L$ linear combinations generates a Maximum Distance Separable (MDS)\ncode. We prove that the capacity for both models is given by $L/(K-D+L)$, where\nthe capacity is defined as the supremum of all achievable download rates. Our\nconverse proofs are based on linear-algebraic and information-theoretic\narguments that establish connections between PLT schemes and linear codes. We\nalso present an achievability scheme for each of the models being considered.",
          "link": "http://arxiv.org/abs/2106.05220",
          "publishedOn": "2021-06-10T01:56:48.257Z",
          "wordCount": 638,
          "title": "Single-Server Private Linear Transformation: The Joint Privacy Case. (arXiv:2106.05220v1 [cs.IT])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05113",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gaziv_G/0/1/0/all/0/1\">Guy Gaziv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Irani_M/0/1/0/all/0/1\">Michal Irani</a>",
          "description": "In the past few years, significant advancements were made in reconstruction\nof observed natural images from fMRI brain recordings using deep-learning\ntools. Here, for the first time, we show that dense 3D depth maps of observed\n2D natural images can also be recovered directly from fMRI brain recordings. We\nuse an off-the-shelf method to estimate the unknown depth maps of natural\nimages. This is applied to both: (i) the small number of images presented to\nsubjects in an fMRI scanner (images for which we have fMRI recordings -\nreferred to as \"paired\" data), and (ii) a very large number of natural images\nwith no fMRI recordings (\"unpaired data\"). The estimated depth maps are then\nused as an auxiliary reconstruction criterion to train for depth reconstruction\ndirectly from fMRI. We propose two main approaches: Depth-only recovery and\njoint image-depth RGBD recovery. Because the number of available \"paired\"\ntraining data (images with fMRI) is small, we enrich the training data via\nself-supervised cycle-consistent training on many \"unpaired\" data (natural\nimages & depth maps without fMRI). This is achieved using our newly defined and\ntrained Depth-based Perceptual Similarity metric as a reconstruction criterion.\nWe show that predicting the depth map directly from fMRI outperforms its\nindirect sequential recovery from the reconstructed images. We further show\nthat activations from early cortical visual areas dominate our depth\nreconstruction results, and propose means to characterize fMRI voxels by their\ndegree of depth-information tuning. This work adds an important layer of\ndecoded information, extending the current envelope of visual brain decoding\ncapabilities.",
          "link": "http://arxiv.org/abs/2106.05113",
          "publishedOn": "2021-06-10T01:56:48.250Z",
          "wordCount": 696,
          "title": "More than meets the eye: Self-supervised depth reconstruction from brain activity. (arXiv:2106.05113v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2103.04985",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Dai_B/0/1/0/all/0/1\">Ben Dai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shen_X/0/1/0/all/0/1\">Xiaotong Shen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pan_W/0/1/0/all/0/1\">Wei Pan</a>",
          "description": "An exciting recent development is the uptake of deep learning in many\nscientific fields, where the objective is seeking novel scientific insights and\ndiscoveries. To interpret a learning outcome, researchers perform hypothesis\ntesting for explainable features to advance scientific domain knowledge. In\nsuch a situation, testing for a blackbox learner poses a severe challenge\nbecause of intractable models, unknown limiting distributions of parameter\nestimates, and high computational constraints. In this article, we derive two\nconsistent tests for the feature relevance of a blackbox learner. The first one\nevaluates a loss difference with perturbation on an inference sample, which is\nindependent of an estimation sample used for parameter estimation in model\nfitting. The second further splits the inference sample into two but does not\nrequire data perturbation. Also, we develop their combined versions by\naggregating the order statistics of the $p$-values based on repeated sample\nsplitting. To estimate the splitting ratio and the perturbation size, we\ndevelop adaptive splitting schemes for suitably controlling the Type \\rom{1}\nerror subject to computational constraints. By deflating the\n\\textit{bias-sd-ratio}, we establish asymptotic null distributions of the test\nstatistics and their consistency in terms of statistical power. Our theoretical\npower analysis and simulations indicate that the one-split test is more\npowerful than the two-split test, though the latter is easier to apply for\nlarge datasets. Moreover, the combined tests are more stable while compensating\nfor a power loss by repeated sample splitting. Numerically, we demonstrate the\nutility of the proposed tests on two benchmark examples. Accompanying this\npaper is our Python library {\\tt dnn-inference}\nhttps://dnn-inference.readthedocs.io/en/latest/ that implements the proposed\ntests.",
          "link": "http://arxiv.org/abs/2103.04985",
          "publishedOn": "2021-06-10T01:56:48.211Z",
          "wordCount": 713,
          "title": "Significance tests of feature relevance for a blackbox learner. (arXiv:2103.04985v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04876",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zimerman_I/0/1/0/all/0/1\">Itamar Zimerman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nachmani_E/0/1/0/all/0/1\">Eliya Nachmani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolf_L/0/1/0/all/0/1\">Lior Wolf</a>",
          "description": "Cold boot attacks inspect the corrupted random access memory soon after the\npower has been shut down. While most of the bits have been corrupted, many\nbits, at random locations, have not. Since the keys in many encryption schemes\nare being expanded in memory into longer keys with fixed redundancies, the keys\ncan often be restored. In this work, we combine a novel cryptographic variant\nof a deep error correcting code technique with a modified SAT solver scheme to\napply the attack on AES keys. Even though AES consists of Rijndael S-box\nelements, that are specifically designed to be resistant to linear and\ndifferential cryptanalysis, our method provides a novel formalization of the\nAES key scheduling as a computational graph, which is implemented by a neural\nmessage passing network. Our results show that our methods outperform the state\nof the art attack methods by a very large margin.",
          "link": "http://arxiv.org/abs/2106.04876",
          "publishedOn": "2021-06-10T01:56:48.205Z",
          "wordCount": 588,
          "title": "Recovering AES Keys with a Deep Cold Boot Attack. (arXiv:2106.04876v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2105.11802",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kirschner_J/0/1/0/all/0/1\">Johannes Kirschner</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Krause_A/0/1/0/all/0/1\">Andreas Krause</a>",
          "description": "We consider Bayesian optimization in settings where observations can be\nadversarially biased, for example by an uncontrolled hidden confounder. Our\nfirst contribution is a reduction of the confounded setting to the dueling\nbandit model. Then we propose a novel approach for dueling bandits based on\ninformation-directed sampling (IDS). Thereby, we obtain the first efficient\nkernelized algorithm for dueling bandits that comes with cumulative regret\nguarantees. Our analysis further generalizes a previously proposed\nsemi-parametric linear bandit model to non-linear reward functions, and\nuncovers interesting links to doubly-robust estimation.",
          "link": "http://arxiv.org/abs/2105.11802",
          "publishedOn": "2021-06-10T01:56:48.182Z",
          "wordCount": 524,
          "title": "Bias-Robust Bayesian Optimization via Dueling Bandits. (arXiv:2105.11802v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04751",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1\">Chang Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reddy_C/0/1/0/all/0/1\">Chandan K. Reddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ning_Y/0/1/0/all/0/1\">Yue Ning</a>",
          "description": "Electronic Health Records (EHR) have been heavily used in modern healthcare\nsystems for recording patients' admission information to hospitals. Many\ndata-driven approaches employ temporal features in EHR for predicting specific\ndiseases, readmission times, or diagnoses of patients. However, most existing\npredictive models cannot fully utilize EHR data, due to an inherent lack of\nlabels in supervised training for some temporal events. Moreover, it is hard\nfor existing works to simultaneously provide generic and personalized\ninterpretability. To address these challenges, we first propose a hyperbolic\nembedding method with information flow to pre-train medical code\nrepresentations in a hierarchical structure. We incorporate these pre-trained\nrepresentations into a graph neural network to detect disease complications,\nand design a multi-level attention method to compute the contributions of\nparticular diseases and admissions, thus enhancing personalized\ninterpretability. We present a new hierarchy-enhanced historical prediction\nproxy task in our self-supervised learning framework to fully utilize EHR data\nand exploit medical domain knowledge. We conduct a comprehensive set of\nexperiments and case studies on widely used publicly available EHR datasets to\nverify the effectiveness of our model. The results demonstrate our model's\nstrengths in both predictive tasks and interpretable abilities.",
          "link": "http://arxiv.org/abs/2106.04751",
          "publishedOn": "2021-06-10T01:56:48.177Z",
          "wordCount": 652,
          "title": "Self-Supervised Graph Learning with Hyperbolic Embedding for Temporal Health Event Prediction. (arXiv:2106.04751v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.03928",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wies_N/0/1/0/all/0/1\">Noam Wies</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_Y/0/1/0/all/0/1\">Yoav Levine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jannai_D/0/1/0/all/0/1\">Daniel Jannai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shashua_A/0/1/0/all/0/1\">Amnon Shashua</a>",
          "description": "After their successful debut in natural language processing, Transformer\narchitectures are now becoming the de-facto standard in many domains. An\nobstacle for their deployment over new modalities is the architectural\nconfiguration: the optimal depth-to-width ratio has been shown to dramatically\nvary across data types (e.g., $10$x larger over images than over language). We\ntheoretically predict the existence of an embedding rank bottleneck that limits\nthe contribution of self-attention width to the Transformer expressivity. We\nthus directly tie the input vocabulary size and rank to the optimal\ndepth-to-width ratio, since a small vocabulary size or rank dictates an added\nadvantage of depth over width. We empirically demonstrate the existence of this\nbottleneck and its implications on the depth-to-width interplay of Transformer\narchitectures, linking the architecture variability across domains to the often\nglossed-over usage of different vocabulary sizes or embedding ranks in\ndifferent domains. As an additional benefit, our rank bottlenecking framework\nallows us to identify size redundancies of $25\\%-50\\%$ in leading NLP models\nsuch as ALBERT and T5.",
          "link": "http://arxiv.org/abs/2105.03928",
          "publishedOn": "2021-06-10T01:56:48.168Z",
          "wordCount": 632,
          "title": "Which transformer architecture fits my data? A vocabulary bottleneck in self-attention. (arXiv:2105.03928v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09046",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ingale_V/0/1/0/all/0/1\">Vaishali Ingale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohan_A/0/1/0/all/0/1\">Anush Mohan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adlakha_D/0/1/0/all/0/1\">Divit Adlakha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_K/0/1/0/all/0/1\">Krishan Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_M/0/1/0/all/0/1\">Mohit Gupta</a>",
          "description": "This paper explores the idea of utilising Long Short-Term Memory neural\nnetworks (LSTMNN) for the generation of musical sequences in ABC notation. The\nproposed approach takes ABC notations from the Nottingham dataset and encodes\nit to be fed as input for the neural networks. The primary objective is to\ninput the neural networks with an arbitrary note, let the network process and\naugment a sequence based on the note until a good piece of music is produced.\nMultiple calibrations have been done to amend the parameters of the network for\noptimal generation. The output is assessed on the basis of rhythm, harmony, and\ngrammar accuracy.",
          "link": "http://arxiv.org/abs/2105.09046",
          "publishedOn": "2021-06-10T01:56:48.163Z",
          "wordCount": 573,
          "title": "Music Generation using Three-layered LSTM. (arXiv:2105.09046v3 [cs.SD] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.12353",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1\">Chaochao Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yuhuai Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hernandez_Lobato_J/0/1/0/all/0/1\">Jo&#x15b;e Miguel Hern&#xe1;ndez-Lobato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1\">Bernhard Sch&#xf6;lkopf</a>",
          "description": "Due to spurious correlations, machine learning systems often fail to\ngeneralize to environments whose distributions differ from the ones used at\ntraining time. Prior work addressing this, either explicitly or implicitly,\nattempted to find a data representation that has an invariant relationship with\nthe target. This is done by leveraging a diverse set of training environments\nto reduce the effect of spurious features and build an invariant predictor.\nHowever, these methods have generalization guarantees only when both data\nrepresentation and classifiers come from a linear model class. We propose\ninvariant Causal Representation Learning (iCaRL), an approach that enables\nout-of-distribution (OOD) generalization in the nonlinear setting (i.e.,\nnonlinear representations and nonlinear classifiers). It builds upon a\npractical and general assumption: the prior over the data representation (i.e.,\na set of latent variables encoding the data) given the target and the\nenvironment belongs to general exponential family distributions. Based on this,\nwe show that it is possible to identify the data representation up to simple\ntransformations. We also prove that all direct causes of the target can be\nfully discovered, which further enables us to obtain generalization guarantees\nin the nonlinear setting. Extensive experiments on both synthetic and\nreal-world datasets show that our approach outperforms a variety of baseline\nmethods. Finally, in the discussion, we further explore the aforementioned\nassumption and propose a more general hypothesis, called the Agnostic\nHypothesis: there exist a set of hidden causal factors affecting both inputs\nand outcomes. The Agnostic Hypothesis can provide a unifying view of machine\nlearning. More importantly, it can inspire a new direction to explore a general\ntheory for identifying hidden causal factors, which is key to enabling the OOD\ngeneralization guarantees.",
          "link": "http://arxiv.org/abs/2102.12353",
          "publishedOn": "2021-06-10T01:56:48.156Z",
          "wordCount": 737,
          "title": "Nonlinear Invariant Risk Minimization: A Causal Approach. (arXiv:2102.12353v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14422",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cai_H/0/1/0/all/0/1\">Hengrui Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cen_Z/0/1/0/all/0/1\">Zhihao Cen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leng_L/0/1/0/all/0/1\">Ling Leng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_R/0/1/0/all/0/1\">Rui Song</a>",
          "description": "We consider the sequential decision optimization on the periodic environment,\nthat occurs in a wide variety of real-world applications when the data involves\nseasonality, such as the daily demand of drivers in ride-sharing and dynamic\ntraffic patterns in transportation. In this work, we focus on learning the\nstochastic periodic world by leveraging this seasonal law. To deal with the\ngeneral action space, we use the bandit based on Gaussian process (GP) as the\nbase model due to its flexibility and generality, and propose the Periodic-GP\nmethod with a temporal periodic kernel based on the upper confidence bound.\nTheoretically, we provide a new regret bound of the proposed method, by\nexplicitly characterizing the periodic kernel in the periodic stationary model.\nEmpirically, the proposed algorithm significantly outperforms the existing\nmethods in both synthetic data experiments and a real data application on\nMadrid traffic pollution.",
          "link": "http://arxiv.org/abs/2105.14422",
          "publishedOn": "2021-06-10T01:56:48.139Z",
          "wordCount": 602,
          "title": "Periodic-GP: Learning Periodic World with Gaussian Process Bandits. (arXiv:2105.14422v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04911",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bokun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Z/0/1/0/all/0/1\">Zhuoning Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ying_Y/0/1/0/all/0/1\">Yiming Ying</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1\">Tianbao Yang</a>",
          "description": "Recently, model-agnostic meta-learning (MAML) has garnered tremendous\nattention. However, stochastic optimization of MAML is still immature. Existing\nalgorithms for MAML are based on the ``episode\" idea by sampling a number of\ntasks and a number of data points for each sampled task at each iteration for\nupdating the meta-model. However, they either do not necessarily guarantee\nconvergence with a constant mini-batch size or require processing a larger\nnumber of tasks at every iteration, which is not viable for continual learning\nor cross-device federated learning where only a small number of tasks are\navailable per-iteration or per-round. This paper addresses these issues by (i)\nproposing efficient memory-based stochastic algorithms for MAML with a\ndiminishing convergence error, which only requires sampling a constant number\nof tasks and a constant number of examples per-task per-iteration; (ii)\nproposing communication-efficient distributed memory-based MAML algorithms for\npersonalized federated learning in both the cross-device (w/ client sampling)\nand the cross-silo (w/o client sampling) settings. The key novelty of the\nproposed algorithms is to maintain an individual personalized model (aka\nmemory) for each task besides the meta-model and only update them for the\nsampled tasks by a momentum method that incorporates historical updates at each\niteration. The theoretical results significantly improve the optimization\ntheory for MAML and the empirical results also corroborate the theory.",
          "link": "http://arxiv.org/abs/2106.04911",
          "publishedOn": "2021-06-10T01:56:48.128Z",
          "wordCount": 635,
          "title": "Memory-based Optimization Methods for Model-Agnostic Meta-Learning. (arXiv:2106.04911v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00116",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cherti_M/0/1/0/all/0/1\">Mehdi Cherti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jitsev_J/0/1/0/all/0/1\">Jenia Jitsev</a>",
          "description": "Transfer learning aims to exploit pre-trained models for more efficient\nfollow-up training on wide range of downstream tasks and datasets, enabling\nsuccessful training also on small data. Recent line of work posits strong\nbenefits for model generalization and transfer when model size, data size, and\ncompute budget are increased for the pre-training. It remains however still\nlargely unclear whether the observed transfer improvement due to increase in\nscale also holds when source and target data distributions are far apart from\neach other. In this work we conduct large-scale pre-training on large source\ndatasets of either natural (ImageNet-21k/1k) or medical chest X-Ray images and\ncompare full and few-shot transfer using different target datasets from both\nnatural and medical imaging domains. Our observations provide evidence that\nwhile pre-training and transfer on closely related datasets do show clear\nbenefit of increasing model and data size during pre-training, such benefits\nare not clearly visible when source and target datasets are further apart.\nThese observations hold across both full and few-shot transfer and indicate\nthat scaling laws pointing to improvement of generalization and transfer with\nincreasing model and data size are incomplete and should be revised by taking\ninto account the type and proximity of the source and target data, to correctly\npredict the effect of model and data scale during pre-training on transfer.\nRemarkably, in full shot transfer to a large X-Ray chest imaging target\n(PadChest), the largest model pre-trained on ImageNet-21k slightly outperforms\nbest models pre-trained on large X-Ray chest imaging data. This indicates\npossibility to obtain high quality models for domain-specific transfer even\nwithout access to large domain-specific data, by pre-training instead on\ncomparably very large, generic source data.",
          "link": "http://arxiv.org/abs/2106.00116",
          "publishedOn": "2021-06-10T01:56:48.121Z",
          "wordCount": 742,
          "title": "Effect of large-scale pre-training on full and few-shot transfer learning for natural and medical images. (arXiv:2106.00116v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05262",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Biedenkapp_A/0/1/0/all/0/1\">Andr&#xe9; Biedenkapp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajan_R/0/1/0/all/0/1\">Raghu Rajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hutter_F/0/1/0/all/0/1\">Frank Hutter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lindauer_M/0/1/0/all/0/1\">Marius Lindauer</a>",
          "description": "Reinforcement learning is a powerful approach to learn behaviour through\ninteractions with an environment. However, behaviours are usually learned in a\npurely reactive fashion, where an appropriate action is selected based on an\nobservation. In this form, it is challenging to learn when it is necessary to\nexecute new decisions. This makes learning inefficient, especially in\nenvironments that need various degrees of fine and coarse control. To address\nthis, we propose a proactive setting in which the agent not only selects an\naction in a state but also for how long to commit to that action. Our TempoRL\napproach introduces skip connections between states and learns a skip-policy\nfor repeating the same action along these skips. We demonstrate the\neffectiveness of TempoRL on a variety of traditional and deep RL environments,\nshowing that our approach is capable of learning successful policies up to an\norder of magnitude faster than vanilla Q-learning.",
          "link": "http://arxiv.org/abs/2106.05262",
          "publishedOn": "2021-06-10T01:56:48.115Z",
          "wordCount": 573,
          "title": "TempoRL: Learning When to Act. (arXiv:2106.05262v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.11174",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schlag_I/0/1/0/all/0/1\">Imanol Schlag</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Irie_K/0/1/0/all/0/1\">Kazuki Irie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidhuber_J/0/1/0/all/0/1\">J&#xfc;rgen Schmidhuber</a>",
          "description": "We show the formal equivalence of linearised self-attention mechanisms and\nfast weight controllers from the early '90s, where a ``slow\" neural net learns\nby gradient descent to program the ``fast weights\" of another net through\nsequences of elementary programming instructions which are additive outer\nproducts of self-invented activation patterns (today called keys and values).\nSuch Fast Weight Programmers (FWPs) learn to manipulate the contents of a\nfinite memory and dynamically interact with it. We infer a memory capacity\nlimitation of recent linearised softmax attention variants, and replace the\npurely additive outer products by a delta rule-like programming instruction,\nsuch that the FWP can more easily learn to correct the current mapping from\nkeys to values. The FWP also learns to compute dynamically changing learning\nrates. We also propose a new kernel function to linearise attention which\nbalances simplicity and effectiveness. We conduct experiments on synthetic\nretrieval problems as well as standard machine translation and language\nmodelling tasks which demonstrate the benefits of our methods.",
          "link": "http://arxiv.org/abs/2102.11174",
          "publishedOn": "2021-06-10T01:56:48.101Z",
          "wordCount": 620,
          "title": "Linear Transformers Are Secretly Fast Weight Programmers. (arXiv:2102.11174v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04967",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Petersen_J/0/1/0/all/0/1\">Jens Petersen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kohler_G/0/1/0/all/0/1\">Gregor K&#xf6;hler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zimmerer_D/0/1/0/all/0/1\">David Zimmerer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Isensee_F/0/1/0/all/0/1\">Fabian Isensee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jager_P/0/1/0/all/0/1\">Paul F. J&#xe4;ger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maier_Hein_K/0/1/0/all/0/1\">Klaus H. Maier-Hein</a>",
          "description": "Neural Processes (NPs) are a family of conditional generative models that are\nable to model a distribution over functions, in a way that allows them to\nperform predictions at test time conditioned on a number of context points. A\nrecent addition to this family, Convolutional Conditional Neural Processes\n(ConvCNP), have shown remarkable improvement in performance over prior art, but\nwe find that they sometimes struggle to generalize when applied to time series\ndata. In particular, they are not robust to distribution shifts and fail to\nextrapolate observed patterns into the future. By incorporating a Gaussian\nProcess into the model, we are able to remedy this and at the same time improve\nperformance within distribution. As an added benefit, the Gaussian Process\nreintroduces the possibility to sample from the model, a key feature of other\nmembers in the NP family.",
          "link": "http://arxiv.org/abs/2106.04967",
          "publishedOn": "2021-06-10T01:56:48.079Z",
          "wordCount": 588,
          "title": "GP-ConvCNP: Better Generalization for Convolutional Conditional Neural Processes on Time Series Data. (arXiv:2106.04967v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09501",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1\">Xiao Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mingxuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1\">Liwei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>",
          "description": "Existing multilingual machine translation approaches mainly focus on\nEnglish-centric directions, while the non-English directions still lag behind.\nIn this work, we aim to build a many-to-many translation system with an\nemphasis on the quality of non-English language directions. Our intuition is\nbased on the hypothesis that a universal cross-language representation leads to\nbetter multilingual translation performance. To this end, we propose mRASP2, a\ntraining method to obtain a single unified multilingual translation model.\nmRASP2 is empowered by two techniques: a) a contrastive learning scheme to\nclose the gap among representations of different languages, and b) data\naugmentation on both multiple parallel and monolingual data to further align\ntoken representations. For English-centric directions, mRASP2 outperforms\nexisting best unified model and achieves competitive or even better performance\nthan the pre-trained and fine-tuned model mBART on tens of WMT's translation\ndirections. For non-English directions, mRASP2 achieves an improvement of\naverage 10+ BLEU compared with the multilingual Transformer baseline. Code,\ndata and trained models are available at https://github.com/PANXiao1994/mRASP2.",
          "link": "http://arxiv.org/abs/2105.09501",
          "publishedOn": "2021-06-10T01:56:48.073Z",
          "wordCount": 627,
          "title": "Contrastive Learning for Many-to-many Multilingual Neural Machine Translation. (arXiv:2105.09501v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.03111",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+De_S/0/1/0/all/0/1\">Sourav De</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_H/0/1/0/all/0/1\">Hoang-Hiep Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_B/0/1/0/all/0/1\">Bo-Han Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baig_M/0/1/0/all/0/1\">Md. Aftab Baig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sung_P/0/1/0/all/0/1\">Po-Jung Sung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_C/0/1/0/all/0/1\">Chung Jun Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1\">Yao-Jen Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_D/0/1/0/all/0/1\">Darsen D. Lu</a>",
          "description": "A synergistic approach for optimizing devices, circuits, and neural network\narchitectures was used to abate junction-temperature-change-induced performance\ndegradation of a Fe-FinFET-based artificial neural network. We demonstrated\nthat the digital nature of the binarized neural network, with the \"0\" state\nprogrammed deep in the subthreshold and the \"1\" state in strong inversion, is\ncrucial for robust DNN inference. The performance of a purely software-based\nbinary neural network (BNN), with 96.1% accuracy for Modified National\nInstitute of Standards and Technology (MNIST) handwritten digit recognition,\nwas used as a baseline. The Fe-FinFET-based BNN (including device-to-device\nvariation at 300 K) achieved 95.7% inference accuracy on the MNIST dataset.\nAlthough substantial inference accuracy degradation with temperature change was\nobserved in a nonbinary neural network, the BNN with optimized Fe-FinFETs as\nsynaptic devices had excellent resistance to temperature change effects and\nmaintained a minimum inference accuracy of 95.2% within a temperature range of\n-233K to 398K after gate stack and bias optimization. However, reprogramming to\nadjust device conductance was necessary for temperatures higher than 398K.",
          "link": "http://arxiv.org/abs/2103.03111",
          "publishedOn": "2021-06-10T01:56:48.067Z",
          "wordCount": 669,
          "title": "Robust Binary Neural Network Operation from 233 K to 398 K via Gate Stack and Bias Optimization of Ferroelectric FinFET Synapses. (arXiv:2103.03111v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.01710",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Thiede_E/0/1/0/all/0/1\">Erik Henning Thiede</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Wenda Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kondor_R/0/1/0/all/0/1\">Risi Kondor</a>",
          "description": "We introduce Automorphism-based graph neural networks (Autobahn), a new\nfamily of graph neural networks. In an Autobahn, we decompose the graph into a\ncollection of subgraphs and apply local convolutions that are equivariant to\neach subgraph's automorphism group. Specific choices of local neighborhoods and\nsubgraphs recover existing architectures such as message passing neural\nnetworks. Our formalism also encompasses novel architectures: as an example, we\nintroduce a graph neural network that decomposes the graph into paths and\ncycles. The resulting convolutions reflect the natural way that parts of the\ngraph can transform, preserving the intuitive meaning of convolution without\nsacrificing global permutation equivariance. We validate our approach by\napplying Autobahn to molecular graphs, where it achieves state-of-the-art\nresults.",
          "link": "http://arxiv.org/abs/2103.01710",
          "publishedOn": "2021-06-10T01:56:48.061Z",
          "wordCount": 566,
          "title": "Autobahn: Automorphism-based Graph Neural Nets. (arXiv:2103.01710v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05134",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Nath_R/0/1/0/all/0/1\">Rajdeep Kumar Nath</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Thapliyal_H/0/1/0/all/0/1\">Himanshu Thapliyal</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Humble_T/0/1/0/all/0/1\">Travis S. Humble</a>",
          "description": "We present a novel methodology for automated feature subset selection from a\npool of physiological signals using Quantum Annealing (QA). As a case study, we\nwill investigate the effectiveness of QA-based feature selection techniques in\nselecting the optimal feature subset for stress detection. Features are\nextracted from four signal sources: foot EDA, hand EDA, ECG, and respiration.\nThe proposed method embeds the feature variables extracted from the\nphysiological signals in a binary quadratic model. The bias of the feature\nvariable is calculated using the Pearson correlation coefficient between the\nfeature variable and the target variable. The weight of the edge connecting the\ntwo feature variables is calculated using the Pearson correlation coefficient\nbetween two feature variables in the binary quadratic model. Subsequently,\nD-Wave's clique sampler is used to sample cliques from the binary quadratic\nmodel. The underlying solution is then re-sampled to obtain multiple good\nsolutions and the clique with the lowest energy is returned as the optimal\nsolution. The proposed method is compared with commonly used feature selection\ntechniques for stress detection. Results indicate that QA-based feature subset\nselection performed equally as that of classical techniques. However, under\ndata uncertainty conditions such as limited training data, the performance of\nquantum annealing for selecting optimum features remained unaffected, whereas a\nsignificant decrease in performance is observed with classical feature\nselection techniques. Preliminary results show the promise of quantum annealing\nin optimizing the training phase of a machine learning classifier, especially\nunder data uncertainty conditions.",
          "link": "http://arxiv.org/abs/2106.05134",
          "publishedOn": "2021-06-10T01:56:48.044Z",
          "wordCount": 693,
          "title": "Quantum Annealing for Automated Feature Selection in Stress Detection. (arXiv:2106.05134v1 [quant-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04929",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Das_D/0/1/0/all/0/1\">Diptesh Das</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Duy_V/0/1/0/all/0/1\">Vo Nguyen Le Duy</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hanada_H/0/1/0/all/0/1\">Hiroyuki Hanada</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tsuda_K/0/1/0/all/0/1\">Koji Tsuda</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Takeuchi_I/0/1/0/all/0/1\">Ichiro Takeuchi</a>",
          "description": "Automated high-stake decision-making such as medical diagnosis requires\nmodels with high interpretability and reliability. As one of the interpretable\nand reliable models with good prediction ability, we consider Sparse High-order\nInteraction Model (SHIM) in this study. However, finding statistically\nsignificant high-order interactions is challenging due to the intrinsic high\ndimensionality of the combinatorial effects. Another problem in data-driven\nmodeling is the effect of \"cherry-picking\" a.k.a. selection bias. Our main\ncontribution is to extend the recently developed parametric programming\napproach for selective inference to high-order interaction models. Exhaustive\nsearch over the cherry tree (all possible interactions) can be daunting and\nimpractical even for a small-sized problem. We introduced an efficient pruning\nstrategy and demonstrated the computational efficiency and statistical power of\nthe proposed method using both synthetic and real data.",
          "link": "http://arxiv.org/abs/2106.04929",
          "publishedOn": "2021-06-10T01:56:48.038Z",
          "wordCount": 567,
          "title": "Fast and More Powerful Selective Inference for Sparse High-order Interaction Model. (arXiv:2106.04929v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2103.09108",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tuggener_L/0/1/0/all/0/1\">Lukas Tuggener</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidhuber_J/0/1/0/all/0/1\">J&#xfc;rgen Schmidhuber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stadelmann_T/0/1/0/all/0/1\">Thilo Stadelmann</a>",
          "description": "An implicit but pervasive hypothesis of modern computer vision research is\nthat convolutional neural network (CNN) architectures that perform better on\nImageNet will also perform better on other vision datasets. We challenge this\nhypothesis through an extensive empirical study for which we train 500 sampled\nCNN architectures on ImageNet as well as 8 other image classification datasets\nfrom a wide array of application domains. The relationship between architecture\nand performance varies wildly, depending on the datasets. For some of them, the\nperformance correlation with ImageNet is even negative. Clearly, it is not\nenough to optimize architectures solely for ImageNet when aiming for progress\nthat is relevant for all applications. Therefore, we identify two\ndataset-specific performance indicators: the cumulative width across layers as\nwell as the total depth of the network. Lastly, we show that the range of\ndataset variability covered by ImageNet can be significantly extended by adding\nImageNet subsets restricted to few classes.",
          "link": "http://arxiv.org/abs/2103.09108",
          "publishedOn": "2021-06-10T01:56:48.032Z",
          "wordCount": 615,
          "title": "Is it Enough to Optimize CNN Architectures on ImageNet?. (arXiv:2103.09108v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.03452",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Tran_Dinh_Q/0/1/0/all/0/1\">Quoc Tran-Dinh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pham_N/0/1/0/all/0/1\">Nhan H. Pham</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Phan_D/0/1/0/all/0/1\">Dzung T. Phan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nguyen_L/0/1/0/all/0/1\">Lam M. Nguyen</a>",
          "description": "We develop two new algorithms, called, FedDR and asyncFedDR, for solving a\nfundamental nonconvex composite optimization problem in federated learning. Our\nalgorithms rely on a novel combination between a nonconvex Douglas-Rachford\nsplitting method, randomized block-coordinate strategies, and asynchronous\nimplementation. They can also handle convex regularizers. Unlike recent methods\nin the literature, e.g., FedSplit and FedPD, our algorithms update only a\nsubset of users at each communication round, and possibly in an asynchronous\nmanner, making them more practical. These new algorithms also achieve\ncommunication efficiency and more importantly can handle statistical and system\nheterogeneity, which are the two main challenges in federated learning. Our\nconvergence analysis shows that the new algorithms match the communication\ncomplexity lower bound up to a constant factor under standard assumptions. Our\nnumerical experiments illustrate the advantages of our methods compared to\nexisting ones on several datasets.",
          "link": "http://arxiv.org/abs/2103.03452",
          "publishedOn": "2021-06-10T01:56:48.027Z",
          "wordCount": 610,
          "title": "FedDR -- Randomized Douglas-Rachford Splitting Algorithms for Nonconvex Federated Composite Optimization. (arXiv:2103.03452v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.05462",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Herbert_T/0/1/0/all/0/1\">Tobias Herbert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mangler_J/0/1/0/all/0/1\">Juergen Mangler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rinderle_Ma_S/0/1/0/all/0/1\">Stefanie Rinderle-Ma</a>",
          "description": "Domains such as manufacturing and medicine crave for continuous monitoring\nand analysis of their processes, especially in combination with time series as\nproduced by sensors. Time series data can be exploited to, for example, explain\nand predict concept drifts during runtime. Generally, a certain data volume is\nrequired in order to produce meaningful analysis results. However, reliable\ndata sets are often missing, for example, if event streams and times series\ndata are collected separately, in case of a new process, or if it is too\nexpensive to obtain a sufficient data volume. Additional challenges arise with\npreparing time series data from multiple event sources, variations in data\ncollection frequency, and concept drift. This paper proposes the GENLOG\napproach to generate reliable event and time series data that follows the\ndistribution of the underlying input data set. GENLOG employs data resampling\nand enables the user to select different parts of the log data to orchestrate\nthe training of a recurrent neural network for stream generation. The generated\ndata is sampled back to its original sample rate and is embedded into the\noriginating log data file. Overall, GENLOG can boost small data sets and\nconsequently the application of online process mining.",
          "link": "http://arxiv.org/abs/2103.05462",
          "publishedOn": "2021-06-10T01:56:48.021Z",
          "wordCount": 669,
          "title": "Generating Reliable Process Event Streams and Time Series Data based on Neural Networks. (arXiv:2103.05462v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14111",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Koch_J/0/1/0/all/0/1\">Jack Koch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Langosco_L/0/1/0/all/0/1\">Lauro Langosco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfau_J/0/1/0/all/0/1\">Jacob Pfau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_J/0/1/0/all/0/1\">James Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharkey_L/0/1/0/all/0/1\">Lee Sharkey</a>",
          "description": "We study objective robustness failures, a type of out-of-distribution\nrobustness failure in reinforcement learning (RL). Objective robustness\nfailures occur when an RL agent retains its capabilities out-of-distribution\nyet pursues the wrong objective. This kind of failure presents different risks\nthan the robustness problems usually considered in the literature, since it\ninvolves agents that leverage their capabilities to pursue the wrong objective\nrather than simply failing to do anything useful. We provide the first explicit\nempirical demonstrations of objective robustness failures and present a partial\ncharacterization of its causes.",
          "link": "http://arxiv.org/abs/2105.14111",
          "publishedOn": "2021-06-10T01:56:48.015Z",
          "wordCount": 537,
          "title": "Objective Robustness in Deep Reinforcement Learning. (arXiv:2105.14111v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.13037",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ramabathiran_A/0/1/0/all/0/1\">Amuthan A. Ramabathiran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramachandran_P/0/1/0/all/0/1\">Prabhu Ramachandran</a>",
          "description": "We introduce a class of Sparse, Physics-based, and Interpretable Neural\nNetworks (SPINN) for solving ordinary and partial differential equations\n(PDEs). By reinterpreting a traditional meshless representation of solutions of\nPDEs we develop a class of sparse neural network architectures that are\ninterpretable. The SPINN model we propose here serves as a seamless bridge\nbetween two extreme modeling tools for PDEs, namely dense neural network based\nmethods like Physics Informed Neural Networks (PINNs) and traditional mesh-free\nnumerical methods, thereby providing a novel means to develop a new class of\nhybrid algorithms that build on the best of both these viewpoints. A unique\nfeature of the SPINN model that distinguishes it from other neural network\nbased approximations proposed earlier is that it is (i) interpretable, and (ii)\nsparse in the sense that it has much fewer connections than typical dense\nneural networks used for PDEs. Further, the SPINN algorithm implicitly encodes\nmesh adaptivity and is able to handle discontinuities in the solutions. In\naddition, we demonstrate that Fourier series representations can also be\nexpressed as a special class of SPINN and propose generalized neural network\nanalogues of Fourier representations. We illustrate the utility of the proposed\nmethod with a variety of examples involving ordinary differential equations,\nelliptic, parabolic, hyperbolic and nonlinear partial differential equations,\nand an example in fluid dynamics.",
          "link": "http://arxiv.org/abs/2102.13037",
          "publishedOn": "2021-06-10T01:56:47.998Z",
          "wordCount": 688,
          "title": "SPINN: Sparse, Physics-based, and Interpretable Neural Networks for PDEs. (arXiv:2102.13037v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04886",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Both_G/0/1/0/all/0/1\">Gert-Jan Both</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kusters_R/0/1/0/all/0/1\">Remy Kusters</a>",
          "description": "Model discovery aims at autonomously discovering differential equations\nunderlying a dataset. Approaches based on Physics Informed Neural Networks\n(PINNs) have shown great promise, but a fully-differentiable model which\nexplicitly learns the equation has remained elusive. In this paper we propose\nsuch an approach by combining neural network based surrogates with Sparse\nBayesian Learning (SBL). We start by reinterpreting PINNs as multitask models,\napplying multitask learning using uncertainty, and show that this leads to a\nnatural framework for including Bayesian regression techniques. We then\nconstruct a robust model discovery algorithm by using SBL, which we showcase on\nvarious datasets. Concurrently, the multitask approach allows the use of\nprobabilistic approximators, and we show a proof of concept using normalizing\nflows to directly learn a density model from single particle data. Our work\nexpands PINNs to various types of neural network architectures, and connects\nneural network-based surrogates to the rich field of Bayesian parameter\ninference.",
          "link": "http://arxiv.org/abs/2106.04886",
          "publishedOn": "2021-06-10T01:56:47.992Z",
          "wordCount": 568,
          "title": "Fully differentiable model discovery. (arXiv:2106.04886v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2102.07541",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+No_A/0/1/0/all/0/1\">Albert No</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_T/0/1/0/all/0/1\">TaeHo Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwon_S/0/1/0/all/0/1\">Sehyun Kwon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ryu_E/0/1/0/all/0/1\">Ernest K. Ryu</a>",
          "description": "Generative adversarial networks (GAN) are a widely used class of deep\ngenerative models, but their minimax training dynamics are not understood very\nwell. In this work, we show that GANs with a 2-layer infinite-width generator\nand a 2-layer finite-width discriminator trained with stochastic gradient\nascent-descent have no spurious stationary points. We then show that when the\nwidth of the generator is finite but wide, there are no spurious stationary\npoints within a ball whose radius becomes arbitrarily large (to cover the\nentire parameter space) as the width goes to infinity.",
          "link": "http://arxiv.org/abs/2102.07541",
          "publishedOn": "2021-06-10T01:56:47.983Z",
          "wordCount": 559,
          "title": "WGAN with an Infinitely Wide Generator Has No Spurious Stationary Points. (arXiv:2102.07541v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.07686",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ashley_D/0/1/0/all/0/1\">Dylan R. Ashley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghiassian_S/0/1/0/all/0/1\">Sina Ghiassian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sutton_R/0/1/0/all/0/1\">Richard S. Sutton</a>",
          "description": "Catastrophic forgetting remains a severe hindrance to the broad application\nof artificial neural networks (ANNs), however, it continues to be a poorly\nunderstood phenomenon. Despite the extensive amount of work on catastrophic\nforgetting, we argue that it is still unclear how exactly the phenomenon should\nbe quantified, and, moreover, to what degree all of the choices we make when\ndesigning learning systems affect the amount of catastrophic forgetting. We use\nvarious testbeds from the reinforcement learning and supervised learning\nliterature to (1) provide evidence that the choice of which modern\ngradient-based optimization algorithm is used to train an ANN has a significant\nimpact on the amount of catastrophic forgetting and show that-surprisingly-in\nmany instances classical algorithms such as vanilla SGD experience less\ncatastrophic forgetting than the more modern algorithms such as Adam. We\nempirically compare four different existing metrics for quantifying\ncatastrophic forgetting and (2) show that the degree to which the learning\nsystems experience catastrophic forgetting is sufficiently sensitive to the\nmetric used that a change from one principled metric to another is enough to\nchange the conclusions of a study dramatically. Our results suggest that a much\nmore rigorous experimental methodology is required when looking at catastrophic\nforgetting. Based on our results, we recommend inter-task forgetting in\nsupervised learning must be measured with both retention and relearning metrics\nconcurrently, and intra-task forgetting in reinforcement learning must-at the\nvery least-be measured with pairwise interference.",
          "link": "http://arxiv.org/abs/2102.07686",
          "publishedOn": "2021-06-10T01:56:47.976Z",
          "wordCount": 753,
          "title": "Does the Adam Optimizer Exacerbate Catastrophic Forgetting?. (arXiv:2102.07686v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.10710",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wilkinson_W/0/1/0/all/0/1\">William J. Wilkinson</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Solin_A/0/1/0/all/0/1\">Arno Solin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Adam_V/0/1/0/all/0/1\">Vincent Adam</a>",
          "description": "Approximate Bayesian inference methods that scale to very large datasets are\ncrucial in leveraging probabilistic models for real-world time series. Sparse\nMarkovian Gaussian processes combine the use of inducing variables with\nefficient Kalman filter-like recursions, resulting in algorithms whose\ncomputational and memory requirements scale linearly in the number of inducing\npoints, whilst also enabling parallel parameter updates and stochastic\noptimisation. Under this paradigm, we derive a general site-based approach to\napproximate inference, whereby we approximate the non-Gaussian likelihood with\nlocal Gaussian terms, called sites. Our approach results in a suite of novel\nsparse extensions to algorithms from both the machine learning and signal\nprocessing literature, including variational inference, expectation\npropagation, and the classical nonlinear Kalman smoothers. The derived methods\nare suited to large time series, and we also demonstrate their applicability to\nspatio-temporal data, where the model has separate inducing points in both time\nand space.",
          "link": "http://arxiv.org/abs/2103.10710",
          "publishedOn": "2021-06-10T01:56:47.970Z",
          "wordCount": 609,
          "title": "Sparse Algorithms for Markovian Gaussian Processes. (arXiv:2103.10710v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04923",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Andeol_L/0/1/0/all/0/1\">L&#xe9;o And&#xe9;ol</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kawakami_Y/0/1/0/all/0/1\">Yusei Kawakami</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wada_Y/0/1/0/all/0/1\">Yuichiro Wada</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kanamori_T/0/1/0/all/0/1\">Takafumi Kanamori</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Muller_K/0/1/0/all/0/1\">Klaus-Robert M&#xfc;ller</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Montavon_G/0/1/0/all/0/1\">Gr&#xe9;goire Montavon</a>",
          "description": "Domain shifts in the training data are common in practical applications of\nmachine learning, they occur for instance when the data is coming from\ndifferent sources. Ideally, a ML model should work well independently of these\nshifts, for example, by learning a domain-invariant representation. Moreover,\nprivacy concerns regarding the source also require a domain-invariant\nrepresentation. In this work, we provide theoretical results that link domain\ninvariant representations -- measured by the Wasserstein distance on the joint\ndistributions -- to a practical semi-supervised learning objective based on a\ncross-entropy classifier and a novel domain critic. Quantitative experiments\ndemonstrate that the proposed approach is indeed able to practically learn such\nan invariant representation (between two domains), and the latter also supports\nmodels with higher predictive accuracy on both domains, comparing favorably to\nexisting techniques.",
          "link": "http://arxiv.org/abs/2106.04923",
          "publishedOn": "2021-06-10T01:56:47.955Z",
          "wordCount": 573,
          "title": "Learning Domain Invariant Representations by Joint Wasserstein Distance Minimization. (arXiv:2106.04923v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2101.08539",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Sikai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lang_Z/0/1/0/all/0/1\">Zi-Qiang Lang</a>",
          "description": "An Orthogonal Least Squares (OLS) based feature selection method is proposed\nfor both binomial and multinomial classification. The novel Squared Orthogonal\nCorrelation Coefficient (SOCC) is defined based on Error Reduction Ratio (ERR)\nin OLS and used as the feature ranking criterion. The equivalence between the\ncanonical correlation coefficient, Fisher's criterion, and the sum of the SOCCs\nis revealed, which unveils the statistical implication of ERR in OLS for the\nfirst time. It is also shown that the OLS based feature selection method has\nspeed advantages when applied for greedy search. The proposed method is\ncomprehensively compared with the mutual information based feature selection\nmethods in 2 synthetic and 7 real world datasets. The results show that the\nproposed method is always in the top 5 among the 10 candidate methods. Besides,\nthe proposed method can be directly applied to continuous features without\ndiscretisation, which is another significant advantage over mutual information\nbased methods.",
          "link": "http://arxiv.org/abs/2101.08539",
          "publishedOn": "2021-06-10T01:56:47.944Z",
          "wordCount": 608,
          "title": "Orthogonal Least Squares Based Fast Feature Selection for Linear Classification. (arXiv:2101.08539v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04844",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_F/0/1/0/all/0/1\">Feng Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_Q/0/1/0/all/0/1\">Quyu Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yixuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_C/0/1/0/all/0/1\">Cheng Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jun Zhu</a>",
          "description": "Hawkes processes are a class of point processes that have the ability to\nmodel the self- and mutual-exciting phenomena. Although the classic Hawkes\nprocesses cover a wide range of applications, their expressive ability is\nlimited due to three key hypotheses: parametric, linear and homogeneous. Recent\nwork has attempted to address these limitations separately. This work aims to\novercome all three assumptions simultaneously by proposing the flexible\nstate-switching Hawkes processes: a flexible, nonlinear and nonhomogeneous\nvariant where a state process is incorporated to interact with the point\nprocesses. The proposed model empowers Hawkes processes to be applied to\ntime-varying systems. For inference, we utilize the latent variable\naugmentation technique to design two efficient Bayesian inference algorithms:\nGibbs sampler and mean-field variational inference, with analytical iterative\nupdates to estimate the posterior. In experiments, our model achieves superior\nperformance compared to the state-of-the-art competitors.",
          "link": "http://arxiv.org/abs/2106.04844",
          "publishedOn": "2021-06-10T01:56:47.938Z",
          "wordCount": 568,
          "title": "Nonlinear Hawkes Processes in Time-Varying System. (arXiv:2106.04844v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2011.09996",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moreu_J/0/1/0/all/0/1\">Jos&#xe9; M. Moreu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Annaswamy_A/0/1/0/all/0/1\">Anuradha M. Annaswamy</a>",
          "description": "Iterative gradient-based algorithms have been increasingly applied for the\ntraining of a broad variety of machine learning models including large\nneural-nets. In particular, momentum-based methods, with accelerated learning\nguarantees, have received a lot of attention due to their provable guarantees\nof fast learning in certain classes of problems and multiple algorithms have\nbeen derived. However, properties for these methods hold only for constant\nregressors. When time-varying regressors occur, which is commonplace in dynamic\nsystems, many of these momentum-based methods cannot guarantee stability.\nRecently, a new High-order Tuner (HT) was developed for linear regression\nproblems and shown to have 1) stability and asymptotic convergence for\ntime-varying regressors and 2) non-asymptotic accelerated learning guarantees\nfor constant regressors. In this paper, we extend and discuss the results of\nthis same HT for general convex loss functions. Through the exploitation of\nconvexity and smoothness definitions, we establish similar stability and\nasymptotic convergence guarantees. Finally, we provide numerical simulations\nsupporting the satisfactory behavior of the HT algorithm as well as an\naccelerated learning property.",
          "link": "http://arxiv.org/abs/2011.09996",
          "publishedOn": "2021-06-10T01:56:47.930Z",
          "wordCount": 653,
          "title": "A Stable High-order Tuner for General Convex Functions. (arXiv:2011.09996v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04966",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+McCay_K/0/1/0/all/0/1\">Kevin D. McCay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ho_E/0/1/0/all/0/1\">Edmond S. L. Ho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sakkos_D/0/1/0/all/0/1\">Dimitrios Sakkos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woo_W/0/1/0/all/0/1\">Wai Lok Woo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marcroft_C/0/1/0/all/0/1\">Claire Marcroft</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dulson_P/0/1/0/all/0/1\">Patricia Dulson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Embleton_N/0/1/0/all/0/1\">Nicholas D. Embleton</a>",
          "description": "Providing early diagnosis of cerebral palsy (CP) is key to enhancing the\ndevelopmental outcomes for those affected. Diagnostic tools such as the General\nMovements Assessment (GMA), have produced promising results in early diagnosis,\nhowever these manual methods can be laborious.\n\nIn this paper, we propose a new framework for the automated classification of\ninfant body movements, based upon the GMA, which unlike previous methods, also\nincorporates a visualization framework to aid with interpretability. Our\nproposed framework segments extracted features to detect the presence of\nFidgety Movements (FMs) associated with the GMA spatiotemporally. These\nfeatures are then used to identify the body-parts with the greatest\ncontribution towards a classification decision and highlight the related\nbody-part segment providing visual feedback to the user.\n\nWe quantitatively compare the proposed framework's classification performance\nwith several other methods from the literature and qualitatively evaluate the\nvisualization's veracity. Our experimental results show that the proposed\nmethod performs more robustly than comparable techniques in this setting whilst\nsimultaneously providing relevant visual interpretability.",
          "link": "http://arxiv.org/abs/2106.04966",
          "publishedOn": "2021-06-10T01:56:47.924Z",
          "wordCount": 645,
          "title": "Towards Explainable Abnormal Infant Movements Identification: A Body-part Based Prediction and Visualisation Framework. (arXiv:2106.04966v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04627",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Grcic_M/0/1/0/all/0/1\">Matej Grci&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grubisic_I/0/1/0/all/0/1\">Ivan Grubi&#x161;i&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Segvic_S/0/1/0/all/0/1\">Sini&#x161;a &#x160;egvi&#x107;</a>",
          "description": "Normalizing flows are bijective mappings between inputs and latent\nrepresentations with a fully factorized distribution. They are very attractive\ndue to exact likelihood evaluation and efficient sampling. However, their\neffective capacity is often insufficient since the bijectivity constraint\nlimits the model width. We address this issue by incrementally padding\nintermediate representations with noise. We precondition the noise in\naccordance with previous invertible units, which we describe as cross-unit\ncoupling. Our invertible glow-like modules express intra-unit affine coupling\nas a fusion of a densely connected block and Nystr\\\"om self-attention. We refer\nto our architecture as DenseFlow since both cross-unit and intra-unit couplings\nrely on dense connectivity. Experiments show significant improvements due to\nthe proposed contributions, and reveal state-of-the-art density estimation\namong all generative models under moderate computing budgets.",
          "link": "http://arxiv.org/abs/2106.04627",
          "publishedOn": "2021-06-10T01:56:47.907Z",
          "wordCount": 551,
          "title": "Densely connected normalizing flows. (arXiv:2106.04627v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.01623",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhiyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cutkosky_A/0/1/0/all/0/1\">Ashok Cutkosky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paschalidis_I/0/1/0/all/0/1\">Ioannis Ch. Paschalidis</a>",
          "description": "We consider tracking adversarial targets in a delayed time-varying linear\nsystem with adversarial disturbances and loss functions, which significantly\ngeneralizes earlier work. To this end, we develop three techniques that each\ncould be of independent interest. First, we propose a black-box reduction from\nadversarial tracking control to strongly adaptive online learning with memory.\nAny solution to the latter translates to a tracking controller that pursues the\nbest action on any time interval. Second, for the resulting online learning\nproblem we develop a novel approach that further adapts to the observed\ngradients. Third, we propose a new algorithm for unconstrained online linear\noptimization: for all (unknown) $T\\in\\mathbb{N}_+$, the cumulative loss and\nmovement on the time horizon $[1:T]$ is upper-bounded by a user-specified\nconstant. Combining these individual techniques, we propose a tracking\ncontroller with a sensible performance guarantee even when the adversarial\ntarget has a large range of movement.",
          "link": "http://arxiv.org/abs/2102.01623",
          "publishedOn": "2021-06-10T01:56:47.902Z",
          "wordCount": 609,
          "title": "Adversarial Tracking Control via Strongly Adaptive Online Learning with Memory. (arXiv:2102.01623v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.03509",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ramasinghe_S/0/1/0/all/0/1\">Sameera Ramasinghe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fernando_K/0/1/0/all/0/1\">Kasun Fernando</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1\">Salman Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barnes_N/0/1/0/all/0/1\">Nick Barnes</a>",
          "description": "Modeling real-world distributions can often be challenging due to sample data\nthat are subjected to perturbations, e.g., instrumentation errors, or added\nrandom noise. Since flow models are typically nonlinear algorithms, they\namplify these initial errors, leading to poor generalizations. This paper\nproposes a framework to construct Normalizing Flows (NF), which demonstrates\nhigher robustness against such initial errors. To this end, we utilize\nBernstein-type polynomials inspired by the optimal stability of the Bernstein\nbasis. Further, compared to the existing NF frameworks, our method provides\ncompelling advantages like theoretical upper bounds for the approximation\nerror, higher interpretability, suitability for compactly supported densities,\nand the ability to employ higher degree polynomials without training\ninstability. We conduct a thorough theoretical analysis and empirically\ndemonstrate the efficacy of the proposed technique using experiments on both\nreal-world and synthetic datasets.",
          "link": "http://arxiv.org/abs/2102.03509",
          "publishedOn": "2021-06-10T01:56:47.896Z",
          "wordCount": 588,
          "title": "Robust normalizing flows using Bernstein-type polynomials. (arXiv:2102.03509v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04895",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1\">Tengyang Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_N/0/1/0/all/0/1\">Nan Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Huan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1\">Caiming Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1\">Yu Bai</a>",
          "description": "Recent theoretical work studies sample-efficient reinforcement learning (RL)\nextensively in two settings: learning interactively in the environment (online\nRL), or learning from an offline dataset (offline RL). However, existing\nalgorithms and theories for learning near-optimal policies in these two\nsettings are rather different and disconnected. Towards bridging this gap, this\npaper initiates the theoretical study of policy finetuning, that is, online RL\nwhere the learner has additional access to a \"reference policy\" $\\mu$ close to\nthe optimal policy $\\pi_\\star$ in a certain sense. We consider the policy\nfinetuning problem in episodic Markov Decision Processes (MDPs) with $S$\nstates, $A$ actions, and horizon length $H$. We first design a sharp offline\nreduction algorithm -- which simply executes $\\mu$ and runs offline policy\noptimization on the collected dataset -- that finds an $\\varepsilon$\nnear-optimal policy within $\\widetilde{O}(H^3SC^\\star/\\varepsilon^2)$ episodes,\nwhere $C^\\star$ is the single-policy concentrability coefficient between $\\mu$\nand $\\pi_\\star$. This offline result is the first that matches the sample\ncomplexity lower bound in this setting, and resolves a recent open question in\noffline RL. We then establish an $\\Omega(H^3S\\min\\{C^\\star, A\\}/\\varepsilon^2)$\nsample complexity lower bound for any policy finetuning algorithm, including\nthose that can adaptively explore the environment. This implies that -- perhaps\nsurprisingly -- the optimal policy finetuning algorithm is either offline\nreduction or a purely online RL algorithm that does not use $\\mu$. Finally, we\ndesign a new hybrid offline/online algorithm for policy finetuning that\nachieves better sample complexity than both vanilla offline reduction and\npurely online RL algorithms, in a relaxed setting where $\\mu$ only satisfies\nconcentrability partially up to a certain time step.",
          "link": "http://arxiv.org/abs/2106.04895",
          "publishedOn": "2021-06-10T01:56:47.890Z",
          "wordCount": 698,
          "title": "Policy Finetuning: Bridging Sample-Efficient Offline and Online Reinforcement Learning. (arXiv:2106.04895v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04799",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schwarzer_M/0/1/0/all/0/1\">Max Schwarzer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajkumar_N/0/1/0/all/0/1\">Nitarshan Rajkumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noukhovitch_M/0/1/0/all/0/1\">Michael Noukhovitch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anand_A/0/1/0/all/0/1\">Ankesh Anand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Charlin_L/0/1/0/all/0/1\">Laurent Charlin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hjelm_D/0/1/0/all/0/1\">Devon Hjelm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bachman_P/0/1/0/all/0/1\">Philip Bachman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Courville_A/0/1/0/all/0/1\">Aaron Courville</a>",
          "description": "Data efficiency is a key challenge for deep reinforcement learning. We\naddress this problem by using unlabeled data to pretrain an encoder which is\nthen finetuned on a small amount of task-specific data. To encourage learning\nrepresentations which capture diverse aspects of the underlying MDP, we employ\na combination of latent dynamics modelling and unsupervised goal-conditioned\nRL. When limited to 100k steps of interaction on Atari games (equivalent to two\nhours of human experience), our approach significantly surpasses prior work\ncombining offline representation pretraining with task-specific finetuning, and\ncompares favourably with other pretraining methods that require orders of\nmagnitude more data. Our approach shows particular promise when combined with\nlarger models as well as more diverse, task-aligned observational data --\napproaching human-level performance and data-efficiency on Atari in our best\nsetting. We provide code associated with this work at\nhttps://github.com/mila-iqia/SGI.",
          "link": "http://arxiv.org/abs/2106.04799",
          "publishedOn": "2021-06-10T01:56:47.884Z",
          "wordCount": 570,
          "title": "Pretraining Representations for Data-Efficient Reinforcement Learning. (arXiv:2106.04799v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04631",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zafar_M/0/1/0/all/0/1\">Muhammad Bilal Zafar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Donini_M/0/1/0/all/0/1\">Michele Donini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Slack_D/0/1/0/all/0/1\">Dylan Slack</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Archambeau_C/0/1/0/all/0/1\">C&#xe9;dric Archambeau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1\">Sanjiv Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kenthapadi_K/0/1/0/all/0/1\">Krishnaram Kenthapadi</a>",
          "description": "With the ever-increasing complexity of neural language models, practitioners\nhave turned to methods for understanding the predictions of these models. One\nof the most well-adopted approaches for model interpretability is feature-based\ninterpretability, i.e., ranking the features in terms of their impact on model\npredictions. Several prior studies have focused on assessing the fidelity of\nfeature-based interpretability methods, i.e., measuring the impact of dropping\nthe top-ranked features on the model output. However, relatively little work\nhas been conducted on quantifying the robustness of interpretations. In this\nwork, we assess the robustness of interpretations of neural text classifiers,\nspecifically, those based on pretrained Transformer encoders, using two\nrandomization tests. The first compares the interpretations of two models that\nare identical except for their initializations. The second measures whether the\ninterpretations differ between a model with trained parameters and a model with\nrandom parameters. Both tests show surprising deviations from expected\nbehavior, raising questions about the extent of insights that practitioners may\ndraw from interpretations.",
          "link": "http://arxiv.org/abs/2106.04631",
          "publishedOn": "2021-06-10T01:56:47.868Z",
          "wordCount": 608,
          "title": "On the Lack of Robust Interpretability of Neural Text Classifiers. (arXiv:2106.04631v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04928",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jianing Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1\">Jiangchao Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1\">Bo Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jingfeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tongliang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1\">Gang Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jingren Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jianliang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hongxia Yang</a>",
          "description": "In ordinary distillation, student networks are trained with soft labels (SLs)\ngiven by pretrained teacher networks, and students are expected to improve upon\nteachers since SLs are stronger supervision than the original hard labels.\nHowever, when considering adversarial robustness, teachers may become\nunreliable and adversarial distillation may not work: teachers are pretrained\non their own adversarial data, and it is too demanding to require that teachers\nare also good at every adversarial data queried by students. Therefore, in this\npaper, we propose reliable introspective adversarial distillation (IAD) where\nstudents partially instead of fully trust their teachers. Specifically, IAD\ndistinguishes between three cases given a query of a natural data (ND) and the\ncorresponding adversarial data (AD): (a) if a teacher is good at AD, its SL is\nfully trusted; (b) if a teacher is good at ND but not AD, its SL is partially\ntrusted and the student also takes its own SL into account; (c) otherwise, the\nstudent only relies on its own SL. Experiments demonstrate the effectiveness of\nIAD for improving upon teachers in terms of adversarial robustness.",
          "link": "http://arxiv.org/abs/2106.04928",
          "publishedOn": "2021-06-10T01:56:47.861Z",
          "wordCount": 610,
          "title": "Reliable Adversarial Distillation with Unreliable Teachers. (arXiv:2106.04928v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00120",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chang_D/0/1/0/all/0/1\">Daniel T. Chang</a>",
          "description": "Probabilistic deep learning is deep learning that accounts for uncertainty,\nboth model uncertainty and data uncertainty. It is based on the use of\nprobabilistic models and deep neural networks. We distinguish two approaches to\nprobabilistic deep learning: probabilistic neural networks and deep\nprobabilistic models. The former employs deep neural networks that utilize\nprobabilistic layers which can represent and process uncertainty; the latter\nuses probabilistic models that incorporate deep neural network components which\ncapture complex non-linear stochastic relationships between the random\nvariables. We discuss some major examples of each approach including Bayesian\nneural networks and mixture density networks (for probabilistic neural\nnetworks), and variational autoencoders, deep Gaussian processes and deep mixed\neffects models (for deep probabilistic models). TensorFlow Probability is a\nlibrary for probabilistic modeling and inference which can be used for both\napproaches of probabilistic deep learning. We include its code examples for\nillustration.",
          "link": "http://arxiv.org/abs/2106.00120",
          "publishedOn": "2021-06-10T01:56:47.856Z",
          "wordCount": 608,
          "title": "Probabilistic Deep Learning with Probabilistic Neural Networks and Deep Probabilistic Models. (arXiv:2106.00120v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04880",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Junsu Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahn_S/0/1/0/all/0/1\">Sungsoo Ahn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hankook Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1\">Jinwoo Shin</a>",
          "description": "Retrosynthetic planning is a fundamental problem in chemistry for finding a\npathway of reactions to synthesize a target molecule. Recently, search\nalgorithms have shown promising results for solving this problem by using deep\nneural networks (DNNs) to expand their candidate solutions, i.e., adding new\nreactions to reaction pathways. However, the existing works on this line are\nsuboptimal; the retrosynthetic planning problem requires the reaction pathways\nto be (a) represented by real-world reactions and (b) executable using\n\"building block\" molecules, yet the DNNs expand reaction pathways without fully\nincorporating such requirements. Motivated by this, we propose an end-to-end\nframework for directly training the DNNs towards generating reaction pathways\nwith the desirable properties. Our main idea is based on a self-improving\nprocedure that trains the model to imitate successful trajectories found by\nitself. We also propose a novel reaction augmentation scheme based on a forward\nreaction model. Our experiments demonstrate that our scheme significantly\nimproves the success rate of solving the retrosynthetic problem from 86.84% to\n96.32% while maintaining the performance of DNN for predicting valid reactions.",
          "link": "http://arxiv.org/abs/2106.04880",
          "publishedOn": "2021-06-10T01:56:47.850Z",
          "wordCount": 599,
          "title": "Self-Improved Retrosynthetic Planning. (arXiv:2106.04880v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04920",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maschler_B/0/1/0/all/0/1\">Benjamin Maschler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Knodel_T/0/1/0/all/0/1\">Tim Knodel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weyrich_M/0/1/0/all/0/1\">Michael Weyrich</a>",
          "description": "Deep learning promises performant anomaly detection on time-variant datasets,\nbut greatly suffers from low availability of suitable training datasets and\nfrequently changing tasks. Deep transfer learning offers mitigation by letting\nalgorithms built upon previous knowledge from different tasks or locations. In\nthis article, a modular deep learning algorithm for anomaly detection on time\nseries datasets is presented that allows for an easy integration of such\ntransfer learning capabilities. It is thoroughly tested on a dataset from a\ndiscrete manufacturing process in order to prove its fundamental adequacy\ntowards deep industrial transfer learning - the transfer of knowledge in\nindustrial applications' special environment.",
          "link": "http://arxiv.org/abs/2106.04920",
          "publishedOn": "2021-06-10T01:56:47.836Z",
          "wordCount": 549,
          "title": "Towards Deep Industrial Transfer Learning for Anomaly Detection on Time Series Data. (arXiv:2106.04920v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04900",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lino_M/0/1/0/all/0/1\">Mario Lino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cantwell_C/0/1/0/all/0/1\">Chris Cantwell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bharath_A/0/1/0/all/0/1\">Anil A. Bharath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fotiadis_S/0/1/0/all/0/1\">Stathi Fotiadis</a>",
          "description": "Continuum mechanics simulators, numerically solving one or more partial\ndifferential equations, are essential tools in many areas of science and\nengineering, but their performance often limits application in practice. Recent\nmodern machine learning approaches have demonstrated their ability to\naccelerate spatio-temporal predictions, although, with only moderate accuracy\nin comparison. Here we introduce MultiScaleGNN, a novel multi-scale graph\nneural network model for learning to infer unsteady continuum mechanics.\nMultiScaleGNN represents the physical domain as an unstructured set of nodes,\nand it constructs one or more graphs, each of them encoding different scales of\nspatial resolution. Successive learnt message passing between these graphs\nimproves the ability of GNNs to capture and forecast the system state in\nproblems encompassing a range of length scales. Using graph representations,\nMultiScaleGNN can impose periodic boundary conditions as an inductive bias on\nthe edges in the graphs, and achieve independence to the nodes' positions. We\ndemonstrate this method on advection problems and incompressible fluid\ndynamics. Our results show that the proposed model can generalise from uniform\nadvection fields to high-gradient fields on complex domains at test time and\ninfer long-term Navier-Stokes solutions within a range of Reynolds numbers.\nSimulations obtained with MultiScaleGNN are between two and four orders of\nmagnitude faster than the ones on which it was trained.",
          "link": "http://arxiv.org/abs/2106.04900",
          "publishedOn": "2021-06-10T01:56:47.826Z",
          "wordCount": 641,
          "title": "Simulating Continuum Mechanics with Multi-Scale Graph Neural Networks. (arXiv:2106.04900v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04953",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Reichelt_T/0/1/0/all/0/1\">Tim Reichelt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Golinski_A/0/1/0/all/0/1\">Adam Goli&#x144;ski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ong_L/0/1/0/all/0/1\">Luke Ong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rainforth_T/0/1/0/all/0/1\">Tom Rainforth</a>",
          "description": "Building on ideas from probabilistic programming, we introduce the concept of\nan expectation programming framework (EPF) that automates the calculation of\nexpectations. Analogous to a probabilistic program, an expectation program is\ncomprised of a mix of probabilistic constructs and deterministic calculations\nthat define a conditional distribution over its variables. However, the focus\nof the inference engine in an EPF is to directly estimate the resulting\nexpectation of the program return values, rather than approximate the\nconditional distribution itself. This distinction allows us to achieve\nsubstantial performance improvements over the standard probabilistic\nprogramming pipeline by tailoring the inference to the precise expectation we\ncare about. We realize a particular instantiation of our EPF concept by\nextending the probabilistic programming language Turing to allow so-called\ntarget-aware inference to be run automatically, and show that this leads to\nsignificant empirical gains compared to conventional posterior-based inference.",
          "link": "http://arxiv.org/abs/2106.04953",
          "publishedOn": "2021-06-10T01:56:47.795Z",
          "wordCount": 558,
          "title": "Expectation Programming. (arXiv:2106.04953v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04732",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Berthelot_D/0/1/0/all/0/1\">David Berthelot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roelofs_R/0/1/0/all/0/1\">Rebecca Roelofs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sohn_K/0/1/0/all/0/1\">Kihyuk Sohn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carlini_N/0/1/0/all/0/1\">Nicholas Carlini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurakin_A/0/1/0/all/0/1\">Alex Kurakin</a>",
          "description": "We extend semi-supervised learning to the problem of domain adaptation to\nlearn significantly higher-accuracy models that train on one data distribution\nand test on a different one. With the goal of generality, we introduce\nAdaMatch, a method that unifies the tasks of unsupervised domain adaptation\n(UDA), semi-supervised learning (SSL), and semi-supervised domain adaptation\n(SSDA). In an extensive experimental study, we compare its behavior with\nrespective state-of-the-art techniques from SSL, SSDA, and UDA on vision\nclassification tasks. We find AdaMatch either matches or significantly exceeds\nthe state-of-the-art in each case using the same hyper-parameters regardless of\nthe dataset or task. For example, AdaMatch nearly doubles the accuracy compared\nto that of the prior state-of-the-art on the UDA task for DomainNet and even\nexceeds the accuracy of the prior state-of-the-art obtained with pre-training\nby 6.4% when AdaMatch is trained completely from scratch. Furthermore, by\nproviding AdaMatch with just one labeled example per class from the target\ndomain (i.e., the SSDA setting), we increase the target accuracy by an\nadditional 6.1%, and with 5 labeled examples, by 13.6%.",
          "link": "http://arxiv.org/abs/2106.04732",
          "publishedOn": "2021-06-10T01:56:47.788Z",
          "wordCount": 616,
          "title": "AdaMatch: A Unified Approach to Semi-Supervised Learning and Domain Adaptation. (arXiv:2106.04732v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04913",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bressan_M/0/1/0/all/0/1\">Marco Bressan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cesa_Bianchi_N/0/1/0/all/0/1\">Nicol&#xf2; Cesa-Bianchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lattanzi_S/0/1/0/all/0/1\">Silvio Lattanzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paudice_A/0/1/0/all/0/1\">Andrea Paudice</a>",
          "description": "We study an active cluster recovery problem where, given a set of $n$ points\nand an oracle answering queries like \"are these two points in the same\ncluster?\", the task is to recover exactly all clusters using as few queries as\npossible. We begin by introducing a simple but general notion of margin between\nclusters that captures, as special cases, the margins used in previous work,\nthe classic SVM margin, and standard notions of stability for center-based\nclusterings. Then, under our margin assumptions we design algorithms that, in a\nvariety of settings, recover all clusters exactly using only $O(\\log n)$\nqueries. For the Euclidean case, $\\mathbb{R}^m$, we give an algorithm that\nrecovers arbitrary convex clusters, in polynomial time, and with a number of\nqueries that is lower than the best existing algorithm by $\\Theta(m^m)$\nfactors. For general pseudometric spaces, where clusters might not be convex or\nmight not have any notion of shape, we give an algorithm that achieves the\n$O(\\log n)$ query bound, and is provably near-optimal as a function of the\npacking number of the space. Finally, for clusterings realized by binary\nconcept classes, we give a combinatorial characterization of recoverability\nwith $O(\\log n)$ queries, and we show that, for many concept classes in\nEuclidean spaces, this characterization is equivalent to our margin condition.\nOur results show a deep connection between cluster margins and active cluster\nrecoverability.",
          "link": "http://arxiv.org/abs/2106.04913",
          "publishedOn": "2021-06-10T01:56:47.781Z",
          "wordCount": 657,
          "title": "On Margin-Based Cluster Recovery with Oracle Queries. (arXiv:2106.04913v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05135",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yi_X/0/1/0/all/0/1\">Xinlei Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiuxian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1\">Tao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_L/0/1/0/all/0/1\">Lihua Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chai_T/0/1/0/all/0/1\">Tianyou Chai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johansson_K/0/1/0/all/0/1\">Karl H. Johansson</a>",
          "description": "This paper considers online convex optimization with long term constraints,\nwhere constraints can be violated in intermediate rounds, but need to be\nsatisfied in the long run. The cumulative constraint violation is used as the\nmetric to measure constraint violations, which excludes the situation that\nstrictly feasible constraints can compensate the effects of violated\nconstraints. A novel algorithm is first proposed and it achieves an\n$\\mathcal{O}(T^{\\max\\{c,1-c\\}})$ bound for static regret and an\n$\\mathcal{O}(T^{(1-c)/2})$ bound for cumulative constraint violation, where\n$c\\in(0,1)$ is a user-defined trade-off parameter, and thus has improved\nperformance compared with existing results. Both static regret and cumulative\nconstraint violation bounds are reduced to $\\mathcal{O}(\\log(T))$ when the loss\nfunctions are strongly convex, which also improves existing results. %In order\nto bound the regret with respect to any comparator sequence, In order to\nachieve the optimal regret with respect to any comparator sequence, another\nalgorithm is then proposed and it achieves the optimal\n$\\mathcal{O}(\\sqrt{T(1+P_T)})$ regret and an $\\mathcal{O}(\\sqrt{T})$ cumulative\nconstraint violation, where $P_T$ is the path-length of the comparator\nsequence. Finally, numerical simulations are provided to illustrate the\neffectiveness of the theoretical results.",
          "link": "http://arxiv.org/abs/2106.05135",
          "publishedOn": "2021-06-10T01:56:47.764Z",
          "wordCount": 631,
          "title": "Regret and Cumulative Constraint Violation Analysis for Online Convex Optimization with Long Term Constraints. (arXiv:2106.05135v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04641",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pogrebnyakov_N/0/1/0/all/0/1\">Nicolai Pogrebnyakov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shaghaghian_S/0/1/0/all/0/1\">Shohreh Shaghaghian</a>",
          "description": "Transfer learning methods, and in particular domain adaptation, help exploit\nlabeled data in one domain to improve the performance of a certain task in\nanother domain. However, it is still not clear what factors affect the success\nof domain adaptation. This paper models adaptation success and selection of the\nmost suitable source domains among several candidates in text similarity. We\nuse descriptive domain information and cross-domain similarity metrics as\npredictive features. While mostly positive, the results also point to some\ndomains where adaptation success was difficult to predict.",
          "link": "http://arxiv.org/abs/2106.04641",
          "publishedOn": "2021-06-10T01:56:47.731Z",
          "wordCount": 520,
          "title": "Predicting the Success of Domain Adaptation in Text Similarity. (arXiv:2106.04641v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04804",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_Q/0/1/0/all/0/1\">Qi Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1\">Sujit K. Ghosh</a>",
          "description": "High dimensional incomplete data can be found in a wide range of systems. Due\nto the fact that most of the data mining techniques and machine learning\nalgorithms require complete observations, data imputation is vital for\ndown-stream analysis. In this work, we introduce an imputation approach, called\nEMFlow, that performs imputation in an latent space via an online version of\nExpectation-Maximization (EM) algorithm and connects the latent space and the\ndata space via the normalizing flow (NF). The inference of EMFlow is iterative,\ninvolving updating the parameters of online EM and NF alternatively. Extensive\nexperimental results on multivariate and image datasets show that the proposed\nEMFlow has superior performance to competing methods in terms of both\nimputation quality and convergence speed.",
          "link": "http://arxiv.org/abs/2106.04804",
          "publishedOn": "2021-06-10T01:56:47.714Z",
          "wordCount": 549,
          "title": "EMFlow: Data Imputation in Latent Space via EM and Deep Flow Models. (arXiv:2106.04804v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04941",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lopez_F/0/1/0/all/0/1\">Federico L&#xf3;pez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pozzetti_B/0/1/0/all/0/1\">Beatrice Pozzetti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trettel_S/0/1/0/all/0/1\">Steve Trettel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Strube_M/0/1/0/all/0/1\">Michael Strube</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wienhard_A/0/1/0/all/0/1\">Anna Wienhard</a>",
          "description": "Learning faithful graph representations as sets of vertex embeddings has\nbecome a fundamental intermediary step in a wide range of machine learning\napplications. We propose the systematic use of symmetric spaces in\nrepresentation learning, a class encompassing many of the previously used\nembedding targets. This enables us to introduce a new method, the use of\nFinsler metrics integrated in a Riemannian optimization scheme, that better\nadapts to dissimilar structures in the graph. We develop a tool to analyze the\nembeddings and infer structural properties of the data sets. For\nimplementation, we choose Siegel spaces, a versatile family of symmetric\nspaces. Our approach outperforms competitive baselines for graph reconstruction\ntasks on various synthetic and real-world datasets. We further demonstrate its\napplicability on two downstream tasks, recommender systems and node\nclassification.",
          "link": "http://arxiv.org/abs/2106.04941",
          "publishedOn": "2021-06-10T01:56:47.676Z",
          "wordCount": 568,
          "title": "Symmetric Spaces for Graph Embeddings: A Finsler-Riemannian Approach. (arXiv:2106.04941v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04812",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tayal_K/0/1/0/all/0/1\">Kshitij Tayal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manekar_R/0/1/0/all/0/1\">Raunak Manekar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_Z/0/1/0/all/0/1\">Zhong Zhuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">David Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1\">Vipin Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hofmann_F/0/1/0/all/0/1\">Felix Hofmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Ju Sun</a>",
          "description": "Several deep learning methods for phase retrieval exist, but most of them\nfail on realistic data without precise support information. We propose a novel\nmethod based on single-instance deep generative prior that works well on\ncomplex-valued crystal data.",
          "link": "http://arxiv.org/abs/2106.04812",
          "publishedOn": "2021-06-10T01:56:47.670Z",
          "wordCount": 472,
          "title": "Phase Retrieval using Single-Instance Deep Generative Prior. (arXiv:2106.04812v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05080",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ferber_A/0/1/0/all/0/1\">Aaron Ferber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1\">Jialin Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dilkina_B/0/1/0/all/0/1\">Bistra Dilkina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yue_Y/0/1/0/all/0/1\">Yisong Yue</a>",
          "description": "We propose a machine learning approach for quickly solving Mixed Integer\nPrograms (MIP) by learning to prioritize a set of decision variables, which we\ncall pseudo-backdoors, for branching that results in faster solution times.\nLearning-based approaches have seen success in the area of solving\ncombinatorial optimization problems by being able to flexibly leverage common\nstructures in a given distribution of problems. Our approach takes inspiration\nfrom the concept of strong backdoors, which corresponds to a small set of\nvariables such that only branching on these variables yields an optimal\nintegral solution and a proof of optimality. Our notion of pseudo-backdoors\ncorresponds to a small set of variables such that only branching on them leads\nto faster solve time (which can be solver dependent). A key advantage of\npseudo-backdoors over strong backdoors is that they are much amenable to\ndata-driven identification or prediction. Our proposed method learns to\nestimate the solver performance of a proposed pseudo-backdoor, using a labeled\ndataset collected on a set of training MIP instances. This model can then be\nused to identify high-quality pseudo-backdoors on new MIP instances from the\nsame distribution. We evaluate our method on the generalized independent set\nproblems and find that our approach can efficiently identify high-quality\npseudo-backdoors. In addition, we compare our learned approach against Gurobi,\na state-of-the-art MIP solver, demonstrating that our method can be used to\nimprove solver performance.",
          "link": "http://arxiv.org/abs/2106.05080",
          "publishedOn": "2021-06-10T01:56:47.665Z",
          "wordCount": 665,
          "title": "Learning Pseudo-Backdoors for Mixed Integer Programs. (arXiv:2106.05080v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04716",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dai_E/0/1/0/all/0/1\">Enyan Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shu_K/0/1/0/all/0/1\">Kai Shu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yiwei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Suhang Wang</a>",
          "description": "The recent advanced deep learning techniques have shown the promising results\nin various domains such as computer vision and natural language processing. The\nsuccess of deep neural networks in supervised learning heavily relies on a\nlarge amount of labeled data. However, obtaining labeled data with target\nlabels is often challenging due to various reasons such as cost of labeling and\nprivacy issues, which challenges existing deep models. In spite of that, it is\nrelatively easy to obtain data with \\textit{inexact supervision}, i.e., having\nlabels/tags related to the target task. For example, social media platforms are\noverwhelmed with billions of posts and images with self-customized tags, which\nare not the exact labels for target classification tasks but are usually\nrelated to the target labels. It is promising to leverage these tags (inexact\nsupervision) and their relations with target classes to generate labeled data\nto facilitate the downstream classification tasks. However, the work on this is\nrather limited. Therefore, we study a novel problem of labeled data generation\nwith inexact supervision. We propose a novel generative framework named as\nADDES which can synthesize high-quality labeled data for target classification\ntasks by learning from data with inexact supervision and the relations between\ninexact supervision and target classes. Experimental results on image and text\ndatasets demonstrate the effectiveness of the proposed ADDES for generating\nrealistic labeled data from inexact supervision to facilitate the target\nclassification task.",
          "link": "http://arxiv.org/abs/2106.04716",
          "publishedOn": "2021-06-10T01:56:47.628Z",
          "wordCount": 652,
          "title": "Labeled Data Generation with Inexact Supervision. (arXiv:2106.04716v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.05509",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cygert_S/0/1/0/all/0/1\">Sebastian Cygert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Czyzewski_A/0/1/0/all/0/1\">Andrzej Czy&#x17c;ewski</a>",
          "description": "Model compression techniques allow to significantly reduce the computational\ncost associated with data processing by deep neural networks with only a minor\ndecrease in average accuracy. Simultaneously, reducing the model size may have\na large effect on noisy cases or objects belonging to less frequent classes. It\nis a crucial problem from the perspective of the models' safety, especially for\nobject detection in the autonomous driving setting, which is considered in this\nwork. It was shown in the paper that the sensitivity of compressed models to\ndifferent distortion types is nuanced, and some of the corruptions are heavily\nimpacted by the compression methods (i.e., additive noise), while others (blur\neffect) are only slightly affected. A common way to improve the robustness of\nmodels is to use data augmentation, which was confirmed to positively affect\nmodels' robustness, also for highly compressed models. It was further shown\nthat while data imbalance methods brought only a slight increase in accuracy\nfor the baseline model (without compression), the impact was more striking at\nhigher compression rates for the structured pruning. Finally, methods for\nhandling data imbalance brought a significant improvement of the pruned models'\nworst-detected class accuracy.",
          "link": "http://arxiv.org/abs/2102.05509",
          "publishedOn": "2021-06-10T01:56:47.537Z",
          "wordCount": 647,
          "title": "Robustness in Compressed Neural Networks for Object Detection. (arXiv:2102.05509v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04840",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jin Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_B/0/1/0/all/0/1\">Bin Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yaowei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yonghong Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Feng Wu</a>",
          "description": "Tracking-by-detection is a very popular framework for single object tracking\nwhich attempts to search the target object within a local search window for\neach frame. Although such local search mechanism works well on simple videos,\nhowever, it makes the trackers sensitive to extremely challenging scenarios,\nsuch as heavy occlusion and fast motion. In this paper, we propose a novel and\ngeneral target-aware attention mechanism (termed TANet) and integrate it with\ntracking-by-detection framework to conduct joint local and global search for\nrobust tracking. Specifically, we extract the features of target object patch\nand continuous video frames, then we concatenate and feed them into a decoder\nnetwork to generate target-aware global attention maps. More importantly, we\nresort to adversarial training for better attention prediction. The appearance\nand motion discriminator networks are designed to ensure its consistency in\nspatial and temporal views. In the tracking procedure, we integrate the\ntarget-aware attention with multiple trackers by exploring candidate search\nregions for robust tracking. Extensive experiments on both short-term and\nlong-term tracking benchmark datasets all validated the effectiveness of our\nalgorithm. The project page of this paper can be found at\n\\url{https://sites.google.com/view/globalattentiontracking/home/extend}.",
          "link": "http://arxiv.org/abs/2106.04840",
          "publishedOn": "2021-06-10T01:56:47.520Z",
          "wordCount": 641,
          "title": "Tracking by Joint Local and Global Search: A Target-aware Attention based Approach. (arXiv:2106.04840v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05229",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yu-Chen Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsieh_T/0/1/0/all/0/1\">Tsun-An Hsieh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hung_K/0/1/0/all/0/1\">Kuo-Hsuan Hung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1\">Cheng Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garudadri_H/0/1/0/all/0/1\">Harinath Garudadri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsao_Y/0/1/0/all/0/1\">Yu Tsao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuo_T/0/1/0/all/0/1\">Tei-Wei Kuo</a>",
          "description": "A large number of Internet of Things (IoT) devices today are powered by\nbatteries, which are often expensive to maintain and may cause serious\nenvironmental pollution. To avoid these problems, researchers have begun to\nconsider the use of energy systems based on energy-harvesting units for such\ndevices. However, the power harvested from an ambient source is fundamentally\nsmall and unstable, resulting in frequent power failures during the operation\nof IoT applications involving, for example, intermittent speech signals and the\nstreaming of videos. This paper presents a deep-learning-based speech recovery\nsystem that reconstructs intermittent speech signals from self-powered IoT\ndevices. Our intermittent speech recovery system (ISR) consists of three\nstages: interpolation, recovery, and combination. The experimental results show\nthat our recovery system increases speech quality by up to 707.1%, while\nincreasing speech intelligibility by up to 92.1%. Most importantly, our ISR\nsystem also enhances the WER scores by up to 65.6%. To the best of our\nknowledge, this study is one of the first to reconstruct intermittent speech\nsignals from self-powered-sensing IoT devices. These promising results suggest\nthat even though self powered microphone devices function with weak energy\nsources, our ISR system can still maintain the performance of most\nspeech-signal-based applications.",
          "link": "http://arxiv.org/abs/2106.05229",
          "publishedOn": "2021-06-10T01:56:47.506Z",
          "wordCount": 629,
          "title": "Intermittent Speech Recovery. (arXiv:2106.05229v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05194",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+He_Y/0/1/0/all/0/1\">Yixuan He</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Reinert_G/0/1/0/all/0/1\">Gesine Reinert</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cucuringu_M/0/1/0/all/0/1\">Mihai Cucuringu</a>",
          "description": "Node clustering is a powerful tool in the analysis of networks. Here, we\nintroduce a graph neural network framework with a novel scalable Directed Mixed\nPath Aggregation(DIMPA) scheme to obtain node embeddings for directed networks\nin a self-supervised manner, including a novel probabilistic imbalance loss.\nThe method is end-to-end in combining embedding generation and clustering\nwithout an intermediate step. In contrast to standard approaches in the\nliterature, in this paper, directionality is not treated as a nuisance, but\nrather contains the main signal. In particular, we leverage the recently\nintroduced cut flow imbalance measure, which is tightly related to\ndirectionality; cut flow imbalance is optimized without resorting to spectral\nmethods or cluster labels. Experimental results on synthetic data, in the form\nof directed stochastic block models and real-world data at different scales,\ndemonstrate that our method attains state-of-the-art results on directed\nclustering, for a wide range of noise and sparsity levels, as well as graph\nstructures.",
          "link": "http://arxiv.org/abs/2106.05194",
          "publishedOn": "2021-06-10T01:56:47.489Z",
          "wordCount": 593,
          "title": "DIGRAC: Digraph Clustering with Flow Imbalance. (arXiv:2106.05194v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05190",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Nguyen_T/0/1/0/all/0/1\">Thu Nguyen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nguyen_Duy_K/0/1/0/all/0/1\">Khoi Minh Nguyen-Duy</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nguyen_D/0/1/0/all/0/1\">Duy Ho Minh Nguyen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nguyen_B/0/1/0/all/0/1\">Binh T. Nguyen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wade_B/0/1/0/all/0/1\">Bruce Alan Wade</a>",
          "description": "The missing data problem has been broadly studied in the last few decades and\nhas various applications in different areas such as statistics or\nbioinformatics. Even though many methods have been developed to tackle this\nchallenge, most of those are imputation techniques that require multiple\niterations through the data before yielding convergence. In addition, such\napproaches may introduce extra biases and noises to the estimated parameters.\nIn this work, we propose novel algorithms to find the maximum likelihood\nestimates (MLEs) for a one-class/multiple-class randomly missing data set under\nsome mild assumptions. As the computation is direct without any imputation, our\nalgorithms do not require multiple iterations through the data, thus promising\nto be less time-consuming than other methods while maintaining superior\nestimation performance. We validate these claims by empirical results on\nvarious data sets of different sizes and release all codes in a GitHub\nrepository to contribute to the research community related to this problem.",
          "link": "http://arxiv.org/abs/2106.05190",
          "publishedOn": "2021-06-10T01:56:47.470Z",
          "wordCount": 605,
          "title": "DPER: Efficient Parameter Estimation for Randomly Missing Data. (arXiv:2106.05190v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05238",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Willetts_M/0/1/0/all/0/1\">Matthew Willetts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paige_B/0/1/0/all/0/1\">Brooks Paige</a>",
          "description": "In this work we introduce a new approach for identifiable non-linear ICA\nmodels. Recently there has been a renaissance in identifiability results in\ndeep generative models, not least for non-linear ICA. These prior works,\nhowever, have assumed access to a sufficiently-informative auxiliary set of\nobservations, denoted $\\mathbf{u}$. We show here how identifiability can be\nobtained in the absence of this side-information, rendering possible\nfully-unsupervised identifiable non-linear ICA. While previous theoretical\nresults have established the impossibility of identifiable non-linear ICA in\nthe presence of infinitely-flexible universal function approximators, here we\nrely on the intrinsically-finite modelling capacity of any particular chosen\nparameterisation of a deep generative model. In particular, we focus on\ngenerative models which perform clustering in their latent space -- a model\nstructure which matches previous identifiable models, but with the learnt\nclustering providing a synthetic form of auxiliary information. We evaluate our\nproposals using VAEs, on synthetic and image datasets, and find that the\nlearned clusterings function effectively: deep generative models with latent\nclusterings are empirically identifiable, to the same degree as models which\nrely on side information.",
          "link": "http://arxiv.org/abs/2106.05238",
          "publishedOn": "2021-06-10T01:56:47.464Z",
          "wordCount": 620,
          "title": "I Don't Need $\\mathbf{u}$: Identifiable Non-Linear ICA Without Side Information. (arXiv:2106.05238v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.09972",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Razin_N/0/1/0/all/0/1\">Noam Razin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maman_A/0/1/0/all/0/1\">Asaf Maman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_N/0/1/0/all/0/1\">Nadav Cohen</a>",
          "description": "Recent efforts to unravel the mystery of implicit regularization in deep\nlearning have led to a theoretical focus on matrix factorization -- matrix\ncompletion via linear neural network. As a step further towards practical deep\nlearning, we provide the first theoretical analysis of implicit regularization\nin tensor factorization -- tensor completion via certain type of non-linear\nneural network. We circumvent the notorious difficulty of tensor problems by\nadopting a dynamical systems perspective, and characterizing the evolution\ninduced by gradient descent. The characterization suggests a form of greedy low\ntensor rank search, which we rigorously prove under certain conditions, and\nempirically demonstrate under others. Motivated by tensor rank capturing the\nimplicit regularization of a non-linear neural network, we empirically explore\nit as a measure of complexity, and find that it captures the essence of\ndatasets on which neural networks generalize. This leads us to believe that\ntensor rank may pave way to explaining both implicit regularization in deep\nlearning, and the properties of real-world data translating this implicit\nregularization to generalization.",
          "link": "http://arxiv.org/abs/2102.09972",
          "publishedOn": "2021-06-10T01:56:47.458Z",
          "wordCount": 641,
          "title": "Implicit Regularization in Tensor Factorization. (arXiv:2102.09972v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.05170",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lin_L/0/1/0/all/0/1\">Licong Lin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dobriban_E/0/1/0/all/0/1\">Edgar Dobriban</a>",
          "description": "Modern machine learning methods are often overparametrized, allowing\nadaptation to the data at a fine level. This can seem puzzling; in the worst\ncase, such models do not need to generalize. This puzzle inspired a great\namount of work, arguing when overparametrization reduces test error, in a\nphenomenon called \"double descent\". Recent work aimed to understand in greater\ndepth why overparametrization is helpful for generalization. This leads to\ndiscovering the unimodality of variance as a function of the level of\nparametrization, and to decomposing the variance into that arising from label\nnoise, initialization, and randomness in the training data to understand the\nsources of the error.\n\nIn this work we develop a deeper understanding of this area. Specifically, we\npropose using the analysis of variance (ANOVA) to decompose the variance in the\ntest error in a symmetric way, for studying the generalization performance of\ncertain two-layer linear and non-linear networks. The advantage of the analysis\nof variance is that it reveals the effects of initialization, label noise, and\ntraining data more clearly than prior approaches. Moreover, we also study the\nmonotonicity and unimodality of the variance components. While prior work\nstudied the unimodality of the overall variance, we study the properties of\neach term in variance decomposition.\n\nOne key insight is that in typical settings, the interaction between training\nsamples and initialization can dominate the variance; surprisingly being larger\nthan their marginal effect. Also, we characterize \"phase transitions\" where the\nvariance changes from unimodal to monotone. On a technical level, we leverage\nadvanced deterministic equivalent techniques for Haar random matrices, that --\nto our knowledge -- have not yet been used in the area. We also verify our\nresults in numerical simulations and on empirical data examples.",
          "link": "http://arxiv.org/abs/2010.05170",
          "publishedOn": "2021-06-10T01:56:47.452Z",
          "wordCount": 747,
          "title": "What causes the test error? Going beyond bias-variance via ANOVA. (arXiv:2010.05170v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05065",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xutong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zuo_J/0/1/0/all/0/1\">Jinhang Zuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiaowei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lui_J/0/1/0/all/0/1\">John C.S. Lui</a>",
          "description": "Multi-layered network exploration (MuLaNE) problem is an important problem\nabstracted from many applications. In MuLaNE, there are multiple network layers\nwhere each node has an importance weight and each layer is explored by a random\nwalk. The MuLaNE task is to allocate total random walk budget $B$ into each\nnetwork layer so that the total weights of the unique nodes visited by random\nwalks are maximized. We systematically study this problem from offline\noptimization to online learning. For the offline optimization setting where the\nnetwork structure and node weights are known, we provide greedy based\nconstant-ratio approximation algorithms for overlapping networks, and greedy or\ndynamic-programming based optimal solutions for non-overlapping networks. For\nthe online learning setting, neither the network structure nor the node weights\nare known initially. We adapt the combinatorial multi-armed bandit framework\nand design algorithms to learn random walk related parameters and node weights\nwhile optimizing the budget allocation in multiple rounds, and prove that they\nachieve logarithmic regret bounds. Finally, we conduct experiments on a\nreal-world social network dataset to validate our theoretical results.",
          "link": "http://arxiv.org/abs/2106.05065",
          "publishedOn": "2021-06-10T01:56:47.446Z",
          "wordCount": 616,
          "title": "Multi-layered Network Exploration via Random Walks: From Offline Optimization to Online Learning. (arXiv:2106.05065v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2007.04833",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qitian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hengrui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1\">Xiaofeng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Junchi Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zha_H/0/1/0/all/0/1\">Hongyuan Zha</a>",
          "description": "Recommendation models can effectively estimate underlying user interests and\npredict one's future behaviors by factorizing an observed user-item rating\nmatrix into products of two sets of latent factors. However, the user-specific\nembedding factors can only be learned in a transductive way, making it\ndifficult to handle new users on-the-fly. In this paper, we propose an\ninductive collaborative filtering framework that contains two representation\nmodels. The first model follows conventional matrix factorization which\nfactorizes a group of key users' rating matrix to obtain meta latents. The\nsecond model resorts to attention-based structure learning that estimates\nhidden relations from query to key users and learns to leverage meta latents to\ninductively compute embeddings for query users via neural message passing. Our\nmodel enables inductive representation learning for users and meanwhile\nguarantees equivalent representation capacity as matrix factorization.\nExperiments demonstrate that our model achieves promising results for\nrecommendation on few-shot users with limited training ratings and new unseen\nusers which are commonly encountered in open-world recommender systems.",
          "link": "http://arxiv.org/abs/2007.04833",
          "publishedOn": "2021-06-10T01:56:47.428Z",
          "wordCount": 626,
          "title": "Towards Open-World Recommendation: An Inductive Model-based Collaborative Filtering Approach. (arXiv:2007.04833v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1910.09417",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Marvasti_A/0/1/0/all/0/1\">Amir Emad Marvasti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marvasti_E/0/1/0/all/0/1\">Ehsan Emad Marvasti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Foroosh_H/0/1/0/all/0/1\">Hassan Foroosh</a>",
          "description": "We present a theoretical framework of probabilistic learning derived by\nMaximum Probability (MP) Theorem shown in the current paper. In this\nprobabilistic framework, a model is defined as an event in the probability\nspace, and a model or the associated event - either the true underlying model\nor the parameterized model - have a quantified probability measure. This\nquantification of a model's probability measure is derived by the MP Theorem,\nin which we have shown that an event's probability measure has an upper-bound\ngiven its conditional distribution on an arbitrary random variable. Through\nthis alternative framework, the notion of model parameters is encompassed in\nthe definition of the model or the associated event. Therefore, this framework\ndeviates from the conventional approach of assuming a prior on the model\nparameters. Instead, the regularizing effects of assuming prior over parameters\nis seen through maximizing probabilities of models or according to information\ntheory, minimizing the information content of a model. The probability of a\nmodel in our framework is invariant to reparameterization and is solely\ndependent on the model's likelihood function. Also, rather than maximizing the\nposterior in a conventional Bayesian setting, the objective function in our\nalternative framework is defined as the probability of set operations (e.g.\nintersection) on the event of the true underlying model and the event of the\nmodel at hand. Our theoretical framework, as a derivation of MP theorem, adds\nclarity to probabilistic learning through solidifying the definition of\nprobabilistic models, quantifying their probabilities, and providing a visual\nunderstanding of objective functions.",
          "link": "http://arxiv.org/abs/1910.09417",
          "publishedOn": "2021-06-10T01:56:47.423Z",
          "wordCount": 736,
          "title": "Maximum Probability Theorem: A Framework for Probabilistic Learning. (arXiv:1910.09417v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.03792",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kato_M/0/1/0/all/0/1\">Masahiro Kato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yasui_S/0/1/0/all/0/1\">Shota Yasui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McAlinn_K/0/1/0/all/0/1\">Kenichiro McAlinn</a>",
          "description": "The doubly robust (DR) estimator, which consists of two nuisance parameters,\nthe conditional mean outcome and the logging policy (the probability of\nchoosing an action), is crucial in causal inference. This paper proposes a DR\nestimator for dependent samples obtained from adaptive experiments. To obtain\nan asymptotically normal semiparametric estimator from dependent samples with\nnon-Donsker nuisance estimators, we propose adaptive-fitting as a variant of\nsample-splitting. We also report an empirical paradox that our proposed DR\nestimator tends to show better performances compared to other estimators\nutilizing the true logging policy. While a similar phenomenon is known for\nestimators with i.i.d. samples, traditional explanations based on asymptotic\nefficiency cannot elucidate our case with dependent samples. We confirm this\nhypothesis through simulation studies.",
          "link": "http://arxiv.org/abs/2010.03792",
          "publishedOn": "2021-06-10T01:56:47.417Z",
          "wordCount": 617,
          "title": "The Adaptive Doubly Robust Estimator for Policy Evaluation in Adaptive Experiments and a Paradox Concerning Logging Policy. (arXiv:2010.03792v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05061",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jarboui_F/0/1/0/all/0/1\">Firas Jarboui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perchet_V/0/1/0/all/0/1\">Viannet Perchet</a>",
          "description": "We consider the quickest change detection problem where both the parameters\nof pre- and post- change distributions are unknown, which prevents the use of\nclassical simple hypothesis testing. Without additional assumptions, optimal\nsolutions are not tractable as they rely on some minimax and robust variant of\nthe objective. As a consequence, change points might be detected too late for\npractical applications (in economics, health care or maintenance for instance).\nAvailable constant complexity techniques typically solve a relaxed version of\nthe problem, deeply relying on very specific probability distributions and/or\nsome very precise additional knowledge. We consider a totally different\napproach that leverages the theoretical asymptotic properties of optimal\nsolutions to derive a new scalable approximate algorithm with near optimal\nperformance that runs~in~$\\mathcal{O}(1)$, adapted to even more complex\nMarkovian settings.",
          "link": "http://arxiv.org/abs/2106.05061",
          "publishedOn": "2021-06-10T01:56:47.411Z",
          "wordCount": 560,
          "title": "Quickest change detection with unknown parameters: Constant complexity and near optimality. (arXiv:2106.05061v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/1909.12038",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qimai Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaotong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Han Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_Q/0/1/0/all/0/1\">Quanyu Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xiao-Ming Wu</a>",
          "description": "Graph convolutional neural networks (GCN) have been the model of choice for\ngraph representation learning, which is mainly due to the effective design of\ngraph convolution that computes the representation of a node by aggregating\nthose of its neighbors. However, existing GCN variants commonly use 1-D graph\nconvolution that solely operates on the object link graph without exploring\ninformative relational information among object attributes. This significantly\nlimits their modeling capability and may lead to inferior performance on noisy\nand sparse real-world networks. In this paper, we explore 2-D graph convolution\nto jointly model object links and attribute relations for graph representation\nlearning. Specifically, we propose a computationally efficient dimensionwise\nseparable 2-D graph convolution (DSGC) for filtering node features.\nTheoretically, we show that DSGC can reduce intra-class variance of node\nfeatures on both the object dimension and the attribute dimension to learn more\neffective representations. Empirically, we demonstrate that by modeling\nattribute relations, DSGC achieves significant performance gain over\nstate-of-the-art methods for node classification and clustering on a variety of\nreal-world networks. The source code for reproducing the experimental results\nis available at https://github.com/liqimai/DSGC.",
          "link": "http://arxiv.org/abs/1909.12038",
          "publishedOn": "2021-06-10T01:56:47.405Z",
          "wordCount": 698,
          "title": "Dimensionwise Separable 2-D Graph Convolution for Unsupervised and Semi-Supervised Learning on Graphs. (arXiv:1909.12038v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04800",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dawkins_Q/0/1/0/all/0/1\">Quinlan Dawkins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tianxi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haifeng Xu</a>",
          "description": "Diffusion source identification on networks is a problem of fundamental\nimportance in a broad class of applications, including rumor controlling and\nvirus identification. Though this problem has received significant recent\nattention, most studies have focused only on very restrictive settings and lack\ntheoretical guarantees for more realistic networks. We introduce a statistical\nframework for the study of diffusion source identification and develop a\nconfidence set inference approach inspired by hypothesis testing. Our method\nefficiently produces a small subset of nodes, which provably covers the source\nnode with any pre-specified confidence level without restrictive assumptions on\nnetwork structures. Moreover, we propose multiple Monte Carlo strategies for\nthe inference procedure based on network topology and the probabilistic\nproperties that significantly improve the scalability. To our knowledge, this\nis the first diffusion source identification method with a practically useful\ntheoretical guarantee on general networks. We demonstrate our approach via\nextensive synthetic experiments on well-known random network models and a\nmobility network between cities concerning the COVID-19 spreading.",
          "link": "http://arxiv.org/abs/2106.04800",
          "publishedOn": "2021-06-10T01:56:47.388Z",
          "wordCount": 644,
          "title": "Diffusion Source Identification on Networks with Statistical Confidence. (arXiv:2106.04800v1 [cs.SI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04682",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deshwal_A/0/1/0/all/0/1\">Aryan Deshwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belakaria_S/0/1/0/all/0/1\">Syrine Belakaria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doppa_J/0/1/0/all/0/1\">Janardhan Rao Doppa</a>",
          "description": "We consider the problem of optimizing hybrid structures (mixture of discrete\nand continuous input variables) via expensive black-box function evaluations.\nThis problem arises in many real-world applications. For example, in materials\ndesign optimization via lab experiments, discrete and continuous variables\ncorrespond to the presence/absence of primitive elements and their relative\nconcentrations respectively. The key challenge is to accurately model the\ncomplex interactions between discrete and continuous variables. In this paper,\nwe propose a novel approach referred as Hybrid Bayesian Optimization (HyBO) by\nutilizing diffusion kernels, which are naturally defined over continuous and\ndiscrete variables. We develop a principled approach for constructing diffusion\nkernels over hybrid spaces by utilizing the additive kernel formulation, which\nallows additive interactions of all orders in a tractable manner. We\ntheoretically analyze the modeling strength of additive hybrid kernels and\nprove that it has the universal approximation property. Our experiments on\nsynthetic and six diverse real-world benchmarks show that HyBO significantly\noutperforms the state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2106.04682",
          "publishedOn": "2021-06-10T01:56:47.371Z",
          "wordCount": 595,
          "title": "Bayesian Optimization over Hybrid Spaces. (arXiv:2106.04682v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04718",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1\">Yu Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_F/0/1/0/all/0/1\">Fei Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiusheng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhendawade_N/0/1/0/all/0/1\">Nikhil Bhendawade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_T/0/1/0/all/0/1\">Ting Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1\">Yeyun Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1\">Nan Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_D/0/1/0/all/0/1\">Desheng Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chi_B/0/1/0/all/0/1\">Bingyu Chi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ruifei Zhang</a>",
          "description": "Transformer-based models have made tremendous impacts in natural language\ngeneration. However the inference speed is a bottleneck due to large model size\nand intensive computing involved in auto-regressive decoding process. We\ndevelop FastSeq framework to accelerate sequence generation without accuracy\nloss. The proposed optimization techniques include an attention cache\noptimization, an efficient algorithm for detecting repeated n-grams, and an\nasynchronous generation pipeline with parallel I/O. These optimizations are\ngeneral enough to be applicable to Transformer-based models (e.g., T5, GPT2,\nand UniLM). Our benchmark results on a set of widely used and diverse models\ndemonstrate 4-9x inference speed gain. Additionally, FastSeq is easy to use\nwith a simple one-line code change. The source code is available at\nhttps://github.com/microsoft/fastseq.",
          "link": "http://arxiv.org/abs/2106.04718",
          "publishedOn": "2021-06-10T01:56:47.365Z",
          "wordCount": 560,
          "title": "FastSeq: Make Sequence Generation Faster. (arXiv:2106.04718v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.14139",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Ketkov_S/0/1/0/all/0/1\">Sergey S. Ketkov</a>, <a href=\"http://arxiv.org/find/math/1/au:+Shilov_A/0/1/0/all/0/1\">Andrei S. Shilov</a>, <a href=\"http://arxiv.org/find/math/1/au:+Prokopyev_O/0/1/0/all/0/1\">Oleg A. Prokopyev</a>",
          "description": "In this study we analyze linear combinatorial optimization problems where the\ncost vector is not known a priori, but is only observable through a finite data\nset. In contrast to the related studies, we presume that the number of\nobservations with respect to particular components of the cost vector may vary.\nThe goal is to find a procedure that transforms the data set into an estimate\nof the expected value of the objective function (which is referred to as a\nprediction rule) and a procedure that retrieves a candidate decision (which is\nreferred to as a prescription rule). We aim at finding the least conservative\nprediction and prescription rules, which satisfy some specified asymptotic\nguarantees. We demonstrate that the resulting vector optimization problems\nadmit a weakly optimal solution, which can be obtained by solving a particular\ndistributionally robust optimization problem. Specifically, the decision-maker\nmay optimize the worst-case expected loss across all probability distributions\nwith given component-wise relative entropy distances from the empirical\nmarginal distributions. Finally, we perform numerical experiments to analyze\nthe out-of-sample performance of the proposed solution approach.",
          "link": "http://arxiv.org/abs/2105.14139",
          "publishedOn": "2021-06-10T01:56:47.357Z",
          "wordCount": 642,
          "title": "On a class of data-driven combinatorial optimization problems under uncertainty: a distributionally robust approach. (arXiv:2105.14139v2 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04678",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Biyik_E/0/1/0/all/0/1\">Erdem B&#x131;y&#x131;k</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lazar_D/0/1/0/all/0/1\">Daniel A. Lazar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pedarsani_R/0/1/0/all/0/1\">Ramtin Pedarsani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sadigh_D/0/1/0/all/0/1\">Dorsa Sadigh</a>",
          "description": "Traffic congestion has large economic and social costs. The introduction of\nautonomous vehicles can potentially reduce this congestion by increasing road\ncapacity via vehicle platooning and by creating an avenue for influencing\npeople's choice of routes. We consider a network of parallel roads with two\nmodes of transportation: (i) human drivers, who will choose the quickest route\navailable to them, and (ii) a ride hailing service, which provides an array of\nautonomous vehicle route options, each with different prices, to users. We\nformalize a model of vehicle flow in mixed autonomy and a model of how\nautonomous service users make choices between routes with different prices and\nlatencies. Developing an algorithm to learn the preferences of the users, we\nformulate a planning optimization that chooses prices to maximize a social\nobjective. We demonstrate the benefit of the proposed scheme by comparing the\nresults to theoretical benchmarks which we show can be efficiently calculated.",
          "link": "http://arxiv.org/abs/2106.04678",
          "publishedOn": "2021-06-10T01:56:47.351Z",
          "wordCount": 617,
          "title": "Incentivizing Efficient Equilibria in Traffic Networks with Mixed Autonomy. (arXiv:2106.04678v1 [cs.MA])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04767",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhilu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_V/0/1/0/all/0/1\">Vianne R. Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabuncu_M/0/1/0/all/0/1\">Mert R. Sabuncu</a>",
          "description": "Monte Carlo (MC) dropout is a simple and efficient ensembling method that can\nimprove the accuracy and confidence calibration of high-capacity deep neural\nnetwork models. However, MC dropout is not as effective as more\ncompute-intensive methods such as deep ensembles. This performance gap can be\nattributed to the relatively poor quality of individual models in the MC\ndropout ensemble and their lack of diversity. These issues can in turn be\ntraced back to the coupled training and substantial parameter sharing of the\ndropout models. Motivated by this perspective, we propose a strategy to compute\nan ensemble of subnetworks, each corresponding to a non-overlapping dropout\nmask computed via a pruning strategy and trained independently. We show that\nthe proposed subnetwork ensembling method can perform as well as standard deep\nensembles in both accuracy and uncertainty estimates, yet with a computational\nefficiency similar to MC dropout. Lastly, using several computer vision\ndatasets like CIFAR10/100, CUB200, and Tiny-Imagenet, we experimentally\ndemonstrate that subnetwork ensembling also consistently outperforms recently\nproposed approaches that efficiently ensemble neural networks.",
          "link": "http://arxiv.org/abs/2106.04767",
          "publishedOn": "2021-06-10T01:56:47.331Z",
          "wordCount": 609,
          "title": "Ex uno plures: Splitting One Model into an Ensemble of Subnetworks. (arXiv:2106.04767v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.07826",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Komiyama_J/0/1/0/all/0/1\">Junpei Komiyama</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Abe_M/0/1/0/all/0/1\">Masaya Abe</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nakagawa_K/0/1/0/all/0/1\">Kei Nakagawa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+McAlinn_K/0/1/0/all/0/1\">Kenichiro McAlinn</a>",
          "description": "We consider controlling the false discovery rate for testing many time series\nwith an unknown cross-sectional correlation structure. Given a large number of\nhypotheses, false and missing discoveries can plague an analysis. While many\nprocedures have been proposed to control false discovery, most of them either\nassume independent hypotheses or lack statistical power. A problem of\nparticular interest is in financial asset pricing, where the goal is to\ndetermine which ``factors\" lead to excess returns out of a large number of\npotential factors. Our contribution is two-fold. First, we show the consistency\nof Fama and French's prominent method under multiple testing. Second, we\npropose a novel method for false discovery control using double bootstrapping.\nWe achieve superior statistical power to existing methods and prove that the\nfalse discovery rate is controlled. Simulations and a real data application\nillustrate the efficacy of our method over existing methods.",
          "link": "http://arxiv.org/abs/2102.07826",
          "publishedOn": "2021-06-10T01:56:47.271Z",
          "wordCount": 595,
          "title": "Controlling False Discovery Rates under Cross-Sectional Correlations. (arXiv:2102.07826v2 [stat.ME] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.11409",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Amersfoort_J/0/1/0/all/0/1\">Joost van Amersfoort</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_L/0/1/0/all/0/1\">Lewis Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jesson_A/0/1/0/all/0/1\">Andrew Jesson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Key_O/0/1/0/all/0/1\">Oscar Key</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gal_Y/0/1/0/all/0/1\">Yarin Gal</a>",
          "description": "Gaussian processes are often considered a gold standard in uncertainty\nestimation with low dimensional data, but they have difficulty scaling to high\ndimensional inputs. Deep Kernel Learning (DKL) was introduced as a solution to\nthis problem: a deep feature extractor is used to transform the inputs over\nwhich a Gaussian process' kernel is defined. However, DKL has been shown to\nprovide unreliable uncertainty estimates in practice. We study why, and show\nthat for certain feature extractors, \"far-away\" data points are mapped to the\nsame features as those of training-set points. With this insight we propose to\nconstrain DKL's feature extractor to approximately preserve distances through a\nbi-Lipschitz constraint, resulting in a feature space favorable to DKL. We\nobtain a model, DUE, which demonstrates uncertainty quality outperforming\nprevious DKL and single forward pass uncertainty methods, while maintaining the\nspeed and accuracy of softmax neural networks.",
          "link": "http://arxiv.org/abs/2102.11409",
          "publishedOn": "2021-06-10T01:56:47.242Z",
          "wordCount": 615,
          "title": "On Feature Collapse and Deep Kernel Learning for Single Forward Pass Uncertainty. (arXiv:2102.11409v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04741",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Gilboa_D/0/1/0/all/0/1\">Dar Gilboa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pakman_A/0/1/0/all/0/1\">Ari Pakman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vatter_T/0/1/0/all/0/1\">Thibault Vatter</a>",
          "description": "Probability density models based on deep networks have achieved remarkable\nsuccess in modeling complex high-dimensional datasets. However, unlike kernel\ndensity estimators, modern neural models do not yield marginals or conditionals\nin closed form, as these quantities require the evaluation of seldom tractable\nintegrals. In this work, we present the Marginalizable Density Model\nApproximator (MDMA), a novel deep network architecture which provides closed\nform expressions for the probabilities, marginals and conditionals of any\nsubset of the variables. The MDMA learns deep scalar representations for each\nindividual variable and combines them via learned hierarchical tensor\ndecompositions into a tractable yet expressive CDF, from which marginals and\nconditional densities are easily obtained. We illustrate the advantage of exact\nmarginalizability in several tasks that are out of reach of previous deep\nnetwork-based density estimation models, such as estimating mutual information\nbetween arbitrary subsets of variables, inferring causality by testing for\nconditional independence, and inference with missing data without the need for\ndata imputation, outperforming state-of-the-art models on these tasks. The\nmodel also allows for parallelized sampling with only a logarithmic dependence\nof the time complexity on the number of variables.",
          "link": "http://arxiv.org/abs/2106.04741",
          "publishedOn": "2021-06-10T01:56:47.225Z",
          "wordCount": 604,
          "title": "Marginalizable Density Models. (arXiv:2106.04741v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2104.10611",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Deb_D/0/1/0/all/0/1\">Diptodip Deb</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jiao_Z/0/1/0/all/0/1\">Zhenfei Jiao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_A/0/1/0/all/0/1\">Alex B. Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ahrens_M/0/1/0/all/0/1\">Misha B. Ahrens</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Podgorski_K/0/1/0/all/0/1\">Kaspar Podgorski</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Turaga_S/0/1/0/all/0/1\">Srinivas C. Turaga</a>",
          "description": "3D snapshot microscopy enables fast volumetric imaging by capturing a 3D\nvolume in a single 2D camera image, and has found a variety of biological\napplications such as whole brain imaging of fast neural activity in larval\nzebrafish. The optimal microscope design for this optical 3D-to-2D encoding is\nboth sample- and task-dependent, with no general solution known. Highly\nprogrammable optical elements create new possibilities for sample-specific\ncomputational optimization of microscope parameters, e.g. tuning the collection\nof light for a given sample structure. We perform such optimization with deep\nlearning, using a differentiable wave-optics simulation of light propagation\nthrough a programmable microscope and a neural network to reconstruct volumes\nfrom the microscope image. We introduce a class of global kernel Fourier\nconvolutional neural networks which can efficiently decode information from\nmultiple depths in the volume, globally encoded across a 3D snapshot image. We\nshow that our proposed networks succeed in large field of view volume\nreconstruction and microscope parameter optimization where traditional networks\nfail. We also show that our networks outperform the state-of-the-art learned\nreconstruction algorithms for lensless computational photography.",
          "link": "http://arxiv.org/abs/2104.10611",
          "publishedOn": "2021-06-10T01:56:47.217Z",
          "wordCount": 656,
          "title": "Programmable 3D snapshot microscopy with Fourier convolutional networks. (arXiv:2104.10611v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03760",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hazimeh_H/0/1/0/all/0/1\">Hussein Hazimeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1\">Zhe Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chowdhery_A/0/1/0/all/0/1\">Aakanksha Chowdhery</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sathiamoorthy_M/0/1/0/all/0/1\">Maheswaran Sathiamoorthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yihua Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mazumder_R/0/1/0/all/0/1\">Rahul Mazumder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_L/0/1/0/all/0/1\">Lichan Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chi_E/0/1/0/all/0/1\">Ed H. Chi</a>",
          "description": "The Mixture-of-experts (MoE) architecture is showing promising results in\nmulti-task learning (MTL) and in scaling high-capacity neural networks.\nState-of-the-art MoE models use a trainable sparse gate to select a subset of\nthe experts for each input example. While conceptually appealing, existing\nsparse gates, such as Top-k, are not smooth. The lack of smoothness can lead to\nconvergence and statistical performance issues when training with\ngradient-based methods. In this paper, we develop DSelect-k: the first,\ncontinuously differentiable and sparse gate for MoE, based on a novel binary\nencoding formulation. Our gate can be trained using first-order methods, such\nas stochastic gradient descent, and offers explicit control over the number of\nexperts to select. We demonstrate the effectiveness of DSelect-k in the context\nof MTL, on both synthetic and real datasets with up to 128 tasks. Our\nexperiments indicate that MoE models based on DSelect-k can achieve\nstatistically significant improvements in predictive and expert selection\nperformance. Notably, on a real-world large-scale recommender system, DSelect-k\nachieves over 22% average improvement in predictive performance compared to the\nTop-k gate. We provide an open-source TensorFlow implementation of our gate.",
          "link": "http://arxiv.org/abs/2106.03760",
          "publishedOn": "2021-06-10T01:56:47.211Z",
          "wordCount": 655,
          "title": "DSelect-k: Differentiable Selection in the Mixture of Experts with Applications to Multi-Task Learning. (arXiv:2106.03760v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04802",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_C/0/1/0/all/0/1\">Cuong C. Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Do_T/0/1/0/all/0/1\">Thanh-Toan Do</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carneiro_G/0/1/0/all/0/1\">Gustavo Carneiro</a>",
          "description": "We propose probabilistic task modelling -- a generative probabilistic model\nfor collections of tasks used in meta-learning. The proposed model combines\nvariational auto-encoding and latent Dirichlet allocation to model each task as\na mixture of Gaussian distribution in an embedding space. Such modelling\nprovides an explicit representation of a task through its task-theme mixture.\nWe present an efficient approximation inference technique based on variational\ninference method for empirical Bayes parameter estimation. We perform empirical\nevaluations to validate the task uncertainty and task distance produced by the\nproposed method through correlation diagrams of the prediction accuracy on\ntesting tasks. We also carry out experiments of task selection in meta-learning\nto demonstrate how the task relatedness inferred from the proposed model help\nto facilitate meta-learning algorithms.",
          "link": "http://arxiv.org/abs/2106.04802",
          "publishedOn": "2021-06-10T01:56:47.187Z",
          "wordCount": 546,
          "title": "Probabilistic task modelling for meta-learning. (arXiv:2106.04802v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04770",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sonoda_S/0/1/0/all/0/1\">Sho Sonoda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ishikawa_I/0/1/0/all/0/1\">Isao Ishikawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ikeda_M/0/1/0/all/0/1\">Masahiro Ikeda</a>",
          "description": "Overparametrization has been remarkably successful for deep learning studies.\nThis study investigates an overlooked but important aspect of overparametrized\nneural networks, that is, the null components in the parameters of neural\nnetworks, or the ghosts. Since deep learning is not explicitly regularized,\ntypical deep learning solutions contain null components. In this paper, we\npresent a structure theorem of the null space for a general class of neural\nnetworks. Specifically, we show that any null element can be uniquely written\nby the linear combination of ridgelet transforms. In general, it is quite\ndifficult to fully characterize the null space of an arbitrarily given\noperator. Therefore, the structure theorem is a great advantage for\nunderstanding a complicated landscape of neural network parameters. As\napplications, we discuss the roles of ghosts on the generalization performance\nof deep learning.",
          "link": "http://arxiv.org/abs/2106.04770",
          "publishedOn": "2021-06-10T01:56:47.181Z",
          "wordCount": 571,
          "title": "Ghosts in Neural Networks: Existence, Structure and Role of Infinite-Dimensional Null Space. (arXiv:2106.04770v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05074",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gultchin_L/0/1/0/all/0/1\">Limor Gultchin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watson_D/0/1/0/all/0/1\">David S. Watson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kusner_M/0/1/0/all/0/1\">Matt J. Kusner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silva_R/0/1/0/all/0/1\">Ricardo Silva</a>",
          "description": "We examine the problem of causal response estimation for complex objects\n(e.g., text, images, genomics). In this setting, classical \\emph{atomic}\ninterventions are often not available (e.g., changes to characters, pixels, DNA\nbase-pairs). Instead, we only have access to indirect or \\emph{crude}\ninterventions (e.g., enrolling in a writing program, modifying a scene,\napplying a gene therapy). In this work, we formalize this problem and provide\nan initial solution. Given a collection of candidate mediators, we propose (a)\na two-step method for predicting the causal responses of crude interventions;\nand (b) a testing procedure to identify mediators of crude interventions. We\ndemonstrate, on a range of simulated and real-world-inspired examples, that our\napproach allows us to efficiently estimate the effect of crude interventions\nwith limited data from new treatment regimes.",
          "link": "http://arxiv.org/abs/2106.05074",
          "publishedOn": "2021-06-10T01:56:47.176Z",
          "wordCount": 559,
          "title": "Operationalizing Complex Causes:A Pragmatic View of Mediation. (arXiv:2106.05074v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04748",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheung_Y/0/1/0/all/0/1\">Yun Kuen Cheung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piliouras_G/0/1/0/all/0/1\">Georgios Piliouras</a>",
          "description": "We present a novel control-theoretic understanding of online optimization and\nlearning in games, via the notion of passivity. Passivity is a fundamental\nconcept in control theory, which abstracts energy conservation and dissipation\nin physical systems. It has become a standard tool in analysis of general\nfeedback systems, to which game dynamics belong. Our starting point is to show\nthat all continuous-time Follow-the-Regularized-Leader (FTRL) dynamics, which\nincludes the well-known Replicator Dynamic, are lossless, i.e. it is passive\nwith no energy dissipation. Interestingly, we prove that passivity implies\nbounded regret, connecting two fundamental primitives of control theory and\nonline optimization.\n\nThe observation of energy conservation in FTRL inspires us to present a\nfamily of lossless learning dynamics, each of which has an underlying energy\nfunction with a simple gradient structure. This family is closed under convex\ncombination; as an immediate corollary, any convex combination of FTRL dynamics\nis lossless and thus has bounded regret. This allows us to extend the framework\nof Fox and Shamma (Games, 2013) to prove not just global asymptotic stability\nresults for game dynamics, but Poincar\\'e recurrence results as well.\nIntuitively, when a lossless game (e.g. graphical constant-sum game) is coupled\nwith lossless learning dynamic, their interconnection is also lossless, which\nresults in a pendulum-like energy-preserving recurrent behavior, generalizing\nthe results of Piliouras and Shamma (SODA, 2014) and Mertikopoulos,\nPapadimitriou and Piliouras (SODA, 2018).",
          "link": "http://arxiv.org/abs/2106.04748",
          "publishedOn": "2021-06-10T01:56:47.170Z",
          "wordCount": 680,
          "title": "Online Optimization in Games via Control Theory: Connecting Regret, Passivity and Poincar\\'e Recurrence. (arXiv:2106.04748v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04791",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liao_D/0/1/0/all/0/1\">Danqi Liao</a>",
          "description": "Sentence embeddings encode sentences in fixed dense vectors and have played\nan important role in various NLP tasks and systems. Methods for building\nsentence embeddings include unsupervised learning such as Quick-Thoughts and\nsupervised learning such as InferSent. With the success of pretrained NLP\nmodels, recent research shows that fine-tuning pretrained BERT on SNLI and\nMulti-NLI data creates state-of-the-art sentence embeddings, outperforming\nprevious sentence embeddings methods on various evaluation benchmarks. In this\npaper, we propose a new method to build sentence embeddings by doing supervised\ncontrastive learning. Specifically our method fine-tunes pretrained BERT on\nSNLI data, incorporating both supervised crossentropy loss and supervised\ncontrastive loss. Compared with baseline where fine-tuning is only done with\nsupervised cross-entropy loss similar to current state-of-the-art method SBERT,\nour supervised contrastive method improves 2.8% in average on Semantic Textual\nSimilarity (STS) benchmarks and 1.05% in average on various sentence transfer\ntasks.",
          "link": "http://arxiv.org/abs/2106.04791",
          "publishedOn": "2021-06-10T01:56:47.147Z",
          "wordCount": 565,
          "title": "Sentence Embeddings using Supervised Contrastive Learning. (arXiv:2106.04791v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2103.09815",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Romac_C/0/1/0/all/0/1\">Cl&#xe9;ment Romac</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Portelas_R/0/1/0/all/0/1\">R&#xe9;my Portelas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hofmann_K/0/1/0/all/0/1\">Katja Hofmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oudeyer_P/0/1/0/all/0/1\">Pierre-Yves Oudeyer</a>",
          "description": "Training autonomous agents able to generalize to multiple tasks is a key\ntarget of Deep Reinforcement Learning (DRL) research. In parallel to improving\nDRL algorithms themselves, Automatic Curriculum Learning (ACL) study how\nteacher algorithms can train DRL agents more efficiently by adapting task\nselection to their evolving abilities. While multiple standard benchmarks exist\nto compare DRL agents, there is currently no such thing for ACL algorithms.\nThus, comparing existing approaches is difficult, as too many experimental\nparameters differ from paper to paper. In this work, we identify several key\nchallenges faced by ACL algorithms. Based on these, we present TeachMyAgent\n(TA), a benchmark of current ACL algorithms leveraging procedural task\ngeneration. It includes 1) challenge-specific unit-tests using variants of a\nprocedural Box2D bipedal walker environment, and 2) a new procedural Parkour\nenvironment combining most ACL challenges, making it ideal for global\nperformance assessment. We then use TeachMyAgent to conduct a comparative study\nof representative existing approaches, showcasing the competitiveness of some\nACL algorithms that do not use expert knowledge. We also show that the Parkour\nenvironment remains an open problem. We open-source our environments, all\nstudied ACL algorithms (collected from open-source code or re-implemented), and\nDRL students in a Python package available at\nhttps://github.com/flowersteam/TeachMyAgent.",
          "link": "http://arxiv.org/abs/2103.09815",
          "publishedOn": "2021-06-10T01:56:47.141Z",
          "wordCount": 662,
          "title": "TeachMyAgent: a Benchmark for Automatic Curriculum Learning in Deep RL. (arXiv:2103.09815v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04819",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gollapudi_S/0/1/0/all/0/1\">Sreenivas Gollapudi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guruganesh_G/0/1/0/all/0/1\">Guru Guruganesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kollias_K/0/1/0/all/0/1\">Kostas Kollias</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manurangsi_P/0/1/0/all/0/1\">Pasin Manurangsi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leme_R/0/1/0/all/0/1\">Renato Paes Leme</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schneider_J/0/1/0/all/0/1\">Jon Schneider</a>",
          "description": "We consider the following variant of contextual linear bandits motivated by\nrouting applications in navigational engines and recommendation systems. We\nwish to learn a hidden $d$-dimensional value $w^*$. Every round, we are\npresented with a subset $\\mathcal{X}_t \\subseteq \\mathbb{R}^d$ of possible\nactions. If we choose (i.e. recommend to the user) action $x_t$, we obtain\nutility $\\langle x_t, w^* \\rangle$ but only learn the identity of the best\naction $\\arg\\max_{x \\in \\mathcal{X}_t} \\langle x, w^* \\rangle$. We design\nalgorithms for this problem which achieve regret $O(d\\log T)$ and $\\exp(O(d\n\\log d))$. To accomplish this, we design novel cutting-plane algorithms with\nlow \"regret\" -- the total distance between the true point $w^*$ and the\nhyperplanes the separation oracle returns. We also consider the variant where\nwe are allowed to provide a list of several recommendations. In this variant,\nwe give an algorithm with $O(d^2 \\log d)$ regret and list size\n$\\mathrm{poly}(d)$. Finally, we construct nearly tight algorithms for a weaker\nvariant of this problem where the learner only learns the identity of an action\nthat is better than the recommendation. Our results rely on new algorithmic\ntechniques in convex geometry (including a variant of Steiner's formula for the\ncentroid of a convex set) which may be of independent interest.",
          "link": "http://arxiv.org/abs/2106.04819",
          "publishedOn": "2021-06-10T01:56:47.135Z",
          "wordCount": 644,
          "title": "Contextual Recommendations and Low-Regret Cutting-Plane Algorithms. (arXiv:2106.04819v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04615",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ozair_S/0/1/0/all/0/1\">Sherjil Ozair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yazhe Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Razavi_A/0/1/0/all/0/1\">Ali Razavi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Antonoglou_I/0/1/0/all/0/1\">Ioannis Antonoglou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oord_A/0/1/0/all/0/1\">A&#xe4;ron van den Oord</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vinyals_O/0/1/0/all/0/1\">Oriol Vinyals</a>",
          "description": "Recent developments in the field of model-based RL have proven successful in\na range of environments, especially ones where planning is essential. However,\nsuch successes have been limited to deterministic fully-observed environments.\nWe present a new approach that handles stochastic and partially-observable\nenvironments. Our key insight is to use discrete autoencoders to capture the\nmultiple possible effects of an action in a stochastic environment. We use a\nstochastic variant of \\emph{Monte Carlo tree search} to plan over both the\nagent's actions and the discrete latent variables representing the\nenvironment's response. Our approach significantly outperforms an offline\nversion of MuZero on a stochastic interpretation of chess where the opponent is\nconsidered part of the environment. We also show that our approach scales to\n\\emph{DeepMind Lab}, a first-person 3D environment with large visual\nobservations and partial observability.",
          "link": "http://arxiv.org/abs/2106.04615",
          "publishedOn": "2021-06-10T01:56:47.120Z",
          "wordCount": 570,
          "title": "Vector Quantized Models for Planning. (arXiv:2106.04615v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04862",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_B/0/1/0/all/0/1\">Boyao Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Griesbach_C/0/1/0/all/0/1\">Colin Griesbach</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kim_C/0/1/0/all/0/1\">Cora Kim</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Muller_Voggel_N/0/1/0/all/0/1\">Nadia M&#xfc;ller-Voggel</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bergherr_E/0/1/0/all/0/1\">Elisabeth Bergherr</a>",
          "description": "Boosting methods are widely used in statistical learning to deal with\nhigh-dimensional data due to their variable selection feature. However, those\nmethods lack straightforward ways to construct estimators for the precision of\nthe parameters such as variance or confidence interval, which can be achieved\nby conventional statistical methods like Bayesian inference. In this paper, we\npropose a new inference method \"BayesBoost\" that combines boosting and Bayesian\nfor linear mixed models to make the uncertainty estimation for the random\neffects possible on the one hand. On the other hand, the new method overcomes\nthe shortcomings of Bayesian inference in giving precise and unambiguous\nguidelines for the selection of covariates by benefiting from boosting\ntechniques. The implementation of Bayesian inference leads to the randomness of\nmodel selection criteria like the conditional AIC (cAIC), so we also propose a\ncAIC-based model selection criteria that focus on the stabilized regions\ninstead of the global minimum. The effectiveness of the new approach can be\nobserved via simulation and in a data example from the field of neurophysiology\nfocussing on the mechanisms in the brain while listening to unpleasant sounds.",
          "link": "http://arxiv.org/abs/2106.04862",
          "publishedOn": "2021-06-10T01:56:47.114Z",
          "wordCount": 613,
          "title": "Bayesian Boosting for Linear Mixed Models. (arXiv:2106.04862v1 [stat.ME])"
        },
        {
          "id": "http://arxiv.org/abs/2102.08329",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Isik_B/0/1/0/all/0/1\">Berivan Isik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+No_A/0/1/0/all/0/1\">Albert No</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weissman_T/0/1/0/all/0/1\">Tsachy Weissman</a>",
          "description": "We study the neural network (NN) compression problem, viewing the tension\nbetween the compression ratio and NN performance through the lens of\nrate-distortion theory. We choose a distortion metric that reflects the effect\nof NN compression on the model output and then derive the tradeoff between rate\n(compression ratio) and distortion. In addition to characterizing theoretical\nlimits of NN compression, this formulation shows that \\emph{pruning},\nimplicitly or explicitly, must be a part of a good compression algorithm. This\nobservation bridges a gap between parts of the literature pertaining to NN and\ndata compression, respectively, providing insight into the empirical success of\npruning for NN compression. Finally, we propose a novel pruning strategy\nderived from our information-theoretic formulation and show that it outperforms\nthe relevant baselines on CIFAR-10 and ImageNet datasets.",
          "link": "http://arxiv.org/abs/2102.08329",
          "publishedOn": "2021-06-10T01:56:47.106Z",
          "wordCount": 602,
          "title": "Rate-Distortion Theoretic Model Compression: Successive Refinement for Pruning. (arXiv:2102.08329v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04794",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Han Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaorui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wentao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_W/0/1/0/all/0/1\">Wenbiao Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhongqin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zitao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1\">Anil Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jiliang Tang</a>",
          "description": "Recent studies suggest that ``memorization'' is one important factor for\noverparameterized deep neural networks (DNNs) to achieve optimal performance.\nSpecifically, the perfectly fitted DNNs can memorize the labels of many\natypical samples, generalize their memorization to correctly classify test\natypical samples and enjoy better test performance. While, DNNs which are\noptimized via adversarial training algorithms can also achieve perfect training\nperformance by memorizing the labels of atypical samples, as well as the\nadversarially perturbed atypical samples. However, adversarially trained models\nalways suffer from poor generalization, with both relatively low clean accuracy\nand robustness on the test set. In this work, we study the effect of\nmemorization in adversarial trained DNNs and disclose two important findings:\n(a) Memorizing atypical samples is only effective to improve DNN's accuracy on\nclean atypical samples, but hardly improve their adversarial robustness and (b)\nMemorizing certain atypical samples will even hurt the DNN's performance on\ntypical samples. Based on these two findings, we propose Benign Adversarial\nTraining (BAT) which can facilitate adversarial training to avoid fitting\n``harmful'' atypical samples and fit as more ``benign'' atypical samples as\npossible. In our experiments, we validate the effectiveness of BAT, and show it\ncan achieve better clean accuracy vs. robustness trade-off than baseline\nmethods, in benchmark datasets such as CIFAR100 and Tiny~ImageNet.",
          "link": "http://arxiv.org/abs/2106.04794",
          "publishedOn": "2021-06-10T01:56:47.081Z",
          "wordCount": 653,
          "title": "Towards the Memorization Effect of Neural Networks in Adversarial Training. (arXiv:2106.04794v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04693",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mostafa_S/0/1/0/all/0/1\">Sakib Mostafa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mondal_D/0/1/0/all/0/1\">Debajyoti Mondal</a>",
          "description": "Deep learning techniques are increasingly being adopted for classification\ntasks over the past decade, yet explaining how deep learning architectures can\nachieve state-of-the-art performance is still an elusive goal. While all the\ntraining information is embedded deeply in a trained model, we still do not\nunderstand much about its performance by only analyzing the model. This paper\nexamines the neuron activation patterns of deep learning-based classification\nmodels and explores whether the models' performances can be explained through\nneurons' activation behavior. We propose two approaches: one that models\nneurons' activation behavior as a graph and examines whether the neurons form\nmeaningful communities, and the other examines the predictability of neurons'\nbehavior using entropy. Our comprehensive experimental study reveals that both\nthe community quality (modularity) and entropy are closely related to the deep\nlearning models' performances, thus paves a novel way of explaining deep\nlearning models directly from the neurons' activation pattern.",
          "link": "http://arxiv.org/abs/2106.04693",
          "publishedOn": "2021-06-10T01:56:47.075Z",
          "wordCount": 588,
          "title": "On the Evolution of Neuron Communities in a Deep Learning Architecture. (arXiv:2106.04693v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04781",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rao_C/0/1/0/all/0/1\">Chengping Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Hao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>",
          "description": "Modeling nonlinear spatiotemporal dynamical systems has primarily relied on\npartial differential equations (PDEs) that are typically derived from first\nprinciples. However, the explicit formulation of PDEs for many underexplored\nprocesses, such as climate systems, biochemical reaction and epidemiology,\nremains uncertain or partially unknown, where very sparse measurement data is\nyet available. To tackle this challenge, we propose a novel deep learning\narchitecture that forcibly embedded known physics knowledge in a\nresidual-recurrent $\\Pi$-block network, to facilitate the learning of the\nspatiotemporal dynamics in a data-driven manner. The coercive embedding\nmechanism of physics, fundamentally different from physics-informed neural\nnetworks based on loss penalty, ensures the network to rigorously obey given\nphysics. Numerical experiments demonstrate that the resulting learning paradigm\nthat embeds physics possesses remarkable accuracy, robustness, interpretability\nand generalizability for learning spatiotemporal dynamics.",
          "link": "http://arxiv.org/abs/2106.04781",
          "publishedOn": "2021-06-10T01:56:47.069Z",
          "wordCount": 577,
          "title": "Embedding Physics to Learn Spatiotemporal Dynamics from Sparse Data. (arXiv:2106.04781v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04823",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mohseni_S/0/1/0/all/0/1\">Sina Mohseni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haotao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhiding Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1\">Chaowei Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhangyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yadawa_J/0/1/0/all/0/1\">Jay Yadawa</a>",
          "description": "The open-world deployment of Machine Learning (ML) algorithms in\nsafety-critical applications such as autonomous vehicles needs to address a\nvariety of ML vulnerabilities such as interpretability, verifiability, and\nperformance limitations. Research explores different approaches to improve ML\ndependability by proposing new models and training techniques to reduce\ngeneralization error, achieve domain adaptation, and detect outlier examples\nand adversarial attacks. In this paper, we review and organize practical ML\ntechniques that can improve the safety and dependability of ML algorithms and\ntherefore ML-based software. Our organization maps state-of-the-art ML\ntechniques to safety strategies in order to enhance the dependability of the ML\nalgorithm from different aspects, and discuss research gaps as well as\npromising solutions.",
          "link": "http://arxiv.org/abs/2106.04823",
          "publishedOn": "2021-06-10T01:56:47.064Z",
          "wordCount": 546,
          "title": "Practical Machine Learning Safety: A Survey and Primer. (arXiv:2106.04823v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04707",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Choudhury_T/0/1/0/all/0/1\">Tuhinangshu Choudhury</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Joshi_G/0/1/0/all/0/1\">Gauri Joshi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_W/0/1/0/all/0/1\">Weina Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shakkottai_S/0/1/0/all/0/1\">Sanjay Shakkottai</a>",
          "description": "In multi-server queueing systems where there is no central queue holding all\nincoming jobs, job dispatching policies are used to assign incoming jobs to the\nqueue at one of the servers. Classic job dispatching policies such as\njoin-the-shortest-queue and shortest expected delay assume that the service\nrates and queue lengths of the servers are known to the dispatcher. In this\nwork, we tackle the problem of job dispatching without the knowledge of service\nrates and queue lengths, where the dispatcher can only obtain noisy estimates\nof the service rates by observing job departures. This problem presents a novel\nexploration-exploitation trade-off between sending jobs to all the servers to\nestimate their service rates, and exploiting the currently known fastest\nservers to minimize the expected queueing delay. We propose a bandit-based\nexploration policy that learns the service rates from observed job departures.\nUnlike the standard multi-armed bandit problem where only one out of a finite\nset of actions is optimal, here the optimal policy requires identifying the\noptimal fraction of incoming jobs to be sent to each server. We present a\nregret analysis and simulations to demonstrate the effectiveness of the\nproposed bandit-based exploration policy.",
          "link": "http://arxiv.org/abs/2106.04707",
          "publishedOn": "2021-06-10T01:56:47.058Z",
          "wordCount": 631,
          "title": "Job Dispatching Policies for Queueing Systems with Unknown Service Rates. (arXiv:2106.04707v1 [eess.SY])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04769",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Mitra_S/0/1/0/all/0/1\">Siddharth Mitra</a>, <a href=\"http://arxiv.org/find/math/1/au:+Feldman_M/0/1/0/all/0/1\">Moran Feldman</a>, <a href=\"http://arxiv.org/find/math/1/au:+Karbasi_A/0/1/0/all/0/1\">Amin Karbasi</a>",
          "description": "It has been well established that first order optimization methods can\nconverge to the maximal objective value of concave functions and provide\nconstant factor approximation guarantees for (non-convex/non-concave)\ncontinuous submodular functions. In this work, we initiate the study of the\nmaximization of functions of the form $F(x) = G(x) +C(x)$ over a solvable\nconvex body $P$, where $G$ is a smooth DR-submodular function and $C$ is a\nsmooth concave function. This class of functions is a strict extension of both\nconcave and continuous DR-submodular functions for which no theoretical\nguarantee is known. We provide a suite of Frank-Wolfe style algorithms, which,\ndepending on the nature of the objective function (i.e., if $G$ and $C$ are\nmonotone or not, and non-negative or not) and on the nature of the set $P$\n(i.e., whether it is downward closed or not), provide $1-1/e$, $1/e$, or $1/2$\napproximation guarantees. We then use our algorithms to get a framework to\nsmoothly interpolate between choosing a diverse set of elements from a given\nground set (corresponding to the mode of a determinantal point process) and\nchoosing a clustered set of elements (corresponding to the maxima of a suitable\nconcave function). Additionally, we apply our algorithms to various functions\nin the above class (DR-submodular + concave) in both constrained and\nunconstrained settings, and show that our algorithms consistently outperform\nnatural baselines.",
          "link": "http://arxiv.org/abs/2106.04769",
          "publishedOn": "2021-06-10T01:56:47.043Z",
          "wordCount": 650,
          "title": "Submodular + Concave. (arXiv:2106.04769v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04729",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Asadi_A/0/1/0/all/0/1\">Amin Asadi</a>, <a href=\"http://arxiv.org/find/math/1/au:+Pinkley_S/0/1/0/all/0/1\">Sarah Nurre Pinkley</a>",
          "description": "We consider the problem of optimizing the distribution operations of a hub\nusing drones to deliver medical supplies to different geographic regions.\nDrones are an innovative method with many benefits including low-contact\ndelivery thereby reducing the spread of pandemic and vaccine-preventable\ndiseases. While we focus on medical supply delivery for this work, it is\napplicable to drone delivery for many other applications, including food,\npostal items, and e-commerce delivery. In this paper, our goal is to address\ndrone delivery challenges by optimizing the distribution operations at a drone\nhub that dispatch drones to different geographic locations generating\nstochastic demands for medical supplies. By considering different geographic\nlocations, we consider different classes of demand that require different\nflight ranges, which is directly related to the amount of charge held in a\ndrone battery. We classify the stochastic demands based on their distance from\nthe drone hub, use a Markov decision process to model the problem, and perform\ncomputational tests using realistic data representing a prominent drone\ndelivery company. We solve the problem using a reinforcement learning method\nand show its high performance compared with the exact solution found using\ndynamic programming. Finally, we analyze the results and provide insights for\nmanaging the drone hub operations.",
          "link": "http://arxiv.org/abs/2106.04729",
          "publishedOn": "2021-06-10T01:56:47.037Z",
          "wordCount": 658,
          "title": "Drones for Medical Delivery Considering Different Demands Classes: A Markov Decision Process Approach for Managing Health Centers Dispatching Medical Products. (arXiv:2106.04729v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04668",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liyanage_Y/0/1/0/all/0/1\">Yasitha Warahena Liyanage</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zois_D/0/1/0/all/0/1\">Daphney-Stavroula Zois</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chelmis_C/0/1/0/all/0/1\">Charalampos Chelmis</a>",
          "description": "In a typical supervised machine learning setting, the predictions on all test\ninstances are based on a common subset of features discovered during model\ntraining. However, using a different subset of features that is most\ninformative for each test instance individually may not only improve prediction\naccuracy, but also the overall interpretability of the model. At the same time,\nfeature selection methods for classification have been known to be the most\neffective when many features are irrelevant and/or uncorrelated. In fact,\nfeature selection ignoring correlations between features can lead to poor\nclassification performance. In this work, a Bayesian network is utilized to\nmodel feature dependencies. Using the dependency network, a new method is\nproposed that sequentially selects the best feature to evaluate for each test\ninstance individually, and stops the selection process to make a prediction\nonce it determines that no further improvement can be achieved with respect to\nclassification accuracy. The optimum number of features to acquire and the\noptimum classification strategy are derived for each test instance. The\ntheoretical properties of the optimum solution are analyzed, and a new\nalgorithm is proposed that takes advantage of these properties to implement a\nrobust and scalable solution for high dimensional settings. The effectiveness,\ngeneralizability, and scalability of the proposed method is illustrated on a\nvariety of real-world datasets from diverse application domains.",
          "link": "http://arxiv.org/abs/2106.04668",
          "publishedOn": "2021-06-10T01:56:47.025Z",
          "wordCount": 647,
          "title": "Dynamic Instance-Wise Classification in Correlated Feature Spaces. (arXiv:2106.04668v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04656",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Karami_F/0/1/0/all/0/1\">Farzad Karami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kehtarnavaz_N/0/1/0/all/0/1\">Nasser Kehtarnavaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rotea_M/0/1/0/all/0/1\">Mario Rotea</a>",
          "description": "Each year a growing number of wind farms are being added to power grids to\ngenerate electricity. The power curve of a wind turbine, which exhibits the\nrelationship between generated power and wind speed, plays a major role in\nassessing the performance of a wind farm. Neural networks have been used for\npower curve estimation. However, they do not produce a confidence measure for\ntheir output, unless computationally prohibitive Bayesian methods are used. In\nthis paper, a probabilistic neural network with Monte Carlo dropout is\nconsidered to quantify the model (epistemic) uncertainty of the power curve\nestimation. This approach offers a minimal increase in computational complexity\nover deterministic approaches. Furthermore, by incorporating a probabilistic\nloss function, the noise or aleatoric uncertainty in the data is estimated. The\ndeveloped network captures both model and noise uncertainty which is found to\nbe useful tools in assessing performance. Also, the developed network is\ncompared with existing ones across a public domain dataset showing superior\nperformance in terms of prediction accuracy.",
          "link": "http://arxiv.org/abs/2106.04656",
          "publishedOn": "2021-06-10T01:56:47.019Z",
          "wordCount": 606,
          "title": "Probabilistic Neural Network to Quantify Uncertainty of Wind Power Estimation. (arXiv:2106.04656v1 [cs.NE])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04739",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1\">Dai Hai Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_C/0/1/0/all/0/1\">Canh Hao Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mamitsuka_H/0/1/0/all/0/1\">Hiroshi Mamitsuka</a>",
          "description": "Graph is an usual representation of relational data, which are ubiquitous in\nmanydomains such as molecules, biological and social networks. A popular\napproach to learningwith graph structured data is to make use of graph kernels,\nwhich measure the similaritybetween graphs and are plugged into a kernel\nmachine such as a support vector machine.Weisfeiler-Lehman (WL) based graph\nkernels, which employ WL labeling scheme to extract subtree patterns and\nperform node embedding, are demonstrated to achieve great performance while\nbeing efficiently computable. However, one of the main drawbacks of ageneral\nkernel is the decoupling of kernel construction and learning process. For\nmoleculargraphs, usual kernels such as WL subtree, based on substructures of\nthe molecules, consider all available substructures having the same importance,\nwhich might not be suitable inpractice. In this paper, we propose a method to\nlearn the weights of subtree patterns in the framework of WWL kernels, the\nstate of the art method for graph classification task [14]. To overcome the\ncomputational issue on large scale data sets, we present an efficient learning\nalgorithm and also derive a generalization gap bound to show its convergence.\nFinally, through experiments on synthetic and real-world data sets, we\ndemonstrate the effectiveness of our proposed method for learning the weights\nof subtree patterns.",
          "link": "http://arxiv.org/abs/2106.04739",
          "publishedOn": "2021-06-10T01:56:47.004Z",
          "wordCount": 638,
          "title": "Learning subtree pattern importance for Weisfeiler-Lehmanbased graph kernels. (arXiv:2106.04739v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04805",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wu_Y/0/1/0/all/0/1\">Yuchen Wu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bateni_M/0/1/0/all/0/1\">MohammadHossein Bateni</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Linhares_A/0/1/0/all/0/1\">Andre Linhares</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Almeida_F/0/1/0/all/0/1\">Filipe Miguel Goncalves de Almeida</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Montanari_A/0/1/0/all/0/1\">Andrea Montanari</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Norouzi_Fard_A/0/1/0/all/0/1\">Ashkan Norouzi-Fard</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tardos_J/0/1/0/all/0/1\">Jakab Tardos</a>",
          "description": "The community detection problem requires to cluster the nodes of a network\ninto a small number of well-connected \"communities\". There has been substantial\nrecent progress in characterizing the fundamental statistical limits of\ncommunity detection under simple stochastic block models. However, in\nreal-world applications, the network structure is typically dynamic, with nodes\nthat join over time. In this setting, we would like a detection algorithm to\nperform only a limited number of updates at each node arrival. While standard\nvoting approaches satisfy this constraint, it is unclear whether they exploit\nthe network information optimally. We introduce a simple model for networks\ngrowing over time which we refer to as streaming stochastic block model\n(StSBM). Within this model, we prove that voting algorithms have fundamental\nlimitations. We also develop a streaming belief-propagation (StreamBP)\napproach, for which we prove optimality in certain regimes. We validate our\ntheoretical findings on synthetic and real data.",
          "link": "http://arxiv.org/abs/2106.04805",
          "publishedOn": "2021-06-10T01:56:46.998Z",
          "wordCount": 598,
          "title": "Streaming Belief Propagation for Community Detection. (arXiv:2106.04805v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04683",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mani_A/0/1/0/all/0/1\">A. Mani</a>",
          "description": "In this research, a general theoretical framework for clustering is proposed\nover specific partial algebraic systems by the present author. Her theory helps\nin isolating minimal assumptions necessary for different concepts of clustering\ninformation in any form to be realized in a situation (and therefore in a\nsemantics). \\emph{It is well-known that of the limited number of proofs in the\ntheory of hard and soft clustering that are known to exist, most involve\nstatistical assumptions}. Many methods seem to work because they seem to work\nin specific empirical practice. A new general rough method of analyzing\nclusterings is invented, and this opens the subject to clearer conceptions and\ncontamination-free theoretical proofs. Numeric ideas of validation are also\nproposed to be replaced by those based on general rough approximation. The\nessence of the approach is explained in brief and supported by an example.",
          "link": "http://arxiv.org/abs/2106.04683",
          "publishedOn": "2021-06-10T01:56:46.992Z",
          "wordCount": 579,
          "title": "General Rough Modeling of Cluster Analysis. (arXiv:2106.04683v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04765",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schiff_Y/0/1/0/all/0/1\">Yair Schiff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quanz_B/0/1/0/all/0/1\">Brian Quanz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_P/0/1/0/all/0/1\">Payel Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1\">Pin-Yu Chen</a>",
          "description": "The field of Deep Learning is rich with empirical evidence of human-like\nperformance on a variety of prediction tasks. However, despite these successes,\nthe recent Predicting Generalization in Deep Learning (PGDL) NeurIPS 2020\ncompetition suggests that there is a need for more robust and efficient\nmeasures of network generalization. In this work, we propose a new framework\nfor evaluating the generalization capabilities of trained networks. We use\nperturbation response (PR) curves that capture the accuracy change of a given\nnetwork as a function of varying levels of training sample perturbation. From\nthese PR curves, we derive novel statistics that capture generalization\ncapability. Specifically, we introduce two new measures for accurately\npredicting generalization gaps: the Gi-score and Pal-score, that are inspired\nby the Gini coefficient and Palma ratio (measures of income inequality), that\naccurately predict generalization gaps. Using our framework applied to intra\nand inter class sample mixup, we attain better predictive scores than the\ncurrent state-of-the-art measures on a majority of tasks in the PGDL\ncompetition. In addition, we show that our framework and the proposed\nstatistics can be used to capture to what extent a trained network is invariant\nto a given parametric input transformation, such as rotation or translation.\nTherefore, these generalization gap prediction statistics also provide a useful\nmeans for selecting the optimal network architectures and hyperparameters that\nare invariant to a certain perturbation.",
          "link": "http://arxiv.org/abs/2106.04765",
          "publishedOn": "2021-06-10T01:56:46.986Z",
          "wordCount": 666,
          "title": "Predicting Deep Neural Network Generalization with Perturbation Response Curves. (arXiv:2106.04765v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04727",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1\">Shangdi Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yiqiu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1\">Yan Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dhulipala_L/0/1/0/all/0/1\">Laxman Dhulipala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shun_J/0/1/0/all/0/1\">Julian Shun</a>",
          "description": "This paper studies the hierarchical clustering problem, where the goal is to\nproduce a dendrogram that represents clusters at varying scales of a data set.\nWe propose the ParChain framework for designing parallel hierarchical\nagglomerative clustering (HAC) algorithms, and using the framework we obtain\nnovel parallel algorithms for the complete linkage, average linkage, and Ward's\nlinkage criteria. Compared to most previous parallel HAC algorithms, which\nrequire quadratic memory, our new algorithms require only linear memory, and\nare scalable to large data sets. ParChain is based on our parallelization of\nthe nearest-neighbor chain algorithm, and enables multiple clusters to be\nmerged on every round. We introduce two key optimizations that are critical for\nefficiency: a range query optimization that reduces the number of distance\ncomputations required when finding nearest neighbors of clusters, and a caching\noptimization that stores a subset of previously computed distances, which are\nlikely to be reused.\n\nExperimentally, we show that our highly-optimized implementations using 48\ncores with two-way hyper-threading achieve 5.8--110.1x speedup over\nstate-of-the-art parallel HAC algorithms and achieve 13.75--54.23x\nself-relative speedup. Compared to state-of-the-art algorithms, our algorithms\nrequire up to 237.3x less space. Our algorithms are able to scale to data set\nsizes with tens of millions of points, which existing algorithms are not able\nto handle.",
          "link": "http://arxiv.org/abs/2106.04727",
          "publishedOn": "2021-06-10T01:56:46.979Z",
          "wordCount": 661,
          "title": "ParChain: A Framework for Parallel Hierarchical Agglomerative Clustering using Nearest-Neighbor Chain. (arXiv:2106.04727v1 [cs.DS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04803",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dai_Z/0/1/0/all/0/1\">Zihang Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hanxiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1\">Quoc V. Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_M/0/1/0/all/0/1\">Mingxing Tan</a>",
          "description": "Transformers have attracted increasing interests in computer vision, but they\nstill fall behind state-of-the-art convolutional networks. In this work, we\nshow that while Transformers tend to have larger model capacity, their\ngeneralization can be worse than convolutional networks due to the lack of the\nright inductive bias. To effectively combine the strengths from both\narchitectures, we present CoAtNets(pronounced \"coat\" nets), a family of hybrid\nmodels built from two key insights:(1) depthwise Convolution and self-Attention\ncan be naturally unified via simple relative attention; (2) vertically stacking\nconvolution layers and attention layers in a principled way is surprisingly\neffective in improving generalization, capacity and efficiency. Experiments\nshow that our CoAtNets achieve state-of-the-art performance under different\nresource constraints across various datasets. For example, CoAtNet achieves\n86.0% ImageNet top-1 accuracy without extra data, and 89.77% with extra JFT\ndata, outperforming prior arts of both convolutional networks and Transformers.\nNotably, when pre-trained with 13M images fromImageNet-21K, our CoAtNet\nachieves 88.56% top-1 accuracy, matching ViT-huge pre-trained with 300M images\nfrom JFT while using 23x less data.",
          "link": "http://arxiv.org/abs/2106.04803",
          "publishedOn": "2021-06-10T01:56:46.958Z",
          "wordCount": 607,
          "title": "CoAtNet: Marrying Convolution and Attention for All Data Sizes. (arXiv:2106.04803v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04815",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qingyun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Langford_J/0/1/0/all/0/1\">John Langford</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mineiro_P/0/1/0/all/0/1\">Paul Mineiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rossi_M/0/1/0/all/0/1\">Marco Rossi</a>",
          "description": "We propose the ChaCha (Champion-Challengers) algorithm for making an online\nchoice of hyperparameters in online learning settings. ChaCha handles the\nprocess of determining a champion and scheduling a set of `live' challengers\nover time based on sample complexity bounds. It is guaranteed to have sublinear\nregret after the optimal configuration is added into consideration by an\napplication-dependent oracle based on the champions. Empirically, we show that\nChaCha provides good performance across a wide array of datasets when\noptimizing over featurization and hyperparameter decisions.",
          "link": "http://arxiv.org/abs/2106.04815",
          "publishedOn": "2021-06-10T01:56:46.951Z",
          "wordCount": 514,
          "title": "ChaCha for Online AutoML. (arXiv:2106.04815v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04630",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_R/0/1/0/all/0/1\">Rongmei Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jie Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zalmout_N/0/1/0/all/0/1\">Nasser Zalmout</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_L/0/1/0/all/0/1\">Li Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1\">Xin Luna Dong</a>",
          "description": "Understanding product attributes plays an important role in improving online\nshopping experience for customers and serves as an integral part for\nconstructing a product knowledge graph. Most existing methods focus on\nattribute extraction from text description or utilize visual information from\nproduct images such as shape and color. Compared to the inputs considered in\nprior works, a product image in fact contains more information, represented by\na rich mixture of words and visual clues with a layout carefully designed to\nimpress customers. This work proposes a more inclusive framework that fully\nutilizes these different modalities for attribute extraction. Inspired by\nrecent works in visual question answering, we use a transformer based sequence\nto sequence model to fuse representations of product text, Optical Character\nRecognition (OCR) tokens and visual objects detected in the product image. The\nframework is further extended with the capability to extract attribute value\nacross multiple product categories with a single model, by training the decoder\nto predict both product category and attribute value and conditioning its\noutput on product category. The model provides a unified attribute extraction\nsolution desirable at an e-commerce platform that offers numerous product\ncategories with a diverse body of product attributes. We evaluated the model on\ntwo product attributes, one with many possible values and one with a small set\nof possible values, over 14 product categories and found the model could\nachieve 15% gain on the Recall and 10% gain on the F1 score compared to\nexisting methods using text-only features.",
          "link": "http://arxiv.org/abs/2106.04630",
          "publishedOn": "2021-06-10T01:56:46.943Z",
          "wordCount": 704,
          "title": "PAM: Understanding Product Images in Cross Product Category Attribute Extraction. (arXiv:2106.04630v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04784",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Na_B/0/1/0/all/0/1\">Byunggook Na</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mok_J/0/1/0/all/0/1\">Jisoo Mok</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choe_H/0/1/0/all/0/1\">Hyeokjun Choe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1\">Sungroh Yoon</a>",
          "description": "Despite the increasing interest in neural architecture search (NAS), the\nsignificant computational cost of NAS is a hindrance to researchers. Hence, we\npropose to reduce the cost of NAS using proxy data, i.e., a representative\nsubset of the target data, without sacrificing search performance. Even though\ndata selection has been used across various fields, our evaluation of existing\nselection methods for NAS algorithms offered by NAS-Bench-1shot1 reveals that\nthey are not always appropriate for NAS and a new selection method is\nnecessary. By analyzing proxy data constructed using various selection methods\nthrough data entropy, we propose a novel proxy data selection method tailored\nfor NAS. To empirically demonstrate the effectiveness, we conduct thorough\nexperiments across diverse datasets, search spaces, and NAS algorithms.\nConsequently, NAS algorithms with the proposed selection discover architectures\nthat are competitive with those obtained using the entire dataset. It\nsignificantly reduces the search cost: executing DARTS with the proposed\nselection requires only 40 minutes on CIFAR-10 and 7.5 hours on ImageNet with a\nsingle GPU. Additionally, when the architecture searched on ImageNet using the\nproposed selection is inversely transferred to CIFAR-10, a state-of-the-art\ntest error of 2.4\\% is yielded. Our code is available at\nhttps://github.com/nabk89/NAS-with-Proxy-data.",
          "link": "http://arxiv.org/abs/2106.04784",
          "publishedOn": "2021-06-10T01:56:46.937Z",
          "wordCount": 633,
          "title": "Accelerating Neural Architecture Search via Proxy Data. (arXiv:2106.04784v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04708",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Truong_D/0/1/0/all/0/1\">Duc P. Truong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Skau_E/0/1/0/all/0/1\">Erik Skau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Desantis_D/0/1/0/all/0/1\">Derek Desantis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alexandrov_B/0/1/0/all/0/1\">Boian Alexandrov</a>",
          "description": "A novel approach to Boolean matrix factorization (BMF) is presented. Instead\nof solving the BMF problem directly, this approach solves a nonnegative\noptimization problem with the constraint over an auxiliary matrix whose Boolean\nstructure is identical to the initial Boolean data. Then the solution of the\nnonnegative auxiliary optimization problem is thresholded to provide a solution\nfor the BMF problem. We provide the proofs for the equivalencies of the two\nsolution spaces under the existence of an exact solution. Moreover, the\nnonincreasing property of the algorithm is also proven. Experiments on\nsynthetic and real datasets are conducted to show the effectiveness and\ncomplexity of the algorithm compared to other current methods.",
          "link": "http://arxiv.org/abs/2106.04708",
          "publishedOn": "2021-06-10T01:56:46.931Z",
          "wordCount": 548,
          "title": "Boolean Matrix Factorization via Nonnegative Auxiliary Optimization. (arXiv:2106.04708v1 [cs.DS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04714",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dai_E/0/1/0/all/0/1\">Enyan Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aggarwal_C/0/1/0/all/0/1\">Charu Aggarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Suhang Wang</a>",
          "description": "Graph Neural Networks (GNNs) have achieved promising results for\nsemi-supervised learning tasks on graphs such as node classification. Despite\nthe great success of GNNs, many real-world graphs are often sparsely and\nnoisily labeled, which could significantly degrade the performance of GNNs, as\nthe noisy information could propagate to unlabeled nodes via graph structure.\nThus, it is important to develop a label noise-resistant GNN for\nsemi-supervised node classification. Though extensive studies have been\nconducted to learn neural networks with noisy labels, they mostly focus on\nindependent and identically distributed data and assume a large number of noisy\nlabels are available, which are not directly applicable for GNNs. Thus, we\ninvestigate a novel problem of learning a robust GNN with noisy and limited\nlabels. To alleviate the negative effects of label noise, we propose to link\nthe unlabeled nodes with labeled nodes of high feature similarity to bring more\nclean label information. Furthermore, accurate pseudo labels could be obtained\nby this strategy to provide more supervision and further reduce the effects of\nlabel noise. Our theoretical and empirical analysis verify the effectiveness of\nthese two strategies under mild conditions. Extensive experiments on real-world\ndatasets demonstrate the effectiveness of the proposed method in learning a\nrobust GNN with noisy and limited labels.",
          "link": "http://arxiv.org/abs/2106.04714",
          "publishedOn": "2021-06-10T01:56:46.925Z",
          "wordCount": 643,
          "title": "NRGNN: Learning a Label Noise-Resistant Graph Neural Network on Sparsely and Noisily Labeled Graphs. (arXiv:2106.04714v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04619",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kugelgen_J/0/1/0/all/0/1\">Julius von K&#xfc;gelgen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sharma_Y/0/1/0/all/0/1\">Yash Sharma</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gresele_L/0/1/0/all/0/1\">Luigi Gresele</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Brendel_W/0/1/0/all/0/1\">Wieland Brendel</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Scholkopf_B/0/1/0/all/0/1\">Bernhard Sch&#xf6;lkopf</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Besserve_M/0/1/0/all/0/1\">Michel Besserve</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Locatello_F/0/1/0/all/0/1\">Francesco Locatello</a>",
          "description": "Self-supervised representation learning has shown remarkable success in a\nnumber of domains. A common practice is to perform data augmentation via\nhand-crafted transformations intended to leave the semantics of the data\ninvariant. We seek to understand the empirical success of this approach from a\ntheoretical perspective. We formulate the augmentation process as a latent\nvariable model by postulating a partition of the latent representation into a\ncontent component, which is assumed invariant to augmentation, and a style\ncomponent, which is allowed to change. Unlike prior work on disentanglement and\nindependent component analysis, we allow for both nontrivial statistical and\ncausal dependencies in the latent space. We study the identifiability of the\nlatent representation based on pairs of views of the observations and prove\nsufficient conditions that allow us to identify the invariant content partition\nup to an invertible mapping in both generative and discriminative settings. We\nfind numerical simulations with dependent latent variables are consistent with\nour theory. Lastly, we introduce Causal3DIdent, a dataset of high-dimensional,\nvisually complex images with rich causal dependencies, which we use to study\nthe effect of data augmentations performed in practice.",
          "link": "http://arxiv.org/abs/2106.04619",
          "publishedOn": "2021-06-10T01:56:46.909Z",
          "wordCount": 637,
          "title": "Self-Supervised Learning with Data Augmentations Provably Isolates Content from Style. (arXiv:2106.04619v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04763",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Azizi_M/0/1/0/all/0/1\">MohammadJavad Azizi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kveton_B/0/1/0/all/0/1\">Branislav Kveton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghavamzadeh_M/0/1/0/all/0/1\">Mohammad Ghavamzadeh</a>",
          "description": "We study the problem of best-arm identification (BAI) in contextual bandits\nin the fixed-budget setting. We propose a general successive elimination\nalgorithm that proceeds in stages and eliminates a fixed fraction of suboptimal\narms in each stage. This design takes advantage of the strengths of static and\nadaptive allocations. We analyze the algorithm in linear models and obtain a\nbetter error bound than prior work. We also apply it to generalized linear\nmodels (GLMs) and bound its error. This is the first BAI algorithm for GLMs in\nthe fixed-budget setting. Our extensive numerical experiments show that our\nalgorithm outperforms the state of art.",
          "link": "http://arxiv.org/abs/2106.04763",
          "publishedOn": "2021-06-10T01:56:46.903Z",
          "wordCount": 532,
          "title": "Fixed-Budget Best-Arm Identification in Contextual Bandits: A Static-Adaptive Algorithm. (arXiv:2106.04763v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04696",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yengera_G/0/1/0/all/0/1\">Gaurav Yengera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Devidze_R/0/1/0/all/0/1\">Rati Devidze</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamalaruban_P/0/1/0/all/0/1\">Parameswaran Kamalaruban</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singla_A/0/1/0/all/0/1\">Adish Singla</a>",
          "description": "We consider the problem of teaching via demonstrations in sequential\ndecision-making settings. In particular, we study how to design a personalized\ncurriculum over demonstrations to speed up the learner's convergence. We\nprovide a unified curriculum strategy for two popular learner models: Maximum\nCausal Entropy Inverse Reinforcement Learning (MaxEnt-IRL) and Cross-Entropy\nBehavioral Cloning (CrossEnt-BC). Our unified strategy induces a ranking over\ndemonstrations based on a notion of difficulty scores computed w.r.t. the\nteacher's optimal policy and the learner's current policy. Compared to the\nstate of the art, our strategy doesn't require access to the learner's internal\ndynamics and still enjoys similar convergence guarantees under mild technical\nconditions. Furthermore, we adapt our curriculum strategy to teach a learner\nusing domain knowledge in the form of task-specific difficulty scores when the\nteacher's optimal policy is unknown. Experiments on a car driving simulator\nenvironment and shortest path problems in a grid-world environment demonstrate\nthe effectiveness of our proposed curriculum strategy.",
          "link": "http://arxiv.org/abs/2106.04696",
          "publishedOn": "2021-06-10T01:56:46.895Z",
          "wordCount": 586,
          "title": "Curriculum Design for Teaching via Demonstrations: Theory and Applications. (arXiv:2106.04696v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04689",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Leme_R/0/1/0/all/0/1\">Renato Paes Leme</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sivan_B/0/1/0/all/0/1\">Balasubramanian Sivan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teng_Y/0/1/0/all/0/1\">Yifeng Teng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Worah_P/0/1/0/all/0/1\">Pratik Worah</a>",
          "description": "In the Learning to Price setting, a seller posts prices over time with the\ngoal of maximizing revenue while learning the buyer's valuation. This problem\nis very well understood when values are stationary (fixed or iid). Here we\nstudy the problem where the buyer's value is a moving target, i.e., they change\nover time either by a stochastic process or adversarially with bounded\nvariation. In either case, we provide matching upper and lower bounds on the\noptimal revenue loss. Since the target is moving, any information learned soon\nbecomes out-dated, which forces the algorithms to keep switching between\nexploring and exploiting phases.",
          "link": "http://arxiv.org/abs/2106.04689",
          "publishedOn": "2021-06-10T01:56:46.888Z",
          "wordCount": 538,
          "title": "Learning to Price Against a Moving Target. (arXiv:2106.04689v1 [cs.GT])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04723",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Venieris_S/0/1/0/all/0/1\">Stylianos I. Venieris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panopoulos_I/0/1/0/all/0/1\">Ioannis Panopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venieris_I/0/1/0/all/0/1\">Iakovos S. Venieris</a>",
          "description": "Radical progress in the field of deep learning (DL) has led to unprecedented\naccuracy in diverse inference tasks. As such, deploying DL models across mobile\nplatforms is vital to enable the development and broad availability of the\nnext-generation intelligent apps. Nevertheless, the wide and optimised\ndeployment of DL models is currently hindered by the vast system heterogeneity\nof mobile devices, the varying computational cost of different DL models and\nthe variability of performance needs across DL applications. This paper\nproposes OODIn, a framework for the optimised deployment of DL apps across\nheterogeneous mobile devices. OODIn comprises a novel DL-specific software\narchitecture together with an analytical framework for modelling DL\napplications that: (1) counteract the variability in device resources and DL\nmodels by means of a highly parametrised multi-layer design; and (2) perform a\nprincipled optimisation of both model- and system-level parameters through a\nmulti-objective formulation, designed for DL inference apps, in order to adapt\nthe deployment to the user-specified performance requirements and device\ncapabilities. Quantitative evaluation shows that the proposed framework\nconsistently outperforms status-quo designs across heterogeneous devices and\ndelivers up to 4.3x and 3.5x performance gain over highly optimised platform-\nand model-aware designs respectively, while effectively adapting execution to\ndynamic changes in resource availability.",
          "link": "http://arxiv.org/abs/2106.04723",
          "publishedOn": "2021-06-10T01:56:46.867Z",
          "wordCount": 653,
          "title": "OODIn: An Optimised On-Device Inference Framework for Heterogeneous Mobile Devices. (arXiv:2106.04723v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04692",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Junjie Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_K/0/1/0/all/0/1\">Kaiyi Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yingbin Liang</a>",
          "description": "Bilevel optimization has been widely applied in many important machine\nlearning applications such as hyperparameter optimization and meta-learning.\nRecently, several momentum-based algorithms have been proposed to solve bilevel\noptimization problems faster. However, those momentum-based algorithms do not\nachieve provably better computational complexity than\n$\\mathcal{O}(\\epsilon^{-2})$ of the SGD-based algorithm. In this paper, we\npropose two new algorithms for bilevel optimization, where the first algorithm\nadopts momentum-based recursive iterations, and the second algorithm adopts\nrecursive gradient estimations in nested loops to decrease the variance. We\nshow that both algorithms achieve the complexity of\n$\\mathcal{O}(\\epsilon^{-1.5})$, which outperforms all existing algorithms by\nthe order of magnitude. Our experiments validate our theoretical results and\ndemonstrate the superior empirical performance of our algorithms in\nhyperparameter applications. Our codes for MRBO, VRBO and other benchmarks are\navailable $\\text{online}^1$.",
          "link": "http://arxiv.org/abs/2106.04692",
          "publishedOn": "2021-06-10T01:56:46.854Z",
          "wordCount": 570,
          "title": "Provably Faster Algorithms for Bilevel Optimization. (arXiv:2106.04692v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04679",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1\">Qin Yang</a>",
          "description": "Distributed artificial intelligence (DAI) studies artificial intelligence\nentities working together to reason, plan, solve problems, organize behaviors\nand strategies, make collective decisions and learn. This Ph.D. research\nproposes a principled Multi-Agent Systems (MAS) cooperation framework,\nSelf-Adaptive Swarm System (SASS), to bridge the fourth level automation gap\nbetween perception, communication, planning, execution, decision-making, and\nlearning.",
          "link": "http://arxiv.org/abs/2106.04679",
          "publishedOn": "2021-06-10T01:56:46.837Z",
          "wordCount": 494,
          "title": "Self-Adaptive Swarm System (SASS). (arXiv:2106.04679v1 [cs.MA])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04590",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liew_S/0/1/0/all/0/1\">Seng Pei Liew</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takahashi_T/0/1/0/all/0/1\">Tsubasa Takahashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ueno_M/0/1/0/all/0/1\">Michihiko Ueno</a>",
          "description": "We propose a new framework of synthesizing data using deep generative models\nin a differentially private manner. Within our framework, sensitive data are\nsanitized with rigorous privacy guarantees in a one-shot fashion, such that\ntraining deep generative models is possible without re-using the original data.\nHence, no extra privacy costs or model constraints are incurred, in contrast to\npopular approaches such as Differentially Private Stochastic Gradient Descent\n(DP-SGD), which, among other issues, causes degradation in privacy guarantees\nas the training iteration increases. We demonstrate a realization of our\nframework by making use of the characteristic function and an adversarial\nre-weighting objective, which are of independent interest as well. Our proposal\nhas theoretical guarantees of performance, and empirical evaluations on\nmultiple datasets show that our approach outperforms other methods at\nreasonable levels of privacy.",
          "link": "http://arxiv.org/abs/2106.04590",
          "publishedOn": "2021-06-10T01:56:46.832Z",
          "wordCount": 572,
          "title": "PEARL: Data Synthesis via Private Embeddings and Adversarial Reconstruction Learning. (arXiv:2106.04590v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04624",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ravanelli_M/0/1/0/all/0/1\">Mirco Ravanelli</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Parcollet_T/0/1/0/all/0/1\">Titouan Parcollet</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Plantinga_P/0/1/0/all/0/1\">Peter Plantinga</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rouhe_A/0/1/0/all/0/1\">Aku Rouhe</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cornell_S/0/1/0/all/0/1\">Samuele Cornell</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lugosch_L/0/1/0/all/0/1\">Loren Lugosch</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Subakan_C/0/1/0/all/0/1\">Cem Subakan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dawalatabad_N/0/1/0/all/0/1\">Nauman Dawalatabad</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Heba_A/0/1/0/all/0/1\">Abdelwahab Heba</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhong_J/0/1/0/all/0/1\">Jianyuan Zhong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chou_J/0/1/0/all/0/1\">Ju-Chieh Chou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yeh_S/0/1/0/all/0/1\">Sung-Lin Yeh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fu_S/0/1/0/all/0/1\">Szu-Wei Fu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liao_C/0/1/0/all/0/1\">Chien-Feng Liao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rastorgueva_E/0/1/0/all/0/1\">Elena Rastorgueva</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Grondin_F/0/1/0/all/0/1\">Fran&#xe7;ois Grondin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Aris_W/0/1/0/all/0/1\">William Aris</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Na_H/0/1/0/all/0/1\">Hwidong Na</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gao_Y/0/1/0/all/0/1\">Yan Gao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mori_R/0/1/0/all/0/1\">Renato De Mori</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bengio_Y/0/1/0/all/0/1\">Yoshua Bengio</a>",
          "description": "SpeechBrain is an open-source and all-in-one speech toolkit. It is designed\nto facilitate the research and development of neural speech processing\ntechnologies by being simple, flexible, user-friendly, and well-documented.\nThis paper describes the core architecture designed to support several tasks of\ncommon interest, allowing users to naturally conceive, compare and share novel\nspeech processing pipelines. SpeechBrain achieves competitive or\nstate-of-the-art performance in a wide range of speech benchmarks. It also\nprovides training recipes, pretrained models, and inference scripts for popular\nspeech datasets, as well as tutorials which allow anyone with basic Python\nproficiency to familiarize themselves with speech technologies.",
          "link": "http://arxiv.org/abs/2106.04624",
          "publishedOn": "2021-06-10T01:56:46.799Z",
          "wordCount": 573,
          "title": "SpeechBrain: A General-Purpose Speech Toolkit. (arXiv:2106.04624v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04618",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bliek_L/0/1/0/all/0/1\">Laurens Bliek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guijt_A/0/1/0/all/0/1\">Arthur Guijt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karlsson_R/0/1/0/all/0/1\">Rickard Karlsson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verwer_S/0/1/0/all/0/1\">Sicco Verwer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weerdt_M/0/1/0/all/0/1\">Mathijs de Weerdt</a>",
          "description": "Surrogate algorithms such as Bayesian optimisation are especially designed\nfor black-box optimisation problems with expensive objectives, such as\nhyperparameter tuning or simulation-based optimisation. In the literature,\nthese algorithms are usually evaluated with synthetic benchmarks which are well\nestablished but have no expensive objective, and only on one or two real-life\napplications which vary wildly between papers. There is a clear lack of\nstandardisation when it comes to benchmarking surrogate algorithms on\nreal-life, expensive, black-box objective functions. This makes it very\ndifficult to draw conclusions on the effect of algorithmic contributions. A new\nbenchmark library, EXPObench, provides first steps towards such a\nstandardisation. The library is used to provide an extensive comparison of six\ndifferent surrogate algorithms on four expensive optimisation problems from\ndifferent real-life applications. This has led to new insights regarding the\nrelative importance of exploration, the evaluation time of the objective, and\nthe used model. A further contribution is that we make the algorithms and\nbenchmark problem instances publicly available, contributing to more uniform\nanalysis of surrogate algorithms. Most importantly, we include the performance\nof the six algorithms on all evaluated problem instances. This results in a\nunique new dataset that lowers the bar for researching new methods as the\nnumber of expensive evaluations required for comparison is significantly\nreduced.",
          "link": "http://arxiv.org/abs/2106.04618",
          "publishedOn": "2021-06-10T01:56:46.788Z",
          "wordCount": 655,
          "title": "EXPObench: Benchmarking Surrogate-based Optimisation Algorithms on Expensive Black-box Functions. (arXiv:2106.04618v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04516",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1\">Fan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barth_Maron_G/0/1/0/all/0/1\">Gabriel Barth-Maron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stanczyk_P/0/1/0/all/0/1\">Piotr Sta&#x144;czyk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoffman_M/0/1/0/all/0/1\">Matthew Hoffman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Siqi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kroiss_M/0/1/0/all/0/1\">Manuel Kroiss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pope_A/0/1/0/all/0/1\">Aedan Pope</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rrustemi_A/0/1/0/all/0/1\">Alban Rrustemi</a>",
          "description": "A major driver behind the success of modern machine learning algorithms has\nbeen their ability to process ever-larger amounts of data. As a result, the use\nof distributed systems in both research and production has become increasingly\nprevalent as a means to scale to this growing data. At the same time, however,\ndistributing the learning process can drastically complicate the implementation\nof even simple algorithms. This is especially problematic as many machine\nlearning practitioners are not well-versed in the design of distributed\nsystems, let alone those that have complicated communication topologies. In\nthis work we introduce Launchpad, a programming model that simplifies the\nprocess of defining and launching distributed systems that is specifically\ntailored towards a machine learning audience. We describe our framework, its\ndesign philosophy and implementation, and give a number of examples of common\nlearning algorithms whose designs are greatly simplified by this approach.",
          "link": "http://arxiv.org/abs/2106.04516",
          "publishedOn": "2021-06-10T00:27:39.761Z",
          "wordCount": 595,
          "title": "Launchpad: A Programming Model for Distributed Machine Learning Research. (arXiv:2106.04516v1 [cs.DC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00772",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khodadadian_S/0/1/0/all/0/1\">Sajad Khodadadian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nafea_M/0/1/0/all/0/1\">Mohamed Nafea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghassami_A/0/1/0/all/0/1\">AmirEmad Ghassami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiyavash_N/0/1/0/all/0/1\">Negar Kiyavash</a>",
          "description": "Machine learning algorithms are increasingly used for consequential decision\nmaking regarding individuals based on their relevant features. Features that\nare relevant for accurate decisions may however lead to either explicit or\nimplicit forms of discrimination against unprivileged groups, such as those of\ncertain race or gender. This happens due to existing biases in the training\ndata, which are often replicated or even exacerbated by the learning algorithm.\nIdentifying and measuring these biases at the data level is a challenging\nproblem due to the interdependence among the features, and the decision\noutcome. In this work, we develop a framework for fairness-aware feature\nselection which takes into account the correlation among the features and the\ndecision outcome, and is based on information theoretic measures for the\naccuracy and discriminatory impacts of features. In particular, we first\npropose information theoretic measures which quantify the impact of different\nsubsets of features on the accuracy and discrimination of the decision\noutcomes. We then deduce the marginal impact of each feature using Shapley\nvalue function; a solution concept in cooperative game theory used to estimate\nmarginal contributions of players in a coalitional game. Finally, we design a\nfairness utility score for each feature (for feature selection) which\nquantifies how this feature influences accurate as well as nondiscriminatory\ndecisions. Our framework depends on the joint statistics of the data rather\nthan a particular classifier design. We examine our proposed framework on real\nand synthetic data to evaluate its performance.",
          "link": "http://arxiv.org/abs/2106.00772",
          "publishedOn": "2021-06-09T22:43:50.610Z",
          "wordCount": 696,
          "title": "Information Theoretic Measures for Fairness-aware Feature Selection. (arXiv:2106.00772v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.08826",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wickramasinghe_U/0/1/0/all/0/1\">Udaranga Wickramasinghe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Knott_G/0/1/0/all/0/1\">Graham Knott</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fua_P/0/1/0/all/0/1\">Pascal Fua</a>",
          "description": "Active Surface Models have a long history of being useful to model complex 3D\nsurfaces but only Active Contours have been used in conjunction with deep\nnetworks, and then only to produce the data term as well as meta-parameter maps\ncontrolling them. In this paper, we advocate a much tighter integration. We\nintroduce layers that implement them that can be integrated seamlessly into\nGraph Convolutional Networks to enforce sophisticated smoothness priors at an\nacceptable computational cost. We will show that the resulting Deep Active\nSurface Models outperform equivalent architectures that use traditional\nregularization loss terms to impose smoothness priors for 3D surface\nreconstruction from 2D images and for 3D volume segmentation.",
          "link": "http://arxiv.org/abs/2011.08826",
          "publishedOn": "2021-06-09T22:43:50.598Z",
          "wordCount": 599,
          "title": "Deep Active Surface Models. (arXiv:2011.08826v5 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.00958",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Almeida_D/0/1/0/all/0/1\">Diogo Almeida</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Winter_C/0/1/0/all/0/1\">Clemens Winter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jie Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaremba_W/0/1/0/all/0/1\">Wojciech Zaremba</a>",
          "description": "A core issue with learning to optimize neural networks has been the lack of\ngeneralization to real world problems. To address this, we describe a system\ndesigned from a generalization-first perspective, learning to update optimizer\nhyperparameters instead of model parameters directly using novel features,\nactions, and a reward function. This system outperforms Adam at all neural\nnetwork tasks including on modalities not seen during training. We achieve 2x\nspeedups on ImageNet, and a 2.5x speedup on a language modeling task using over\n5 orders of magnitude more compute than the training tasks.",
          "link": "http://arxiv.org/abs/2106.00958",
          "publishedOn": "2021-06-09T22:43:50.588Z",
          "wordCount": 544,
          "title": "A Generalizable Approach to Learning Optimizers. (arXiv:2106.00958v2 [cs.LG] UPDATED)"
        }
      ]
    }
  ],
  "cliVersion": "1.10.2"
}