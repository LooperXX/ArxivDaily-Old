{
  "sources": [
    {
      "title": "cs.LG updates on arXiv.org",
      "feedUrl": "http://export.arxiv.org/rss/cs.LG",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2105.09855",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ramesh_L/0/1/0/all/0/1\">Lekshmi Ramesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murthy_C/0/1/0/all/0/1\">Chandra R. Murthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tyagi_H/0/1/0/all/0/1\">Himanshu Tyagi</a>",
          "description": "In the problem of multiple support recovery, we are given access to linear\nmeasurements of multiple sparse samples in $\\mathbb{R}^{d}$. These samples can\nbe partitioned into $\\ell$ groups, with samples having the same support\nbelonging to the same group. For a given budget of $m$ measurements per sample,\nthe goal is to recover the $\\ell$ underlying supports, in the absence of the\nknowledge of group labels. We study this problem with a focus on the\nmeasurement-constrained regime where $m$ is smaller than the…",
          "link": "http://arxiv.org/abs/2105.09855",
          "publishedOn": "2021-05-22T06:24:29.909Z",
          "wordCount": 591,
          "title": "Multiple Support Recovery Using Very Few Measurements Per Sample. (arXiv:2105.09855v1 [cs.IT])"
        },
        {
          "id": "http://arxiv.org/abs/2010.10391",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Michalopoulos_G/0/1/0/all/0/1\">George Michalopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuanxin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaka_H/0/1/0/all/0/1\">Hussam Kaka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Helen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_A/0/1/0/all/0/1\">Alexander Wong</a>",
          "description": "Contextual word embedding models, such as BioBERT and Bio_ClinicalBERT, have\nachieved state-of-the-art results in biomedical natural language processing\ntasks by focusing their pre-training process on domain-specific corpora.\nHowever, such models do not take into consideration expert domain knowledge.\n\nIn this work, we introduced UmlsBERT, a contextual embedding model that\nintegrates domain knowledge during the pre-training process via a novel\nknowledge augmentation strategy. More specifically, the augmenta…",
          "link": "http://arxiv.org/abs/2010.10391",
          "publishedOn": "2021-05-22T06:24:29.878Z",
          "wordCount": 642,
          "title": "UmlsBERT: Clinical Domain Knowledge Augmentation of Contextual Embeddings Using the Unified Medical Language System Metathesaurus. (arXiv:2010.10391v4 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09900",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Giovanini_L/0/1/0/all/0/1\">Luiz Giovanini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ceschin_F/0/1/0/all/0/1\">Fabr&#xed;cio Ceschin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silva_M/0/1/0/all/0/1\">Mirela Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1\">Aokun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulkarni_R/0/1/0/all/0/1\">Ramchandra Kulkarni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Banda_S/0/1/0/all/0/1\">Sanjay Banda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lysaght_M/0/1/0/all/0/1\">Madison Lysaght</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_H/0/1/0/all/0/1\">Heng Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sapountzis_N/0/1/0/all/0/1\">Nikolaos Sapountzis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1\">Ruimin Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matthews_B/0/1/0/all/0/1\">Brandon Matthews</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1\">Dapeng Oliver Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gregio_A/0/1/0/all/0/1\">Andr&#xe9; Gr&#xe9;gio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oliveira_D/0/1/0/all/0/1\">Daniela Oliveira</a>",
          "description": "This paper investigates whether computer usage profiles comprised of\nprocess-, network-, mouse- and keystroke-related events are unique and\ntemporally consistent in a naturalistic setting, discussing challenges and\nopportunities of using such profiles in applications of continuous\nauthentication. We collected ecologically-valid computer usage profiles from 28\nMS Windows 10 computer users over 8 weeks and submitted this data to\ncomprehensive machine learning analysis involving a diverse set of online and\noff…",
          "link": "http://arxiv.org/abs/2105.09900",
          "publishedOn": "2021-05-22T06:24:29.870Z",
          "wordCount": 613,
          "title": "Computer Users Have Unique Yet Temporally Inconsistent Computer Usage Profiles. (arXiv:2105.09900v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.08869",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1\">Tianchen Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jia Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_C/0/1/0/all/0/1\">Chaosheng Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1\">Jingyuan Deng</a>",
          "description": "In this paper, we investigate a new multi-armed bandit (MAB) online learning\nmodel that considers real-world phenomena in many recommender systems: (i) the\nlearning agent cannot pull the arms by itself and thus has to offer rewards to\nusers to incentivize arm-pulling indirectly; and (ii) if users with specific\narm preferences are well rewarded, they induce a \"self-reinforcing\" effect in\nthe sense that they will attract more users of similar arm preferences. Besides\naddressing the tradeoff of exploration and…",
          "link": "http://arxiv.org/abs/2105.08869",
          "publishedOn": "2021-05-22T06:24:29.717Z",
          "wordCount": 672,
          "title": "Incentivized Bandit Learning with Self-Reinforcing User Preferences. (arXiv:2105.08869v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09903",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Madan_M/0/1/0/all/0/1\">Manav Madan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jakob_P/0/1/0/all/0/1\">Peter Jakob</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmid_Schirling_T/0/1/0/all/0/1\">Tobias Schmid-Schirling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valada_A/0/1/0/all/0/1\">Abhinav Valada</a>",
          "description": "Multi-view classification is inspired by the behavior of humans, especially\nwhen fine-grained features or in our case rarely occurring anomalies are to be\ndetected. Current contributions point to the problem of how high-dimensional\ndata can be fused. In this work, we build upon the deep support vector data\ndescription algorithm and address multi-perspective anomaly detection using\nthree different fusion techniques i.e. early fusion, late fusion, and late\nfusion with multiple decoders. We employ different au…",
          "link": "http://arxiv.org/abs/2105.09903",
          "publishedOn": "2021-05-22T06:24:29.711Z",
          "wordCount": 633,
          "title": "Multi-Perspective Anomaly Detection. (arXiv:2105.09903v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.08506",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ahmed_S/0/1/0/all/0/1\">Sara Atito Ali Ahmed</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yavuz_M/0/1/0/all/0/1\">Mehmet Can Yavuz</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sen_M/0/1/0/all/0/1\">Mehmet Umut Sen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gulsen_F/0/1/0/all/0/1\">Fatih Gulsen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tutar_O/0/1/0/all/0/1\">Onur Tutar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Korkmazer_B/0/1/0/all/0/1\">Bora Korkmazer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Samanci_C/0/1/0/all/0/1\">Cesur Samanci</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sirolu_S/0/1/0/all/0/1\">Sabri Sirolu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hamid_R/0/1/0/all/0/1\">Rauf Hamid</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Eryurekli_A/0/1/0/all/0/1\">Ali Ergun Eryurekli</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mammadov_T/0/1/0/all/0/1\">Toghrul Mammadov</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yanikoglu_B/0/1/0/all/0/1\">Berrin Yanikoglu</a>",
          "description": "Detecting COVID-19 in computed tomography (CT) or radiography images has been\nproposed as a supplement to the definitive RT-PCR test. We present a deep\nlearning ensemble for detecting COVID-19 infection, combining slice-based (2D)\nand volume-based (3D) approaches. The 2D system detects the infection on each\nCT slice independently, combining them to obtain the patient-level decision via\ndifferent methods (averaging and long-short term memory networks). The 3D\nsystem takes the whole CT volume to arrive to the…",
          "link": "http://arxiv.org/abs/2105.08506",
          "publishedOn": "2021-05-22T06:24:29.704Z",
          "wordCount": 693,
          "title": "COVID-19 Detection in Computed Tomography Images with 2D and 3D Approaches. (arXiv:2105.08506v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.10683",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Koeppe_A/0/1/0/all/0/1\">Arnd Koeppe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bamer_F/0/1/0/all/0/1\">Franz Bamer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Selzer_M/0/1/0/all/0/1\">Michael Selzer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nestler_B/0/1/0/all/0/1\">Britta Nestler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Markert_B/0/1/0/all/0/1\">Bernd Markert</a>",
          "description": "(Artificial) neural networks have become increasingly popular in mechanics as\nmeans to accelerate computations with model order reduction techniques and as\nuniversal models for a wide variety of materials. However, the major\ndisadvantage of neural networks remains: their numerous parameters are\nchallenging to interpret and explain. Thus, neural networks are often labeled\nas black boxes, and their results often elude human interpretation. In\nmechanics, the new and active field of physics-informed neural netw…",
          "link": "http://arxiv.org/abs/2104.10683",
          "publishedOn": "2021-05-22T06:24:29.650Z",
          "wordCount": 713,
          "title": "Explainable artificial intelligence for mechanics: physics-informing neural networks for constitutive models. (arXiv:2104.10683v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.09342",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xiaohang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1\">Hao Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Lichao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhuiyan_M/0/1/0/all/0/1\">Md Zakirul Alam Bhuiyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lianzhong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1\">Lifang He</a>",
          "description": "Depression is one of the most common mental illness problems, and the\nsymptoms shown by patients are not consistent, making it difficult to diagnose\nin the process of clinical practice and pathological research. Although\nresearchers hope that artificial intelligence can contribute to the diagnosis\nand treatment of depression, the traditional centralized machine learning needs\nto aggregate patient data, and the data privacy of patients with mental illness\nneeds to be strictly confidential, which hinders mach…",
          "link": "http://arxiv.org/abs/2102.09342",
          "publishedOn": "2021-05-22T06:24:29.629Z",
          "wordCount": 672,
          "title": "FedMood: Federated Learning on Mobile Health Data for Mood Detection. (arXiv:2102.09342v6 [cs.CY] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.07662",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1\">Yuqing Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watkins_O/0/1/0/all/0/1\">Olivia Watkins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Darrell_T/0/1/0/all/0/1\">Trevor Darrell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1\">Pieter Abbeel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pathak_D/0/1/0/all/0/1\">Deepak Pathak</a>",
          "description": "Policies trained in simulation often fail when transferred to the real world\ndue to the `reality gap' where the simulator is unable to accurately capture\nthe dynamics and visual properties of the real world. Current approaches to\ntackle this problem, such as domain randomization, require prior knowledge and\nengineering to determine how much to randomize system parameters in order to\nlearn a policy that is robust to sim-to-real transfer while also not being too\nconservative. We propose a method for automatic…",
          "link": "http://arxiv.org/abs/2104.07662",
          "publishedOn": "2021-05-22T06:24:29.611Z",
          "wordCount": 681,
          "title": "Auto-Tuned Sim-to-Real Transfer. (arXiv:2104.07662v2 [cs.RO] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.02372",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Greenberg_I/0/1/0/all/0/1\">Ido Greenberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yannay_N/0/1/0/all/0/1\">Netanel Yannay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mannor_S/0/1/0/all/0/1\">Shie Mannor</a>",
          "description": "Determining the noise parameters of a Kalman Filter (KF) has been studied for\ndecades. A huge body of research focuses on the task of estimation of the noise\nunder various conditions, since precise noise estimation is considered\nequivalent to minimization of the filtering errors. However, we show that even\na small violation of the KF assumptions can significantly modify the effective\nnoise, breaking the equivalence between the tasks and making noise estimation\nan inferior strategy. We show that such violati…",
          "link": "http://arxiv.org/abs/2104.02372",
          "publishedOn": "2021-05-22T06:24:29.601Z",
          "wordCount": 689,
          "title": "Noise Estimation Is Not Optimal: How to Use Kalman Filter the Right Way. (arXiv:2104.02372v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.02331",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ben_Basat_R/0/1/0/all/0/1\">Ran Ben-Basat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitzenmacher_M/0/1/0/all/0/1\">Michael Mitzenmacher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vargaftik_S/0/1/0/all/0/1\">Shay Vargaftik</a>",
          "description": "We consider the fundamental problem of communicating an estimate of a real\nnumber $x\\in[0,1]$ using a single bit. A sender that knows $x$ chooses a value\n$X\\in\\set{0,1}$ to transmit. In turn, a receiver estimates $x$ based on the\nvalue of $X$. We consider both the biased and unbiased estimation problems and\naim to minimize the cost. For the biased case, the cost is the worst-case (over\nthe choice of $x$) expected squared error, which coincides with the variance if\nthe algorithm is required to be unbiased.\n\n…",
          "link": "http://arxiv.org/abs/2010.02331",
          "publishedOn": "2021-05-22T06:24:29.549Z",
          "wordCount": 664,
          "title": "How to send a real number using a single bit (and some shared randomness). (arXiv:2010.02331v4 [cs.DS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.00359",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pan_C/0/1/0/all/0/1\">Chenjian Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_C/0/1/0/all/0/1\">Chen Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1\">Hongjin He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_L/0/1/0/all/0/1\">Liqun Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yanwei Xu</a>",
          "description": "Tensor completion refers to the task of estimating the missing data from an\nincomplete measurement or observation, which is a core problem frequently\narising from the areas of big data analysis, computer vision, and network\nengineering. Due to the multidimensional nature of high-order tensors, the\nmatrix approaches, e.g., matrix factorization and direct matricization of\ntensors, are often not ideal for tensor completion and recovery. In this paper,\nwe introduce a unified low-rank and sparse enhanced Tucker …",
          "link": "http://arxiv.org/abs/2010.00359",
          "publishedOn": "2021-05-22T06:24:29.543Z",
          "wordCount": 699,
          "title": "Low-Rank and Sparse Enhanced Tucker Decomposition for Tensor Completion. (arXiv:2010.00359v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.08413",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Feng_R/0/1/0/all/0/1\">Ruimin Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jiayi Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">He Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1\">Baofeng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jie Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yuting Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Ming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chunlei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuyao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_J/0/1/0/all/0/1\">Jie Zhuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_H/0/1/0/all/0/1\">Hongjiang Wei</a>",
          "description": "Quantitative susceptibility mapping (QSM) has demonstrated great potential in\nquantifying tissue susceptibility in various brain diseases. However, the\nintrinsic ill-posed inverse problem relating the tissue phase to the underlying\nsusceptibility distribution affects the accuracy for quantifying tissue\nsusceptibility. Recently, deep learning has shown promising results to improve\naccuracy by reducing the streaking artifacts. However, there exists a mismatch\nbetween the observed phase and the theoretical for…",
          "link": "http://arxiv.org/abs/2101.08413",
          "publishedOn": "2021-05-22T06:24:29.536Z",
          "wordCount": 660,
          "title": "MoDL-QSM: Model-based Deep Learning for Quantitative Susceptibility Mapping. (arXiv:2101.08413v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.04350",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Zheng_L/0/1/0/all/0/1\">Liangzhen Zheng</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Lan_H/0/1/0/all/0/1\">Haidong Lan</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Shen_T/0/1/0/all/0/1\">Tao Shen</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Wu_J/0/1/0/all/0/1\">Jiaxiang Wu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Wang_S/0/1/0/all/0/1\">Sheng Wang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Liu_W/0/1/0/all/0/1\">Wei Liu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Huang_J/0/1/0/all/0/1\">Junzhou Huang</a>",
          "description": "Proteins structure prediction has long been a grand challenge over the past\n50 years, owing to its board scientific and application interests. There are\ntwo major types of modelling algorithm, template-free modelling and\ntemplate-based modelling, which is suitable for easy prediction tasks, and is\nwidely adopted in computer aided drug discoveries for drug design and\nscreening. Although it has been several decades since its first edition, the\ncurrent template-based modeling approach suffers from two importan…",
          "link": "http://arxiv.org/abs/2105.04350",
          "publishedOn": "2021-05-22T06:24:29.527Z",
          "wordCount": 649,
          "title": "tFold-TR: Combining Deep Learning Enhanced Hybrid Potential Energy for Template-Based Modelling Structure Refinement. (arXiv:2105.04350v2 [physics.bio-ph] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.03814",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Autthasan_P/0/1/0/all/0/1\">Phairot Autthasan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chaisaen_R/0/1/0/all/0/1\">Rattanaphon Chaisaen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sudhawiyangkul_T/0/1/0/all/0/1\">Thapanun Sudhawiyangkul</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rangpong_P/0/1/0/all/0/1\">Phurin Rangpong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kiatthaveephong_S/0/1/0/all/0/1\">Suktipol Kiatthaveephong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dilokthanakul_N/0/1/0/all/0/1\">Nat Dilokthanakul</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bhakdisongkhram_G/0/1/0/all/0/1\">Gun Bhakdisongkhram</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Phan_H/0/1/0/all/0/1\">Huy Phan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Guan_C/0/1/0/all/0/1\">Cuntai Guan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wilaiprasitporn_T/0/1/0/all/0/1\">Theerawit Wilaiprasitporn</a>",
          "description": "Advances in the motor imagery (MI)-based brain-computer interfaces (BCIs)\nallow control of several applications by decoding neurophysiological phenomena,\nwhich are usually recorded by electroencephalography (EEG) using a non-invasive\ntechnique. Despite great advances in MI-based BCI, EEG rhythms are specific to\na subject and various changes over time. These issues point to significant\nchallenges to enhance the classification performance, especially in a\nsubject-independent manner. To overcome these challeng…",
          "link": "http://arxiv.org/abs/2102.03814",
          "publishedOn": "2021-05-22T06:24:29.521Z",
          "wordCount": 664,
          "title": "MIN2Net: End-to-End Multi-Task Learning for Subject-Independent Motor Imagery EEG Classification. (arXiv:2102.03814v3 [eess.SP] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.10718",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Rangi_A/0/1/0/all/0/1\">Anshuka Rangi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Khojasteh_M/0/1/0/all/0/1\">Mohammad Javad Khojasteh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Franceschetti_M/0/1/0/all/0/1\">Massimo Franceschetti</a>",
          "description": "We study the problem of learning-based attacks in linear systems, where the\ncommunication channel between the controller and the plant can be hijacked by a\nmalicious attacker. We assume the attacker learns the dynamics of the system\nfrom observations, then overrides the controller's actuation signal, while\nmimicking legitimate operation by providing fictitious sensor readings to the\ncontroller. On the other hand, the controller is on a lookout to detect the\npresence of the attacker and tries to enhance the …",
          "link": "http://arxiv.org/abs/2011.10718",
          "publishedOn": "2021-05-22T06:24:29.513Z",
          "wordCount": 720,
          "title": "Learning-based attacks in Cyber-Physical Systems: Exploration, Detection, and Control Cost trade-offs. (arXiv:2011.10718v2 [eess.SY] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.05600",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xi_D/0/1/0/all/0/1\">Dongbo Xi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_B/0/1/0/all/0/1\">Bowen Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_F/0/1/0/all/0/1\">Fuzhen Zhuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yongchun Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Shuai Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tianyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_Y/0/1/0/all/0/1\">Yuan Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Q/0/1/0/all/0/1\">Qing He</a>",
          "description": "With the explosive growth of e-commerce, online transaction fraud has become\none of the biggest challenges for e-commerce platforms. The historical\nbehaviors of users provide rich information for digging into the users' fraud\nrisk. While considerable efforts have been made in this direction, a\nlong-standing challenge is how to effectively exploit internal user information\nand provide explainable prediction results. In fact, the value variations of\nsame field from different events and the interactions of dif…",
          "link": "http://arxiv.org/abs/2008.05600",
          "publishedOn": "2021-05-22T06:24:29.497Z",
          "wordCount": 673,
          "title": "Modeling the Field Value Variations and Field Interactions Simultaneously for Fraud Detection. (arXiv:2008.05600v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.10241",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1\">Dapeng Zhao</a>",
          "description": "Thesis document of the degree of Master of Science in Robotics of Carnegie\nMellon University School of Computer Science.",
          "link": "http://arxiv.org/abs/2104.10241",
          "publishedOn": "2021-05-22T06:24:29.490Z",
          "wordCount": 465,
          "title": "Predicting Human Trajectories by Learning and Matching Patterns. (arXiv:2104.10241v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.05996",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ranasinghe_T/0/1/0/all/0/1\">Tharindu Ranasinghe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zampieri_M/0/1/0/all/0/1\">Marcos Zampieri</a>",
          "description": "Offensive content is pervasive in social media and a reason for concern to\ncompanies and government organizations. Several studies have been recently\npublished investigating methods to detect the various forms of such content\n(e.g. hate speech, cyberbullying, and cyberaggression). The clear majority of\nthese studies deal with English partially because most annotated datasets\navailable contain English data. In this paper, we take advantage of available\nEnglish datasets by applying cross-lingual contextual wo…",
          "link": "http://arxiv.org/abs/2105.05996",
          "publishedOn": "2021-05-22T06:24:29.484Z",
          "wordCount": 695,
          "title": "Multilingual Offensive Language Identification for Low-resource Languages. (arXiv:2105.05996v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.02694",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Perugachi_Diaz_Y/0/1/0/all/0/1\">Yura Perugachi-Diaz</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tomczak_J/0/1/0/all/0/1\">Jakub M. Tomczak</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bhulai_S/0/1/0/all/0/1\">Sandjai Bhulai</a>",
          "description": "We introduce Invertible Dense Networks (i-DenseNets), a more parameter\nefficient extension of Residual Flows. The method relies on an analysis of the\nLipschitz continuity of the concatenation in DenseNets, where we enforce\ninvertibility of the network by satisfying the Lipschitz constant. Furthermore,\nwe propose a learnable weighted concatenation, which not only improves the\nmodel performance but also indicates the importance of the concatenated\nweighted representation. Additionally, we introduce the Concat…",
          "link": "http://arxiv.org/abs/2102.02694",
          "publishedOn": "2021-05-22T06:24:29.467Z",
          "wordCount": 588,
          "title": "Invertible DenseNets with Concatenated LipSwish. (arXiv:2102.02694v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.05737",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zili Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valentino_M/0/1/0/all/0/1\">Marco Valentino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Landers_D/0/1/0/all/0/1\">Donal Landers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freitas_A/0/1/0/all/0/1\">Andre Freitas</a>",
          "description": "This paper describes N-XKT (Neural encoding based on eXplanatory Knowledge\nTransfer), a novel method for the automatic transfer of explanatory knowledge\nthrough neural encoding mechanisms. We demonstrate that N-XKT is able to\nimprove accuracy and generalization on science Question Answering (QA).\nSpecifically, by leveraging facts from background explanatory knowledge\ncorpora, the N-XKT model shows a clear improvement on zero-shot QA.\nFurthermore, we show that N-XKT can be fine-tuned on a target QA dataset,\n…",
          "link": "http://arxiv.org/abs/2105.05737",
          "publishedOn": "2021-05-22T06:24:29.460Z",
          "wordCount": 554,
          "title": "Encoding Explanatory Knowledge for Zero-shot Science Question Answering. (arXiv:2105.05737v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.14958",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kefato_Z/0/1/0/all/0/1\">Zekarias T. Kefato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Girdzijauskas_S/0/1/0/all/0/1\">Sarunas Girdzijauskas</a>",
          "description": "Real world data is mostly unlabeled or only few instances are labeled.\nManually labeling data is a very expensive and daunting task. This calls for\nunsupervised learning techniques that are powerful enough to achieve comparable\nresults as semi-supervised/supervised techniques. Contrastive self-supervised\nlearning has emerged as a powerful direction, in some cases outperforming\nsupervised techniques. In this study, we propose, SelfGNN, a novel contrastive\nself-supervised graph neural network (GNN) without re…",
          "link": "http://arxiv.org/abs/2103.14958",
          "publishedOn": "2021-05-22T06:24:29.451Z",
          "wordCount": 666,
          "title": "Self-supervised Graph Neural Networks without explicit negative sampling. (arXiv:2103.14958v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.07495",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Majdabadi_M/0/1/0/all/0/1\">Mahdiyar Molahasani Majdabadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Younhee Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deivalakshmi_S/0/1/0/all/0/1\">S. Deivalakshmi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ko_S/0/1/0/all/0/1\">Seokbum Ko</a>",
          "description": "Prostate cancer is a very common disease among adult men. One in seven\nCanadian men is diagnosed with this cancer in their lifetime. Super-Resolution\n(SR) can facilitate early diagnosis and potentially save many lives. In this\npaper, a robust and accurate model is proposed for prostate MRI SR. The model\nis trained on the Prostate-Diagnosis and PROSTATEx datasets. The proposed model\noutperformed the state-of-the-art prostate SR model in all similarity metrics\nwith notable margins. A new task-specific similar…",
          "link": "http://arxiv.org/abs/2105.07495",
          "publishedOn": "2021-05-22T06:24:29.445Z",
          "wordCount": 573,
          "title": "Capsule GAN for Prostate MRI Super-Resolution. (arXiv:2105.07495v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.01059",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Paletta_Q/0/1/0/all/0/1\">Quentin Paletta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lasenby_J/0/1/0/all/0/1\">Joan Lasenby</a>",
          "description": "Improving irradiance forecasting is critical to further increase the share of\nsolar in the energy mix. On a short time scale, fish-eye cameras on the ground\nare used to capture cloud displacements causing the local variability of the\nelectricity production. As most of the solar radiation comes directly from the\nSun, current forecasting approaches use its position in the image as a\nreference to interpret the cloud cover dynamics. However, existing Sun tracking\nmethods rely on external data and a calibration …",
          "link": "http://arxiv.org/abs/2012.01059",
          "publishedOn": "2021-05-22T06:24:29.439Z",
          "wordCount": 634,
          "title": "A Temporally Consistent Image-based Sun Tracking Algorithm for Solar Energy Forecasting Applications. (arXiv:2012.01059v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09917",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Beknazaryan_A/0/1/0/all/0/1\">Aleksandr Beknazaryan</a>",
          "description": "An example of an activation function $\\sigma$ is given such that networks\nwith activations $\\{\\sigma, \\lfloor\\cdot\\rfloor\\}$, integer weights and a fixed\narchitecture depending on $d$ approximate continuous functions on $[0,1]^d$.\nThe range of integer weights required for $\\varepsilon$-approximation of\nH\\\"older continuous functions is derived, which leads to a convergence rate of\norder $n^{\\frac{-2\\beta}{2\\beta+d}}\\log_2n$ for neural network regression\nestimation of unknown $\\beta$-H\\\"older continuous funct…",
          "link": "http://arxiv.org/abs/2105.09917",
          "publishedOn": "2021-05-22T06:24:29.431Z",
          "wordCount": 489,
          "title": "Neural networks with superexpressive activations and integer weights. (arXiv:2105.09917v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2105.06129",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1\">Aaditya Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hingane_S/0/1/0/all/0/1\">Shreeshail Hingane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_X/0/1/0/all/0/1\">Xinyu Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhangyang Wang</a>",
          "description": "Artistic style transfer aims to transfer the style characteristics of one\nimage onto another image while retaining its content. Existing approaches\ncommonly leverage various normalization techniques, although these face\nlimitations in adequately transferring diverse textures to different spatial\nlocations. Self-Attention-based approaches have tackled this issue with partial\nsuccess but suffer from unwanted artifacts. Motivated by these observations,\nthis paper aims to combine the best of both worlds: self-a…",
          "link": "http://arxiv.org/abs/2105.06129",
          "publishedOn": "2021-05-22T06:24:29.424Z",
          "wordCount": 616,
          "title": "SAFIN: Arbitrary Style Transfer With Self-Attentive Factorized Instance Normalization. (arXiv:2105.06129v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.03514",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dai_W/0/1/0/all/0/1\">Wang-Zhou Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muggleton_S/0/1/0/all/0/1\">Stephen H. Muggleton</a>",
          "description": "For many reasoning-heavy tasks involving raw inputs, it is challenging to\ndesign an appropriate end-to-end learning pipeline. Neuro-Symbolic Learning,\ndivide the process into sub-symbolic perception and symbolic reasoning, trying\nto utilise data-driven machine learning and knowledge-driven reasoning\nsimultaneously. However, they suffer from the exponential computational\ncomplexity within the interface between these two components, where the\nsub-symbolic learning model lacks direct supervision, and the symbo…",
          "link": "http://arxiv.org/abs/2010.03514",
          "publishedOn": "2021-05-22T06:24:29.418Z",
          "wordCount": 639,
          "title": "Abductive Knowledge Induction From Raw Data. (arXiv:2010.03514v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.05089",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cachay_S/0/1/0/all/0/1\">Salva R&#xfc;hling Cachay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erickson_E/0/1/0/all/0/1\">Emma Erickson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bucker_A/0/1/0/all/0/1\">Arthur Fender C. Bucker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pokropek_E/0/1/0/all/0/1\">Ernest Pokropek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potosnak_W/0/1/0/all/0/1\">Willa Potosnak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bire_S/0/1/0/all/0/1\">Suyash Bire</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Osei_S/0/1/0/all/0/1\">Salomey Osei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lutjens_B/0/1/0/all/0/1\">Bj&#xf6;rn L&#xfc;tjens</a>",
          "description": "Deep learning-based models have recently outperformed state-of-the-art\nseasonal forecasting models, such as for predicting El Ni\\~no-Southern\nOscillation (ENSO). However, current deep learning models are based on\nconvolutional neural networks which are difficult to interpret and can fail to\nmodel large-scale atmospheric patterns. In comparison, graph neural networks\n(GNNs) are capable of modeling large-scale spatial dependencies and are more\ninterpretable due to the explicit modeling of information flow thr…",
          "link": "http://arxiv.org/abs/2104.05089",
          "publishedOn": "2021-05-22T06:24:29.404Z",
          "wordCount": 632,
          "title": "The World as a Graph: Improving El Ni\\~no Forecasts with Graph Neural Networks. (arXiv:2104.05089v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.05824",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Joseph_J/0/1/0/all/0/1\">Joel Joseph</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_A/0/1/0/all/0/1\">Alex Gu</a>",
          "description": "The Continual Learning (CL) problem involves performing well on a sequence of\ntasks under limited compute. Current algorithms in the domain are either slow,\noffline or sensitive to hyper-parameters. La-MAML, an optimization-based\nmeta-learning algorithm claims to be better than other replay-based,\nprior-based and meta-learning based approaches. According to the MER paper [1],\nmetrics to measure performance in the continual learning arena are Retained\nAccuracy (RA) and Backward Transfer-Interference (BTI). L…",
          "link": "http://arxiv.org/abs/2102.05824",
          "publishedOn": "2021-05-22T06:24:29.387Z",
          "wordCount": 550,
          "title": "Reproducibility Report: La-MAML: Look-ahead Meta Learning for Continual Learning. (arXiv:2102.05824v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.09657",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nishad_S/0/1/0/all/0/1\">Sunil Nishad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_S/0/1/0/all/0/1\">Shubhangi Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharya_A/0/1/0/all/0/1\">Arnab Bhattacharya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranu_S/0/1/0/all/0/1\">Sayan Ranu</a>",
          "description": "Majority of the existing graph neural networks (GNN) learn node embeddings\nthat encode their local neighborhoods but not their positions. Consequently,\ntwo nodes that are vastly distant but located in similar local neighborhoods\nmap to similar embeddings in those networks. This limitation prevents accurate\nperformance in predictive tasks that rely on position information. In this\npaper,we develop GraphReach, a position-aware inductive GNN that captures the\nglobal positions of nodes through reachability esti…",
          "link": "http://arxiv.org/abs/2008.09657",
          "publishedOn": "2021-05-22T06:24:29.361Z",
          "wordCount": 616,
          "title": "GraphReach: Position-Aware Graph Neural Network using Reachability Estimations. (arXiv:2008.09657v3 [cs.SI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2003.01383",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Hao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siebert_J/0/1/0/all/0/1\">Jan Paul Siebert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xiangrong Xu</a>",
          "description": "This paper proposes a novel automatically generating image masks method for\nthe state-of-the-art Mask R-CNN deep learning method. The Mask R-CNN method\nachieves the best results in object detection until now, however, it is very\ntime-consuming and laborious to get the object Masks for training, the proposed\nmethod is composed by a two-stage design, to automatically generating image\nmasks, the first stage implements a fully convolutional networks (FCN) based\nsegmentation network, the second stage network, a …",
          "link": "http://arxiv.org/abs/2003.01383",
          "publishedOn": "2021-05-22T06:24:29.354Z",
          "wordCount": 603,
          "title": "Fully Convolutional Networks for Automatically Generating Image Masks to Train Mask R-CNN. (arXiv:2003.01383v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.02995",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_J/0/1/0/all/0/1\">Jingyi Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhong_W/0/1/0/all/0/1\">Wenxuan Zhong</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ma_P/0/1/0/all/0/1\">Ping Ma</a>",
          "description": "Optimal transport has been one of the most exciting subjects in mathematics,\nstarting from the 18th century. As a powerful tool to transport between two\nprobability measures, optimal transport methods have been reinvigorated\nnowadays in a remarkable proliferation of modern data science applications. To\nmeet the big data challenges, various computational tools have been developed\nin the recent decade to accelerate the computation for optimal transport\nmethods. In this review, we present some cutting-edge com…",
          "link": "http://arxiv.org/abs/2008.02995",
          "publishedOn": "2021-05-22T06:24:29.332Z",
          "wordCount": 566,
          "title": "A Review on Modern Computational Optimal Transport Methods with Applications in Biomedical Research. (arXiv:2008.02995v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.00685",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Marvin_D/0/1/0/all/0/1\">Dario Marvin</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Nespoli_L/0/1/0/all/0/1\">Lorenzo Nespoli</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Strepparava_D/0/1/0/all/0/1\">Davide Strepparava</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Medici_V/0/1/0/all/0/1\">Vasco Medici</a>",
          "description": "The ability to forecast the concentration of air pollutants in an urban\nregion is crucial for decision-makers wishing to reduce the impact of pollution\non public health through active measures (e.g. temporary traffic closures). In\nthis study, we present a machine learning approach applied to the forecast of\nthe day-ahead maximum value of the ozone concentration for several geographical\nlocations in southern Switzerland. Due to the low density of measurement\nstations and to the complex orography of the use c…",
          "link": "http://arxiv.org/abs/2012.00685",
          "publishedOn": "2021-05-22T06:24:29.323Z",
          "wordCount": 629,
          "title": "A data-driven approach to the forecasting of ground-level ozone concentration. (arXiv:2012.00685v3 [physics.ao-ph] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.06284",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Tikhonov_A/0/1/0/all/0/1\">Alexey Tikhonov</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yamshchikov_I/0/1/0/all/0/1\">Ivan P. Yamshchikov</a>",
          "description": "This paper addresses the issue of long-scale correlations that is\ncharacteristic for symbolic music and is a challenge for modern generative\nalgorithms. It suggests a very simple workaround for this challenge, namely,\ngeneration of a drum pattern that could be further used as a foundation for\nmelody generation. The paper presents a large dataset of drum patterns\nalongside with corresponding melodies. It explores two possible methods for\ndrum pattern generation. Exploring a latent space of drum patterns one …",
          "link": "http://arxiv.org/abs/2007.06284",
          "publishedOn": "2021-05-22T06:24:29.301Z",
          "wordCount": 604,
          "title": "Artificial Neural Networks Jamming on the Beat. (arXiv:2007.06284v3 [eess.AS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.04785",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lutjens_B/0/1/0/all/0/1\">Bj&#xf6;rn L&#xfc;tjens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leshchinskiy_B/0/1/0/all/0/1\">Brandon Leshchinskiy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Requena_Mesa_C/0/1/0/all/0/1\">Christian Requena-Mesa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chishtie_F/0/1/0/all/0/1\">Farrukh Chishtie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diaz_Rodriguez_N/0/1/0/all/0/1\">Natalia D&#xed;az-Rodr&#xed;guez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boulais_O/0/1/0/all/0/1\">Oc&#xe9;ane Boulais</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sankaranarayanan_A/0/1/0/all/0/1\">Aruna Sankaranarayanan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pina_A/0/1/0/all/0/1\">Aaron Pi&#xf1;a</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gal_Y/0/1/0/all/0/1\">Yarin Gal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raissi_C/0/1/0/all/0/1\">Chedy Ra&#xef;ssi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lavin_A/0/1/0/all/0/1\">Alexander Lavin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Newman_D/0/1/0/all/0/1\">Dava Newman</a>",
          "description": "As climate change increases the intensity of natural disasters, society needs\nbetter tools for adaptation. Floods, for example, are the most frequent natural\ndisaster, and better tools for flood risk communication could increase the\nsupport for flood-resilient infrastructure development. Our work aims to enable\nmore visual communication of large-scale climate impacts via visualizing the\noutput of coastal flood models as satellite imagery. We propose the first deep\nlearning pipeline to ensure physical-consis…",
          "link": "http://arxiv.org/abs/2104.04785",
          "publishedOn": "2021-05-22T06:24:29.282Z",
          "wordCount": 685,
          "title": "Physically-Consistent Generative Adversarial Networks for Coastal Flood Visualization. (arXiv:2104.04785v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.00742",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Ziwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">Wenwu Zhu</a>",
          "description": "Machine learning on graphs has been extensively studied in both academic and\nindustry. However, as the literature on graph learning booms with a vast number\nof emerging methods and techniques, it becomes increasingly difficult to\nmanually design the optimal machine learning algorithm for different\ngraph-related tasks. To solve this critical challenge, automated machine\nlearning (AutoML) on graphs which combines the strength of graph machine\nlearning and AutoML together, is gaining attention from the researc…",
          "link": "http://arxiv.org/abs/2103.00742",
          "publishedOn": "2021-05-22T06:24:29.275Z",
          "wordCount": 625,
          "title": "Automated Machine Learning on Graphs: A Survey. (arXiv:2103.00742v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.08911",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yueyao Yu</a>",
          "description": "What makes an artificial neural network easier to train and more likely to\nproduce desirable solutions than other comparable networks? In this paper, we\nprovide a new angle to study such issues under the setting of a fixed number of\nmodel parameters which in general is the most dominant cost factor. We\nintroduce a notion of variability and show that it correlates positively to the\nactivation ratio and negatively to a phenomenon called {Collapse to Constants}\n(or C2C), which is closely related but not identi…",
          "link": "http://arxiv.org/abs/2105.08911",
          "publishedOn": "2021-05-22T06:24:29.253Z",
          "wordCount": 564,
          "title": "Variability of Artificial Neural Networks. (arXiv:2105.08911v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.04301",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhewei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1\">Linyue Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1\">Wenwen Yu</a>",
          "description": "Intrusion detection has been a key topic in the field of cyber security, and\nthe common network threats nowadays have the characteristics of varieties and\nvariation. Considering the serious imbalance of intrusion detection datasets\nwill result in low classification performance on attack behaviors of small\nsample size and difficulty to detect network attacks accurately and\nefficiently, using Adaptive Synthetic Sampling (ADASYN) method to balance\ndatasets was proposed in this paper. In addition, Random Forest…",
          "link": "http://arxiv.org/abs/2105.04301",
          "publishedOn": "2021-05-22T06:24:29.210Z",
          "wordCount": 615,
          "title": "ADASYN-Random Forest Based Intrusion Detection Model. (arXiv:2105.04301v3 [cs.CR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.13934",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hug_R/0/1/0/all/0/1\">Ronny Hug</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Becker_S/0/1/0/all/0/1\">Stefan Becker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hubner_W/0/1/0/all/0/1\">Wolfgang H&#xfc;bner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arens_M/0/1/0/all/0/1\">Michael Arens</a>",
          "description": "Methods to quantify the complexity of trajectory datasets are still a missing\npiece in benchmarking human trajectory prediction models. In order to gain a\nbetter understanding of the complexity of trajectory prediction tasks and\nfollowing the intuition, that more complex datasets contain more information,\nan approach for quantifying the amount of information contained in a dataset\nfrom a prototype-based dataset representation is proposed. The dataset\nrepresentation is obtained by first employing a non-trivi…",
          "link": "http://arxiv.org/abs/2005.13934",
          "publishedOn": "2021-05-22T06:24:29.201Z",
          "wordCount": 600,
          "title": "Quantifying the Complexity of Standard Benchmarking Datasets for Long-Term Human Trajectory Prediction. (arXiv:2005.13934v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.05525",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gou_J/0/1/0/all/0/1\">Jianping Gou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1\">Baosheng Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maybank_S/0/1/0/all/0/1\">Stephen John Maybank</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>",
          "description": "In recent years, deep neural networks have been successful in both industry\nand academia, especially for computer vision tasks. The great success of deep\nlearning is mainly due to its scalability to encode large-scale data and to\nmaneuver billions of model parameters. However, it is a challenge to deploy\nthese cumbersome deep models on devices with limited resources, e.g., mobile\nphones and embedded devices, not only because of the high computational\ncomplexity but also the large storage requirements. To th…",
          "link": "http://arxiv.org/abs/2006.05525",
          "publishedOn": "2021-05-22T06:24:29.183Z",
          "wordCount": 677,
          "title": "Knowledge Distillation: A Survey. (arXiv:2006.05525v7 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09930",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sodhi_S/0/1/0/all/0/1\">Sukhdeep S. Sodhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chio_E/0/1/0/all/0/1\">Ellie Ka-In Chio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jash_A/0/1/0/all/0/1\">Ambarish Jash</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ontanon_S/0/1/0/all/0/1\">Santiago Onta&#xf1;&#xf3;n</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Apte_A/0/1/0/all/0/1\">Ajit Apte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1\">Ankit Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeje_A/0/1/0/all/0/1\">Ayooluwakunmi Jeje</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuzmin_D/0/1/0/all/0/1\">Dima Kuzmin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fung_H/0/1/0/all/0/1\">Harry Fung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1\">Heng-Tze Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Effrat_J/0/1/0/all/0/1\">Jon Effrat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bali_T/0/1/0/all/0/1\">Tarush Bali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jindal_N/0/1/0/all/0/1\">Nitin Jindal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_P/0/1/0/all/0/1\">Pei Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Sarvjeet Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1\">Senqiang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_T/0/1/0/all/0/1\">Tameen Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wankhede_A/0/1/0/all/0/1\">Amol Wankhede</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alzantot_M/0/1/0/all/0/1\">Moustafa Alzantot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_A/0/1/0/all/0/1\">Allen Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandra_T/0/1/0/all/0/1\">Tushar Chandra</a>",
          "description": "As more and more online search queries come from voice, automatic speech\nrecognition becomes a key component to deliver relevant search results. Errors\nintroduced by automatic speech recognition (ASR) lead to irrelevant search\nresults returned to the user, thus causing user dissatisfaction. In this paper,\nwe introduce an approach, Mondegreen, to correct voice queries in text space\nwithout depending on audio signals, which may not always be available due to\nsystem constraints or privacy or bandwidth (for exa…",
          "link": "http://arxiv.org/abs/2105.09930",
          "publishedOn": "2021-05-22T06:24:29.159Z",
          "wordCount": 678,
          "title": "Mondegreen: A Post-Processing Solution to Speech Recognition Error Correction for Voice Search Queries. (arXiv:2105.09930v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09858",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tobing_P/0/1/0/all/0/1\">Patrick Lumban Tobing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Toda_T/0/1/0/all/0/1\">Tomoki Toda</a>",
          "description": "This paper presents a low-latency real-time (LLRT) non-parallel voice\nconversion (VC) framework based on cyclic variational autoencoder (CycleVAE)\nand multiband WaveRNN with data-driven linear prediction (MWDLP). CycleVAE is a\nrobust non-parallel multispeaker spectral model, which utilizes a\nspeaker-independent latent space and a speaker-dependent code to generate\nreconstructed/converted spectral features given the spectral features of an\ninput speaker. On the other hand, MWDLP is an efficient and a high-qu…",
          "link": "http://arxiv.org/abs/2105.09858",
          "publishedOn": "2021-05-22T06:24:29.127Z",
          "wordCount": 646,
          "title": "Low-Latency Real-Time Non-Parallel Voice Conversion based on Cyclic Variational Autoencoder and Multiband WaveRNN with Data-Driven Linear Prediction. (arXiv:2105.09858v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2007.13693",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pares_F/0/1/0/all/0/1\">Ferran Par&#xe9;s</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arias_Duart_A/0/1/0/all/0/1\">Anna Arias-Duart</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garcia_Gasulla_D/0/1/0/all/0/1\">Dario Garcia-Gasulla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Campo_Frances_G/0/1/0/all/0/1\">Gema Campo-Franc&#xe9;s</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Viladrich_N/0/1/0/all/0/1\">Nina Viladrich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ayguade_E/0/1/0/all/0/1\">Eduard Ayguad&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Labarta_J/0/1/0/all/0/1\">Jes&#xfa;s Labarta</a>",
          "description": "In the image classification task, the most common approach is to resize all\nimages in a dataset to a unique shape, while reducing their precision to a size\nwhich facilitates experimentation at scale. This practice has benefits from a\ncomputational perspective, but it entails negative side-effects on performance\ndue to loss of information and image deformation. In this work we introduce the\nMAMe dataset, an image classification dataset with remarkable high resolution\nand variable shape properties. The goal o…",
          "link": "http://arxiv.org/abs/2007.13693",
          "publishedOn": "2021-05-22T06:24:29.120Z",
          "wordCount": 725,
          "title": "The MAMe Dataset: On the relevance of High Resolution and Variable Shape image properties. (arXiv:2007.13693v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1912.07913",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Grelier_E/0/1/0/all/0/1\">Erwan Grelier</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nouy_A/0/1/0/all/0/1\">Anthony Nouy</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lebrun_R/0/1/0/all/0/1\">R&#xe9;gis Lebrun</a>",
          "description": "We consider the problem of the estimation of a high-dimensional probability\ndistribution from i.i.d. samples of the distribution using model classes of\nfunctions in tree-based tensor formats, a particular case of tensor networks\nassociated with a dimension partition tree. The distribution is assumed to\nadmit a density with respect to a product measure, possibly discrete for\nhandling the case of discrete random variables.\n\nAfter discussing the representation of classical model classes in tree-based\ntensor fo…",
          "link": "http://arxiv.org/abs/1912.07913",
          "publishedOn": "2021-05-22T06:24:29.113Z",
          "wordCount": 685,
          "title": "Learning high-dimensional probability distributions using tree tensor networks. (arXiv:1912.07913v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09837",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Junxiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hongyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chai_Z/0/1/0/all/0/1\">Zheng Chai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yongchao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1\">Yue Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1\">Liang Zhao</a>",
          "description": "The Graph Augmented Multi-layer Perceptron (GA-MLP) model is an attractive\nalternative to Graph Neural Networks (GNNs). This is because it is resistant to\nthe over-smoothing problem, and deeper GA-MLP models yield better performance.\nGA-MLP models are traditionally optimized by the Stochastic Gradient Descent\n(SGD). However, SGD suffers from the layer dependency problem, which prevents\nthe gradients of different layers of GA-MLP models from being calculated in\nparallel. In this paper, we propose a parallel …",
          "link": "http://arxiv.org/abs/2105.09837",
          "publishedOn": "2021-05-22T06:24:29.091Z",
          "wordCount": 638,
          "title": "Towards Quantized Model Parallelism for Graph-Augmented MLPs Based on Gradient-Free ADMM framework. (arXiv:2105.09837v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09829",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yunqi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hanxiong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shuyuan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1\">Yingqiang Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongfeng Zhang</a>",
          "description": "Recommender systems are gaining increasing and critical impacts on human and\nsociety since a growing number of users use them for information seeking and\ndecision making. Therefore, it is crucial to address the potential unfairness\nproblems in recommendations. Just like users have personalized preferences on\nitems, users' demands for fairness are also personalized in many scenarios.\nTherefore, it is important to provide personalized fair recommendations for\nusers to satisfy their personalized fairness deman…",
          "link": "http://arxiv.org/abs/2105.09829",
          "publishedOn": "2021-05-22T06:24:29.083Z",
          "wordCount": 630,
          "title": "Towards Personalized Fairness based on Causal Notion. (arXiv:2105.09829v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09787",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Das_D/0/1/0/all/0/1\">Devleena Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nishimura_Y/0/1/0/all/0/1\">Yasutaka Nishimura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vivek_R/0/1/0/all/0/1\">Rajan P. Vivek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takeda_N/0/1/0/all/0/1\">Naoto Takeda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fish_S/0/1/0/all/0/1\">Sean T. Fish</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ploetz_T/0/1/0/all/0/1\">Thomas Ploetz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chernova_S/0/1/0/all/0/1\">Sonia Chernova</a>",
          "description": "Smart home environments are designed to provide services that help improve\nthe quality of life for the occupant via a variety of sensors and actuators\ninstalled throughout the space. Many automated actions taken by a smart home\nare governed by the output of an underlying activity recognition system.\nHowever, activity recognition systems may not be perfectly accurate and\ntherefore inconsistencies in smart home operations can lead a user to wonder\n\"why did the smart home do that?\" In this work, we build on in…",
          "link": "http://arxiv.org/abs/2105.09787",
          "publishedOn": "2021-05-22T06:24:29.071Z",
          "wordCount": 704,
          "title": "Explainable Activity Recognition for Smart Home Systems. (arXiv:2105.09787v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09908",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wangyang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_A/0/1/0/all/0/1\">Abraham Noah Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biljecki_F/0/1/0/all/0/1\">Filip Biljecki</a>",
          "description": "There is a prevailing trend to study urban morphology quantitatively thanks\nto the growing accessibility to various forms of spatial big data, increasing\ncomputing power, and use cases benefiting from such information. The methods\ndeveloped up to now measure urban morphology with numerical indices describing\ndensity, proportion, and mixture, but they do not directly represent\nmorphological features from human's visual and intuitive perspective. We take\nthe first step to bridge the gap by proposing a deep le…",
          "link": "http://arxiv.org/abs/2105.09908",
          "publishedOn": "2021-05-22T06:24:29.059Z",
          "wordCount": 703,
          "title": "Classification of Urban Morphology with Deep Learning: Application on Urban Vitality. (arXiv:2105.09908v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09783",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_Thai_B/0/1/0/all/0/1\">Binh Nguyen-Thai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_V/0/1/0/all/0/1\">Vuong Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morgan_C/0/1/0/all/0/1\">Catherine Morgan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Badawi_N/0/1/0/all/0/1\">Nadia Badawi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1\">Truyen Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venkatesh_S/0/1/0/all/0/1\">Svetha Venkatesh</a>",
          "description": "The absence or abnormality of fidgety movements of joints or limbs is\nstrongly indicative of cerebral palsy in infants. Developing computer-based\nmethods for assessing infant movements in videos is pivotal for improved\ncerebral palsy screening. Most existing methods use appearance-based features\nand are thus sensitive to strong but irrelevant signals caused by background\nclutter or a moving camera. Moreover, these features are computed over the\nwhole frame, thus they measure gross whole body movements rathe…",
          "link": "http://arxiv.org/abs/2105.09783",
          "publishedOn": "2021-05-22T06:24:28.964Z",
          "wordCount": 657,
          "title": "A Spatio-temporal Attention-based Model for Infant Movement Assessment from Videos. (arXiv:2105.09783v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09788",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Liu_R/0/1/0/all/0/1\">Ruiqi Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Xu_G/0/1/0/all/0/1\">Ganggang Xu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shang_Z/0/1/0/all/0/1\">Zuofeng Shang</a>",
          "description": "When data is of an extraordinarily large size or physically stored in\ndifferent locations, the distributed nearest neighbor (NN) classifier is an\nattractive tool for classification. We propose a novel distributed adaptive NN\nclassifier for which the number of nearest neighbors is a tuning parameter\nstochastically chosen by a data-driven criterion. An early stopping rule is\nproposed when searching for the optimal tuning parameter, which not only speeds\nup the computation but also improves the finite sample p…",
          "link": "http://arxiv.org/abs/2105.09788",
          "publishedOn": "2021-05-22T06:24:28.954Z",
          "wordCount": 571,
          "title": "Distributed Adaptive Nearest Neighbor Classifier: Algorithm and Theory. (arXiv:2105.09788v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09720",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Mudiyanselage_T/0/1/0/all/0/1\">Thosini Bamunu Mudiyanselage</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Senanayake_N/0/1/0/all/0/1\">Nipuna Senanayake</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ji_C/0/1/0/all/0/1\">Chunyan Ji</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pan_Y/0/1/0/all/0/1\">Yi Pan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_Y/0/1/0/all/0/1\">Yanqing Zhang</a>",
          "description": "The novel corona virus (Covid-19) has introduced significant challenges due\nto its rapid spreading nature through respiratory transmission. As a result,\nthere is a huge demand for Artificial Intelligence (AI) based quick disease\ndiagnosis methods as an alternative to high demand tests such as Polymerase\nChain Reaction (PCR). Chest X-ray (CXR) Image analysis is such cost-effective\nradiography technique due to resource availability and quick screening. But, a\nsufficient and systematic data collection that is …",
          "link": "http://arxiv.org/abs/2105.09720",
          "publishedOn": "2021-05-22T06:24:28.949Z",
          "wordCount": 747,
          "title": "Covid-19 Detection from Chest X-ray and Patient Metadata using Graph Convolutional Neural Networks. (arXiv:2105.09720v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09899",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_R/0/1/0/all/0/1\">Ran Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Mingkun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_R/0/1/0/all/0/1\">Rujun Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_B/0/1/0/all/0/1\">Bo Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Z/0/1/0/all/0/1\">Zhuoling Xiao</a>",
          "description": "The technology for Visual Odometry (VO) that estimates the position and\norientation of the moving object through analyzing the image sequences captured\nby on-board cameras, has been well investigated with the rising interest in\nautonomous driving. This paper studies monocular VO from the perspective of\nDeep Learning (DL). Unlike most current learning-based methods, our approach,\ncalled DeepAVO, is established on the intuition that features contribute\ndiscriminately to different motion patterns. Specifically…",
          "link": "http://arxiv.org/abs/2105.09899",
          "publishedOn": "2021-05-22T06:24:28.942Z",
          "wordCount": 619,
          "title": "DeepAVO: Efficient Pose Refining with Feature Distilling for Deep Visual Odometry. (arXiv:2105.09899v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09681",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_C/0/1/0/all/0/1\">Chen Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1\">Zhuangwei Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Weihua Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yanbu Guo</a>",
          "description": "Chinese word segmentation (CWS) is the basic of Chinese natural language\nprocessing (NLP). The quality of word segmentation will directly affect the\nrest of NLP tasks. Recently, with the artificial intelligence tide rising\nagain, Long Short-Term Memory (LSTM) neural network, as one of easily modeling\nin sequence, has been widely utilized in various kinds of NLP tasks, and\nfunctions well. Attention mechanism is an ingenious method to solve the memory\ncompression problem on LSTM. Furthermore, inspired by the …",
          "link": "http://arxiv.org/abs/2105.09681",
          "publishedOn": "2021-05-22T06:24:28.936Z",
          "wordCount": 546,
          "title": "Bidirectional LSTM-CRF Attention-based Model for Chinese Word Segmentation. (arXiv:2105.09681v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09821",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Awad_N/0/1/0/all/0/1\">Noor Awad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mallik_N/0/1/0/all/0/1\">Neeratyoy Mallik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hutter_F/0/1/0/all/0/1\">Frank Hutter</a>",
          "description": "Modern machine learning algorithms crucially rely on several design decisions\nto achieve strong performance, making the problem of Hyperparameter\nOptimization (HPO) more important than ever. Here, we combine the advantages of\nthe popular bandit-based HPO method Hyperband (HB) and the evolutionary search\napproach of Differential Evolution (DE) to yield a new HPO method which we call\nDEHB. Comprehensive results on a very broad range of HPO problems, as well as a\nwide range of tabular benchmarks from neural ar…",
          "link": "http://arxiv.org/abs/2105.09821",
          "publishedOn": "2021-05-22T06:24:28.917Z",
          "wordCount": 571,
          "title": "DEHB: Evolutionary Hyberband for Scalable, Robust and Efficient Hyperparameter Optimization. (arXiv:2105.09821v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09540",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiaolin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1\">Shuai Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1\">Kai Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_H/0/1/0/all/0/1\">Hao Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1\">Zejin Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yongji Wang</a>",
          "description": "The increasing concerns about data privacy and security drives the emergence\nof a new field of studying privacy-preserving machine learning from isolated\ndata sources, i.e., \\textit{federated learning}. Vertical federated learning,\nwhere different parties hold different features for common users, has a great\npotential of driving a more variety of business cooperation among enterprises\nin different fields. Decision tree models especially decision tree ensembles\nare a class of widely applied powerful machine …",
          "link": "http://arxiv.org/abs/2105.09540",
          "publishedOn": "2021-05-22T06:24:28.910Z",
          "wordCount": 684,
          "title": "Fed-EINI: An Efficient and Interpretable Inference Framework for Decision Tree Ensembles in Federated Learning. (arXiv:2105.09540v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09866",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Wang_Z/0/1/0/all/0/1\">Zhe Wang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Guet_C/0/1/0/all/0/1\">Claude Guet</a>",
          "description": "Solving physics problems for which we know the equations, boundary conditions\nand symmetries can be done by deep learning. The constraints can be either\nimposed as terms in a loss function or used to formulate a neural ansatz. In\nthe present case study, we calculate the induced field inside and outside a\ndielectric cube placed in a uniform electric field, wherein the dielectric\nmismatch at edges and corners of the cube makes accurate calculations\nnumerically challenging. The electric potential is expressed …",
          "link": "http://arxiv.org/abs/2105.09866",
          "publishedOn": "2021-05-22T06:24:28.903Z",
          "wordCount": 707,
          "title": "Deep learning in physics: a study of dielectric quasi-cubic particles in a uniform electric field. (arXiv:2105.09866v1 [physics.class-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09679",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Kimura_S/0/1/0/all/0/1\">Shun Kimura</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Ota_K/0/1/0/all/0/1\">Keisuke Ota</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Takeda_K/0/1/0/all/0/1\">Koujin Takeda</a>",
          "description": "Neuronal ensemble inference is a significant problem in the study of\nbiological neural networks. Various methods have been proposed for ensemble\ninference from experimental data of neuronal activity. Among them, Bayesian\ninference approach with generative model was proposed recently. However, this\nmethod requires large computational cost for appropriate inference. In this\nwork, we give an improved Bayesian inference algorithm by modifying update rule\nin Markov chain Monte Carlo method and introducing the id…",
          "link": "http://arxiv.org/abs/2105.09679",
          "publishedOn": "2021-05-22T06:24:28.897Z",
          "wordCount": 556,
          "title": "Improved Neuronal Ensemble Inference with Generative Model and MCMC. (arXiv:2105.09679v1 [cond-mat.dis-nn])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09501",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1\">Xiao Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mingxuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1\">Liwei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>",
          "description": "Existing multilingual machine translation approaches mainly focus on\nEnglish-centric directions, while the non-English directions still lag behind.\nIn this work, we aim to build a many-to-many translation system with an\nemphasis on the quality of non-English language directions. Our intuition is\nbased on the hypothesis that a universal cross-language representation leads to\nbetter multilingual translation performance. To this end, we propose \\method, a\ntraining method to obtain a single unified multilingual…",
          "link": "http://arxiv.org/abs/2105.09501",
          "publishedOn": "2021-05-22T06:24:28.890Z",
          "wordCount": 576,
          "title": "Contrastive Learning for Many-to-many Multilingual Neural Machine Translation. (arXiv:2105.09501v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09580",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dong_N/0/1/0/all/0/1\">Nanqing Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kampffmeyer_M/0/1/0/all/0/1\">Michael Kampffmeyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Voiculescu_I/0/1/0/all/0/1\">Irina Voiculescu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1\">Eric Xing</a>",
          "description": "Entanglement is a physical phenomenon, which has fueled recent successes of\nquantum algorithms. Although quantum neural networks (QNNs) have shown\npromising results in solving simple machine learning tasks recently, for the\ntime being, the effect of entanglement in QNNs and the behavior of QNNs in\nbinary pattern classification are still underexplored. In this work, we provide\nsome theoretical insight into the properties of QNNs by presenting and\nanalyzing a new form of invariance embedded in QNNs for both q…",
          "link": "http://arxiv.org/abs/2105.09580",
          "publishedOn": "2021-05-22T06:24:28.868Z",
          "wordCount": 634,
          "title": "Negational Symmetry of Quantum Neural Networks for Binary Pattern Classification. (arXiv:2105.09580v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09856",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tobing_P/0/1/0/all/0/1\">Patrick Lumban Tobing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Toda_T/0/1/0/all/0/1\">Tomoki Toda</a>",
          "description": "This paper presents a novel high-fidelity and low-latency universal neural\nvocoder framework based on multiband WaveRNN with data-driven linear prediction\nfor discrete waveform modeling (MWDLP). MWDLP employs a coarse-fine bit WaveRNN\narchitecture for 10-bit mu-law waveform modeling. A sparse gated recurrent unit\nwith a relatively large size of hidden units is utilized, while the multiband\nmodeling is deployed to achieve real-time low-latency usage. A novel technique\nfor data-driven linear prediction (LP) w…",
          "link": "http://arxiv.org/abs/2105.09856",
          "publishedOn": "2021-05-22T06:24:28.861Z",
          "wordCount": 635,
          "title": "High-Fidelity and Low-Latency Universal Neural Vocoder based on Multiband WaveRNN with Data-Driven Linear Prediction for Discrete Waveform Modeling. (arXiv:2105.09856v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09506",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Cai_S/0/1/0/all/0/1\">Shengze Cai</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Mao_Z/0/1/0/all/0/1\">Zhiping Mao</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Wang_Z/0/1/0/all/0/1\">Zhicheng Wang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Yin_M/0/1/0/all/0/1\">Minglang Yin</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Karniadakis_G/0/1/0/all/0/1\">George Em Karniadakis</a>",
          "description": "Despite the significant progress over the last 50 years in simulating flow\nproblems using numerical discretization of the Navier-Stokes equations (NSE),\nwe still cannot incorporate seamlessly noisy data into existing algorithms,\nmesh-generation is complex, and we cannot tackle high-dimensional problems\ngoverned by parametrized NSE. Moreover, solving inverse flow problems is often\nprohibitively expensive and requires complex and expensive formulations and new\ncomputer codes. Here, we review flow physics-info…",
          "link": "http://arxiv.org/abs/2105.09506",
          "publishedOn": "2021-05-22T06:24:28.847Z",
          "wordCount": 535,
          "title": "Physics-informed neural networks (PINNs) for fluid mechanics: A review. (arXiv:2105.09506v1 [physics.flu-dyn])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09801",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Shuangshuang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_S/0/1/0/all/0/1\">Sihao Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karayiannidis_Y/0/1/0/all/0/1\">Yiannis Karayiannidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bjorkman_M/0/1/0/all/0/1\">M&#xe5;rten Bj&#xf6;rkman</a>",
          "description": "Learning generative models and inferring latent trajectories have shown to be\nchallenging for time series due to the intractable marginal likelihoods of\nflexible generative models. It can be addressed by surrogate objectives for\noptimization. We propose Monte Carlo filtering objectives (MCFOs), a family of\nvariational objectives for jointly learning parametric generative models and\namortized adaptive importance proposals of time series. MCFOs extend the\nchoices of likelihood estimators beyond Sequential Mon…",
          "link": "http://arxiv.org/abs/2105.09801",
          "publishedOn": "2021-05-22T06:24:28.841Z",
          "wordCount": 595,
          "title": "Monte Carlo Filtering Objectives: A New Family of Variational Objectives to Learn Generative Model and Neural Adaptive Proposal for Time Series. (arXiv:2105.09801v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09494",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Berahmand_K/0/1/0/all/0/1\">Kamal Berahmand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nasiri_E/0/1/0/all/0/1\">Elahe Nasiri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Forouzandeh_S/0/1/0/all/0/1\">Saman Forouzandeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuefeng Li</a>",
          "description": "Predicting links in complex networks has been one of the essential topics\nwithin the realm of data mining and science discovery over the past few years.\nThis problem remains an attempt to identify future, deleted, and redundant\nlinks using the existing links in a graph. Local random walk is considered to\nbe one of the most well-known algorithms in the category of quasi-local\nmethods. It traverses the network using the traditional random walk with a\nlimited number of steps, randomly selecting one adjacent no…",
          "link": "http://arxiv.org/abs/2105.09494",
          "publishedOn": "2021-05-22T06:24:28.834Z",
          "wordCount": 671,
          "title": "A Preference Random Walk Algorithm for Link Prediction through Mutual Influence Nodes in Complex Networks. (arXiv:2105.09494v1 [cs.SI])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09673",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Daniely_A/0/1/0/all/0/1\">Amit Daniely</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Granot_E/0/1/0/all/0/1\">Elad Granot</a>",
          "description": "As machine learning increasingly becomes more prevalent in our everyday life,\nmany organizations offer neural-networks based services as a black-box. The\nreasons for hiding a learning model may vary: e.g., preventing copying of its\nbehavior or keeping back an adversarial from reverse-engineering its mechanism\nand revealing sensitive information about its training data.\n\nHowever, even as a black-box, some information can still be discovered by\nspecific queries. In this work, we show a polynomial-time algorit…",
          "link": "http://arxiv.org/abs/2105.09673",
          "publishedOn": "2021-05-22T06:24:28.807Z",
          "wordCount": 521,
          "title": "An Exact Poly-Time Membership-Queries Algorithm for Extraction a three-Layer ReLU Network. (arXiv:2105.09673v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09637",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Devlin_S/0/1/0/all/0/1\">Sam Devlin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Georgescu_R/0/1/0/all/0/1\">Raluca Georgescu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Momennejad_I/0/1/0/all/0/1\">Ida Momennejad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rzepecki_J/0/1/0/all/0/1\">Jaroslaw Rzepecki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zuniga_E/0/1/0/all/0/1\">Evelyn Zuniga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Costello_G/0/1/0/all/0/1\">Gavin Costello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leroy_G/0/1/0/all/0/1\">Guy Leroy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shaw_A/0/1/0/all/0/1\">Ali Shaw</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hofmann_K/0/1/0/all/0/1\">Katja Hofmann</a>",
          "description": "A key challenge on the path to developing agents that learn complex\nhuman-like behavior is the need to quickly and accurately quantify\nhuman-likeness. While human assessments of such behavior can be highly\naccurate, speed and scalability are limited. We address these limitations\nthrough a novel automated Navigation Turing Test (ANTT) that learns to predict\nhuman judgments of human-likeness. We demonstrate the effectiveness of our\nautomated NTT on a navigation task in a complex 3D environment. We investigate…",
          "link": "http://arxiv.org/abs/2105.09637",
          "publishedOn": "2021-05-22T06:24:28.786Z",
          "wordCount": 589,
          "title": "Navigation Turing Test (NTT): Learning to Evaluate Human-Like Navigation. (arXiv:2105.09637v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09618",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Malem_Shinitski_N/0/1/0/all/0/1\">Noa Malem-Shinitski</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ojeda_C/0/1/0/all/0/1\">Cesar Ojeda</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Opper_M/0/1/0/all/0/1\">Manfred Opper</a>",
          "description": "Traditionally, Hawkes processes are used to model time--continuous point\nprocesses with history dependence. Here we propose an extended model where the\nself--effects are of both excitatory and inhibitory type and follow a Gaussian\nProcess. Whereas previous work either relies on a less flexible\nparameterization of the model, or requires a large amount of data, our\nformulation allows for both a flexible model and learning when data are scarce.\nWe continue the line of work of Bayesian inference for Hawkes proc…",
          "link": "http://arxiv.org/abs/2105.09618",
          "publishedOn": "2021-05-22T06:24:28.780Z",
          "wordCount": 584,
          "title": "Nonlinear Hawkes Process with Gaussian Process Self Effects. (arXiv:2105.09618v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09632",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dessi_D/0/1/0/all/0/1\">Danilo Dessi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Helaoui_R/0/1/0/all/0/1\">Rim Helaoui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1\">Vivek Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Recupero_D/0/1/0/all/0/1\">Diego Reforgiato Recupero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riboni_D/0/1/0/all/0/1\">Daniele Riboni</a>",
          "description": "Today, we are seeing an ever-increasing number of clinical notes that contain\nclinical results, images, and textual descriptions of patient's health state.\nAll these data can be analyzed and employed to cater novel services that can\nhelp people and domain experts with their common healthcare tasks. However,\nmany technologies such as Deep Learning and tools like Word Embeddings have\nstarted to be investigated only recently, and many challenges remain open when\nit comes to healthcare domain applications. To a…",
          "link": "http://arxiv.org/abs/2105.09632",
          "publishedOn": "2021-05-22T06:24:28.774Z",
          "wordCount": 680,
          "title": "TF-IDF vs Word Embeddings for Morbidity Identification in Clinical Notes: An Initial Study. (arXiv:2105.09632v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09474",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lazic_S/0/1/0/all/0/1\">Stanley E. Lazic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Williams_D/0/1/0/all/0/1\">Dominic P. Williams</a>",
          "description": "Knowing the uncertainty in a prediction is critical when making expensive\ninvestment decisions and when patient safety is paramount, but machine learning\n(ML) models in drug discovery typically provide only a single best estimate and\nignore all sources of uncertainty. Predictions from these models may therefore\nbe over-confident, which can put patients at risk and waste resources when\ncompounds that are destined to fail are further developed. Probabilistic\npredictive models (PPMs) can incorporate uncertaint…",
          "link": "http://arxiv.org/abs/2105.09474",
          "publishedOn": "2021-05-22T06:24:28.767Z",
          "wordCount": 649,
          "title": "Quantifying sources of uncertainty in drug discovery predictions with probabilistic models. (arXiv:2105.09474v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09716",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Li_Y/0/1/0/all/0/1\">Yongfeng Li</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhao_M/0/1/0/all/0/1\">Mingming Zhao</a>, <a href=\"http://arxiv.org/find/math/1/au:+Chen_W/0/1/0/all/0/1\">Weijie Chen</a>, <a href=\"http://arxiv.org/find/math/1/au:+Wen_Z/0/1/0/all/0/1\">Zaiwen Wen</a>",
          "description": "In this paper, we consider the linear programming (LP) formulation for deep\nreinforcement learning. The number of the constraints depends on the size of\nstate and action spaces, which makes the problem intractable in large or\ncontinuous environments. The general augmented Lagrangian method suffers the\ndouble-sampling obstacle in solving the LP. Namely, the conditional\nexpectations originated from the constraint functions and the quadratic\npenalties in the augmented Lagrangian function impose difficulties in…",
          "link": "http://arxiv.org/abs/2105.09716",
          "publishedOn": "2021-05-22T06:24:28.752Z",
          "wordCount": 642,
          "title": "A Stochastic Composite Augmented Lagrangian Method For Reinforcement Learning. (arXiv:2105.09716v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09601",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Atri_Y/0/1/0/all/0/1\">Yash Kumar Atri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pramanick_S/0/1/0/all/0/1\">Shraman Pramanick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_V/0/1/0/all/0/1\">Vikram Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_T/0/1/0/all/0/1\">Tanmoy Chakraborty</a>",
          "description": "In recent years, abstractive text summarization with multimodal inputs has\nstarted drawing attention due to its ability to accumulate information from\ndifferent source modalities and generate a fluent textual summary. However,\nexisting methods use short videos as the visual modality and short summary as\nthe ground-truth, therefore, perform poorly on lengthy videos and long\nground-truth summary. Additionally, there exists no benchmark dataset to\ngeneralize this task on videos of varying lengths. In this pape…",
          "link": "http://arxiv.org/abs/2105.09601",
          "publishedOn": "2021-05-22T06:24:28.735Z",
          "wordCount": 667,
          "title": "See, Hear, Read: Leveraging Multimodality with Guided Attention for Abstractive Text Summarization. (arXiv:2105.09601v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09428",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lahlou_C/0/1/0/all/0/1\">Chuhong Lahlou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crayton_A/0/1/0/all/0/1\">Ancil Crayton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trier_C/0/1/0/all/0/1\">Caroline Trier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Willett_E/0/1/0/all/0/1\">Evan Willett</a>",
          "description": "In 2019, The Centers for Medicare and Medicaid Services (CMS) launched an\nArtificial Intelligence (AI) Health Outcomes Challenge seeking solutions to\npredict risk in value-based care for incorporation into CMS Innovation Center\npayment and service delivery models. Recently, modern language models have\nplayed key roles in a number of health related tasks. This paper presents, to\nthe best of our knowledge, the first application of these models to patient\nreadmission prediction. To facilitate this, we create a…",
          "link": "http://arxiv.org/abs/2105.09428",
          "publishedOn": "2021-05-22T06:24:28.726Z",
          "wordCount": 592,
          "title": "Explainable Health Risk Predictor with Transformer-based Medicare Claim Encoder. (arXiv:2105.09428v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09369",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wainakh_A/0/1/0/all/0/1\">Aidmar Wainakh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ventola_F/0/1/0/all/0/1\">Fabrizio Ventola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mussig_T/0/1/0/all/0/1\">Till M&#xfc;&#xdf;ig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keim_J/0/1/0/all/0/1\">Jens Keim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cordero_C/0/1/0/all/0/1\">Carlos Garcia Cordero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zimmer_E/0/1/0/all/0/1\">Ephraim Zimmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grube_T/0/1/0/all/0/1\">Tim Grube</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kersting_K/0/1/0/all/0/1\">Kristian Kersting</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muhlhauser_M/0/1/0/all/0/1\">Max M&#xfc;hlh&#xe4;user</a>",
          "description": "Federated learning enables multiple users to build a joint model by sharing\ntheir model updates (gradients), while their raw data remains local on their\ndevices. In contrast to the common belief that this provides privacy benefits,\nwe here add to the very recent results on privacy risks when sharing gradients.\nSpecifically, we propose Label Leakage from Gradients (LLG), a novel attack to\nextract the labels of the users' training data from their shared gradients. The\nattack exploits the direction and magnitu…",
          "link": "http://arxiv.org/abs/2105.09369",
          "publishedOn": "2021-05-22T06:24:28.720Z",
          "wordCount": 611,
          "title": "User Label Leakage from Gradients in Federated Learning. (arXiv:2105.09369v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09685",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Borkar_J/0/1/0/all/0/1\">Jaydeep Borkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1\">Pin-Yu Chen</a>",
          "description": "There has been a rise in the use of Machine Learning as a Service (MLaaS)\nVision APIs as they offer multiple services including pre-built models and\nalgorithms, which otherwise take a huge amount of resources if built from\nscratch. As these APIs get deployed for high-stakes applications, it's very\nimportant that they are robust to different manipulations. Recent works have\nonly focused on typical adversarial attacks when evaluating the robustness of\nvision APIs. We propose two new aspects of adversarial ima…",
          "link": "http://arxiv.org/abs/2105.09685",
          "publishedOn": "2021-05-22T06:24:28.702Z",
          "wordCount": 694,
          "title": "Simple Transparent Adversarial Examples. (arXiv:2105.09685v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09557",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mori_T/0/1/0/all/0/1\">Takashi Mori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ziyin_L/0/1/0/all/0/1\">Liu Ziyin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1\">Kangqiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ueda_M/0/1/0/all/0/1\">Masahito Ueda</a>",
          "description": "Stochastic gradient descent (SGD) undergoes complicated multiplicative noise\nfor the mean-square loss. We use this property of the SGD noise to derive a\nstochastic differential equation (SDE) with simpler additive noise by\nperforming a non-uniform transformation of the time variable. In the SDE, the\ngradient of the loss is replaced by that of the logarithmized loss.\nConsequently, we show that, near a local or global minimum, the stationary\ndistribution $P_\\mathrm{ss}(\\theta)$ of the network parameters $\\the…",
          "link": "http://arxiv.org/abs/2105.09557",
          "publishedOn": "2021-05-22T06:24:28.696Z",
          "wordCount": 604,
          "title": "Logarithmic landscape and power-law escape rate of SGD. (arXiv:2105.09557v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09371",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Karnan_H/0/1/0/all/0/1\">Haresh Karnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Warnell_G/0/1/0/all/0/1\">Garrett Warnell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1\">Xuesu Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stone_P/0/1/0/all/0/1\">Peter Stone</a>",
          "description": "While imitation learning for vision based autonomous mobile robot navigation\nhas recently received a great deal of attention in the research community,\nexisting approaches typically require state action demonstrations that were\ngathered using the deployment platform. However, what if one cannot easily\noutfit their platform to record these demonstration signals or worse yet the\ndemonstrator does not have access to the platform at all? Is imitation learning\nfor vision based autonomous navigation even possible…",
          "link": "http://arxiv.org/abs/2105.09371",
          "publishedOn": "2021-05-22T06:24:28.689Z",
          "wordCount": 671,
          "title": "VOILA: Visual-Observation-Only Imitation Learning for Autonomous Navigation. (arXiv:2105.09371v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09481",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pryor_W/0/1/0/all/0/1\">Will Pryor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barnoy_Y/0/1/0/all/0/1\">Yotam Barnoy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raval_S/0/1/0/all/0/1\">Suraj Raval</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaolong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mair_L/0/1/0/all/0/1\">Lamar Mair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lerner_D/0/1/0/all/0/1\">Daniel Lerner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erin_O/0/1/0/all/0/1\">Onder Erin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hager_G/0/1/0/all/0/1\">Gregory D. Hager</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diaz_Mercado_Y/0/1/0/all/0/1\">Yancy Diaz-Mercado</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krieger_A/0/1/0/all/0/1\">Axel Krieger</a>",
          "description": "Real-time visual localization of needles is necessary for various surgical\napplications, including surgical automation and visual feedback. In this study\nwe investigate localization and autonomous robotic control of needles in the\ncontext of our magneto-suturing system. Our system holds the potential for\nsurgical manipulation with the benefit of minimal invasiveness and reduced\npatient side effects. However, the non-linear magnetic fields produce\nunintuitive forces and demand delicate position-based control…",
          "link": "http://arxiv.org/abs/2105.09481",
          "publishedOn": "2021-05-22T06:24:28.683Z",
          "wordCount": 664,
          "title": "Localization and Control of Magnetic Suture Needles in Cluttered Surgical Site with Blood and Tissue. (arXiv:2105.09481v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09543",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_T/0/1/0/all/0/1\">Tianyu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_K/0/1/0/all/0/1\">Keyue Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1\">Yuzhuo Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1\">Zhiyu Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yankai Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Peng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>",
          "description": "Distantly supervised (DS) relation extraction (RE) has attracted much\nattention in the past few years as it can utilize large-scale auto-labeled\ndata. However, its evaluation has long been a problem: previous works either\ntook costly and inconsistent methods to manually examine a small sample of\nmodel predictions, or directly test models on auto-labeled data -- which, by\nour check, produce as much as 53% wrong labels at the entity pair level in the\npopular NYT10 dataset. This problem has not only led to ina…",
          "link": "http://arxiv.org/abs/2105.09543",
          "publishedOn": "2021-05-22T06:24:28.666Z",
          "wordCount": 643,
          "title": "Manual Evaluation Matters: Reviewing Test Protocols of Distantly Supervised Relation Extraction. (arXiv:2105.09543v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09356",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rezaei_S/0/1/0/all/0/1\">Seyed Saeed Changiz Rezaei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_F/0/1/0/all/0/1\">Fred X. Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_D/0/1/0/all/0/1\">Di Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salameh_M/0/1/0/all/0/1\">Mohammad Salameh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mills_K/0/1/0/all/0/1\">Keith Mills</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lian_S/0/1/0/all/0/1\">Shuo Lian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1\">Wei Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jui_S/0/1/0/all/0/1\">Shangling Jui</a>",
          "description": "Despite the empirical success of neural architecture search (NAS) in deep\nlearning applications, the optimality, reproducibility and cost of NAS schemes\nremain hard to assess. In this paper, we propose Generative Adversarial NAS\n(GA-NAS) with theoretically provable convergence guarantees, promoting\nstability and reproducibility in neural architecture search. Inspired by\nimportance sampling, GA-NAS iteratively fits a generator to previously\ndiscovered top architectures, thus increasingly focusing on importan…",
          "link": "http://arxiv.org/abs/2105.09356",
          "publishedOn": "2021-05-22T06:24:28.660Z",
          "wordCount": 621,
          "title": "Generative Adversarial Neural Architecture Search. (arXiv:2105.09356v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09492",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_R/0/1/0/all/0/1\">Rundi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1\">Chang Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1\">Changxi Zheng</a>",
          "description": "Deep generative models of 3D shapes have received a great deal of research\ninterest. Yet, almost all of them generate discrete shape representations, such\nas voxels, point clouds, and polygon meshes. We present the first 3D generative\nmodel for a drastically different shape representation -- describing a shape as\na sequence of computer-aided design (CAD) operations. Unlike meshes and point\nclouds, CAD models encode the user creation process of 3D shapes, widely used\nin numerous industrial and engineering de…",
          "link": "http://arxiv.org/abs/2105.09492",
          "publishedOn": "2021-05-22T06:24:28.647Z",
          "wordCount": 608,
          "title": "DeepCAD: A Deep Generative Network for Computer-Aided Design Models. (arXiv:2105.09492v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09471",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Leblebici_A/0/1/0/all/0/1\">Asim Leblebici</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gesoglu_O/0/1/0/all/0/1\">Omer Gesoglu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basbinar_Y/0/1/0/all/0/1\">Yasemin Basbinar</a>",
          "description": "Until the beginning of 2021, lung cancer is known to be the most common\ncancer in the world. The disease is common due to factors such as occupational\nexposure, smoking and environmental pollution. The early diagnosis and\ntreatment of the disease is of great importance as well as the prevention of\nthe causes that cause the disease. The study was planned to create a web\ninterface that works with machine learning algorithms to predict prognosis\nusing lung cancer clinical and gene expression in the GDC data po…",
          "link": "http://arxiv.org/abs/2105.09471",
          "publishedOn": "2021-05-22T06:24:28.632Z",
          "wordCount": 515,
          "title": "AI-Decision Support System Interface Using Cancer Related Data for Lung Cancer Prognosis. (arXiv:2105.09471v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09401",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1\">Lecheng Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yada Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jingrui He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_J/0/1/0/all/0/1\">Jinjun Xiong</a>",
          "description": "With the advent of big data across multiple high-impact applications, we are\noften facing the challenge of complex heterogeneity. The newly collected data\nusually consist of multiple modalities and characterized with multiple labels,\nthus exhibiting the co-existence of multiple types of heterogeneity. Although\nstate-of-the-art techniques are good at modeling the complex heterogeneity with\nsufficient label information, such label information can be quite expensive to\nobtain in real applications, leading to s…",
          "link": "http://arxiv.org/abs/2105.09401",
          "publishedOn": "2021-05-22T06:24:28.549Z",
          "wordCount": 613,
          "title": "Heterogeneous Contrastive Learning. (arXiv:2105.09401v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.01187",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Qi_Z/0/1/0/all/0/1\">Zhengling Qi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Miao_R/0/1/0/all/0/1\">Rui Miao</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaoke Zhang</a>",
          "description": "Data-driven individualized decision making has recently received increasing\nresearch interests. Most existing methods rely on the assumption of no\nunmeasured confounding, which unfortunately cannot be ensured in practice\nespecially in observational studies. Motivated by the recent proposed proximal\ncausal inference, we develop several proximal learning approaches to estimating\noptimal individualized treatment regimes (ITRs) in the presence of unmeasured\nconfounding. In particular, we establish several ident…",
          "link": "http://arxiv.org/abs/2105.01187",
          "publishedOn": "2021-05-22T06:24:28.526Z",
          "wordCount": 580,
          "title": "Proximal Learning for Individualized Treatment Regimes Under Unmeasured Confounding. (arXiv:2105.01187v2 [stat.ME] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.08769",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Walton_N/0/1/0/all/0/1\">Neil Walton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1\">Kuang Xu</a>",
          "description": "We review the role of information and learning in the stability and\noptimization of queueing systems. In recent years, techniques from supervised\nlearning, bandit learning and reinforcement learning have been applied to\nqueueing systems supported by increasing role of information in decision\nmaking. We present observations and new results that help rationalize the\napplication of these areas to queueing systems.\n\nWe prove that the MaxWeight and BackPressure policies are an application of\nBlackwell's Approach…",
          "link": "http://arxiv.org/abs/2105.08769",
          "publishedOn": "2021-05-22T06:24:28.504Z",
          "wordCount": 609,
          "title": "Learning and Information in Stochastic Networks and Queues. (arXiv:2105.08769v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.08147",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ramesh_V/0/1/0/all/0/1\">Vignav Ramesh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rister_B/0/1/0/all/0/1\">Blaine Rister</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rubin_D/0/1/0/all/0/1\">Daniel L. Rubin</a>",
          "description": "Chest X-rays of coronavirus disease 2019 (COVID-19) patients are frequently\nobtained to determine the extent of lung disease and are a valuable source of\ndata for creating artificial intelligence models. Most work to date assessing\ndisease severity on chest imaging has focused on segmenting computed tomography\n(CT) images; however, given that CTs are performed much less frequently than\nchest X-rays for COVID-19 patients, automated lung lesion segmentation on chest\nX-rays could be clinically valuable. There …",
          "link": "http://arxiv.org/abs/2105.08147",
          "publishedOn": "2021-05-22T06:24:28.497Z",
          "wordCount": 779,
          "title": "COVID-19 Lung Lesion Segmentation Using a Sparsely Supervised Mask R-CNN on Chest X-rays Automatically Computed from Volumetric CTs. (arXiv:2105.08147v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09379",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Adler_A/0/1/0/all/0/1\">Avraham Adler</a>",
          "description": "This paper reviews a wide selection of machine learning models built to\npredict both the presence of diabetes and the presence of undiagnosed diabetes\nusing eight years of National Health and Nutrition Examination Survey (NHANES)\ndata. Models are tuned and compared via their Brier Scores. The most relevant\nvariables of the best performing models are then compared. A Support Vector\nMachine with a linear kernel performed best for predicting diabetes, returning\na Brier score of 0.0654 and an AUROC of 0.9235 on…",
          "link": "http://arxiv.org/abs/2105.09379",
          "publishedOn": "2021-05-22T06:24:28.490Z",
          "wordCount": 588,
          "title": "Using Machine Learning Techniques to Identify Key Risk Factors for Diabetes and Undiagnosed Diabetes. (arXiv:2105.09379v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2103.00073",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_N/0/1/0/all/0/1\">Nan Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lutellier_T/0/1/0/all/0/1\">Thibaud Lutellier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_L/0/1/0/all/0/1\">Lin Tan</a>",
          "description": "Automatic program repair (APR) is crucial to improve software reliability.\nRecently, neural machine translation (NMT) techniques have been used to fix\nsoftware bugs automatically. While promising, these approaches have two major\nlimitations. Their search space often does not contain the correct fix, and\ntheir search strategy ignores software knowledge such as strict code syntax.\nDue to these limitations, existing NMT-based techniques underperform the best\ntemplate-based approaches.\n\nWe propose CURE, a new N…",
          "link": "http://arxiv.org/abs/2103.00073",
          "publishedOn": "2021-05-22T06:24:28.471Z",
          "wordCount": 659,
          "title": "CURE: Code-Aware Neural Machine Translation for Automatic Program Repair. (arXiv:2103.00073v3 [cs.SE] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09448",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chhablani_G/0/1/0/all/0/1\">Gunjan Chhablani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Abheesht Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pandey_H/0/1/0/all/0/1\">Harshit Pandey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dash_T/0/1/0/all/0/1\">Tirtharaj Dash</a>",
          "description": "Superpixels are higher-order perceptual groups of pixels in an image, often\ncarrying much more information than raw pixels. There is an inherent relational\nstructure to the relationship among different superpixels of an image. This\nrelational information can convey some form of domain information about the\nimage, e.g. relationship between superpixels representing two eyes in a cat\nimage. Our interest in this paper is to construct computer vision models,\nspecifically those based on Deep Neural Networks (DNNs…",
          "link": "http://arxiv.org/abs/2105.09448",
          "publishedOn": "2021-05-22T06:24:28.465Z",
          "wordCount": 693,
          "title": "Superpixel-based Domain-Knowledge Infusion in Computer Vision. (arXiv:2105.09448v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2010.01017",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qinbin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_B/0/1/0/all/0/1\">Bingsheng He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1\">Dawn Song</a>",
          "description": "Federated learning enables multiple parties to collaboratively learn a model\nwithout exchanging their data. While most existing federated learning\nalgorithms need many rounds to converge, one-shot federated learning (i.e.,\nfederated learning with a single communication round) is a promising approach\nto make federated learning applicable in cross-silo setting in practice.\nHowever, existing one-shot algorithms only support specific models and do not\nprovide any privacy guarantees, which significantly limit th…",
          "link": "http://arxiv.org/abs/2010.01017",
          "publishedOn": "2021-05-22T06:24:28.458Z",
          "wordCount": 581,
          "title": "Practical One-Shot Federated Learning for Cross-Silo Setting. (arXiv:2010.01017v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.12365",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Siegel_J/0/1/0/all/0/1\">Jonathan W. Siegel</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Xu_J/0/1/0/all/0/1\">Jinchao Xu</a>",
          "description": "This article addresses several fundamental issues associated with the\napproximation theory of neural networks, including the characterization of\napproximation spaces, the determination of the metric entropy of these spaces,\nand approximation rates of neural networks. For any activation function\n$\\sigma$, we show that the largest Banach space of functions which can be\nefficiently approximated by the corresponding shallow neural networks is the\nspace whose norm is given by the gauge of the closed convex hull …",
          "link": "http://arxiv.org/abs/2101.12365",
          "publishedOn": "2021-05-22T06:24:28.451Z",
          "wordCount": 762,
          "title": "Optimal Approximation Rates and Metric Entropy of ReLU$^k$ and Cosine Networks. (arXiv:2101.12365v5 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.07686",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ashley_D/0/1/0/all/0/1\">Dylan R. Ashley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghiassian_S/0/1/0/all/0/1\">Sina Ghiassian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sutton_R/0/1/0/all/0/1\">Richard S. Sutton</a>",
          "description": "Catastrophic forgetting remains a severe hindrance to the broad application\nof artificial neural networks (ANNs), however, it continues to be a poorly\nunderstood phenomenon. Despite the extensive amount of work on catastrophic\nforgetting, we argue that it is still unclear how exactly the phenomenon should\nbe quantified, and, moreover, to what degree all of the choices we make when\ndesigning learning systems affect the amount of catastrophic forgetting. We use\nvarious testbeds from the reinforcement learning…",
          "link": "http://arxiv.org/abs/2102.07686",
          "publishedOn": "2021-05-22T06:24:28.445Z",
          "wordCount": 752,
          "title": "Does Standard Backpropagation Forget Less Catastrophically Than Adam?. (arXiv:2102.07686v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.07775",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiangmeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_G/0/1/0/all/0/1\">Guandong Xu</a>",
          "description": "In recommendation systems, the existence of the missing-not-at-random (MNAR)\nproblem results in the selection bias issue, degrading the recommendation\nperformance ultimately. A common practice to address MNAR is to treat missing\nentries from the so-called \"exposure\" perspective, i.e., modeling how an item\nis exposed (provided) to a user. Most of the existing approaches use heuristic\nmodels or re-weighting strategy on observed ratings to mimic the\nmissing-at-random setting. However, little research has been …",
          "link": "http://arxiv.org/abs/2105.07775",
          "publishedOn": "2021-05-22T06:24:28.422Z",
          "wordCount": 632,
          "title": "Be Causal: De-biasing Social Network Confounding in Recommendation. (arXiv:2105.07775v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09461",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Al_Kababji_A/0/1/0/all/0/1\">Ayman Al-Kababji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amira_A/0/1/0/all/0/1\">Abbes Amira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bensaali_F/0/1/0/all/0/1\">Faycal Bensaali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jarouf_A/0/1/0/all/0/1\">Abdulah Jarouf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shidqi_L/0/1/0/all/0/1\">Lisan Shidqi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Djelouat_H/0/1/0/all/0/1\">Hamza Djelouat</a>",
          "description": "Fall detection is a serious healthcare issue that needs to be solved. Falling\nwithout quick medical intervention would lower the chances of survival for the\nelderly, especially if living alone. Hence, the need is there for developing\nfall detection algorithms with high accuracy. This paper presents a novel\nIoT-based system for fall detection that includes a sensing device transmitting\ndata to a mobile application through a cloud-connected gateway device. Then,\nthe focus is shifted to the algorithmic aspect …",
          "link": "http://arxiv.org/abs/2105.09461",
          "publishedOn": "2021-05-22T06:24:28.411Z",
          "wordCount": 658,
          "title": "An IoT-Based Framework for Remote Fall Monitoring. (arXiv:2105.09461v1 [cs.NI])"
        },
        {
          "id": "http://arxiv.org/abs/2006.16362",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cordonnier_J/0/1/0/all/0/1\">Jean-Baptiste Cordonnier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Loukas_A/0/1/0/all/0/1\">Andreas Loukas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaggi_M/0/1/0/all/0/1\">Martin Jaggi</a>",
          "description": "Attention layers are widely used in natural language processing (NLP) and are\nbeginning to influence computer vision architectures. Training very large\ntransformer models allowed significant improvement in both fields, but once\ntrained, these networks show symptoms of over-parameterization. For instance,\nit is known that many attention heads can be pruned without impacting accuracy.\nThis work aims to enhance current understanding on how multiple heads interact.\nMotivated by the observation that attention he…",
          "link": "http://arxiv.org/abs/2006.16362",
          "publishedOn": "2021-05-22T06:24:28.405Z",
          "wordCount": 628,
          "title": "Multi-Head Attention: Collaborate Instead of Concatenate. (arXiv:2006.16362v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09938",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hendrycks_D/0/1/0/all/0/1\">Dan Hendrycks</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basart_S/0/1/0/all/0/1\">Steven Basart</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kadavath_S/0/1/0/all/0/1\">Saurav Kadavath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mazeika_M/0/1/0/all/0/1\">Mantas Mazeika</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arora_A/0/1/0/all/0/1\">Akul Arora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_E/0/1/0/all/0/1\">Ethan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burns_C/0/1/0/all/0/1\">Collin Burns</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Puranik_S/0/1/0/all/0/1\">Samir Puranik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1\">Horace He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1\">Dawn Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steinhardt_J/0/1/0/all/0/1\">Jacob Steinhardt</a>",
          "description": "While programming is one of the most broadly applicable skills in modern\nsociety, modern machine learning models still cannot code solutions to basic\nproblems. It can be difficult to accurately assess code generation performance,\nand there has been surprisingly little work on evaluating code generation in a\nway that is both flexible and rigorous. To meet this challenge, we introduce\nAPPS, a benchmark for code generation. Unlike prior work in more restricted\nsettings, our benchmark measures the ability of mo…",
          "link": "http://arxiv.org/abs/2105.09938",
          "publishedOn": "2021-05-22T06:24:28.399Z",
          "wordCount": 662,
          "title": "Measuring Coding Challenge Competence With APPS. (arXiv:2105.09938v1 [cs.SE])"
        },
        {
          "id": "http://arxiv.org/abs/2002.08797",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Hayou_S/0/1/0/all/0/1\">Soufiane Hayou</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ton_J/0/1/0/all/0/1\">Jean-Francois Ton</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Doucet_A/0/1/0/all/0/1\">Arnaud Doucet</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Teh_Y/0/1/0/all/0/1\">Yee Whye Teh</a>",
          "description": "Overparameterized Neural Networks (NN) display state-of-the-art performance.\nHowever, there is a growing need for smaller, energy-efficient, neural networks\ntobe able to use machine learning applications on devices with limited\ncomputational resources. A popular approach consists of using pruning\ntechniques. While these techniques have traditionally focused on pruning\npre-trained NN (LeCun et al.,1990; Hassibi et al., 1993), recent work by Lee et\nal. (2018) has shown promising results when pruning at initia…",
          "link": "http://arxiv.org/abs/2002.08797",
          "publishedOn": "2021-05-22T06:24:28.391Z",
          "wordCount": 619,
          "title": "Robust Pruning at Initialization. (arXiv:2002.08797v5 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09452",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alegre_L/0/1/0/all/0/1\">Lucas N. Alegre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bazzan_A/0/1/0/all/0/1\">Ana L. C. Bazzan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silva_B/0/1/0/all/0/1\">Bruno C. da Silva</a>",
          "description": "Non-stationary environments are challenging for reinforcement learning\nalgorithms. If the state transition and/or reward functions change based on\nlatent factors, the agent is effectively tasked with optimizing a behavior that\nmaximizes performance over a possibly infinite random sequence of Markov\nDecision Processes (MDPs), each of which drawn from some unknown distribution.\nWe call each such MDP a context. Most related works make strong assumptions\nsuch as knowledge about the distribution over contexts, t…",
          "link": "http://arxiv.org/abs/2105.09452",
          "publishedOn": "2021-05-22T06:24:28.374Z",
          "wordCount": 713,
          "title": "Minimum-Delay Adaptation in Non-Stationary Reinforcement Learning via Online High-Confidence Change-Point Detection. (arXiv:2105.09452v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09579",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Toda_T/0/1/0/all/0/1\">Takamichi Toda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moriwaki_D/0/1/0/all/0/1\">Daisuke Moriwaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ota_K/0/1/0/all/0/1\">Kazuhiro Ota</a>",
          "description": "Large and acute economic shocks such as the 2007-2009 financial crisis and\nthe current COVID-19 infections rapidly change the economic environment. In\nsuch a situation, the importance of real-time economic analysis using\nalternative datais emerging. Alternative data such as search query and location\ndata are closer to real-time and richer than official statistics that are\ntypically released once a month in an aggregated form. We take advantage of\nspatio-temporal granularity of alternative data and propose a…",
          "link": "http://arxiv.org/abs/2105.09579",
          "publishedOn": "2021-05-22T06:24:28.368Z",
          "wordCount": 613,
          "title": "Aggregate Learning for Mixed Frequency Data. (arXiv:2105.09579v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.04916",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yanqi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhaofei Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_W/0/1/0/all/0/1\">Wei Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1\">Tiejun Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yonghong Tian</a>",
          "description": "Spiking Neural Networks (SNNs) have been attached great importance due to\ntheir biological plausibility and high energy-efficiency on neuromorphic chips.\nAs these chips are usually resource-constrained, the compression of SNNs is\nthus crucial along the road of practical use of SNNs. Most existing methods\ndirectly apply pruning approaches in artificial neural networks (ANNs) to SNNs,\nwhich ignore the difference between ANNs and SNNs, thus limiting the\nperformance of the pruned SNNs. Besides, these methods ar…",
          "link": "http://arxiv.org/abs/2105.04916",
          "publishedOn": "2021-05-22T06:24:28.360Z",
          "wordCount": 696,
          "title": "Pruning of Deep Spiking Neural Networks through Gradient Rewiring. (arXiv:2105.04916v2 [cs.NE] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09477",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Haghighat_E/0/1/0/all/0/1\">Ehsan Haghighat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bekar_A/0/1/0/all/0/1\">Ali Can Bekar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madenci_E/0/1/0/all/0/1\">Erdogan Madenci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Juanes_R/0/1/0/all/0/1\">Ruben Juanes</a>",
          "description": "Deep learning has been the most popular machine learning method in the last\nfew years. In this chapter, we present the application of deep learning and\nphysics-informed neural networks concerning structural mechanics and vibration\nproblems. Demonstration problems involve de-noising data, solution to\ntime-dependent ordinary and partial differential equations, and characterizing\nthe system's response for a given data.",
          "link": "http://arxiv.org/abs/2105.09477",
          "publishedOn": "2021-05-22T06:24:28.333Z",
          "wordCount": 491,
          "title": "Deep learning for solution and inversion of structural mechanics and vibrations. (arXiv:2105.09477v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09400",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_P/0/1/0/all/0/1\">Pau-Chen Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eykholt_K/0/1/0/all/0/1\">Kevin Eykholt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Z/0/1/0/all/0/1\">Zhongshu Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jamjoom_H/0/1/0/all/0/1\">Hani Jamjoom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jayaram_K/0/1/0/all/0/1\">K. R. Jayaram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valdez_E/0/1/0/all/0/1\">Enriquillo Valdez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verma_A/0/1/0/all/0/1\">Ashish Verma</a>",
          "description": "Federated Learning (FL) enables collaborative training among mutually\ndistrusting parties. Model updates, rather than training data, are concentrated\nand fused in a central aggregation server. A key security challenge in FL is\nthat an untrustworthy or compromised aggregation process might lead to\nunforeseeable information leakage. This challenge is especially acute due to\nrecently demonstrated attacks that have reconstructed large fractions of\ntraining data from ostensibly \"sanitized\" model updates.\n\nIn thi…",
          "link": "http://arxiv.org/abs/2105.09400",
          "publishedOn": "2021-05-22T06:24:28.327Z",
          "wordCount": 604,
          "title": "Separation of Powers in Federated Learning. (arXiv:2105.09400v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09513",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jagtap_A/0/1/0/all/0/1\">Ameya D. Jagtap</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_Y/0/1/0/all/0/1\">Yeonjong Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kawaguchi_K/0/1/0/all/0/1\">Kenji Kawaguchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karniadakis_G/0/1/0/all/0/1\">George Em Karniadakis</a>",
          "description": "We propose a new type of neural networks, Kronecker neural networks (KNNs),\nthat form a general framework for neural networks with adaptive activation\nfunctions. KNNs employ the Kronecker product, which provides an efficient way\nof constructing a very wide network while keeping the number of parameters low.\nOur theoretical analysis reveals that under suitable conditions, KNNs induce a\nfaster decay of the loss than that by the feed-forward networks. This is also\nempirically verified through a set of computat…",
          "link": "http://arxiv.org/abs/2105.09513",
          "publishedOn": "2021-05-22T06:24:28.249Z",
          "wordCount": 632,
          "title": "Deep Kronecker neural networks: A general framework for neural networks with adaptive activation functions. (arXiv:2105.09513v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09365",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Uysal_E/0/1/0/all/0/1\">Enes Sadi Uysal</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bilici_M/0/1/0/all/0/1\">M.&#x15e;afak Bilici</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zaza_B/0/1/0/all/0/1\">B. Selin Zaza</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ozgenc_M/0/1/0/all/0/1\">M. Yi&#x11f;it &#xd6;zgen&#xe7;</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Boyar_O/0/1/0/all/0/1\">Onur Boyar</a>",
          "description": "Retinal Vessel Segmentation is important for diagnosis of various diseases.\nThe research on retinal vessel segmentation focuses mainly on improvement of\nthe segmentation model which is usually based on U-Net architecture. In our\nstudy we use the U-Net architecture and we rely on heavy data augmentation in\norder to achieve better performance. The success of the data augmentation\nrelies on successfully addressing the problem of input images. By analyzing\ninput images and performing the augmentation accordingl…",
          "link": "http://arxiv.org/abs/2105.09365",
          "publishedOn": "2021-05-22T06:24:28.242Z",
          "wordCount": 564,
          "title": "Exploring The Limits Of Data Augmentation For Retinal Vessel Segmentation. (arXiv:2105.09365v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2010.10777",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Santu_S/0/1/0/all/0/1\">Shubhra Kanti Karmaker Santu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hassan_M/0/1/0/all/0/1\">Md. Mahadi Hassan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_M/0/1/0/all/0/1\">Micah J. Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1\">Lei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_C/0/1/0/all/0/1\">ChengXiang Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Veeramachaneni_K/0/1/0/all/0/1\">Kalyan Veeramachaneni</a>",
          "description": "As big data becomes ubiquitous across domains, and more and more stakeholders\naspire to make the most of their data, demand for machine learning tools has\nspurred researchers to explore the possibilities of automated machine learning\n(AutoML). AutoML tools aim to make machine learning accessible for non-machine\nlearning experts (domain experts), to improve the efficiency of machine\nlearning, and to accelerate machine learning research. But although automation\nand efficiency are among AutoML's main selling p…",
          "link": "http://arxiv.org/abs/2010.10777",
          "publishedOn": "2021-05-22T06:24:28.235Z",
          "wordCount": 775,
          "title": "AutoML to Date and Beyond: Challenges and Opportunities. (arXiv:2010.10777v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.11192",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Frerix_T/0/1/0/all/0/1\">Thomas Frerix</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kochkov_D/0/1/0/all/0/1\">Dmitrii Kochkov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_J/0/1/0/all/0/1\">Jamie A. Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cremers_D/0/1/0/all/0/1\">Daniel Cremers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brenner_M/0/1/0/all/0/1\">Michael P. Brenner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoyer_S/0/1/0/all/0/1\">Stephan Hoyer</a>",
          "description": "Variational data assimilation optimizes for an initial state of a dynamical\nsystem such that its evolution fits observational data. The physical model can\nsubsequently be evolved into the future to make predictions. This principle is\na cornerstone of large scale forecasting applications such as numerical weather\nprediction. As such, it is implemented in current operational systems of\nweather forecasting agencies across the globe. However, finding a good initial\nstate poses a difficult optimization problem i…",
          "link": "http://arxiv.org/abs/2102.11192",
          "publishedOn": "2021-05-22T06:24:28.228Z",
          "wordCount": 643,
          "title": "Variational Data Assimilation with a Learned Inverse Observation Operator. (arXiv:2102.11192v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.08796",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Li_X/0/1/0/all/0/1\">Xiaojun Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_J/0/1/0/all/0/1\">Jianwei Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Abdollahi_A/0/1/0/all/0/1\">Ali Abdollahi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jones_T/0/1/0/all/0/1\">Trevor Jones</a>",
          "description": "For electric vehicles (EV) and energy storage (ES) batteries, thermal runaway\nis a critical issue as it can lead to uncontrollable fires or even explosions.\nThermal anomaly detection can identify problematic battery packs that may\neventually undergo thermal runaway. However, there are common challenges like\ndata unavailability, environment and configuration variations, and battery\naging. We propose a data-driven method to detect battery thermal anomaly based\non comparing shape-similarity between thermal mea…",
          "link": "http://arxiv.org/abs/2103.08796",
          "publishedOn": "2021-05-22T06:24:28.210Z",
          "wordCount": 607,
          "title": "Data-driven Thermal Anomaly Detection for Batteries using Unsupervised Shape Clustering. (arXiv:2103.08796v2 [eess.SY] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.03842",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Leng_Y/0/1/0/all/0/1\">Yichong Leng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1\">Xu Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1\">Linchen Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_R/0/1/0/all/0/1\">Renqian Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Linquan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1\">Tao Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiang-Yang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_E/0/1/0/all/0/1\">Ed Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tie-Yan Liu</a>",
          "description": "Error correction techniques have been used to refine the output sentences\nfrom automatic speech recognition (ASR) models and achieve a lower word error\nrate (WER) than original ASR outputs. Previous works usually use a\nsequence-to-sequence model to correct an ASR output sentence autoregressively,\nwhich causes large latency and cannot be deployed in online ASR services. A\nstraightforward solution to reduce latency, inspired by non-autoregressive\n(NAR) neural machine translation, is to use an NAR sequence gen…",
          "link": "http://arxiv.org/abs/2105.03842",
          "publishedOn": "2021-05-22T06:24:28.204Z",
          "wordCount": 751,
          "title": "FastCorrect: Fast Error Correction with Edit Alignment for Automatic Speech Recognition. (arXiv:2105.03842v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.05929",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schwarzer_M/0/1/0/all/0/1\">Max Schwarzer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anand_A/0/1/0/all/0/1\">Ankesh Anand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goel_R/0/1/0/all/0/1\">Rishab Goel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hjelm_R/0/1/0/all/0/1\">R Devon Hjelm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Courville_A/0/1/0/all/0/1\">Aaron Courville</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bachman_P/0/1/0/all/0/1\">Philip Bachman</a>",
          "description": "While deep reinforcement learning excels at solving tasks where large amounts\nof data can be collected through virtually unlimited interaction with the\nenvironment, learning from limited interaction remains a key challenge. We\nposit that an agent can learn more efficiently if we augment reward\nmaximization with self-supervised objectives based on structure in its visual\ninput and sequential interaction with the environment. Our method,\nSelf-Predictive Representations(SPR), trains an agent to predict its own…",
          "link": "http://arxiv.org/abs/2007.05929",
          "publishedOn": "2021-05-22T06:24:28.196Z",
          "wordCount": 723,
          "title": "Data-Efficient Reinforcement Learning with Self-Predictive Representations. (arXiv:2007.05929v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.08791",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1\">Xiaocheng Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Fan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1\">Zhiwei Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yansheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_D/0/1/0/all/0/1\">Dingyuan Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_B/0/1/0/all/0/1\">Bingchen Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_Y/0/1/0/all/0/1\">Yongxin Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Hongtu Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jieping Ye</a>",
          "description": "Large ride-hailing platforms, such as DiDi, Uber and Lyft, connect tens of\nthousands of vehicles in a city to millions of ride demands throughout the day,\nproviding great promises for improving transportation efficiency through the\ntasks of order dispatching and vehicle repositioning. Existing studies,\nhowever, usually consider the two tasks in simplified settings that hardly\naddress the complex interactions between the two, the real-time fluctuations\nbetween supply and demand, and the necessary coordinatio…",
          "link": "http://arxiv.org/abs/2105.08791",
          "publishedOn": "2021-05-22T06:24:28.189Z",
          "wordCount": 705,
          "title": "Value Function is All You Need: A Unified Learning Framework for Ride Hailing Platforms. (arXiv:2105.08791v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.11156",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Truong_L/0/1/0/all/0/1\">Lan V. Truong</a>",
          "description": "We establish exact asymptotic expressions for the normalized mutual\ninformation and minimum mean-square-error (MMSE) of sparse linear regression in\nthe sub-linear sparsity regime. Our result is achieved by a generalization of\nthe adaptive interpolation method in Bayesian inference for linear regimes to\nsub-linear ones. A modification of the well-known approximate message passing\nalgorithm to approach the MMSE fundamental limit is also proposed, and its\nstate evolution is rigorously analysed. Our results sho…",
          "link": "http://arxiv.org/abs/2101.11156",
          "publishedOn": "2021-05-22T06:24:28.182Z",
          "wordCount": 596,
          "title": "Fundamental limits and algorithms for sparse linear regression with sublinear sparsity. (arXiv:2101.11156v3 [cs.IT] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.06709",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lv_G/0/1/0/all/0/1\">Guofeng Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Zhiqiang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bi_Y/0/1/0/all/0/1\">Yanguang Bi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shaoting Zhang</a>",
          "description": "The study of multi-type Protein-Protein Interaction (PPI) is fundamental for\nunderstanding biological processes from a systematic perspective and revealing\ndisease mechanisms. Existing methods suffer from significant performance\ndegradation when tested in unseen dataset. In this paper, we investigate the\nproblem and find that it is mainly attributed to the poor performance for\ninter-novel-protein interaction prediction. However, current evaluations\noverlook the inter-novel-protein interactions, and thus fai…",
          "link": "http://arxiv.org/abs/2105.06709",
          "publishedOn": "2021-05-22T06:24:28.162Z",
          "wordCount": 631,
          "title": "Learning Unknown from Correlations: Graph Neural Network for Inter-novel-protein Interaction Prediction. (arXiv:2105.06709v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1812.00002",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1\">Mingyuan Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Na_S/0/1/0/all/0/1\">Sen Na</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Congzhou Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jin Xu</a>",
          "description": "Interactive news recommendation has been launched and attracted much\nattention recently. In this scenario, user's behavior evolves from single click\nbehavior to multiple behaviors including like, comment, share etc. However,\nmost of the existing methods still use single click behavior as the unique\ncriterion of judging user's preferences. Further, although heterogeneous graphs\nhave been applied in different areas, a proper way to construct a heterogeneous\ngraph for interactive news data with an appropriate …",
          "link": "http://arxiv.org/abs/1812.00002",
          "publishedOn": "2021-05-22T06:24:28.151Z",
          "wordCount": 678,
          "title": "The Graph-Based Behavior-Aware Recommendation for Interactive News. (arXiv:1812.00002v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.07239",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cramer_B/0/1/0/all/0/1\">Benjamin Cramer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Billaudelle_S/0/1/0/all/0/1\">Sebastian Billaudelle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanya_S/0/1/0/all/0/1\">Simeon Kanya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leibfried_A/0/1/0/all/0/1\">Aron Leibfried</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grubl_A/0/1/0/all/0/1\">Andreas Gr&#xfc;bl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karasenko_V/0/1/0/all/0/1\">Vitali Karasenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pehle_C/0/1/0/all/0/1\">Christian Pehle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schreiber_K/0/1/0/all/0/1\">Korbinian Schreiber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stradmann_Y/0/1/0/all/0/1\">Yannik Stradmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weis_J/0/1/0/all/0/1\">Johannes Weis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schemmel_J/0/1/0/all/0/1\">Johannes Schemmel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zenke_F/0/1/0/all/0/1\">Friedemann Zenke</a>",
          "description": "To rapidly process temporal information at a low metabolic cost, biological\nneurons integrate inputs as an analog sum but communicate with spikes, binary\nevents in time. Analog neuromorphic hardware uses the same principles to\nemulate spiking neural networks with exceptional energy-efficiency. However,\ninstantiating high-performing spiking networks on such hardware remains a\nsignificant challenge due to device mismatch and the lack of efficient training\nalgorithms. Here, we introduce a general in-the-loop l…",
          "link": "http://arxiv.org/abs/2006.07239",
          "publishedOn": "2021-05-22T06:24:28.143Z",
          "wordCount": 664,
          "title": "Surrogate gradients for analog neuromorphic computing. (arXiv:2006.07239v3 [cs.NE] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09872",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Yoon_J/0/1/0/all/0/1\">Jun Ho Yoon</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kim_S/0/1/0/all/0/1\">Seyoung Kim</a>",
          "description": "In many real-world problems, complex dependencies are present both among\nsamples and among features. The Kronecker sum or the Cartesian product of two\ngraphs, each modeling dependencies across features and across samples, has been\nused as an inverse covariance matrix for a matrix-variate Gaussian\ndistribution, as an alternative to a Kronecker-product inverse covariance\nmatrix, due to its more intuitive sparse structure. However, the existing\nmethods for sparse Kronecker-sum inverse covariance estimation are…",
          "link": "http://arxiv.org/abs/2105.09872",
          "publishedOn": "2021-05-22T06:24:28.136Z",
          "wordCount": 626,
          "title": "EiGLasso for Scalable Sparse Kronecker-Sum Inverse Covariance Estimation. (arXiv:2105.09872v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09564",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1\">Zhiqiang Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_C/0/1/0/all/0/1\">Cong Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yunxin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leng_J/0/1/0/all/0/1\">Jingwen Leng</a>",
          "description": "Leveraging sparsity in deep neural network (DNN) models is promising for\naccelerating model inference. Yet existing GPUs can only leverage the sparsity\nfrom weights but not activations, which are dynamic, unpredictable, and hence\nchallenging to exploit. In this work, we propose a novel architecture to\nefficiently harness the dual-side sparsity (i.e., weight and activation\nsparsity). We take a systematic approach to understand the (dis)advantages of\nprevious sparsity-related architectures and propose a novel…",
          "link": "http://arxiv.org/abs/2105.09564",
          "publishedOn": "2021-05-22T06:24:28.129Z",
          "wordCount": 586,
          "title": "Dual-side Sparse Tensor Core. (arXiv:2105.09564v1 [cs.AR])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09737",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Arnavaz_K/0/1/0/all/0/1\">Kasra Arnavaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krause_O/0/1/0/all/0/1\">Oswin Krause</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krivokapic_J/0/1/0/all/0/1\">Jelena M. Krivokapic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heilmann_S/0/1/0/all/0/1\">Silja Heilmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baerentzen_J/0/1/0/all/0/1\">Jakob Andreas B&#xe6;rentzen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nyeng_P/0/1/0/all/0/1\">Pia Nyeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feragen_A/0/1/0/all/0/1\">Aasa Feragen</a>",
          "description": "Motivated by a challenging tubular network segmentation task, this paper\ntackles two commonly encountered problems in biomedical imaging: Topological\nconsistency of the segmentation, and limited annotations. We propose a\ntopological score which measures both topological and geometric consistency\nbetween the predicted and ground truth segmentations, applied for model\nselection and validation. We apply our topological score in three scenarios: i.\na U-net ii. a U-net pretrained on an autoencoder, and iii. a se…",
          "link": "http://arxiv.org/abs/2105.09737",
          "publishedOn": "2021-05-22T06:24:28.111Z",
          "wordCount": 590,
          "title": "Semi-supervised, Topology-Aware Segmentation of Tubular Structures from Live Imaging 3D Microscopy. (arXiv:2105.09737v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09848",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yanli Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lake_B/0/1/0/all/0/1\">Brenden M. Lake</a>",
          "description": "Humans are highly efficient learners, with the ability to grasp the meaning\nof a new concept from just a few examples. Unlike popular computer vision\nsystems, humans can flexibly leverage the compositional structure of the visual\nworld, understanding new concepts as combinations of existing concepts. In the\ncurrent paper, we study how people learn different types of visual\ncompositions, using abstract visual forms with rich relational structure. We\nfind that people can make meaningful compositional generali…",
          "link": "http://arxiv.org/abs/2105.09848",
          "publishedOn": "2021-05-22T06:24:28.105Z",
          "wordCount": 587,
          "title": "Flexible Compositional Learning of Structured Visual Concepts. (arXiv:2105.09848v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09670",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_J/0/1/0/all/0/1\">Jingyi Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhu_H/0/1/0/all/0/1\">Huolan Zhu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1\">Yongkai Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yang_C/0/1/0/all/0/1\">Chenguang Yang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cheng_H/0/1/0/all/0/1\">Huimin Cheng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_Y/0/1/0/all/0/1\">Yi Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhong_W/0/1/0/all/0/1\">Wenxuan Zhong</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_F/0/1/0/all/0/1\">Fang Wang</a>",
          "description": "Background: Extensive clinical evidence suggests that a preventive screening\nof coronary heart disease (CHD) at an earlier stage can greatly reduce the\nmortality rate. We use 64 two-dimensional speckle tracking echocardiography\n(2D-STE) features and seven clinical features to predict whether one has CHD.\nMethods: We develop a machine learning approach that integrates a number of\npopular classification methods together by model stacking, and generalize the\ntraditional stacking method to a two-step stacking m…",
          "link": "http://arxiv.org/abs/2105.09670",
          "publishedOn": "2021-05-22T06:24:28.098Z",
          "wordCount": 612,
          "title": "Ensemble machine learning approach for screening of coronary heart disease based on echocardiography and risk factors. (arXiv:2105.09670v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09536",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Fried_S/0/1/0/all/0/1\">Sela Fried</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wolfer_G/0/1/0/all/0/1\">Geoffrey Wolfer</a>",
          "description": "We formulate extendibility of the minimax one-trajectory length of several\nstatistical Markov chains inference problems and give sufficient conditions for\nboth the possibility and impossibility of such extensions. We follow up and\napply this framework to recently published results on learning and identity\ntesting of ergodic Markov chains. In particular, we show that for some of the\naforementioned results, we can omit the aperiodicity requirement by simulating\nan $\\alpha$-lazy version of the original process…",
          "link": "http://arxiv.org/abs/2105.09536",
          "publishedOn": "2021-05-22T06:24:28.070Z",
          "wordCount": 516,
          "title": "On the $\\alpha$-lazy version of Markov chains in estimation and testing problems. (arXiv:2105.09536v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09675",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gruttemeier_N/0/1/0/all/0/1\">Niels Gr&#xfc;ttemeier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Komusiewicz_C/0/1/0/all/0/1\">Christian Komusiewicz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morawietz_N/0/1/0/all/0/1\">Nils Morawietz</a>",
          "description": "A Bayesian network is a directed acyclic graph that represents statistical\ndependencies between variables of a joint probability distribution. A\nfundamental task in data science is to learn a Bayesian network from observed\ndata. \\textsc{Polytree Learning} is the problem of learning an optimal Bayesian\nnetwork that fulfills the additional property that its underlying undirected\ngraph is a forest. In this work, we revisit the complexity of \\textsc{Polytree\nLearning}. We show that \\textsc{Polytree Learning} ca…",
          "link": "http://arxiv.org/abs/2105.09675",
          "publishedOn": "2021-05-22T06:24:28.056Z",
          "wordCount": 602,
          "title": "On the Parameterized Complexity of Polytree Learning. (arXiv:2105.09675v1 [cs.DS])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09469",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Frostig_R/0/1/0/all/0/1\">Roy Frostig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johnson_M/0/1/0/all/0/1\">Matthew J. Johnson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maclaurin_D/0/1/0/all/0/1\">Dougal Maclaurin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paszke_A/0/1/0/all/0/1\">Adam Paszke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radul_A/0/1/0/all/0/1\">Alexey Radul</a>",
          "description": "We decompose reverse-mode automatic differentiation into (forward-mode)\nlinearization followed by transposition. Doing so isolates the essential\ndifference between forward- and reverse-mode AD, and simplifies their joint\nimplementation. In particular, once forward-mode AD rules are defined for every\nprimitive operation in a source language, only linear primitives require an\nadditional transposition rule in order to arrive at a complete reverse-mode AD\nimplementation. This is how reverse-mode AD is written i…",
          "link": "http://arxiv.org/abs/2105.09469",
          "publishedOn": "2021-05-22T06:24:28.049Z",
          "wordCount": 507,
          "title": "Decomposing reverse-mode automatic differentiation. (arXiv:2105.09469v1 [cs.PL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09433",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Parulekar_A/0/1/0/all/0/1\">Aditya Parulekar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parulekar_A/0/1/0/all/0/1\">Advait Parulekar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Price_E/0/1/0/all/0/1\">Eric Price</a>",
          "description": "We consider the problem of finding an approximate solution to $\\ell_1$\nregression while only observing a small number of labels. Given an $n \\times d$\nunlabeled data matrix $X$, we must choose a small set of $m \\ll n$ rows to\nobserve the labels of, then output an estimate $\\widehat{\\beta}$ whose error on\nthe original problem is within a $1 + \\varepsilon$ factor of optimal. We show\nthat sampling from $X$ according to its Lewis weights and outputting the\nempirical minimizer succeeds with probability $1-\\delta…",
          "link": "http://arxiv.org/abs/2105.09433",
          "publishedOn": "2021-05-22T06:24:28.029Z",
          "wordCount": 552,
          "title": "L1 Regression with Lewis Weights Subsampling. (arXiv:2105.09433v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09384",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zhe Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_H/0/1/0/all/0/1\">Hanghang Tong</a>",
          "description": "The past decades have witnessed the prosperity of graph mining, with a\nmultitude of sophisticated models and algorithms designed for various mining\ntasks, such as ranking, classification, clustering and anomaly detection.\nGenerally speaking, the vast majority of the existing works aim to answer the\nfollowing question, that is, given a graph, what is the best way to mine it? In\nthis paper, we introduce the graph sanitation problem, to answer an orthogonal\nquestion. That is, given a mining task and an initial…",
          "link": "http://arxiv.org/abs/2105.09384",
          "publishedOn": "2021-05-22T06:24:28.022Z",
          "wordCount": 631,
          "title": "Graph Sanitation with Application to Node Classification. (arXiv:2105.09384v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09592",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bountrogiannis_K/0/1/0/all/0/1\">Konstantinos Bountrogiannis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tzagkarakis_G/0/1/0/all/0/1\">George Tzagkarakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsakalides_P/0/1/0/all/0/1\">Panagiotis Tsakalides</a>",
          "description": "Due to the importance of the lower bounding distances and the attractiveness\nof symbolic representations, the family of symbolic aggregate approximations\n(SAX) has been used extensively for encoding time series data. However, typical\nSAX-based methods rely on two restrictive assumptions; the Gaussian\ndistribution and equiprobable symbols. This paper proposes two novel\ndata-driven SAX-based symbolic representations, distinguished by their\ndiscretization steps. The first representation, oriented for general d…",
          "link": "http://arxiv.org/abs/2105.09592",
          "publishedOn": "2021-05-22T06:24:28.014Z",
          "wordCount": 634,
          "title": "Distribution Agnostic Symbolic Representations for Time Series Dimensionality Reduction and Online Anomaly Detection. (arXiv:2105.09592v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09406",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Javaheri_B/0/1/0/all/0/1\">Behzad Javaheri</a>",
          "description": "Herein, we have compared the performance of SVM and MLP in emotion\nrecognition using speech and song channels of the RAVDESS dataset. We have\nundertaken a journey to extract various audio features, identify optimal\nscaling strategy and hyperparameter for our models. To increase sample size, we\nhave performed audio data augmentation and addressed data imbalance using\nSMOTE. Our data indicate that optimised SVM outperforms MLP with an accuracy of\n82 compared to 75%. Following data augmentation, the performanc…",
          "link": "http://arxiv.org/abs/2105.09406",
          "publishedOn": "2021-05-22T06:24:27.993Z",
          "wordCount": 576,
          "title": "Speech & Song Emotion Recognition Using Multilayer Perceptron and Standard Vector Machine. (arXiv:2105.09406v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09421",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1\">Ming-Chang Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jia-Chun Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gran_E/0/1/0/all/0/1\">Ernst Gunnar Gran</a>",
          "description": "Over the past decade, many approaches have been introduced for traffic speed\nprediction. However, providing fine-grained, accurate, time-efficient, and\nadaptive traffic speed prediction for a growing transportation network where\nthe size of the network keeps increasing and new traffic detectors are\nconstantly deployed has not been well studied. To address this issue, this\npaper presents DistTune based on Long Short-Term Memory (LSTM) and the\nNelder-Mead method. Whenever encountering an unprocessed detector,…",
          "link": "http://arxiv.org/abs/2105.09421",
          "publishedOn": "2021-05-22T06:24:27.976Z",
          "wordCount": 658,
          "title": "DistTune: Distributed Fine-Grained Adaptive Traffic Speed Prediction for Growing Transportation Networks. (arXiv:2105.09421v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09446",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lowe_E/0/1/0/all/0/1\">Evan Lowe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guvenc_L/0/1/0/all/0/1\">Levent Guven&#xe7;</a>",
          "description": "As passenger vehicle technologies have advanced, so have their capabilities\nto avoid obstacles, especially with developments in tires, suspensions,\nsteering, as well as safety technologies like ABS, ESC, and more recently, ADAS\nsystems. However, environments around passenger vehicles have also become more\ncomplex, and dangerous. There have previously been studies that outline driver\ntendencies and performance capabilities when attempting to avoid obstacles\nwhile driving passenger vehicles. Now that autonomo…",
          "link": "http://arxiv.org/abs/2105.09446",
          "publishedOn": "2021-05-22T06:24:27.969Z",
          "wordCount": 619,
          "title": "A Review of Autonomous Road Vehicle Integrated Approaches to an Emergency Obstacle Avoidance Maneuver. (arXiv:2105.09446v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09468",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Tang_H/0/1/0/all/0/1\">Hewei Tang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Fu_P/0/1/0/all/0/1\">Pengcheng Fu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Sherman_C/0/1/0/all/0/1\">Christopher S. Sherman</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Zhang_J/0/1/0/all/0/1\">Jize Zhang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Ju_X/0/1/0/all/0/1\">Xin Ju</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Hamon_F/0/1/0/all/0/1\">Fran&#xe7;ois Hamon</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Azzolina_N/0/1/0/all/0/1\">Nicholas A. Azzolina</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Burton_Kelly_M/0/1/0/all/0/1\">Matthew Burton-Kelly</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Morris_J/0/1/0/all/0/1\">Joseph P. Morris</a>",
          "description": "Fast assimilation of monitoring data to update forecasts of pressure buildup\nand carbon dioxide (CO2) plume migration under geologic uncertainties is a\nchallenging problem in geologic carbon storage. The high computational cost of\ndata assimilation with a high-dimensional parameter space impedes fast\ndecision-making for commercial-scale reservoir management. We propose to\nleverage physical understandings of porous medium flow behavior with deep\nlearning techniques to develop a fast history matching-reservoi…",
          "link": "http://arxiv.org/abs/2105.09468",
          "publishedOn": "2021-05-22T06:24:27.908Z",
          "wordCount": 658,
          "title": "A Deep Learning-Accelerated Data Assimilation and Forecasting Workflow for Commercial-Scale Geologic Carbon Storage. (arXiv:2105.09468v1 [physics.geo-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09467",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Yan_B/0/1/0/all/0/1\">Bicheng Yan</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Harp_D/0/1/0/all/0/1\">Dylan Robert Harp</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Chen_B/0/1/0/all/0/1\">Bailian Chen</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Pawar_R/0/1/0/all/0/1\">Rajesh Pawar</a>",
          "description": "In this work, an efficient physics-constrained deep learning model is\ndeveloped for solving multiphase flow in 3D heterogeneous porous media. The\nmodel fully leverages the spatial topology predictive capability of\nconvolutional neural networks, and is coupled with an efficient\ncontinuity-based smoother to predict flow responses that need spatial\ncontinuity. Furthermore, the transient regions are penalized to steer the\ntraining process such that the model can accurately capture flow in these\nregions. The mod…",
          "link": "http://arxiv.org/abs/2105.09467",
          "publishedOn": "2021-05-22T06:24:27.895Z",
          "wordCount": 727,
          "title": "A Physics-Constrained Deep Learning Model for Simulating Multiphase Flow in 3D Heterogeneous Porous Media. (arXiv:2105.09467v1 [physics.geo-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09394",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Seungyeon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glasner_D/0/1/0/all/0/1\">Daniel Glasner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramalingam_S/0/1/0/all/0/1\">Srikumar Ramalingam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1\">Cho-Jui Hsieh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papineni_K/0/1/0/all/0/1\">Kishore Papineni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Sanjiv Kumar</a>",
          "description": "It is generally believed that robust training of extremely large networks is\ncritical to their success in real-world applications. However, when taken to\nthe extreme, methods that promote robustness can hurt the model's sensitivity\nto rare or underrepresented patterns. In this paper, we discuss this trade-off\nbetween sensitivity and robustness to natural (non-adversarial) perturbations\nby introducing two notions: contextual feature utility and contextual feature\nsensitivity. We propose Feature Contrastive L…",
          "link": "http://arxiv.org/abs/2105.09394",
          "publishedOn": "2021-05-22T06:24:27.827Z",
          "wordCount": 552,
          "title": "Balancing Robustness and Sensitivity using Feature Contrastive Learning. (arXiv:2105.09394v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09352",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Drain_D/0/1/0/all/0/1\">Dawn Drain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clement_C/0/1/0/all/0/1\">Colin B. Clement</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Serrato_G/0/1/0/all/0/1\">Guillermo Serrato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sundaresan_N/0/1/0/all/0/1\">Neel Sundaresan</a>",
          "description": "The joint task of bug localization and program repair is an integral part of\nthe software development process. In this work we present DeepDebug, an\napproach to automated debugging using large, pretrained transformers. We begin\nby training a bug-creation model on reversed commit data for the purpose of\ngenerating synthetic bugs. We apply these synthetic bugs toward two ends.\nFirst, we directly train a backtranslation model on all functions from 200K\nrepositories. Next, we focus on 10K repositories for which…",
          "link": "http://arxiv.org/abs/2105.09352",
          "publishedOn": "2021-05-22T06:24:27.776Z",
          "wordCount": 678,
          "title": "DeepDebug: Fixing Python Bugs Using Stack Traces, Backtranslation, and Code Skeletons. (arXiv:2105.09352v1 [cs.SE])"
        }
      ]
    }
  ],
  "cliVersion": "1.8.1"
}