{
  "sources": [
    {
      "title": "cs.CL updates on arXiv.org",
      "feedUrl": "http://export.arxiv.org/rss/cs.CL",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2106.05426",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Antonello_R/0/1/0/all/0/1\">Richard Antonello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turek_J/0/1/0/all/0/1\">Javier Turek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vo_V/0/1/0/all/0/1\">Vy Vo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huth_A/0/1/0/all/0/1\">Alexander Huth</a>",
          "description": "How related are the representations learned by neural language models,\ntranslation models, and language tagging tasks? We answer this question by\nadapting an encoder-decoder transfer learning method from computer vision to\ninvestigate the structure among 100 different feature spaces extracted from\nhidden representations of various networks trained on language tasks. This\nmethod reveals a low-dimensional structure where language models and\ntranslation models smoothly interpolate between word embeddings, syntactic and\nsemantic tasks, and future word embeddings. We call this low-dimensional\nstructure a language representation embedding because it encodes the\nrelationships between representations needed to process language for a variety\nof NLP tasks. We find that this representation embedding can predict how well\neach individual feature space maps to human brain responses to natural language\nstimuli recorded using fMRI. Additionally, we find that the principal dimension\nof this structure can be used to create a metric which highlights the brain's\nnatural language processing hierarchy. This suggests that the embedding\ncaptures some part of the brain's natural language representation structure.",
          "link": "http://arxiv.org/abs/2106.05426",
          "publishedOn": "2021-06-17T15:44:16.262Z",
          "wordCount": 628,
          "title": "Low-Dimensional Structure in the Space of Language Representations is Reflected in Brain Responses. (arXiv:2106.05426v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04426",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roller_S/0/1/0/all/0/1\">Stephen Roller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sukhbaatar_S/0/1/0/all/0/1\">Sainbayar Sukhbaatar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szlam_A/0/1/0/all/0/1\">Arthur Szlam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weston_J/0/1/0/all/0/1\">Jason Weston</a>",
          "description": "We investigate the training of sparse layers that use different parameters\nfor different inputs based on hashing in large Transformer models.\nSpecifically, we modify the feedforward layer to hash to different sets of\nweights depending on the current token, over all tokens in the sequence. We\nshow that this procedure either outperforms or is competitive with\nlearning-to-route mixture-of-expert methods such as Switch Transformers and\nBASE Layers, while requiring no routing parameters or extra terms in the\nobjective function such as a load balancing loss, and no sophisticated\nassignment algorithm. We study the performance of different hashing techniques,\nhash sizes and input features, and show that balanced and random hashes focused\non the most local features work best, compared to either learning clusters or\nusing longer-range context. We show our approach works well both on large\nlanguage modeling and dialogue tasks, and on downstream fine-tuning tasks.",
          "link": "http://arxiv.org/abs/2106.04426",
          "publishedOn": "2021-06-17T01:58:44.889Z",
          "wordCount": 587,
          "title": "Hash Layers For Large Sparse Models. (arXiv:2106.04426v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08829",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheema_G/0/1/0/all/0/1\">Gullal S. Cheema</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hakimov_S/0/1/0/all/0/1\">Sherzod Hakimov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muller_Budack_E/0/1/0/all/0/1\">Eric M&#xfc;ller-Budack</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ewerth_R/0/1/0/all/0/1\">Ralph Ewerth</a>",
          "description": "Opinion and sentiment analysis is a vital task to characterize subjective\ninformation in social media posts. In this paper, we present a comprehensive\nexperimental evaluation and comparison with six state-of-the-art methods, from\nwhich we have re-implemented one of them. In addition, we investigate different\ntextual and visual feature embeddings that cover different aspects of the\ncontent, as well as the recently introduced multimodal CLIP embeddings.\nExperimental results are presented for two different publicly available\nbenchmark datasets of tweets and corresponding images. In contrast to the\nevaluation methodology of previous work, we introduce a reproducible and fair\nevaluation scheme to make results comparable. Finally, we conduct an error\nanalysis to outline the limitations of the methods and possibilities for the\nfuture work.",
          "link": "http://arxiv.org/abs/2106.08829",
          "publishedOn": "2021-06-17T01:58:43.289Z",
          "wordCount": 583,
          "title": "A Fair and Comprehensive Comparison of Multimodal Tweet Sentiment Analysis Methods. (arXiv:2106.08829v1 [cs.SI])"
        },
        {
          "id": "http://arxiv.org/abs/2012.15788",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Thorne_J/0/1/0/all/0/1\">James Thorne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vlachos_A/0/1/0/all/0/1\">Andreas Vlachos</a>",
          "description": "This paper introduces the task of factual error correction: performing edits\nto a claim so that the generated rewrite is better supported by evidence. This\nextends the well-studied task of fact verification by providing a mechanism to\ncorrect written texts that are refuted or only partially supported by evidence.\nWe demonstrate that it is feasible to train factual error correction systems\nfrom existing fact checking datasets which only contain labeled claims\naccompanied by evidence, but not the correction. We achieve this by employing a\ntwo-stage distant supervision approach that incorporates evidence into masked\nclaims when generating corrections. Our approach, based on the T5 transformer\nand using retrieved evidence, achieved better results than existing work which\nused a pointer copy network and gold evidence, producing accurate factual error\ncorrections for 5x more instances in human evaluation and a .125 increase in\nSARI score. The evaluation is conducted on a dataset of 65,000 instances based\non a recent fact verification shared task and we release it to enable further\nwork on the task.",
          "link": "http://arxiv.org/abs/2012.15788",
          "publishedOn": "2021-06-17T01:58:42.859Z",
          "wordCount": 620,
          "title": "Evidence-based Factual Error Correction. (arXiv:2012.15788v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.01345",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hipson_W/0/1/0/all/0/1\">Will E. Hipson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohammad_S/0/1/0/all/0/1\">Saif M. Mohammad</a>",
          "description": "Emotion dynamics is a framework for measuring how an individual's emotions\nchange over time. It is a powerful tool for understanding how we behave and\ninteract with the world. In this paper, we introduce a framework to track\nemotion dynamics through one's utterances. Specifically we introduce a number\nof utterance emotion dynamics (UED) metrics inspired by work in Psychology. We\nuse this approach to trace emotional arcs of movie characters. We analyze\nthousands of such character arcs to test hypotheses that inform our broader\nunderstanding of stories. Notably, we show that there is a tendency for\ncharacters to use increasingly more negative words and become increasingly\nemotionally discordant with each other until about 90 percent of the narrative\nlength. UED also has applications in behavior studies, social sciences, and\npublic health.",
          "link": "http://arxiv.org/abs/2103.01345",
          "publishedOn": "2021-06-17T01:58:42.811Z",
          "wordCount": 589,
          "title": "Emotion Dynamics in Movie Dialogues. (arXiv:2103.01345v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08927",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Boes_W/0/1/0/all/0/1\">Wim Boes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rompaey_R/0/1/0/all/0/1\">Robbe Van Rompaey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verwimp_L/0/1/0/all/0/1\">Lyan Verwimp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pelemans_J/0/1/0/all/0/1\">Joris Pelemans</a>, <a href=\"http://arxiv.org/find/cs/1/au:+hamme_H/0/1/0/all/0/1\">Hugo Van hamme</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wambacq_P/0/1/0/all/0/1\">Patrick Wambacq</a>",
          "description": "We inspect the long-term learning ability of Long Short-Term Memory language\nmodels (LSTM LMs) by evaluating a contextual extension based on the Continuous\nBag-of-Words (CBOW) model for both sentence- and discourse-level LSTM LMs and\nby analyzing its performance. We evaluate on text and speech. Sentence-level\nmodels using the long-term contextual module perform comparably to vanilla\ndiscourse-level LSTM LMs. On the other hand, the extension does not provide\ngains for discourse-level models. These findings indicate that discourse-level\nLSTM LMs already rely on contextual information to perform long-term learning.",
          "link": "http://arxiv.org/abs/2106.08927",
          "publishedOn": "2021-06-17T01:58:42.805Z",
          "wordCount": 540,
          "title": "On the long-term learning ability of LSTM LMs. (arXiv:2106.08927v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08785",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zaijing Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_F/0/1/0/all/0/1\">Fengxiao Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_T/0/1/0/all/0/1\">Tieyu Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yusen Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_M/0/1/0/all/0/1\">Ming Zhao</a>",
          "description": "For the task of conversation emotion recognition, recent works focus on\nspeaker relationship modeling but ignore the role of utterance's emotional\ntendency.In this paper, we propose a new expression paradigm of sentence-level\nemotion orientation vector to model the potential correlation of emotions\nbetween sentence vectors. Based on it, we design an emotion recognition model,\nwhich extracts the sentence-level emotion orientation vectors from the language\nmodel and jointly learns from the dialogue sentiment analysis model and\nextracted sentence-level emotion orientation vectors to identify the speaker's\nemotional orientation during the conversation. We conduct experiments on two\nbenchmark datasets and compare them with the five baseline models.The\nexperimental results show that our model has better performance on all data\nsets.",
          "link": "http://arxiv.org/abs/2106.08785",
          "publishedOn": "2021-06-17T01:58:42.405Z",
          "wordCount": 555,
          "title": "SEOVER: Sentence-level Emotion Orientation Vector based Conversation Emotion Recognition Model. (arXiv:2106.08785v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08427",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Illa_M/0/1/0/all/0/1\">Marc Illa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Halpern_B/0/1/0/all/0/1\">Bence Mark Halpern</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Son_R/0/1/0/all/0/1\">Rob van Son</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moro_Velazquez_L/0/1/0/all/0/1\">Laureano Moro-Velazquez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scharenborg_O/0/1/0/all/0/1\">Odette Scharenborg</a>",
          "description": "In this paper, we propose a new approach to pathological speech synthesis.\nInstead of using healthy speech as a source, we customise an existing\npathological speech sample to a new speaker's voice characteristics. This\napproach alleviates the evaluation problem one normally has when converting\ntypical speech to pathological speech, as in our approach, the voice conversion\n(VC) model does not need to be optimised for speech degradation but only for\nthe speaker change. This change in the optimisation ensures that any\ndegradation found in naturalness is due to the conversion process and not due\nto the model exaggerating characteristics of a speech pathology. To show a\nproof of concept of this method, we convert dysarthric speech using the\nUASpeech database and an autoencoder-based VC technique. Subjective evaluation\nresults show reasonable naturalness for high intelligibility dysarthric\nspeakers, though lower intelligibility seems to introduce a marginal\ndegradation in naturalness scores for mid and low intelligibility speakers\ncompared to ground truth. Conversion of speaker characteristics for low and\nhigh intelligibility speakers is successful, but not for mid. Whether the\ndifferences in the results for the different intelligibility levels is due to\nthe intelligibility levels or due to the speakers needs to be further\ninvestigated.",
          "link": "http://arxiv.org/abs/2106.08427",
          "publishedOn": "2021-06-17T01:58:42.393Z",
          "wordCount": 650,
          "title": "Pathological voice adaptation with autoencoder-based voice conversion. (arXiv:2106.08427v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08838",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Hsien-chin Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lubis_N/0/1/0/all/0/1\">Nurul Lubis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1\">Songbo Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niekerk_C/0/1/0/all/0/1\">Carel van Niekerk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geishauser_C/0/1/0/all/0/1\">Christian Geishauser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heck_M/0/1/0/all/0/1\">Michael Heck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1\">Shutong Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gasic_M/0/1/0/all/0/1\">Milica Ga&#x161;i&#x107;</a>",
          "description": "Dialogue policy optimisation via reinforcement learning requires a large\nnumber of training interactions, which makes learning with real users time\nconsuming and expensive. Many set-ups therefore rely on a user simulator\ninstead of humans. These user simulators have their own problems. While\nhand-coded, rule-based user simulators have been shown to be sufficient in\nsmall, simple domains, for complex domains the number of rules quickly becomes\nintractable. State-of-the-art data-driven user simulators, on the other hand,\nare still domain-dependent. This means that adaptation to each new domain\nrequires redesigning and retraining. In this work, we propose a\ndomain-independent transformer-based user simulator (TUS). The structure of our\nTUS is not tied to a specific domain, enabling domain generalisation and\nlearning of cross-domain user behaviour from data. We compare TUS with the\nstate of the art using automatic as well as human evaluations. TUS can compete\nwith rule-based user simulators on pre-defined domains and is able to\ngeneralise to unseen domains in a zero-shot fashion.",
          "link": "http://arxiv.org/abs/2106.08838",
          "publishedOn": "2021-06-17T01:58:42.340Z",
          "wordCount": 597,
          "title": "Domain-independent User Simulation with Transformers for Task-oriented Dialogue Systems. (arXiv:2106.08838v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08694",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Baroni_M/0/1/0/all/0/1\">Marco Baroni</a>",
          "description": "A lively research field has recently emerged that uses experimental methods\nto probe the linguistic behavior of modern deep networks. While work in this\ntradition often reports intriguing results about the grammatical skills of deep\nnets, it is not clear what their implications for linguistic theorizing should\nbe. As a consequence, linguistically-oriented deep net analysis has had very\nlittle impact on linguistics at large. In this chapter, I suggest that deep\nnetworks should be treated as theories making explicit predictions about the\nacceptability of linguistic utterances. I argue that, if we overcome some\nobstacles standing in the way of seriously pursuing this idea, we will gain a\npowerful new theoretical tool, complementary to mainstream algebraic\napproaches.",
          "link": "http://arxiv.org/abs/2106.08694",
          "publishedOn": "2021-06-17T01:58:42.035Z",
          "wordCount": 559,
          "title": "On the proper role of linguistically-oriented deep net analysis in linguistic theorizing. (arXiv:2106.08694v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2102.12136",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1\">Duc-Vu Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1\">Kiet Van Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1\">Ngan Luu-Thuy Nguyen</a>",
          "description": "Word segmentation and part-of-speech tagging are two critical preliminary\nsteps for downstream tasks in Vietnamese natural language processing. In\nreality, people tend to consider also the phrase boundary when performing word\nsegmentation and part of speech tagging rather than solely process word by word\nfrom left to right. In this paper, we implement this idea to improve word\nsegmentation and part of speech tagging the Vietnamese language by employing a\nsimplified constituency parser. Our neural model for joint word segmentation\nand part-of-speech tagging has the architecture of the syllable-based CRF\nconstituency parser. To reduce the complexity of parsing, we replace all\nconstituent labels with a single label indicating for phrases. This model can\nbe augmented with predicted word boundary and part-of-speech tags by other\ntools. Because Vietnamese and Chinese have some similar linguistic phenomena,\nwe evaluated the proposed model and its augmented versions on three Vietnamese\nbenchmark datasets and six Chinese benchmark datasets. Our experimental results\nshow that the proposed model achieves higher performances than previous works\nfor both languages.",
          "link": "http://arxiv.org/abs/2102.12136",
          "publishedOn": "2021-06-17T01:58:41.744Z",
          "wordCount": 662,
          "title": "Augmenting Part-of-speech Tagging with Syntactic Information for Vietnamese and Chinese. (arXiv:2102.12136v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.15525",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qi_W/0/1/0/all/0/1\">Weizhen Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1\">Yeyun Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_J/0/1/0/all/0/1\">Jian Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1\">Yu Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Weizhu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1\">Dayiheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_K/0/1/0/all/0/1\">Kewen Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Houqiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiusheng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ruofei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1\">Ming Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1\">Nan Duan</a>",
          "description": "In this paper, we propose BANG, a new pretraining model to Bridge the gap\nbetween Autoregressive (AR) and Non-autoregressive (NAR) Generation. AR and NAR\ngeneration can be uniformly regarded as to what extent previous tokens can be\nattended, and BANG bridges AR and NAR generation by designing a novel model\nstructure for large-scale pretraining. The pretrained BANG model can\nsimultaneously support AR, NAR and semi-NAR generation to meet different\nrequirements. Experiments on question generation (SQuAD 1.1), summarization\n(XSum) and dialogue generation (PersonaChat) show that BANG improves NAR and\nsemi-NAR performance significantly as well as attaining comparable performance\nwith strong AR pretrained models. Compared with the semi-NAR strong baselines,\nBANG achieves absolute improvements of 14.01 and 5.24 in the overall scores of\nSQuAD 1.1 and XSum, respectively. In addition, BANG achieves absolute\nimprovements of 10.73, 6.39 and 5.90 in the overall scores of SQuAD, XSUM and\nPersonaChat respectively compared with the strong NAR baselines.",
          "link": "http://arxiv.org/abs/2012.15525",
          "publishedOn": "2021-06-17T01:58:41.703Z",
          "wordCount": 644,
          "title": "BANG: Bridging Autoregressive and Non-autoregressive Generation with Large Scale Pretraining. (arXiv:2012.15525v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.06762",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yulong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Liang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>",
          "description": "Proposal of large-scale datasets has facilitated research on deep neural\nmodels for news summarization. Deep learning can also be potentially useful for\nspoken dialogue summarization, which can benefit a range of real-life scenarios\nincluding customer service management and medication tracking. To this end, we\npropose DialogSum, a large-scale labeled dialogue summarization dataset. We\nconduct empirical analysis on DialogSum using state-of-the-art neural\nsummarizers. Experimental results show unique challenges in dialogue\nsummarization, such as spoken terms, special discourse structures, coreferences\nand ellipsis, pragmatics and social common sense, which require specific\nrepresentation learning technologies to better deal with.",
          "link": "http://arxiv.org/abs/2105.06762",
          "publishedOn": "2021-06-17T01:58:41.617Z",
          "wordCount": 571,
          "title": "DialogSum: A Real-Life Scenario Dialogue Summarization Dataset. (arXiv:2105.06762v4 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09002",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_H/0/1/0/all/0/1\">Haipeng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1\">Kun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yuxue Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zakari_R/0/1/0/all/0/1\">Rufai Yusuf Zakari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Owusu_J/0/1/0/all/0/1\">Jim Wilson Owusu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_K/0/1/0/all/0/1\">Ke Qin</a>",
          "description": "Knowledge graph embedding has been an active research topic for knowledge\nbase completion (KGC), with progressive improvement from the initial TransE,\nTransH, RotatE et al to the current state-of-the-art QuatE. However, QuatE\nignores the multi-faceted nature of the entity and the complexity of the\nrelation, only using rigorous operation on quaternion space to capture the\ninteraction between entitiy pair and relation, leaving opportunities for better\nknowledge representation which will finally help KGC. In this paper, we propose\na novel model, QuatDE, with a dynamic mapping strategy to explicitly capture\nthe variety of relational patterns and separate different semantic information\nof the entity, using transition vectors to adjust the point position of the\nentity embedding vectors in the quaternion space via Hamilton product,\nenhancing the feature interaction capability between elements of the triplet.\nExperiment results show QuatDE achieves state-of-the-art performance on three\nwell-established knowledge graph completion benchmarks. In particular, the MR\nevaluation has relatively increased by 26% on WN18 and 15% on WN18RR, which\nproves the generalization of QuatDE.",
          "link": "http://arxiv.org/abs/2105.09002",
          "publishedOn": "2021-06-17T01:58:41.610Z",
          "wordCount": 627,
          "title": "QuatDE: Dynamic Quaternion Embedding for Knowledge Graph Completion. (arXiv:2105.09002v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.08459",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Mussakhojayeva_S/0/1/0/all/0/1\">Saida Mussakhojayeva</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Janaliyeva_A/0/1/0/all/0/1\">Aigerim Janaliyeva</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mirzakhmetov_A/0/1/0/all/0/1\">Almas Mirzakhmetov</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Khassanov_Y/0/1/0/all/0/1\">Yerbolat Khassanov</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Varol_H/0/1/0/all/0/1\">Huseyin Atakan Varol</a>",
          "description": "This paper introduces a high-quality open-source speech synthesis dataset for\nKazakh, a low-resource language spoken by over 13 million people worldwide. The\ndataset consists of about 93 hours of transcribed audio recordings spoken by\ntwo professional speakers (female and male). It is the first publicly available\nlarge-scale dataset developed to promote Kazakh text-to-speech (TTS)\napplications in both academia and industry. In this paper, we share our\nexperience by describing the dataset development procedures and faced\nchallenges, and discuss important future directions. To demonstrate the\nreliability of our dataset, we built baseline end-to-end TTS models and\nevaluated them using the subjective mean opinion score (MOS) measure.\nEvaluation results show that the best TTS models trained on our dataset achieve\nMOS above 4 for both speakers, which makes them applicable for practical use.\nThe dataset, training recipe, and pretrained TTS models are freely available.",
          "link": "http://arxiv.org/abs/2104.08459",
          "publishedOn": "2021-06-17T01:58:41.604Z",
          "wordCount": 619,
          "title": "KazakhTTS: An Open-Source Kazakh Text-to-Speech Synthesis Dataset. (arXiv:2104.08459v3 [eess.AS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.01454",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pillutla_K/0/1/0/all/0/1\">Krishna Pillutla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swayamdipta_S/0/1/0/all/0/1\">Swabha Swayamdipta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zellers_R/0/1/0/all/0/1\">Rowan Zellers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thickstun_J/0/1/0/all/0/1\">John Thickstun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Welleck_S/0/1/0/all/0/1\">Sean Welleck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harchaoui_Z/0/1/0/all/0/1\">Zaid Harchaoui</a>",
          "description": "As major progress is made in open-ended text generation, measuring how close\nmachine-generated text is to human language remains a critical open problem. We\npropose Mauve, a comparison measure for open-ended text generation, which\ndirectly compares a generation model's distribution to that of human-written\ntext. Mauve measures the mean area under a divergence curve for the two\ndistributions, exploring the trade-off between two types of errors: those\narising from parts of the human distribution that the model distribution\napproximates well, and those it does not. Mauve extends a family of information\ndivergence metrics, introducing a tractable approximation based on computing\nthe KL divergence in a quantized embedding space. This yields an efficient\nimplementation that scales up to modern text generation models. Through an\nextensive empirical study on three open-ended generation tasks, we find that\nMauve identifies known properties of generated text, scales naturally with\nmodel size, and correlates with human judgments, with fewer restrictions than\nexisting distributional evaluation metrics.",
          "link": "http://arxiv.org/abs/2102.01454",
          "publishedOn": "2021-06-17T01:58:41.552Z",
          "wordCount": 625,
          "title": "An Information Divergence Measure Between Neural Text and Human Text. (arXiv:2102.01454v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.06274",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Korencic_D/0/1/0/all/0/1\">Damir Koren&#x10d;i&#x107;</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Ristov_S/0/1/0/all/0/1\">Strahil Ristov</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Repar_J/0/1/0/all/0/1\">Jelena Repar</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Snajder_J/0/1/0/all/0/1\">Jan &#x160;najder</a> (2) ((1) Rudjer Bo&#x161;kovi&#x107; Institute, Croatia, (2) University of Zagreb, Faculty of Electrical Engineering and Computing, Croatia)",
          "description": "Topic models are widely used unsupervised models of text capable of learning\ntopics - weighted lists of words and documents - from large collections of text\ndocuments. When topic models are used for discovery of topics in text\ncollections, a question that arises naturally is how well the model-induced\ntopics correspond to topics of interest to the analyst. In this paper we\nrevisit and extend a so far neglected approach to topic model evaluation based\non measuring topic coverage - computationally matching model topics with a set\nof reference topics that models are expected to uncover. The approach is well\nsuited for analyzing models' performance in topic discovery and for large-scale\nanalysis of both topic models and measures of model quality. We propose new\nmeasures of coverage and evaluate, in a series of experiments, different types\nof topic models on two distinct text domains for which interest for topic\ndiscovery exists. The experiments include evaluation of model quality, analysis\nof coverage of distinct topic categories, and the analysis of the relationship\nbetween coverage and other methods of topic model evaluation. The contributions\nof the paper include new measures of coverage, insights into both topic models\nand other methods of model evaluation, and the datasets and code for\nfacilitating future research of both topic coverage and other approaches to\ntopic model evaluation.",
          "link": "http://arxiv.org/abs/2012.06274",
          "publishedOn": "2021-06-17T01:58:41.545Z",
          "wordCount": 741,
          "title": "A Topic Coverage Approach to Evaluation of Topic Models. (arXiv:2012.06274v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.08529",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1\">Yu Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Wei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kerz_E/0/1/0/all/0/1\">Elma Kerz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schluter_R/0/1/0/all/0/1\">Ralf Schl&#xfc;ter</a>",
          "description": "In recent years, automated approaches to assessing linguistic complexity in\nsecond language (L2) writing have made significant progress in gauging learner\nperformance, predicting human ratings of the quality of learner productions,\nand benchmarking L2 development. In contrast, there is comparatively little\nwork in the area of speaking, particularly with respect to fully automated\napproaches to assessing L2 spontaneous speech. While the importance of a\nwell-performing ASR system is widely recognized, little research has been\nconducted to investigate the impact of its performance on subsequent automatic\ntext analysis. In this paper, we focus on this issue and examine the impact of\nusing a state-of-the-art ASR system for subsequent automatic analysis of\nlinguistic complexity in spontaneously produced L2 speech. A set of 30 selected\nmeasures were considered, falling into four categories: syntactic, lexical,\nn-gram frequency, and information-theoretic measures. The agreement between the\nscores for these measures obtained on the basis of ASR-generated vs. manual\ntranscriptions was determined through correlation analysis. A more differential\neffect of ASR performance on specific types of complexity measures when\ncontrolling for task type effects is also presented.",
          "link": "http://arxiv.org/abs/2104.08529",
          "publishedOn": "2021-06-17T01:58:41.539Z",
          "wordCount": 655,
          "title": "The Impact of ASR on the Automatic Analysis of Linguistic Complexity and Sophistication in Spontaneous L2 Speech. (arXiv:2104.08529v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.10415",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yao_H/0/1/0/all/0/1\">Huihan Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Ying Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_Q/0/1/0/all/0/1\">Qinyuan Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1\">Xisen Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>",
          "description": "Pre-trained language models have been successful on text classification\ntasks, but are prone to learning spurious correlations from biased datasets,\nand are thus vulnerable when making inferences in a new domain. Prior works\nreveal such spurious patterns via post-hoc explanation algorithms which compute\nthe importance of input features. Further, the model is regularized to align\nthe importance scores with human knowledge, so that the unintended model\nbehaviors are eliminated. However, such a regularization technique lacks\nflexibility and coverage, since only importance scores towards a pre-defined\nlist of features are adjusted, while more complex human knowledge such as\nfeature interaction and pattern generalization can hardly be incorporated. In\nthis work, we propose to refine a learned language model for a target domain by\ncollecting human-provided compositional explanations regarding observed biases.\nBy parsing these explanations into executable logic rules, the human-specified\nrefinement advice from a small set of explanations can be generalized to more\ntraining examples. We additionally introduce a regularization term allowing\nadjustments for both importance and interaction of features to better rectify\nmodel behavior. We demonstrate the effectiveness of the proposed approach on\ntwo text classification tasks by showing improved performance in target domain\nas well as improved model fairness after refinement.",
          "link": "http://arxiv.org/abs/2103.10415",
          "publishedOn": "2021-06-17T01:58:41.531Z",
          "wordCount": 663,
          "title": "Refining Language Models with Compositional Explanations. (arXiv:2103.10415v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.11348",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rio_M/0/1/0/all/0/1\">Miguel Del Rio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Delworth_N/0/1/0/all/0/1\">Natalie Delworth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Westerman_R/0/1/0/all/0/1\">Ryan Westerman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Michelle Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhandari_N/0/1/0/all/0/1\">Nishchal Bhandari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Palakapilly_J/0/1/0/all/0/1\">Joseph Palakapilly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McNamara_Q/0/1/0/all/0/1\">Quinten McNamara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1\">Joshua Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zelasko_P/0/1/0/all/0/1\">Piotr Zelasko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jette_M/0/1/0/all/0/1\">Miguel Jette</a>",
          "description": "Commonly used speech corpora inadequately challenge academic and commercial\nASR systems. In particular, speech corpora lack metadata needed for detailed\nanalysis and WER measurement. In response, we present Earnings-21, a 39-hour\ncorpus of earnings calls containing entity-dense speech from nine different\nfinancial sectors. This corpus is intended to benchmark ASR systems in the wild\nwith special attention towards named entity recognition. We benchmark four\ncommercial ASR models, two internal models built with open-source tools, and an\nopen-source LibriSpeech model and discuss their differences in performance on\nEarnings-21. Using our recently released fstalign tool, we provide a candid\nanalysis of each model's recognition capabilities under different partitions.\nOur analysis finds that ASR accuracy for certain NER categories is poor,\npresenting a significant impediment to transcript comprehension and usage.\nEarnings-21 bridges academic and commercial ASR system evaluation and enables\nfurther research on entity modeling and WER on real world audio.",
          "link": "http://arxiv.org/abs/2104.11348",
          "publishedOn": "2021-06-17T01:58:41.524Z",
          "wordCount": 700,
          "title": "Earnings-21: A Practical Benchmark for ASR in the Wild. (arXiv:2104.11348v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2004.09764",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fang_X/0/1/0/all/0/1\">Xianghong Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_H/0/1/0/all/0/1\">Haoli Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zenglin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_M/0/1/0/all/0/1\">Michael Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+King_I/0/1/0/all/0/1\">Irwin King</a>",
          "description": "Variational autoencoders have been widely applied for natural language\ngeneration, however, there are two long-standing problems: information\nunder-representation and posterior collapse. The former arises from the fact\nthat only the last hidden state from the encoder is transformed to the latent\nspace, which is insufficient to summarize data. The latter comes as a result of\nthe imbalanced scale between the reconstruction loss and the KL divergence in\nthe objective function. To tackle these issues, in this paper we propose the\ndiscrete variational attention model with categorical distribution over the\nattention mechanism owing to the discrete nature in languages. Our approach is\ncombined with an auto-regressive prior to capture the sequential dependency\nfrom observations, which can enhance the latent space for language generation.\nMoreover, thanks to the property of discreteness, the training of our proposed\napproach does not suffer from posterior collapse. Furthermore, we carefully\nanalyze the superiority of discrete latent space over the continuous space with\nthe common Gaussian distribution. Extensive experiments on language generation\ndemonstrate superior advantages of our proposed approach in comparison with the\nstate-of-the-art counterparts.",
          "link": "http://arxiv.org/abs/2004.09764",
          "publishedOn": "2021-06-17T01:58:41.517Z",
          "wordCount": 665,
          "title": "Discrete Variational Attention Models for Language Generation. (arXiv:2004.09764v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.11657",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Asgari_E/0/1/0/all/0/1\">Ehsaneddin Asgari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabet_M/0/1/0/all/0/1\">Masoud Jalili Sabet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dufter_P/0/1/0/all/0/1\">Philipp Dufter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ringlstetter_C/0/1/0/all/0/1\">Christopher Ringlstetter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schutze_H/0/1/0/all/0/1\">Hinrich Sch&#xfc;tze</a>",
          "description": "Annotation projection is an important area in NLP that can greatly contribute\nto creating language resources for low-resource languages. Word alignment plays\na key role in this setting. However, most of the existing word alignment\nmethods are designed for a high resource setting in machine translation where\nmillions of parallel sentences are available. This amount reduces to a few\nthousands of sentences when dealing with low-resource languages failing the\nexisting established IBM models. In this paper, we propose subword\nsampling-based alignment of text units. This method's hypothesis is that the\naggregation of different granularities of text for certain language pairs can\nhelp word-level alignment. For certain languages for which gold-standard\nalignments exist, we propose an iterative Bayesian optimization framework to\noptimize selecting possible subwords from the space of possible subword\nrepresentations of the source and target sentences. We show that the subword\nsampling method consistently outperforms word-level alignment on six language\npairs: English-German, English-French, English-Romanian, English-Persian,\nEnglish-Hindi, and English-Inuktitut. In addition, we show that the\nhyperparameters learned for certain language pairs can be applied to other\nlanguages at no supervision and consistently improve the alignment results. We\nobserve that using $5K$ parallel sentences together with our proposed subword\nsampling approach, we obtain similar F1 scores to the use of $100K$'s of\nparallel sentences in existing word-level fast-align/eflomal alignment methods.",
          "link": "http://arxiv.org/abs/2012.11657",
          "publishedOn": "2021-06-17T01:58:41.489Z",
          "wordCount": 676,
          "title": "Subword Sampling for Low Resource Word Alignment. (arXiv:2012.11657v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.00804",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sundararaman_M/0/1/0/all/0/1\">Mukuntha Narayanan Sundararaman</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kumar_A/0/1/0/all/0/1\">Ayush Kumar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Vepa_J/0/1/0/all/0/1\">Jithendra Vepa</a>",
          "description": "Recent years have witnessed significant improvement in ASR systems to\nrecognize spoken utterances. However, it is still a challenging task for noisy\nand out-of-domain data, where substitution and deletion errors are prevalent in\nthe transcribed text. These errors significantly degrade the performance of\ndownstream tasks. In this work, we propose a BERT-style language model,\nreferred to as PhonemeBERT, that learns a joint language model with phoneme\nsequence and ASR transcript to learn phonetic-aware representations that are\nrobust to ASR errors. We show that PhonemeBERT can be used on downstream tasks\nusing phoneme sequences as additional features, and also in low-resource setup\nwhere we only have ASR-transcripts for the downstream tasks with no phoneme\ninformation available. We evaluate our approach extensively by generating noisy\ndata for three benchmark datasets - Stanford Sentiment Treebank, TREC and ATIS\nfor sentiment, question and intent classification tasks respectively. The\nresults of the proposed approach beats the state-of-the-art baselines\ncomprehensively on each dataset.",
          "link": "http://arxiv.org/abs/2102.00804",
          "publishedOn": "2021-06-17T01:58:41.472Z",
          "wordCount": 619,
          "title": "Phoneme-BERT: Joint Language Modelling of Phoneme Sequence and ASR Transcript. (arXiv:2102.00804v2 [eess.AS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.08566",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+West_P/0/1/0/all/0/1\">Peter West</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Ximing Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holtzman_A/0/1/0/all/0/1\">Ari Holtzman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhagavatula_C/0/1/0/all/0/1\">Chandra Bhagavatula</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_J/0/1/0/all/0/1\">Jena Hwang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>",
          "description": "Publicly available, large pretrained LanguageModels (LMs) generate text with\nremarkable quality, but only sequentially from left to right. As a result, they\nare not immediately applicable to generation tasks that break the\nunidirectional assumption, such as paraphrasing or text-infilling,\nnecessitating task-specific supervision.\n\nIn this paper, we present Reflective Decoding, a novel unsupervised algorithm\nthat allows for direct application of unidirectional LMs to non-sequential\ntasks. Our 2-step approach requires no supervision or even parallel corpora,\nonly two off-the-shelf pretrained LMs in opposite directions: forward and\nbackward. First, in the contextualization step, we use LMs to generate\nensembles of past and future contexts which collectively capture the input\n(e.g. the source sentence for paraphrasing). Second, in the reflection step, we\ncondition on these \"context ensembles\", generating outputs that are compatible\nwith them. Comprehensive empirical results demonstrate that Reflective Decoding\noutperforms strong unsupervised baselines on both paraphrasing and abductive\ntext infilling, significantly narrowing the gap between unsupervised and\nsupervised methods. Reflective Decoding surpasses multiple supervised baselines\non various metrics including human evaluation.",
          "link": "http://arxiv.org/abs/2010.08566",
          "publishedOn": "2021-06-17T01:58:41.430Z",
          "wordCount": 640,
          "title": "Reflective Decoding: Beyond Unidirectional Generation with Off-the-Shelf Language Models. (arXiv:2010.08566v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.04293",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ates_T/0/1/0/all/0/1\">Tayfun Ates</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Atesoglu_M/0/1/0/all/0/1\">Muhammed Samil Atesoglu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yigit_C/0/1/0/all/0/1\">Cagatay Yigit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kesen_I/0/1/0/all/0/1\">Ilker Kesen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kobas_M/0/1/0/all/0/1\">Mert Kobas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erdem_E/0/1/0/all/0/1\">Erkut Erdem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erdem_A/0/1/0/all/0/1\">Aykut Erdem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goksun_T/0/1/0/all/0/1\">Tilbe Goksun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuret_D/0/1/0/all/0/1\">Deniz Yuret</a>",
          "description": "Humans are able to perceive, understand and reason about physical events.\nDeveloping models with similar physical understanding capabilities is a\nlong-standing goal of artificial intelligence. As a step towards this goal, in\nthis work, we introduce CRAFT, a new visual question answering dataset that\nrequires causal reasoning about physical forces and object interactions. It\ncontains 58K video and question pairs that are generated from 10K videos from\n20 different virtual environments, containing various objects in motion that\ninteract with each other and the scene. Two question categories from CRAFT\ninclude previously studied descriptive and counterfactual questions. Besides,\ninspired by the theories of force dynamics in cognitive linguistics, we\nintroduce new question categories that involve understanding the interactions\nof objects through the notions of cause, enable, and prevent. Our results\ndemonstrate that even though these tasks seem to be simple and intuitive for\nhumans, the evaluated baseline models, including existing state-of-the-art\nmethods, do not yet deal with the challenges posed in our benchmark dataset.",
          "link": "http://arxiv.org/abs/2012.04293",
          "publishedOn": "2021-06-17T01:58:41.390Z",
          "wordCount": 659,
          "title": "CRAFT: A Benchmark for Causal Reasoning About Forces and inTeractions. (arXiv:2012.04293v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1910.09991",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fausti_F/0/1/0/all/0/1\">Fabrizio De Fausti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pugliese_F/0/1/0/all/0/1\">Francesco Pugliese</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zardetto_D/0/1/0/all/0/1\">Diego Zardetto</a>",
          "description": "In recent years, the interest in Big Data sources has been steadily growing\nwithin the Official Statistic community. The Italian National Institute of\nStatistics (Istat) is currently carrying out several Big Data pilot studies.\nOne of these studies, the ICT Big Data pilot, aims at exploiting massive\namounts of textual data automatically scraped from the websites of Italian\nenterprises in order to predict a set of target variables (e.g. e-commerce)\nthat are routinely observed by the traditional ICT Survey. In this paper, we\nshow that Deep Learning techniques can successfully address this problem.\nEssentially, we tackle a text classification task: an algorithm must learn to\ninfer whether an Italian enterprise performs e-commerce from the textual\ncontent of its website. To reach this goal, we developed a sophisticated\nprocessing pipeline and evaluated its performance through extensive\nexperiments. Our pipeline uses Convolutional Neural Networks and relies on Word\nEmbeddings to encode raw texts into grayscale images (i.e. normalized numeric\nmatrices). Web-scraped texts are huge and have very low signal to noise ratio:\nto overcome these issues, we adopted a framework known as False Positive\nReduction, which has seldom (if ever) been applied before to text\nclassification tasks. Several original contributions enable our processing\npipeline to reach good classification results. Empirical evidence shows that\nour proposal outperforms all the alternative Machine Learning solutions already\ntested in Istat for the same task.",
          "link": "http://arxiv.org/abs/1910.09991",
          "publishedOn": "2021-06-17T01:58:41.379Z",
          "wordCount": 714,
          "title": "Towards Automated Website Classification by Deep Learning. (arXiv:1910.09991v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08914",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Le_H/0/1/0/all/0/1\">Hung Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1\">Nancy F. Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoi_S/0/1/0/all/0/1\">Steven C.H. Hoi</a>",
          "description": "Video-grounded dialogue systems aim to integrate video understanding and\ndialogue understanding to generate responses that are relevant to both the\ndialogue and video context. Most existing approaches employ deep learning\nmodels and have achieved remarkable performance, given the relatively small\ndatasets available. However, the results are partly accomplished by exploiting\nbiases in the datasets rather than developing multimodal reasoning, resulting\nin limited generalization. In this paper, we propose a novel approach of\nCompositional Counterfactual Contrastive Learning ($C^3$) to develop\ncontrastive training between factual and counterfactual samples in\nvideo-grounded dialogues. Specifically, we design factual/counterfactual\nsampling based on the temporal steps in videos and tokens in dialogues and\npropose contrastive loss functions that exploit object-level or action-level\nvariance. Different from prior approaches, we focus on contrastive hidden state\nrepresentations among compositional output tokens to optimize the\nrepresentation space in a generation setting. We achieved promising performance\ngains on the Audio-Visual Scene-Aware Dialogues (AVSD) benchmark and showed the\nbenefits of our approach in grounding video and dialogue context.",
          "link": "http://arxiv.org/abs/2106.08914",
          "publishedOn": "2021-06-17T01:58:41.308Z",
          "wordCount": 608,
          "title": "$C^3$: Compositional Counterfactual Constrastive Learning for Video-grounded Dialogues. (arXiv:2106.08914v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08960",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nagaraja_V/0/1/0/all/0/1\">Varun Nagaraja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yangyang Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venkatesh_G/0/1/0/all/0/1\">Ganesh Venkatesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalinli_O/0/1/0/all/0/1\">Ozlem Kalinli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seltzer_M/0/1/0/all/0/1\">Michael L. Seltzer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandra_V/0/1/0/all/0/1\">Vikas Chandra</a>",
          "description": "On-device speech recognition requires training models of different sizes for\ndeploying on devices with various computational budgets. When building such\ndifferent models, we can benefit from training them jointly to take advantage\nof the knowledge shared between them. Joint training is also efficient since it\nreduces the redundancy in the training procedure's data handling operations. We\npropose a method for collaboratively training acoustic encoders of different\nsizes for speech recognition. We use a sequence transducer setup where\ndifferent acoustic encoders share a common predictor and joiner modules. The\nacoustic encoders are also trained using co-distillation through an auxiliary\ntask for frame level chenone prediction, along with the transducer loss. We\nperform experiments using the LibriSpeech corpus and demonstrate that the\ncollaboratively trained acoustic encoders can provide up to a 11% relative\nimprovement in the word error rate on both the test partitions.",
          "link": "http://arxiv.org/abs/2106.08960",
          "publishedOn": "2021-06-17T01:58:41.287Z",
          "wordCount": 576,
          "title": "Collaborative Training of Acoustic Encoders for Speech Recognition. (arXiv:2106.08960v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08898",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinyi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Haiqin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1\">Liang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mo_Y/0/1/0/all/0/1\">Yang Mo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1\">Jianping Shen</a>",
          "description": "Recently developed large pre-trained language models, e.g., BERT, have\nachieved remarkable performance in many downstream natural language processing\napplications. These pre-trained language models often contain hundreds of\nmillions of parameters and suffer from high computation and latency in\nreal-world applications. It is desirable to reduce the computation overhead of\nthe models for fast training and inference while keeping the model performance\nin downstream applications. Several lines of work utilize knowledge\ndistillation to compress the teacher model to a smaller student model. However,\nthey usually discard the teacher's knowledge when in inference. Differently, in\nthis paper, we propose RefBERT to leverage the knowledge learned from the\nteacher, i.e., facilitating the pre-computed BERT representation on the\nreference sample and compressing BERT into a smaller student model. To\nguarantee our proposal, we provide theoretical justification on the loss\nfunction and the usage of reference samples. Significantly, the theoretical\nresult shows that including the pre-computed teacher's representations on the\nreference samples indeed increases the mutual information in learning the\nstudent model. Finally, we conduct the empirical evaluation and show that our\nRefBERT can beat the vanilla TinyBERT over 8.1\\% and achieves more than 94\\% of\nthe performance of $\\BERTBASE$ on the GLUE benchmark. Meanwhile, RefBERT is\n7.4x smaller and 9.5x faster on inference than BERT$_{\\rm BASE}$.",
          "link": "http://arxiv.org/abs/2106.08898",
          "publishedOn": "2021-06-17T01:58:41.281Z",
          "wordCount": 652,
          "title": "RefBERT: Compressing BERT by Referencing to Pre-computed Representations. (arXiv:2106.08898v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.09009",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Saxon_M/0/1/0/all/0/1\">Michael Saxon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choudhary_S/0/1/0/all/0/1\">Samridhi Choudhary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McKenna_J/0/1/0/all/0/1\">Joseph P. McKenna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mouchtaris_A/0/1/0/all/0/1\">Athanasios Mouchtaris</a>",
          "description": "End-to-end (E2E) spoken language understanding (SLU) systems predict\nutterance semantics directly from speech using a single model. Previous work in\nthis area has focused on targeted tasks in fixed domains, where the output\nsemantic structure is assumed a priori and the input speech is of limited\ncomplexity. In this work we present our approach to developing an E2E model for\ngeneralized SLU in commercial voice assistants (VAs). We propose a fully\ndifferentiable, transformer-based, hierarchical system that can be pretrained\nat both the ASR and NLU levels. This is then fine-tuned on both transcription\nand semantic classification losses to handle a diverse set of intent and\nargument combinations. This leads to an SLU system that achieves significant\nimprovements over baselines on a complex internal generalized VA dataset with a\n43% improvement in accuracy, while still meeting the 99% accuracy benchmark on\nthe popular Fluent Speech Commands dataset. We further evaluate our model on a\nhard test set, exclusively containing slot arguments unseen in training, and\ndemonstrate a nearly 20% improvement, showing the efficacy of our approach in\ntruly demanding VA scenarios.",
          "link": "http://arxiv.org/abs/2106.09009",
          "publishedOn": "2021-06-17T01:58:41.271Z",
          "wordCount": 632,
          "title": "End-to-End Spoken Language Understanding for Generalized Voice Assistants. (arXiv:2106.09009v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08977",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Haoming Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Danqing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_T/0/1/0/all/0/1\">Tianyu Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_B/0/1/0/all/0/1\">Bing Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tuo Zhao</a>",
          "description": "Weak supervision has shown promising results in many natural language\nprocessing tasks, such as Named Entity Recognition (NER). Existing work mainly\nfocuses on learning deep NER models only with weak supervision, i.e., without\nany human annotation, and shows that by merely using weakly labeled data, one\ncan achieve good performance, though still underperforms fully supervised NER\nwith manually/strongly labeled data. In this paper, we consider a more\npractical scenario, where we have both a small amount of strongly labeled data\nand a large amount of weakly labeled data. Unfortunately, we observe that\nweakly labeled data does not necessarily improve, or even deteriorate the model\nperformance (due to the extensive noise in the weak labels) when we train deep\nNER models over a simple or weighted combination of the strongly labeled and\nweakly labeled data. To address this issue, we propose a new multi-stage\ncomputational framework -- NEEDLE with three essential ingredients: (1) weak\nlabel completion, (2) noise-aware loss function, and (3) final fine-tuning over\nthe strongly labeled data. Through experiments on E-commerce query NER and\nBiomedical NER, we demonstrate that NEEDLE can effectively suppress the noise\nof the weak labels and outperforms existing methods. In particular, we achieve\nnew SOTA F1-scores on 3 Biomedical NER datasets: BC5CDR-chem 93.74,\nBC5CDR-disease 90.69, NCBI-disease 92.28.",
          "link": "http://arxiv.org/abs/2106.08977",
          "publishedOn": "2021-06-17T01:58:41.262Z",
          "wordCount": 669,
          "title": "Named Entity Recognition with Small Strongly Labeled and Large Weakly Labeled Data. (arXiv:2106.08977v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08629",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jialong Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Hongyu Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_M/0/1/0/all/0/1\">Meng Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yaojie Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xianpei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Le Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_W/0/1/0/all/0/1\">Weijian Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jin Xu</a>",
          "description": "Current event-centric knowledge graphs highly rely on explicit connectives to\nmine relations between events. Unfortunately, due to the sparsity of\nconnectives, these methods severely undermine the coverage of EventKGs. The\nlack of high-quality labelled corpora further exacerbates that problem. In this\npaper, we propose a knowledge projection paradigm for event relation\nextraction: projecting discourse knowledge to narratives by exploiting the\ncommonalities between them. Specifically, we propose Multi-tier Knowledge\nProjection Network (MKPNet), which can leverage multi-tier discourse knowledge\neffectively for event relation extraction. In this way, the labelled data\nrequirement is significantly reduced, and implicit event relations can be\neffectively extracted. Intrinsic experimental results show that MKPNet achieves\nthe new state-of-the-art performance, and extrinsic experimental results verify\nthe value of the extracted event relations.",
          "link": "http://arxiv.org/abs/2106.08629",
          "publishedOn": "2021-06-17T01:58:41.255Z",
          "wordCount": 567,
          "title": "From Discourse to Narrative: Knowledge Projection for Event Relation Extraction. (arXiv:2106.08629v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08858",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Karch_T/0/1/0/all/0/1\">Tristan Karch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teodorescu_L/0/1/0/all/0/1\">Laetitia Teodorescu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hofmann_K/0/1/0/all/0/1\">Katja Hofmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moulin_Frier_C/0/1/0/all/0/1\">Cl&#xe9;ment Moulin-Frier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oudeyer_P/0/1/0/all/0/1\">Pierre-Yves Oudeyer</a>",
          "description": "Language is an interface to the outside world. In order for embodied agents\nto use it, language must be grounded in other, sensorimotor modalities. While\nthere is an extended literature studying how machines can learn grounded\nlanguage, the topic of how to learn spatio-temporal linguistic concepts is\nstill largely uncharted. To make progress in this direction, we here introduce\na novel spatio-temporal language grounding task where the goal is to learn the\nmeaning of spatio-temporal descriptions of behavioral traces of an embodied\nagent. This is achieved by training a truth function that predicts if a\ndescription matches a given history of observations. The descriptions involve\ntime-extended predicates in past and present tense as well as spatio-temporal\nreferences to objects in the scene. To study the role of architectural biases\nin this task, we train several models including multimodal Transformer\narchitectures; the latter implement different attention computations between\nwords and objects across space and time. We test models on two classes of\ngeneralization: 1) generalization to randomly held-out sentences; 2)\ngeneralization to grammar primitives. We observe that maintaining object\nidentity in the attention computation of our Transformers is instrumental to\nachieving good performance on generalization overall, and that summarizing\nobject traces in a single token has little influence on performance. We then\ndiscuss how this opens new perspectives for language-guided autonomous embodied\nagents. We also release our code under open-source license as well as\npretrained models and datasets to encourage the wider community to build upon\nand extend our work in the future.",
          "link": "http://arxiv.org/abs/2106.08858",
          "publishedOn": "2021-06-17T01:58:41.228Z",
          "wordCount": 687,
          "title": "Grounding Spatio-Temporal Language with Transformers. (arXiv:2106.08858v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08689",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1\">Yu Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_X/0/1/0/all/0/1\">Xuefeng Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wiechmann_D/0/1/0/all/0/1\">Daniel Wiechmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kerz_E/0/1/0/all/0/1\">Elma Kerz</a>",
          "description": "In this paper, we combined linguistic complexity and (dis)fluency features\nwith pretrained language models for the task of Alzheimer's disease detection\nof the 2021 ADReSSo (Alzheimer's Dementia Recognition through Spontaneous\nSpeech) challenge. An accuracy of 83.1% was achieved on the test set, which\namounts to an improvement of 4.23% over the baseline model. Our best-performing\nmodel that integrated component models using a stacking ensemble technique\nperformed equally well on cross-validation and test data, indicating that it is\nrobust against overfitting.",
          "link": "http://arxiv.org/abs/2106.08689",
          "publishedOn": "2021-06-17T01:58:41.215Z",
          "wordCount": 528,
          "title": "Alzheimer's Disease Detection from Spontaneous Speech through Combining Linguistic Complexity and (Dis)Fluency Features with Pretrained Language Models. (arXiv:2106.08689v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08723",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Han_T/0/1/0/all/0/1\">Ting Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1\">Chongxuan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1\">Wei Peng</a>",
          "description": "Dialogue State Tracking (DST), which is the process of inferring user goals\nby estimating belief states given the dialogue history, plays a critical role\nin task-oriented dialogue systems. A coreference phenomenon observed in\nmulti-turn conversations is not addressed by existing DST models, leading to\nsub-optimal performances. In this paper, we propose Coreference Dialogue State\nTracker (CDST) that explicitly models the coreference feature. In particular,\nat each turn, the proposed model jointly predicts the coreferred domain-slot\npair and extracts the coreference values from the dialogue context.\nExperimental results on MultiWOZ 2.1 dataset show that the proposed model\nachieves the state-of-the-art joint goal accuracy of 56.47%.",
          "link": "http://arxiv.org/abs/2106.08723",
          "publishedOn": "2021-06-17T01:58:41.207Z",
          "wordCount": 532,
          "title": "Coreference Augmentation for Multi-Domain Task-Oriented Dialogue State Tracking. (arXiv:2106.08723v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08859",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Olaleye_K/0/1/0/all/0/1\">Kayode Olaleye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamper_H/0/1/0/all/0/1\">Herman Kamper</a>",
          "description": "Visually grounded speech models learn from images paired with spoken\ncaptions. By tagging images with soft text labels using a trained visual\nclassifier with a fixed vocabulary, previous work has shown that it is possible\nto train a model that can detect whether a particular text keyword occurs in\nspeech utterances or not. Here we investigate whether visually grounded speech\nmodels can also do keyword localisation: predicting where, within an utterance,\na given textual keyword occurs without any explicit text-based or alignment\nsupervision. We specifically consider whether incorporating attention into a\nconvolutional model is beneficial for localisation. Although absolute\nlocalisation performance with visually supervised models is still modest\n(compared to using unordered bag-of-word text labels for supervision), we show\nthat attention provides a large gain in performance over previous visually\ngrounded models. As in many other speech-image studies, we find that many of\nthe incorrect localisations are due to semantic confusions, e.g. locating the\nword 'backstroke' for the query keyword 'swimming'.",
          "link": "http://arxiv.org/abs/2106.08859",
          "publishedOn": "2021-06-17T01:58:41.200Z",
          "wordCount": 598,
          "title": "Attention-Based Keyword Localisation in Speech using Visual Grounding. (arXiv:2106.08859v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08942",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kiegeland_S/0/1/0/all/0/1\">Samuel Kiegeland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kreutzer_J/0/1/0/all/0/1\">Julia Kreutzer</a>",
          "description": "Policy gradient algorithms have found wide adoption in NLP, but have recently\nbecome subject to criticism, doubting their suitability for NMT. Choshen et al.\n(2020) identify multiple weaknesses and suspect that their success is\ndetermined by the shape of output distributions rather than the reward. In this\npaper, we revisit these claims and study them under a wider range of\nconfigurations. Our experiments on in-domain and cross-domain adaptation reveal\nthe importance of exploration and reward scaling, and provide empirical\ncounter-evidence to these claims.",
          "link": "http://arxiv.org/abs/2106.08942",
          "publishedOn": "2021-06-17T01:58:41.183Z",
          "wordCount": 524,
          "title": "Revisiting the Weaknesses of Reinforcement Learning for Neural Machine Translation. (arXiv:2106.08942v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08649",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Gabrys_A/0/1/0/all/0/1\">Adam Gabry&#x15b;</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jiao_Y/0/1/0/all/0/1\">Yunlong Jiao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Klimkov_V/0/1/0/all/0/1\">Viacheslav Klimkov</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Korzekwa_D/0/1/0/all/0/1\">Daniel Korzekwa</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Barra_Chicote_R/0/1/0/all/0/1\">Roberto Barra-Chicote</a>",
          "description": "This paper proposes a general enhancement to the Normalizing Flows (NF) used\nin neural vocoding. As a case study, we improve expressive speech vocoding with\na revamped Parallel Wavenet (PW). Specifically, we propose to extend the affine\ntransformation of PW to the more expressive invertible non-affine function. The\ngreater expressiveness of the improved PW leads to better-perceived signal\nquality and naturalness in the waveform reconstruction and text-to-speech (TTS)\ntasks. We evaluate the model across different speaking styles on a\nmulti-speaker, multi-lingual dataset. In the waveform reconstruction task, the\nproposed model closes the naturalness and signal quality gap from the original\nPW to recordings by $10\\%$, and from other state-of-the-art neural vocoding\nsystems by more than $60\\%$. We also demonstrate improvements in objective\nmetrics on the evaluation test set with L2 Spectral Distance and Cross-Entropy\nreduced by $3\\%$ and $6\\unicode{x2030}$ comparing to the affine PW.\nFurthermore, we extend the probability density distillation procedure proposed\nby the original PW paper, so that it works with any non-affine invertible and\ndifferentiable function.",
          "link": "http://arxiv.org/abs/2106.08649",
          "publishedOn": "2021-06-17T01:58:41.166Z",
          "wordCount": 624,
          "title": "Improving the expressiveness of neural vocoding with non-affine Normalizing Flows. (arXiv:2106.08649v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08846",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_F/0/1/0/all/0/1\">Fu-Ming Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_A/0/1/0/all/0/1\">Austin Huang</a>",
          "description": "Reducing computation cost, inference latency, and memory footprint of neural\nnetworks are frequently cited as research motivations for pruning and sparsity.\nHowever, operationalizing those benefits and understanding the end-to-end\neffect of algorithm design and regularization on the runtime execution is not\noften examined in depth.\n\nHere we apply structured and unstructured pruning to attention weights of\ntransformer blocks of the BERT language model, while also expanding block\nsparse representation (BSR) operations in the TVM compiler. Integration of BSR\noperations enables the TVM runtime execution to leverage structured pattern\nsparsity induced by model regularization.\n\nThis integrated view of pruning algorithms enables us to study relationships\nbetween modeling decisions and their direct impact on sparsity-enhanced\nexecution. Our main findings are: 1) we validate that performance benefits of\nstructured sparsity block regularization must be enabled by the BSR\naugmentations to TVM, with 4x speedup relative to vanilla PyTorch and 2.2x\nspeedup relative to standard TVM compilation (without expanded BSR support). 2)\nfor BERT attention weights, the end-to-end optimal block sparsity shape in this\nCPU inference context is not a square block (as in \\cite{gray2017gpu}) but\nrather a linear 32x1 block 3) the relationship between performance and block\nsize / shape is is suggestive of how model regularization parameters interact\nwith task scheduler optimizations resulting in the observed end-to-end\nperformance.",
          "link": "http://arxiv.org/abs/2106.08846",
          "publishedOn": "2021-06-17T01:58:41.071Z",
          "wordCount": 657,
          "title": "Algorithm to Compilation Codesign: An Integrated View of Neural Network Sparsity. (arXiv:2106.08846v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08648",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Merkx_D/0/1/0/all/0/1\">Danny Merkx</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frank_S/0/1/0/all/0/1\">Stefan L. Frank</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ernestus_M/0/1/0/all/0/1\">Mirjam Ernestus</a>",
          "description": "This study addresses the question whether visually grounded speech\nrecognition (VGS) models learn to capture sentence semantics without access to\nany prior linguistic knowledge. We produce synthetic and natural spoken\nversions of a well known semantic textual similarity database and show that our\nVGS model produces embeddings that correlate well with human semantic\nsimilarity judgements. Our results show that a model trained on a small\nimage-caption database outperforms two models trained on much larger databases,\nindicating that database size is not all that matters. We also investigate the\nimportance of having multiple captions per image and find that this is indeed\nhelpful even if the total number of images is lower, suggesting that\nparaphrasing is a valuable learning signal. While the general trend in the\nfield is to create ever larger datasets to train models on, our findings\nindicate other characteristics of the database can just as important important.",
          "link": "http://arxiv.org/abs/2106.08648",
          "publishedOn": "2021-06-17T01:58:41.037Z",
          "wordCount": 597,
          "title": "Semantic sentence similarity: size does not always matter. (arXiv:2106.08648v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08680",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_G/0/1/0/all/0/1\">Gauri Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramesh_K/0/1/0/all/0/1\">Krithika Ramesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Sanjay Singh</a>",
          "description": "With language models being deployed increasingly in the real world, it is\nessential to address the issue of the fairness of their outputs. The word\nembedding representations of these language models often implicitly draw\nunwanted associations that form a social bias within the model. The nature of\ngendered languages like Hindi, poses an additional problem to the\nquantification and mitigation of bias, owing to the change in the form of the\nwords in the sentence, based on the gender of the subject. Additionally, there\nis sparse work done in the realm of measuring and debiasing systems for Indic\nlanguages. In our work, we attempt to evaluate and quantify the gender bias\nwithin a Hindi-English machine translation system. We implement a modified\nversion of the existing TGBI metric based on the grammatical considerations for\nHindi. We also compare and contrast the resulting bias measurements across\nmultiple metrics for pre-trained embeddings and the ones learned by our machine\ntranslation model.",
          "link": "http://arxiv.org/abs/2106.08680",
          "publishedOn": "2021-06-17T01:58:41.028Z",
          "wordCount": 587,
          "title": "Evaluating Gender Bias in Hindi-English Machine Translation. (arXiv:2106.08680v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08582",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiao_R/0/1/0/all/0/1\">Rui Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zonghan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>",
          "description": "While synthetic bilingual corpora have demonstrated their effectiveness in\nlow-resource neural machine translation (NMT), adding more synthetic data often\ndeteriorates translation performance. In this work, we propose alternated\ntraining with synthetic and authentic data for NMT. The basic idea is to\nalternate synthetic and authentic corpora iteratively during training. Compared\nwith previous work, we introduce authentic data as guidance to prevent the\ntraining of NMT models from being disturbed by noisy synthetic data.\nExperiments on Chinese-English and German-English translation tasks show that\nour approach improves the performance over several strong baselines. We\nvisualize the BLEU landscape to further investigate the role of authentic and\nsynthetic data during alternated training. From the visualization, we find that\nauthentic data helps to direct the NMT model parameters towards points with\nhigher BLEU scores and leads to consistent translation performance improvement.",
          "link": "http://arxiv.org/abs/2106.08582",
          "publishedOn": "2021-06-17T01:58:41.007Z",
          "wordCount": 574,
          "title": "Alternated Training with Synthetic and Authentic Data for Neural Machine Translation. (arXiv:2106.08582v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08556",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhengyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_K/0/1/0/all/0/1\">Ke Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1\">Nancy F. Chen</a>",
          "description": "Summarizing conversations via neural approaches has been gaining research\ntraction lately, yet it is still challenging to obtain practical solutions.\nExamples of such challenges include unstructured information exchange in\ndialogues, informal interactions between speakers, and dynamic role changes of\nspeakers as the dialogue evolves. Many of such challenges result in complex\ncoreference links. Therefore, in this work, we investigate different approaches\nto explicitly incorporate coreference information in neural abstractive\ndialogue summarization models to tackle the aforementioned challenges.\nExperimental results show that the proposed approaches achieve state-of-the-art\nperformance, implying it is useful to utilize coreference information in\ndialogue summarization. Evaluation results on factual correctness suggest such\ncoreference-aware models are better at tracing the information flow among\ninterlocutors and associating accurate status/actions with the corresponding\ninterlocutors and person mentions.",
          "link": "http://arxiv.org/abs/2106.08556",
          "publishedOn": "2021-06-17T01:58:41.001Z",
          "wordCount": 552,
          "title": "Coreference-Aware Dialogue Summarization. (arXiv:2106.08556v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08801",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qi_Z/0/1/0/all/0/1\">Zhiyuan Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Ziheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiaoyan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yefeng Zheng</a>",
          "description": "Knowledge Graph (KG) alignment aims at finding equivalent entities and\nrelations (i.e., mappings) between two KGs. The existing approaches utilize\neither reasoning-based or semantic embedding-based techniques, but few studies\nexplore their combination. In this demonstration, we present PRASEMap, an\nunsupervised KG alignment system that iteratively computes the Mappings with\nboth Probabilistic Reasoning (PR) And Semantic Embedding (SE) techniques.\nPRASEMap can support various embedding-based KG alignment approaches as the SE\nmodule, and enables easy human computer interaction that additionally provides\nan option for users to feed the mapping annotations back to the system for\nbetter results. The demonstration showcases these features via a stand-alone\nWeb application with user friendly interfaces.",
          "link": "http://arxiv.org/abs/2106.08801",
          "publishedOn": "2021-06-17T01:58:40.968Z",
          "wordCount": 552,
          "title": "PRASEMap: A Probabilistic Reasoning and Semantic Embedding based Knowledge Graph Alignment System. (arXiv:2106.08801v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08367",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+OConnor_J/0/1/0/all/0/1\">Joe O&#x27;Connor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andreas_J/0/1/0/all/0/1\">Jacob Andreas</a>",
          "description": "Transformer-based language models benefit from conditioning on contexts of\nhundreds to thousands of previous tokens. What aspects of these contexts\ncontribute to accurate model prediction? We describe a series of experiments\nthat measure usable information by selectively ablating lexical and structural\ninformation in transformer language models trained on English Wikipedia. In\nboth mid- and long-range contexts, we find that several extremely destructive\ncontext manipulations -- including shuffling word order within sentences and\ndeleting all words other than nouns -- remove less than 15% of the usable\ninformation. Our results suggest that long contexts, but not their detailed\nsyntactic and propositional content, are important for the low perplexity of\ncurrent transformer language models.",
          "link": "http://arxiv.org/abs/2106.08367",
          "publishedOn": "2021-06-17T01:58:40.892Z",
          "wordCount": 545,
          "title": "What Context Features Can Transformer Language Models Use?. (arXiv:2106.08367v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08364",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Majumder_B/0/1/0/all/0/1\">Bodhisattwa Prasad Majumder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berg_Kirkpatrick_T/0/1/0/all/0/1\">Taylor Berg-Kirkpatrick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McAuley_J/0/1/0/all/0/1\">Julian McAuley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jhamtani_H/0/1/0/all/0/1\">Harsh Jhamtani</a>",
          "description": "Humans often refer to personal narratives, life experiences, and events to\nmake a conversation more engaging and rich. While persona-grounded dialog\nmodels are able to generate responses that follow a given persona, they often\nmiss out on stating detailed experiences or events related to a persona, often\nleaving conversations shallow and dull. In this work, we equip dialog models\nwith 'background stories' related to a persona by leveraging fictional\nnarratives from existing story datasets (e.g. ROCStories). Since current dialog\ndatasets do not contain such narratives as responses, we perform an\nunsupervised adaptation of a retrieved story for generating a dialog response\nusing a gradient-based rewriting technique. Our proposed method encourages the\ngenerated response to be fluent (i.e., highly likely) with the dialog history,\nminimally different from the retrieved story to preserve event ordering and\nconsistent with the original persona. We demonstrate that our method can\ngenerate responses that are more diverse, and are rated more engaging and\nhuman-like by human evaluators, compared to outputs from existing dialog\nmodels.",
          "link": "http://arxiv.org/abs/2106.08364",
          "publishedOn": "2021-06-17T01:58:40.885Z",
          "wordCount": 603,
          "title": "Unsupervised Enrichment of Persona-grounded Dialog with Background Stories. (arXiv:2106.08364v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08495",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hou_F/0/1/0/all/0/1\">Feng Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Ruili Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jun He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yi Zhou</a>",
          "description": "Entity embeddings, which represent different aspects of each entity with a\nsingle vector like word embeddings, are a key component of neural entity\nlinking models. Existing entity embeddings are learned from canonical Wikipedia\narticles and local contexts surrounding target entities. Such entity embeddings\nare effective, but too distinctive for linking models to learn contextual\ncommonality. We propose a simple yet effective method, FGS2EE, to inject\nfine-grained semantic information into entity embeddings to reduce the\ndistinctiveness and facilitate the learning of contextual commonality. FGS2EE\nfirst uses the embeddings of semantic type words to generate semantic\nembeddings, and then combines them with existing entity embeddings through\nlinear aggregation. Extensive experiments show the effectiveness of such\nembeddings. Based on our entity embeddings, we achieved new sate-of-the-art\nperformance on entity linking.",
          "link": "http://arxiv.org/abs/2106.08495",
          "publishedOn": "2021-06-17T01:58:40.825Z",
          "wordCount": 576,
          "title": "Improving Entity Linking through Semantic Reinforced Entity Embeddings. (arXiv:2106.08495v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08571",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fang_X/0/1/0/all/0/1\">Xianghong Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_H/0/1/0/all/0/1\">Haoli Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zenglin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_M/0/1/0/all/0/1\">Michael Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+King_I/0/1/0/all/0/1\">Irwin King</a>",
          "description": "Variational autoencoders (VAEs) have been widely applied for text modeling.\nIn practice, however, they are troubled by two challenges: information\nunderrepresentation and posterior collapse. The former arises as only the last\nhidden state of LSTM encoder is transformed into the latent space, which is\ngenerally insufficient to summarize the data. The latter is a long-standing\nproblem during the training of VAEs as the optimization is trapped to a\ndisastrous local optimum. In this paper, we propose Discrete Auto-regressive\nVariational Attention Model (DAVAM) to address the challenges. Specifically, we\nintroduce an auto-regressive variational attention approach to enrich the\nlatent space by effectively capturing the semantic dependency from the input.\nWe further design discrete latent space for the variational attention and\nmathematically show that our model is free from posterior collapse. Extensive\nexperiments on language modeling tasks demonstrate the superiority of DAVAM\nagainst several VAE counterparts.",
          "link": "http://arxiv.org/abs/2106.08571",
          "publishedOn": "2021-06-17T01:58:40.807Z",
          "wordCount": 579,
          "title": "Discrete Auto-regressive Variational Attention Models for Text Modeling. (arXiv:2106.08571v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08415",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mahmud_J/0/1/0/all/0/1\">Junayed Mahmud</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faisal_F/0/1/0/all/0/1\">Fahim Faisal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arnob_R/0/1/0/all/0/1\">Raihan Islam Arnob</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anastasopoulos_A/0/1/0/all/0/1\">Antonios Anastasopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moran_K/0/1/0/all/0/1\">Kevin Moran</a>",
          "description": "Automated source code summarization is a popular software engineering\nresearch topic wherein machine translation models are employed to \"translate\"\ncode snippets into relevant natural language descriptions. Most evaluations of\nsuch models are conducted using automatic reference-based metrics. However,\ngiven the relatively large semantic gap between programming languages and\nnatural language, we argue that this line of research would benefit from a\nqualitative investigation into the various error modes of current\nstate-of-the-art models. Therefore, in this work, we perform both a\nquantitative and qualitative comparison of three recently proposed source code\nsummarization models. In our quantitative evaluation, we compare the models\nbased on the smoothed BLEU-4, METEOR, and ROUGE-L machine translation metrics,\nand in our qualitative evaluation, we perform a manual open-coding of the most\ncommon errors committed by the models when compared to ground truth captions.\nOur investigation reveals new insights into the relationship between\nmetric-based performance and model prediction errors grounded in an empirically\nderived error taxonomy that can be used to drive future research efforts",
          "link": "http://arxiv.org/abs/2106.08415",
          "publishedOn": "2021-06-17T01:58:40.800Z",
          "wordCount": 651,
          "title": "Code to Comment Translation: A Comparative Study on Model Effectiveness & Errors. (arXiv:2106.08415v1 [cs.SE])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08657",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yiqing Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1\">Jiaming Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Sha Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1\">Yuning Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>",
          "description": "Document-level relation extraction (DocRE) aims at extracting the semantic\nrelations among entity pairs in a document. In DocRE, a subset of the sentences\nin a document, called the evidence sentences, might be sufficient for\npredicting the relation between a specific entity pair. To make better use of\nthe evidence sentences, in this paper, we propose a three-stage\nevidence-enhanced DocRE framework consisting of joint relation and evidence\nextraction, evidence-centered relation extraction (RE), and fusion of\nextraction results. We first jointly train an RE model with a simple and\nmemory-efficient evidence extraction model. Then, we construct pseudo documents\nbased on the extracted evidence sentences and run the RE model again. Finally,\nwe fuse the extraction results of the first two stages using a blending layer\nand make a final prediction. Extensive experiments show that our proposed\nframework achieves state-of-the-art performance on the DocRED dataset,\noutperforming the second-best method by 0.76/0.82 Ign F1/F1. In particular, our\nmethod significantly improves the performance on inter-sentence relations by\n1.23 Inter F1.",
          "link": "http://arxiv.org/abs/2106.08657",
          "publishedOn": "2021-06-17T01:58:40.790Z",
          "wordCount": 587,
          "title": "Eider: Evidence-enhanced Document-level Relation Extraction. (arXiv:2106.08657v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08484",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Papangelis_A/0/1/0/all/0/1\">Alexandros Papangelis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gopalakrishnan_K/0/1/0/all/0/1\">Karthik Gopalakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Padmakumar_A/0/1/0/all/0/1\">Aishwarya Padmakumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Seokhwan Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tur_G/0/1/0/all/0/1\">Gokhan Tur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hakkani_Tur_D/0/1/0/all/0/1\">Dilek Hakkani-Tur</a>",
          "description": "Inspired by recent work in meta-learning and generative teaching networks, we\npropose a framework called Generative Conversational Networks, in which\nconversational agents learn to generate their own labelled training data (given\nsome seed data) and then train themselves from that data to perform a given\ntask. We use reinforcement learning to optimize the data generation process\nwhere the reward signal is the agent's performance on the task. The task can be\nany language-related task, from intent detection to full task-oriented\nconversations. In this work, we show that our approach is able to generalise\nfrom seed data and performs well in limited data and limited computation\nsettings, with significant gains for intent detection and slot tagging across\nmultiple datasets: ATIS, TOD, SNIPS, and Restaurants8k. We show an average\nimprovement of 35% in intent detection and 21% in slot tagging over a baseline\nmodel trained from the seed data. We also conduct an analysis of the novelty of\nthe generated data and provide generated examples for intent detection, slot\ntagging, and non-goal oriented conversations.",
          "link": "http://arxiv.org/abs/2106.08484",
          "publishedOn": "2021-06-17T01:58:40.780Z",
          "wordCount": 599,
          "title": "Generative Conversational Networks. (arXiv:2106.08484v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08468",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zandie_R/0/1/0/all/0/1\">Rohola Zandie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahoor_M/0/1/0/all/0/1\">Mohammad H. Mahoor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madsen_J/0/1/0/all/0/1\">Julia Madsen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Emamian_E/0/1/0/all/0/1\">Eshrat S. Emamian</a>",
          "description": "This paper introduces RyanSpeech, a new speech corpus for research on\nautomated text-to-speech (TTS) systems. Publicly available TTS corpora are\noften noisy, recorded with multiple speakers, or lack quality male speech data.\nIn order to meet the need for a high quality, publicly available male speech\ncorpus within the field of speech recognition, we have designed and created\nRyanSpeech which contains textual materials from real-world conversational\nsettings. These materials contain over 10 hours of a professional male voice\nactor's speech recorded at 44.1 kHz. This corpus's design and pipeline make\nRyanSpeech ideal for developing TTS systems in real-world applications. To\nprovide a baseline for future research, protocols, and benchmarks, we trained 4\nstate-of-the-art speech models and a vocoder on RyanSpeech. The results show\n3.36 in mean opinion scores (MOS) in our best model. We have made both the\ncorpus and trained models for public use.",
          "link": "http://arxiv.org/abs/2106.08468",
          "publishedOn": "2021-06-17T01:58:40.772Z",
          "wordCount": 570,
          "title": "RyanSpeech: A Corpus for Conversational Text-to-Speech Synthesis. (arXiv:2106.08468v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08616",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhan_L/0/1/0/all/0/1\">Li-Ming Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_H/0/1/0/all/0/1\">Haowen Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1\">Lu Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xiao-Ming Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lam_A/0/1/0/all/0/1\">Albert Y.S. Lam</a>",
          "description": "Out-of-scope intent detection is of practical importance in task-oriented\ndialogue systems. Since the distribution of outlier utterances is arbitrary and\nunknown in the training stage, existing methods commonly rely on strong\nassumptions on data distribution such as mixture of Gaussians to make\ninference, resulting in either complex multi-step training procedures or\nhand-crafted rules such as confidence threshold selection for outlier\ndetection. In this paper, we propose a simple yet effective method to train an\nout-of-scope intent classifier in a fully end-to-end manner by simulating the\ntest scenario in training, which requires no assumption on data distribution\nand no additional post-processing or threshold setting. Specifically, we\nconstruct a set of pseudo outliers in the training stage, by generating\nsynthetic outliers using inliner features via self-supervision and sampling\nout-of-scope sentences from easily available open-domain datasets. The pseudo\noutliers are used to train a discriminative classifier that can be directly\napplied to and generalize well on the test task. We evaluate our method\nextensively on four benchmark dialogue datasets and observe significant\nimprovements over state-of-the-art approaches. Our code has been released at\nhttps://github.com/liam0949/DCLOOS.",
          "link": "http://arxiv.org/abs/2106.08616",
          "publishedOn": "2021-06-17T01:58:40.754Z",
          "wordCount": 618,
          "title": "Out-of-Scope Intent Detection with Self-Supervision and Discriminative Training. (arXiv:2106.08616v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08686",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abdullah_B/0/1/0/all/0/1\">Badr M. Abdullah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mosbach_M/0/1/0/all/0/1\">Marius Mosbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaitova_I/0/1/0/all/0/1\">Iuliia Zaitova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mobius_B/0/1/0/all/0/1\">Bernd M&#xf6;bius</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klakow_D/0/1/0/all/0/1\">Dietrich Klakow</a>",
          "description": "Several variants of deep neural networks have been successfully employed for\nbuilding parametric models that project variable-duration spoken word segments\nonto fixed-size vector representations, or acoustic word embeddings (AWEs).\nHowever, it remains unclear to what degree we can rely on the distance in the\nemerging AWE space as an estimate of word-form similarity. In this paper, we\nask: does the distance in the acoustic embedding space correlate with\nphonological dissimilarity? To answer this question, we empirically investigate\nthe performance of supervised approaches for AWEs with different neural\narchitectures and learning objectives. We train AWE models in controlled\nsettings for two languages (German and Czech) and evaluate the embeddings on\ntwo tasks: word discrimination and phonological similarity. Our experiments\nshow that (1) the distance in the embedding space in the best cases only\nmoderately correlates with phonological distance, and (2) improving the\nperformance on the word discrimination task does not necessarily yield models\nthat better reflect word phonological similarity. Our findings highlight the\nnecessity to rethink the current intrinsic evaluations for AWEs.",
          "link": "http://arxiv.org/abs/2106.08686",
          "publishedOn": "2021-06-17T01:58:40.737Z",
          "wordCount": 619,
          "title": "Do Acoustic Word Embeddings Capture Phonological Similarity? An Empirical Study. (arXiv:2106.08686v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02182",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1\">Nuo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1\">Chenyu You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1\">Yuexian Zou</a>",
          "description": "In spoken conversational question answering (SCQA), the answer to the\ncorresponding question is generated by retrieving and then analyzing a fixed\nspoken document, including multi-part conversations. Most SCQA systems have\nconsidered only retrieving information from ordered utterances. However, the\nsequential order of dialogue is important to build a robust spoken\nconversational question answering system, and the changes of utterances order\nmay severely result in low-quality and incoherent corpora. To this end, we\nintroduce a self-supervised learning approach, including incoherence\ndiscrimination, insertion detection, and question prediction, to explicitly\ncapture the coreference resolution and dialogue coherence among spoken\ndocuments. Specifically, we design a joint learning framework where the\nauxiliary self-supervised tasks can enable the pre-trained SCQA systems towards\nmore coherent and meaningful spoken dialogue learning. We also utilize the\nproposed self-supervised learning tasks to capture intra-sentence coherence.\nExperimental results demonstrate that our proposed method provides more\ncoherent, meaningful, and appropriate responses, yielding superior performance\ngains compared to the original pre-trained language models. Our method achieves\nstate-of-the-art results on the Spoken-CoQA dataset.",
          "link": "http://arxiv.org/abs/2106.02182",
          "publishedOn": "2021-06-16T01:21:10.832Z",
          "wordCount": 630,
          "title": "Self-supervised Dialogue Learning for Spoken Conversational Question Answering. (arXiv:2106.02182v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.09106",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Wei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeineldeen_M/0/1/0/all/0/1\">Mohammad Zeineldeen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zuoyun Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schluter_R/0/1/0/all/0/1\">Ralf Schl&#xfc;ter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ney_H/0/1/0/all/0/1\">Hermann Ney</a>",
          "description": "Subword units are commonly used for end-to-end automatic speech recognition\n(ASR), while a fully acoustic-oriented subword modeling approach is somewhat\nmissing. We propose an acoustic data-driven subword modeling (ADSM) approach\nthat adapts the advantages of several text-based and acoustic-based subword\nmethods into one pipeline. With a fully acoustic-oriented label design and\nlearning process, ADSM produces acoustic-structured subword units and\nacoustic-matched target sequence for further ASR training. The obtained ADSM\nlabels are evaluated with different end-to-end ASR approaches including CTC,\nRNN-Transducer and attention models. Experiments on the LibriSpeech corpus show\nthat ADSM clearly outperforms both byte pair encoding (BPE) and\npronunciation-assisted subword modeling (PASM) in all cases. Detailed analysis\nshows that ADSM achieves acoustically more logical word segmentation and more\nbalanced sequence length, and thus, is suitable for both time-synchronous and\nlabel-synchronous models. We also briefly describe how to apply acoustic-based\nsubword regularization and unseen text segmentation using ADSM.",
          "link": "http://arxiv.org/abs/2104.09106",
          "publishedOn": "2021-06-16T01:21:08.065Z",
          "wordCount": 609,
          "title": "Acoustic Data-Driven Subword Modeling for End-to-End Speech Recognition. (arXiv:2104.09106v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08190",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1\">Robin Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lewis_M/0/1/0/all/0/1\">Mike Lewis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1\">Luke Zettlemoyer</a>",
          "description": "This paper proposes a pre-training objective based on question answering (QA)\nfor learning general-purpose contextual representations, motivated by the\nintuition that the representation of a phrase in a passage should encode all\nquestions that the phrase can answer in context. We accomplish this goal by\ntraining a bi-encoder QA model, which independently encodes passages and\nquestions, to match the predictions of a more accurate cross-encoder model on\n80 million synthesized QA pairs. By encoding QA-relevant information, the\nbi-encoder's token-level representations are useful for non-QA downstream tasks\nwithout extensive (or in some cases, any) fine-tuning. We show large\nimprovements over both RoBERTa-large and previous state-of-the-art results on\nzero-shot and few-shot paraphrase detection on four datasets, few-shot named\nentity recognition on two datasets, and zero-shot sentiment analysis on three\ndatasets.",
          "link": "http://arxiv.org/abs/2106.08190",
          "publishedOn": "2021-06-16T01:21:08.021Z",
          "wordCount": 552,
          "title": "Question Answering Infused Pre-training of General-Purpose Contextualized Representations. (arXiv:2106.08190v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.05535",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Taya_Y/0/1/0/all/0/1\">Yuki Taya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pereira_L/0/1/0/all/0/1\">Lis Kanashiro Pereira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_F/0/1/0/all/0/1\">Fei Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kobayashi_I/0/1/0/all/0/1\">Ichiro Kobayashi</a>",
          "description": "We propose an ensemble model for predicting the lexical complexity of words\nand multiword expressions (MWEs). The model receives as input a sentence with a\ntarget word or MWEand outputs its complexity score. Given that a key challenge\nwith this task is the limited size of annotated data, our model relies on\npretrained contextual representations from different state-of-the-art\ntransformer-based language models (i.e., BERT and RoBERTa), and on a variety of\ntraining methods for further enhancing model generalization and\nrobustness:multi-step fine-tuning and multi-task learning, and adversarial\ntraining. Additionally, we propose to enrich contextual representations by\nadding hand-crafted features during training. Our model achieved competitive\nresults and ranked among the top-10 systems in both sub-tasks.",
          "link": "http://arxiv.org/abs/2105.05535",
          "publishedOn": "2021-06-16T01:21:08.014Z",
          "wordCount": 587,
          "title": "OCHADAI-KYOTO at SemEval-2021 Task 1: Enhancing Model Generalization and Robustness for Lexical Complexity Prediction. (arXiv:2105.05535v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08226",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_B/0/1/0/all/0/1\">Bo Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_L/0/1/0/all/0/1\">Li Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shaohan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenhui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chi_Z/0/1/0/all/0/1\">Zewen Chi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singhal_S/0/1/0/all/0/1\">Saksham Singhal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Che_W/0/1/0/all/0/1\">Wanxiang Che</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Ting Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xia Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>",
          "description": "Fine-tuning pre-trained cross-lingual language models can transfer\ntask-specific supervision from one language to the others. In this work, we\npropose to improve cross-lingual fine-tuning with consistency regularization.\nSpecifically, we use example consistency regularization to penalize the\nprediction sensitivity to four types of data augmentations, i.e., subword\nsampling, Gaussian noise, code-switch substitution, and machine translation. In\naddition, we employ model consistency to regularize the models trained with two\naugmented versions of the same training set. Experimental results on the XTREME\nbenchmark show that our method significantly improves cross-lingual fine-tuning\nacross various tasks, including text classification, question answering, and\nsequence labeling.",
          "link": "http://arxiv.org/abs/2106.08226",
          "publishedOn": "2021-06-16T01:21:08.008Z",
          "wordCount": 533,
          "title": "Consistency Regularization for Cross-Lingual Fine-Tuning. (arXiv:2106.08226v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08007",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Isonuma_M/0/1/0/all/0/1\">Masaru Isonuma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mori_J/0/1/0/all/0/1\">Junichiro Mori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bollegala_D/0/1/0/all/0/1\">Danushka Bollegala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sakata_I/0/1/0/all/0/1\">Ichiro Sakata</a>",
          "description": "This paper presents a novel unsupervised abstractive summarization method for\nopinionated texts. While the basic variational autoencoder-based models assume\na unimodal Gaussian prior for the latent code of sentences, we alternate it\nwith a recursive Gaussian mixture, where each mixture component corresponds to\nthe latent code of a topic sentence and is mixed by a tree-structured topic\ndistribution. By decoding each Gaussian component, we generate sentences with\ntree-structured topic guidance, where the root sentence conveys generic\ncontent, and the leaf sentences describe specific topics. Experimental results\ndemonstrate that the generated topic sentences are appropriate as a summary of\nopinionated texts, which are more informative and cover more input contents\nthan those generated by the recent unsupervised summarization model\n(Bra\\v{z}inskas et al., 2020). Furthermore, we demonstrate that the variance of\nlatent Gaussians represents the granularity of sentences, analogous to Gaussian\nword embedding (Vilnis and McCallum, 2015).",
          "link": "http://arxiv.org/abs/2106.08007",
          "publishedOn": "2021-06-16T01:21:07.994Z",
          "wordCount": 592,
          "title": "Unsupervised Abstractive Opinion Summarization by Generating Sentences with Tree-Structured Topic Guidance. (arXiv:2106.08007v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2102.07024",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1\">Khanh Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Misra_D/0/1/0/all/0/1\">Dipendra Misra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schapire_R/0/1/0/all/0/1\">Robert Schapire</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dudik_M/0/1/0/all/0/1\">Miro Dud&#xed;k</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shafto_P/0/1/0/all/0/1\">Patrick Shafto</a>",
          "description": "We present a novel interactive learning protocol that enables training\nrequest-fulfilling agents by verbally describing their activities. Unlike\nimitation learning (IL), our protocol allows the teaching agent to provide\nfeedback in a language that is most appropriate for them. Compared with reward\nin reinforcement learning (RL), the description feedback is richer and allows\nfor improved sample complexity. We develop a probabilistic framework and an\nalgorithm that practically implements our protocol. Empirical results in two\nchallenging request-fulfilling problems demonstrate the strengths of our\napproach: compared with RL baselines, it is more sample-efficient; compared\nwith IL baselines, it achieves competitive success rates without requiring the\nteaching agent to be able to demonstrate the desired behavior using the\nlearning agent's actions. Apart from empirical evaluation, we also provide\ntheoretical guarantees for our algorithm under certain assumptions about the\nteacher and the environment.",
          "link": "http://arxiv.org/abs/2102.07024",
          "publishedOn": "2021-06-16T01:21:07.976Z",
          "wordCount": 606,
          "title": "Interactive Learning from Activity Description. (arXiv:2102.07024v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.11066",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1\">Chenyu You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1\">Nuo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1\">Yuexian Zou</a>",
          "description": "Spoken conversational question answering (SCQA) requires machines to model\ncomplex dialogue flow given the speech utterances and text corpora. Different\nfrom traditional text question answering (QA) tasks, SCQA involves audio signal\nprocessing, passage comprehension, and contextual understanding. However, ASR\nsystems introduce unexpected noisy signals to the transcriptions, which result\nin performance degradation on SCQA. To overcome the problem, we propose CADNet,\na novel contextualized attention-based distillation approach, which applies\nboth cross-attention and self-attention to obtain ASR-robust contextualized\nembedding representations of the passage and dialogue history for performance\nimprovements. We also introduce the spoken conventional knowledge distillation\nframework to distill the ASR-robust knowledge from the estimated probabilities\nof the teacher model to the student. We conduct extensive experiments on the\nSpoken-CoQA dataset and demonstrate that our approach achieves remarkable\nperformance in this task.",
          "link": "http://arxiv.org/abs/2010.11066",
          "publishedOn": "2021-06-16T01:21:07.968Z",
          "wordCount": 616,
          "title": "Contextualized Attention-based Knowledge Transfer for Spoken Conversational Question Answering. (arXiv:2010.11066v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08207",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Long Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ravichandran_V/0/1/0/all/0/1\">Venkatesh Ravichandran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stolcke_A/0/1/0/all/0/1\">Andreas Stolcke</a>",
          "description": "Speaker identification in the household scenario (e.g., for smart speakers)\nis typically based on only a few enrollment utterances but a much larger set of\nunlabeled data, suggesting semisupervised learning to improve speaker profiles.\nWe propose a graph-based semi-supervised learning approach for speaker\nidentification in the household scenario, to leverage the unlabeled speech\nsamples. In contrast to most of the works in speaker recognition that focus on\nspeaker-discriminative embeddings, this work focuses on speaker label inference\n(scoring). Given a pre-trained embedding extractor, graph-based learning allows\nus to integrate information about both labeled and unlabeled utterances.\nConsidering each utterance as a graph node, we represent pairwise utterance\nsimilarity scores as edge weights. Graphs are constructed per household, and\nspeaker identities are propagated to unlabeled nodes to optimize a global\nconsistency criterion. We show in experiments on the VoxCeleb dataset that this\napproach makes effective use of unlabeled data and improves speaker\nidentification accuracy compared to two state-of-the-art scoring methods as\nwell as their semi-supervised variants based on pseudo-labels.",
          "link": "http://arxiv.org/abs/2106.08207",
          "publishedOn": "2021-06-16T01:21:07.961Z",
          "wordCount": 599,
          "title": "Graph-based Label Propagation for Semi-Supervised Speaker Identification. (arXiv:2106.08207v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2008.03945",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1\">Leyang Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1\">Sijie Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>",
          "description": "BERT has been used for solving commonsense tasks such as CommonsenseQA. While\nprior research has found that BERT does contain commonsense information to some\nextent, there has been work showing that pre-trained models can rely on\nspurious associations (e.g., data bias) rather than key cues in solving\nsentiment classification and other problems. We quantitatively investigate the\npresence of structural commonsense cues in BERT when solving commonsense tasks,\nand the importance of such cues for the model prediction. Using two different\nmeasures, we find that BERT does use relevant knowledge for solving the task,\nand the presence of commonsense knowledge is positively correlated to the model\naccuracy.",
          "link": "http://arxiv.org/abs/2008.03945",
          "publishedOn": "2021-06-16T01:21:07.944Z",
          "wordCount": 570,
          "title": "On Commonsense Cues in BERT for Solving Commonsense Tasks. (arXiv:2008.03945v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.07967",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wahle_J/0/1/0/all/0/1\">Jan Philip Wahle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruas_T/0/1/0/all/0/1\">Terry Ruas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meuschke_N/0/1/0/all/0/1\">Norman Meuschke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gipp_B/0/1/0/all/0/1\">Bela Gipp</a>",
          "description": "We present two supervised (pre-)training methods to incorporate gloss\ndefinitions from lexical resources into neural language models (LMs). The\ntraining improves our models' performance for Word Sense Disambiguation (WSD)\nbut also benefits general language understanding tasks while adding almost no\nparameters. We evaluate our techniques with seven different neural LMs and find\nthat XLNet is more suitable for WSD than BERT. Our best-performing methods\nexceeds state-of-the-art WSD techniques on the SemCor 3.0 dataset by 0.5% F1\nand increase BERT's performance on the GLUE benchmark by 1.1% on average.",
          "link": "http://arxiv.org/abs/2106.07967",
          "publishedOn": "2021-06-16T01:21:07.936Z",
          "wordCount": 519,
          "title": "Incorporating Word Sense Disambiguation in Neural Language Models. (arXiv:2106.07967v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07823",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_V/0/1/0/all/0/1\">Vivek Srivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_M/0/1/0/all/0/1\">Mayank Singh</a>",
          "description": "Multilingualism refers to the high degree of proficiency in two or more\nlanguages in the written and oral communication modes. It often results in\nlanguage mixing, a.k.a. code-mixing, when a multilingual speaker switches\nbetween multiple languages in a single utterance of a text or speech. This\npaper discusses the current state of the NLP research, limitations, and\nforeseeable pitfalls in addressing five real-world applications for social good\ncrisis management, healthcare, political campaigning, fake news, and hate\nspeech for multilingual societies. We also propose futuristic datasets, models,\nand tools that can significantly advance the current research in multilingual\nNLP applications for the societal good. As a representative example, we\nconsider English-Hindi code-mixing but draw similar inferences for other\nlanguage pairs",
          "link": "http://arxiv.org/abs/2106.07823",
          "publishedOn": "2021-06-16T01:21:07.925Z",
          "wordCount": 547,
          "title": "Challenges and Considerations with Code-Mixed NLP for Multilingual Societies. (arXiv:2106.07823v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08117",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Dongsheng Wang</a>",
          "description": "Semantic representation and inference is essential for Natural Language\nProcessing (NLP). The state of the art for semantic representation and\ninference is deep learning, and particularly Recurrent Neural Networks (RNNs),\nConvolutional Neural Networks (CNNs), and transformer Self-Attention models.\nThis thesis investigates the use of deep learning for novel semantic\nrepresentation and inference, and makes contributions in the following three\nareas: creating training data, improving semantic representations and extending\ninference learning. In terms of creating training data, we contribute the\nlargest publicly available dataset of real-life factual claims for the purpose\nof automatic claim verification (MultiFC), and we present a novel inference\nmodel composed of multi-scale CNNs with different kernel sizes that learn from\nexternal sources to infer fact checking labels. In terms of improving semantic\nrepresentations, we contribute a novel model that captures non-compositional\nsemantic indicators. By definition, the meaning of a non-compositional phrase\ncannot be inferred from the individual meanings of its composing words (e.g.,\nhot dog). Motivated by this, we operationalize the compositionality of a phrase\ncontextually by enriching the phrase representation with external word\nembeddings and knowledge graphs. Finally, in terms of inference learning, we\npropose a series of novel deep learning architectures that improve inference by\nusing syntactic dependencies, by ensembling role guided attention heads,\nincorporating gating layers, and concatenating multiple heads in novel and\neffective ways. This thesis consists of seven publications (five published and\ntwo under review).",
          "link": "http://arxiv.org/abs/2106.08117",
          "publishedOn": "2021-06-16T01:21:07.918Z",
          "wordCount": 663,
          "title": "Semantic Representation and Inference for NLP. (arXiv:2106.08117v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07999",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tanaka_S/0/1/0/all/0/1\">Shohei Tanaka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoshino_K/0/1/0/all/0/1\">Koichiro Yoshino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sudoh_K/0/1/0/all/0/1\">Katsuhito Sudoh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakamura_S/0/1/0/all/0/1\">Satoshi Nakamura</a>",
          "description": "Human-assisting systems such as dialogue systems must take thoughtful,\nappropriate actions not only for clear and unambiguous user requests, but also\nfor ambiguous user requests, even if the users themselves are not aware of\ntheir potential requirements. To construct such a dialogue agent, we collected\na corpus and developed a model that classifies ambiguous user requests into\ncorresponding system actions. In order to collect a high-quality corpus, we\nasked workers to input antecedent user requests whose pre-defined actions could\nbe regarded as thoughtful. Although multiple actions could be identified as\nthoughtful for a single user request, annotating all combinations of user\nrequests and system actions is impractical. For this reason, we fully annotated\nonly the test data and left the annotation of the training data incomplete. In\norder to train the classification model on such training data, we applied the\npositive/unlabeled (PU) learning method, which assumes that only a part of the\ndata is labeled with positive examples. The experimental results show that the\nPU learning method achieved better performance than the general\npositive/negative (PN) learning method to classify thoughtful actions given an\nambiguous user request.",
          "link": "http://arxiv.org/abs/2106.07999",
          "publishedOn": "2021-06-16T01:21:07.911Z",
          "wordCount": 633,
          "title": "ARTA: Collection and Classification of Ambiguous Requests and Thoughtful Actions. (arXiv:2106.07999v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2104.02207",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shangguan_Y/0/1/0/all/0/1\">Yuan Shangguan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prabhavalkar_R/0/1/0/all/0/1\">Rohit Prabhavalkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1\">Hang Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahadeokar_J/0/1/0/all/0/1\">Jay Mahadeokar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yangyang Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jiatong Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chunyang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_D/0/1/0/all/0/1\">Duc Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalinli_O/0/1/0/all/0/1\">Ozlem Kalinli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fuegen_C/0/1/0/all/0/1\">Christian Fuegen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seltzer_M/0/1/0/all/0/1\">Michael L. Seltzer</a>",
          "description": "As speech-enabled devices such as smartphones and smart speakers become\nincreasingly ubiquitous, there is growing interest in building automatic speech\nrecognition (ASR) systems that can run directly on-device; end-to-end (E2E)\nspeech recognition models such as recurrent neural network transducers and\ntheir variants have recently emerged as prime candidates for this task. Apart\nfrom being accurate and compact, such systems need to decode speech with low\nuser-perceived latency (UPL), producing words as soon as they are spoken. This\nwork examines the impact of various techniques - model architectures, training\ncriteria, decoding hyperparameters, and endpointer parameters - on UPL. Our\nanalyses suggest that measures of model size (parameters, input chunk sizes),\nor measures of computation (e.g., FLOPS, RTF) that reflect the model's ability\nto process input frames are not always strongly correlated with observed UPL.\nThus, conventional algorithmic latency measurements might be inadequate in\naccurately capturing latency observed when models are deployed on embedded\ndevices. Instead, we find that factors affecting token emission latency, and\nendpointing behavior have a larger impact on UPL. We achieve the best trade-off\nbetween latency and word error rate when performing ASR jointly with\nendpointing, while utilizing the recently proposed alignment regularization\nmechanism.",
          "link": "http://arxiv.org/abs/2104.02207",
          "publishedOn": "2021-06-16T01:21:07.898Z",
          "wordCount": 681,
          "title": "Dissecting User-Perceived Latency of On-Device E2E Speech Recognition. (arXiv:2104.02207v2 [cs.SD] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08122",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shao_C/0/1/0/all/0/1\">Chenze Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yang Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jinchao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_F/0/1/0/all/0/1\">Fandong Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>",
          "description": "In recent years, Neural Machine Translation (NMT) has achieved notable\nresults in various translation tasks. However, the word-by-word generation\nmanner determined by the autoregressive mechanism leads to high translation\nlatency of the NMT and restricts its low-latency applications.\nNon-Autoregressive Neural Machine Translation (NAT) removes the autoregressive\nmechanism and achieves significant decoding speedup through generating target\nwords independently and simultaneously. Nevertheless, NAT still takes the\nword-level cross-entropy loss as the training objective, which is not optimal\nbecause the output of NAT cannot be properly evaluated due to the multimodality\nproblem. In this paper, we propose using sequence-level training objectives to\ntrain NAT models, which evaluate the NAT outputs as a whole and correlates well\nwith the real translation quality. Firstly, we propose training NAT models to\noptimize sequence-level evaluation metrics (e.g., BLEU) based on several novel\nreinforcement algorithms customized for NAT, which outperforms the conventional\nmethod by reducing the variance of gradient estimation. Secondly, we introduce\na novel training objective for NAT models, which aims to minimize the\nBag-of-Ngrams (BoN) difference between the model output and the reference\nsentence. The BoN training objective is differentiable and can be calculated\nefficiently without doing any approximations. Finally, we apply a three-stage\ntraining strategy to combine these two methods to train the NAT model. We\nvalidate our approach on four translation tasks (WMT14 En$\\leftrightarrow$De,\nWMT16 En$\\leftrightarrow$Ro), which shows that our approach largely outperforms\nNAT baselines and achieves remarkable performance on all translation tasks.",
          "link": "http://arxiv.org/abs/2106.08122",
          "publishedOn": "2021-06-16T01:21:07.859Z",
          "wordCount": 669,
          "title": "Sequence-Level Training for Non-Autoregressive Neural Machine Translation. (arXiv:2106.08122v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07843",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jisi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zorila_C/0/1/0/all/0/1\">Catalin Zorila</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doddipatla_R/0/1/0/all/0/1\">Rama Doddipatla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barker_J/0/1/0/all/0/1\">Jon Barker</a>",
          "description": "In this paper, we introduce a novel semi-supervised learning framework for\nend-to-end speech separation. The proposed method first uses mixtures of\nunseparated sources and the mixture invariant training (MixIT) criterion to\ntrain a teacher model. The teacher model then estimates separated sources that\nare used to train a student model with standard permutation invariant training\n(PIT). The student model can be fine-tuned with supervised data, i.e., paired\nartificial mixtures and clean speech sources, and further improved via model\ndistillation. Experiments with single and multi channel mixtures show that the\nteacher-student training resolves the over-separation problem observed in the\noriginal MixIT method. Further, the semisupervised performance is comparable to\na fully-supervised separation system trained using ten times the amount of\nsupervised data.",
          "link": "http://arxiv.org/abs/2106.07843",
          "publishedOn": "2021-06-16T01:21:07.836Z",
          "wordCount": 560,
          "title": "Teacher-Student MixIT for Unsupervised and Semi-supervised Speech Separation. (arXiv:2106.07843v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2101.00420",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ye_Q/0/1/0/all/0/1\">Qinyuan Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>",
          "description": "Pre-trained text-to-text transformers such as BART have achieved impressive\nperformance across a range of NLP tasks. Recent study further shows that they\ncan learn to generalize to novel tasks, by including task descriptions as part\nof the source sequence and training the model with (source, target) examples.\nAt test time, these fine-tuned models can make inferences on new tasks using\nthe new task descriptions as part of the input. However, this approach has\npotential limitations, as the model learns to solve individual (source, target)\nexamples (i.e., at the instance level), instead of learning to solve tasks by\ntaking all examples within a task as a whole (i.e., at the task level). To this\nend, we introduce Hypter, a framework that improves text-to-text transformer's\ngeneralization ability to unseen tasks by training a hypernetwork to generate\ntask-specific, light-weight adapters from task descriptions. Experiments on\nZEST dataset and a synthetic SQuAD dataset demonstrate that Hypter improves\nupon fine-tuning baselines. Notably, when using BART-Large as the main network,\nHypter brings 11.3% comparative improvement on ZEST dataset.",
          "link": "http://arxiv.org/abs/2101.00420",
          "publishedOn": "2021-06-16T01:21:07.822Z",
          "wordCount": 636,
          "title": "Learning to Generate Task-Specific Adapters from Task Description. (arXiv:2101.00420v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.07799",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Eyre_H/0/1/0/all/0/1\">Hannah Eyre</a> (1 and 2), <a href=\"http://arxiv.org/find/cs/1/au:+Chapman_A/0/1/0/all/0/1\">Alec B Chapman</a> (1 and 2), <a href=\"http://arxiv.org/find/cs/1/au:+Peterson_K/0/1/0/all/0/1\">Kelly S Peterson</a> (1 and 2), <a href=\"http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1\">Jianlin Shi</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Alba_P/0/1/0/all/0/1\">Patrick R Alba</a> (1 and 2), <a href=\"http://arxiv.org/find/cs/1/au:+Jones_M/0/1/0/all/0/1\">Makoto M Jones</a> (1 and 2), <a href=\"http://arxiv.org/find/cs/1/au:+Box_T/0/1/0/all/0/1\">Tamara L Box</a> (3), <a href=\"http://arxiv.org/find/cs/1/au:+DuVall_S/0/1/0/all/0/1\">Scott L DuVall</a> (1 and 2), <a href=\"http://arxiv.org/find/cs/1/au:+Patterson_O/0/1/0/all/0/1\">Olga V Patterson</a> (1 and 2) ((1) VA Salt Lake City Health Care System, (2) University of Utah, Salt Lake City, UT, USA, (3) Veterans Health Administration Office of Analytics and Performance Integration)",
          "description": "Despite impressive success of machine learning algorithms in clinical natural\nlanguage processing (cNLP), rule-based approaches still have a prominent role.\nIn this paper, we introduce medspaCy, an extensible, open-source cNLP library\nbased on spaCy framework that allows flexible integration of rule-based and\nmachine learning-based algorithms adapted to clinical text. MedspaCy includes a\nvariety of components that meet common cNLP needs such as context analysis and\nmapping to standard terminologies. By utilizing spaCy's clear and easy-to-use\nconventions, medspaCy enables development of custom pipelines that integrate\neasily with other spaCy-based modules. Our toolkit includes several core\ncomponents and facilitates rapid development of pipelines for clinical text.",
          "link": "http://arxiv.org/abs/2106.07799",
          "publishedOn": "2021-06-16T01:21:07.797Z",
          "wordCount": 616,
          "title": "Launching into clinical space with medspaCy: a new clinical text processing toolkit in Python. (arXiv:2106.07799v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07699",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Slottje_A/0/1/0/all/0/1\">Andrew Slottje</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wotherspoon_S/0/1/0/all/0/1\">Shannon Wotherspoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hartmann_W/0/1/0/all/0/1\">William Hartmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Snover_M/0/1/0/all/0/1\">Matthew Snover</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kimball_O/0/1/0/all/0/1\">Owen Kimball</a>",
          "description": "Modeling code-switched speech is an important problem in automatic speech\nrecognition (ASR). Labeled code-switched data are rare, so monolingual data are\noften used to model code-switched speech. These monolingual data may be more\nclosely matched to one of the languages in the code-switch pair. We show that\nsuch asymmetry can bias prediction toward the better-matched language and\ndegrade overall model performance. To address this issue, we propose a\nsemi-supervised approach for code-switched ASR. We consider the case of\nEnglish-Mandarin code-switching, and the problem of using monolingual data to\nbuild bilingual \"transcription models'' for annotation of unlabeled\ncode-switched data. We first build multiple transcription models so that their\nindividual predictions are variously biased toward either English or Mandarin.\nWe then combine these biased transcriptions using confidence-based selection.\nThis strategy generates a superior transcript for semi-supervised training, and\nobtains a 19% relative improvement compared to a semi-supervised system that\nrelies on a transcription model built with only the best-matched monolingual\ndata.",
          "link": "http://arxiv.org/abs/2106.07699",
          "publishedOn": "2021-06-16T01:21:07.767Z",
          "wordCount": 606,
          "title": "Using heterogeneity in semi-supervised transcription hypotheses to improve code-switched speech recognition. (arXiv:2106.07699v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07306",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Papay_S/0/1/0/all/0/1\">Sean Papay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klinger_R/0/1/0/all/0/1\">Roman Klinger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pado_S/0/1/0/all/0/1\">Sebastian Pad&#xf3;</a>",
          "description": "In structured prediction, a major challenge for models is to represent the\ninterdependencies within their output structures. For the common case where\noutputs are structured as a sequence, linear-chain conditional random fields\n(CRFs) are a widely used model class which can learn local dependencies in\noutput sequences. However, the CRF's Markov assumption makes it impossible for\nthese models to capture nonlocal dependencies, and standard CRFs are unable to\nrespect nonlocal constraints of the data (such as global arity constraints on\noutput labels). We present a generalization of CRFs that can enforce a broad\nclass of constraints, including nonlocal ones, by specifying the space of\npossible output structures as a regular language $\\mathcal{L}$. The resulting\nregular-constrained CRF (RegCCRF) has the same formal properties as a standard\nCRF, but assigns zero probability to all label sequences not in $\\mathcal{L}$.\nNotably, RegCCRFs can incorporate their constraints during training, while\nrelated models only enforce constraints during decoding. We prove that\nconstrained training is never worse than constrained decoding, and show using\nsynthetic data that it can be substantially better in practice. Additionally,\nwe demonstrate a practical benefit on downstream tasks by incorporating a\nRegCCRF into a deep neural model for semantic role labeling, exceeding\nstate-of-the-art results on a standard dataset.",
          "link": "http://arxiv.org/abs/2106.07306",
          "publishedOn": "2021-06-16T01:21:07.743Z",
          "wordCount": 646,
          "title": "Constraining Linear-chain CRFs to Regular Languages. (arXiv:2106.07306v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.07719",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hajiaghayi_M/0/1/0/all/0/1\">Mahdi Hajiaghayi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hajiaghayi_M/0/1/0/all/0/1\">Monir Hajiaghayi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bolin_M/0/1/0/all/0/1\">Mark Bolin</a>",
          "description": "In this paper, we present a multi-lingual sentence encoder that can be used\nin search engines as a query and document encoder. This embedding enables a\nsemantic similarity score between queries and documents that can be an\nimportant feature in document ranking and relevancy. To train such a customized\nsentence encoder, it is beneficial to leverage users search data in the form of\nquery-document clicked pairs however, we must avoid relying too much on search\nclick data as it is biased and does not cover many unseen cases. The search\ndata is heavily skewed towards short queries and for long queries is small and\noften noisy. The goal is to design a universal multi-lingual encoder that works\nfor all cases and covers both short and long queries. We select a number of\npublic NLI datasets in different languages and translation data and together\nwith user search data we train a language model using a multi-task approach. A\nchallenge is that these datasets are not homogeneous in terms of content, size\nand the balance ratio. While the public NLI datasets are usually two-sentence\nbased with the same portion of positive and negative pairs, the user search\ndata can contain multi-sentence documents and only positive pairs. We show how\nmulti-task training enables us to leverage all these datasets and exploit\nknowledge sharing across these tasks.",
          "link": "http://arxiv.org/abs/2106.07719",
          "publishedOn": "2021-06-16T01:21:07.736Z",
          "wordCount": 651,
          "title": "Unbiased Sentence Encoder For Large-Scale Multi-lingual Search Engines. (arXiv:2106.07719v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07742",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brandsen_A/0/1/0/all/0/1\">Alex Brandsen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verberne_S/0/1/0/all/0/1\">Suzan Verberne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lambers_K/0/1/0/all/0/1\">Karsten Lambers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wansleeben_M/0/1/0/all/0/1\">Milco Wansleeben</a>",
          "description": "The amount of archaeological literature is growing rapidly. Until recently,\nthese data were only accessible through metadata search. We implemented a text\nretrieval engine for a large archaeological text collection ($\\sim 658$ Million\nwords). In archaeological IR, domain-specific entities such as locations, time\nperiods, and artefacts, play a central role. This motivated the development of\na named entity recognition (NER) model to annotate the full collection with\narchaeological named entities. In this paper, we present ArcheoBERTje, a BERT\nmodel pre-trained on Dutch archaeological texts. We compare the model's quality\nand output on a Named Entity Recognition task to a generic multilingual model\nand a generic Dutch model. We also investigate ensemble methods for combining\nmultiple BERT models, and combining the best BERT model with a domain thesaurus\nusing Conditional Random Fields (CRF). We find that ArcheoBERTje outperforms\nboth the multilingual and Dutch model significantly with a smaller standard\ndeviation between runs, reaching an average F1 score of 0.735. The model also\noutperforms ensemble methods combining the three models. Combining ArcheoBERTje\npredictions and explicit domain knowledge from the thesaurus did not increase\nthe F1 score. We quantitatively and qualitatively analyse the differences\nbetween the vocabulary and output of the BERT models on the full collection and\nprovide some valuable insights in the effect of fine-tuning for specific\ndomains. Our results indicate that for a highly specific text domain such as\narchaeology, further pre-training on domain-specific data increases the model's\nquality on NER by a much larger margin than shown for other domains in the\nliterature, and that domain-specific pre-training makes the addition of domain\nknowledge from a thesaurus unnecessary.",
          "link": "http://arxiv.org/abs/2106.07742",
          "publishedOn": "2021-06-16T01:21:07.661Z",
          "wordCount": 710,
          "title": "Can BERT Dig It? -- Named Entity Recognition for Information Retrieval in the Archaeology Domain. (arXiv:2106.07742v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2104.00769",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Berg_A/0/1/0/all/0/1\">Axel Berg</a>, <a href=\"http://arxiv.org/find/eess/1/au:+OConnor_M/0/1/0/all/0/1\">Mark O&#x27;Connor</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cruz_M/0/1/0/all/0/1\">Miguel Tairum Cruz</a>",
          "description": "The Transformer architecture has been successful across many domains,\nincluding natural language processing, computer vision and speech recognition.\nIn keyword spotting, self-attention has primarily been used on top of\nconvolutional or recurrent encoders. We investigate a range of ways to adapt\nthe Transformer architecture to keyword spotting and introduce the Keyword\nTransformer (KWT), a fully self-attentional architecture that exceeds\nstate-of-the-art performance across multiple tasks without any pre-training or\nadditional data. Surprisingly, this simple architecture outperforms more\ncomplex models that mix convolutional, recurrent and attentive layers. KWT can\nbe used as a drop-in replacement for these models, setting two new benchmark\nrecords on the Google Speech Commands dataset with 98.6% and 97.7% accuracy on\nthe 12 and 35-command tasks respectively.",
          "link": "http://arxiv.org/abs/2104.00769",
          "publishedOn": "2021-06-16T01:21:07.623Z",
          "wordCount": 592,
          "title": "Keyword Transformer: A Self-Attention Model for Keyword Spotting. (arXiv:2104.00769v3 [eess.AS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.04056",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schlegel_V/0/1/0/all/0/1\">Viktor Schlegel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nenadic_G/0/1/0/all/0/1\">Goran Nenadic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Batista_Navarro_R/0/1/0/all/0/1\">Riza Batista-Navarro</a>",
          "description": "Advances in NLP have yielded impressive results for the task of machine\nreading comprehension (MRC), with approaches having been reported to achieve\nperformance comparable to that of humans. In this paper, we investigate whether\nstate-of-the-art MRC models are able to correctly process Semantics Altering\nModifications (SAM): linguistically-motivated phenomena that alter the\nsemantics of a sentence while preserving most of its lexical surface form. We\npresent a method to automatically generate and align challenge sets featuring\noriginal and altered examples. We further propose a novel evaluation\nmethodology to correctly assess the capability of MRC systems to process these\nexamples independent of the data they were optimised on, by discounting for\neffects introduced by domain shift. In a large-scale empirical study, we apply\nthe methodology in order to evaluate extractive MRC models with regard to their\ncapability to correctly process SAM-enriched data. We comprehensively cover 12\ndifferent state-of-the-art neural architecture configurations and four training\ndatasets and find that -- despite their well-known remarkable performance --\noptimised models consistently struggle to correctly process semantically\naltered data.",
          "link": "http://arxiv.org/abs/2012.04056",
          "publishedOn": "2021-06-16T01:21:07.529Z",
          "wordCount": 642,
          "title": "Semantics Altering Modifications for Evaluating Comprehension in Machine Reading. (arXiv:2012.04056v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.07805",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Carlini_N/0/1/0/all/0/1\">Nicholas Carlini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tramer_F/0/1/0/all/0/1\">Florian Tramer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wallace_E/0/1/0/all/0/1\">Eric Wallace</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jagielski_M/0/1/0/all/0/1\">Matthew Jagielski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Herbert_Voss_A/0/1/0/all/0/1\">Ariel Herbert-Voss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Katherine Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roberts_A/0/1/0/all/0/1\">Adam Roberts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brown_T/0/1/0/all/0/1\">Tom Brown</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1\">Dawn Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erlingsson_U/0/1/0/all/0/1\">Ulfar Erlingsson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oprea_A/0/1/0/all/0/1\">Alina Oprea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raffel_C/0/1/0/all/0/1\">Colin Raffel</a>",
          "description": "It has become common to publish large (billion parameter) language models\nthat have been trained on private datasets. This paper demonstrates that in\nsuch settings, an adversary can perform a training data extraction attack to\nrecover individual training examples by querying the language model.\n\nWe demonstrate our attack on GPT-2, a language model trained on scrapes of\nthe public Internet, and are able to extract hundreds of verbatim text\nsequences from the model's training data. These extracted examples include\n(public) personally identifiable information (names, phone numbers, and email\naddresses), IRC conversations, code, and 128-bit UUIDs. Our attack is possible\neven though each of the above sequences are included in just one document in\nthe training data.\n\nWe comprehensively evaluate our extraction attack to understand the factors\nthat contribute to its success. Worryingly, we find that larger models are more\nvulnerable than smaller models. We conclude by drawing lessons and discussing\npossible safeguards for training large language models.",
          "link": "http://arxiv.org/abs/2012.07805",
          "publishedOn": "2021-06-16T01:21:07.435Z",
          "wordCount": 643,
          "title": "Extracting Training Data from Large Language Models. (arXiv:2012.07805v2 [cs.CR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.07583",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ujiie_S/0/1/0/all/0/1\">Shogo Ujiie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iso_H/0/1/0/all/0/1\">Hayate Iso</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aramaki_E/0/1/0/all/0/1\">Eiji Aramaki</a>",
          "description": "We introduce BioCoM, a contrastive learning framework for biomedical entity\nlinking that uses only two resources: a small-sized dictionary and a large\nnumber of raw biomedical articles. Specifically, we build the training\ninstances from raw PubMed articles by dictionary matching and use them to train\na context-aware entity linking model with contrastive learning. We predict the\nnormalized biomedical entity at inference time through a nearest-neighbor\nsearch. Results found that BioCoM substantially outperforms state-of-the-art\nmodels, especially in low-resource settings, by effectively using the context\nof the entities.",
          "link": "http://arxiv.org/abs/2106.07583",
          "publishedOn": "2021-06-16T01:21:07.402Z",
          "wordCount": 526,
          "title": "Biomedical Entity Linking with Contrastive Context Matching. (arXiv:2106.07583v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.07139",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhengyan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_N/0/1/0/all/0/1\">Ning Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1\">Yuxian Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huo_Y/0/1/0/all/0/1\">Yuqi Huo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_J/0/1/0/all/0/1\">Jiezhong Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Liang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_W/0/1/0/all/0/1\">Wentao Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Minlie Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Q/0/1/0/all/0/1\">Qin Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_Y/0/1/0/all/0/1\">Yanyan Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1\">Zhiwu Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1\">Xipeng Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_R/0/1/0/all/0/1\">Ruihua Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jie Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Ji-Rong Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1\">Jinhui Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wayne Xin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jun Zhu</a>",
          "description": "Large-scale pre-trained models (PTMs) such as BERT and GPT have recently\nachieved great success and become a milestone in the field of artificial\nintelligence (AI). Owing to sophisticated pre-training objectives and huge\nmodel parameters, large-scale PTMs can effectively capture knowledge from\nmassive labeled and unlabeled data. By storing knowledge into huge parameters\nand fine-tuning on specific tasks, the rich knowledge implicitly encoded in\nhuge parameters can benefit a variety of downstream tasks, which has been\nextensively demonstrated via experimental verification and empirical analysis.\nIt is now the consensus of the AI community to adopt PTMs as backbone for\ndownstream tasks rather than learning models from scratch. In this paper, we\ntake a deep look into the history of pre-training, especially its special\nrelation with transfer learning and self-supervised learning, to reveal the\ncrucial position of PTMs in the AI development spectrum. Further, we\ncomprehensively review the latest breakthroughs of PTMs. These breakthroughs\nare driven by the surge of computational power and the increasing availability\nof data, towards four important directions: designing effective architectures,\nutilizing rich contexts, improving computational efficiency, and conducting\ninterpretation and theoretical analysis. Finally, we discuss a series of open\nproblems and research directions of PTMs, and hope our view can inspire and\nadvance the future study of PTMs.",
          "link": "http://arxiv.org/abs/2106.07139",
          "publishedOn": "2021-06-16T01:21:07.396Z",
          "wordCount": 690,
          "title": "Pre-Trained Models: Past, Present and Future. (arXiv:2106.07139v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1909.06723",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaosen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_H/0/1/0/all/0/1\">Hao Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yichen Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_K/0/1/0/all/0/1\">Kun He</a>",
          "description": "In the area of natural language processing, deep learning models are recently\nknown to be vulnerable to various types of adversarial perturbations, but\nrelatively few works are done on the defense side. Especially, there exists few\neffective defense method against the successful synonym substitution based\nattacks that preserve the syntactic structure and semantic information of the\noriginal text while fooling the deep learning models. We contribute in this\ndirection and propose a novel adversarial defense method called Synonym\nEncoding Method (SEM). Specifically, SEM inserts an encoder before the input\nlayer of the target model to map each cluster of synonyms to a unique encoding\nand trains the model to eliminate possible adversarial perturbations without\nmodifying the network architecture or adding extra data. Extensive experiments\ndemonstrate that SEM can effectively defend the current synonym substitution\nbased attacks and block the transferability of adversarial examples. SEM is\nalso easy and efficient to scale to large models and big datasets.",
          "link": "http://arxiv.org/abs/1909.06723",
          "publishedOn": "2021-06-16T01:21:07.353Z",
          "wordCount": 643,
          "title": "Natural Language Adversarial Defense through Synonym Encoding. (arXiv:1909.06723v4 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.05752",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chen Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1\">Bojie Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yanyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuhao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+huang_s/0/1/0/all/0/1\">shen huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ju_Q/0/1/0/all/0/1\">Qi Ju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_T/0/1/0/all/0/1\">Tong Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jingbo Zhu</a>",
          "description": "Encoder pre-training is promising in end-to-end Speech Translation (ST),\ngiven the fact that speech-to-translation data is scarce. But ST encoders are\nnot simple instances of Automatic Speech Recognition (ASR) or Machine\nTranslation (MT) encoders. For example, we find that ASR encoders lack the\nglobal context representation, which is necessary for translation, whereas MT\nencoders are not designed to deal with long but locally attentive acoustic\nsequences. In this work, we propose a Stacked Acoustic-and-Textual Encoding\n(SATE) method for speech translation. Our encoder begins with processing the\nacoustic sequence as usual, but later behaves more like an MT encoder for a\nglobal representation of the input sequence. In this way, it is straightforward\nto incorporate the pre-trained models into the system. Also, we develop an\nadaptor module to alleviate the representation inconsistency between the\npre-trained ASR encoder and MT encoder, and develop a multi-teacher knowledge\ndistillation method to preserve the pre-training knowledge. Experimental\nresults on the LibriSpeech En-Fr and MuST-C En-De ST tasks show that our method\nachieves state-of-the-art BLEU scores of 18.3 and 25.2. To our knowledge, we\nare the first to develop an end-to-end ST system that achieves comparable or\neven better BLEU performance than the cascaded ST counterpart when large-scale\nASR and MT data is available.",
          "link": "http://arxiv.org/abs/2105.05752",
          "publishedOn": "2021-06-16T01:21:07.328Z",
          "wordCount": 692,
          "title": "Stacked Acoustic-and-Textual Encoding: Integrating the Pre-trained Models into Speech Translation Encoders. (arXiv:2105.05752v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.07400",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meister_C/0/1/0/all/0/1\">Clara Meister</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Forster_M/0/1/0/all/0/1\">Martina Forster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>",
          "description": "Beam search is a go-to strategy for decoding neural sequence models. The\nalgorithm can naturally be viewed as a subset optimization problem, albeit one\nwhere the corresponding set function does not reflect interactions between\ncandidates. Empirically, this leads to sets often exhibiting high overlap,\ne.g., strings may differ by only a single word. Yet in use-cases that call for\nmultiple solutions, a diverse or representative set is often desired. To\naddress this issue, we propose a reformulation of beam search, which we call\ndeterminantal beam search. Determinantal beam search has a natural relationship\nto determinantal point processes (DPPs), models over sets that inherently\nencode intra-set interactions. By posing iterations in beam search as a series\nof subdeterminant maximization problems, we can turn the algorithm into a\ndiverse subset selection process. In a case study, we use the string\nsubsequence kernel to explicitly encourage n-gram coverage in text generated\nfrom a sequence model. We observe that our algorithm offers competitive\nperformance against other diverse set generation strategies in the context of\nlanguage generation, while providing a more general approach to optimizing for\ndiversity.",
          "link": "http://arxiv.org/abs/2106.07400",
          "publishedOn": "2021-06-16T01:21:07.284Z",
          "wordCount": 619,
          "title": "Determinantal Beam Search. (arXiv:2106.07400v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.09914",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Stephenson_B/0/1/0/all/0/1\">Brooke Stephenson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hueber_T/0/1/0/all/0/1\">Thomas Hueber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Girin_L/0/1/0/all/0/1\">Laurent Girin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Besacier_L/0/1/0/all/0/1\">Laurent Besacier</a>",
          "description": "The prosody of a spoken word is determined by its surrounding context. In\nincremental text-to-speech synthesis, where the synthesizer produces an output\nbefore it has access to the complete input, the full context is often unknown\nwhich can result in a loss of naturalness in the synthesized speech. In this\npaper, we investigate whether the use of predicted future text can attenuate\nthis loss. We compare several test conditions of next future word: (a) unknown\n(zero-word), (b) language model predicted, (c) randomly predicted and (d)\nground-truth. We measure the prosodic features (pitch, energy and duration) and\nfind that predicted text provides significant improvements over a zero-word\nlookahead, but only slight gains over random-word lookahead. We confirm these\nresults with a perceptive test.",
          "link": "http://arxiv.org/abs/2102.09914",
          "publishedOn": "2021-06-16T01:21:07.267Z",
          "wordCount": 595,
          "title": "Alternate Endings: Improving Prosody for Incremental Neural TTS with Predicted Future Text Input. (arXiv:2102.09914v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.07947",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yixiao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bouraoui_Z/0/1/0/all/0/1\">Zied Bouraoui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anke_L/0/1/0/all/0/1\">Luis Espinosa Anke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schockaert_S/0/1/0/all/0/1\">Steven Schockaert</a>",
          "description": "One of the long-standing challenges in lexical semantics consists in learning\nrepresentations of words which reflect their semantic properties. The\nremarkable success of word embeddings for this purpose suggests that\nhigh-quality representations can be obtained by summarizing the sentence\ncontexts of word mentions. In this paper, we propose a method for learning word\nrepresentations that follows this basic strategy, but differs from standard\nword embeddings in two important ways. First, we take advantage of\ncontextualized language models (CLMs) rather than bags of word vectors to\nencode contexts. Second, rather than learning a word vector directly, we use a\ntopic model to partition the contexts in which words appear, and then learn\ndifferent topic-specific vectors for each word. Finally, we use a task-specific\nsupervision signal to make a soft selection of the resulting vectors. We show\nthat this simple strategy leads to high-quality word vectors, which are more\npredictive of semantic properties than word embeddings and existing CLM-based\nstrategies.",
          "link": "http://arxiv.org/abs/2106.07947",
          "publishedOn": "2021-06-16T01:21:07.233Z",
          "wordCount": 591,
          "title": "Deriving Word Vectors from Contextualized Language Models using Topic-Aware Mention Selection. (arXiv:2106.07947v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2103.01620",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Caucheteux_C/0/1/0/all/0/1\">Charlotte Caucheteux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gramfort_A/0/1/0/all/0/1\">Alexandre Gramfort</a>, <a href=\"http://arxiv.org/find/cs/1/au:+King_J/0/1/0/all/0/1\">Jean-Remi King</a>",
          "description": "The activations of language transformers like GPT-2 have been shown to\nlinearly map onto brain activity during speech comprehension. However, the\nnature of these activations remains largely unknown and presumably conflate\ndistinct linguistic classes. Here, we propose a taxonomy to factorize the\nhigh-dimensional activations of language models into four combinatorial\nclasses: lexical, compositional, syntactic, and semantic representations. We\nthen introduce a statistical method to decompose, through the lens of GPT-2's\nactivations, the brain activity of 345 subjects recorded with functional\nmagnetic resonance imaging (fMRI) during the listening of ~4.6 hours of\nnarrated text. The results highlight two findings. First, compositional\nrepresentations recruit a more widespread cortical network than lexical ones,\nand encompass the bilateral temporal, parietal and prefrontal cortices. Second,\ncontrary to previous claims, syntax and semantics are not associated with\nseparated modules, but, instead, appear to share a common and distributed\nneural substrate. Overall, this study introduces a versatile framework to\nisolate, in the brain activity, the distributed representations of linguistic\nconstructs.",
          "link": "http://arxiv.org/abs/2103.01620",
          "publishedOn": "2021-06-16T01:21:07.206Z",
          "wordCount": 631,
          "title": "Disentangling Syntax and Semantics in the Brain with Deep Networks. (arXiv:2103.01620v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1909.00453",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Sachin Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wintner_S/0/1/0/all/0/1\">Shuly Wintner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1\">Noah A. Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsvetkov_Y/0/1/0/all/0/1\">Yulia Tsvetkov</a>",
          "description": "Despite impressive performance on many text classification tasks, deep neural\nnetworks tend to learn frequent superficial patterns that are specific to the\ntraining data and do not always generalize well. In this work, we observe this\nlimitation with respect to the task of native language identification. We find\nthat standard text classifiers which perform well on the test set end up\nlearning topical features which are confounds of the prediction task (e.g., if\nthe input text mentions Sweden, the classifier predicts that the author's\nnative language is Swedish). We propose a method that represents the latent\ntopical confounds and a model which \"unlearns\" confounding features by\npredicting both the label of the input text and the confound; but we train the\ntwo predictors adversarially in an alternating fashion to learn a text\nrepresentation that predicts the correct label but is less prone to using\ninformation about the confound. We show that this model generalizes better and\nlearns features that are indicative of the writing style rather than the\ncontent.",
          "link": "http://arxiv.org/abs/1909.00453",
          "publishedOn": "2021-06-16T01:21:07.198Z",
          "wordCount": 648,
          "title": "Topics to Avoid: Demoting Latent Confounds in Text Classification. (arXiv:1909.00453v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.01757",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Salesky_E/0/1/0/all/0/1\">Elizabeth Salesky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wiesner_M/0/1/0/all/0/1\">Matthew Wiesner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bremerman_J/0/1/0/all/0/1\">Jacob Bremerman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cattoni_R/0/1/0/all/0/1\">Roldano Cattoni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Negri_M/0/1/0/all/0/1\">Matteo Negri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turchi_M/0/1/0/all/0/1\">Marco Turchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oard_D/0/1/0/all/0/1\">Douglas W. Oard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Post_M/0/1/0/all/0/1\">Matt Post</a>",
          "description": "We present the Multilingual TEDx corpus, built to support speech recognition\n(ASR) and speech translation (ST) research across many non-English source\nlanguages. The corpus is a collection of audio recordings from TEDx talks in 8\nsource languages. We segment transcripts into sentences and align them to the\nsource-language audio and target-language translations. The corpus is released\nalong with open-sourced code enabling extension to new talks and languages as\nthey become available. Our corpus creation methodology can be applied to more\nlanguages than previous work, and creates multi-way parallel evaluation sets.\nWe provide baselines in multiple ASR and ST settings, including multilingual\nmodels to improve translation performance for low-resource language pairs.",
          "link": "http://arxiv.org/abs/2102.01757",
          "publishedOn": "2021-06-16T01:21:07.191Z",
          "wordCount": 583,
          "title": "The Multilingual TEDx Corpus for Speech Recognition and Translation. (arXiv:2102.01757v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.07043",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Haitian Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verga_P/0/1/0/all/0/1\">Pat Verga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dhingra_B/0/1/0/all/0/1\">Bhuwan Dhingra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1\">Ruslan Salakhutdinov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_W/0/1/0/all/0/1\">William W. Cohen</a>",
          "description": "We present the Open Predicate Query Language (OPQL); a method for\nconstructing a virtual KB (VKB) trained entirely from text. Large Knowledge\nBases (KBs) are indispensable for a wide-range of industry applications such as\nquestion answering and recommendation. Typically, KBs encode world knowledge in\na structured, readily accessible form derived from laborious human annotation\nefforts. Unfortunately, while they are extremely high precision, KBs are\ninevitably highly incomplete and automated methods for enriching them are far\ntoo inaccurate. Instead, OPQL constructs a VKB by encoding and indexing a set\nof relation mentions in a way that naturally enables reasoning and can be\ntrained without any structured supervision. We demonstrate that OPQL\noutperforms prior VKB methods on two different KB reasoning tasks and,\nadditionally, can be used as an external memory integrated into a language\nmodel (OPQL-LM) leading to improvements on two open-domain question answering\ntasks.",
          "link": "http://arxiv.org/abs/2102.07043",
          "publishedOn": "2021-06-16T01:21:07.184Z",
          "wordCount": 625,
          "title": "Reasoning Over Virtual Knowledge Bases With Open Predicate Relations. (arXiv:2102.07043v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.07936",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Heitmeier_M/0/1/0/all/0/1\">Maria Heitmeier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chuang_Y/0/1/0/all/0/1\">Yu-Ying Chuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baayen_R/0/1/0/all/0/1\">R. Harald Baayen</a>",
          "description": "This study addresses a series of methodological questions that arise when\nmodeling inflectional morphology with Linear Discriminative Learning. Taking\nthe semi-productive German noun system as example, we illustrate how decisions\nmade about the representation of form and meaning influence model performance.\nWe clarify that for modeling frequency effects in learning, it is essential to\nmake use of incremental learning rather than the endstate of learning. We also\ndiscuss how the model can be set up to approximate the learning of inflected\nwords in context. In addition, we illustrate how in this approach the wug task\ncan be modeled in considerable detail. In general, the model provides an\nexcellent memory for known words, but appropriately shows more limited\nperformance for unseen data, in line with the semi-productivity of German noun\ninflection and generalization performance of native German speakers.",
          "link": "http://arxiv.org/abs/2106.07936",
          "publishedOn": "2021-06-16T01:21:07.178Z",
          "wordCount": 572,
          "title": "Modeling morphology with Linear Discriminative Learning: considerations and design choices. (arXiv:2106.07936v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08062",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1\">Soyoung Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1\">Gyuwan Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_K/0/1/0/all/0/1\">Kyumin Park</a>",
          "description": "Data augmentation with mixup has shown to be effective on various computer\nvision tasks. Despite its great success, there has been a hurdle to apply mixup\nto NLP tasks since text consists of discrete tokens with variable length. In\nthis work, we propose SSMix, a novel mixup method where the operation is\nperformed on input text rather than on hidden vectors like previous approaches.\nSSMix synthesizes a sentence while preserving the locality of two original\ntexts by span-based mixing and keeping more tokens related to the prediction\nrelying on saliency information. With extensive experiments, we empirically\nvalidate that our method outperforms hidden-level mixup methods on a wide range\nof text classification benchmarks, including textual entailment, sentiment\nclassification, and question-type classification. Our code is available at\nhttps://github.com/clovaai/ssmix.",
          "link": "http://arxiv.org/abs/2106.08062",
          "publishedOn": "2021-06-16T01:21:07.158Z",
          "wordCount": 563,
          "title": "SSMix: Saliency-Based Span Mixup for Text Classification. (arXiv:2106.08062v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08126",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Arabskyy_Y/0/1/0/all/0/1\">Yuriy Arabskyy</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Agarwal_A/0/1/0/all/0/1\">Aashish Agarwal</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dey_S/0/1/0/all/0/1\">Subhadeep Dey</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Koller_O/0/1/0/all/0/1\">Oscar Koller</a>",
          "description": "This paper describes the winning approach in the public SwissText 2021\ncompetition on dialect recognition and translation of Swiss German speech to\nstandard German text. Swiss German refers to the multitude of Alemannic\ndialects spoken in the German-speaking parts of Switzerland. Swiss German\ndiffers significantly from standard German in pronunciation, word inventory and\ngrammar. It is mostly incomprehensible to native German speakers. Moreover, it\nlacks a standardized written script. To solve the challenging task, we propose\na hybrid automatic speech recognition system with a lexicon that incorporates\ntranslations, a 1st pass language model that deals with Swiss German\nparticularities, a transfer-learned acoustic model and a strong neural language\nmodel for 2nd pass rescoring. Our submission reaches 46.04% BLEU on a blind\nconversational test set and outperforms the second best competitor by a 12%\nrelative margin.",
          "link": "http://arxiv.org/abs/2106.08126",
          "publishedOn": "2021-06-16T01:21:07.152Z",
          "wordCount": 598,
          "title": "Dialectal Speech Recognition and Translation of Swiss German Speech to Standard German Text: Microsoft's Submission to SwissText 2021. (arXiv:2106.08126v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2104.06104",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Wei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeyer_A/0/1/0/all/0/1\">Albert Zeyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Merboldt_A/0/1/0/all/0/1\">Andr&#xe9; Merboldt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schluter_R/0/1/0/all/0/1\">Ralf Schl&#xfc;ter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ney_H/0/1/0/all/0/1\">Hermann Ney</a>",
          "description": "With the advent of direct models in automatic speech recognition (ASR), the\nformerly prevalent frame-wise acoustic modeling based on hidden Markov models\n(HMM) diversified into a number of modeling architectures like encoder-decoder\nattention models, transducer models and segmental models (direct HMM). While\ntransducer models stay with a frame-level model definition, segmental models\nare defined on the level of label segments directly. While\n(soft-)attention-based models avoid explicit alignment, transducer and\nsegmental approach internally do model alignment, either by segment hypotheses\nor, more implicitly, by emitting so-called blank symbols. In this work, we\nprove that the widely used class of RNN-Transducer models and segmental models\n(direct HMM) are equivalent and therefore show equal modeling power. It is\nshown that blank probabilities translate into segment length probabilities and\nvice versa. In addition, we provide initial experiments investigating decoding\nand beam-pruning, comparing time-synchronous and label-/segment-synchronous\nsearch strategies and their properties using the same underlying model.",
          "link": "http://arxiv.org/abs/2104.06104",
          "publishedOn": "2021-06-16T01:21:07.137Z",
          "wordCount": 626,
          "title": "Equivalence of Segmental and Neural Transducer Modeling: A Proof of Concept. (arXiv:2104.06104v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08252",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ebadi_N/0/1/0/all/0/1\">Nima Ebadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Najafirad_P/0/1/0/all/0/1\">Peyman Najafirad</a>",
          "description": "The rapidly evolving literature of COVID-19 related articles makes it\nchallenging for NLP models to be effectively trained for information retrieval\nand extraction with the corresponding labeled data that follows the current\ndistribution of the pandemic. On the other hand, due to the uncertainty of the\nsituation, human experts' supervision would always be required to double check\nthe decision making of these models highlighting the importance of\ninterpretability. In the light of these challenges, this study proposes an\ninterpretable self-supervised multi-task learning model to jointly and\neffectively tackle the tasks of information retrieval (IR) and extraction (IE)\nduring the current emergency health crisis situation. Our results show that our\nmodel effectively leverage the multi-task and self-supervised learning to\nimprove generalization, data efficiency and robustness to the ongoing dataset\nshift problem. Our model outperforms baselines in IE and IR tasks, respectively\nby micro-f score of 0.08 (LCA-F score of 0.05), and MAP of 0.05 on average. In\nIE the zero- and few-shot learning performances are on average 0.32 and 0.19\nmicro-f score higher than those of the baselines.",
          "link": "http://arxiv.org/abs/2106.08252",
          "publishedOn": "2021-06-16T01:21:07.129Z",
          "wordCount": 650,
          "title": "Interpretable Self-supervised Multi-task Learning for COVID-19 Information Retrieval and Extraction. (arXiv:2106.08252v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08004",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_R/0/1/0/all/0/1\">Runqiu Xiao</a>",
          "description": "Deep-Neural-Network (DNN) based speaker verification sys-tems use the angular\nsoftmax loss with margin penalties toenhance the intra-class compactness of\nspeaker embeddings,which achieved remarkable performance. In this paper, we\npro-pose a novel angular loss function called adaptive margin cir-cle loss for\nspeaker verification. The stage-based margin andchunk-based margin are applied\nto improve the angular discrim-ination of circle loss on the training set. The\nanalysis on gradi-ents shows that, compared with the previous angular loss\nlikeAdditive Margin Softmax(Am-Softmax), circle loss has flexi-ble optimization\nand definite convergence status. Experimentsare carried out on the Voxceleb and\nSITW. By applying adap-tive margin circle loss, our best system achieves\n1.31%EER onVoxceleb1 and 2.13% on SITW core-core.",
          "link": "http://arxiv.org/abs/2106.08004",
          "publishedOn": "2021-06-16T01:21:07.110Z",
          "wordCount": 541,
          "title": "Adaptive Margin Circle Loss for Speaker Verification. (arXiv:2106.08004v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04554",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_T/0/1/0/all/0/1\">Tianyang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuxin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiangyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1\">Xipeng Qiu</a>",
          "description": "Transformers have achieved great success in many artificial intelligence\nfields, such as natural language processing, computer vision, and audio\nprocessing. Therefore, it is natural to attract lots of interest from academic\nand industry researchers. Up to the present, a great variety of Transformer\nvariants (a.k.a. X-formers) have been proposed, however, a systematic and\ncomprehensive literature review on these Transformer variants is still missing.\nIn this survey, we provide a comprehensive review of various X-formers. We\nfirst briefly introduce the vanilla Transformer and then propose a new taxonomy\nof X-formers. Next, we introduce the various X-formers from three perspectives:\narchitectural modification, pre-training, and applications. Finally, we outline\nsome potential directions for future research.",
          "link": "http://arxiv.org/abs/2106.04554",
          "publishedOn": "2021-06-16T01:21:07.104Z",
          "wordCount": 554,
          "title": "A Survey of Transformers. (arXiv:2106.04554v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08235",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zhaozhuo Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_M/0/1/0/all/0/1\">Minghao Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Junyan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shrivastava_A/0/1/0/all/0/1\">Anshumali Shrivastava</a>",
          "description": "Transformer models have demonstrated superior performance in natural language\nprocessing. The dot product self-attention in Transformer allows us to model\ninteractions between words. However, this modeling comes with significant\ncomputational overhead. In this work, we revisit the memory-compute trade-off\nassociated with Transformer, particularly multi-head attention, and show a\nmemory-heavy but significantly more compute-efficient alternative to\nTransformer. Our proposal, denoted as PairConnect, a multilayer perceptron\n(MLP), models the pairwise interaction between words by explicit pairwise word\nembeddings. As a result, PairConnect substitutes self dot product with a simple\nembedding lookup. We show mathematically that despite being an MLP, our\ncompute-efficient PairConnect is strictly more expressive than Transformer. Our\nexperiment on language modeling tasks suggests that PairConnect could achieve\ncomparable results with Transformer while reducing the computational cost\nassociated with inference significantly.",
          "link": "http://arxiv.org/abs/2106.08235",
          "publishedOn": "2021-06-16T01:21:07.098Z",
          "wordCount": 557,
          "title": "PairConnect: A Compute-Efficient MLP Alternative to Attention. (arXiv:2106.08235v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08159",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Grunewald_S/0/1/0/all/0/1\">Stefan Gr&#xfc;newald</a>",
          "description": "Modern graph-based syntactic dependency parsers operate by predicting, for\neach token within a sentence, a probability distribution over its possible\nsyntactic heads (i.e., all other tokens) and then extracting a maximum spanning\ntree from the resulting log-probabilities. Nowadays, virtually all such parsers\nutilize deep neural networks and may thus be susceptible to miscalibration (in\nparticular, overconfident predictions). In this paper, we prove that\ntemperature scaling, a popular technique for post-hoc calibration of neural\nnetworks, cannot change the output of the aforementioned procedure. We conclude\nthat other techniques are needed to tackle miscalibration in graph-based\ndependency parsers in a way that improves parsing accuracy.",
          "link": "http://arxiv.org/abs/2106.08159",
          "publishedOn": "2021-06-16T01:21:07.091Z",
          "wordCount": 536,
          "title": "Maximum Spanning Trees Are Invariant to Temperature Scaling in Graph-based Dependency Parsing. (arXiv:2106.08159v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08294",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kutuzov_A/0/1/0/all/0/1\">Andrey Kutuzov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pivovarova_L/0/1/0/all/0/1\">Lidia Pivovarova</a>",
          "description": "We present a manually annotated lexical semantic change dataset for Russian:\nRuShiftEval. Its novelty is ensured by a single set of target words annotated\nfor their diachronic semantic shifts across three time periods, while the\nprevious work either used only two time periods, or different sets of target\nwords. The paper describes the composition and annotation procedure for the\ndataset. In addition, it is shown how the ternary nature of RuShiftEval allows\nto trace specific diachronic trajectories: `changed at a particular time period\nand stable afterwards' or `was changing throughout all time periods'. Based on\nthe analysis of the submissions to the recent shared task on semantic change\ndetection for Russian, we argue that correctly identifying such trajectories\ncan be an interesting sub-task itself.",
          "link": "http://arxiv.org/abs/2106.08294",
          "publishedOn": "2021-06-16T01:21:07.085Z",
          "wordCount": 559,
          "title": "Three-part diachronic semantic change dataset for Russian. (arXiv:2106.08294v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08087",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bi_Z/0/1/0/all/0/1\">Zhen Bi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1\">Xiaozhuan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Shumin Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Luoqiu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xin Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1\">Hongbin Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shang_X/0/1/0/all/0/1\">Xin Shang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_K/0/1/0/all/0/1\">Kangping Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Chuanqi Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jian Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Mosha Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Si_L/0/1/0/all/0/1\">Luo Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_Y/0/1/0/all/0/1\">Yuan Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_G/0/1/0/all/0/1\">Guotong Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sui_Z/0/1/0/all/0/1\">Zhifang Sui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_B/0/1/0/all/0/1\">Baobao Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zong_H/0/1/0/all/0/1\">Hui Zong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Z/0/1/0/all/0/1\">Zheng Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Linfeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Jun Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zan_H/0/1/0/all/0/1\">Hongying Zan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kunli Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_B/0/1/0/all/0/1\">Buzhou Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qingcai Chen</a>",
          "description": "Artificial Intelligence (AI), along with the recent progress in biomedical\nlanguage understanding, is gradually changing medical practice. With the\ndevelopment of biomedical language understanding benchmarks, AI applications\nare widely used in the medical field. However, most benchmarks are limited to\nEnglish, which makes it challenging to replicate many of the successes in\nEnglish for other languages. To facilitate research in this direction, we\ncollect real-world biomedical data and present the first Chinese Biomedical\nLanguage Understanding Evaluation (CBLUE) benchmark: a collection of natural\nlanguage understanding tasks including named entity recognition, information\nextraction, clinical diagnosis normalization, single-sentence/sentence-pair\nclassification, and an associated online platform for model evaluation,\ncomparison, and analysis. To establish evaluation on these tasks, we report\nempirical results with the current 11 pre-trained Chinese models, and\nexperimental results show that state-of-the-art neural models perform by far\nworse than the human ceiling. Our benchmark is released at\n\\url{https://tianchi.aliyun.com/dataset/dataDetail?dataId=95414&lang=en-us}.",
          "link": "http://arxiv.org/abs/2106.08087",
          "publishedOn": "2021-06-16T01:21:07.078Z",
          "wordCount": 624,
          "title": "CBLUE: A Chinese Biomedical Language Understanding Evaluation Benchmark. (arXiv:2106.08087v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08181",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Balazy_K/0/1/0/all/0/1\">Klaudia Ba&#x142;azy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Banaei_M/0/1/0/all/0/1\">Mohammadreza Banaei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lebret_R/0/1/0/all/0/1\">R&#xe9;mi Lebret</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tabor_J/0/1/0/all/0/1\">Jacek Tabor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aberer_K/0/1/0/all/0/1\">Karl Aberer</a>",
          "description": "The adoption of Transformer-based models in natural language processing (NLP)\nhas led to great success using a massive number of parameters. However, due to\ndeployment constraints in edge devices, there has been a rising interest in the\ncompression of these models to improve their inference time and memory\nfootprint. This paper presents a novel loss objective to compress token\nembeddings in the Transformer-based models by leveraging an AutoEncoder\narchitecture. More specifically, we emphasize the importance of the direction\nof compressed embeddings with respect to original uncompressed embeddings. The\nproposed method is task-agnostic and does not require further language modeling\npre-training. Our method significantly outperforms the commonly used SVD-based\nmatrix-factorization approach in terms of initial language model Perplexity.\nMoreover, we evaluate our proposed approach over SQuAD v1.1 dataset and several\ndownstream tasks from the GLUE benchmark, where we also outperform the baseline\nin most scenarios. Our code is public.",
          "link": "http://arxiv.org/abs/2106.08181",
          "publishedOn": "2021-06-16T01:21:07.059Z",
          "wordCount": 586,
          "title": "Direction is what you need: Improving Word Embedding Compression in Large Language Models. (arXiv:2106.08181v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08043",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maiya_A/0/1/0/all/0/1\">Arun S. Maiya</a>",
          "description": "The vast majority of existing methods and systems for causal inference assume\nthat all variables under consideration are categorical or numerical (e.g.,\ngender, price, blood pressure, enrollment). In this paper, we present\nCausalNLP, a toolkit for inferring causality from observational data that\nincludes text in addition to traditional numerical and categorical variables.\nCausalNLP employs the use of meta-learners for treatment effect estimation and\nsupports using raw text and its linguistic properties as both a treatment and a\n\"controlled-for\" variable (e.g., confounder). The library is open-source and\navailable at: https://github.com/amaiya/causalnlp.",
          "link": "http://arxiv.org/abs/2106.08043",
          "publishedOn": "2021-06-16T01:21:07.053Z",
          "wordCount": 521,
          "title": "CausalNLP: A Practical Toolkit for Causal Inference with Text. (arXiv:2106.08043v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07759",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Manohar_V/0/1/0/all/0/1\">Vimal Manohar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Likhomanenko_T/0/1/0/all/0/1\">Tatiana Likhomanenko</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_Q/0/1/0/all/0/1\">Qiantong Xu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hsu_W/0/1/0/all/0/1\">Wei-Ning Hsu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Collobert_R/0/1/0/all/0/1\">Ronan Collobert</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Saraf_Y/0/1/0/all/0/1\">Yatharth Saraf</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zweig_G/0/1/0/all/0/1\">Geoffrey Zweig</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mohamed_A/0/1/0/all/0/1\">Abdelrahman Mohamed</a>",
          "description": "In this paper, we introduce the Kaizen framework that uses a continuously\nimproving teacher to generate pseudo-labels for semi-supervised training. The\nproposed approach uses a teacher model which is updated as the exponential\nmoving average of the student model parameters. This can be seen as a\ncontinuous version of the iterative pseudo-labeling approach for\nsemi-supervised training. It is applicable for different training criteria, and\nin this paper we demonstrate it for frame-level hybrid hidden Markov model -\ndeep neural network (HMM-DNN) models and sequence-level connectionist temporal\nclassification (CTC) based models. The proposed approach shows more than 10%\nword error rate (WER) reduction over standard teacher-student training and more\nthan 50\\% relative WER reduction over 10 hour supervised baseline when using\nlarge scale realistic unsupervised public videos in UK English and Italian\nlanguages.",
          "link": "http://arxiv.org/abs/2106.07759",
          "publishedOn": "2021-06-16T01:21:07.045Z",
          "wordCount": 598,
          "title": "Kaizen: Continuously improving teacher using Exponential Moving Average for semi-supervised speech recognition. (arXiv:2106.07759v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2104.01894",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sanabria_R/0/1/0/all/0/1\">Ramon Sanabria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Waters_A/0/1/0/all/0/1\">Austin Waters</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baldridge_J/0/1/0/all/0/1\">Jason Baldridge</a>",
          "description": "Speech-based image retrieval has been studied as a proxy for joint\nrepresentation learning, usually without emphasis on retrieval itself. As such,\nit is unclear how well speech-based retrieval can work in practice -- both in\nan absolute sense and versus alternative strategies that combine automatic\nspeech recognition (ASR) with strong text encoders. In this work, we\nextensively study and expand choices of encoder architectures, training\nmethodology (including unimodal and multimodal pretraining), and other factors.\nOur experiments cover different types of speech in three datasets: Flickr\nAudio, Places Audio, and Localized Narratives. Our best model configuration\nachieves large gains over state of the art, e.g., pushing recall-at-one from\n21.8% to 33.2% for Flickr Audio and 27.6% to 53.4% for Places Audio. We also\nshow our best speech-based models can match or exceed cascaded ASR-to-text\nencoding when speech is spontaneous, accented, or otherwise hard to\nautomatically transcribe.",
          "link": "http://arxiv.org/abs/2104.01894",
          "publishedOn": "2021-06-16T01:21:07.030Z",
          "wordCount": 631,
          "title": "Talk, Don't Write: A Study of Direct Speech-Based Image Retrieval. (arXiv:2104.01894v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08037",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pyatkin_V/0/1/0/all/0/1\">Valentina Pyatkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sadde_S/0/1/0/all/0/1\">Shoval Sadde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubinstein_A/0/1/0/all/0/1\">Aynat Rubinstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Portner_P/0/1/0/all/0/1\">Paul Portner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsarfaty_R/0/1/0/all/0/1\">Reut Tsarfaty</a>",
          "description": "Modality is the linguistic ability to describe events with added information\nsuch as how desirable, plausible, or feasible they are. Modality is important\nfor many NLP downstream tasks such as the detection of hedging, uncertainty,\nspeculation, and more. Previous studies that address modality detection in NLP\noften restrict modal expressions to a closed syntactic class, and the modal\nsense labels are vastly different across different studies, lacking an accepted\nstandard. Furthermore, these senses are often analyzed independently of the\nevents that they modify. This work builds on the theoretical foundations of the\nGeorgetown Gradable Modal Expressions (GME) work by Rubinstein et al. (2013) to\npropose an event-based modality detection task where modal expressions can be\nwords of any syntactic class and sense labels are drawn from a comprehensive\ntaxonomy which harmonizes the modal concepts contributed by the different\nstudies. We present experiments on the GME corpus aiming to detect and classify\nfine-grained modal concepts and associate them with their modified events. We\nshow that detecting and classifying modal expressions is not only feasible, but\nalso improves the detection of modal events in their own right.",
          "link": "http://arxiv.org/abs/2106.08037",
          "publishedOn": "2021-06-16T01:21:07.012Z",
          "wordCount": 626,
          "title": "The Possible, the Plausible, and the Desirable: Event-Based Modality Detection for Language Processing. (arXiv:2106.08037v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07847",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bao_Y/0/1/0/all/0/1\">Yujia Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1\">Shiyu Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barzilay_R/0/1/0/all/0/1\">Regina Barzilay</a>",
          "description": "We study transfer learning in the presence of spurious correlations. We\nexperimentally demonstrate that directly transferring the stable feature\nextractor learned on the source task may not eliminate these biases for the\ntarget task. However, we hypothesize that the unstable features in the source\ntask and those in the target task are directly related. By explicitly informing\nthe target classifier of the source task's unstable features, we can regularize\nthe biases in the target task. Specifically, we derive a representation that\nencodes the unstable features by contrasting different data environments in the\nsource task. On the target task, we cluster data from this representation, and\nachieve robustness by minimizing the worst-case risk across all clusters. We\nevaluate our method on both text and image classifications. Empirical results\ndemonstrate that our algorithm is able to maintain robustness on the target\ntask, outperforming the best baseline by 22.9% in absolute accuracy across 12\ntransfer settings. Our code is available at https://github.com/YujiaBao/Tofu.",
          "link": "http://arxiv.org/abs/2106.07847",
          "publishedOn": "2021-06-16T01:21:07.005Z",
          "wordCount": 601,
          "title": "Learning Stable Classifiers by Transferring Unstable Features. (arXiv:2106.07847v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08298",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1\">Suraj Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brennan_J/0/1/0/all/0/1\">Joseph Brennan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nurse_J/0/1/0/all/0/1\">Jason R. C. Nurse</a>",
          "description": "We introduce StockBabble, a conversational agent designed to support\nunderstanding and engagement with the stock market. StockBabble's value and\nnovelty is in its ability to empower retail investors -- many of which may be\nnew to investing -- and supplement their informational needs using a\nuser-friendly agent. Users have the ability to query information on companies\nto retrieve a general and financial overview of a stock, including accessing\nthe latest news and trading recommendations. They can also request charts which\ncontain live prices and technical investment indicators, and add shares to a\npersonal portfolio to allow performance monitoring over time. To evaluate our\nagent's potential, we conducted a user study with 15 participants. In total,\n73% (11/15) of respondents said that they felt more confident in investing\nafter using StockBabble, and all 15 would consider recommending it to others.\nThese results are encouraging and suggest a wider appeal for such agents.\nMoreover, we believe this research can help to inform the design and\ndevelopment of future intelligent, financial personal assistants.",
          "link": "http://arxiv.org/abs/2106.08298",
          "publishedOn": "2021-06-16T01:21:06.989Z",
          "wordCount": 629,
          "title": "StockBabble: A Conversational Financial Agent to support Stock Market Investors. (arXiv:2106.08298v1 [cs.HC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07922",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhuohao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Flemotomos_N/0/1/0/all/0/1\">Nikolaos Flemotomos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singla_K/0/1/0/all/0/1\">Karan Singla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Creed_T/0/1/0/all/0/1\">Torrey A. Creed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Atkins_D/0/1/0/all/0/1\">David C. Atkins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narayanan_S/0/1/0/all/0/1\">Shrikanth Narayanan</a>",
          "description": "Computational approaches for assessing the quality of conversation-based\npsychotherapy, such as Cognitive Behavioral Therapy (CBT) and Motivational\nInterviewing (MI), have been developed recently to support quality assurance\nand clinical training. However, due to the long session lengths and limited\nmodeling resources, computational methods largely rely on frequency-based\nlexical features or distribution of dialogue acts. In this work, we propose a\nhierarchical framework to automatically evaluate the quality of a CBT\ninteraction. We divide each psychotherapy session into conversation segments\nand input those into a BERT-based model to produce segment embeddings. We first\nfine-tune BERT for predicting segment-level (local) quality scores and then use\nsegment embeddings as lower-level input to a Bidirectional LSTM-based neural\nnetwork to predict session-level (global) quality estimates. In particular, the\nsegment-level quality scores are initialized with the session-level scores and\nwe model the global quality as a function of the local quality scores to\nachieve the accurate segment-level quality estimates. These estimated\nsegment-level scores benefit theBERT fine-tuning and in learning better segment\nembeddings. We evaluate the proposed framework on data drawn from real-world\nCBT clinical session recordings to predict multiple session-level behavior\ncodes. The results indicate that our approach leads to improved evaluation\naccuracy for most codes in both regression and classification tasks.",
          "link": "http://arxiv.org/abs/2106.07922",
          "publishedOn": "2021-06-16T01:21:06.932Z",
          "wordCount": 653,
          "title": "An Automated Quality Evaluation Framework of Psychotherapy Conversations with Local Quality Estimates. (arXiv:2106.07922v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07691",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nighojkar_A/0/1/0/all/0/1\">Animesh Nighojkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Licato_J/0/1/0/all/0/1\">John Licato</a>",
          "description": "If two sentences have the same meaning, it should follow that they are\nequivalent in their inferential properties, i.e., each sentence should\ntextually entail the other. However, many paraphrase datasets currently in\nwidespread use rely on a sense of paraphrase based on word overlap and syntax.\nCan we teach them instead to identify paraphrases in a way that draws on the\ninferential properties of the sentences, and is not over-reliant on lexical and\nsyntactic similarities of a sentence pair? We apply the adversarial paradigm to\nthis question, and introduce a new adversarial method of dataset creation for\nparaphrase identification: the Adversarial Paraphrasing Task (APT), which asks\nparticipants to generate semantically equivalent (in the sense of mutually\nimplicative) but lexically and syntactically disparate paraphrases. These\nsentence pairs can then be used both to test paraphrase identification models\n(which get barely random accuracy) and then improve their performance. To\naccelerate dataset generation, we explore automation of APT using T5, and show\nthat the resulting dataset also improves accuracy. We discuss implications for\nparaphrase detection and release our dataset in the hope of making paraphrase\ndetection models better able to detect sentence-level meaning equivalence.",
          "link": "http://arxiv.org/abs/2106.07691",
          "publishedOn": "2021-06-16T01:21:06.889Z",
          "wordCount": 616,
          "title": "Improving Paraphrase Detection with the Adversarial Paraphrasing Task. (arXiv:2106.07691v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07890",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Bradley_T/0/1/0/all/0/1\">Tai-Danae Bradley</a>, <a href=\"http://arxiv.org/find/math/1/au:+Terilla_J/0/1/0/all/0/1\">John Terilla</a>, <a href=\"http://arxiv.org/find/math/1/au:+Vlassopoulos_Y/0/1/0/all/0/1\">Yiannis Vlassopoulos</a>",
          "description": "Given a piece of text, the ability to generate a coherent extension of it\nimplies some sophistication, including a knowledge of grammar and semantics. In\nthis paper, we propose a mathematical framework for passing from probability\ndistributions on extensions of given texts to an enriched category containing\nsemantic information. Roughly speaking, we model probability distributions on\ntexts as a category enriched over the unit interval. Objects of this category\nare expressions in language and hom objects are conditional probabilities that\none expression is an extension of another. This category is syntactical: it\ndescribes what goes with what. We then pass to the enriched category of unit\ninterval-valued copresheaves on this syntactical category to find semantic\ninformation.",
          "link": "http://arxiv.org/abs/2106.07890",
          "publishedOn": "2021-06-16T01:21:06.883Z",
          "wordCount": 551,
          "title": "An enriched category theory of language: from syntax to semantics. (arXiv:2106.07890v1 [math.CT])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07734",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Swaminathan_R/0/1/0/all/0/1\">Rupak Vignesh Swaminathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+King_B/0/1/0/all/0/1\">Brian King</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Strimel_G/0/1/0/all/0/1\">Grant P. Strimel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Droppo_J/0/1/0/all/0/1\">Jasha Droppo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mouchtaris_A/0/1/0/all/0/1\">Athanasios Mouchtaris</a>",
          "description": "We propose a simple yet effective method to compress an RNN-Transducer\n(RNN-T) through the well-known knowledge distillation paradigm. We show that\nthe transducer's encoder outputs naturally have a high entropy and contain rich\ninformation about acoustically similar word-piece confusions. This rich\ninformation is suppressed when combined with the lower entropy decoder outputs\nto produce the joint network logits. Consequently, we introduce an auxiliary\nloss to distill the encoder logits from a teacher transducer's encoder, and\nexplore training strategies where this encoder distillation works effectively.\nWe find that tandem training of teacher and student encoders with an inplace\nencoder distillation outperforms the use of a pre-trained and static teacher\ntransducer. We also report an interesting phenomenon we refer to as implicit\ndistillation, that occurs when the teacher and student encoders share the same\ndecoder. Our experiments show 5.37-8.4% relative word error rate reductions\n(WERR) on in-house test sets, and 5.05-6.18% relative WERRs on LibriSpeech test\nsets.",
          "link": "http://arxiv.org/abs/2106.07734",
          "publishedOn": "2021-06-16T01:21:06.826Z",
          "wordCount": 606,
          "title": "CoDERT: Distilling Encoder Representations with Co-learning for Transducer-based Speech Recognition. (arXiv:2106.07734v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07857",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_B/0/1/0/all/0/1\">Bin Sun</a> (Member, IEEE), <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shutao Li</a> (Fellow, IEEE)",
          "description": "Generating personalized responses is one of the major challenges in natural\nhuman-robot interaction. Current researches in this field mainly focus on\ngenerating responses consistent with the robot's pre-assigned persona, while\nignoring the user's persona. Such responses may be inappropriate or even\noffensive, which may lead to the bad user experience. Therefore, we propose a\nbilateral personalized dialogue generation (BPDG) method with dynamic\npersona-aware fusion via multi-task transfer learning to generate responses\nconsistent with both personas. The proposed method aims to accomplish three\nlearning tasks: 1) an encoder is trained with dialogue utterances added with\ncorresponded personalized attributes and relative position (language model\ntask), 2) a dynamic persona-aware fusion module predicts the persona presence\nto adaptively fuse the contextual and bilateral personas encodings (persona\nprediction task) and 3) a decoder generates natural, fluent and personalized\nresponses (dialogue generation task). To make the generated responses more\npersonalized and bilateral persona-consistent, the Conditional Mutual\nInformation Maximum (CMIM) criterion is adopted to select the final response\nfrom the generated candidates. The experimental results show that the proposed\nmethod outperforms several state-of-the-art methods in terms of both automatic\nand manual evaluations.",
          "link": "http://arxiv.org/abs/2106.07857",
          "publishedOn": "2021-06-16T01:21:06.797Z",
          "wordCount": 623,
          "title": "Bilateral Personalized Dialogue Generation with Dynamic Persona-Aware Fusion. (arXiv:2106.07857v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07930",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1\">Liwei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1\">Shanbo Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mingxuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>",
          "description": "Multilingual Neural Machine Translation (MNMT) has aroused widespread\ninterest due to its efficiency. An exciting advantage of MNMT models is that\nthey could also translate between unsupervised (zero-shot) language directions.\nLanguage tag (LT) strategies are often adopted to indicate the translation\ndirections in MNMT. In this paper, we demonstrate that the LTs are not only\nindicators for translation directions but also crucial to zero-shot translation\nqualities. Unfortunately, previous work tends to ignore the importance of LT\nstrategies. We demonstrate that a proper LT strategy could enhance the\nconsistency of semantic representations and alleviate the off-target issue in\nzero-shot directions. Experimental results show that by ignoring the source\nlanguage tag (SLT) and adding the target language tag (TLT) to the encoder, the\nzero-shot translations could achieve a +8 BLEU score difference over other LT\nstrategies in IWSLT17, Europarl, TED talks translation tasks.",
          "link": "http://arxiv.org/abs/2106.07930",
          "publishedOn": "2021-06-16T01:21:06.788Z",
          "wordCount": 578,
          "title": "Language Tags Matter for Zero-Shot Neural Machine Translation. (arXiv:2106.07930v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07728",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kwon_M/0/1/0/all/0/1\">Minae Kwon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karamcheti_S/0/1/0/all/0/1\">Siddharth Karamcheti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cuellar_M/0/1/0/all/0/1\">Mariano-Florentino Cuellar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sadigh_D/0/1/0/all/0/1\">Dorsa Sadigh</a>",
          "description": "Successful negotiators must learn how to balance optimizing for self-interest\nand cooperation. Yet current artificial negotiation agents often heavily depend\non the quality of the static datasets they were trained on, limiting their\ncapacity to fashion an adaptive response balancing self-interest and\ncooperation. For this reason, we find that these agents can achieve either high\nutility or cooperation, but not both. To address this, we introduce a targeted\ndata acquisition framework where we guide the exploration of a reinforcement\nlearning agent using annotations from an expert oracle. The guided exploration\nincentivizes the learning agent to go beyond its static dataset and develop new\nnegotiation strategies. We show that this enables our agents to obtain\nhigher-reward and more Pareto-optimal solutions when negotiating with both\nsimulated and human partners compared to standard supervised learning and\nreinforcement learning methods. This trend additionally holds when comparing\nagents using our targeted data acquisition framework to variants of agents\ntrained with a mix of supervised learning and reinforcement learning, or to\nagents using tailored reward functions that explicitly optimize for utility and\nPareto-optimality.",
          "link": "http://arxiv.org/abs/2106.07728",
          "publishedOn": "2021-06-16T01:21:06.781Z",
          "wordCount": 615,
          "title": "Targeted Data Acquisition for Evolving Negotiation Agents. (arXiv:2106.07728v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07935",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Imperial_J/0/1/0/all/0/1\">Joseph Marvin Imperial</a>",
          "description": "Automatic readability assessment (ARA) is the task of evaluating the level of\nease or difficulty of text documents for a target audience. For researchers,\none of the many open problems in the field is to make such models trained for\nthe task show efficacy even for low-resource languages. In this study, we\npropose an alternative way of utilizing the information-rich embeddings of BERT\nmodels through a joint-learning method combined with handcrafted linguistic\nfeatures for readability assessment. Results show that the proposed method\noutperforms classical approaches in readability assessment using English and\nFilipino datasets, and obtaining as high as 12.4% increase in F1 performance.\nWe also show that the knowledge encoded in BERT embeddings can be used as a\nsubstitute feature set for low-resource languages like Filipino with limited\nsemantic and syntactic NLP tools to explicitly extract feature values for the\ntask.",
          "link": "http://arxiv.org/abs/2106.07935",
          "publishedOn": "2021-06-16T01:21:06.744Z",
          "wordCount": 558,
          "title": "Knowledge-Rich BERT Embeddings for Readability Assessment. (arXiv:2106.07935v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07704",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1\">Han Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_B/0/1/0/all/0/1\">Bowen Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhengzhong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1\">Eric P. Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Zhiting Hu</a>",
          "description": "Maximum likelihood estimation (MLE) is the predominant algorithm for training\ntext generation models. This paradigm relies on direct supervision examples,\nwhich is not applicable to many applications, such as generating adversarial\nattacks or generating prompts to control language models. Reinforcement\nlearning (RL) on the other hand offers a more flexible solution by allowing\nusers to plug in arbitrary task metrics as reward. Yet previous RL algorithms\nfor text generation, such as policy gradient (on-policy RL) and Q-learning\n(off-policy RL), are often notoriously inefficient or unstable to train due to\nthe large sequence space and the sparse reward received only at the end of\nsequences. In this paper, we introduce a new RL formulation for text generation\nfrom the soft Q-learning perspective. It further enables us to draw from the\nlatest RL advances, such as path consistency learning, to combine the best of\non-/off-policy updates, and learn effectively from sparse reward. We apply the\napproach to a wide range of tasks, including learning from noisy/negative\nexamples, adversarial attacks, and prompt generation. Experiments show our\napproach consistently outperforms both task-specialized algorithms and the\nprevious RL methods. On standard supervised tasks where MLE prevails, our\napproach also achieves competitive performance and stability by training text\ngeneration from scratch.",
          "link": "http://arxiv.org/abs/2106.07704",
          "publishedOn": "2021-06-16T01:21:06.738Z",
          "wordCount": 641,
          "title": "Text Generation with Efficient (Soft) Q-Learning. (arXiv:2106.07704v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07794",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1\">Trang Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ostendorf_M/0/1/0/all/0/1\">Mari Ostendorf</a>",
          "description": "This work explores constituency parsing on automatically recognized\ntranscripts of conversational speech. The neural parser is based on a sentence\nencoder that leverages word vectors contextualized with prosodic features,\njointly learning prosodic feature extraction with parsing. We assess the\nutility of the prosody in parsing on imperfect transcripts, i.e. transcripts\nwith automatic speech recognition (ASR) errors, by applying the parser in an\nN-best reranking framework. In experiments on Switchboard, we obtain 13-15% of\nthe oracle N-best gain relative to parsing the 1-best ASR output, with\ninsignificant impact on word recognition error rate. Prosody provides a\nsignificant part of the gain, and analyses suggest that it leads to more\ngrammatical utterances via recovering function words.",
          "link": "http://arxiv.org/abs/2106.07794",
          "publishedOn": "2021-06-16T01:21:06.702Z",
          "wordCount": 544,
          "title": "Assessing the Use of Prosody in Constituency Parsing of Imperfect Transcripts. (arXiv:2106.07794v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07722",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1\">Jiarun Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Veen_E/0/1/0/all/0/1\">Elke M van Veen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peek_N/0/1/0/all/0/1\">Niels Peek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Renehan_A/0/1/0/all/0/1\">Andrew G Renehan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ananiadou_S/0/1/0/all/0/1\">Sophia Ananiadou</a>",
          "description": "To interpret the genetic profile present in a patient sample, it is necessary\nto know which mutations have important roles in the development of the\ncorresponding cancer type. Named entity recognition is a core step in the text\nmining pipeline which facilitates mining valuable cancer information from the\nscientific literature. However, due to the scarcity of related datasets,\nprevious NER attempts in this domain either suffer from low performance when\ndeep learning based models are deployed, or they apply feature based machine\nlearning models or rule based models to tackle this problem, which requires\nintensive efforts from domain experts, and limit the model generalization\ncapability. In this paper, we propose EPICURE, an ensemble pre trained model\nequipped with a conditional random field pattern layer and a span prediction\npattern layer to extract cancer mutations from text. We also adopt a data\naugmentation strategy to expand our training set from multiple datasets.\nExperimental results on three benchmark datasets show competitive results\ncompared to the baseline models.",
          "link": "http://arxiv.org/abs/2106.07722",
          "publishedOn": "2021-06-16T01:21:06.615Z",
          "wordCount": 602,
          "title": "EPICURE Ensemble Pretrained Models for Extracting Cancer Mutations from Literature. (arXiv:2106.07722v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07716",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chak-Fai Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keith_F/0/1/0/all/0/1\">Francis Keith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hartmann_W/0/1/0/all/0/1\">William Hartmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Snover_M/0/1/0/all/0/1\">Matthew Snover</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kimball_O/0/1/0/all/0/1\">Owen Kimball</a>",
          "description": "Sequence-to-sequence (seq2seq) models are competitive with hybrid models for\nautomatic speech recognition (ASR) tasks when large amounts of training data\nare available. However, data sparsity and domain adaptation are more\nproblematic for seq2seq models than their hybrid counterparts. We examine\ncorpora of five languages from the IARPA MATERIAL program where the transcribed\ndata is conversational telephone speech (CTS) and evaluation data is broadcast\nnews (BN). We show that there is a sizable initial gap in such a data condition\nbetween hybrid and seq2seq models, and the hybrid model is able to further\nimprove through the use of additional language model (LM) data. We use an\nadditional set of untranscribed data primarily in the BN domain for\nsemisupervised training. In semisupervised training, a seed model trained on\ntranscribed data generates hypothesized transcripts for unlabeled\ndomain-matched data for further training. By using a hybrid model with an\nexpanded language model for pseudotranscription, we are able to improve our\nseq2seq model from an average word error rate (WER) of 66.7% across all five\nlanguages to 29.0% WER. While this puts the seq2seq model at a competitive\noperating point, hybrid models are still able to use additional LM data to\nmaintain an advantage.",
          "link": "http://arxiv.org/abs/2106.07716",
          "publishedOn": "2021-06-16T01:21:06.609Z",
          "wordCount": 650,
          "title": "Overcoming Domain Mismatch in Low Resource Sequence-to-Sequence ASR Models using Hybrid Generated Pseudotranscripts. (arXiv:2106.07716v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2101.06983",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1\">Luyu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yunyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Callan_J/0/1/0/all/0/1\">Jamie Callan</a>",
          "description": "Contrastive learning has been applied successfully to learn vector\nrepresentations of text. Previous research demonstrated that learning\nhigh-quality representations benefits from batch-wise contrastive loss with a\nlarge number of negatives. In practice, the technique of in-batch negative is\nused, where for each example in a batch, other batch examples' positives will\nbe taken as its negatives, avoiding encoding extra negatives. This, however,\nstill conditions each example's loss on all batch examples and requires fitting\nthe entire large batch into GPU memory. This paper introduces a gradient\ncaching technique that decouples backpropagation between contrastive loss and\nthe encoder, removing encoder backward pass data dependency along the batch\ndimension. As a result, gradients can be computed for one subset of the batch\nat a time, leading to almost constant memory usage.",
          "link": "http://arxiv.org/abs/2101.06983",
          "publishedOn": "2021-06-16T00:27:38.461Z",
          "wordCount": 593,
          "title": "Scaling Deep Contrastive Learning Batch Size under Memory Limited Setup. (arXiv:2101.06983v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04563",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_S/0/1/0/all/0/1\">Subhabrata Mukherjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awadallah_A/0/1/0/all/0/1\">Ahmed Hassan Awadallah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>",
          "description": "While deep and large pre-trained models are the state-of-the-art for various\nnatural language processing tasks, their huge size poses significant challenges\nfor practical uses in resource constrained settings. Recent works in knowledge\ndistillation propose task-agnostic as well as task-specific methods to compress\nthese models, with task-specific ones often yielding higher compression rate.\nIn this work, we develop a new task-agnostic distillation framework\nXtremeDistilTransformers that leverages the advantage of task-specific methods\nfor learning a small universal model that can be applied to arbitrary tasks and\nlanguages. To this end, we study the transferability of several source tasks,\naugmentation resources and model architecture for distillation. We evaluate our\nmodel performance on multiple tasks, including the General Language\nUnderstanding Evaluation (GLUE) benchmark, SQuAD question answering dataset and\na massive multi-lingual NER dataset with 41 languages. We release three\ndistilled task-agnostic checkpoints with 13MM, 22MM and 33MM parameters\nobtaining SOTA performance in several tasks.",
          "link": "http://arxiv.org/abs/2106.04563",
          "publishedOn": "2021-06-15T22:41:24.981Z",
          "wordCount": 604,
          "title": "XtremeDistilTransformers: Task Transfer for Task-agnostic Distillation. (arXiv:2106.04563v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04102",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1\">Mina Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Donahue_C/0/1/0/all/0/1\">Chris Donahue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1\">Robin Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iyabor_A/0/1/0/all/0/1\">Alexander Iyabor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1\">Percy Liang</a>",
          "description": "We release a new benchmark for lexical substitution, the task of finding\nappropriate substitutes for a target word in a context. To assist humans with\nwriting, lexical substitution systems can suggest words that humans cannot\neasily think of. However, existing benchmarks depend on human recall as the\nonly source of data, and therefore lack coverage of the substitutes that would\nbe most helpful to humans. Furthermore, annotators often provide substitutes of\nlow quality, which are not actually appropriate in the given context. We\ncollect higher-coverage and higher-quality data by framing lexical substitution\nas a classification problem, guided by the intuition that it is easier for\nhumans to judge the appropriateness of candidate substitutes than conjure them\nfrom memory. To this end, we use a context-free thesaurus to produce candidates\nand rely on human judgement to determine contextual appropriateness. Compared\nto the previous largest benchmark, our Swords benchmark has 4.1x more\nsubstitutes per target word for the same level of quality, and its substitutes\nare 1.5x more appropriate (based on human judgement) for the same number of\nsubstitutes.",
          "link": "http://arxiv.org/abs/2106.04102",
          "publishedOn": "2021-06-15T22:41:24.969Z",
          "wordCount": 638,
          "title": "Swords: A Benchmark for Lexical Substitution with Improved Data Coverage and Quality. (arXiv:2106.04102v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04476",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Damonte_M/0/1/0/all/0/1\">Marco Damonte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monti_E/0/1/0/all/0/1\">Emilio Monti</a>",
          "description": "Semantic parsers map natural language utterances to meaning representations.\nThe lack of a single standard for meaning representations led to the creation\nof a plethora of semantic parsing datasets. To unify different datasets and\ntrain a single model for them, we investigate the use of Multi-Task Learning\n(MTL) architectures. We experiment with five datasets (Geoquery, NLMaps, TOP,\nOvernight, AMR). We find that an MTL architecture that shares the entire\nnetwork across datasets yields competitive or better parsing accuracies than\nthe single-task baselines, while reducing the total number of parameters by\n68%. We further provide evidence that MTL has also better compositional\ngeneralization than single-task models. We also present a comparison of task\nsampling methods and propose a competitive alternative to widespread\nproportional sampling strategies.",
          "link": "http://arxiv.org/abs/2106.04476",
          "publishedOn": "2021-06-15T22:41:24.890Z",
          "wordCount": 592,
          "title": "One Semantic Parser to Parse Them All: Sequence to Sequence Multi-Task Learning on Semantic Parsing Datasets. (arXiv:2106.04476v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.01408",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1\">Rui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sisman_B/0/1/0/all/0/1\">Berrak Sisman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haizhou Li</a>",
          "description": "Emotional text-to-speech synthesis (ETTS) has seen much progress in recent\nyears. However, the generated voice is often not perceptually identifiable by\nits intended emotion category. To address this problem, we propose a new\ninteractive training paradigm for ETTS, denoted as i-ETTS, which seeks to\ndirectly improve the emotion discriminability by interacting with a speech\nemotion recognition (SER) model. Moreover, we formulate an iterative training\nstrategy with reinforcement learning to ensure the quality of i-ETTS\noptimization. Experimental results demonstrate that the proposed i-ETTS\noutperforms the state-of-the-art baselines by rendering speech with more\naccurate emotion style. To our best knowledge, this is the first study of\nreinforcement learning in emotional text-to-speech synthesis.",
          "link": "http://arxiv.org/abs/2104.01408",
          "publishedOn": "2021-06-15T01:45:21.295Z",
          "wordCount": 582,
          "title": "Reinforcement Learning for Emotional Text-to-Speech Synthesis with Improved Emotion Discriminability. (arXiv:2104.01408v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.04779",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1\">Yu Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiusheng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_W/0/1/0/all/0/1\">Weizhen Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhendawade_N/0/1/0/all/0/1\">Nikhil Bhendawade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1\">Yeyun Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1\">Nan Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ruofei Zhang</a>",
          "description": "Transformer model with multi-head attention requires caching intermediate\nresults for efficient inference in generation tasks. However, cache brings new\nmemory-related costs and prevents leveraging larger batch size for faster\nspeed. We propose memory-efficient lossless attention (called EL-attention) to\naddress this issue. It avoids heavy operations for building multi-head keys and\nvalues, cache for them is not needed. EL-attention constructs an ensemble of\nattention results by expanding query while keeping key and value shared. It\nproduces the same result as multi-head attention with less GPU memory and\nfaster inference speed. We conduct extensive experiments on Transformer, BART,\nand GPT-2 for summarization and question generation tasks. The results show\nEL-attention speeds up existing models by 1.6x to 5.3x without accuracy loss.",
          "link": "http://arxiv.org/abs/2105.04779",
          "publishedOn": "2021-06-15T01:45:21.283Z",
          "wordCount": 589,
          "title": "EL-Attention: Memory Efficient Lossless Attention for Generation. (arXiv:2105.04779v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.01797",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qin_P/0/1/0/all/0/1\">Pengda Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuhong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_K/0/1/0/all/0/1\">Kefeng Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qiang Wu</a>",
          "description": "Among ubiquitous multimodal data in the real world, text is the modality\ngenerated by human, while image reflects the physical world honestly. In a\nvisual understanding application, machines are expected to understand images\nlike human. Inspired by this, we propose a novel self-supervised learning\nmethod, named Text-enhanced Visual Deep InfoMax (TVDIM), to learn better visual\nrepresentations by fully utilizing the naturally-existing multimodal data. Our\ncore idea of self-supervised learning is to maximize the mutual information\nbetween features extracted from multiple views of a shared context to a\nrational degree. Different from previous methods which only consider multiple\nviews from a single modality, our work produces multiple views from different\nmodalities, and jointly optimizes the mutual information for features pairs of\nintra-modality and inter-modality. Considering the information gap between\ninter-modality features pairs from data noise, we adopt a \\emph{ranking-based}\ncontrastive learning to optimize the mutual information. During evaluation, we\ndirectly use the pre-trained visual representations to complete various image\nclassification tasks. Experimental results show that, TVDIM significantly\noutperforms previous visual self-supervised methods when processing the same\nset of images.",
          "link": "http://arxiv.org/abs/2106.01797",
          "publishedOn": "2021-06-15T01:45:20.243Z",
          "wordCount": 623,
          "title": "TVDIM: Enhancing Image Self-Supervised Pretraining via Noisy Text Data. (arXiv:2106.01797v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.03743",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_J/0/1/0/all/0/1\">Jiehang Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1\">Xiaoqing Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jianhan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Linyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1\">Liping Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuanjing Huang</a>",
          "description": "Recently, few certified defense methods have been developed to provably\nguarantee the robustness of a text classifier to adversarial synonym\nsubstitutions. However, all existing certified defense methods assume that the\ndefenders are informed of how the adversaries generate synonyms, which is not a\nrealistic scenario. In this paper, we propose a certifiably robust defense\nmethod by randomly masking a certain proportion of the words in an input text,\nin which the above unrealistic assumption is no longer necessary. The proposed\nmethod can defend against not only word substitution-based attacks, but also\ncharacter-level perturbations. We can certify the classifications of over 50%\ntexts to be robust to any perturbation of 5 words on AGNEWS, and 2 words on\nSST2 dataset. The experimental results show that our randomized smoothing\nmethod significantly outperforms recently proposed defense methods across\nmultiple datasets.",
          "link": "http://arxiv.org/abs/2105.03743",
          "publishedOn": "2021-06-15T01:45:20.192Z",
          "wordCount": 596,
          "title": "Certified Robustness to Text Adversarial Attacks by Randomized [MASK]. (arXiv:2105.03743v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.11387",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Boateng_G/0/1/0/all/0/1\">George Boateng</a>",
          "description": "Introductory hands-on courses such as our smartphone-based coding course,\nSuaCode require a lot of support for students to accomplish learning goals.\nOnline environments make it even more difficult to get assistance especially\nmore recently because of COVID-19. Given the multilingual context of SuaCode\nstudents - learners across 42 African countries that are mostly Anglophone or\nFrancophone - in this work, we developed a bilingual Artificial Intelligence\n(AI) Teaching Assistant (TA) - Kwame - that provides answers to students'\ncoding questions from SuaCode courses in English and French. Kwame is a\nSentence-BERT (SBERT)-based question-answering (QA) system that we trained and\nevaluated offline using question-answer pairs created from the course's\nquizzes, lesson notes and students' questions in past cohorts. Kwame finds the\nparagraph most semantically similar to the question via cosine similarity. We\ncompared the system with TF-IDF and Universal Sentence Encoder. Our results\nshowed that fine-tuning on the course data and returning the top 3 and 5\nanswers improved the accuracy results. Kwame will make it easy for students to\nget quick and accurate answers to questions in SuaCode courses.",
          "link": "http://arxiv.org/abs/2010.11387",
          "publishedOn": "2021-06-15T01:45:19.615Z",
          "wordCount": null,
          "title": "Kwame: A Bilingual AI Teaching Assistant for Online SuaCode Courses. (arXiv:2010.11387v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.13856",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mao_Z/0/1/0/all/0/1\">Zhuoyuan Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_P/0/1/0/all/0/1\">Prakhar Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chu_C/0/1/0/all/0/1\">Chenhui Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaggi_M/0/1/0/all/0/1\">Martin Jaggi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurohashi_S/0/1/0/all/0/1\">Sadao Kurohashi</a>",
          "description": "Large-scale models for learning fixed-dimensional cross-lingual sentence\nrepresentations like LASER (Artetxe and Schwenk, 2019b) lead to significant\nimprovement in performance on downstream tasks. However, further increases and\nmodifications based on such large-scale models are usually impractical due to\nmemory limitations. In this work, we introduce a lightweight dual-transformer\narchitecture with just 2 layers for generating memory-efficient cross-lingual\nsentence representations. We explore different training tasks and observe that\ncurrent cross-lingual training tasks leave a lot to be desired for this shallow\narchitecture. To ameliorate this, we propose a novel cross-lingual language\nmodel, which combines the existing single-word masked language model with the\nnewly proposed cross-lingual token-level reconstruction task. We further\naugment the training task by the introduction of two computationally-lite\nsentence-level contrastive learning tasks to enhance the alignment of\ncross-lingual sentence representation space, which compensates for the learning\nbottleneck of the lightweight transformer for generative tasks. Our comparisons\nwith competing models on cross-lingual sentence retrieval and multilingual\ndocument classification confirm the effectiveness of the newly proposed\ntraining tasks for a shallow model.",
          "link": "http://arxiv.org/abs/2105.13856",
          "publishedOn": "2021-06-15T01:45:19.596Z",
          "wordCount": null,
          "title": "Lightweight Cross-Lingual Sentence Representation Learning. (arXiv:2105.13856v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.07639",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_H/0/1/0/all/0/1\">Hongyu Gong</a>",
          "description": "Multilingual models are parameter-efficient with the prospect improving\nlow-resource languages by leveraging crosslingual transfer. Despite recent\nadvance in massive multilingual translation with ever-growing model and data,\nhow to effectively train multilingual models has not been well understood. In\nthis paper, we show that a common situation in multilingual training, data\nimbalance among languages, poses optimization tension between high resource and\nlow resource languages where the found multilingual solution is often\nsub-optimal for low resources. We show that common training method which\nupsamples low resources can not robustly optimize population loss with risks of\neither underfitting high resource languages or overfitting low resource ones.\nDrawing on recent findings on the geometry of loss landscape and its effect on\ngeneralization, we propose a principled optimization algorithm, Curvature Aware\nTask Scaling (CATS), which adaptively rescales gradients from different tasks\nwith a meta objective of guiding multilingual training to low-curvature\nneighborhoods with uniformly low loss for all languages. We ran experiments on\ncommon benchmarks (TED, WMT and OPUS-100) with varying degrees of data\nimbalance. CATS effectively improved multilingual optimization and as a result\ndemonstrated consistent gains on low resources ( to BLEU) without hurting high\nresources. In addition, CATS is robust to overparameterization and large batch\nsize training, making it a promising training method for massive multilingual\nmodels that truly improve low resource languages.",
          "link": "http://arxiv.org/abs/2104.07639",
          "publishedOn": "2021-06-15T01:45:19.347Z",
          "wordCount": 685,
          "title": "Robust Optimization for Multilingual Translation with Imbalanced Data. (arXiv:2104.07639v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.00148",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1\">Haoyue Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1\">Luke Zettlemoyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Sida I. Wang</a>",
          "description": "Bilingual lexicons map words in one language to their translations in\nanother, and are typically induced by learning linear projections to align\nmonolingual word embedding spaces. In this paper, we show it is possible to\nproduce much higher quality lexicons with methods that combine (1) unsupervised\nbitext mining and (2) unsupervised word alignment. Directly applying a pipeline\nthat uses recent algorithms for both subproblems significantly improves induced\nlexicon quality and further gains are possible by learning to filter the\nresulting lexical entries, with both unsupervised and semi-supervised schemes.\nOur final model outperforms the state of the art on the BUCC 2020 shared task\nby 14 $F_1$ points averaged over 12 language pairs, while also providing a more\ninterpretable approach that allows for rich reasoning of word meaning in\ncontext. Further analysis of our output and the standard reference lexicons\nsuggests they are of comparable quality, and new benchmarks may be needed to\nmeasure further progress on this task.",
          "link": "http://arxiv.org/abs/2101.00148",
          "publishedOn": "2021-06-15T01:45:19.323Z",
          "wordCount": 625,
          "title": "Bilingual Lexicon Induction via Unsupervised Bitext Construction and Word Alignment. (arXiv:2101.00148v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.15082",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_A/0/1/0/all/0/1\">An Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Junyang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Men_R/0/1/0/all/0/1\">Rui Men</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Chang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1\">Le Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_X/0/1/0/all/0/1\">Xianyan Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_A/0/1/0/all/0/1\">Ang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jie Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiamang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Di Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1\">Wei Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_L/0/1/0/all/0/1\">Lin Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jingren Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hongxia Yang</a>",
          "description": "Mixture-of-Experts (MoE) models can achieve promising results with outrageous\nlarge amount of parameters but constant computation cost, and thus it has\nbecome a trend in model scaling. Still it is a mystery how MoE layers bring\nquality gains by leveraging the parameters with sparse activation. In this\nwork, we investigate several key factors in sparse expert models. We observe\nthat load imbalance may not be a significant problem affecting model quality,\ncontrary to the perspectives of recent studies, while the number of sparsely\nactivated experts $k$ and expert capacity $C$ in top-$k$ routing can\nsignificantly make a difference in this context. Furthermore, we take a step\nforward to propose a simple method called expert prototyping that splits\nexperts into different prototypes and applies $k$ top-$1$ routing. This\nstrategy improves the model quality but maintains constant computational costs,\nand our further exploration on extremely large-scale models reflects that it is\nmore effective in training larger models. We push the model scale to over $1$\ntrillion parameters and implement it on solely $480$ NVIDIA V100-32GB GPUs, in\ncomparison with the recent SOTAs on $2048$ TPU cores. The proposed giant model\nachieves substantial speedup in convergence over the same-size baseline.",
          "link": "http://arxiv.org/abs/2105.15082",
          "publishedOn": "2021-06-15T01:45:18.811Z",
          "wordCount": 674,
          "title": "Exploring Sparse Expert Models and Beyond. (arXiv:2105.15082v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.07003",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1\">Gyuwan Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1\">Kyunghyun Cho</a>",
          "description": "Despite transformers' impressive accuracy, their computational cost is often\nprohibitive to use with limited computational resources. Most previous\napproaches to improve inference efficiency require a separate model for each\npossible computational budget. In this paper, we extend PoWER-BERT (Goyal et\nal., 2020) and propose Length-Adaptive Transformer that can be used for various\ninference scenarios after one-shot training. We train a transformer with\nLengthDrop, a structural variant of dropout, which stochastically determines a\nsequence length at each layer. We then conduct a multi-objective evolutionary\nsearch to find a length configuration that maximizes the accuracy and minimizes\nthe efficiency metric under any given computational budget. Additionally, we\nsignificantly extend the applicability of PoWER-BERT beyond sequence-level\nclassification into token-level classification with Drop-and-Restore process\nthat drops word-vectors temporarily in intermediate layers and restores at the\nlast layer if necessary. We empirically verify the utility of the proposed\napproach by demonstrating the superior accuracy-efficiency trade-off under\nvarious setups, including span-based question answering and text\nclassification. Code is available at\nhttps://github.com/clovaai/length-adaptive-transformer.",
          "link": "http://arxiv.org/abs/2010.07003",
          "publishedOn": "2021-06-15T01:45:18.309Z",
          "wordCount": 633,
          "title": "Length-Adaptive Transformer: Train Once with Length Drop, Use Anytime with Search. (arXiv:2010.07003v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.02194",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Le_D/0/1/0/all/0/1\">Duc Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_M/0/1/0/all/0/1\">Mahaveer Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keren_G/0/1/0/all/0/1\">Gil Keren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Suyoun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yangyang Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahadeokar_J/0/1/0/all/0/1\">Jay Mahadeokar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_J/0/1/0/all/0/1\">Julian Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shangguan_Y/0/1/0/all/0/1\">Yuan Shangguan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fuegen_C/0/1/0/all/0/1\">Christian Fuegen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalinli_O/0/1/0/all/0/1\">Ozlem Kalinli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saraf_Y/0/1/0/all/0/1\">Yatharth Saraf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seltzer_M/0/1/0/all/0/1\">Michael L. Seltzer</a>",
          "description": "How to leverage dynamic contextual information in end-to-end speech\nrecognition has remained an active research area. Previous solutions to this\nproblem were either designed for specialized use cases that did not generalize\nwell to open-domain scenarios, did not scale to large biasing lists, or\nunderperformed on rare long-tail words. We address these limitations by\nproposing a novel solution that combines shallow fusion, trie-based deep\nbiasing, and neural network language model contextualization. These techniques\nresult in significant 19.5% relative Word Error Rate improvement over existing\ncontextual biasing approaches and 5.4%-9.3% improvement compared to a strong\nhybrid baseline on both open-domain and constrained contextualization tasks,\nwhere the targets consist of mostly rare long-tail words. Our final system\nremains lightweight and modular, allowing for quick modification without model\nre-training.",
          "link": "http://arxiv.org/abs/2104.02194",
          "publishedOn": "2021-06-15T01:45:17.513Z",
          "wordCount": 626,
          "title": "Contextualized Streaming End-to-End Speech Recognition with Trie-Based Deep Biasing and Shallow Fusion. (arXiv:2104.02194v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.13878",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaonan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_Y/0/1/0/all/0/1\">Yunfan Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_T/0/1/0/all/0/1\">Tianxiang Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_H/0/1/0/all/0/1\">Hang Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1\">Xipeng Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuanjing Huang</a>",
          "description": "Both performance and efficiency are crucial factors for sequence labeling\ntasks in many real-world scenarios. Although the pre-trained models (PTMs) have\nsignificantly improved the performance of various sequence labeling tasks,\ntheir computational cost is expensive. To alleviate this problem, we extend the\nrecent successful early-exit mechanism to accelerate the inference of PTMs for\nsequence labeling tasks. However, existing early-exit mechanisms are\nspecifically designed for sequence-level tasks, rather than sequence labeling.\nIn this paper, we first propose a simple extension of sentence-level early-exit\nfor sequence labeling tasks. To further reduce the computational cost, we also\npropose a token-level early-exit mechanism that allows partial tokens to exit\nearly at different layers. Considering the local dependency inherent in\nsequence labeling, we employed a window-based criterion to decide for a token\nwhether or not to exit. The token-level early-exit brings the gap between\ntraining and inference, so we introduce an extra self-sampling fine-tuning\nstage to alleviate it. The extensive experiments on three popular sequence\nlabeling tasks show that our approach can save up to 66%-75% inference cost\nwith minimal performance degradation. Compared with competitive compressed\nmodels such as DistilBERT, our approach can achieve better performance under\nthe same speed-up ratios of 2X, 3X, and 4X.",
          "link": "http://arxiv.org/abs/2105.13878",
          "publishedOn": "2021-06-15T01:45:17.117Z",
          "wordCount": 671,
          "title": "Accelerating BERT Inference for Sequence Labeling via Early-Exit. (arXiv:2105.13878v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.13648",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1\">Yu Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yang Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Heyan Huang</a>",
          "description": "Parallel cross-lingual summarization data is scarce, requiring models to\nbetter use the limited available cross-lingual resources. Existing methods to\ndo so often adopt sequence-to-sequence networks with multi-task frameworks.\nSuch approaches apply multiple decoders, each of which is utilized for a\nspecific task. However, these independent decoders share no parameters, hence\nfail to capture the relationships between the discrete phrases of summaries in\ndifferent languages, breaking the connections in order to transfer the\nknowledge of the high-resource languages to low-resource languages. To bridge\nthese connections, we propose a novel Multi-Task framework for Cross-Lingual\nAbstractive Summarization (MCLAS) in a low-resource setting. Employing one\nunified decoder to generate the sequential concatenation of monolingual and\ncross-lingual summaries, MCLAS makes the monolingual summarization task a\nprerequisite of the cross-lingual summarization (CLS) task. In this way, the\nshared decoder learns interactions involving alignments and summary patterns\nacross languages, which encourages attaining knowledge transfer. Experiments on\ntwo CLS datasets demonstrate that our model significantly outperforms three\nbaseline models in both low-resource and full-dataset scenarios. Moreover,\nin-depth analysis on the generated summaries and attention heads verifies that\ninteractions are learned well using MCLAS, which benefits the CLS task under\nlimited parallel resources.",
          "link": "http://arxiv.org/abs/2105.13648",
          "publishedOn": "2021-06-15T01:45:16.554Z",
          "wordCount": 658,
          "title": "Cross-Lingual Abstractive Summarization with Limited Parallel Resources. (arXiv:2105.13648v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.04941",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ou_J/0/1/0/all/0/1\">Jiefu Ou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weir_N/0/1/0/all/0/1\">Nathaniel Weir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belyy_A/0/1/0/all/0/1\">Anton Belyy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1\">Felix Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durme_B/0/1/0/all/0/1\">Benjamin Van Durme</a>",
          "description": "We propose a structured extension to bidirectional-context conditional\nlanguage generation, or \"infilling,\" inspired by Frame Semantic theory\n(Fillmore, 1976). Guidance is provided through two approaches: (1) model\nfine-tuning, conditioning directly on observed symbolic frames, and (2) a novel\nextension to disjunctive lexically constrained decoding that leverages frame\nsemantic lexical units. Automatic and human evaluations confirm that\nframe-guided generation allows for explicit manipulation of intended infill\nsemantics, with minimal loss in distinguishability from human-generated text.\nOur methods flexibly apply to a variety of use scenarios, and we provide a\ncodebase and interactive demo available from\nhttps://nlp.jhu.edu/demos/infillmore.",
          "link": "http://arxiv.org/abs/2103.04941",
          "publishedOn": "2021-06-15T01:45:16.461Z",
          "wordCount": 558,
          "title": "InFillmore: Frame-Guided Language Generation with Bidirectional Context. (arXiv:2103.04941v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06965",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fenglin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_C/0/1/0/all/0/1\">Changchang Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_S/0/1/0/all/0/1\">Shen Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Ping Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xu Sun</a>",
          "description": "Recently, chest X-ray report generation, which aims to automatically generate\ndescriptions of given chest X-ray images, has received growing research\ninterests. The key challenge of chest X-ray report generation is to accurately\ncapture and describe the abnormal regions. In most cases, the normal regions\ndominate the entire chest X-ray image, and the corresponding descriptions of\nthese normal regions dominate the final report. Due to such data bias,\nlearning-based models may fail to attend to abnormal regions. In this work, to\neffectively capture and describe abnormal regions, we propose the Contrastive\nAttention (CA) model. Instead of solely focusing on the current input image,\nthe CA model compares the current input image with normal images to distill the\ncontrastive information. The acquired contrastive information can better\nrepresent the visual features of abnormal regions. According to the experiments\non the public IU-X-ray and MIMIC-CXR datasets, incorporating our CA into\nseveral existing models can boost their performance across most metrics. In\naddition, according to the analysis, the CA model can help existing models\nbetter attend to the abnormal regions and provide more accurate descriptions\nwhich are crucial for an interpretable diagnosis. Specifically, we achieve the\nstate-of-the-art results on the two public datasets.",
          "link": "http://arxiv.org/abs/2106.06965",
          "publishedOn": "2021-06-15T01:45:16.418Z",
          "wordCount": 669,
          "title": "Contrastive Attention for Automatic Chest X-ray Report Generation. (arXiv:2106.06965v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2102.02959",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+DAnniballe_V/0/1/0/all/0/1\">Vincent M. D&#x27;Anniballe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tushar_F/0/1/0/all/0/1\">Fakrul I. Tushar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faryna_K/0/1/0/all/0/1\">Khrystyna Faryna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Songyue Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mazurowski_M/0/1/0/all/0/1\">Maciej A. Mazurowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubin_G/0/1/0/all/0/1\">Geoffrey D. Rubin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lo_J/0/1/0/all/0/1\">Joseph Y. Lo</a>",
          "description": "Purpose: To develop high throughput multi-label annotators for body (chest,\nabdomen, and pelvis) Computed Tomography (CT) reports that can be applied\nacross a variety of abnormalities, organs, and disease states.\n\nApproach: We used a dictionary approach to develop rule-based algorithms\n(RBA) for extraction of disease labels from radiology text reports. We targeted\nthree organ systems (lungs/pleura, liver/gallbladder, kidneys/ureters) with\nfour diseases per system based on their prevalence in our dataset. To expand\nthe algorithms beyond pre-defined keywords, attention-guided recurrent neural\nnetworks (RNN) were trained using the RBA-extracted labels to classify reports\nas being positive for one or more diseases or normal for each organ system.\nConfounding effects on model performance were evaluated using random\ninitialization or pre-trained embedding as well as different sizes of training\ndatasets. Performance was evaluated using the receiver operating characteristic\n(ROC) area under the curve (AUC) against 2,158 manually obtained labels.\n\nResults: Our models extracted disease labels from 261,229 radiology reports\nof 112,501 unique subjects. Pre-trained models outperformed random\ninitialization across all diseases. As the training dataset size was reduced,\nperformance was robust except for a few diseases with relatively small number\nof cases. Pre-trained classification AUCs achieved > 0.95 for all five disease\noutcomes across all three organ systems.\n\nConclusions: Our label-extracting pipeline was able to encompass a variety of\ncases and diseases by generalizing beyond strict rules with exceptional\naccuracy. This method can be easily adapted to enable automated labeling of\nhospital-scale medical data sets for training image-based disease classifiers.",
          "link": "http://arxiv.org/abs/2102.02959",
          "publishedOn": "2021-06-15T01:45:15.907Z",
          "wordCount": 748,
          "title": "Multi-Label Annotation of Chest Abdomen Pelvis Computed Tomography Text Reports Using Deep Learning. (arXiv:2102.02959v4 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06811",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pritom_M/0/1/0/all/0/1\">Mir Mehedi A. Pritom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_R/0/1/0/all/0/1\">Rosana Montanez Rodriguez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1\">Asad Ali Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nugroho_S/0/1/0/all/0/1\">Sebastian A. Nugroho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alrashydah_E/0/1/0/all/0/1\">Esra&#x27;a Alrashydah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruiz_B/0/1/0/all/0/1\">Beatrice N. Ruiz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rios_A/0/1/0/all/0/1\">Anthony Rios</a>",
          "description": "COVID-19 pandemic has generated what public health officials called an\ninfodemic of misinformation. As social distancing and stay-at-home orders came\ninto effect, many turned to social media for socializing. This increase in\nsocial media usage has made it a prime vehicle for the spreading of\nmisinformation. This paper presents a mechanism to detect COVID-19\nhealth-related misinformation in social media following an interdisciplinary\napproach. Leveraging social psychology as a foundation and existing\nmisinformation frameworks, we defined misinformation themes and associated\nkeywords incorporated into the misinformation detection mechanism using applied\nmachine learning techniques. Next, using the Twitter dataset, we explored the\nperformance of the proposed methodology using multiple state-of-the-art machine\nlearning classifiers. Our method shows promising results with at most 78%\naccuracy in classifying health-related misinformation versus true information\nusing uni-gram-based NLP feature generations from tweets and the Decision Tree\nclassifier. We also provide suggestions on alternatives for countering\nmisinformation and ethical consideration for the study.",
          "link": "http://arxiv.org/abs/2106.06811",
          "publishedOn": "2021-06-15T01:45:15.849Z",
          "wordCount": 656,
          "title": "Case Study on Detecting COVID-19 Health-Related Misinformation in Social Media. (arXiv:2106.06811v1 [cs.SI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06823",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Paranjape_B/0/1/0/all/0/1\">Bhargavi Paranjape</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Michael_J/0/1/0/all/0/1\">Julian Michael</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghazvininejad_M/0/1/0/all/0/1\">Marjan Ghazvininejad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1\">Luke Zettlemoyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1\">Hannaneh Hajishirzi</a>",
          "description": "Many commonsense reasoning NLP tasks involve choosing between one or more\npossible answers to a question or prompt based on knowledge that is often\nimplicit. Large pretrained language models (PLMs) can achieve near-human\nperformance on such tasks, while providing little human-interpretable evidence\nof the underlying reasoning they use. In this work, we show how to use these\nsame models to generate such evidence: inspired by the contrastive nature of\nhuman explanations, we use PLMs to complete explanation prompts which contrast\nalternatives according to the key attribute(s) required to justify the correct\nanswer (for example, peanuts are usually salty while raisins are sweet).\nConditioning model decisions on these explanations improves performance on two\ncommonsense reasoning benchmarks, as compared to previous non-contrastive\nalternatives. These explanations are also judged by humans to be more relevant\nfor solving the task, and facilitate a novel method to evaluate explanation\nfaithfulfness.",
          "link": "http://arxiv.org/abs/2106.06823",
          "publishedOn": "2021-06-15T01:45:15.842Z",
          "wordCount": 579,
          "title": "Prompting Contrastive Explanations for Commonsense Reasoning Tasks. (arXiv:2106.06823v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2101.06561",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khashabi_D/0/1/0/all/0/1\">Daniel Khashabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stanovsky_G/0/1/0/all/0/1\">Gabriel Stanovsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bragg_J/0/1/0/all/0/1\">Jonathan Bragg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lourie_N/0/1/0/all/0/1\">Nicholas Lourie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kasai_J/0/1/0/all/0/1\">Jungo Kasai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1\">Noah A. Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weld_D/0/1/0/all/0/1\">Daniel S. Weld</a>",
          "description": "Leaderboards have eased model development for many NLP datasets by\nstandardizing their evaluation and delegating it to an independent external\nrepository. Their adoption, however, is so far limited to tasks that can be\nreliably evaluated in an automatic manner. This work introduces GENIE, an\nextensible human evaluation leaderboard, which brings the ease of leaderboards\nto text generation tasks. GENIE automatically posts leaderboard submissions to\ncrowdsourcing platforms asking human annotators to evaluate them on various\naxes (e.g., correctness, conciseness, fluency) and compares their answers to\nvarious automatic metrics. We introduce several datasets in English to GENIE,\nrepresenting four core challenges in text generation: machine translation,\nsummarization, commonsense reasoning, and machine comprehension. We provide\nformal granular evaluation metrics and identify areas for future research. We\nmake GENIE publicly available and hope that it will spur progress in language\ngeneration models as well as their automatic and manual evaluation.",
          "link": "http://arxiv.org/abs/2101.06561",
          "publishedOn": "2021-06-15T01:45:15.806Z",
          "wordCount": 620,
          "title": "GENIE: A Leaderboard for Human-in-the-Loop Evaluation of Text Generation. (arXiv:2101.06561v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06751",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yang Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_S/0/1/0/all/0/1\">Shuhao Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_D/0/1/0/all/0/1\">Dengji Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhengxin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_C/0/1/0/all/0/1\">Chenze Shao</a>",
          "description": "Although teacher forcing has become the main training paradigm for neural\nmachine translation, it usually makes predictions only conditioned on past\ninformation, and hence lacks global planning for the future. To address this\nproblem, we introduce another decoder, called seer decoder, into the\nencoder-decoder framework during training, which involves future information in\ntarget predictions. Meanwhile, we force the conventional decoder to simulate\nthe behaviors of the seer decoder via knowledge distillation. In this way, at\ntest the conventional decoder can perform like the seer decoder without the\nattendance of it. Experiment results on the Chinese-English, English-German and\nEnglish-Romanian translation tasks show our method can outperform competitive\nbaselines significantly and achieves greater improvements on the bigger data\nsets. Besides, the experiments also prove knowledge distillation the best way\nto transfer knowledge from the seer decoder to the conventional decoder\ncompared to adversarial learning and L2 regularization.",
          "link": "http://arxiv.org/abs/2106.06751",
          "publishedOn": "2021-06-15T01:45:15.372Z",
          "wordCount": 583,
          "title": "Guiding Teacher Forcing with Seer Forcing for Neural Machine Translation. (arXiv:2106.06751v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2101.07393",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hanjie_A/0/1/0/all/0/1\">Austin W. Hanjie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_V/0/1/0/all/0/1\">Victor Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narasimhan_K/0/1/0/all/0/1\">Karthik Narasimhan</a>",
          "description": "We investigate the use of natural language to drive the generalization of\ncontrol policies and introduce the new multi-task environment Messenger with\nfree-form text manuals describing the environment dynamics. Unlike previous\nwork, Messenger does not assume prior knowledge connecting text and state\nobservations $-$ the control policy must simultaneously ground the game manual\nto entity symbols and dynamics in the environment. We develop a new model, EMMA\n(Entity Mapper with Multi-modal Attention) which uses an entity-conditioned\nattention module that allows for selective focus over relevant descriptions in\nthe manual for each entity in the environment. EMMA is end-to-end\ndifferentiable and learns a latent grounding of entities and dynamics from text\nto observations using only environment rewards. EMMA achieves successful\nzero-shot generalization to unseen games with new dynamics, obtaining a 40%\nhigher win rate compared to multiple baselines. However, win rate on the\nhardest stage of Messenger remains low (10%), demonstrating the need for\nadditional work in this direction.",
          "link": "http://arxiv.org/abs/2101.07393",
          "publishedOn": "2021-06-15T01:45:15.298Z",
          "wordCount": 638,
          "title": "Grounding Language to Entities and Dynamics for Generalization in Reinforcement Learning. (arXiv:2101.07393v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.06969",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhengyan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_G/0/1/0/all/0/1\">Guangxuan Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yongwei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_T/0/1/0/all/0/1\">Tian Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_F/0/1/0/all/0/1\">Fanchao Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yasheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1\">Xin Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>",
          "description": "Pre-trained models (PTMs) have been widely used in various downstream tasks.\nThe parameters of PTMs are distributed on the Internet and may suffer backdoor\nattacks. In this work, we demonstrate the universal vulnerability of PTMs,\nwhere fine-tuned PTMs can be easily controlled by backdoor attacks in arbitrary\ndownstream tasks. Specifically, attackers can add a simple pre-training task,\nwhich restricts the output representations of trigger instances to pre-defined\nvectors, namely neuron-level backdoor attack (NeuBA). If the backdoor\nfunctionality is not eliminated during fine-tuning, the triggers can make the\nfine-tuned model predict fixed labels by pre-defined vectors. In the\nexperiments of both natural language processing (NLP) and computer vision (CV),\nwe show that NeuBA absolutely controls the predictions for trigger instances\nwithout any knowledge of downstream tasks. Finally, we apply several defense\nmethods to NeuBA and find that model pruning is a promising direction to resist\nNeuBA by excluding backdoored neurons. Our findings sound a red alarm for the\nwide use of PTMs. Our source code and models are available at\n\\url{https://github.com/thunlp/NeuBA}.",
          "link": "http://arxiv.org/abs/2101.06969",
          "publishedOn": "2021-06-15T01:45:15.267Z",
          "wordCount": 660,
          "title": "Red Alarm for Pre-trained Models: Universal Vulnerability to Neuron-Level Backdoor Attacks. (arXiv:2101.06969v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06797",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Sachin Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anastasopoulos_A/0/1/0/all/0/1\">Antonios Anastasopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wintner_S/0/1/0/all/0/1\">Shuly Wintner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsvetkov_Y/0/1/0/all/0/1\">Yulia Tsvetkov</a>",
          "description": "State-of-the-art machine translation (MT) systems are typically trained to\ngenerate the \"standard\" target language; however, many languages have multiple\nvarieties (regional varieties, dialects, sociolects, non-native varieties) that\nare different from the standard language. Such varieties are often\nlow-resource, and hence do not benefit from contemporary NLP solutions, MT\nincluded. We propose a general framework to rapidly adapt MT systems to\ngenerate language varieties that are close to, but different from, the standard\ntarget language, using no parallel (source--variety) data. This also includes\nadaptation of MT systems to low-resource typologically-related target\nlanguages. We experiment with adapting an English--Russian MT system to\ngenerate Ukrainian and Belarusian, an English--Norwegian Bokm{\\aa}l system to\ngenerate Nynorsk, and an English--Arabic system to generate four Arabic\ndialects, obtaining significant improvements over competitive baselines.",
          "link": "http://arxiv.org/abs/2106.06797",
          "publishedOn": "2021-06-15T01:45:15.254Z",
          "wordCount": 575,
          "title": "Machine Translation into Low-resource Language Varieties. (arXiv:2106.06797v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06673",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sayyed_Z/0/1/0/all/0/1\">Zeeshan Ali Sayyed</a>",
          "description": "This work investigates the application of sampling methods for sentiment\nanalysis on two different highly imbalanced datasets. One dataset contains\nonline user reviews from the cooking platform Epicurious and the other contains\ncomments given to the Planned Parenthood organization. In both these datasets,\nthe classes of interest are rare. Word n-grams were used as features from these\ndatasets. A feature selection technique based on information gain is first\napplied to reduce the number of features to a manageable space. A number of\ndifferent sampling methods were then applied to mitigate the class imbalance\nproblem which are then analyzed.",
          "link": "http://arxiv.org/abs/2106.06673",
          "publishedOn": "2021-06-15T01:45:15.220Z",
          "wordCount": 522,
          "title": "Study of sampling methods in sentiment analysis of imbalanced data. (arXiv:2106.06673v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06766",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sachintha_D/0/1/0/all/0/1\">Dilan Sachintha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piyarathna_L/0/1/0/all/0/1\">Lakmali Piyarathna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajitha_C/0/1/0/all/0/1\">Charith Rajitha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranathunga_S/0/1/0/all/0/1\">Surangika Ranathunga</a>",
          "description": "Multilingual sentence representations pose a great advantage for low-resource\nlanguages that do not have enough data to build monolingual models on their\nown. These multilingual sentence representations have been separately exploited\nby few research for document and sentence alignment. However, most of the\nlow-resource languages are under-represented in these pre-trained models. Thus,\nin the context of low-resource languages, these models have to be fine-tuned\nfor the task at hand, using additional data sources. This paper presents a\nweighting mechanism that makes use of available small-scale parallel corpora to\nimprove the performance of multilingual sentence representations on document\nand sentence alignment. Experiments are conducted with respect to two\nlow-resource languages, Sinhala and Tamil. Results on a newly created dataset\nof Sinhala-English, Tamil-English, and Sinhala-Tamil show that this new\nweighting mechanism significantly improves both document and sentence\nalignment. This dataset, as well as the source-code, is publicly released.",
          "link": "http://arxiv.org/abs/2106.06766",
          "publishedOn": "2021-06-15T01:45:15.190Z",
          "wordCount": 585,
          "title": "Exploiting Parallel Corpora to Improve Multilingual Embedding based Document and Sentence Alignment. (arXiv:2106.06766v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06605",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Reddy_S/0/1/0/all/0/1\">Sravana Reddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lazarova_M/0/1/0/all/0/1\">Marina Lazarova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yongze Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jones_R/0/1/0/all/0/1\">Rosie Jones</a>",
          "description": "While there is an abundance of popular writing targeted to podcast creators\non how to speak in ways that engage their listeners, there has been little\ndata-driven analysis of podcasts that relates linguistic style with listener\nengagement. In this paper, we investigate how various factors -- vocabulary\ndiversity, distinctiveness, emotion, and syntax, among others -- correlate with\nengagement, based on analysis of the creators' written descriptions and\ntranscripts of the audio. We build models with different textual\nrepresentations, and show that the identified features are highly predictive of\nengagement. Our analysis tests popular wisdom about stylistic elements in\nhigh-engagement podcasts, corroborating some aspects, and adding new\nperspectives on others.",
          "link": "http://arxiv.org/abs/2106.06605",
          "publishedOn": "2021-06-15T01:45:15.153Z",
          "wordCount": 537,
          "title": "Modeling Language Usage and Listener Engagement in Podcasts. (arXiv:2106.06605v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06963",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fenglin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_S/0/1/0/all/0/1\">Shen Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_W/0/1/0/all/0/1\">Wei Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1\">Yuexian Zou</a>",
          "description": "Automatically generating radiology reports can improve current clinical\npractice in diagnostic radiology. On one hand, it can relieve radiologists from\nthe heavy burden of report writing; On the other hand, it can remind\nradiologists of abnormalities and avoid the misdiagnosis and missed diagnosis.\nYet, this task remains a challenging job for data-driven neural networks, due\nto the serious visual and textual data biases. To this end, we propose a\nPosterior-and-Prior Knowledge Exploring-and-Distilling approach (PPKED) to\nimitate the working patterns of radiologists, who will first examine the\nabnormal regions and assign the disease topic tags to the abnormal regions, and\nthen rely on the years of prior medical knowledge and prior working experience\naccumulations to write reports. Thus, the PPKED includes three modules:\nPosterior Knowledge Explorer (PoKE), Prior Knowledge Explorer (PrKE) and\nMulti-domain Knowledge Distiller (MKD). In detail, PoKE explores the posterior\nknowledge, which provides explicit abnormal visual regions to alleviate visual\ndata bias; PrKE explores the prior knowledge from the prior medical knowledge\ngraph (medical knowledge) and prior radiology reports (working experience) to\nalleviate textual data bias. The explored knowledge is distilled by the MKD to\ngenerate the final reports. Evaluated on MIMIC-CXR and IU-Xray datasets, our\nmethod is able to outperform previous state-of-the-art models on these two\ndatasets.",
          "link": "http://arxiv.org/abs/2106.06963",
          "publishedOn": "2021-06-15T01:45:15.146Z",
          "wordCount": 656,
          "title": "Exploring and Distilling Posterior and Prior Knowledge for Radiology Report Generation. (arXiv:2106.06963v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2010.14318",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Peidong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sainath_T/0/1/0/all/0/1\">Tara N. Sainath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weiss_R/0/1/0/all/0/1\">Ron J. Weiss</a>",
          "description": "We propose a multitask training method for attention-based end-to-end speech\nrecognition models. We regularize the decoder in a listen, attend, and spell\nmodel by multitask training it on both audio-text and text-only data. Trained\non the 100-hour subset of LibriSpeech, the proposed method, without requiring\nan additional language model, leads to an 11% relative performance improvement\nover the baseline and approaches the performance of language model shallow\nfusion on the test-clean evaluation set. We observe a similar trend on the\nwhole 960-hour LibriSpeech training set. Analyses of different types of errors\nand sample output sentences demonstrate that the proposed method can\nincorporate language level information, suggesting its effectiveness in\nreal-world applications.",
          "link": "http://arxiv.org/abs/2010.14318",
          "publishedOn": "2021-06-15T01:45:15.137Z",
          "wordCount": 570,
          "title": "Multitask Training with Text Data for End-to-End Speech Recognition. (arXiv:2010.14318v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.06040",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Herzig_J/0/1/0/all/0/1\">Jonathan Herzig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berant_J/0/1/0/all/0/1\">Jonathan Berant</a>",
          "description": "Despite the success of sequence-to-sequence (seq2seq) models in semantic\nparsing, recent work has shown that they fail in compositional generalization,\ni.e., the ability to generalize to new structures built of components observed\nduring training. In this work, we posit that a span-based parser should lead to\nbetter compositional generalization. we propose SpanBasedSP, a parser that\npredicts a span tree over an input utterance, explicitly encoding how partial\nprograms compose over spans in the input. SpanBasedSP extends Pasupat et al.\n(2019) to be comparable to seq2seq models by (i) training from programs,\nwithout access to gold trees, treating trees as latent variables, (ii) parsing\na class of non-projective trees through an extension to standard CKY. On\nGeoQuery, SCAN and CLOSURE datasets, SpanBasedSP performs similarly to strong\nseq2seq baselines on random splits, but dramatically improves performance\ncompared to baselines on splits that require compositional generalization: from\n$61.0 \\rightarrow 88.9$ average accuracy.",
          "link": "http://arxiv.org/abs/2009.06040",
          "publishedOn": "2021-06-15T01:45:15.086Z",
          "wordCount": 600,
          "title": "Span-based Semantic Parsing for Compositional Generalization. (arXiv:2009.06040v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06937",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1\">Bill Yuchen Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Seyeon Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_X/0/1/0/all/0/1\">Xiaoyang Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>",
          "description": "Commonsense reasoning research has so far been limited to English. We aim to\nevaluate and improve popular multilingual language models (ML-LMs) to help\nadvance commonsense reasoning (CSR) beyond English. We collect the Mickey\nCorpus, consisting of 561k sentences in 11 different languages, which can be\nused for analyzing and improving ML-LMs. We propose Mickey Probe, a\nlanguage-agnostic probing task for fairly evaluating the common sense of\npopular ML-LMs across different languages. In addition, we also create two new\ndatasets, X-CSQA and X-CODAH, by translating their English versions to 15 other\nlanguages, so that we can evaluate popular ML-LMs for cross-lingual commonsense\nreasoning. To improve the performance beyond English, we propose a simple yet\neffective method -- multilingual contrastive pre-training (MCP). It\nsignificantly enhances sentence representations, yielding a large performance\ngain on both benchmarks.",
          "link": "http://arxiv.org/abs/2106.06937",
          "publishedOn": "2021-06-15T01:45:15.080Z",
          "wordCount": 589,
          "title": "Common Sense Beyond English: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning. (arXiv:2106.06937v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06899",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Ankit Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dar_G/0/1/0/all/0/1\">Guy Dar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goodman_S/0/1/0/all/0/1\">Shaya Goodman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ciprut_D/0/1/0/all/0/1\">David Ciprut</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berant_J/0/1/0/all/0/1\">Jonathan Berant</a>",
          "description": "Following the success of dot-product attention in Transformers, numerous\napproximations have been recently proposed to address its quadratic complexity\nwith respect to the input length. While these variants are memory and compute\nefficient, it is not possible to directly use them with popular pre-trained\nlanguage models trained using vanilla attention, without an expensive\ncorrective pre-training stage. In this work, we propose a simple yet highly\naccurate approximation for vanilla attention. We process the queries in chunks,\nand for each query, compute the top-$k$ scores with respect to the keys. Our\napproach offers several advantages: (a) its memory usage is linear in the input\nsize, similar to linear attention variants, such as Performer and RFA (b) it is\na drop-in replacement for vanilla attention that does not require any\ncorrective pre-training, and (c) it can also lead to significant memory savings\nin the feed-forward layers after casting them into the familiar query-key-value\nframework. We evaluate the quality of top-$k$ approximation for multi-head\nattention layers on the Long Range Arena Benchmark, and for feed-forward layers\nof T5 and UnifiedQA on multiple QA datasets. We show our approach leads to\naccuracy that is nearly-identical to vanilla attention in multiple setups\nincluding training from scratch, fine-tuning, and zero-shot inference.",
          "link": "http://arxiv.org/abs/2106.06899",
          "publishedOn": "2021-06-15T01:45:15.055Z",
          "wordCount": 630,
          "title": "Memory-efficient Transformers via Top-$k$ Attention. (arXiv:2106.06899v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06588",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Henn_S/0/1/0/all/0/1\">Sophia Henn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sticha_A/0/1/0/all/0/1\">Abigail Sticha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burley_T/0/1/0/all/0/1\">Timothy Burley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verdeja_E/0/1/0/all/0/1\">Ernesto Verdeja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brenner_P/0/1/0/all/0/1\">Paul Brenner</a>",
          "description": "Robust visualization of complex data is critical for the effective use of NLP\nfor event classification, as the volume of data is large and the\nhigh-dimensional structure of text makes data challenging to summarize\nsuccinctly. In event extraction tasks in particular, visualization can aid in\nunderstanding and illustrating the textual relationships from which machine\nlearning tools produce insights. Through our case study which seeks to identify\npotential triggers of state-led mass killings from news articles using NLP, we\ndemonstrate how visualizations can aid in each stage, from exploratory analysis\nof raw data, to machine learning training analysis, and finally post-inference\nvalidation.",
          "link": "http://arxiv.org/abs/2106.06588",
          "publishedOn": "2021-06-15T01:45:15.040Z",
          "wordCount": 534,
          "title": "Visualization Techniques to Enhance Automated Event Extraction. (arXiv:2106.06588v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06981",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weiss_G/0/1/0/all/0/1\">Gail Weiss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldberg_Y/0/1/0/all/0/1\">Yoav Goldberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yahav_E/0/1/0/all/0/1\">Eran Yahav</a>",
          "description": "What is the computational model behind a Transformer? Where recurrent neural\nnetworks have direct parallels in finite state machines, allowing clear\ndiscussion and thought around architecture variants or trained models,\nTransformers have no such familiar parallel. In this paper we aim to change\nthat, proposing a computational model for the transformer-encoder in the form\nof a programming language. We map the basic components of a transformer-encoder\n-- attention and feed-forward computation -- into simple primitives, around\nwhich we form a programming language: the Restricted Access Sequence Processing\nLanguage (RASP). We show how RASP can be used to program solutions to tasks\nthat could conceivably be learned by a Transformer, and how a Transformer can\nbe trained to mimic a RASP solution. In particular, we provide RASP programs\nfor histograms, sorting, and Dyck-languages. We further use our model to relate\ntheir difficulty in terms of the number of required layers and attention heads:\nanalyzing a RASP program implies a maximum number of heads and layers necessary\nto encode a task in a transformer. Finally, we see how insights gained from our\nabstraction might be used to explain phenomena seen in recent works.",
          "link": "http://arxiv.org/abs/2106.06981",
          "publishedOn": "2021-06-15T01:45:15.033Z",
          "wordCount": 611,
          "title": "Thinking Like Transformers. (arXiv:2106.06981v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2104.14470",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1\">Ha Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Esteve_Y/0/1/0/all/0/1\">Yannick Est&#xe8;ve</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Besacier_L/0/1/0/all/0/1\">Laurent Besacier</a>",
          "description": "Boosted by the simultaneous translation shared task at IWSLT 2020, promising\nend-to-end online speech translation approaches were recently proposed. They\nconsist in incrementally encoding a speech input (in a source language) and\ndecoding the corresponding text (in a target language) with the best possible\ntrade-off between latency and translation quality. This paper investigates two\nkey aspects of end-to-end simultaneous speech translation: (a) how to encode\nefficiently the continuous speech flow, and (b) how to segment the speech flow\nin order to alternate optimally between reading (R: encoding input) and writing\n(W: decoding output) operations. We extend our previously proposed end-to-end\nonline decoding strategy and show that while replacing BLSTM by ULSTM encoding\ndegrades performance in offline mode, it actually improves both efficiency and\nperformance in online mode. We also measure the impact of different methods to\nsegment the speech signal (using fixed interval boundaries, oracle word\nboundaries or randomly set boundaries) and show that our best end-to-end online\ndecoding strategy is surprisingly the one that alternates R/W operations on\nfixed size blocks on our English-German speech translation setup.",
          "link": "http://arxiv.org/abs/2104.14470",
          "publishedOn": "2021-06-15T01:45:14.799Z",
          "wordCount": 653,
          "title": "Impact of Encoding and Segmentation Strategies on End-to-End Simultaneous Speech Translation. (arXiv:2104.14470v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.08620",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rozner_J/0/1/0/all/0/1\">Josh Rozner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potts_C/0/1/0/all/0/1\">Christopher Potts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahowald_K/0/1/0/all/0/1\">Kyle Mahowald</a>",
          "description": "Cryptic crosswords, the dominant English-language crossword variety in the\nUnited Kingdom, can be solved by expert humans using flexible, creative\nintelligence and knowledge of language. Cryptic clues read like fluent natural\nlanguage, but they are adversarially composed of two parts: a definition and a\nwordplay cipher requiring sub-word or character-level manipulations. As such,\nthey are a promising target for evaluating and advancing NLP systems that seek\nto process language in more creative, human-like ways. We present a dataset of\ncryptic crossword clues from a major newspaper that can be used as a benchmark\nand train a sequence-to-sequence model to solve them. We also develop related\nbenchmarks that can guide development of approaches to this challenging task.\nWe show that performance can be substantially improved using a novel curriculum\nlearning approach in which the model is pre-trained on related tasks involving,\ne.g, unscrambling words, before it is trained to solve cryptics. However, even\nthis curricular approach does not generalize to novel clue types in the way\nthat humans can, and so cryptic crosswords remain a challenge for NLP systems\nand a potential source of future innovation.",
          "link": "http://arxiv.org/abs/2104.08620",
          "publishedOn": "2021-06-15T01:45:14.661Z",
          "wordCount": 647,
          "title": "Decrypting Cryptic Crosswords: Semantically Complex Wordplay Puzzles as a Target for NLP. (arXiv:2104.08620v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.05752",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cha_S/0/1/0/all/0/1\">Sujeong Cha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_W/0/1/0/all/0/1\">Wangrui Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_H/0/1/0/all/0/1\">Hyun Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Phung_M/0/1/0/all/0/1\">My Phung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Picheny_M/0/1/0/all/0/1\">Michael Picheny</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuo_H/0/1/0/all/0/1\">Hong-Kwang Kuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thomas_S/0/1/0/all/0/1\">Samuel Thomas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morais_E/0/1/0/all/0/1\">Edmilson Morais</a>",
          "description": "A major focus of recent research in spoken language understanding (SLU) has\nbeen on the end-to-end approach where a single model can predict intents\ndirectly from speech inputs without intermediate transcripts. However, this\napproach presents some challenges. First, since speech can be considered as\npersonally identifiable information, in some cases only automatic speech\nrecognition (ASR) transcripts are accessible. Second, intent-labeled speech\ndata is scarce. To address the first challenge, we propose a novel system that\ncan predict intents from flexible types of inputs: speech, ASR transcripts, or\nboth. We demonstrate strong performance for either modality separately, and\nwhen both speech and ASR transcripts are available, through system combination,\nwe achieve better results than using a single input modality. To address the\nsecond challenge, we leverage a semantically robust pre-trained BERT model and\nadopt a cross-modal system that co-trains text embeddings and acoustic\nembeddings in a shared latent space. We further enhance this system by\nutilizing an acoustic module pre-trained on LibriSpeech and domain-adapting the\ntext module on our target datasets. Our experiments show significant advantages\nfor these pre-training and fine-tuning strategies, resulting in a system that\nachieves competitive intent-classification performance on Snips SLU and Fluent\nSpeech Commands datasets.",
          "link": "http://arxiv.org/abs/2104.05752",
          "publishedOn": "2021-06-15T01:45:14.609Z",
          "wordCount": 689,
          "title": "Speak or Chat with Me: End-to-End Spoken Language Understanding System with Flexible Inputs. (arXiv:2104.05752v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03153",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Min_D/0/1/0/all/0/1\">Dongchan Min</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_D/0/1/0/all/0/1\">Dong Bok Lee</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_E/0/1/0/all/0/1\">Eunho Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hwang_S/0/1/0/all/0/1\">Sung Ju Hwang</a>",
          "description": "With rapid progress in neural text-to-speech (TTS) models, personalized\nspeech generation is now in high demand for many applications. For practical\napplicability, a TTS model should generate high-quality speech with only a few\naudio samples from the given speaker, that are also short in length. However,\nexisting methods either require to fine-tune the model or achieve low\nadaptation quality without fine-tuning. In this work, we propose StyleSpeech, a\nnew TTS model which not only synthesizes high-quality speech but also\neffectively adapts to new speakers. Specifically, we propose Style-Adaptive\nLayer Normalization (SALN) which aligns gain and bias of the text input\naccording to the style extracted from a reference speech audio. With SALN, our\nmodel effectively synthesizes speech in the style of the target speaker even\nfrom single speech audio. Furthermore, to enhance StyleSpeech's adaptation to\nspeech from new speakers, we extend it to Meta-StyleSpeech by introducing two\ndiscriminators trained with style prototypes, and performing episodic training.\nThe experimental results show that our models generate high-quality speech\nwhich accurately follows the speaker's voice with single short-duration (1-3\nsec) speech audio, significantly outperforming baselines.",
          "link": "http://arxiv.org/abs/2106.03153",
          "publishedOn": "2021-06-15T01:45:14.370Z",
          "wordCount": 645,
          "title": "Meta-StyleSpeech : Multi-Speaker Adaptive Text-to-Speech Generation. (arXiv:2106.03153v2 [eess.AS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.03006",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeyer_A/0/1/0/all/0/1\">Albert Zeyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Merboldt_A/0/1/0/all/0/1\">Andr&#xe9; Merboldt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Michel_W/0/1/0/all/0/1\">Wilfried Michel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schluter_R/0/1/0/all/0/1\">Ralf Schl&#xfc;ter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ney_H/0/1/0/all/0/1\">Hermann Ney</a>",
          "description": "We present our transducer model on Librispeech. We study variants to include\nan external language model (LM) with shallow fusion and subtract an estimated\ninternal LM. This is justified by a Bayesian interpretation where the\ntransducer model prior is given by the estimated internal LM. The subtraction\nof the internal LM gives us over 14% relative improvement over normal shallow\nfusion. Our transducer has a separate probability distribution for the\nnon-blank labels which allows for easier combination with the external LM, and\neasier estimation of the internal LM. We additionally take care of including\nthe end-of-sentence (EOS) probability of the external LM in the last blank\nprobability which further improves the performance. All our code and setups are\npublished.",
          "link": "http://arxiv.org/abs/2104.03006",
          "publishedOn": "2021-06-15T01:45:14.323Z",
          "wordCount": 592,
          "title": "Librispeech Transducer Model with Internal Language Model Prior Correction. (arXiv:2104.03006v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.10685",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zou_X/0/1/0/all/0/1\">Xu Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_D/0/1/0/all/0/1\">Da Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_Q/0/1/0/all/0/1\">Qingyang Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1\">Ming Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhilin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jie Tang</a>",
          "description": "Large-scale pre-trained language models have demonstrated strong capabilities\nof generating realistic text. However, it remains challenging to control the\ngeneration results. Previous approaches such as prompting are far from\nsufficient, which limits the usage of language models. To tackle this\nchallenge, we propose an innovative method, inverse prompting, to better\ncontrol text generation. The core idea of inverse prompting is to use generated\ntext to inversely predict the prompt during beam search, which enhances the\nrelevance between the prompt and the generated text and provides better\ncontrollability. Empirically, we pre-train a large-scale Chinese language model\nto perform a systematic study using human evaluation on the tasks of\nopen-domain poem generation and open-domain long-form question answering. Our\nresults show that our proposed method substantially outperforms the baselines\nand that our generation quality is close to human performance on some of the\ntasks.\n\nNarrators can try our poem generation demo at\nhttps://pretrain.aminer.cn/apps/poetry.html, while our QA demo can be found at\nhttps://pretrain.aminer.cn/app/qa. For researchers, the code is provided in\nhttps://github.com/THUDM/InversePrompting.",
          "link": "http://arxiv.org/abs/2103.10685",
          "publishedOn": "2021-06-15T01:45:14.275Z",
          "wordCount": 641,
          "title": "Controllable Generation from Pre-trained Language Models via Inverse Prompting. (arXiv:2103.10685v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03469",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xia_M/0/1/0/all/0/1\">Menglin Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monti_E/0/1/0/all/0/1\">Emilio Monti</a>",
          "description": "Multilingual semantic parsing is a cost-effective method that allows a single\nmodel to understand different languages. However, researchers face a great\nimbalance of availability of training data, with English being resource rich,\nand other languages having much less data. To tackle the data limitation\nproblem, we propose using machine translation to bootstrap multilingual\ntraining data from the more abundant English data. To compensate for the data\nquality of machine translated training data, we utilize transfer learning from\npretrained multilingual encoders to further improve the model. To evaluate our\nmultilingual models on human-written sentences as opposed to machine translated\nones, we introduce a new multilingual semantic parsing dataset in English,\nItalian and Japanese based on the Facebook Task Oriented Parsing (TOP) dataset.\nWe show that joint multilingual training with pretrained encoders substantially\noutperforms our baselines on the TOP dataset and outperforms the\nstate-of-the-art model on the public NLMaps dataset. We also establish a new\nbaseline for zero-shot learning on the TOP dataset. We find that a semantic\nparser trained only on English data achieves a zero-shot performance of 44.9%\nexact-match accuracy on Italian sentences.",
          "link": "http://arxiv.org/abs/2106.03469",
          "publishedOn": "2021-06-15T01:45:14.234Z",
          "wordCount": 623,
          "title": "Multilingual Neural Semantic Parsing for Low-Resourced Languages. (arXiv:2106.03469v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1906.01154",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schmaltz_A/0/1/0/all/0/1\">Allen Schmaltz</a>",
          "description": "We propose a new, more actionable view of neural network interpretability and\ndata analysis by leveraging the remarkable matching effectiveness of\nrepresentations derived from deep networks, guided by an approach for\nclass-conditional feature detection. The decomposition of the filter-ngram\ninteractions of a convolutional neural network and a linear layer over a\npre-trained deep network yields a strong binary sequence labeler, with\nflexibility in producing predictions at -- and defining loss functions for --\nvarying label granularities, from the fully-supervised sequence labeling\nsetting to the challenging zero-shot sequence labeling setting, in which we\nseek token-level predictions but only have document-level labels for training.\nFrom this sequence-labeling layer we derive dense representations of the input\nthat can then be matched to instances from training, or a support set with\nknown labels. Such introspection with inference-time decision rules provides a\nmeans, in some settings, of making local updates to the model by altering the\nlabels or instances in the support set without re-training the full model.\nFinally, we construct a particular K-nearest neighbors (K-NN) model from\nmatched exemplar representations that approximates the original model's\npredictions and is at least as effective a predictor with respect to the\nground-truth labels. This additionally yields interpretable heuristics at the\ntoken level for determining when predictions are less likely to be reliable,\nand for screening input dissimilar to the support set. In effect, we show that\nwe can transform the deep network into a simple weighting over exemplars and\nassociated labels, yielding an introspectable -- and modestly updatable --\nversion of the original model.",
          "link": "http://arxiv.org/abs/1906.01154",
          "publishedOn": "2021-06-15T01:45:14.214Z",
          "wordCount": 760,
          "title": "Detecting Local Insights from Global Labels: Supervised & Zero-Shot Sequence Labeling via a Convolutional Decomposition. (arXiv:1906.01154v6 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.00981",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gusev_I/0/1/0/all/0/1\">Ilya Gusev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smurov_I/0/1/0/all/0/1\">Ivan Smurov</a>",
          "description": "This paper presents the results of the Russian News Clustering and Headline\nSelection shared task. As a part of it, we propose the tasks of Russian news\nevent detection, headline selection, and headline generation. These tasks are\naccompanied by datasets and baselines. The presented datasets for event\ndetection and headline selection are the first public Russian datasets for\ntheir tasks. The headline generation dataset is based on clustering and\nprovides multiple reference headlines for every cluster, unlike the previous\ndatasets. Finally, the approaches proposed by the shared task participants are\nreported and analyzed.",
          "link": "http://arxiv.org/abs/2105.00981",
          "publishedOn": "2021-06-15T01:45:14.144Z",
          "wordCount": 557,
          "title": "Russian News Clustering and Headline Selection Shared Task. (arXiv:2105.00981v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.09261",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1\">Xu Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Boyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Han Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miao_C/0/1/0/all/0/1\">Chunyan Miao</a>",
          "description": "The existence of multiple datasets for sarcasm detection prompts us to apply\ntransfer learning to exploit their commonality. The adversarial neural transfer\n(ANT) framework utilizes multiple loss terms that encourage the source-domain\nand the target-domain feature distributions to be similar while optimizing for\ndomain-specific performance. However, these objectives may be in conflict,\nwhich can lead to optimization difficulties and sometimes diminished transfer.\nWe propose a generalized latent optimization strategy that allows different\nlosses to accommodate each other and improves training dynamics. The proposed\nmethod outperforms transfer learning and meta-learning baselines. In\nparticular, we achieve 10.02% absolute performance gain over the previous state\nof the art on the iSarcasm dataset.",
          "link": "http://arxiv.org/abs/2104.09261",
          "publishedOn": "2021-06-15T01:45:14.126Z",
          "wordCount": 579,
          "title": "Latent-Optimized Adversarial Neural Transfer for Sarcasm Detection. (arXiv:2104.09261v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06944",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yan_H/0/1/0/all/0/1\">Hua Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_W/0/1/0/all/0/1\">Weikang Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_F/0/1/0/all/0/1\">Feng Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jian Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_F/0/1/0/all/0/1\">Furao Shen</a>",
          "description": "Subtext is a kind of deep semantics which can be acquired after one or more\nrounds of expression transformation. As a popular way of expressing one's\nintentions, it is well worth studying. In this paper, we try to make computers\nunderstand whether there is a subtext by means of machine learning. We build a\nChinese dataset whose source data comes from the popular social media (e.g.\nWeibo, Netease Music, Zhihu, and Bilibili). In addition, we also build a\nbaseline model called SASICM to deal with subtext recognition. The F1 score of\nSASICMg, whose pretrained model is GloVe, is as high as 64.37%, which is 3.97%\nhigher than that of BERT based model, 12.7% higher than that of traditional\nmethods on average, including support vector machine, logistic regression\nclassifier, maximum entropy classifier, naive bayes classifier and decision\ntree and 2.39% higher than that of the state-of-the-art, including MARIN and\nBTM. The F1 score of SASICMBERT, whose pretrained model is BERT, is 65.12%,\nwhich is 0.75% higher than that of SASICMg. The accuracy rates of SASICMg and\nSASICMBERT are 71.16% and 70.76%, respectively, which can compete with those of\nother methods which are mentioned before.",
          "link": "http://arxiv.org/abs/2106.06944",
          "publishedOn": "2021-06-15T01:45:14.106Z",
          "wordCount": 647,
          "title": "SASICM A Multi-Task Benchmark For Subtext Recognition. (arXiv:2106.06944v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2003.00330",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lamb_L/0/1/0/all/0/1\">Luis C. Lamb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garcez_A/0/1/0/all/0/1\">Artur Garcez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gori_M/0/1/0/all/0/1\">Marco Gori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prates_M/0/1/0/all/0/1\">Marcelo Prates</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Avelar_P/0/1/0/all/0/1\">Pedro Avelar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vardi_M/0/1/0/all/0/1\">Moshe Vardi</a>",
          "description": "Neural-symbolic computing has now become the subject of interest of both\nacademic and industry research laboratories. Graph Neural Networks (GNN) have\nbeen widely used in relational and symbolic domains, with widespread\napplication of GNNs in combinatorial optimization, constraint satisfaction,\nrelational reasoning and other scientific domains. The need for improved\nexplainability, interpretability and trust of AI systems in general demands\nprincipled methodologies, as suggested by neural-symbolic computing. In this\npaper, we review the state-of-the-art on the use of GNNs as a model of\nneural-symbolic computing. This includes the application of GNNs in several\ndomains as well as its relationship to current developments in neural-symbolic\ncomputing.",
          "link": "http://arxiv.org/abs/2003.00330",
          "publishedOn": "2021-06-15T01:45:14.041Z",
          "wordCount": 645,
          "title": "Graph Neural Networks Meet Neural-Symbolic Computing: A Survey and Perspective. (arXiv:2003.00330v7 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.00151",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Le_H/0/1/0/all/0/1\">Hung Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sankar_C/0/1/0/all/0/1\">Chinnadhurai Sankar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moon_S/0/1/0/all/0/1\">Seungwhan Moon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beirami_A/0/1/0/all/0/1\">Ahmad Beirami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geramifard_A/0/1/0/all/0/1\">Alborz Geramifard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kottur_S/0/1/0/all/0/1\">Satwik Kottur</a>",
          "description": "A video-grounded dialogue system is required to understand both dialogue,\nwhich contains semantic dependencies from turn to turn, and video, which\ncontains visual cues of spatial and temporal scene variations. Building such\ndialogue systems is a challenging problem, involving various reasoning types on\nboth visual and language inputs. Existing benchmarks do not have enough\nannotations to thoroughly analyze dialogue systems and understand their\ncapabilities and limitations in isolation. These benchmarks are also not\nexplicitly designed to minimise biases that models can exploit without actual\nreasoning. To address these limitations, in this paper, we present DVD, a\nDiagnostic Dataset for Video-grounded Dialogues. The dataset is designed to\ncontain minimal biases and has detailed annotations for the different types of\nreasoning over the spatio-temporal space of video. Dialogues are synthesized\nover multiple question turns, each of which is injected with a set of\ncross-turn semantic relationships. We use DVD to analyze existing approaches,\nproviding interesting insights into their abilities and limitations. In total,\nDVD is built from $11k$ CATER synthetic videos and contains $10$ instances of\n$10$-round dialogues for each video, resulting in more than $100k$ dialogues\nand $1M$ question-answer pairs. Our code and dataset are publicly available at\nhttps://github.com/facebookresearch/DVDialogues.",
          "link": "http://arxiv.org/abs/2101.00151",
          "publishedOn": "2021-06-15T01:45:14.016Z",
          "wordCount": 688,
          "title": "DVD: A Diagnostic Dataset for Multi-step Reasoning in Video Grounded Dialogue. (arXiv:2101.00151v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.12919",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pryzant_R/0/1/0/all/0/1\">Reid Pryzant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Card_D/0/1/0/all/0/1\">Dallas Card</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jurafsky_D/0/1/0/all/0/1\">Dan Jurafsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Veitch_V/0/1/0/all/0/1\">Victor Veitch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sridhar_D/0/1/0/all/0/1\">Dhanya Sridhar</a>",
          "description": "We consider the problem of using observational data to estimate the causal\neffects of linguistic properties. For example, does writing a complaint\npolitely lead to a faster response time? How much will a positive product\nreview increase sales? This paper addresses two technical challenges related to\nthe problem before developing a practical method. First, we formalize the\ncausal quantity of interest as the effect of a writer's intent, and establish\nthe assumptions necessary to identify this from observational data. Second, in\npractice, we only have access to noisy proxies for the linguistic properties of\ninterest -- e.g., predictions from classifiers and lexicons. We propose an\nestimator for this setting and prove that its bias is bounded when we perform\nan adjustment for the text. Based on these results, we introduce TextCause, an\nalgorithm for estimating causal effects of linguistic properties. The method\nleverages (1) distant supervision to improve the quality of noisy proxies, and\n(2) a pre-trained language model (BERT) to adjust for the text. We show that\nthe proposed method outperforms related approaches when estimating the effect\nof Amazon review sentiment on semi-simulated sales figures. Finally, we present\nan applied case study investigating the effects of complaint politeness on\nbureaucratic response times.",
          "link": "http://arxiv.org/abs/2010.12919",
          "publishedOn": "2021-06-15T01:45:14.004Z",
          "wordCount": 705,
          "title": "Causal Effects of Linguistic Properties. (arXiv:2010.12919v5 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06849",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Laverghetta_A/0/1/0/all/0/1\">Antonio Laverghetta Jr.</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nighojkar_A/0/1/0/all/0/1\">Animesh Nighojkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mirzakhalov_J/0/1/0/all/0/1\">Jamshidbek Mirzakhalov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Licato_J/0/1/0/all/0/1\">John Licato</a>",
          "description": "Transformer-based language models (LMs) continue to advance state-of-the-art\nperformance on NLP benchmark tasks, including tasks designed to mimic\nhuman-inspired \"commonsense\" competencies. To better understand the degree to\nwhich LMs can be said to have certain linguistic reasoning skills, researchers\nare beginning to adapt the tools and concepts of the field of psychometrics.\nBut to what extent can the benefits flow in the other direction? I.e., can LMs\nbe of use in predicting what the psychometric properties of test items will be\nwhen those items are given to human participants? We gather responses from\nnumerous human participants and LMs (transformer and non-transformer-based) on\na broad diagnostic test of linguistic competencies. We then use the responses\nto calculate standard psychometric properties of the items in the diagnostic\ntest, using the human responses and the LM responses separately. We then\ndetermine how well these two sets of predictions match. We find cases in which\ntransformer-based LMs predict psychometric properties consistently well in\ncertain categories but consistently poorly in others, thus providing new\ninsights into fundamental similarities and differences between human and LM\nreasoning.",
          "link": "http://arxiv.org/abs/2106.06849",
          "publishedOn": "2021-06-15T01:45:13.991Z",
          "wordCount": 619,
          "title": "Can Transformer Language Models Predict Psychometric Properties?. (arXiv:2106.06849v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06905",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1\">Runshi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_P/0/1/0/all/0/1\">Pengda Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuhong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_W/0/1/0/all/0/1\">Weigao Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_K/0/1/0/all/0/1\">Kefeng Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qiang Wu</a>",
          "description": "E-commerce companies have to face abnormal sellers who sell potentially-risky\nproducts. Typically, the risk can be identified by jointly considering product\ncontent (e.g., title and image) and seller behavior. This work focuses on\nbehavior feature extraction as behavior sequences can provide valuable clues\nfor the risk discovery by reflecting the sellers' operation habits. Traditional\nfeature extraction techniques heavily depend on domain experts and adapt poorly\nto new tasks. In this paper, we propose a self-supervised method InfoBehavior\nto automatically extract meaningful representations from ultra-long raw\nbehavior sequences instead of the costly feature selection procedure.\nInfoBehavior utilizes Bidirectional Transformer as feature encoder due to its\nexcellent capability in modeling long-term dependency. However, it is\nintractable for commodity GPUs because the time and memory required by\nTransformer grow quadratically with the increase of sequence length. Thus, we\npropose a hierarchical grouping strategy to aggregate ultra-long raw behavior\nsequences to length-processable high-level embedding sequences. Moreover, we\nintroduce two types of pretext tasks. Sequence-related pretext task defines a\ncontrastive-based training objective to correctly select the masked-out\ncoarse-grained/fine-grained behavior sequences against other \"distractor\"\nbehavior sequences; Domain-related pretext task designs a classification\ntraining objective to correctly predict the domain-specific statistical results\nof anomalous behavior. We show that behavior representations from the\npre-trained InfoBehavior can be directly used or integrated with features from\nother side information to support a wide range of downstream tasks.\nExperimental results demonstrate that InfoBehavior significantly improves the\nperformance of Product Risk Management and Intellectual Property Protection.",
          "link": "http://arxiv.org/abs/2106.06905",
          "publishedOn": "2021-06-15T01:45:13.984Z",
          "wordCount": 682,
          "title": "InfoBehavior: Self-supervised Representation Learning for Ultra-long Behavior Sequence via Hierarchical Grouping. (arXiv:2106.06905v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06697",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ventura_F/0/1/0/all/0/1\">Francesco Ventura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Greco_S/0/1/0/all/0/1\">Salvatore Greco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Apiletti_D/0/1/0/all/0/1\">Daniele Apiletti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cerquitelli_T/0/1/0/all/0/1\">Tania Cerquitelli</a>",
          "description": "Despite the high accuracy offered by state-of-the-art deep natural-language\nmodels (e.g. LSTM, BERT), their application in real-life settings is still\nwidely limited, as they behave like a black-box to the end-user. Hence,\nexplainability is rapidly becoming a fundamental requirement of\nfuture-generation data-driven systems based on deep-learning approaches.\nSeveral attempts to fulfill the existing gap between accuracy and\ninterpretability have been done. However, robust and specialized xAI\n(Explainable Artificial Intelligence) solutions tailored to deep\nnatural-language models are still missing. We propose a new framework, named\nT-EBAnO, which provides innovative prediction-local and class-based\nmodel-global explanation strategies tailored to black-box deep natural-language\nmodels. Given a deep NLP model and the textual input data, T-EBAnO provides an\nobjective, human-readable, domain-specific assessment of the reasons behind the\nautomatic decision-making process. Specifically, the framework extracts sets of\ninterpretable features mining the inner knowledge of the model. Then, it\nquantifies the influence of each feature during the prediction process by\nexploiting the novel normalized Perturbation Influence Relation index at the\nlocal level and the novel Global Absolute Influence and Global Relative\nInfluence indexes at the global level. The effectiveness and the quality of the\nlocal and global explanations obtained with T-EBAnO are proved on (i) a\nsentiment analysis task performed by a fine-tuned BERT model, and (ii) a toxic\ncomment classification task performed by an LSTM model.",
          "link": "http://arxiv.org/abs/2106.06697",
          "publishedOn": "2021-06-15T01:45:13.965Z",
          "wordCount": 655,
          "title": "Explaining the Deep Natural Language Processing by Mining Textual Interpretable Features. (arXiv:2106.06697v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06830",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1\">Anthony Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gudipati_P/0/1/0/all/0/1\">Pallavi Gudipati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Longpre_S/0/1/0/all/0/1\">Shayne Longpre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_X/0/1/0/all/0/1\">Xiao Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Sameer Singh</a>",
          "description": "Retrieval is a core component for open-domain NLP tasks. In open-domain\ntasks, multiple entities can share a name, making disambiguation an inherent\nyet under-explored problem. We propose an evaluation benchmark for assessing\nthe entity disambiguation capabilities of these retrievers, which we call\nAmbiguous Entity Retrieval (AmbER) sets. We define an AmbER set as a collection\nof entities that share a name along with queries about those entities. By\ncovering the set of entities for polysemous names, AmbER sets act as a\nchallenging test of entity disambiguation. We create AmbER sets for three\npopular open-domain tasks: fact checking, slot filling, and question answering,\nand evaluate a diverse set of retrievers. We find that the retrievers exhibit\npopularity bias, significantly under-performing on rarer entities that share a\nname, e.g., they are twice as likely to retrieve erroneous documents on queries\nfor the less popular entity under the same name. These experiments on AmbER\nsets show their utility as an evaluation tool and highlight the weaknesses of\npopular retrieval systems.",
          "link": "http://arxiv.org/abs/2106.06830",
          "publishedOn": "2021-06-15T01:45:13.954Z",
          "wordCount": 604,
          "title": "Evaluating Entity Disambiguation and the Role of Popularity in Retrieval-Based NLP. (arXiv:2106.06830v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2010.05594",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Han_T/0/1/0/all/0/1\">Ting Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Ximing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takanobu_R/0/1/0/all/0/1\">Ryuichi Takanobu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lian_Y/0/1/0/all/0/1\">Yixin Lian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1\">Chongxuan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_D/0/1/0/all/0/1\">Dazhen Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1\">Wei Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Minlie Huang</a>",
          "description": "Task-oriented dialogue systems have made unprecedented progress with multiple\nstate-of-the-art (SOTA) models underpinned by a number of publicly available\nMultiWOZ datasets. Dialogue state annotations are error-prone, leading to\nsub-optimal performance. Various efforts have been put in rectifying the\nannotation errors presented in the original MultiWOZ dataset. In this paper, we\nintroduce MultiWOZ 2.3, in which we differentiate incorrect annotations in\ndialogue acts from dialogue states, identifying a lack of co-reference when\npublishing the updated dataset. To ensure consistency between dialogue acts and\ndialogue states, we implement co-reference features and unify annotations of\ndialogue acts and dialogue states. We update the state of the art performance\nof natural language understanding and dialogue state tracking on MultiWOZ 2.3,\nwhere the results show significant improvements than on previous versions of\nMultiWOZ datasets (2.0-2.2).",
          "link": "http://arxiv.org/abs/2010.05594",
          "publishedOn": "2021-06-15T01:45:13.945Z",
          "wordCount": 615,
          "title": "MultiWOZ 2.3: A multi-domain task-oriented dialogue dataset enhanced with annotation corrections and co-reference annotation. (arXiv:2010.05594v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06636",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Junkun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1\">Mingbo Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_R/0/1/0/all/0/1\">Renjie Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1\">Liang Huang</a>",
          "description": "Simultaneous speech-to-text translation is widely useful in many scenarios.\nThe conventional cascaded approach uses a pipeline of streaming ASR followed by\nsimultaneous MT, but suffers from error propagation and extra latency. To\nalleviate these issues, recent efforts attempt to directly translate the source\nspeech into target text simultaneously, but this is much harder due to the\ncombination of two separate tasks. We instead propose a new paradigm with the\nadvantages of both cascaded and end-to-end approaches. The key idea is to use\ntwo separate, but synchronized, decoders on streaming ASR and direct\nspeech-to-text translation (ST), respectively, and the intermediate results of\nASR guide the decoding policy of (but is not fed as input to) ST. During\ntraining time, we use multitask learning to jointly learn these two tasks with\na shared encoder. En-to-De and En-to-Es experiments on the MuSTC dataset\ndemonstrate that our proposed technique achieves substantially better\ntranslation quality at similar levels of latency.",
          "link": "http://arxiv.org/abs/2106.06636",
          "publishedOn": "2021-06-15T01:45:13.937Z",
          "wordCount": 590,
          "title": "Direct Simultaneous Speech-to-Text Translation Assisted by Synchronized Streaming ASR. (arXiv:2106.06636v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2005.00613",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zeqiu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galley_M/0/1/0/all/0/1\">Michel Galley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brockett_C/0/1/0/all/0/1\">Chris Brockett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yizhe Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1\">Xiang Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quirk_C/0/1/0/all/0/1\">Chris Quirk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koncel_Kedziorski_R/0/1/0/all/0/1\">Rik Koncel-Kedziorski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1\">Hannaneh Hajishirzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ostendorf_M/0/1/0/all/0/1\">Mari Ostendorf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dolan_B/0/1/0/all/0/1\">Bill Dolan</a>",
          "description": "Current end-to-end neural conversation models inherently lack the flexibility\nto impose semantic control in the response generation process, often resulting\nin uninteresting responses. Attempts to boost informativeness alone come at the\nexpense of factual accuracy, as attested by pretrained language models'\npropensity to \"hallucinate\" facts. While this may be mitigated by access to\nbackground knowledge, there is scant guarantee of relevance and informativeness\nin generated responses. We propose a framework that we call controllable\ngrounded response generation (CGRG), in which lexical control phrases are\neither provided by a user or automatically extracted by a control phrase\npredictor from dialogue context and grounding knowledge. Quantitative and\nqualitative results show that, using this framework, a transformer based model\nwith a novel inductive attention mechanism, trained on a conversation-like\nReddit dataset, outperforms strong generation baselines.",
          "link": "http://arxiv.org/abs/2005.00613",
          "publishedOn": "2021-06-15T01:45:13.922Z",
          "wordCount": 604,
          "title": "A Controllable Model of Grounded Response Generation. (arXiv:2005.00613v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06786",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lamb_A/0/1/0/all/0/1\">Alex Lamb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clanuwat_T/0/1/0/all/0/1\">Tarin Clanuwat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Siyu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bober_Irizar_M/0/1/0/all/0/1\">Mikel Bober-Irizar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kitamoto_A/0/1/0/all/0/1\">Asanobu Kitamoto</a>",
          "description": "Japan is a unique country with a distinct cultural heritage, which is\nreflected in billions of historical documents that have been preserved.\nHowever, the change in Japanese writing system in 1900 made these documents\ninaccessible for the general public. A major research project has been to make\nthese historical documents accessible and understandable. An increasing amount\nof research has focused on the character recognition task and the location of\ncharacters on image, yet less research has focused on how to predict the\nsequential ordering of the characters. This is because sequence in classical\nJapanese is very different from modern Japanese. Ordering characters into a\nsequence is important for making the document text easily readable and\nsearchable. Additionally, it is a necessary step for any kind of natural\nlanguage processing on the data (e.g. machine translation, language modeling,\nand word embeddings). We explore a few approaches to the task of predicting the\nsequential ordering of the characters: one using simple hand-crafted rules,\nanother using hand-crafted rules with adaptive thresholds, and another using a\ndeep recurrent sequence model trained with teacher forcing. We provide a\nquantitative and qualitative comparison of these techniques as well as their\ndistinct trade-offs. Our best-performing system has an accuracy of 98.65\\% and\nhas a perfect accuracy on 49\\% of the books in our dataset, suggesting that the\ntechnique is able to predict the order of the characters well enough for many\ntasks.",
          "link": "http://arxiv.org/abs/2106.06786",
          "publishedOn": "2021-06-15T01:45:13.898Z",
          "wordCount": 673,
          "title": "Predicting the Ordering of Characters in Japanese Historical Documents. (arXiv:2106.06786v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2008.05221",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_M/0/1/0/all/0/1\">Manish Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_P/0/1/0/all/0/1\">Puneet Agrawal</a>",
          "description": "In recent years, the fields of natural language processing (NLP) and\ninformation retrieval (IR) have made tremendous progress thanksto deep learning\nmodels like Recurrent Neural Networks (RNNs), Gated Recurrent Units (GRUs) and\nLong Short-Term Memory (LSTMs)networks, and Transformer [120] based models like\nBidirectional Encoder Representations from Transformers (BERT) [24],\nGenerativePre-training Transformer (GPT-2) [94], Multi-task Deep Neural Network\n(MT-DNN) [73], Extra-Long Network (XLNet) [134], Text-to-text transfer\ntransformer (T5) [95], T-NLG [98] and GShard [63]. But these models are\nhumongous in size. On the other hand,real world applications demand small model\nsize, low response times and low computational power wattage. In this survey,\nwediscuss six different types of methods (Pruning, Quantization, Knowledge\nDistillation, Parameter Sharing, Tensor Decomposition, andSub-quadratic\nTransformer based methods) for compression of such models to enable their\ndeployment in real industry NLP projects.Given the critical need of building\napplications with efficient and small models, and the large amount of recently\npublished work inthis area, we believe that this survey organizes the plethora\nof work done by the 'deep learning for NLP' community in the past fewyears and\npresents it as a coherent story.",
          "link": "http://arxiv.org/abs/2008.05221",
          "publishedOn": "2021-06-15T01:45:13.888Z",
          "wordCount": 675,
          "title": "Compression of Deep Learning Models for Text: A Survey. (arXiv:2008.05221v4 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06909",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1\">Guoguo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chai_S/0/1/0/all/0/1\">Shuzhou Chai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Guanbo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_J/0/1/0/all/0/1\">Jiayu Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wei-Qiang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weng_C/0/1/0/all/0/1\">Chao Weng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_D/0/1/0/all/0/1\">Dan Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Povey_D/0/1/0/all/0/1\">Daniel Povey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trmal_J/0/1/0/all/0/1\">Jan Trmal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Junbo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_M/0/1/0/all/0/1\">Mingjie Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khudanpur_S/0/1/0/all/0/1\">Sanjeev Khudanpur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watanabe_S/0/1/0/all/0/1\">Shinji Watanabe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Shuaijiang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_W/0/1/0/all/0/1\">Wei Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiangang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_X/0/1/0/all/0/1\">Xuchen Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yongqing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yujun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_Z/0/1/0/all/0/1\">Zhao You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1\">Zhiyong Yan</a>",
          "description": "This paper introduces GigaSpeech, an evolving, multi-domain English speech\nrecognition corpus with 10,000 hours of high quality labeled audio suitable for\nsupervised training, and 40,000 hours of total audio suitable for\nsemi-supervised and unsupervised training. Around 40,000 hours of transcribed\naudio is first collected from audiobooks, podcasts and YouTube, covering both\nread and spontaneous speaking styles, and a variety of topics, such as arts,\nscience, sports, etc. A new forced alignment and segmentation pipeline is\nproposed to create sentence segments suitable for speech recognition training,\nand to filter out segments with low-quality transcription. For system training,\nGigaSpeech provides five subsets of different sizes, 10h, 250h, 1000h, 2500h,\nand 10000h. For our 10,000-hour XL training subset, we cap the word error rate\nat 4% during the filtering/validation stage, and for all our other smaller\ntraining subsets, we cap it at 0%. The DEV and TEST evaluation sets, on the\nother hand, are re-processed by professional human transcribers to ensure high\ntranscription quality. Baseline systems are provided for popular speech\nrecognition toolkits, namely Athena, ESPnet, Kaldi and Pika.",
          "link": "http://arxiv.org/abs/2106.06909",
          "publishedOn": "2021-06-15T01:45:13.880Z",
          "wordCount": 651,
          "title": "GigaSpeech: An Evolving, Multi-domain ASR Corpus with 10,000 Hours of Transcribed Audio. (arXiv:2106.06909v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06598",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shon_S/0/1/0/all/0/1\">Suwon Shon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brusco_P/0/1/0/all/0/1\">Pablo Brusco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1\">Jing Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_K/0/1/0/all/0/1\">Kyu J. Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watanabe_S/0/1/0/all/0/1\">Shinji Watanabe</a>",
          "description": "In this paper, we explore the use of pre-trained language models to learn\nsentiment information of written texts for speech sentiment analysis. First, we\ninvestigate how useful a pre-trained language model would be in a 2-step\npipeline approach employing Automatic Speech Recognition (ASR) and\ntranscripts-based sentiment analysis separately. Second, we propose a pseudo\nlabel-based semi-supervised training strategy using a language model on an\nend-to-end speech sentiment approach to take advantage of a large, but\nunlabeled speech dataset for training. Although spoken and written texts have\ndifferent linguistic characteristics, they can complement each other in\nunderstanding sentiment. Therefore, the proposed system can not only model\nacoustic characteristics to bear sentiment-specific information in speech\nsignals, but learn latent information to carry sentiments in the text\nrepresentation. In these experiments, we demonstrate the proposed approaches\nimprove F1 scores consistently compared to systems without a language model.\nMoreover, we also show that the proposed framework can reduce 65% of human\nsupervision by leveraging a large amount of data without human sentiment\nannotation and boost performance in a low-resource condition where the human\nsentiment annotation is not available enough.",
          "link": "http://arxiv.org/abs/2106.06598",
          "publishedOn": "2021-06-15T01:45:13.854Z",
          "wordCount": 626,
          "title": "Leveraging Pre-trained Language Model for Speech Sentiment Analysis. (arXiv:2106.06598v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06566",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vaduguru_S/0/1/0/all/0/1\">Saujas Vaduguru</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sathe_A/0/1/0/all/0/1\">Aalok Sathe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choudhury_M/0/1/0/all/0/1\">Monojit Choudhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_D/0/1/0/all/0/1\">Dipti Misra Sharma</a>",
          "description": "Neural models excel at extracting statistical patterns from large amounts of\ndata, but struggle to learn patterns or reason about language from only a few\nexamples. In this paper, we ask: Can we learn explicit rules that generalize\nwell from only a few examples? We explore this question using program\nsynthesis. We develop a synthesis model to learn phonology rules as programs in\na domain-specific language. We test the ability of our models to generalize\nfrom few training examples using our new dataset of problems from the\nLinguistics Olympiad, a challenging set of tasks that require strong linguistic\nreasoning ability. In addition to being highly sample-efficient, our approach\ngenerates human-readable programs, and allows control over the generalizability\nof the learnt programs.",
          "link": "http://arxiv.org/abs/2106.06566",
          "publishedOn": "2021-06-15T01:45:13.785Z",
          "wordCount": 554,
          "title": "Sample-efficient Linguistic Generalizations through Program Synthesis: Experiments with Phonology Problems. (arXiv:2106.06566v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06964",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tikhonov_A/0/1/0/all/0/1\">Alexey Tikhonov</a>",
          "description": "Pre-trained word representations became a key component in many NLP tasks.\nHowever, the global geometry of the word embeddings remains poorly understood.\nIn this paper, we demonstrate that a typical word embeddings cloud is shaped as\na high-dimensional simplex with interpretable vertices and propose a simple yet\neffective method for enumeration of these vertices. We show that the proposed\nmethod can detect and describe vertices of the simplex for GloVe and fasttext\nspaces.",
          "link": "http://arxiv.org/abs/2106.06964",
          "publishedOn": "2021-06-15T01:45:13.760Z",
          "wordCount": 514,
          "title": "Shape of Elephant: Study of Macro Properties of Word Embeddings Spaces. (arXiv:2106.06964v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2009.09162",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zeqiu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koncel_Kedziorski_R/0/1/0/all/0/1\">Rik Koncel-Kedziorski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ostendorf_M/0/1/0/all/0/1\">Mari Ostendorf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1\">Hannaneh Hajishirzi</a>",
          "description": "Knowledge graphs capture entities and relations from long documents and can\nfacilitate reasoning in many downstream applications. Extracting compact\nknowledge graphs containing only salient entities and relations is important\nbut challenging for understanding and summarizing long documents. We introduce\na new text-to-graph task of predicting summarized knowledge graphs from long\ndocuments. We develop a dataset of 200k document/graph pairs using automatic\nand human annotations. We also develop strong baselines for this task based on\ngraph learning and text summarization, and provide quantitative and qualitative\nstudies of their effect.",
          "link": "http://arxiv.org/abs/2009.09162",
          "publishedOn": "2021-06-15T01:45:13.751Z",
          "wordCount": 541,
          "title": "Extracting Summary Knowledge Graphs from Long Documents. (arXiv:2009.09162v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06683",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jialu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Eric Wang</a>",
          "description": "Recently pre-trained multimodal models, such as CLIP, have received a surge\nof attention for their exceptional capabilities towards connecting images and\nnatural language. The textual representations in English can be desirably\ntransferred to multilingualism and support promising downstream multimodal\ntasks for different languages. Nevertheless, previous fairness discourse in\nvision-and-language learning mainly focuses on monolingual representational\nbiases, and rarely scrutinizes the principles of multilingual fairness in this\nmultimodal setting, where one language is equated to a group of individuals and\nimages provide the universal grounding for bridging different languages.\n\nIn this paper, we provide a nuanced understanding of individual fairness and\ngroup fairness by viewing language as the recipient of fairness notions. We\ndefine new fairness notions within multilingual context and analytically\narticulate that, pre-trained vision-and-language representations are\nindividually fair across languages but not guaranteed to group fairness.\nFurthermore, we conduct extensive experiments to explore the prevalent group\ndisparity across languages and protected groups including race, gender and age.",
          "link": "http://arxiv.org/abs/2106.06683",
          "publishedOn": "2021-06-15T01:45:13.490Z",
          "wordCount": 593,
          "title": "Assessing Multilingual Fairness in Pre-trained Multimodal Representations. (arXiv:2106.06683v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06910",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_A/0/1/0/all/0/1\">Arunava Kumar Chakraborty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1\">Sourav Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolya_A/0/1/0/all/0/1\">Anup Kumar Kolya</a>",
          "description": "As the Covid-19 outbreaks rapidly all over the world day by day and also\naffects the lives of million, a number of countries declared complete lock-down\nto check its intensity. During this lockdown period, social media plat-forms\nhave played an important role to spread information about this pandemic across\nthe world, as people used to express their feelings through the social\nnetworks. Considering this catastrophic situation, we developed an experimental\napproach to analyze the reactions of people on Twitter taking into ac-count the\npopular words either directly or indirectly based on this pandemic. This paper\nrepresents the sentiment analysis on collected large number of tweets on\nCoronavirus or Covid-19. At first, we analyze the trend of public sentiment on\nthe topics related to Covid-19 epidemic using an evolutionary classification\nfollowed by the n-gram analysis. Then we calculated the sentiment ratings on\ncollected tweet based on their class. Finally, we trained the long-short term\nnetwork using two types of rated tweets to predict sentiment on Covid-19 data\nand obtained an overall accuracy of 84.46%.",
          "link": "http://arxiv.org/abs/2106.06910",
          "publishedOn": "2021-06-15T01:45:13.433Z",
          "wordCount": 680,
          "title": "Sentiment Analysis of Covid-19 Tweets using Evolutionary Classification-Based LSTM Model. (arXiv:2106.06910v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06600",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yasunaga_M/0/1/0/all/0/1\">Michihiro Yasunaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1\">Percy Liang</a>",
          "description": "We consider repair tasks: given a critic (e.g., compiler) that assesses the\nquality of an input, the goal is to train a fixer that converts a bad example\n(e.g., code with syntax errors) into a good one (e.g., code with no errors).\nExisting works create training data consisting of (bad, good) pairs by\ncorrupting good examples using heuristics (e.g., dropping tokens). However,\nfixers trained on this synthetically-generated data do not extrapolate well to\nthe real distribution of bad inputs. To bridge this gap, we propose a new\ntraining approach, Break-It-Fix-It (BIFI), which has two key ideas: (i) we use\nthe critic to check a fixer's output on real bad inputs and add good (fixed)\noutputs to the training data, and (ii) we train a breaker to generate realistic\nbad code from good code. Based on these ideas, we iteratively update the\nbreaker and the fixer while using them in conjunction to generate more paired\ndata. We evaluate BIFI on two code repair datasets: GitHub-Python, a new\ndataset we introduce where the goal is to repair Python code with AST parse\nerrors; and DeepFix, where the goal is to repair C code with compiler errors.\nBIFI outperforms existing methods, obtaining 90.5% repair accuracy on\nGitHub-Python (+28.5%) and 71.7% on DeepFix (+5.6%). Notably, BIFI does not\nrequire any labeled data; we hope it will be a strong starting point for\nunsupervised learning of various repair tasks.",
          "link": "http://arxiv.org/abs/2106.06600",
          "publishedOn": "2021-06-15T01:45:13.411Z",
          "wordCount": 669,
          "title": "Break-It-Fix-It: Unsupervised Learning for Program Repair. (arXiv:2106.06600v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06689",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhousi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Longtu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Imankulova_A/0/1/0/all/0/1\">Aizhan Imankulova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Komachi_M/0/1/0/all/0/1\">Mamoru Komachi</a>",
          "description": "We propose two fast neural combinatory models for constituency parsing:\nbinary and multi-branching. Our models decompose the bottom-up parsing process\ninto 1) classification of tags, labels, and binary orientations or chunks and\n2) vector composition based on the computed orientations or chunks. These\nmodels have theoretical sub-quadratic complexity and empirical linear\ncomplexity. The binary model achieves an F1 score of 92.54 on Penn Treebank,\nspeeding at 1327.2 sents/sec. Both the models with XLNet provide near\nstate-of-the-art accuracies for English. Syntactic branching tendency and\nheadedness of a language are observed during the training and inference\nprocesses for Penn Treebank, Chinese Treebank, and Keyaki Treebank (Japanese).",
          "link": "http://arxiv.org/abs/2106.06689",
          "publishedOn": "2021-06-15T01:45:13.402Z",
          "wordCount": 528,
          "title": "Neural Combinatory Constituency Parsing. (arXiv:2106.06689v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06739",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Siddharth_L/0/1/0/all/0/1\">L Siddharth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blessing_L/0/1/0/all/0/1\">Lucienne T.M. Blessing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wood_K/0/1/0/all/0/1\">Kristin L. Wood</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1\">Jianxi Luo</a>",
          "description": "We propose a large, scalable engineering knowledge graph, comprising sets of\n(entity, relationship, entity) triples that are real-world engineering facts\nfound in the patent database. We apply a set of rules based on the syntactic\nand lexical properties of claims in a patent document to extract facts. We\naggregate these facts within each patent document and integrate the aggregated\nsets of facts across the patent database to obtain the engineering knowledge\ngraph. Such a knowledge graph is expected to support inference, reasoning, and\nrecalling in various engineering tasks. The knowledge graph has a greater size\nand coverage in comparison with the previously used knowledge graphs and\nsemantic networks in the engineering literature.",
          "link": "http://arxiv.org/abs/2106.06739",
          "publishedOn": "2021-06-15T01:45:13.365Z",
          "wordCount": 544,
          "title": "Engineering Knowledge Graph from Patent Database. (arXiv:2106.06739v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06922",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chiu_S/0/1/0/all/0/1\">Shih-Hsuan Chiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lo_T/0/1/0/all/0/1\">Tien-Hong Lo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Berlin Chen</a>",
          "description": "An important research direction in automatic speech recognition (ASR) has\ncentered around the development of effective methods to rerank the output\nhypotheses of an ASR system with more sophisticated language models (LMs) for\nfurther gains. A current mainstream school of thoughts for ASR N-best\nhypothesis reranking is to employ a recurrent neural network (RNN)-based LM or\nits variants, with performance superiority over the conventional n-gram LMs\nacross a range of ASR tasks. In real scenarios such as a long conversation, a\nsequence of consecutive sentences may jointly contain ample cues of\nconversation-level information such as topical coherence, lexical entrainment\nand adjacency pairs, which however remains to be underexplored. In view of\nthis, we first formulate ASR N-best reranking as a prediction problem, putting\nforward an effective cross-sentence neural LM approach that reranks the ASR\nN-best hypotheses of an upcoming sentence by taking into consideration the word\nusage in its precedent sentences. Furthermore, we also explore to extract\ntask-specific global topical information of the cross-sentence history in an\nunsupervised manner for better ASR performance. Extensive experiments conducted\non the AMI conversational benchmark corpus indicate the effectiveness and\nfeasibility of our methods in comparison to several state-of-the-art reranking\nmethods.",
          "link": "http://arxiv.org/abs/2106.06922",
          "publishedOn": "2021-06-15T01:45:13.356Z",
          "wordCount": 645,
          "title": "Cross-sentence Neural Language Models for Conversational Speech Recognition. (arXiv:2106.06922v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06875",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bhatnagar_R/0/1/0/all/0/1\">Rajat Bhatnagar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganesh_A/0/1/0/all/0/1\">Ananya Ganesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kann_K/0/1/0/all/0/1\">Katharina Kann</a>",
          "description": "High-performing machine translation (MT) systems can help overcome language\nbarriers while making it possible for everyone to communicate and use language\ntechnologies in the language of their choice. However, such systems require\nlarge amounts of parallel sentences for training, and translators can be\ndifficult to find and expensive. Here, we present a data collection strategy\nfor MT which, in contrast, is cheap and simple, as it does not require\nbilingual speakers. Based on the insight that humans pay specific attention to\nmovements, we use graphics interchange formats (GIFs) as a pivot to collect\nparallel sentences from monolingual annotators. We use our strategy to collect\ndata in Hindi, Tamil and English. As a baseline, we also collect data using\nimages as a pivot. We perform an intrinsic evaluation by manually evaluating a\nsubset of the sentence pairs and an extrinsic evaluation by finetuning mBART on\nthe collected data. We find that sentences collected via GIFs are indeed of\nhigher quality.",
          "link": "http://arxiv.org/abs/2106.06875",
          "publishedOn": "2021-06-15T01:45:13.316Z",
          "wordCount": 612,
          "title": "Don't Rule Out Monolingual Speakers: A Method For Crowdsourcing Machine Translation Data. (arXiv:2106.06875v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06758",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bar_Haim_R/0/1/0/all/0/1\">Roy Bar-Haim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eden_L/0/1/0/all/0/1\">Lilach Eden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kantor_Y/0/1/0/all/0/1\">Yoav Kantor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Friedman_R/0/1/0/all/0/1\">Roni Friedman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Slonim_N/0/1/0/all/0/1\">Noam Slonim</a>",
          "description": "Previous work on review summarization focused on measuring the sentiment\ntoward the main aspects of the reviewed product or business, or on creating a\ntextual summary. These approaches provide only a partial view of the data:\naspect-based sentiment summaries lack sufficient explanation or justification\nfor the aspect rating, while textual summaries do not quantify the significance\nof each element, and are not well-suited for representing conflicting views.\nRecently, Key Point Analysis (KPA) has been proposed as a summarization\nframework that provides both textual and quantitative summary of the main\npoints in the data. We adapt KPA to review data by introducing Collective Key\nPoint Mining for better key point extraction; integrating sentiment analysis\ninto KPA; identifying good key point candidates for review summaries; and\nleveraging the massive amount of available reviews and their metadata. We show\nempirically that these novel extensions of KPA substantially improve its\nperformance. We demonstrate that promising results can be achieved without any\ndomain-specific annotation, while human supervision can lead to further\nimprovement.",
          "link": "http://arxiv.org/abs/2106.06758",
          "publishedOn": "2021-06-15T01:45:13.307Z",
          "wordCount": 604,
          "title": "Every Bite Is an Experience: Key Point Analysis of Business Reviews. (arXiv:2106.06758v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06731",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_N/0/1/0/all/0/1\">Ning Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Boxin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jinfeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiangyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhouhan Lin</a>",
          "description": "Punctuation restoration is an important post-processing step in automatic\nspeech recognition. Among other kinds of external information, part-of-speech\n(POS) taggers provide informative tags, suggesting each input token's syntactic\nrole, which has been shown to be beneficial for the punctuation restoration\ntask. In this work, we incorporate an external POS tagger and fuse its\npredicted labels into the existing language model to provide syntactic\ninformation. Besides, we propose sequence boundary sampling (SBS) to learn\npunctuation positions more efficiently as a sequence tagging task. Experimental\nresults show that our methods can consistently obtain performance gains and\nachieve a new state-of-the-art on the common IWSLT benchmark. Further ablation\nstudies illustrate that both large pre-trained language models and the external\nPOS tagger take essential parts to improve the model's performance.",
          "link": "http://arxiv.org/abs/2106.06731",
          "publishedOn": "2021-06-15T01:45:13.271Z",
          "wordCount": 559,
          "title": "Incorporating External POS Tagger for Punctuation Restoration. (arXiv:2106.06731v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06822",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yifan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_M/0/1/0/all/0/1\">Min Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Ying Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Min Li</a>",
          "description": "Automatic International Classification of Diseases (ICD) coding is defined as\na kind of text multi-label classification problem, which is difficult because\nthe number of labels is very large and the distribution of labels is\nunbalanced. The label-wise attention mechanism is widely used in automatic ICD\ncoding because it can assign weights to every word in full Electronic Medical\nRecords (EMR) for different ICD codes. However, the label-wise attention\nmechanism is computational redundant and costly. In this paper, we propose a\npseudo label-wise attention mechanism to tackle the problem. Instead of\ncomputing different attention modes for different ICD codes, the pseudo\nlabel-wise attention mechanism automatically merges similar ICD codes and\ncomputes only one attention mode for the similar ICD codes, which greatly\ncompresses the number of attention modes and improves the predicted accuracy.\nIn addition, we apply a more convenient and effective way to obtain the ICD\nvectors, and thus our model can predict new ICD codes by calculating the\nsimilarities between EMR vectors and ICD vectors. Extensive experiments show\nthe superior performance of our model. On the public MIMIC-III dataset and\nprivate Xiangya dataset, our model achieves micro f1 of 0.575 and 0.796,\nrespectively, which outperforms other competing models. Furthermore, we verify\nthe ability of our model in predicting new ICD codes. The case study shows how\npseudo label-wise attention works, and demonstrates the effectiveness of pseudo\nlabel-wise attention mechanism.",
          "link": "http://arxiv.org/abs/2106.06822",
          "publishedOn": "2021-06-15T01:45:13.259Z",
          "wordCount": 658,
          "title": "A Pseudo Label-wise Attention Network for Automatic ICD Coding. (arXiv:2106.06822v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06719",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xing_L/0/1/0/all/0/1\">Linzi Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carenini_G/0/1/0/all/0/1\">Giuseppe Carenini</a>",
          "description": "Dialogue topic segmentation is critical in several dialogue modeling\nproblems. However, popular unsupervised approaches only exploit surface\nfeatures in assessing topical coherence among utterances. In this work, we\naddress this limitation by leveraging supervisory signals from the\nutterance-pair coherence scoring task. First, we present a simple yet effective\nstrategy to generate a training corpus for utterance-pair coherence scoring.\nThen, we train a BERT-based neural utterance-pair coherence model with the\nobtained training corpus. Finally, such model is used to measure the topical\nrelevance between utterances, acting as the basis of the segmentation\ninference. Experiments on three public datasets in English and Chinese\ndemonstrate that our proposal outperforms the state-of-the-art baselines.",
          "link": "http://arxiv.org/abs/2106.06719",
          "publishedOn": "2021-06-15T01:45:13.245Z",
          "wordCount": 539,
          "title": "Improving Unsupervised Dialogue Topic Segmentation with Utterance-Pair Coherence Scoring. (arXiv:2106.06719v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06738",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jinghui Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henchion_M/0/1/0/all/0/1\">Maeve Henchion</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bacher_I/0/1/0/all/0/1\">Ivan Bacher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Namee_B/0/1/0/all/0/1\">Brian Mac Namee</a>",
          "description": "Training deep learning models with limited labelled data is an attractive\nscenario for many NLP tasks, including document classification. While with the\nrecent emergence of BERT, deep learning language models can achieve reasonably\ngood performance in document classification with few labelled instances, there\nis a lack of evidence in the utility of applying BERT-like models on long\ndocument classification. This work introduces a long-text-specific model -- the\nHierarchical BERT Model (HBM) -- that learns sentence-level features of the\ntext and works well in scenarios with limited labelled data. Various evaluation\nexperiments have demonstrated that HBM can achieve higher performance in\ndocument classification than the previous state-of-the-art methods with only 50\nto 200 labelled instances, especially when documents are long. Also, as an\nextra benefit of HBM, the salient sentences identified by learned HBM are\nuseful as explanations for labelling documents based on a user study.",
          "link": "http://arxiv.org/abs/2106.06738",
          "publishedOn": "2021-06-15T01:45:13.232Z",
          "wordCount": 579,
          "title": "A Sentence-level Hierarchical BERT Model for Document Classification with Limited Labelled Data. (arXiv:2106.06738v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.05596",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qi_Z/0/1/0/all/0/1\">Zhiyuan Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Ziheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiaoyan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_Y/0/1/0/all/0/1\">Yuejia Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yefeng Zheng</a>",
          "description": "Knowledge Graph (KG) alignment is to discover the mappings (i.e., equivalent\nentities, relations, and others) between two KGs. The existing methods can be\ndivided into the embedding-based models, and the conventional reasoning and\nlexical matching based systems. The former compute the similarity of entities\nvia their cross-KG embeddings, but they usually rely on an ideal supervised\nlearning setting for good performance and lack appropriate reasoning to avoid\nlogically wrong mappings; while the latter address the reasoning issue but are\npoor at utilizing the KG graph structures and the entity contexts. In this\nstudy, we aim at combining the above two solutions and thus propose an\niterative framework named PRASE which is based on probabilistic reasoning and\nsemantic embedding. It learns the KG embeddings via entity mappings from a\nprobabilistic reasoning system named PARIS, and feeds the resultant entity\nmappings and embeddings back into PARIS for augmentation. The PRASE framework\nis compatible with different embedding-based models, and our experiments on\nmultiple datasets have demonstrated its state-of-the-art performance.",
          "link": "http://arxiv.org/abs/2105.05596",
          "publishedOn": "2021-06-14T01:38:53.094Z",
          "wordCount": 653,
          "title": "Unsupervised Knowledge Graph Alignment by Probabilistic Reasoning and Semantic Embedding. (arXiv:2105.05596v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09680",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Sungjoon Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moon_J/0/1/0/all/0/1\">Jihyung Moon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sungdong Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_W/0/1/0/all/0/1\">Won Ik Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiyoon Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jangwon Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_C/0/1/0/all/0/1\">Chisung Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Junseong Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yongsook Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_T/0/1/0/all/0/1\">Taehwan Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Joohong Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_J/0/1/0/all/0/1\">Juhyun Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_S/0/1/0/all/0/1\">Sungwon Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeong_Y/0/1/0/all/0/1\">Younghoon Jeong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_I/0/1/0/all/0/1\">Inkwon Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seo_S/0/1/0/all/0/1\">Sangwoo Seo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Dongjun Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyunwoo Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1\">Myeonghwa Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jang_S/0/1/0/all/0/1\">Seongbo Jang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Do_S/0/1/0/all/0/1\">Seungwon Do</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sunkyoung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lim_K/0/1/0/all/0/1\">Kyungtae Lim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jongwon Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_K/0/1/0/all/0/1\">Kyumin Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1\">Jamin Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Seonghyun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_L/0/1/0/all/0/1\">Lucy Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_A/0/1/0/all/0/1\">Alice Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ha_J/0/1/0/all/0/1\">Jung-Woo Ha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1\">Kyunghyun Cho</a>",
          "description": "We introduce Korean Language Understanding Evaluation (KLUE) benchmark. KLUE\nis a collection of 8 Korean natural language understanding (NLU) tasks,\nincluding Topic Classification, SemanticTextual Similarity, Natural Language\nInference, Named Entity Recognition, Relation Extraction, Dependency Parsing,\nMachine Reading Comprehension, and Dialogue State Tracking. We build all of the\ntasks from scratch from diverse source corpora while respecting copyrights, to\nensure accessibility for anyone without any restrictions. With ethical\nconsiderations in mind, we carefully design annotation protocols. Along with\nthe benchmark tasks and data, we provide suitable evaluation metrics and\nfine-tuning recipes for pretrained language models for each task. We\nfurthermore release the pretrained language models (PLM), KLUE-BERT and\nKLUE-RoBERTa, to help reproducing baseline models on KLUE and thereby\nfacilitate future research. We make a few interesting observations from the\npreliminary experiments using the proposed KLUE benchmark suite, already\ndemonstrating the usefulness of this new benchmark suite. First, we find\nKLUE-RoBERTa-large outperforms other baselines, including multilingual PLMs and\nexisting open-source Korean PLMs. Second, we see minimal degradation in\nperformance even when we replace personally identifiable information from the\npretraining corpus, suggesting that privacy and NLU capability are not at odds\nwith each other. Lastly, we find that using BPE tokenization in combination\nwith morpheme-level pre-tokenization is effective in tasks involving\nmorpheme-level tagging, detection and generation. In addition to accelerating\nKorean NLP research, our comprehensive documentation on creating KLUE will\nfacilitate creating similar resources for other languages in the future. KLUE\nis available at https://klue-benchmark.com.",
          "link": "http://arxiv.org/abs/2105.09680",
          "publishedOn": "2021-06-14T01:38:52.938Z",
          "wordCount": 765,
          "title": "KLUE: Korean Language Understanding Evaluation. (arXiv:2105.09680v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06462",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hauer_B/0/1/0/all/0/1\">Bradley Hauer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kondrak_G/0/1/0/all/0/1\">Grzegorz Kondrak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luan_Y/0/1/0/all/0/1\">Yixing Luan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mallik_A/0/1/0/all/0/1\">Arnob Mallik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mou_L/0/1/0/all/0/1\">Lili Mou</a>",
          "description": "Acquisition of multilingual training data continues to be a challenge in word\nsense disambiguation (WSD). To address this problem, unsupervised approaches\nhave been developed in recent years that automatically generate sense\nannotations suitable for training supervised WSD systems. We present three new\nmethods to creating sense-annotated corpora, which leverage translations,\nparallel corpora, lexical resources, and contextual and synset embeddings. Our\nsemi-supervised method applies machine translation to transfer existing sense\nannotations to other languages. Our two unsupervised methods use a\nknowledge-based WSD system to annotate a parallel corpus, and refine the\nresulting sense annotations by identifying lexical translations. We obtain\nstate-of-the-art results on standard WSD benchmarks.",
          "link": "http://arxiv.org/abs/2106.06462",
          "publishedOn": "2021-06-14T01:38:52.571Z",
          "wordCount": 530,
          "title": "Semi-Supervised and Unsupervised Sense Annotation via Translations. (arXiv:2106.06462v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06524",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Serie_E/0/1/0/all/0/1\">Emmanuel S&#xe9;ri&#xe9;</a>",
          "description": "Wax is what you put on a surfboard to avoid slipping. It is an essential tool\nto go surfing... We introduce WAX-ML a research-oriented Python library\nproviding tools to design powerful machine learning algorithms and feedback\nloops working on streaming data. It strives to complement JAX with tools\ndedicated to time series. WAX-ML makes JAX-based programs easy to use for\nend-users working with pandas and xarray for data manipulation. It provides a\nsimple mechanism for implementing feedback loops, allows the implementation of\nonline learning and reinforcement learning algorithms with functions, and makes\nthem easy to integrate by end-users working with the object-oriented\nreinforcement learning framework from the Gym library. It is released with an\nApache open-source license on GitHub at https://github.com/eserie/wax-ml.",
          "link": "http://arxiv.org/abs/2106.06524",
          "publishedOn": "2021-06-14T01:38:52.530Z",
          "wordCount": 560,
          "title": "WAX-ML: A Python library for machine learning and feedback loops on streaming data. (arXiv:2106.06524v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06519",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ganesan_K/0/1/0/all/0/1\">Karthik Ganesan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bamdev_P/0/1/0/all/0/1\">Pakhi Bamdev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+B_J/0/1/0/all/0/1\">Jaivarsan B</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venugopal_A/0/1/0/all/0/1\">Amresh Venugopal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tushar_A/0/1/0/all/0/1\">Abhinav Tushar</a>",
          "description": "Spoken Language Understanding (SLU) systems parse speech into semantic\nstructures like dialog acts and slots. This involves the use of an Automatic\nSpeech Recognizer (ASR) to transcribe speech into multiple text alternatives\n(hypotheses). Transcription errors, common in ASRs, impact downstream SLU\nperformance negatively. Approaches to mitigate such errors involve using richer\ninformation from the ASR, either in form of N-best hypotheses or word-lattices.\nWe hypothesize that transformer models learn better with a simpler utterance\nrepresentation using the concatenation of the N-best ASR alternatives, where\neach alternative is separated by a special delimiter [SEP]. In our work, we\ntest our hypothesis by using concatenated N-best ASR alternatives as the input\nto transformer encoder models, namely BERT and XLM-RoBERTa, and achieve\nperformance equivalent to the prior state-of-the-art model on DSTC2 dataset. We\nalso show that our approach significantly outperforms the prior\nstate-of-the-art when subjected to the low data regime. Additionally, this\nmethodology is accessible to users of third-party ASR APIs which do not provide\nword-lattice information.",
          "link": "http://arxiv.org/abs/2106.06519",
          "publishedOn": "2021-06-14T01:38:52.520Z",
          "wordCount": 623,
          "title": "N-Best ASR Transformer: Enhancing SLU Performance using Multiple ASR Hypotheses. (arXiv:2106.06519v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2101.00010",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sinha_K/0/1/0/all/0/1\">Koustuv Sinha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parthasarathi_P/0/1/0/all/0/1\">Prasanna Parthasarathi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pineau_J/0/1/0/all/0/1\">Joelle Pineau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Williams_A/0/1/0/all/0/1\">Adina Williams</a>",
          "description": "Recent investigations into the inner-workings of state-of-the-art large-scale\npre-trained Transformer-based Natural Language Understanding (NLU) models\nindicate that they appear to know humanlike syntax, at least to some extent. We\nprovide novel evidence that complicates this claim: we find that\nstate-of-the-art Natural Language Inference (NLI) models assign the same labels\nto permuted examples as they do to the original, i.e. they are largely\ninvariant to random word-order permutations. This behavior notably differs from\nthat of humans; we struggle with ungrammatical sentences. To measure the\nseverity of this issue, we propose a suite of metrics and investigate which\nproperties of particular permutations lead models to be word-order invariant.\nIn the MNLI dataset, for example, we find almost all (98.7%) examples contain\nat least one permutation which elicits the gold label. Models are sometimes\neven able to assign gold labels to permutations that they originally failed to\npredict correctly. We provide a comprehensive empirical evaluation of this\nphenomenon, and further show that this issue exists for both Transformers and\npre-Transformer RNN / ConvNet based encoders, as well as across multiple\nlanguages (English and Mandarin Chinese). Our code and data are available at\nhttps://github.com/facebookresearch/unlu.",
          "link": "http://arxiv.org/abs/2101.00010",
          "publishedOn": "2021-06-14T01:38:52.464Z",
          "wordCount": 652,
          "title": "UnNatural Language Inference. (arXiv:2101.00010v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.06304",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Parcalabescu_L/0/1/0/all/0/1\">Letitia Parcalabescu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trost_N/0/1/0/all/0/1\">Nils Trost</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frank_A/0/1/0/all/0/1\">Anette Frank</a>",
          "description": "The last years have shown rapid developments in the field of multimodal\nmachine learning, combining e.g., vision, text or speech. In this position\npaper we explain how the field uses outdated definitions of multimodality that\nprove unfit for the machine learning era. We propose a new task-relative\ndefinition of (multi)modality in the context of multimodal machine learning\nthat focuses on representations and information that are relevant for a given\nmachine learning task. With our new definition of multimodality we aim to\nprovide a missing foundation for multimodal research, an important component of\nlanguage grounding and a crucial milestone towards NLU.",
          "link": "http://arxiv.org/abs/2103.06304",
          "publishedOn": "2021-06-14T01:38:52.425Z",
          "wordCount": 582,
          "title": "What is Multimodality?. (arXiv:2103.06304v3 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.10764",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Huang_L/0/1/0/all/0/1\">Lu Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sun_J/0/1/0/all/0/1\">Jingyu Sun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tang_Y/0/1/0/all/0/1\">Yufeng Tang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hou_J/0/1/0/all/0/1\">Junfeng Hou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_J/0/1/0/all/0/1\">Jinkun Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_J/0/1/0/all/0/1\">Jun Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ma_Z/0/1/0/all/0/1\">Zejun Ma</a>",
          "description": "This work describes an encoder pre-training procedure using frame-wise label\nto improve the training of streaming recurrent neural network transducer\n(RNN-T) model. Streaming RNN-T trained from scratch usually performs worse than\nnon-streaming RNN-T. Although it is common to address this issue through\npre-training components of RNN-T with other criteria or frame-wise alignment\nguidance, the alignment is not easily available in end-to-end manner. In this\nwork, frame-wise alignment, used to pre-train streaming RNN-T's encoder, is\ngenerated without using a HMM-based system. Therefore an all-neural framework\nequipping HMM-free encoder pre-training is constructed. This is achieved by\nexpanding the spikes of CTC model to their left/right blank frames, and two\nexpanding strategies are proposed. To our best knowledge, this is the first\nwork to simulate HMM-based frame-wise label using CTC model for pre-training.\nExperiments conducted on LibriSpeech and MLS English tasks show the proposed\npre-training procedure, compared with random initialization, reduces the WER by\nrelatively 5%~11% and the emission latency by 60 ms. Besides, the method is\nlexicon-free, so it is friendly to new languages without manually designed\nlexicon.",
          "link": "http://arxiv.org/abs/2104.10764",
          "publishedOn": "2021-06-14T01:38:52.361Z",
          "wordCount": 642,
          "title": "HMM-Free Encoder Pre-Training for Streaming RNN Transducer. (arXiv:2104.10764v2 [eess.AS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.12249",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bugert_M/0/1/0/all/0/1\">Michael Bugert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reimers_N/0/1/0/all/0/1\">Nils Reimers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>",
          "description": "Cross-document event coreference resolution (CDCR) is an NLP task in which\nmentions of events need to be identified and clustered throughout a collection\nof documents. CDCR aims to benefit downstream multi-document applications, but\ndespite recent progress on corpora and system development, downstream\nimprovements from applying CDCR have not been shown yet. We make the\nobservation that every CDCR system to date was developed, trained, and tested\nonly on a single respective corpus. This raises strong concerns on their\ngeneralizability -- a must-have for downstream applications where the magnitude\nof domains or event mentions is likely to exceed those found in a curated\ncorpus. To investigate this assumption, we define a uniform evaluation setup\ninvolving three CDCR corpora: ECB+, the Gun Violence Corpus and the Football\nCoreference Corpus (which we reannotate on token level to make our analysis\npossible). We compare a corpus-independent, feature-based system against a\nrecent neural system developed for ECB+. Whilst being inferior in absolute\nnumbers, the feature-based system shows more consistent performance across all\ncorpora whereas the neural system is hit-and-miss. Via model introspection, we\nfind that the importance of event actions, event time, etc. for resolving\ncoreference in practice varies greatly between the corpora. Additional analysis\nshows that several systems overfit on the structure of the ECB+ corpus. We\nconclude with recommendations on how to achieve generally applicable CDCR\nsystems in the future -- the most important being that evaluation on multiple\nCDCR corpora is strongly necessary. To facilitate future research, we release\nour dataset, annotation guidelines, and system implementation to the public.",
          "link": "http://arxiv.org/abs/2011.12249",
          "publishedOn": "2021-06-14T01:38:52.119Z",
          "wordCount": 713,
          "title": "Generalizing Cross-Document Event Coreference Resolution Across Multiple Corpora. (arXiv:2011.12249v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06292",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Santy_S/0/1/0/all/0/1\">Sebastin Santy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharya_P/0/1/0/all/0/1\">Prasanta Bhattacharya</a>",
          "description": "Recent advances in AI and ML applications have benefited from rapid progress\nin NLP research. Leaderboards have emerged as a popular mechanism to track and\naccelerate progress in NLP through competitive model development. While this\nhas increased interest and participation, the over-reliance on single, and\naccuracy-based metrics have shifted focus from other important metrics that\nmight be equally pertinent to consider in real-world contexts. In this paper,\nwe offer a preliminary discussion of the risks associated with focusing\nexclusively on accuracy metrics and draw on recent discussions to highlight\nprescriptive suggestions on how to develop more practical and effective\nleaderboards that can better reflect the real-world utility of models.",
          "link": "http://arxiv.org/abs/2106.06292",
          "publishedOn": "2021-06-14T01:38:52.100Z",
          "wordCount": 545,
          "title": "A Discussion on Building Practical NLP Leaderboards: The Case of Machine Translation. (arXiv:2106.06292v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06297",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hombaiah_S/0/1/0/all/0/1\">Spurthi Amba Hombaiah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mingyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bendersky_M/0/1/0/all/0/1\">Michael Bendersky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Najork_M/0/1/0/all/0/1\">Marc Najork</a>",
          "description": "The content on the web is in a constant state of flux. New entities, issues,\nand ideas continuously emerge, while the semantics of the existing conversation\ntopics gradually shift. In recent years, pre-trained language models like BERT\ngreatly improved the state-of-the-art for a large spectrum of content\nunderstanding tasks. Therefore, in this paper, we aim to study how these\nlanguage models can be adapted to better handle continuously evolving web\ncontent. In our study, we first analyze the evolution of 2013 - 2019 Twitter\ndata, and unequivocally confirm that a BERT model trained on past tweets would\nheavily deteriorate when directly applied to data from later years. Then, we\ninvestigate two possible sources of the deterioration: the semantic shift of\nexisting tokens and the sub-optimal or failed understanding of new tokens. To\nthis end, we both explore two different vocabulary composition methods, as well\nas propose three sampling methods which help in efficient incremental training\nfor BERT-like models. Compared to a new model trained from scratch offline, our\nincremental training (a) reduces the training costs, (b) achieves better\nperformance on evolving content, and (c) is suitable for online deployment. The\nsuperiority of our methods is validated using two downstream tasks. We\ndemonstrate significant improvements when incrementally evolving the model from\na particular base year, on the task of Country Hashtag Prediction, as well as\non the OffensEval 2019 task.",
          "link": "http://arxiv.org/abs/2106.06297",
          "publishedOn": "2021-06-14T01:38:52.068Z",
          "wordCount": 666,
          "title": "Dynamic Language Models for Continuously Evolving Content. (arXiv:2106.06297v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2012.07551",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kamper_H/0/1/0/all/0/1\">Herman Kamper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niekerk_B/0/1/0/all/0/1\">Benjamin van Niekerk</a>",
          "description": "We investigate segmenting and clustering speech into low-bitrate phone-like\nsequences without supervision. We specifically constrain pretrained\nself-supervised vector-quantized (VQ) neural networks so that blocks of\ncontiguous feature vectors are assigned to the same code, thereby giving a\nvariable-rate segmentation of the speech into discrete units. Two segmentation\nmethods are considered. In the first, features are greedily merged until a\nprespecified number of segments are reached. The second uses dynamic\nprogramming to optimize a squared error with a penalty term to encourage fewer\nbut longer segments. We show that these VQ segmentation methods can be used\nwithout alteration across a wide range of tasks: unsupervised phone\nsegmentation, ABX phone discrimination, same-different word discrimination, and\nas inputs to a symbolic word segmentation algorithm. The penalized dynamic\nprogramming method generally performs best. While performance on individual\ntasks is only comparable to the state-of-the-art in some cases, in all tasks a\nreasonable competing approach is outperformed at a substantially lower bitrate.",
          "link": "http://arxiv.org/abs/2012.07551",
          "publishedOn": "2021-06-14T01:38:52.061Z",
          "wordCount": 626,
          "title": "Towards unsupervised phone and word segmentation using self-supervised vector-quantized neural networks. (arXiv:2012.07551v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.05489",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yufan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yanzhe Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiaao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xuezhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Diyi Yang</a>",
          "description": "Continual learning has become increasingly important as it enables NLP models\nto constantly learn and gain knowledge over time. Previous continual learning\nmethods are mainly designed to preserve knowledge from previous tasks, without\nmuch emphasis on how to well generalize models to new tasks. In this work, we\npropose an information disentanglement based regularization method for\ncontinual learning on text classification. Our proposed method first\ndisentangles text hidden spaces into representations that are generic to all\ntasks and representations specific to each individual task, and further\nregularizes these representations differently to better constrain the knowledge\nrequired to generalize. We also introduce two simple auxiliary tasks: next\nsentence prediction and task-id prediction, for learning better generic and\nspecific representation spaces. Experiments conducted on large-scale benchmarks\ndemonstrate the effectiveness of our method in continual text classification\ntasks with various sequences and lengths over state-of-the-art baselines. We\nhave publicly released our code at https://github.com/GT-SALT/IDBR.",
          "link": "http://arxiv.org/abs/2104.05489",
          "publishedOn": "2021-06-14T01:38:52.028Z",
          "wordCount": 620,
          "title": "Continual Learning for Text Classification with Information Disentanglement Based Regularization. (arXiv:2104.05489v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06363",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Scialom_T/0/1/0/all/0/1\">Thomas Scialom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dray_P/0/1/0/all/0/1\">Paul-Alexis Dray</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lamprier_S/0/1/0/all/0/1\">Sylvain Lamprier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piwowarski_B/0/1/0/all/0/1\">Benjamin Piwowarski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Staiano_J/0/1/0/all/0/1\">Jacopo Staiano</a>",
          "description": "Due to the discrete nature of words, language GANs require to be optimized\nfrom rewards provided by discriminator networks, via reinforcement learning\nmethods. This is a much harder setting than for continuous tasks, which enjoy\ngradient flows from discriminators to generators, usually leading to dramatic\nlearning instabilities. However, we claim that this can be solved by making\ndiscriminator and generator networks cooperate to produce output sequences\nduring training. These cooperative outputs, inherently built to obtain higher\ndiscrimination scores, not only provide denser rewards for training, but also\nform a more compact artificial set for discriminator training, hence improving\nits accuracy and stability. In this paper, we show that our SelfGAN framework,\nbuilt on this cooperative principle, outperforms Teacher Forcing and obtains\nstate-of-the-art results on two challenging tasks, Summarization and Question\nGeneration.",
          "link": "http://arxiv.org/abs/2106.06363",
          "publishedOn": "2021-06-14T01:38:52.020Z",
          "wordCount": 577,
          "title": "To Beam Or Not To Beam: That is a Question of Cooperation for Language GANs. (arXiv:2106.06363v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06381",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chi_Z/0/1/0/all/0/1\">Zewen Chi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_L/0/1/0/all/0/1\">Li Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_B/0/1/0/all/0/1\">Bo Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shaohan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_X/0/1/0/all/0/1\">Xian-Ling Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Heyan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>",
          "description": "The cross-lingual language models are typically pretrained with masked\nlanguage modeling on multilingual text or parallel sentences. In this paper, we\nintroduce denoising word alignment as a new cross-lingual pre-training task.\nSpecifically, the model first self-labels word alignments for parallel\nsentences. Then we randomly mask tokens in a bitext pair. Given a masked token,\nthe model uses a pointer network to predict the aligned token in the other\nlanguage. We alternately perform the above two steps in an\nexpectation-maximization manner. Experimental results show that our method\nimproves cross-lingual transferability on various datasets, especially on the\ntoken-level tasks, such as question answering, and structured prediction.\nMoreover, the model can serve as a pretrained word aligner, which achieves\nreasonably low error rates on the alignment benchmarks. The code and pretrained\nparameters are available at https://github.com/CZWin32768/XLM-Align.",
          "link": "http://arxiv.org/abs/2106.06381",
          "publishedOn": "2021-06-14T01:38:51.995Z",
          "wordCount": 571,
          "title": "Improving Pretrained Cross-Lingual Language Models via Self-Labeled Word Alignment. (arXiv:2106.06381v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06471",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xingyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_M/0/1/0/all/0/1\">Muchao Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_Q/0/1/0/all/0/1\">Quanzeng You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_F/0/1/0/all/0/1\">Fenglong Ma</a>",
          "description": "Medical report generation is one of the most challenging tasks in medical\nimage analysis. Although existing approaches have achieved promising results,\nthey either require a predefined template database in order to retrieve\nsentences or ignore the hierarchical nature of medical report generation. To\naddress these issues, we propose MedWriter that incorporates a novel\nhierarchical retrieval mechanism to automatically extract both report and\nsentence-level templates for clinically accurate report generation. MedWriter\nfirst employs the Visual-Language Retrieval~(VLR) module to retrieve the most\nrelevant reports for the given images. To guarantee the logical coherence\nbetween sentences, the Language-Language Retrieval~(LLR) module is introduced\nto retrieve relevant sentences based on the previous generated description. At\nlast, a language decoder fuses image features and features from retrieved\nreports and sentences to generate meaningful medical reports. We verified the\neffectiveness of our model by automatic evaluation and human evaluation on two\ndatasets, i.e., Open-I and MIMIC-CXR.",
          "link": "http://arxiv.org/abs/2106.06471",
          "publishedOn": "2021-06-14T01:38:51.979Z",
          "wordCount": 592,
          "title": "Writing by Memorizing: Hierarchical Retrieval-based Medical Report Generation. (arXiv:2106.06471v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06411",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hazarika_D/0/1/0/all/0/1\">Devamanyu Hazarika</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Namazifar_M/0/1/0/all/0/1\">Mahdi Namazifar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hakkani_Tur_D/0/1/0/all/0/1\">Dilek Hakkani-T&#xfc;r</a>",
          "description": "Controlling neural network-based models for natural language generation (NLG)\nhas broad applications in numerous areas such as machine translation, document\nsummarization, and dialog systems. Approaches that enable such control in a\nzero-shot manner would be of great importance as, among other reasons, they\nremove the need for additional annotated data and training. In this work, we\npropose novel approaches for controlling encoder-decoder transformer-based NLG\nmodels in a zero-shot manner. This is done by introducing three control knobs;\nnamely, attention biasing, decoder mixing, and context augmentation, that are\napplied to these models at generation time. These knobs control the generation\nprocess by directly manipulating trained NLG models (e.g., biasing\ncross-attention layers) to realize the desired attributes in the generated\noutputs. We show that not only are these NLG models robust to such\nmanipulations, but also their behavior could be controlled without an impact on\ntheir generation performance. These results, to the best of our knowledge, are\nthe first of their kind. Through these control knobs, we also investigate the\nrole of transformer decoder's self-attention module and show strong evidence\nthat its primary role is maintaining fluency of sentences generated by these\nmodels. Based on this hypothesis, we show that alternative architectures for\ntransformer decoders could be viable options. We also study how this hypothesis\ncould lead to more efficient ways for training encoder-decoder transformer\nmodels.",
          "link": "http://arxiv.org/abs/2106.06411",
          "publishedOn": "2021-06-14T01:38:51.963Z",
          "wordCount": 648,
          "title": "Zero-Shot Controlled Generation with Encoder-Decoder Transformers. (arXiv:2106.06411v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06528",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tuan_Y/0/1/0/all/0/1\">Yi-Lin Tuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pryor_C/0/1/0/all/0/1\">Connor Pryor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wenhu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Getoor_L/0/1/0/all/0/1\">Lise Getoor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>",
          "description": "In comparison to the interpretation of classification models, the explanation\nof sequence generation models is also an important problem, however it has seen\nlittle attention. In this work, we study model-agnostic explanations of a\nrepresentative text generation task -- dialogue response generation. Dialog\nresponse generation is challenging with its open-ended sentences and multiple\nacceptable responses. To gain insights into the reasoning process of a\ngeneration model, we propose anew method, local explanation of response\ngeneration (LERG) that regards the explanations as the mutual interaction of\nsegments in input and output sentences. LERG views the sequence prediction as\nuncertainty estimation of a human response and then creates explanations by\nperturbing the input and calculating the certainty change over the human\nresponse. We show that LERG adheres to desired properties of explanations for\ntext generation including unbiased approximation, consistency and cause\nidentification. Empirically, our results show that our method consistently\nimproves other widely used methods on proposed automatic- and human- evaluation\nmetrics for this new task by 4.4-12.8%. Our analysis demonstrates that LERG can\nextract both explicit and implicit relations between input and output segments.",
          "link": "http://arxiv.org/abs/2106.06528",
          "publishedOn": "2021-06-14T01:38:51.956Z",
          "wordCount": 613,
          "title": "Local Explanation of Dialogue Response Generation. (arXiv:2106.06528v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06504",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gervits_F/0/1/0/all/0/1\">Felix Gervits</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roque_A/0/1/0/all/0/1\">Antonio Roque</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Briggs_G/0/1/0/all/0/1\">Gordon Briggs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scheutz_M/0/1/0/all/0/1\">Matthias Scheutz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marge_M/0/1/0/all/0/1\">Matthew Marge</a>",
          "description": "Intelligent agents that are confronted with novel concepts in situated\nenvironments will need to ask their human teammates questions to learn about\nthe physical world. To better understand this problem, we need data about\nasking questions in situated task-based interactions. To this end, we present\nthe Human-Robot Dialogue Learning (HuRDL) Corpus - a novel dialogue corpus\ncollected in an online interactive virtual environment in which human\nparticipants play the role of a robot performing a collaborative\ntool-organization task. We describe the corpus data and a corresponding\nannotation scheme to offer insight into the form and content of questions that\nhumans ask to facilitate learning in a situated environment. We provide the\ncorpus as an empirically-grounded resource for improving question generation in\nsituated intelligent agents.",
          "link": "http://arxiv.org/abs/2106.06504",
          "publishedOn": "2021-06-14T01:38:51.937Z",
          "wordCount": 580,
          "title": "How Should Agents Ask Questions For Situated Learning? An Annotated Dialogue Corpus. (arXiv:2106.06504v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2102.05918",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jia_C/0/1/0/all/0/1\">Chao Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yinfei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1\">Ye Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yi-Ting Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parekh_Z/0/1/0/all/0/1\">Zarana Parekh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pham_H/0/1/0/all/0/1\">Hieu Pham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1\">Quoc V. Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sung_Y/0/1/0/all/0/1\">Yunhsuan Sung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duerig_T/0/1/0/all/0/1\">Tom Duerig</a>",
          "description": "Pre-trained representations are becoming crucial for many NLP and perception\ntasks. While representation learning in NLP has transitioned to training on raw\ntext without human annotations, visual and vision-language representations\nstill rely heavily on curated training datasets that are expensive or require\nexpert knowledge. For vision applications, representations are mostly learned\nusing datasets with explicit class labels such as ImageNet or OpenImages. For\nvision-language, popular datasets like Conceptual Captions, MSCOCO, or CLIP all\ninvolve a non-trivial data collection (and cleaning) process. This costly\ncuration process limits the size of datasets and hence hinders the scaling of\ntrained models. In this paper, we leverage a noisy dataset of over one billion\nimage alt-text pairs, obtained without expensive filtering or post-processing\nsteps in the Conceptual Captions dataset. A simple dual-encoder architecture\nlearns to align visual and language representations of the image and text pairs\nusing a contrastive loss. We show that the scale of our corpus can make up for\nits noise and leads to state-of-the-art representations even with such a simple\nlearning scheme. Our visual representation achieves strong performance when\ntransferred to classification tasks such as ImageNet and VTAB. The aligned\nvisual and language representations enables zero-shot image classification and\nalso set new state-of-the-art results on Flickr30K and MSCOCO image-text\nretrieval benchmarks, even when compared with more sophisticated\ncross-attention models. The representations also enable cross-modality search\nwith complex text and text + image queries.",
          "link": "http://arxiv.org/abs/2102.05918",
          "publishedOn": "2021-06-14T01:38:51.931Z",
          "wordCount": 733,
          "title": "Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision. (arXiv:2102.05918v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06233",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jingbei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Y/0/1/0/all/0/1\">Yi Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chenyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhiyong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_H/0/1/0/all/0/1\">Helen Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weng_C/0/1/0/all/0/1\">Chao Weng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_D/0/1/0/all/0/1\">Dan Su</a>",
          "description": "For conversational text-to-speech (TTS) systems, it is vital that the systems\ncan adjust the spoken styles of synthesized speech according to different\ncontent and spoken styles in historical conversations. However, the study about\nlearning spoken styles from historical conversations is still in its infancy.\nOnly the transcripts of the historical conversations are considered, which\nneglects the spoken styles in historical speeches. Moreover, only the\ninteractions of the global aspect between speakers are modeled, missing the\nparty aspect self interactions inside each speaker. In this paper, to achieve\nbetter spoken style learning for conversational TTS, we propose a spoken style\nlearning approach with multi-modal hierarchical context encoding. The textual\ninformation and spoken styles in the historical conversations are processed\nthrough multiple hierarchical recurrent neural networks to learn the spoken\nstyle related features in global and party aspects. The attention mechanism is\nfurther employed to summarize these features into a conversational context\nencoding. Experimental results demonstrate the effectiveness of our proposed\napproach, which outperform a baseline method using context encoding learnt only\nfrom the transcripts in global aspects, with MOS score on the naturalness of\nsynthesized speech increasing from 3.138 to 3.408 and ABX preference rate\nexceeding the baseline method by 36.45%.",
          "link": "http://arxiv.org/abs/2106.06233",
          "publishedOn": "2021-06-14T01:38:51.923Z",
          "wordCount": 647,
          "title": "Spoken Style Learning with Multi-modal Hierarchical Context Encoding for Conversational Text-to-Speech Synthesis. (arXiv:2106.06233v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2102.09690",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tony Z. Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wallace_E/0/1/0/all/0/1\">Eric Wallace</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1\">Shi Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klein_D/0/1/0/all/0/1\">Dan Klein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Sameer Singh</a>",
          "description": "GPT-3 can perform numerous tasks when provided a natural language prompt that\ncontains a few training examples. We show that this type of few-shot learning\ncan be unstable: the choice of prompt format, training examples, and even the\norder of the training examples can cause accuracy to vary from near chance to\nnear state-of-the-art. We demonstrate that this instability arises from the\nbias of language models towards predicting certain answers, e.g., those that\nare placed near the end of the prompt or are common in the pre-training data.\nTo mitigate this, we first estimate the model's bias towards each answer by\nasking for its prediction when given the training prompt and a content-free\ntest input such as \"N/A\". We then fit calibration parameters that cause the\nprediction for this input to be uniform across answers. On a diverse set of\ntasks, this contextual calibration procedure substantially improves GPT-3 and\nGPT-2's average accuracy (up to 30.0% absolute) and reduces variance across\ndifferent choices of the prompt.",
          "link": "http://arxiv.org/abs/2102.09690",
          "publishedOn": "2021-06-14T01:38:51.916Z",
          "wordCount": 632,
          "title": "Calibrate Before Use: Improving Few-Shot Performance of Language Models. (arXiv:2102.09690v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06230",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Peinl_R/0/1/0/all/0/1\">Ren&#xe9; Peinl</a>",
          "description": "Reading text aloud is an important feature for modern computer applications.\nIt not only facilitates access to information for visually impaired people, but\nis also a pleasant convenience for non-impaired users. In this article, the\nstate of the art of speech synthesis is presented separately for\nmel-spectrogram generation and vocoders. It concludes with an overview of\navailable data sets for English and German with a discussion of the\ntransferability of the good speech synthesis results from English to German\nlanguage.",
          "link": "http://arxiv.org/abs/2106.06230",
          "publishedOn": "2021-06-14T01:38:51.907Z",
          "wordCount": 505,
          "title": "Sprachsynthese -- State-of-the-Art in englischer und deutscher Sprache. (arXiv:2106.06230v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06361",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qi_F/0/1/0/all/0/1\">Fanchao Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yuan Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Sophia Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>",
          "description": "Recent studies show that neural natural language processing (NLP) models are\nvulnerable to backdoor attacks. Injected with backdoors, models perform\nnormally on benign examples but produce attacker-specified predictions when the\nbackdoor is activated, presenting serious security threats to real-world\napplications. Since existing textual backdoor attacks pay little attention to\nthe invisibility of backdoors, they can be easily detected and blocked. In this\nwork, we present invisible backdoors that are activated by a learnable\ncombination of word substitution. We show that NLP models can be injected with\nbackdoors that lead to a nearly 100% attack success rate, whereas being highly\ninvisible to existing defense strategies and even human inspections. The\nresults raise a serious alarm to the security of NLP models, which requires\nfurther research to be resolved. All the data and code of this paper are\nreleased at https://github.com/thunlp/BkdAtk-LWS.",
          "link": "http://arxiv.org/abs/2106.06361",
          "publishedOn": "2021-06-14T01:38:51.881Z",
          "wordCount": 593,
          "title": "Turn the Combination Lock: Learnable Textual Backdoor Attacks via Word Substitution. (arXiv:2106.06361v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09043",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Do_P/0/1/0/all/0/1\">Phong Nguyen-Thuan Do</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1\">Nhat Duy Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huynh_T/0/1/0/all/0/1\">Tin Van Huynh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1\">Kiet Van Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1\">Anh Gia-Tuan Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1\">Ngan Luu-Thuy Nguyen</a>",
          "description": "The development of natural language processing (NLP) in general and machine\nreading comprehension in particular has attracted the great attention of the\nresearch community. In recent years, there are a few datasets for machine\nreading comprehension tasks in Vietnamese with large sizes, such as UIT-ViQuAD\nand UIT-ViNewsQA. However, the datasets are not diverse in answers to serve the\nresearch. In this paper, we introduce UIT-ViWikiQA, the first dataset for\nevaluating sentence extraction-based machine reading comprehension in the\nVietnamese language. The UIT-ViWikiQA dataset is converted from the UIT-ViQuAD\ndataset, consisting of comprises 23.074 question-answers based on 5.109\npassages of 174 Wikipedia Vietnamese articles. We propose a conversion\nalgorithm to create the dataset for sentence extraction-based machine reading\ncomprehension and three types of approaches for sentence extraction-based\nmachine reading comprehension in Vietnamese. Our experiments show that the best\nmachine model is XLM-R_Large, which achieves an exact match (EM) of 85.97% and\nan F1-score of 88.77% on our dataset. Besides, we analyze experimental results\nin terms of the question type in Vietnamese and the effect of context on the\nperformance of the MRC models, thereby showing the challenges from the\nUIT-ViWikiQA dataset that we propose to the language processing community.",
          "link": "http://arxiv.org/abs/2105.09043",
          "publishedOn": "2021-06-14T01:38:51.870Z",
          "wordCount": 667,
          "title": "Sentence Extraction-Based Machine Reading Comprehension for Vietnamese. (arXiv:2105.09043v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06247",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jean Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Youn_H/0/1/0/all/0/1\">Hoyoul Luis Youn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stevens_N/0/1/0/all/0/1\">Nicholas Stevens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poon_J/0/1/0/all/0/1\">Josiah Poon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Soyeon Caren Han</a>",
          "description": "The Federal Reserve System (the Fed) plays a significant role in affecting\nmonetary policy and financial conditions worldwide. Although it is important to\nanalyse the Fed's communications to extract useful information, it is generally\nlong-form and complex due to the ambiguous and esoteric nature of content. In\nthis paper, we present FedNLP, an interpretable multi-component Natural\nLanguage Processing system to decode Federal Reserve communications. This\nsystem is designed for end-users to explore how NLP techniques can assist their\nholistic understanding of the Fed's communications with NO coding. Behind the\nscenes, FedNLP uses multiple NLP models from traditional machine learning\nalgorithms to deep neural network architectures in each downstream task. The\ndemonstration shows multiple results at once including sentiment analysis,\nsummary of the document, prediction of the Federal Funds Rate movement and\nvisualization for interpreting the prediction model's result.",
          "link": "http://arxiv.org/abs/2106.06247",
          "publishedOn": "2021-06-14T01:38:51.846Z",
          "wordCount": 583,
          "title": "FedNLP: An interpretable NLP System to Decode Federal Reserve Communications. (arXiv:2106.06247v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06309",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Puchtler_P/0/1/0/all/0/1\">Pascal Puchtler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wirth_J/0/1/0/all/0/1\">Johannes Wirth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peinl_R/0/1/0/all/0/1\">Ren&#xe9; Peinl</a>",
          "description": "The increasing availability of audio data on the internet lead to a multitude\nof datasets for development and training of text to speech applications, based\non neural networks. Highly differing quality of voice, low sampling rates, lack\nof text normalization and disadvantageous alignment of audio samples to\ncorresponding transcript sentences still limit the performance of deep neural\nnetworks trained on this task. Additionally, data resources in languages like\nGerman are still very limited. We introduce the \"HUI-Audio-Corpus-German\", a\nlarge, open-source dataset for TTS engines, created with a processing pipeline,\nwhich produces high quality audio to transcription alignments and decreases\nmanual effort needed for creation.",
          "link": "http://arxiv.org/abs/2106.06309",
          "publishedOn": "2021-06-14T01:38:51.825Z",
          "wordCount": 530,
          "title": "HUI-Audio-Corpus-German: A high quality TTS dataset. (arXiv:2106.06309v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06183",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ray_S/0/1/0/all/0/1\">Swayambhu Nath Ray</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mitra_S/0/1/0/all/0/1\">Soumyajit Mitra</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bilgi_R/0/1/0/all/0/1\">Raghavendra Bilgi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Garimella_S/0/1/0/all/0/1\">Sri Garimella</a>",
          "description": "In this paper, we explore the benefits of incorporating context into a\nRecurrent Neural Network (RNN-T) based Automatic Speech Recognition (ASR) model\nto improve the speech recognition for virtual assistants. Specifically, we use\nmeta information extracted from the time at which the utterance is spoken and\nthe approximate location information to make ASR context aware. We show that\nthese contextual information, when used individually, improves overall\nperformance by as much as 3.48% relative to the baseline and when the contexts\nare combined, the model learns complementary features and the recognition\nimproves by 4.62%. On specific domains, these contextual signals show\nimprovements as high as 11.5%, without any significant degradation on others.\nWe ran experiments with models trained on data of sizes 30K hours and 10K\nhours. We show that the scale of improvement with the 10K hours dataset is much\nhigher than the one obtained with 30K hours dataset. Our results indicate that\nwith limited data to train the ASR model, contextual signals can improve the\nperformance significantly.",
          "link": "http://arxiv.org/abs/2106.06183",
          "publishedOn": "2021-06-14T01:38:51.757Z",
          "wordCount": 619,
          "title": "Improving RNN-T ASR Performance with Date-Time and Location Awareness. (arXiv:2106.06183v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06216",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Waldis_A/0/1/0/all/0/1\">Andreas Waldis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mazzola_L/0/1/0/all/0/1\">Luca Mazzola</a>",
          "description": "Entity Recognition (ER) within a text is a fundamental exercise in Natural\nLanguage Processing, enabling further depending tasks such as Knowledge\nExtraction, Text Summarisation, or Keyphrase Extraction. An entity consists of\nsingle words or of a consecutive sequence of terms, constituting the basic\nbuilding blocks for communication. Mainstream ER approaches are mainly limited\nto flat structures, concentrating on the outermost entities while ignoring the\ninner ones. This paper introduces a partly-layered network architecture that\ndeals with the complexity of overlapping and nested cases. The proposed\narchitecture consists of two parts: (1) a shared Sequence Layer and (2) a\nstacked component with multiple Tagging Layers. The adoption of such an\narchitecture has the advantage of preventing overfit to a specific word-length,\nthus maintaining performance for longer entities despite their lower frequency.\nTo verify the proposed architecture's effectiveness, we train and evaluate this\narchitecture to recognise two kinds of entities - Concepts (CR) and Named\nEntities (NER). Our approach achieves state-of-the-art NER performances, while\nit outperforms previous CR approaches. Considering these promising results, we\nsee the possibility to evolve the architecture for other cases such as the\nextraction of events or the detection of argumentative components.",
          "link": "http://arxiv.org/abs/2106.06216",
          "publishedOn": "2021-06-14T01:38:51.705Z",
          "wordCount": 635,
          "title": "Nested and Balanced Entity Recognition using Multi-Task Learning. (arXiv:2106.06216v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06200",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Huan Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_L/0/1/0/all/0/1\">Liang Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1\">Baosong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1\">Dayiheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Haibo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_W/0/1/0/all/0/1\">Weihua Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1\">Degen Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1\">Jinsong Su</a>",
          "description": "A good translation should not only translate the original content\nsemantically, but also incarnate personal traits of the original text. For a\nreal-world neural machine translation (NMT) system, these user traits (e.g.,\ntopic preference, stylistic characteristics and expression habits) can be\npreserved in user behavior (e.g., historical inputs). However, current NMT\nsystems marginally consider the user behavior due to: 1) the difficulty of\nmodeling user portraits in zero-shot scenarios, and 2) the lack of\nuser-behavior annotated parallel dataset. To fill this gap, we introduce a\nnovel framework called user-driven NMT. Specifically, a cache-based module and\na user-driven contrastive learning method are proposed to offer NMT the ability\nto capture potential user traits from their historical inputs under a zero-shot\nlearning fashion. Furthermore, we contribute the first Chinese-English parallel\ncorpus annotated with user behavior called UDT-Corpus. Experimental results\nconfirm that the proposed user-driven NMT can generate user-specific\ntranslations.",
          "link": "http://arxiv.org/abs/2106.06200",
          "publishedOn": "2021-06-14T01:38:51.697Z",
          "wordCount": 574,
          "title": "Towards User-Driven Neural Machine Translation. (arXiv:2106.06200v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06213",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weld_H/0/1/0/all/0/1\">Henry Weld</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1\">Guanghao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jean Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tongshu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Kunze Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1\">Xinghong Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_S/0/1/0/all/0/1\">Siqu Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poon_J/0/1/0/all/0/1\">Josiah Poon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Soyeon Caren Han</a>",
          "description": "Traditional toxicity detection models have focused on the single utterance\nlevel without deeper understanding of context. We introduce CONDA, a new\ndataset for in-game toxic language detection enabling joint intent\nclassification and slot filling analysis, which is the core task of Natural\nLanguage Understanding (NLU). The dataset consists of 45K utterances from 12K\nconversations from the chat logs of 1.9K completed Dota 2 matches. We propose a\nrobust dual semantic-level toxicity framework, which handles utterance and\ntoken-level patterns, and rich contextual chatting history. Accompanying the\ndataset is a thorough in-game toxicity analysis, which provides comprehensive\nunderstanding of context at utterance, token, and dual levels. Inspired by NLU,\nwe also apply its metrics to the toxicity detection tasks for assessing\ntoxicity and game-specific aspects. We evaluate strong NLU models on CONDA,\nproviding fine-grained results for different intent classes and slot classes.\nFurthermore, we examine the coverage of toxicity nature in our dataset by\ncomparing it with other toxicity datasets.",
          "link": "http://arxiv.org/abs/2106.06213",
          "publishedOn": "2021-06-14T01:38:51.652Z",
          "wordCount": 604,
          "title": "CONDA: a CONtextual Dual-Annotated dataset for in-game toxicity understanding and detection. (arXiv:2106.06213v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06228",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Bo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xin_C/0/1/0/all/0/1\">Chunlei Xin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xianpei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Le Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Weipeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiansong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1\">Fan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_X/0/1/0/all/0/1\">Xunliang Cai</a>",
          "description": "Semantic parsing is challenging due to the structure gap and the semantic gap\nbetween utterances and logical forms. In this paper, we propose an unsupervised\nsemantic parsing method - Synchronous Semantic Decoding (SSD), which can\nsimultaneously resolve the semantic gap and the structure gap by jointly\nleveraging paraphrasing and grammar constrained decoding. Specifically, we\nreformulate semantic parsing as a constrained paraphrasing problem: given an\nutterance, our model synchronously generates its canonical utterance and\nmeaning representation. During synchronous decoding: the utterance paraphrasing\nis constrained by the structure of the logical form, therefore the canonical\nutterance can be paraphrased controlledly; the semantic decoding is guided by\nthe semantics of the canonical utterance, therefore its logical form can be\ngenerated unsupervisedly. Experimental results show that SSD is a promising\napproach and can achieve competitive unsupervised semantic parsing performance\non multiple datasets.",
          "link": "http://arxiv.org/abs/2106.06228",
          "publishedOn": "2021-06-14T01:38:51.627Z",
          "wordCount": 586,
          "title": "From Paraphrasing to Semantic Parsing: Unsupervised Semantic Parsing via Synchronous Semantic Decoding. (arXiv:2106.06228v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06169",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1\">Haoyu Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kaiyan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wei-Nan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Ting Liu</a>",
          "description": "Maintaining consistent personas is essential for dialogue agents. Although\ntremendous advancements have been brought, the limited-scale of annotated\npersona-dense data are still barriers towards training robust and consistent\npersona-based dialogue models. In this work, we show how the challenges can be\naddressed by disentangling persona-based dialogue generation into two sub-tasks\nwith a novel BERT-over-BERT (BoB) model. Specifically, the model consists of a\nBERT-based encoder and two BERT-based decoders, where one decoder is for\nresponse generation, and another is for consistency understanding. In\nparticular, to learn the ability of consistency understanding from large-scale\nnon-dialogue inference data, we train the second decoder in an unlikelihood\nmanner. Under different limited data settings, both automatic and human\nevaluations demonstrate that the proposed model outperforms strong baselines in\nresponse quality and persona consistency.",
          "link": "http://arxiv.org/abs/2106.06169",
          "publishedOn": "2021-06-14T01:38:51.568Z",
          "wordCount": 575,
          "title": "BoB: BERT Over BERT for Training Persona-based Dialogue Models from Limited Personalized Data. (arXiv:2106.06169v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06132",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lal_Y/0/1/0/all/0/1\">Yash Kumar Lal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chambers_N/0/1/0/all/0/1\">Nathanael Chambers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mooney_R/0/1/0/all/0/1\">Raymond Mooney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balasubramanian_N/0/1/0/all/0/1\">Niranjan Balasubramanian</a>",
          "description": "Answering questions about why characters perform certain actions is central\nto understanding and reasoning about narratives. Despite recent progress in QA,\nit is not clear if existing models have the ability to answer \"why\" questions\nthat may require commonsense knowledge external to the input narrative. In this\nwork, we introduce TellMeWhy, a new crowd-sourced dataset that consists of more\nthan 30k questions and free-form answers concerning why characters in short\nnarratives perform the actions described. For a third of this dataset, the\nanswers are not present within the narrative. Given the limitations of\nautomated evaluation for this task, we also present a systematized human\nevaluation interface for this dataset. Our evaluation of state-of-the-art\nmodels show that they are far below human performance on answering such\nquestions. They are especially worse on questions whose answers are external to\nthe narrative, thus providing a challenge for future QA and narrative\nunderstanding research.",
          "link": "http://arxiv.org/abs/2106.06132",
          "publishedOn": "2021-06-14T01:38:51.559Z",
          "wordCount": 590,
          "title": "TellMeWhy: A Dataset for Answering Why-Questions in Narratives. (arXiv:2106.06132v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06160",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ferrand_E/0/1/0/all/0/1\">&#xc9;ric Le Ferrand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bird_S/0/1/0/all/0/1\">Steven Bird</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Besacier_L/0/1/0/all/0/1\">Laurent Besacier</a>",
          "description": "We investigate the efficiency of two very different spoken term detection\napproaches for transcription when the available data is insufficient to train a\nrobust ASR system. This work is grounded in very low-resource language\ndocumentation scenario where only few minutes of recording have been\ntranscribed for a given language so far.Experiments on two oral languages show\nthat a pretrained universal phone recognizer, fine-tuned with only a few\nminutes of target language speech, can be used for spoken term detection with a\nbetter overall performance than a dynamic time warping approach. In addition,\nwe show that representing phoneme recognition ambiguity in a graph structure\ncan further boost the recall while maintaining high precision in the low\nresource spoken term detection task.",
          "link": "http://arxiv.org/abs/2106.06160",
          "publishedOn": "2021-06-14T01:38:51.537Z",
          "wordCount": 561,
          "title": "Spoken Term Detection Methods for Sparse Transcription in Very Low-resource Settings. (arXiv:2106.06160v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06004",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jayanthi_S/0/1/0/all/0/1\">Sai Muralidhar Jayanthi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nerella_K/0/1/0/all/0/1\">Kavya Nerella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandu_K/0/1/0/all/0/1\">Khyathi Raghavi Chandu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Black_A/0/1/0/all/0/1\">Alan W Black</a>",
          "description": "The NLP community has witnessed steep progress in a variety of tasks across\nthe realms of monolingual and multilingual language processing recently. These\nsuccesses, in conjunction with the proliferating mixed language interactions on\nsocial media have boosted interest in modeling code-mixed texts. In this work,\nwe present CodemixedNLP, an open-source library with the goals of bringing\ntogether the advances in code-mixed NLP and opening it up to a wider machine\nlearning community. The library consists of tools to develop and benchmark\nversatile model architectures that are tailored for mixed texts, methods to\nexpand training sets, techniques to quantify mixing styles, and fine-tuned\nstate-of-the-art models for 7 tasks in Hinglish. We believe this work has a\npotential to foster a distributed yet collaborative and sustainable ecosystem\nin an otherwise dispersed space of code-mixing research. The toolkit is\ndesigned to be simple, easily extensible, and resourceful to both researchers\nas well as practitioners.",
          "link": "http://arxiv.org/abs/2106.06004",
          "publishedOn": "2021-06-14T01:38:51.510Z",
          "wordCount": 596,
          "title": "CodemixedNLP: An Extensible and Open NLP Toolkit for Code-Mixing. (arXiv:2106.06004v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06157",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bang_Y/0/1/0/all/0/1\">Yejin Bang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_N/0/1/0/all/0/1\">Nayeon Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ishii_E/0/1/0/all/0/1\">Etsuko Ishii</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madotto_A/0/1/0/all/0/1\">Andrea Madotto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fung_P/0/1/0/all/0/1\">Pascale Fung</a>",
          "description": "Politically sensitive topics are still a challenge for open-domain chatbots.\nHowever, dealing with politically sensitive content in a responsible,\nnon-partisan, and safe behavior way is integral for these chatbots. Currently,\nthe main approach to handling political sensitivity is by simply changing such\na topic when it is detected. This is safe but evasive and results in a chatbot\nthat is less engaging. In this work, as a first step towards a politically safe\nchatbot, we propose a group of metrics for assessing their political prudence.\nWe then conduct political prudence analysis of various chatbots and discuss\ntheir behavior from multiple angles through our automatic metric and human\nevaluation metrics. The testsets and codebase are released to promote research\nin this area.",
          "link": "http://arxiv.org/abs/2106.06157",
          "publishedOn": "2021-06-14T01:38:51.469Z",
          "wordCount": 560,
          "title": "Assessing Political Prudence of Open-domain Chatbots. (arXiv:2106.06157v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06052",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1\">Zhiyi Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ethayarajh_K/0/1/0/all/0/1\">Kawin Ethayarajh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thrush_T/0/1/0/all/0/1\">Tristan Thrush</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1\">Somya Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1\">Ledell Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1\">Robin Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potts_C/0/1/0/all/0/1\">Christopher Potts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Williams_A/0/1/0/all/0/1\">Adina Williams</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiela_D/0/1/0/all/0/1\">Douwe Kiela</a>",
          "description": "We introduce Dynaboard, an evaluation-as-a-service framework for hosting\nbenchmarks and conducting holistic model comparison, integrated with the\nDynabench platform. Our platform evaluates NLP models directly instead of\nrelying on self-reported metrics or predictions on a single dataset. Under this\nparadigm, models are submitted to be evaluated in the cloud, circumventing the\nissues of reproducibility, accessibility, and backwards compatibility that\noften hinder benchmarking in NLP. This allows users to interact with uploaded\nmodels in real time to assess their quality, and permits the collection of\nadditional metrics such as memory use, throughput, and robustness, which --\ndespite their importance to practitioners -- have traditionally been absent\nfrom leaderboards. On each task, models are ranked according to the Dynascore,\na novel utility-based aggregation of these statistics, which users can\ncustomize to better reflect their preferences, placing more/less weight on a\nparticular axis of evaluation or dataset. As state-of-the-art NLP models push\nthe limits of traditional benchmarks, Dynaboard offers a standardized solution\nfor a more diverse and comprehensive evaluation of model quality.",
          "link": "http://arxiv.org/abs/2106.06052",
          "publishedOn": "2021-06-14T01:38:51.458Z",
          "wordCount": 609,
          "title": "Dynaboard: An Evaluation-As-A-Service Platform for Holistic Next-Generation Benchmarking. (arXiv:2106.06052v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06139",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moore_K/0/1/0/all/0/1\">Kristen Moore</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_S/0/1/0/all/0/1\">Shenjun Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1\">Zhen He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rudolf_T/0/1/0/all/0/1\">Torsten Rudolf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fisher_N/0/1/0/all/0/1\">Nils Fisher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Victor_B/0/1/0/all/0/1\">Brandon Victor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jindal_N/0/1/0/all/0/1\">Neha Jindal</a>",
          "description": "In this paper we present the results of our experiments in training and\ndeploying a self-supervised retrieval-based chatbot trained with contrastive\nlearning for assisting customer support agents. In contrast to most existing\nresearch papers in this area where the focus is on solving just one component\nof a deployable chatbot, we present an end-to-end set of solutions to take the\nreader from an unlabelled chatlogs to a deployed chatbot. This set of solutions\nincludes creating a self-supervised dataset and a weakly labelled dataset from\nchatlogs, as well as a systematic approach to selecting a fixed list of canned\nresponses. We present a hierarchical-based RNN architecture for the response\nselection model, chosen for its ability to cache intermediate utterance\nembeddings, which helped to meet deployment inference speed requirements. We\ncompare the performance of this architecture across 3 different learning\nobjectives: self-supervised contrastive learning, binary classification, and\nmulti-class classification. We find that using a self-supervised contrastive\nlearning model outperforms training the binary and multi-class classification\nmodels on a weakly labelled dataset. Our results validate that the\nself-supervised contrastive learning approach can be effectively used for a\nreal-world chatbot scenario.",
          "link": "http://arxiv.org/abs/2106.06139",
          "publishedOn": "2021-06-14T01:38:51.444Z",
          "wordCount": 624,
          "title": "A comprehensive solution to retrieval-based chatbot construction. (arXiv:2106.06139v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06147",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abdelnour_J/0/1/0/all/0/1\">Jerome Abdelnour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rouat_J/0/1/0/all/0/1\">Jean Rouat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salvi_G/0/1/0/all/0/1\">Giampiero Salvi</a>",
          "description": "The goal of the Acoustic Question Answering (AQA) task is to answer a\nfree-form text question about the content of an acoustic scene. It was inspired\nby the Visual Question Answering (VQA) task. In this paper, based on the\npreviously introduced CLEAR dataset, we propose a new benchmark for AQA that\nemphasizes the specific challenges of acoustic inputs, e.g. variable duration\nscenes. We also introduce NAAQA, a neural architecture that leverages specific\nproperties of acoustic inputs. The usage of time and frequency 1D convolutions\nto process 2D spectro-temporal representations of acoustic content shows\npromising results and enables reductions in model complexity. NAAQA achieves\n91.6% of accuracy on the AQA task with about 7 times fewer parameters than the\npreviously explored VQA model. We provide a detailed analysis of the results\nfor the different question types. The effectiveness of coordinate maps in this\nacoustic context was also studied and we show that time coordinate maps augment\ntemporal localization capabilities which enhance performance of the network by\nabout 17 percentage points.",
          "link": "http://arxiv.org/abs/2106.06147",
          "publishedOn": "2021-06-14T01:38:51.433Z",
          "wordCount": 622,
          "title": "NAAQA: A Neural Architecture for Acoustic Question Answering. (arXiv:2106.06147v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06125",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1\">Baosong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1\">Dayiheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Haibo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_W/0/1/0/all/0/1\">Weihua Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Min Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Haiying Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1\">Jinsong Su</a>",
          "description": "A well-known limitation in pretrain-finetune paradigm lies in its\ninflexibility caused by the one-size-fits-all vocabulary. This potentially\nweakens the effect when applying pretrained models into natural language\ngeneration (NLG) tasks, especially for the subword distributions between\nupstream and downstream tasks with significant discrepancy. Towards approaching\nthis problem, we extend the vanilla pretrain-finetune pipeline with an extra\nembedding transfer step. Specifically, a plug-and-play embedding generator is\nintroduced to produce the representation of any input token, according to\npre-trained embeddings of its morphologically similar ones. Thus, embeddings of\nmismatch tokens in downstream tasks can also be efficiently initialized. We\nconduct experiments on a variety of NLG tasks under the pretrain-finetune\nfashion. Experimental results and extensive analyses show that the proposed\nstrategy offers us opportunities to feel free to transfer the vocabulary,\nleading to more efficient and better performed downstream NLG models.",
          "link": "http://arxiv.org/abs/2106.06125",
          "publishedOn": "2021-06-14T01:38:51.408Z",
          "wordCount": 581,
          "title": "Bridging Subword Gaps in Pretrain-Finetune Paradigm for Natural Language Generation. (arXiv:2106.06125v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06090",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1\">Lingfei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_K/0/1/0/all/0/1\">Kai Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1\">Xiaojie Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_H/0/1/0/all/0/1\">Hanning Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shucheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pei_J/0/1/0/all/0/1\">Jian Pei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_B/0/1/0/all/0/1\">Bo Long</a>",
          "description": "Deep learning has become the dominant approach in coping with various tasks\nin Natural LanguageProcessing (NLP). Although text inputs are typically\nrepresented as a sequence of tokens, there isa rich variety of NLP problems\nthat can be best expressed with a graph structure. As a result, thereis a surge\nof interests in developing new deep learning techniques on graphs for a large\nnumberof NLP tasks. In this survey, we present a comprehensive overview onGraph\nNeural Networks(GNNs) for Natural Language Processing. We propose a new\ntaxonomy of GNNs for NLP, whichsystematically organizes existing research of\nGNNs for NLP along three axes: graph construction,graph representation\nlearning, and graph based encoder-decoder models. We further introducea large\nnumber of NLP applications that are exploiting the power of GNNs and summarize\nthecorresponding benchmark datasets, evaluation metrics, and open-source codes.\nFinally, we discussvarious outstanding challenges for making the full use of\nGNNs for NLP as well as future researchdirections. To the best of our\nknowledge, this is the first comprehensive overview of Graph NeuralNetworks for\nNatural Language Processing.",
          "link": "http://arxiv.org/abs/2106.06090",
          "publishedOn": "2021-06-14T01:38:51.397Z",
          "wordCount": 614,
          "title": "Graph Neural Networks for Natural Language Processing: A Survey. (arXiv:2106.06090v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06087",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Finlayson_M/0/1/0/all/0/1\">Matthew Finlayson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mueller_A/0/1/0/all/0/1\">Aaron Mueller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shieber_S/0/1/0/all/0/1\">Stuart Shieber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gehrmann_S/0/1/0/all/0/1\">Sebastian Gehrmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Linzen_T/0/1/0/all/0/1\">Tal Linzen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belinkov_Y/0/1/0/all/0/1\">Yonatan Belinkov</a>",
          "description": "Targeted syntactic evaluations have demonstrated the ability of language\nmodels to perform subject-verb agreement given difficult contexts. To elucidate\nthe mechanisms by which the models accomplish this behavior, this study applies\ncausal mediation analysis to pre-trained neural language models. We investigate\nthe magnitude of models' preferences for grammatical inflections, as well as\nwhether neurons process subject-verb agreement similarly across sentences with\ndifferent syntactic structures. We uncover similarities and differences across\narchitectures and model sizes -- notably, that larger models do not necessarily\nlearn stronger preferences. We also observe two distinct mechanisms for\nproducing subject-verb agreement depending on the syntactic structure of the\ninput sentence. Finally, we find that language models rely on similar sets of\nneurons when given sentences with similar syntactic structure.",
          "link": "http://arxiv.org/abs/2106.06087",
          "publishedOn": "2021-06-14T01:38:51.386Z",
          "wordCount": 572,
          "title": "Causal Analysis of Syntactic Agreement Mechanisms in Neural Language Models. (arXiv:2106.06087v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06017",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hassan_S/0/1/0/all/0/1\">Sabit Hassan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shaar_S/0/1/0/all/0/1\">Shaden Shaar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Darwish_K/0/1/0/all/0/1\">Kareem Darwish</a>",
          "description": "Emotion detection is of great importance for understanding humans.\nConstructing annotated datasets to train automated models can be expensive. We\nexplore the efficacy of cross-lingual approaches that would use data from a\nsource language to build models for emotion detection in a target language. We\ncompare three approaches, namely: i) using inherently multilingual models; ii)\ntranslating training data into the target language; and iii) using an\nautomatically tagged parallel corpus. In our study, we consider English as the\nsource language with Arabic and Spanish as target languages. We study the\neffectiveness of different classification models such as BERT and SVMs trained\nwith different features. Our BERT-based monolingual models that are trained on\ntarget language data surpass state-of-the-art (SOTA) by 4% and 5% absolute\nJaccard score for Arabic and Spanish respectively. Next, we show that using\ncross-lingual approaches with English data alone, we can achieve more than 90%\nand 80% relative effectiveness of the Arabic and Spanish BERT models\nrespectively. Lastly, we use LIME to interpret the differences between models.",
          "link": "http://arxiv.org/abs/2106.06017",
          "publishedOn": "2021-06-14T01:38:51.364Z",
          "wordCount": 582,
          "title": "Cross-lingual Emotion Detection. (arXiv:2106.06017v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06038",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chowdhury_J/0/1/0/all/0/1\">Jishnu Ray Chowdhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caragea_C/0/1/0/all/0/1\">Cornelia Caragea</a>",
          "description": "Recursive Neural Networks (RvNNs), which compose sequences according to their\nunderlying hierarchical syntactic structure, have performed well in several\nnatural language processing tasks compared to similar models without structural\nbiases. However, traditional RvNNs are incapable of inducing the latent\nstructure in a plain text sequence on their own. Several extensions have been\nproposed to overcome this limitation. Nevertheless, these extensions tend to\nrely on surrogate gradients or reinforcement learning at the cost of higher\nbias or variance. In this work, we propose Continuous Recursive Neural Network\n(CRvNN) as a backpropagation-friendly alternative to address the aforementioned\nlimitations. This is done by incorporating a continuous relaxation to the\ninduced structure. We demonstrate that CRvNN achieves strong performance in\nchallenging synthetic tasks such as logical inference and ListOps. We also show\nthat CRvNN performs comparably or better than prior latent structure models on\nreal-world tasks such as sentiment analysis and natural language inference.",
          "link": "http://arxiv.org/abs/2106.06038",
          "publishedOn": "2021-06-14T01:38:51.346Z",
          "wordCount": 589,
          "title": "Modeling Hierarchical Structures with Continuous Recursive Neural Networks. (arXiv:2106.06038v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06082",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hauer_B/0/1/0/all/0/1\">Bradley Hauer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kondrak_G/0/1/0/all/0/1\">Grzegorz Kondrak</a>",
          "description": "The idea of using lexical translations to define sense inventories has a long\nhistory in lexical semantics. We propose a theoretical framework which allows\nus to answer the question of why this apparently reasonable idea failed to\nproduce useful results. We formally prove several propositions on how the\ntranslations of a word relate to its senses, as well as on the relationship\nbetween synonymy and polysemy. We empirically validate our theoretical findings\non BabelNet, and demonstrate how they could be used to perform unsupervised\nword sense disambiguation of a substantial fraction of the lexicon.",
          "link": "http://arxiv.org/abs/2106.06082",
          "publishedOn": "2021-06-14T01:38:51.306Z",
          "wordCount": 508,
          "title": "One Sense Per Translation. (arXiv:2106.06082v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06002",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Blodgett_A/0/1/0/all/0/1\">Austin Blodgett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schneider_N/0/1/0/all/0/1\">Nathan Schneider</a>",
          "description": "We present algorithms for aligning components of Abstract Meaning\nRepresentation (AMR) graphs to spans in English sentences. We leverage\nunsupervised learning in combination with heuristics, taking the best of both\nworlds from previous AMR aligners. Our unsupervised models, however, are more\nsensitive to graph substructures, without requiring a separate syntactic parse.\nOur approach covers a wider variety of AMR substructures than previously\nconsidered, achieves higher coverage of nodes and edges, and does so with\nhigher accuracy. We will release our LEAMR datasets and aligner for use in\nresearch on AMR parsing, generation, and evaluation.",
          "link": "http://arxiv.org/abs/2106.06002",
          "publishedOn": "2021-06-14T01:38:51.293Z",
          "wordCount": 527,
          "title": "Probabilistic, Structure-Aware Algorithms for Improved Variety, Accuracy, and Coverage of AMR Alignments. (arXiv:2106.06002v1 [cs.CL])"
        }
      ]
    },
    {
      "title": "cs.IR updates on arXiv.org",
      "feedUrl": "http://export.arxiv.org/rss/cs.IR",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2105.12937",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_R/0/1/0/all/0/1\">Ruoming Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jing Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Li Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yang Zhou</a>",
          "description": "Recently, linear regression models, such as EASE and SLIM, have shown to\noften produce rather competitive results against more sophisticated deep\nlearning models. On the other side, the (weighted) matrix factorization\napproaches have been popular choices for recommendation in the past and widely\nadopted in the industry. In this work, we aim to theoretically understand the\nrelationship between these two approaches, which are the cornerstones of\nmodel-based recommendations. Through the derivation and analysis of the\nclosed-form solutions for two basic regression and matrix factorization\napproaches, we found these two approaches are indeed inherently related but\nalso diverge in how they \"scale-down\" the singular values of the original\nuser-item interaction matrix. This analysis also helps resolve the questions\nrelated to the regularization parameter range and model complexities. We\nfurther introduce a new learning algorithm in searching (hyper)parameters for\nthe closed-form solution and utilize it to discover the nearby models of the\nexisting solutions. The experimental results demonstrate that the basic models\nand their closed-form solutions are indeed quite competitive against the\nstate-of-the-art models, thus, confirming the validity of studying the basic\nmodels. The effectiveness of exploring the nearby models are also\nexperimentally validated.",
          "link": "http://arxiv.org/abs/2105.12937",
          "publishedOn": "2021-06-17T01:58:40.720Z",
          "wordCount": 663,
          "title": "Towards a Better Understanding of Linear Models for Recommendation. (arXiv:2105.12937v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.06274",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Korencic_D/0/1/0/all/0/1\">Damir Koren&#x10d;i&#x107;</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Ristov_S/0/1/0/all/0/1\">Strahil Ristov</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Repar_J/0/1/0/all/0/1\">Jelena Repar</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Snajder_J/0/1/0/all/0/1\">Jan &#x160;najder</a> (2) ((1) Rudjer Bo&#x161;kovi&#x107; Institute, Croatia, (2) University of Zagreb, Faculty of Electrical Engineering and Computing, Croatia)",
          "description": "Topic models are widely used unsupervised models of text capable of learning\ntopics - weighted lists of words and documents - from large collections of text\ndocuments. When topic models are used for discovery of topics in text\ncollections, a question that arises naturally is how well the model-induced\ntopics correspond to topics of interest to the analyst. In this paper we\nrevisit and extend a so far neglected approach to topic model evaluation based\non measuring topic coverage - computationally matching model topics with a set\nof reference topics that models are expected to uncover. The approach is well\nsuited for analyzing models' performance in topic discovery and for large-scale\nanalysis of both topic models and measures of model quality. We propose new\nmeasures of coverage and evaluate, in a series of experiments, different types\nof topic models on two distinct text domains for which interest for topic\ndiscovery exists. The experiments include evaluation of model quality, analysis\nof coverage of distinct topic categories, and the analysis of the relationship\nbetween coverage and other methods of topic model evaluation. The contributions\nof the paper include new measures of coverage, insights into both topic models\nand other methods of model evaluation, and the datasets and code for\nfacilitating future research of both topic coverage and other approaches to\ntopic model evaluation.",
          "link": "http://arxiv.org/abs/2012.06274",
          "publishedOn": "2021-06-17T01:58:40.701Z",
          "wordCount": 741,
          "title": "A Topic Coverage Approach to Evaluation of Topic Models. (arXiv:2012.06274v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08701",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mryglod_O/0/1/0/all/0/1\">O. Mryglod</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nazarovets_S/0/1/0/all/0/1\">S. Nazarovets</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kozmenko_S/0/1/0/all/0/1\">S. Kozmenko</a>",
          "description": "Our study is one of the first examples of multidimensional and longitudinal\ndisciplinary analysis at the national level based on Crossref data. We present\na large-scale quantitative analysis of Ukrainian economics. This study is not\nyet another example of research aimed at ranking of local journals, authors or\ninstitutions, but rather exploring general tendencies that can be compared to\nother countries or regions. We study different aspects of Ukrainian economics\noutput. In particular, the collaborative nature, geographic landscape and some\npeculiarities of citation statistics are investigated. We have found that\nUkrainian economics is characterized by a comparably small share of co-authored\npublications, however, it demonstrates the tendency towards more collaborative\noutput. Based on our analysis, we discuss specific and universal features of\nUkrainian economic research. The importance of supporting various initiatives\naimed at enriching open scholarly metadata is considered. A comprehensive and\nhigh-quality meta description of publications is probably the shortest path to\na better understanding of national trends, especially for non-English speaking\ncountries. The results of our analysis can be used to better understand\nUkrainian economic research and support research policy decisions.",
          "link": "http://arxiv.org/abs/2106.08701",
          "publishedOn": "2021-06-17T01:58:40.608Z",
          "wordCount": 647,
          "title": "Universal and specific features of Ukrainian economic research: publication analysis based on Crossref data. (arXiv:2106.08701v1 [cs.DL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08770",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dusart_A/0/1/0/all/0/1\">Alexis Dusart</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pinel_Sauvagnat_K/0/1/0/all/0/1\">Karen Pinel-Sauvagnat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hubert_G/0/1/0/all/0/1\">Gilles Hubert</a>",
          "description": "The development of deep neural networks and the emergence of pre-trained\nlanguage models such as BERT allow to increase performance on many NLP tasks.\nHowever, these models do not meet the same popularity for tweet summarization,\nwhich can probably be explained by the lack of existing collections for\ntraining and evaluation. Our contribution in this paper is twofold : (1) we\nintroduce a large dataset for Twitter event summarization, and (2) we propose a\nneural model to automatically summarize huge tweet streams. This extractive\nmodel combines in an original way pre-trained language models and vocabulary\nfrequency-based representations to predict tweet salience. An additional\nadvantage of the model is that it automatically adapts the size of the output\nsummary according to the input tweet stream. We conducted experiments using two\ndifferent Twitter collections, and promising results are observed in comparison\nwith state-of-the-art baselines.",
          "link": "http://arxiv.org/abs/2106.08770",
          "publishedOn": "2021-06-17T01:58:40.264Z",
          "wordCount": 563,
          "title": "TSSuBERT: Tweet Stream Summarization Using BERT. (arXiv:2106.08770v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08934",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chuhan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fangzhao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yongfeng Huang</a>",
          "description": "Personalized news recommendation is an important technique to help users find\ntheir interested news information and alleviate their information overload. It\nhas been extensively studied over decades and has achieved notable success in\nimproving users' news reading experience. However, there are still many\nunsolved problems and challenges that need to be further studied. To help\nresearchers master the advances in personalized news recommendation over the\npast years, in this paper we present a comprehensive overview of personalized\nnews recommendation. Instead of following the conventional taxonomy of news\nrecommendation methods, in this paper we propose a novel perspective to\nunderstand personalized news recommendation based on its core problems and the\nassociated techniques and challenges. We first review the techniques for\ntackling each core problem in a personalized news recommender system and the\nchallenges they face. Next, we introduce the public datasets and evaluation\nmetrics used for personalized news recommendation. We then discuss the key\npoints on improving the responsibility of personalized news recommender\nsystems. Finally, we raise several research directions that are worth\ninvestigating in future. This paper can provide up-to-date and comprehensive\nviews to help readers understand the personalized news recommendation field. We\nhope this paper can facilitate research on personalized news recommendation and\nas well as related fields in natural language processing and data mining.",
          "link": "http://arxiv.org/abs/2106.08934",
          "publishedOn": "2021-06-17T01:58:40.220Z",
          "wordCount": 631,
          "title": "Personalized News Recommendation: A Survey. (arXiv:2106.08934v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2010.12537",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhiruo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1\">Haoyu Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1\">Ran Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jia Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Z/0/1/0/all/0/1\">Zhiyi Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Shi Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dongmei Zhang</a>",
          "description": "Tables are widely used with various structures to organize and present data.\nRecent attempts on table understanding mainly focus on relational tables, yet\noverlook to other common table structures. In this paper, we propose TUTA, a\nunified pre-training architecture for understanding generally structured\ntables. Noticing that understanding a table requires spatial, hierarchical, and\nsemantic information, we enhance transformers with three novel structure-aware\nmechanisms. First, we devise a unified tree-based structure, called a\nbi-dimensional coordinate tree, to describe both the spatial and hierarchical\ninformation of generally structured tables. Upon this, we propose tree-based\nattention and position embedding to better capture the spatial and hierarchical\ninformation. Moreover, we devise three progressive pre-training objectives to\nenable representations at the token, cell, and table levels. We pre-train TUTA\non a wide range of unlabeled web and spreadsheet tables and fine-tune it on two\ncritical tasks in the field of table structure understanding: cell type\nclassification and table type classification. Experiments show that TUTA is\nhighly effective, achieving state-of-the-art on five widely-studied datasets.",
          "link": "http://arxiv.org/abs/2010.12537",
          "publishedOn": "2021-06-17T01:58:40.200Z",
          "wordCount": 645,
          "title": "TUTA: Tree-based Transformers for Generally Structured Table Pre-training. (arXiv:2010.12537v3 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08700",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kang_S/0/1/0/all/0/1\">SeongKu Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_J/0/1/0/all/0/1\">Junyoung Hwang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kweon_W/0/1/0/all/0/1\">Wonbin Kweon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Hwanjo Yu</a>",
          "description": "Recommender Systems (RS) have employed knowledge distillation which is a\nmodel compression technique training a compact student model with the knowledge\ntransferred from a pre-trained large teacher model. Recent work has shown that\ntransferring knowledge from the teacher's intermediate layer significantly\nimproves the recommendation quality of the student. However, they transfer the\nknowledge of individual representation point-wise and thus have a limitation in\nthat primary information of RS lies in the relations in the representation\nspace. This paper proposes a new topology distillation approach that guides the\nstudent by transferring the topological structure built upon the relations in\nthe teacher space. We first observe that simply making the student learn the\nwhole topological structure is not always effective and even degrades the\nstudent's performance. We demonstrate that because the capacity of the student\nis highly limited compared to that of the teacher, learning the whole\ntopological structure is daunting for the student. To address this issue, we\npropose a novel method named Hierarchical Topology Distillation (HTD) which\ndistills the topology hierarchically to cope with the large capacity gap. Our\nextensive experiments on real-world datasets show that the proposed method\nsignificantly outperforms the state-of-the-art competitors. We also provide\nin-depth analyses to ascertain the benefit of distilling the topology for RS.",
          "link": "http://arxiv.org/abs/2106.08700",
          "publishedOn": "2021-06-17T01:58:40.114Z",
          "wordCount": 642,
          "title": "Topology Distillation for Recommender System. (arXiv:2106.08700v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08527",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_R/0/1/0/all/0/1\">Ruoyuan Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1\">Yingqiang Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_C/0/1/0/all/0/1\">Chirag Shah</a>",
          "description": "With the emerging needs of creating fairness-aware solutions for search and\nrecommendation systems, a daunting challenge exists of evaluating such\nsolutions. While many of the traditional information retrieval (IR) metrics can\ncapture the relevance, diversity and novelty for the utility with respect to\nusers, they are not suitable for inferring whether the presented results are\nfair from the perspective of responsible information exposure. On the other\nhand, various fairness metrics have been proposed but they do not account for\nthe user utility or do not measure it adequately. To address this problem, we\npropose a new metric called Fairness-Aware IR (FAIR). By unifying standard IR\nmetrics and fairness measures into an integrated metric, this metric offers a\nnew perspective for evaluating fairness-aware ranking results. Based on this\nmetric, we developed an effective ranking algorithm that jointly optimized user\nutility and fairness. The experimental results showed that our FAIR metric\ncould highlight results with good user utility and fair information exposure.\nWe showed how FAIR related to existing metrics and demonstrated the\neffectiveness of our FAIR-based algorithm. We believe our work opens up a new\ndirection of pursuing a computationally feasible metric for evaluating and\nimplementing the fairness-aware IR systems.",
          "link": "http://arxiv.org/abs/2106.08527",
          "publishedOn": "2021-06-17T01:58:40.089Z",
          "wordCount": 628,
          "title": "FAIR: Fairness-Aware Information Retrieval Evaluation. (arXiv:2106.08527v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08433",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sidiropoulos_G/0/1/0/all/0/1\">Georgios Sidiropoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Voskarides_N/0/1/0/all/0/1\">Nikos Voskarides</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vakulenko_S/0/1/0/all/0/1\">Svitlana Vakulenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanoulas_E/0/1/0/all/0/1\">Evangelos Kanoulas</a>",
          "description": "We analyse the performance of passage retrieval models in the presence of\ncomplex (multi-hop) questions to provide a better understanding of how\nretrieval systems behave when multiple hops of reasoning are needed. In simple\nopen-domain question answering (QA), dense passage retrieval has become one of\nthe standard approaches for retrieving the relevant passages to infer an\nanswer. Recently, dense passage retrieval also achieved state-of-the-art\nresults in multi-hop QA, where aggregating information from multiple documents\nand reasoning over them is required. However, so far, the dense retrieval\nmodels are not evaluated properly concerning the multi-hop nature of the\nproblem: models are typically evaluated by the end result of the retrieval\npipeline, which leaves unclear where their success lies. In this work, we\nprovide an in-depth evaluation of such models not only unveiling the reasons\nbehind their success but also their limitations. Moreover, we introduce a\nhybrid (lexical and dense) retrieval approach that is highly competitive with\nthe state-of-the-art dense retrieval model, while requiring substantially less\ncomputational resources. Furthermore, we also perform qualitative analysis to\nbetter understand the challenges behind passage retrieval for multi-hop QA.",
          "link": "http://arxiv.org/abs/2106.08433",
          "publishedOn": "2021-06-17T01:58:40.067Z",
          "wordCount": 607,
          "title": "Analysing Dense Passage Retrieval for Multi-hop Question Answering. (arXiv:2106.08433v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08908",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pappas_D/0/1/0/all/0/1\">Dimitris Pappas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Androutsopoulos_I/0/1/0/all/0/1\">Ion Androutsopoulos</a>",
          "description": "Question answering (QA) systems for large document collections typically use\npipelines that (i) retrieve possibly relevant documents, (ii) re-rank them,\n(iii) rank paragraphs or other snippets of the top-ranked documents, and (iv)\nselect spans of the top-ranked snippets as exact answers. Pipelines are\nconceptually simple, but errors propagate from one component to the next,\nwithout later components being able to revise earlier decisions. We present an\narchitecture for joint document and snippet ranking, the two middle stages,\nwhich leverages the intuition that relevant documents have good snippets and\ngood snippets come from relevant documents. The architecture is general and can\nbe used with any neural text relevance ranker. We experiment with two main\ninstantiations of the architecture, based on POSIT-DRMM (PDRMM) and a\nBERT-based ranker. Experiments on biomedical data from BIOASQ show that our\njoint models vastly outperform the pipelines in snippet retrieval, the main\ngoal for QA, with fewer trainable parameters, also remaining competitive in\ndocument retrieval. Furthermore, our joint PDRMM-based model is competitive\nwith BERT-based models, despite using orders of magnitude fewer parameters.\nThese claims are also supported by human evaluation on two test batches of\nBIOASQ. To test our key findings on another dataset, we modified the Natural\nQuestions dataset so that it can also be used for document and snippet\nretrieval. Our joint PDRMM-based model again outperforms the corresponding\npipeline in snippet retrieval on the modified Natural Questions dataset, even\nthough it performs worse than the pipeline in document retrieval. We make our\ncode and the modified Natural Questions dataset publicly available.",
          "link": "http://arxiv.org/abs/2106.08908",
          "publishedOn": "2021-06-17T01:58:40.029Z",
          "wordCount": 713,
          "title": "A Neural Model for Joint Document and Snippet Ranking in Question Answering for Large Document Collections. (arXiv:2106.08908v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2009.09931",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pande_H/0/1/0/all/0/1\">Harshit Pande</a>",
          "description": "Click-through rate (CTR) prediction models are common in many online\napplications such as digital advertising and recommender systems. Field-Aware\nFactorization Machine (FFM) and Field-weighted Factorization Machine (FwFM) are\nstate-of-the-art among the shallow models for CTR prediction. Recently, many\ndeep learning-based models have also been proposed. Among deeper models,\nDeepFM, xDeepFM, AutoInt+, and FiBiNet are state-of-the-art models. The deeper\nmodels combine a core architectural component, which learns explicit feature\ninteractions, with a deep neural network (DNN) component. We propose a novel\nshallow Field-Embedded Factorization Machine (FEFM) and its deep counterpart\nDeep Field-Embedded Factorization Machine (DeepFEFM). FEFM learns symmetric\nmatrix embeddings for each field pair along with the usual single vector\nembeddings for each feature. FEFM has significantly lower model complexity than\nFFM and roughly the same complexity as FwFM. FEFM also has insightful\nmathematical properties about important fields and field interactions. DeepFEFM\ncombines the FEFM interaction vectors learned by the FEFM component with a DNN\nand is thus able to learn higher order interactions. We conducted comprehensive\nexperiments over a wide range of hyperparameters on two large publicly\navailable real-world datasets. When comparing test AUC and log loss, the\nresults show that FEFM and DeepFEFM outperform the existing state-of-the-art\nshallow and deep models for CTR prediction tasks. We have made the code of FEFM\nand DeepFEFM available in the DeepCTR library\n(https://github.com/shenweichen/DeepCTR).",
          "link": "http://arxiv.org/abs/2009.09931",
          "publishedOn": "2021-06-16T01:21:04.771Z",
          "wordCount": 675,
          "title": "Field-Embedded Factorization Machines for Click-through rate prediction. (arXiv:2009.09931v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.11066",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1\">Chenyu You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1\">Nuo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1\">Yuexian Zou</a>",
          "description": "Spoken conversational question answering (SCQA) requires machines to model\ncomplex dialogue flow given the speech utterances and text corpora. Different\nfrom traditional text question answering (QA) tasks, SCQA involves audio signal\nprocessing, passage comprehension, and contextual understanding. However, ASR\nsystems introduce unexpected noisy signals to the transcriptions, which result\nin performance degradation on SCQA. To overcome the problem, we propose CADNet,\na novel contextualized attention-based distillation approach, which applies\nboth cross-attention and self-attention to obtain ASR-robust contextualized\nembedding representations of the passage and dialogue history for performance\nimprovements. We also introduce the spoken conventional knowledge distillation\nframework to distill the ASR-robust knowledge from the estimated probabilities\nof the teacher model to the student. We conduct extensive experiments on the\nSpoken-CoQA dataset and demonstrate that our approach achieves remarkable\nperformance in this task.",
          "link": "http://arxiv.org/abs/2010.11066",
          "publishedOn": "2021-06-16T01:21:04.362Z",
          "wordCount": 616,
          "title": "Contextualized Attention-based Knowledge Transfer for Spoken Conversational Question Answering. (arXiv:2010.11066v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08252",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ebadi_N/0/1/0/all/0/1\">Nima Ebadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Najafirad_P/0/1/0/all/0/1\">Peyman Najafirad</a>",
          "description": "The rapidly evolving literature of COVID-19 related articles makes it\nchallenging for NLP models to be effectively trained for information retrieval\nand extraction with the corresponding labeled data that follows the current\ndistribution of the pandemic. On the other hand, due to the uncertainty of the\nsituation, human experts' supervision would always be required to double check\nthe decision making of these models highlighting the importance of\ninterpretability. In the light of these challenges, this study proposes an\ninterpretable self-supervised multi-task learning model to jointly and\neffectively tackle the tasks of information retrieval (IR) and extraction (IE)\nduring the current emergency health crisis situation. Our results show that our\nmodel effectively leverage the multi-task and self-supervised learning to\nimprove generalization, data efficiency and robustness to the ongoing dataset\nshift problem. Our model outperforms baselines in IE and IR tasks, respectively\nby micro-f score of 0.08 (LCA-F score of 0.05), and MAP of 0.05 on average. In\nIE the zero- and few-shot learning performances are on average 0.32 and 0.19\nmicro-f score higher than those of the baselines.",
          "link": "http://arxiv.org/abs/2106.08252",
          "publishedOn": "2021-06-16T01:21:04.341Z",
          "wordCount": 650,
          "title": "Interpretable Self-supervised Multi-task Learning for COVID-19 Information Retrieval and Extraction. (arXiv:2106.08252v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2104.01894",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sanabria_R/0/1/0/all/0/1\">Ramon Sanabria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Waters_A/0/1/0/all/0/1\">Austin Waters</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baldridge_J/0/1/0/all/0/1\">Jason Baldridge</a>",
          "description": "Speech-based image retrieval has been studied as a proxy for joint\nrepresentation learning, usually without emphasis on retrieval itself. As such,\nit is unclear how well speech-based retrieval can work in practice -- both in\nan absolute sense and versus alternative strategies that combine automatic\nspeech recognition (ASR) with strong text encoders. In this work, we\nextensively study and expand choices of encoder architectures, training\nmethodology (including unimodal and multimodal pretraining), and other factors.\nOur experiments cover different types of speech in three datasets: Flickr\nAudio, Places Audio, and Localized Narratives. Our best model configuration\nachieves large gains over state of the art, e.g., pushing recall-at-one from\n21.8% to 33.2% for Flickr Audio and 27.6% to 53.4% for Places Audio. We also\nshow our best speech-based models can match or exceed cascaded ASR-to-text\nencoding when speech is spontaneous, accented, or otherwise hard to\nautomatically transcribe.",
          "link": "http://arxiv.org/abs/2104.01894",
          "publishedOn": "2021-06-16T01:21:04.317Z",
          "wordCount": 631,
          "title": "Talk, Don't Write: A Study of Direct Speech-Based Image Retrieval. (arXiv:2104.01894v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.07813",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Milton_A/0/1/0/all/0/1\">Ashlee Milton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Allen_G/0/1/0/all/0/1\">Garrett Allen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pera_M/0/1/0/all/0/1\">Maria Soledad Pera</a>",
          "description": "Research in the area of search engines for children remains in its infancy.\nSeminal works have studied how children use mainstream search engines, as well\nas how to design and evaluate custom search engines explicitly for children.\nThese works, however, tend to take a one-size-fits-all view, treating children\nas a unit. Nevertheless, even at the same age, children are known to possess\nand exhibit different capabilities. These differences affect how children\naccess and use search engines. To better serve children, in this vision paper,\nwe spotlight accessibility and discuss why current research on children and\nsearch engines does not, but should, focus on this significant matter.",
          "link": "http://arxiv.org/abs/2106.07813",
          "publishedOn": "2021-06-16T01:21:04.306Z",
          "wordCount": 567,
          "title": "To Infinity and Beyond! Accessibility is the Future for Kids' Search Engines. (arXiv:2106.07813v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08166",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alivanistos_D/0/1/0/all/0/1\">Dimitrios Alivanistos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berrendorf_M/0/1/0/all/0/1\">Max Berrendorf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cochez_M/0/1/0/all/0/1\">Michael Cochez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galkin_M/0/1/0/all/0/1\">Mikhail Galkin</a>",
          "description": "Multi-hop logical reasoning is an established problem in the field of\nrepresentation learning on knowledge graphs (KGs). It subsumes both one-hop\nlink prediction as well as other more complex types of logical queries.\nExisting algorithms operate only on classical, triple-based graphs, whereas\nmodern KGs often employ a hyper-relational modeling paradigm. In this paradigm,\ntyped edges may have several key-value pairs known as qualifiers that provide\nfine-grained context for facts. In queries, this context modifies the meaning\nof relations, and usually reduces the answer set. Hyper-relational queries are\noften observed in real-world KG applications, and existing approaches for\napproximate query answering cannot make use of qualifier pairs. In this work,\nwe bridge this gap and extend the multi-hop reasoning problem to\nhyper-relational KGs allowing to tackle this new type of complex queries.\nBuilding upon recent advancements in Graph Neural Networks and query embedding\ntechniques, we study how to embed and answer hyper-relational conjunctive\nqueries. Besides that, we propose a method to answer such queries and\ndemonstrate in our experiments that qualifiers improve query answering on a\ndiverse set of query patterns.",
          "link": "http://arxiv.org/abs/2106.08166",
          "publishedOn": "2021-06-16T01:21:04.296Z",
          "wordCount": 611,
          "title": "Query Embedding on Hyper-relational Knowledge Graphs. (arXiv:2106.08166v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2012.02298",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Du_C/0/1/0/all/0/1\">Chao Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1\">Zhifeng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_S/0/1/0/all/0/1\">Shuo Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1\">Lining Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Ziyan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1\">Yifan Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaoqiang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jian Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gai_K/0/1/0/all/0/1\">Kun Gai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Kuang-chih Lee</a>",
          "description": "Modern online advertising systems inevitably rely on personalization methods,\nsuch as click-through rate (CTR) prediction. Recent progress in CTR prediction\nenjoys the rich representation capabilities of deep learning and achieves great\nsuccess in large-scale industrial applications. However, these methods can\nsuffer from lack of exploration. Another line of prior work addresses the\nexploration-exploitation trade-off problem with contextual bandit methods,\nwhich are recently less studied in the industry due to the difficulty in\nextending their flexibility with deep models. In this paper, we propose a novel\nDeep Uncertainty-Aware Learning (DUAL) method to learn CTR models based on\nGaussian processes, which can provide predictive uncertainty estimations while\nmaintaining the flexibility of deep neural networks. DUAL can be easily\nimplemented on existing models and deployed in real-time systems with minimal\nextra computational overhead. By linking the predictive uncertainty estimation\nability of DUAL to well-known bandit algorithms, we further present DUAL-based\nAd-ranking strategies to boost up long-term utilities such as the social\nwelfare in advertising systems. Experimental results on several public datasets\ndemonstrate the effectiveness of our methods. Remarkably, an online A/B test\ndeployed in the Alibaba display advertising platform shows an 8.2% social\nwelfare improvement and an 8.0% revenue lift.",
          "link": "http://arxiv.org/abs/2012.02298",
          "publishedOn": "2021-06-16T01:21:04.267Z",
          "wordCount": 675,
          "title": "Exploration in Online Advertising Systems with Deep Uncertainty-Aware Learning. (arXiv:2012.02298v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08042",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tseytlin_B/0/1/0/all/0/1\">Boris Tseytlin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Makarov_I/0/1/0/all/0/1\">Ilya Makarov</a>",
          "description": "We approach the problem of hotel recognition with deep metric learning. We\noverview the existing approaches and propose a modification to Contrastive loss\ncalled Contrastive-Triplet loss. We construct a robust pipeline for\nbenchmarking metric learning models and perform experiments on Hotels-50K and\nCUB200 datasets. Contrastive-Triplet loss is shown to achieve better retrieval\non Hotels-50k. We open-source our code.",
          "link": "http://arxiv.org/abs/2106.08042",
          "publishedOn": "2021-06-16T01:21:03.979Z",
          "wordCount": 491,
          "title": "Hotel Recognition via Latent Image Embedding. (arXiv:2106.08042v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08019",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Volske_M/0/1/0/all/0/1\">Michael V&#xf6;lske</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bondarenko_A/0/1/0/all/0/1\">Alexander Bondarenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frobe_M/0/1/0/all/0/1\">Maik Fr&#xf6;be</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hagen_M/0/1/0/all/0/1\">Matthias Hagen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stein_B/0/1/0/all/0/1\">Benno Stein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_J/0/1/0/all/0/1\">Jaspreet Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anand_A/0/1/0/all/0/1\">Avishek Anand</a>",
          "description": "Recently, neural networks have been successfully employed to improve upon\nstate-of-the-art performance in ad-hoc retrieval tasks via machine-learned\nranking functions. While neural retrieval models grow in complexity and impact,\nlittle is understood about their correspondence with well-studied IR\nprinciples. Recent work on interpretability in machine learning has provided\ntools and techniques to understand neural models in general, yet there has been\nlittle progress towards explaining ranking models.\n\nWe investigate whether one can explain the behavior of neural ranking models\nin terms of their congruence with well understood principles of document\nranking by using established theories from axiomatic IR. Axiomatic analysis of\ninformation retrieval models has formalized a set of constraints on ranking\ndecisions that reasonable retrieval models should fulfill. We operationalize\nthis axiomatic thinking to reproduce rankings based on combinations of\nelementary constraints. This allows us to investigate to what extent the\nranking decisions of neural rankers can be explained in terms of retrieval\naxioms, and which axioms apply in which situations. Our experimental study\nconsiders a comprehensive set of axioms over several representative neural\nrankers. While the existing axioms can already explain the particularly\nconfident ranking decisions rather well, future work should extend the axiom\nset to also cover the other still \"unexplainable\" neural IR rank decisions.",
          "link": "http://arxiv.org/abs/2106.08019",
          "publishedOn": "2021-06-16T01:21:03.957Z",
          "wordCount": 649,
          "title": "Towards Axiomatic Explanations for Neural Ranking Models. (arXiv:2106.08019v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07864",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_F/0/1/0/all/0/1\">Fajie Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jiaxi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiangnan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chengming Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Min Yang</a>",
          "description": "Making accurate recommendations for cold-start users has been a longstanding\nand critical challenge for recommender systems (RS). Cross-domain\nrecommendations (CDR) offer a solution to tackle such a cold-start problem when\nthere is no sufficient data for the users who have rarely used the system. An\neffective approach in CDR is to leverage the knowledge (e.g., user\nrepresentations) learned from a related but different domain and transfer it to\nthe target domain. Fine-tuning works as an effective transfer learning\ntechnique for this objective, which adapts the parameters of a pre-trained\nmodel from the source domain to the target domain. However, current methods are\nmainly based on the global fine-tuning strategy: the decision of which layers\nof the pre-trained model to freeze or fine-tune is taken for all users in the\ntarget domain. In this paper, we argue that users in RS are personalized and\nshould have their own fine-tuning policies for better preference transfer\nlearning. As such, we propose a novel User-specific Adaptive Fine-tuning method\n(UAF), selecting which layers of the pre-trained network to fine-tune, on a\nper-user basis. Specifically, we devise a policy network with three alternative\nstrategies to automatically decide which layers to be fine-tuned and which\nlayers to have their parameters frozen for each user. Extensive experiments\nshow that the proposed UAF exhibits significantly better and more robust\nperformance for user cold-start recommendation.",
          "link": "http://arxiv.org/abs/2106.07864",
          "publishedOn": "2021-06-16T01:21:03.932Z",
          "wordCount": 648,
          "title": "User-specific Adaptive Fine-tuning for Cross-domain Recommendations. (arXiv:2106.07864v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07720",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Peito_J/0/1/0/all/0/1\">Joel Peito</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_Q/0/1/0/all/0/1\">Qiwei Han</a>",
          "description": "In contrast to many other domains, recommender systems in health services may\nbenefit particularly from the incorporation of health domain knowledge, as it\nhelps to provide meaningful and personalised recommendations catering to the\nindividual's health needs. With recent advances in representation learning\nenabling the hierarchical embedding of health knowledge into the hyperbolic\nPoincare space, this work proposes a content-based recommender system for\npatient-doctor matchmaking in primary care based on patients' health profiles,\nenriched by pre-trained Poincare embeddings of the ICD-9 codes through transfer\nlearning. The proposed model outperforms its conventional counterpart in terms\nof recommendation accuracy and has several important business implications for\nimproving the patient-doctor relationship.",
          "link": "http://arxiv.org/abs/2106.07720",
          "publishedOn": "2021-06-16T01:21:03.919Z",
          "wordCount": 552,
          "title": "Incorporating Domain Knowledge into Health Recommender Systems using Hyperbolic Embeddings. (arXiv:2106.07720v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07931",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Beelen_T/0/1/0/all/0/1\">T. Beelen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Velner_E/0/1/0/all/0/1\">E. Velner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ordelman_R/0/1/0/all/0/1\">R. Ordelman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Truong_K/0/1/0/all/0/1\">K.P. Truong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Evers_V/0/1/0/all/0/1\">V. Evers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huibers_T/0/1/0/all/0/1\">T. Huibers</a>",
          "description": "In this paper, we identify challenges in children's current information\nretrieval process, and propose conversational robots as an opportunity to ease\nthis process in a responsible way. Tools children currently use in this\nprocess, such as search engines on a computer or voice agents, do not always\nmeet their specific needs. The conversational robot we propose maintains\ncontext, asks clarifying questions, and gives suggestions in order to better\nmeet children's needs. Since children are often too trusting of robots, we\npropose to have the robot measure, monitor and adapt to the trust the child has\nin the robot. This way, we hope to induce a critical attitude with the children\nduring their information retrieval process.",
          "link": "http://arxiv.org/abs/2106.07931",
          "publishedOn": "2021-06-16T01:21:03.897Z",
          "wordCount": 570,
          "title": "Does your robot know? Enhancing children's information retrieval through spoken conversation with responsible robots. (arXiv:2106.07931v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07742",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brandsen_A/0/1/0/all/0/1\">Alex Brandsen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verberne_S/0/1/0/all/0/1\">Suzan Verberne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lambers_K/0/1/0/all/0/1\">Karsten Lambers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wansleeben_M/0/1/0/all/0/1\">Milco Wansleeben</a>",
          "description": "The amount of archaeological literature is growing rapidly. Until recently,\nthese data were only accessible through metadata search. We implemented a text\nretrieval engine for a large archaeological text collection ($\\sim 658$ Million\nwords). In archaeological IR, domain-specific entities such as locations, time\nperiods, and artefacts, play a central role. This motivated the development of\na named entity recognition (NER) model to annotate the full collection with\narchaeological named entities. In this paper, we present ArcheoBERTje, a BERT\nmodel pre-trained on Dutch archaeological texts. We compare the model's quality\nand output on a Named Entity Recognition task to a generic multilingual model\nand a generic Dutch model. We also investigate ensemble methods for combining\nmultiple BERT models, and combining the best BERT model with a domain thesaurus\nusing Conditional Random Fields (CRF). We find that ArcheoBERTje outperforms\nboth the multilingual and Dutch model significantly with a smaller standard\ndeviation between runs, reaching an average F1 score of 0.735. The model also\noutperforms ensemble methods combining the three models. Combining ArcheoBERTje\npredictions and explicit domain knowledge from the thesaurus did not increase\nthe F1 score. We quantitatively and qualitatively analyse the differences\nbetween the vocabulary and output of the BERT models on the full collection and\nprovide some valuable insights in the effect of fine-tuning for specific\ndomains. Our results indicate that for a highly specific text domain such as\narchaeology, further pre-training on domain-specific data increases the model's\nquality on NER by a much larger margin than shown for other domains in the\nliterature, and that domain-specific pre-training makes the addition of domain\nknowledge from a thesaurus unnecessary.",
          "link": "http://arxiv.org/abs/2106.07742",
          "publishedOn": "2021-06-16T01:21:03.869Z",
          "wordCount": 710,
          "title": "Can BERT Dig It? -- Named Entity Recognition for Information Retrieval in the Archaeology Domain. (arXiv:2106.07742v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08072",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Emery_J/0/1/0/all/0/1\">Jules Azad Emery</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Latapy_M/0/1/0/all/0/1\">Matthieu Latapy</a>",
          "description": "Despite the fact that it is publicly available, collecting and processing the\nfull bitcoin blockchain data is not trivial. Its mere size, history, and other\nfeatures indeed raise quite specific challenges, that we address in this paper.\nThe strengths of our approach are the following: it relies on very basic and\nstandard tools, which makes the procedure reliable and easily reproducible; it\nis a purely lossless procedure ensuring that we catch and preserve all existing\ndata; it provides additional indexing that makes it easy to further process the\nwhole data and select appropriate subsets of it. We present our procedure in\ndetails and illustrate its added value on large-scale use cases, like address\nclustering. We provide an implementation online, as well as the obtained\ndataset.",
          "link": "http://arxiv.org/abs/2106.08072",
          "publishedOn": "2021-06-16T01:21:03.828Z",
          "wordCount": 559,
          "title": "Full Bitcoin Blockchain Data Made Easy. (arXiv:2106.08072v1 [cs.SI])"
        },
        {
          "id": "http://arxiv.org/abs/2101.06983",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1\">Luyu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yunyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Callan_J/0/1/0/all/0/1\">Jamie Callan</a>",
          "description": "Contrastive learning has been applied successfully to learn vector\nrepresentations of text. Previous research demonstrated that learning\nhigh-quality representations benefits from batch-wise contrastive loss with a\nlarge number of negatives. In practice, the technique of in-batch negative is\nused, where for each example in a batch, other batch examples' positives will\nbe taken as its negatives, avoiding encoding extra negatives. This, however,\nstill conditions each example's loss on all batch examples and requires fitting\nthe entire large batch into GPU memory. This paper introduces a gradient\ncaching technique that decouples backpropagation between contrastive loss and\nthe encoder, removing encoder backward pass data dependency along the batch\ndimension. As a result, gradients can be computed for one subset of the batch\nat a time, leading to almost constant memory usage.",
          "link": "http://arxiv.org/abs/2101.06983",
          "publishedOn": "2021-06-16T00:27:38.497Z",
          "wordCount": 593,
          "title": "Scaling Deep Contrastive Learning Batch Size under Memory Limited Setup. (arXiv:2101.06983v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03954",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pereira_G/0/1/0/all/0/1\">Geand Trindade Pereira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santos_M/0/1/0/all/0/1\">Moises Rocha dos Santos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carvalho_A/0/1/0/all/0/1\">Andre Carlos Ponce de Leon Ferreira de Carvalho</a>",
          "description": "With the popularity of Machine Learning (ML) solutions, algorithms and data\nhave been released faster than the capacity of processing them. In this\ncontext, the problem of Algorithm Recommendation (AR) is receiving a\nsignificant deal of attention recently. This problem has been addressed in the\nliterature as a learning task, often as a Meta-Learning problem where the aim\nis to recommend the best alternative for a specific dataset. For such, datasets\nencoded by meta-features are explored by ML algorithms that try to learn the\nmapping between meta-representations and the best technique to be used. One of\nthe challenges for the successful use of ML is to define which features are the\nmost valuable for a specific dataset since several meta-features can be used,\nwhich increases the meta-feature dimension. This paper presents an empirical\nanalysis of Feature Selection and Feature Extraction in the meta-level for the\nAR problem. The present study was focused on three criteria: predictive\nperformance, dimensionality reduction, and pipeline runtime. As we verified,\napplying Dimensionality Reduction (DR) methods did not improve predictive\nperformances in general. However, DR solutions reduced about 80% of the\nmeta-features, obtaining pretty much the same performance as the original setup\nbut with lower runtimes. The only exception was PCA, which presented about the\nsame runtime as the original meta-features. Experimental results also showed\nthat various datasets have many non-informative meta-features and that it is\npossible to obtain high predictive performance using around 20% of the original\nmeta-features. Therefore, due to their natural trend for high dimensionality,\nDR methods should be used for Meta-Feature Selection and Meta-Feature\nExtraction.",
          "link": "http://arxiv.org/abs/2106.03954",
          "publishedOn": "2021-06-15T22:41:24.942Z",
          "wordCount": 718,
          "title": "Evaluating Meta-Feature Selection for the Algorithm Recommendation Problem. (arXiv:2106.03954v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14188",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_L/0/1/0/all/0/1\">Liyi Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_J/0/1/0/all/0/1\">Junqi Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Haoqi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zhenzhe Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhiye Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_Z/0/1/0/all/0/1\">Zhizhuang Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_F/0/1/0/all/0/1\">Fei Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_L/0/1/0/all/0/1\">Lvyin Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haiyang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1\">Chuan Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yuning Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaoqiang Zhu</a>",
          "description": "Advertising expenditures have become the major source of revenue for\ne-commerce platforms. Providing good advertising experiences for advertisers by\nreducing their costs of trial and error in discovering the optimal advertising\nstrategies is crucial for the long-term prosperity of online advertising. To\nachieve this goal, the advertising platform needs to identify the advertiser's\noptimization objectives, and then recommend the corresponding strategies to\nfulfill the objectives. In this work, we first deploy a prototype of strategy\nrecommender system on Taobao display advertising platform, which indeed\nincreases the advertisers' performance and the platform's revenue, indicating\nthe effectiveness of strategy recommendation for online advertising. We further\naugment this prototype system by explicitly learning the advertisers'\npreferences over various advertising performance indicators and then\noptimization objectives through their adoptions of different recommending\nadvertising strategies. We use contextual bandit algorithms to efficiently\nlearn the advertisers' preferences and maximize the recommendation adoption,\nsimultaneously. Simulation experiments based on Taobao online bidding data show\nthat the designed algorithms can effectively optimize the strategy adoption\nrate of advertisers.",
          "link": "http://arxiv.org/abs/2105.14188",
          "publishedOn": "2021-06-15T22:41:24.921Z",
          "wordCount": 675,
          "title": "We Know What You Want: An Advertising Strategy Recommender System for Online Advertising. (arXiv:2105.14188v3 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03569",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Junliang Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1\">Hongzhi Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_M/0/1/0/all/0/1\">Min Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_X/0/1/0/all/0/1\">Xin Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiangliang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hung_N/0/1/0/all/0/1\">Nguyen Quoc Viet Hung</a>",
          "description": "Self-supervised learning (SSL), which can automatically generate ground-truth\nsamples from raw data, holds vast potential to improve recommender systems.\nMost existing SSL-based methods perturb the raw data graph with uniform\nnode/edge dropout to generate new data views and then conduct the\nself-discrimination based contrastive learning over different views to learn\ngeneralizable representations. Under this scheme, only a bijective mapping is\nbuilt between nodes in two different views, which means that the\nself-supervision signals from other nodes are being neglected. Due to the\nwidely observed homophily in recommender systems, we argue that the supervisory\nsignals from other nodes are also highly likely to benefit the representation\nlearning for recommendation. To capture these signals, a general socially-aware\nSSL framework that integrates tri-training is proposed in this paper.\nTechnically, our framework first augments the user data views with the user\nsocial information. And then under the regime of tri-training for multi-view\nencoding, the framework builds three graph encoders (one for recommendation)\nupon the augmented views and iteratively improves each encoder with\nself-supervision signals from other users, generated by the other two encoders.\nSince the tri-training operates on the augmented views of the same data sources\nfor self-supervision signals, we name it self-supervised tri-training.\nExtensive experiments on multiple real-world datasets consistently validate the\neffectiveness of the self-supervised tri-training framework for improving\nrecommendation. The code is released at https://github.com/Coder-Yu/QRec.",
          "link": "http://arxiv.org/abs/2106.03569",
          "publishedOn": "2021-06-15T01:45:13.457Z",
          "wordCount": 672,
          "title": "Socially-Aware Self-Supervised Tri-Training for Recommendation. (arXiv:2106.03569v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06900",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zefang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_S/0/1/0/all/0/1\">Shuran Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quan_Y/0/1/0/all/0/1\">Yinzhu Quan</a>",
          "description": "Group recommender systems are widely used in current web applications. In\nthis paper, we propose a novel group recommender system based on the deep\nreinforcement learning. We introduce the MovieLens data at first and generate\none random group dataset, MovieLens-Rand, from it. This randomly generated\ndataset is described and analyzed. We also present experimental settings and\ntwo state-of-art baselines, AGREE and GroupIM. The framework of our novel\nmodel, the Deep Reinforcement learning based Group Recommender system (DRGR),\nis proposed. Actor-critic networks are implemented with the deep deterministic\npolicy gradient algorithm. The DRGR model is applied on the MovieLens-Rand\ndataset with two baselines. Compared with baselines, we conclude that DRGR\nperforms better than GroupIM due to long interaction histories but worse than\nAGREE because of the self-attention mechanism. We express advantages and\nshortcomings of DRGR and also give future improvement directions at the end.",
          "link": "http://arxiv.org/abs/2106.06900",
          "publishedOn": "2021-06-15T01:45:13.386Z",
          "wordCount": 563,
          "title": "Deep Reinforcement Learning based Group Recommender System. (arXiv:2106.06900v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06910",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_A/0/1/0/all/0/1\">Arunava Kumar Chakraborty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1\">Sourav Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolya_A/0/1/0/all/0/1\">Anup Kumar Kolya</a>",
          "description": "As the Covid-19 outbreaks rapidly all over the world day by day and also\naffects the lives of million, a number of countries declared complete lock-down\nto check its intensity. During this lockdown period, social media plat-forms\nhave played an important role to spread information about this pandemic across\nthe world, as people used to express their feelings through the social\nnetworks. Considering this catastrophic situation, we developed an experimental\napproach to analyze the reactions of people on Twitter taking into ac-count the\npopular words either directly or indirectly based on this pandemic. This paper\nrepresents the sentiment analysis on collected large number of tweets on\nCoronavirus or Covid-19. At first, we analyze the trend of public sentiment on\nthe topics related to Covid-19 epidemic using an evolutionary classification\nfollowed by the n-gram analysis. Then we calculated the sentiment ratings on\ncollected tweet based on their class. Finally, we trained the long-short term\nnetwork using two types of rated tweets to predict sentiment on Covid-19 data\nand obtained an overall accuracy of 84.46%.",
          "link": "http://arxiv.org/abs/2106.06910",
          "publishedOn": "2021-06-15T01:45:13.169Z",
          "wordCount": 680,
          "title": "Sentiment Analysis of Covid-19 Tweets using Evolutionary Classification-Based LSTM Model. (arXiv:2106.06910v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2010.09029",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chen Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xinyi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zafarani_R/0/1/0/all/0/1\">Reza Zafarani</a>",
          "description": "COVID-19 has impacted all lives. To maintain social distancing and avoiding\nexposure, works and lives have gradually moved online. Under this trend, social\nmedia usage to obtain COVID-19 news has increased. Also, misinformation on\nCOVID-19 is frequently spread on social media. In this work, we develop\nCHECKED, the first Chinese dataset on COVID-19 misinformation. CHECKED provides\na total 2,104 verified microblogs related to COVID-19 from December 2019 to\nAugust 2020, identified by using a specific list of keywords. Correspondingly,\nCHECKED includes 1,868,175 reposts, 1,185,702 comments, and 56,852,736 likes\nthat reveal how these verified microblogs are spread and reacted on Weibo. The\ndataset contains a rich set of multimedia information for each microblog\nincluding ground-truth label, textual, visual, temporal, and network\ninformation. Extensive experiments have been conducted to analyze CHECKED data\nand to provide benchmark results for well-established methods when predicting\nfake news using CHECKED. We hope that CHECKED can facilitate studies that\ntarget misinformation on coronavirus. The dataset is available at\nhttps://github.com/cyang03/CHECKED.",
          "link": "http://arxiv.org/abs/2010.09029",
          "publishedOn": "2021-06-15T01:45:13.134Z",
          "wordCount": 671,
          "title": "CHECKED: Chinese COVID-19 Fake News Dataset. (arXiv:2010.09029v2 [cs.SI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06739",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Siddharth_L/0/1/0/all/0/1\">L Siddharth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blessing_L/0/1/0/all/0/1\">Lucienne T.M. Blessing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wood_K/0/1/0/all/0/1\">Kristin L. Wood</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1\">Jianxi Luo</a>",
          "description": "We propose a large, scalable engineering knowledge graph, comprising sets of\n(entity, relationship, entity) triples that are real-world engineering facts\nfound in the patent database. We apply a set of rules based on the syntactic\nand lexical properties of claims in a patent document to extract facts. We\naggregate these facts within each patent document and integrate the aggregated\nsets of facts across the patent database to obtain the engineering knowledge\ngraph. Such a knowledge graph is expected to support inference, reasoning, and\nrecalling in various engineering tasks. The knowledge graph has a greater size\nand coverage in comparison with the previously used knowledge graphs and\nsemantic networks in the engineering literature.",
          "link": "http://arxiv.org/abs/2106.06739",
          "publishedOn": "2021-06-15T01:45:13.110Z",
          "wordCount": 544,
          "title": "Engineering Knowledge Graph from Patent Database. (arXiv:2106.06739v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06722",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1\">Kun Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wayne Xin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jingyuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Ji-Rong Wen</a>",
          "description": "Due to the flexibility in modelling data heterogeneity, heterogeneous\ninformation network (HIN) has been adopted to characterize complex and\nheterogeneous auxiliary data in top-$N$ recommender systems, called\n\\emph{HIN-based recommendation}. HIN characterizes complex, heterogeneous data\nrelations, containing a variety of information that may not be related to the\nrecommendation task. Therefore, it is challenging to effectively leverage\nuseful information from HINs for improving the recommendation performance. To\naddress the above issue, we propose a Curriculum pre-training based\nHEterogeneous Subgraph Transformer (called \\emph{CHEST}) with new \\emph{data\ncharacterization}, \\emph{representation model} and \\emph{learning algorithm}.\n\nSpecifically, we consider extracting useful information from HIN to compose\nthe interaction-specific heterogeneous subgraph, containing both sufficient and\nrelevant context information for recommendation. Then we capture the rich\nsemantics (\\eg graph structure and path semantics) within the subgraph via a\nheterogeneous subgraph Transformer, where we encode the subgraph with\nmulti-slot sequence representations. Besides, we design a curriculum\npre-training strategy to provide an elementary-to-advanced learning process, by\nwhich we smoothly transfer basic semantics in HIN for modeling user-item\ninteraction relation.\n\nExtensive experiments conducted on three real-world datasets demonstrate the\nsuperiority of our proposed method over a number of competitive baselines,\nespecially when only limited training data is available.",
          "link": "http://arxiv.org/abs/2106.06722",
          "publishedOn": "2021-06-15T01:45:12.267Z",
          "wordCount": 627,
          "title": "Curriculum Pre-Training Heterogeneous Subgraph Transformer for Top-$N$ Recommendation. (arXiv:2106.06722v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06713",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xiangyu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Haochen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_W/0/1/0/all/0/1\">Wenqi Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jiliang Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chong Wang</a>",
          "description": "Designing an effective loss function plays a crucial role in training deep\nrecommender systems. Most existing works often leverage a predefined and fixed\nloss function that could lead to suboptimal recommendation quality and training\nefficiency. Some recent efforts rely on exhaustively or manually searched\nweights to fuse a group of candidate loss functions, which is exceptionally\ncostly in computation and time. They also neglect the various convergence\nbehaviors of different data examples. In this work, we propose an AutoLoss\nframework that can automatically and adaptively search for the appropriate loss\nfunction from a set of candidates. To be specific, we develop a novel\ncontroller network, which can dynamically adjust the loss probabilities in a\ndifferentiable manner. Unlike existing algorithms, the proposed controller can\nadaptively generate the loss probabilities for different data examples\naccording to their varied convergence behaviors. Such design improves the\nmodel's generalizability and transferability between deep recommender systems\nand datasets. We evaluate the proposed framework on two benchmark datasets. The\nresults show that AutoLoss outperforms representative baselines. Further\nexperiments have been conducted to deepen our understandings of AutoLoss,\nincluding its transferability, components and training efficiency.",
          "link": "http://arxiv.org/abs/2106.06713",
          "publishedOn": "2021-06-15T01:45:12.220Z",
          "wordCount": 634,
          "title": "AutoLoss: Automated Loss Function Search in Recommendations. (arXiv:2106.06713v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2104.08976",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mackenzie_J/0/1/0/all/0/1\">Joel Mackenzie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petri_M/0/1/0/all/0/1\">Matthias Petri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moffat_A/0/1/0/all/0/1\">Alistair Moffat</a>",
          "description": "Inverted indexes continue to be a mainstay of text search engines, allowing\nefficient querying of large document collections. While there are a number of\npossible organizations, document-ordered indexes are the most common, since\nthey are amenable to various query types, support index updates, and allow for\nefficient dynamic pruning operations. One disadvantage with document-ordered\nindexes is that high-scoring documents can be distributed across the document\nidentifier space, meaning that index traversal algorithms that terminate early\nmight put search effectiveness at risk. The alternative is impact-ordered\nindexes, which primarily support top-k disjunctions, but also allow for anytime\nquery processing, where the search can be terminated at any time, with search\nquality improving as processing latency increases. Anytime query processing can\nbe used to effectively reduce high-percentile tail latency which is essential\nfor operational scenarios in which a service level agreement (SLA) imposes\nresponse time requirements. In this work, we show how document-ordered indexes\ncan be organized such that they can be queried in an anytime fashion, enabling\nstrict latency control with effective early termination. Our experiments show\nthat processing document-ordered topical segments selected by a simple score\nestimator outperforms existing anytime algorithms, and allows query runtimes to\nbe accurately limited in order to comply with SLA requirements.",
          "link": "http://arxiv.org/abs/2104.08976",
          "publishedOn": "2021-06-14T01:38:51.546Z",
          "wordCount": 659,
          "title": "Anytime Ranking on Document-Ordered Indexes. (arXiv:2104.08976v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06244",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Otto_C/0/1/0/all/0/1\">Christian Otto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_R/0/1/0/all/0/1\">Ran Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pardi_G/0/1/0/all/0/1\">Georg Pardi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoyer_J/0/1/0/all/0/1\">Johannes von Hoyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rokicki_M/0/1/0/all/0/1\">Markus Rokicki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoppe_A/0/1/0/all/0/1\">Anett Hoppe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holtz_P/0/1/0/all/0/1\">Peter Holtz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kammerer_Y/0/1/0/all/0/1\">Yvonne Kammerer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dietze_S/0/1/0/all/0/1\">Stefan Dietze</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ewerth_R/0/1/0/all/0/1\">Ralph Ewerth</a>",
          "description": "In informal learning scenarios the popularity of multimedia content, such as\nvideo tutorials or lectures, has significantly increased. Yet, the users'\ninteractions, navigation behavior, and consequently learning outcome, have not\nbeen researched extensively. Related work in this field, also called search as\nlearning, has focused on behavioral or text resource features to predict\nlearning outcome and knowledge gain. In this paper, we investigate whether we\ncan exploit features representing multimedia resource consumption to predict of\nknowledge gain (KG) during Web search from in-session data, that is without\nprior knowledge about the learner. For this purpose, we suggest a set of\nmultimedia features related to image and video consumption. Our feature\nextraction is evaluated in a lab study with 113 participants where we collected\ndata for a given search as learning task on the formation of thunderstorms and\nlightning. We automatically analyze the monitored log data and utilize\nstate-of-the-art computer vision methods to extract features about the seen\nmultimedia resources. Experimental results demonstrate that multimedia features\ncan improve KG prediction. Finally, we provide an analysis on feature\nimportance (text and multimedia) for KG prediction.",
          "link": "http://arxiv.org/abs/2106.06244",
          "publishedOn": "2021-06-14T01:38:51.500Z",
          "wordCount": 633,
          "title": "Predicting Knowledge Gain during Web Search based on Multimedia Resource Consumption. (arXiv:2106.06244v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06471",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xingyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_M/0/1/0/all/0/1\">Muchao Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_Q/0/1/0/all/0/1\">Quanzeng You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_F/0/1/0/all/0/1\">Fenglong Ma</a>",
          "description": "Medical report generation is one of the most challenging tasks in medical\nimage analysis. Although existing approaches have achieved promising results,\nthey either require a predefined template database in order to retrieve\nsentences or ignore the hierarchical nature of medical report generation. To\naddress these issues, we propose MedWriter that incorporates a novel\nhierarchical retrieval mechanism to automatically extract both report and\nsentence-level templates for clinically accurate report generation. MedWriter\nfirst employs the Visual-Language Retrieval~(VLR) module to retrieve the most\nrelevant reports for the given images. To guarantee the logical coherence\nbetween sentences, the Language-Language Retrieval~(LLR) module is introduced\nto retrieve relevant sentences based on the previous generated description. At\nlast, a language decoder fuses image features and features from retrieved\nreports and sentences to generate meaningful medical reports. We verified the\neffectiveness of our model by automatic evaluation and human evaluation on two\ndatasets, i.e., Open-I and MIMIC-CXR.",
          "link": "http://arxiv.org/abs/2106.06471",
          "publishedOn": "2021-06-14T01:38:51.477Z",
          "wordCount": 592,
          "title": "Writing by Memorizing: Hierarchical Retrieval-based Medical Report Generation. (arXiv:2106.06471v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06467",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hao_B/0/1/0/all/0/1\">Bin Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Min Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1\">Weizhi Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1\">Shaoyun Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1\">Xinxing Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shan_H/0/1/0/all/0/1\">Houzhi Shan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yiqun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1\">Shaoping Ma</a>",
          "description": "Data plays a vital role in machine learning studies. In the research of\nrecommendation, both user behaviors and side information are helpful to model\nusers. So, large-scale real scenario datasets with abundant user behaviors will\ncontribute a lot. However, it is not easy to get such datasets as most of them\nare only hold and protected by companies. In this paper, a new large-scale\ndataset collected from a knowledge-sharing platform is presented, which is\ncomposed of around 100M interactions collected within 10 days, 798K users, 165K\nquestions, 554K answers, 240K authors, 70K topics, and more than 501K user\nquery keywords. There are also descriptions of users, answers, questions,\nauthors, and topics, which are anonymous. Note that each user's latest query\nkeywords have not been included in previous open datasets, which reveal users'\nexplicit information needs.\n\nWe characterize the dataset and demonstrate its potential applications for\nrecommendation study. Multiple experiments show the dataset can be used to\nevaluate algorithms in general top-N recommendation, sequential recommendation,\nand context-aware recommendation. This dataset can also be used to integrate\nsearch and recommendation and recommendation with negative feedback. Besides,\ntasks beyond recommendation, such as user gender prediction, most valuable\nanswerer identification, and high-quality answer recognition, can also use this\ndataset. To the best of our knowledge, this is the largest real-world\ninteraction dataset for personalized recommendation.",
          "link": "http://arxiv.org/abs/2106.06467",
          "publishedOn": "2021-06-14T01:38:51.319Z",
          "wordCount": 662,
          "title": "A Large-Scale Rich Context Query and Recommendation Dataset in Online Knowledge-Sharing. (arXiv:2106.06467v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06420",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Al_Kaabi_K/0/1/0/all/0/1\">Karrar Al-Kaabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monsefi_R/0/1/0/all/0/1\">Reza Monsefi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zabihzadeh_D/0/1/0/all/0/1\">Davood Zabihzadeh</a>",
          "description": "Metric learning algorithms aim to learn a distance function that brings the\nsemantically similar data items together and keeps dissimilar ones at a\ndistance. The traditional Mahalanobis distance learning is equivalent to find a\nlinear projection. In contrast, Deep Metric Learning (DML) methods are proposed\nthat automatically extract features from data and learn a non-linear\ntransformation from input space to a semantically embedding space. Recently,\nmany DML methods are proposed focused to enhance the discrimination power of\nthe learned metric by providing novel sampling strategies or loss functions.\nThis approach is very helpful when both the training and test examples are\ncoming from the same set of categories. However, it is less effective in many\napplications of DML such as image retrieval and person-reidentification. Here,\nthe DML should learn general semantic concepts from observed classes and employ\nthem to rank or identify objects from unseen categories. Neglecting the\ngeneralization ability of the learned representation and just emphasizing to\nlearn a more discriminative embedding on the observed classes may lead to the\noverfitting problem. To address this limitation, we propose a framework to\nenhance the generalization power of existing DML methods in a Zero-Shot\nLearning (ZSL) setting by general yet discriminative representation learning\nand employing a class adversarial neural network. To learn a more general\nrepresentation, we propose to employ feature maps of intermediate layers in a\ndeep neural network and enhance their discrimination power through an attention\nmechanism. Besides, a class adversarial network is utilized to enforce the deep\nmodel to seek class invariant features for the DML task. We evaluate our work\non widely used machine vision datasets in a ZSL setting.",
          "link": "http://arxiv.org/abs/2106.06420",
          "publishedOn": "2021-06-14T01:38:51.279Z",
          "wordCount": 744,
          "title": "A Framework to Enhance Generalization of Deep Metric Learning methods using General Discriminative Feature Learning and Class Adversarial Neural Networks. (arXiv:2106.06420v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06165",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1\">Ziwei Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiwei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1\">Lei Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Philip S. Yu</a>",
          "description": "The sequential patterns within the user interactions are pivotal for\nrepresenting the user's preference and capturing latent relationships among\nitems. The recent advancements of sequence modeling by Transformers advocate\nthe community to devise more effective encoders for the sequential\nrecommendation. Most existing sequential methods assume users are\ndeterministic. However, item-item transitions might fluctuate significantly in\nseveral item aspects and exhibit randomness of user interests. This\n\\textit{stochastic characteristics} brings up a solid demand to include\nuncertainties in representing sequences and items. Additionally, modeling\nsequences and items with uncertainties expands users' and items' interaction\nspaces, thus further alleviating cold-start problems.\n\nIn this work, we propose a Distribution-based Transformer for Sequential\nRecommendation (DT4SR), which injects uncertainties into sequential modeling.\nWe use Elliptical Gaussian distributions to describe items and sequences with\nuncertainty. We describe the uncertainty in items and sequences as Elliptical\nGaussian distribution. And we adopt Wasserstein distance to measure the\nsimilarity between distributions. We devise two novel Trans-formers for\nmodeling mean and covariance, which guarantees the positive-definite property\nof distributions. The proposed method significantly outperforms the\nstate-of-the-art methods. The experiments on three benchmark datasets also\ndemonstrate its effectiveness in alleviating cold-start issues. The code is\navailable inhttps://github.com/DyGRec/DT4SR.",
          "link": "http://arxiv.org/abs/2106.06165",
          "publishedOn": "2021-06-14T01:38:51.217Z",
          "wordCount": 631,
          "title": "Modeling Sequences as Distributions with Uncertainty for Sequential Recommendation. (arXiv:2106.06165v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06216",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Waldis_A/0/1/0/all/0/1\">Andreas Waldis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mazzola_L/0/1/0/all/0/1\">Luca Mazzola</a>",
          "description": "Entity Recognition (ER) within a text is a fundamental exercise in Natural\nLanguage Processing, enabling further depending tasks such as Knowledge\nExtraction, Text Summarisation, or Keyphrase Extraction. An entity consists of\nsingle words or of a consecutive sequence of terms, constituting the basic\nbuilding blocks for communication. Mainstream ER approaches are mainly limited\nto flat structures, concentrating on the outermost entities while ignoring the\ninner ones. This paper introduces a partly-layered network architecture that\ndeals with the complexity of overlapping and nested cases. The proposed\narchitecture consists of two parts: (1) a shared Sequence Layer and (2) a\nstacked component with multiple Tagging Layers. The adoption of such an\narchitecture has the advantage of preventing overfit to a specific word-length,\nthus maintaining performance for longer entities despite their lower frequency.\nTo verify the proposed architecture's effectiveness, we train and evaluate this\narchitecture to recognise two kinds of entities - Concepts (CR) and Named\nEntities (NER). Our approach achieves state-of-the-art NER performances, while\nit outperforms previous CR approaches. Considering these promising results, we\nsee the possibility to evolve the architecture for other cases such as the\nextraction of events or the detection of argumentative components.",
          "link": "http://arxiv.org/abs/2106.06216",
          "publishedOn": "2021-06-14T01:38:51.205Z",
          "wordCount": 635,
          "title": "Nested and Balanced Entity Recognition using Multi-Task Learning. (arXiv:2106.06216v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06258",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chuhan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fangzhao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yongfeng Huang</a>",
          "description": "News recommendation is important for improving news reading experience of\nusers. Users' news click behaviors are widely used for inferring user interests\nand predicting future clicks. However, click behaviors are heavily affected by\nthe biases brought by the positions of news displayed on the webpage. It is\nimportant to eliminate the effect of position biases on the recommendation\nmodel to accurately target user interests. In this paper, we propose a news\nrecommendation method named DebiasGAN that can effectively eliminate the effect\nof position biases via adversarial learning. We use a bias-aware click model to\ncapture the influence of position bias on click behaviors, and we use a\nbias-invariant click model with random candidate news positions to estimate the\nideally unbiased click scores. We apply adversarial learning techniques to the\nhidden representations learned by the two models to help the bias-invariant\nclick model capture the bias-independent interest of users on news.\nExperimental results on two real-world datasets show that DebiasGAN can\neffectively improve the accuracy of news recommendation by eliminating position\nbiases.",
          "link": "http://arxiv.org/abs/2106.06258",
          "publishedOn": "2021-06-14T01:38:51.192Z",
          "wordCount": 596,
          "title": "DebiasGAN: Eliminating Position Bias in News Recommendation with Adversarial Learning. (arXiv:2106.06258v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06022",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bauer_M/0/1/0/all/0/1\">Martin Bauer</a>",
          "description": "For IoT to reach its full potential, the sharing and reuse of information in\ndifferent applications and across verticals is of paramount importance.\nHowever, there are a plethora of IoT platforms using different representations,\nprotocols and interaction patterns. To address this issue, the Fed4IoT project\nhas developed an IoT virtualization platform that, on the one hand, integrates\ninformation from many different source platforms and, on the other hand, makes\nthe information required by the respective users available in the target\nplatform of choice. To enable this, information is translated into a common,\nneutral exchange format. The format of choice is NGSI-LD, which is being\nstandardized by the ETSI Industry Specification Group on Context Information\nManagement (ETSI ISG CIM). Thing Visors are the components that translate the\nsource information to NGSI-LD, which is then delivered to the target platform\nand translated into the target format. ThingVisors can be implemented by hand,\nbut this requires significant human effort, especially considering the\nheterogeneity of low level information produced by a multitude of sensors.\nThus, supporting the human developer and, ideally, fully automating the process\nof extracting and enriching data and translating it to NGSI-LD is a crucial\nstep. Machine learning is a promising approach for this, but it typically\nrequires large amounts of hand-labelled data for training, an effort that makes\nit unrealistic in many IoT scenarios. A programmatic labelling approach called\nknowledge infusion that encodes expert knowledge is used for matching a schema\nor ontology extracted from the data with a target schema or ontology, providing\nthe basis for annotating the data and facilitating the translation to NGSI-LD.",
          "link": "http://arxiv.org/abs/2106.06022",
          "publishedOn": "2021-06-14T01:38:50.756Z",
          "wordCount": 690,
          "title": "IoT Virtualization with ML-based Information Extraction. (arXiv:2106.06022v1 [cs.DC])"
        }
      ]
    },
    {
      "title": "cs.MM updates on arXiv.org",
      "feedUrl": "http://export.arxiv.org/rss/cs.MM",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2106.08867",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Murray_Browne_T/0/1/0/all/0/1\">Tim Murray-Browne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tigas_P/0/1/0/all/0/1\">Panagiotis Tigas</a>",
          "description": "In many contexts, creating mappings for gestural interactions can form part\nof an artistic process. Creators seeking a mapping that is expressive, novel,\nand affords them a sense of authorship may not know how to program it up in a\nsignal processing patch. Tools like Wekinator and MIMIC allow creators to use\nsupervised machine learning to learn mappings from example input/output\npairings. However, a creator may know a good mapping when they encounter it yet\nstart with little sense of what the inputs or outputs should be. We call this\nan open-ended mapping process. Addressing this need, we introduce the latent\nmapping, which leverages the latent space of an unsupervised machine learning\nalgorithm such as a Variational Autoencoder trained on a corpus of unlabelled\ngestural data from the creator. We illustrate it with Sonified Body, a system\nmapping full-body movement to sound which we explore in a residency with three\ndancers.",
          "link": "http://arxiv.org/abs/2106.08867",
          "publishedOn": "2021-06-17T01:58:40.177Z",
          "wordCount": 629,
          "title": "Latent Mappings: Generating Open-Ended Expressive Mappings Using Variational Autoencoders. (arXiv:2106.08867v1 [cs.HC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08936",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Murn_L/0/1/0/all/0/1\">Luka Murn</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Blasi_S/0/1/0/all/0/1\">Saverio Blasi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Smeaton_A/0/1/0/all/0/1\">Alan F. Smeaton</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mrak_M/0/1/0/all/0/1\">Marta Mrak</a>",
          "description": "The versatility of recent machine learning approaches makes them ideal for\nimprovement of next generation video compression solutions. Unfortunately,\nthese approaches typically bring significant increases in computational\ncomplexity and are difficult to interpret into explainable models, affecting\ntheir potential for implementation within practical video coding applications.\nThis paper introduces a novel explainable neural network-based inter-prediction\nscheme, to improve the interpolation of reference samples needed for fractional\nprecision motion compensation. The approach requires a single neural network to\nbe trained from which a full quarter-pixel interpolation filter set is derived,\nas the network is easily interpretable due to its linear structure. A novel\ntraining framework enables each network branch to resemble a specific\nfractional shift. This practical solution makes it very efficient to use\nalongside conventional video coding schemes. When implemented in the context of\nthe state-of-the-art Versatile Video Coding (VVC) test model, 0.77%, 1.27% and\n2.25% BD-rate savings can be achieved on average for lower resolution sequences\nunder the random access, low-delay B and low-delay P configurations,\nrespectively, while the complexity of the learned interpolation schemes is\nsignificantly reduced compared to the interpolation with full CNNs.",
          "link": "http://arxiv.org/abs/2106.08936",
          "publishedOn": "2021-06-17T01:58:40.151Z",
          "wordCount": 664,
          "title": "Improved CNN-based Learning of Interpolation Filters for Low-Complexity Inter Prediction in Video Coding. (arXiv:2106.08936v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10005",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">C.-H. Huck Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chhabra_M/0/1/0/all/0/1\">Mohit Chhabra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Y.-C. Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_Q/0/1/0/all/0/1\">Quan Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoshinaga_T/0/1/0/all/0/1\">Tomoaki Yoshinaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murakami_T/0/1/0/all/0/1\">Tomokazu Murakami</a>",
          "description": "Physical processes, camera movement, and unpredictable environmental\nconditions like the presence of dust can induce noise and artifacts in video\nfeeds. We observe that popular unsupervised MOT methods are dependent on\nnoise-free inputs. We show that the addition of a small amount of artificial\nrandom noise causes a sharp degradation in model performance on benchmark\nmetrics. We resolve this problem by introducing a robust unsupervised\nmulti-object tracking (MOT) model: AttU-Net. The proposed single-head attention\nmodel helps limit the negative impact of noise by learning visual\nrepresentations at different segment scales. AttU-Net shows better unsupervised\nMOT tracking performance over variational inference-based state-of-the-art\nbaselines. We evaluate our method in the MNIST-MOT and the Atari game video\nbenchmark. We also provide two extended video datasets: ``Kuzushiji-MNIST MOT''\nwhich consists of moving Japanese characters and ``Fashion-MNIST MOT'' to\nvalidate the effectiveness of the MOT models.",
          "link": "http://arxiv.org/abs/2105.10005",
          "publishedOn": "2021-06-16T01:21:04.389Z",
          "wordCount": 644,
          "title": "Robust Unsupervised Multi-Object Tracking in Noisy Environments. (arXiv:2105.10005v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08104",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haoqi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_M/0/1/0/all/0/1\">Mingfu Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1\">Shichang Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yushu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jian Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Weiqiang Liu</a>",
          "description": "Deep neural networks (DNN) have achieved remarkable performance in various\nfields. However, training a DNN model from scratch requires a lot of computing\nresources and training data. It is difficult for most individual users to\nobtain such computing resources and training data. Model copyright infringement\nis an emerging problem in recent years. For instance, pre-trained models may be\nstolen or abuse by illegal users without the authorization of the model owner.\nRecently, many works on protecting the intellectual property of DNN models have\nbeen proposed. In these works, embedding watermarks into DNN based on backdoor\nis one of the widely used methods. However, when the DNN model is stolen, the\nbackdoor-based watermark may face the risk of being detected and removed by an\nadversary. In this paper, we propose a scheme to detect and remove watermark in\ndeep neural networks via generative adversarial networks (GAN). We demonstrate\nthat the backdoor-based DNN watermarks are vulnerable to the proposed GAN-based\nwatermark removal attack. The proposed attack method includes two phases. In\nthe first phase, we use the GAN and few clean images to detect and reverse the\nwatermark in the DNN model. In the second phase, we fine-tune the watermarked\nDNN based on the reversed backdoor images. Experimental evaluations on the\nMNIST and CIFAR10 datasets demonstrate that, the proposed method can\neffectively remove about 98% of the watermark in DNN models, as the watermark\nretention rate reduces from 100% to less than 2% after applying the proposed\nattack. In the meantime, the proposed attack hardly affects the model's\nperformance. The test accuracy of the watermarked DNN on the MNIST and the\nCIFAR10 datasets drops by less than 1% and 3%, respectively.",
          "link": "http://arxiv.org/abs/2106.08104",
          "publishedOn": "2021-06-16T01:21:04.329Z",
          "wordCount": 724,
          "title": "Detect and remove watermark in deep neural networks via generative adversarial networks. (arXiv:2106.08104v1 [cs.MM])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08017",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hengyuan Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Wenhao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yihao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1\">Dongliang He</a>",
          "description": "Legacy black-and-white photos are riddled with people's nostalgia and\nglorious memories of the past. To better relive the elapsed frozen moments, in\nthis paper, we present a deep exemplar-based image colorization approach named\nColor2Style to resurrect these grayscale image media by filling them with\nvibrant colors. Generally, for exemplar-based colorization, unsupervised and\nunpaired training are usually adopted, due to the difficulty of obtaining input\nand ground truth image pairs. To train an exemplar-based colorization model,\ncurrent algorithms usually strive to achieve two procedures: i) retrieving a\nlarge number of reference images with high similarity in advance, which is\ninevitably time-consuming and tedious; ii) designing complicated modules to\ntransfer the colors of the reference image to the grayscale image, by\ncalculating and leveraging the deep semantic correspondence between them (e.g.,\nnon-local operation). Contrary to the previous methods, we solve and simplify\nthe above two steps in one end-to-end learning procedure. First, we adopt a\nself-augmented self-reference training scheme, where the reference image is\ngenerated by graphical transformations from the original colorful one whereby\nthe training can be formulated in a paired manner. Second, instead of computing\ncomplex and inexplicable correspondence maps, our method exploits a simple yet\neffective deep feature modulation (DFM) module, which injects the color\nembeddings extracted from the reference image into the deep representations of\nthe input grayscale image. Such design is much more lightweight and\nintelligible, achieving appealing performance with real-time processing speed.\nMoreover, our model does not require multifarious loss functions and\nregularization terms like existing methods, but only two widely used loss\nfunctions. Codes and models will be available at\nhttps://github.com/zhaohengyuan1/Color2Style.",
          "link": "http://arxiv.org/abs/2106.08017",
          "publishedOn": "2021-06-16T01:21:04.242Z",
          "wordCount": 714,
          "title": "Color2Style: Real-Time Exemplar-Based Image Colorization with Self-Reference Learning and Deep Feature Modulation. (arXiv:2106.08017v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06924",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chang_C/0/1/0/all/0/1\">Ching-Chun Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Sisheng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Echizen_I/0/1/0/all/0/1\">Isao Echizen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanchez_V/0/1/0/all/0/1\">Victor Sanchez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chang-Tsun Li</a>",
          "description": "Deep-learning\\textendash{centric} reversible steganography has emerged as a\npromising research paradigm. A direct way of applying deep learning to\nreversible steganography is to construct a pair of encoder and decoder, whose\nparameters are trained jointly, thereby learning the steganographic system as a\nwhole. This end-to-end framework, however, falls short of the reversibility\nrequirement because it is difficult for this kind of monolithic system, as a\nblack box, to create or duplicate intricate reversible mechanisms. In response\nto this issue, a recent approach is to carve up the steganographic system and\nwork on modules independently. In particular, neural networks are deployed in\nan analytics module to learn the data distribution, while an established\nmechanism is called upon to handle the remaining tasks. In this paper, we\ninvestigate the modular framework and deploy deep neural networks in a\nreversible steganographic scheme referred to as prediction-error modulation, in\nwhich an analytics module serves the purpose of pixel intensity prediction. The\nprimary focus of this study is on deep-learning\\textendash{based} context-aware\npixel intensity prediction. We address the unsolved issues reported in related\nliterature, including the impact of pixel initialisation on prediction accuracy\nand the influence of uncertainty propagation in dual-layer embedding.\nFurthermore, we establish a connection between context-aware pixel intensity\nprediction and low-level computer vision and analyse the performance of several\nadvanced neural networks.",
          "link": "http://arxiv.org/abs/2106.06924",
          "publishedOn": "2021-06-15T22:07:48.721Z",
          "wordCount": 658,
          "title": "Deep Learning for Reversible Steganography: Principles and Insights. (arXiv:2106.06924v1 [cs.MM])"
        },
        {
          "id": "http://arxiv.org/abs/2105.13096",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jieni Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_J/0/1/0/all/0/1\">Junren Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_S/0/1/0/all/0/1\">Shanxiang Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_B/0/1/0/all/0/1\">Bingwen Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiabo Wang</a>",
          "description": "Lattices have been conceived as a powerful tool for data hiding. While\nconventional studies and applications focus on achieving the optimal robustness\nversus distortion tradeoff, in some applications such as data hiding in\nmedical/physiological signals, the primary concern is to achieve a minimum\namount of distortion to the cover signal. In this paper, we revisit the\ncelebrated quantization index modulation (QIM) scheme and propose a\nminimum-distortion version of it, referred to as MD-QIM. The crux of MD-QIM is\nto move the data point to only the boundary of the Voronoi region of the\nlattice point indexed by a message, which suffices for subsequent correct\ndecoding. At any fixed code rate, the scheme achieves the minimum amount of\ndistortion by sacrificing the robustness to the additive white Gaussian noise\n(AWGN) attacks. Simulation results confirm that our scheme significantly\noutperforms QIM in terms of mean square error (MSE), peak signal to noise ratio\n(PSNR) and percentage residual difference (PRD).",
          "link": "http://arxiv.org/abs/2105.13096",
          "publishedOn": "2021-06-15T01:45:14.088Z",
          "wordCount": 615,
          "title": "Lattice-Based Minimum-Distortion Data Hiding. (arXiv:2105.13096v2 [cs.IT] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06736",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brousmiche_M/0/1/0/all/0/1\">Mathilde Brousmiche</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rouat_J/0/1/0/all/0/1\">Jean Rouat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dupont_S/0/1/0/all/0/1\">St&#xe9;phane Dupont</a>",
          "description": "Event classification is inherently sequential and multimodal. Therefore, deep\nneural models need to dynamically focus on the most relevant time window and/or\nmodality of a video. In this study, we propose the Multi-level Attention Fusion\nnetwork (MAFnet), an architecture that can dynamically fuse visual and audio\ninformation for event recognition. Inspired by prior studies in neuroscience,\nwe couple both modalities at different levels of visual and audio paths.\nFurthermore, the network dynamically highlights a modality at a given time\nwindow relevant to classify events. Experimental results in AVE (Audio-Visual\nEvent), UCF51, and Kinetics-Sounds datasets show that the approach can\neffectively improve the accuracy in audio-visual event classification. Code is\navailable at: https://github.com/numediart/MAFnet",
          "link": "http://arxiv.org/abs/2106.06736",
          "publishedOn": "2021-06-15T01:45:13.424Z",
          "wordCount": 555,
          "title": "Multi-level Attention Fusion Network for Audio-visual Event Recognition. (arXiv:2106.06736v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2009.00100",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Young-min Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_Y/0/1/0/all/0/1\">Young-chul Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_K/0/1/0/all/0/1\">Kwangjin Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeon_M/0/1/0/all/0/1\">Moongu Jeon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Seong-Whan Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pedrycz_W/0/1/0/all/0/1\">Witold Pedrycz</a>",
          "description": "In this paper, we propose a highly practical fully online multi-object\ntracking and segmentation (MOTS) method that uses instance segmentation results\nas an input. The proposed method is based on the Gaussian mixture probability\nhypothesis density (GMPHD) filter, a hierarchical data association (HDA), and a\nmask-based affinity fusion (MAF) model to achieve high-performance online\ntracking. The HDA consists of two associations: segment-to-track and\ntrack-to-track associations. One affinity, for position and motion, is computed\nby using the GMPHD filter, and the other affinity, for appearance is computed\nby using the responses from a single object tracker such as a kernalized\ncorrelation filter. These two affinities are simply fused by using a\nscore-level fusion method such as min-max normalization referred to as MAF. In\naddition, to reduce the number of false positive segments, we adopt mask\nIoU-based merging (mask merging). The proposed MOTS framework with the key\nmodules: HDA, MAF, and mask merging, is easily extensible to simultaneously\ntrack multiple types of objects with CPU only execution in parallel processing.\nIn addition, the developed framework only requires simple parameter tuning\nunlike many existing MOTS methods that need intensive hyperparameter\noptimization. In the experiments on the two popular MOTS datasets, the key\nmodules show some improvements. For instance, ID-switch decreases by more than\nhalf compared to a baseline method in the training sets. In conclusion, our\ntracker achieves state-of-the-art MOTS performance in the test sets.",
          "link": "http://arxiv.org/abs/2009.00100",
          "publishedOn": "2021-06-14T01:38:50.799Z",
          "wordCount": 708,
          "title": "Online Multi-Object Tracking and Segmentation with GMPHD Filter and Mask-based Affinity Fusion. (arXiv:2009.00100v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.11376",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wilmot_C/0/1/0/all/0/1\">Charles Wilmot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Triesch_J/0/1/0/all/0/1\">Jochen Triesch</a>",
          "description": "A key competence for open-ended learning is the formation of increasingly\nabstract representations useful for driving complex behavior. Abstract\nrepresentations ignore specific details and facilitate generalization. Here we\nconsider the learning of abstract representations in a multi-modal setting with\ntwo or more input modalities. We treat the problem as a lossy compression\nproblem and show that generic lossy compression of multimodal sensory input\nnaturally extracts abstract representations that tend to strip away modalitiy\nspecific details and preferentially retain information that is shared across\nthe different modalities. Furthermore, we propose an architecture to learn\nabstract representations by identifying and retaining only the information that\nis shared across multiple modalities while discarding any modality specific\ninformation.",
          "link": "http://arxiv.org/abs/2101.11376",
          "publishedOn": "2021-06-14T01:38:50.480Z",
          "wordCount": 568,
          "title": "Learning Abstract Representations through Lossy Compression of Multi-Modal Signals. (arXiv:2101.11376v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06489",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liong_G/0/1/0/all/0/1\">Gen-Bing Liong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+See_J/0/1/0/all/0/1\">John See</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_L/0/1/0/all/0/1\">Lai-Kuan Wong</a>",
          "description": "Facial expressions vary from the visible to the subtle. In recent years, the\nanalysis of micro-expressions $-$ a natural occurrence resulting from the\nsuppression of one's true emotions, has drawn the attention of researchers with\na broad range of potential applications. However, spotting microexpressions in\nlong videos becomes increasingly challenging when intertwined with normal or\nmacro-expressions. In this paper, we propose a shallow optical flow\nthree-stream CNN (SOFTNet) model to predict a score that captures the\nlikelihood of a frame being in an expression interval. By fashioning the\nspotting task as a regression problem, we introduce pseudo-labeling to\nfacilitate the learning process. We demonstrate the efficacy and efficiency of\nthe proposed approach on the recent MEGC 2020 benchmark, where state-of-the-art\nperformance is achieved on CAS(ME)$^{2}$ with equally promising results on SAMM\nLong Videos.",
          "link": "http://arxiv.org/abs/2106.06489",
          "publishedOn": "2021-06-14T01:38:50.449Z",
          "wordCount": 591,
          "title": "Shallow Optical Flow Three-Stream CNN for Macro- and Micro-Expression Spotting from Long Videos. (arXiv:2106.06489v1 [cs.CV])"
        }
      ]
    },
    {
      "title": "cs.CV updates on arXiv.org",
      "feedUrl": "http://export.arxiv.org/rss/cs.CV",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2106.08601",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hou_L/0/1/0/all/0/1\">Liang Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1\">Huawei Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Q/0/1/0/all/0/1\">Qi Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1\">Xueqi Cheng</a>",
          "description": "Recently, transformation-based self-supervised learning has been applied to\ngenerative adversarial networks (GANs) to mitigate the catastrophic forgetting\nproblem of discriminator by learning stable representations. However, the\nseparate self-supervised tasks in existing self-supervised GANs cause an\ninconsistent goal with generative modeling due to the learning of the generator\nfrom their generator distribution-agnostic classifiers. To address this issue,\nwe propose a novel self-supervised GANs framework with label augmentation,\ni.e., augmenting the GAN labels (real or fake) with the self-supervised\npseudo-labels. In particular, the discriminator and the self-supervised\nclassifier are unified to learn a single task that predicts the augmented label\nsuch that the discriminator/classifier is aware of the generator distribution,\nwhile the generator tries to confuse the discriminator/classifier by optimizing\nthe discrepancy between the transformed real and generated distributions.\nTheoretically, we prove that the generator, at the equilibrium point, converges\nto replicate the data distribution. Empirically, we demonstrate that the\nproposed method significantly outperforms competitive baselines on both\ngenerative modeling and representation learning across benchmark datasets.",
          "link": "http://arxiv.org/abs/2106.08601",
          "publishedOn": "2021-06-17T16:16:41.579Z",
          "wordCount": 589,
          "title": "Self-supervised GANs with Label Augmentation. (arXiv:2106.08601v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08756",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1\">Xiaomeng Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potter_M/0/1/0/all/0/1\">Michael Potter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_G/0/1/0/all/0/1\">Gaurav Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsai_Y/0/1/0/all/0/1\">Yun-Chan Tsai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saripalli_V/0/1/0/all/0/1\">V. Ratna Saripalli</a>",
          "description": "It is no secret amongst deep learning researchers that finding the right data\naugmentation strategy during training can mean the difference between a\nstate-of-the-art result and a run-of-the-mill ranking. To that end, the\ncommunity has seen many efforts to automate the process of finding the perfect\naugmentation procedure for any task at hand. Unfortunately, even recent\ncutting-edge methods bring massive computational overhead, requiring as many as\n100 full model trainings to settle on an ideal configuration. We show how to\nachieve even better performance in just 7: with Random Unidimensional\nAugmentation. Source code is available at https://github.com/fastestimator/RUA",
          "link": "http://arxiv.org/abs/2106.08756",
          "publishedOn": "2021-06-17T16:16:41.547Z",
          "wordCount": 528,
          "title": "Automating Augmentation Through Random Unidimensional Search. (arXiv:2106.08756v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05923",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bano_S/0/1/0/all/0/1\">Sophia Bano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Casella_A/0/1/0/all/0/1\">Alessandro Casella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasconcelos_F/0/1/0/all/0/1\">Francisco Vasconcelos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moccia_S/0/1/0/all/0/1\">Sara Moccia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Attilakos_G/0/1/0/all/0/1\">George Attilakos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wimalasundera_R/0/1/0/all/0/1\">Ruwan Wimalasundera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+David_A/0/1/0/all/0/1\">Anna L. David</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paladini_D/0/1/0/all/0/1\">Dario Paladini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deprest_J/0/1/0/all/0/1\">Jan Deprest</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Momi_E/0/1/0/all/0/1\">Elena De Momi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mattos_L/0/1/0/all/0/1\">Leonardo S. Mattos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stoyanov_D/0/1/0/all/0/1\">Danail Stoyanov</a>",
          "description": "Fetoscopy laser photocoagulation is a widely used procedure for the treatment\nof Twin-to-Twin Transfusion Syndrome (TTTS), that occur in mono-chorionic\nmultiple pregnancies due to placental vascular anastomoses. This procedure is\nparticularly challenging due to limited field of view, poor manoeuvrability of\nthe fetoscope, poor visibility due to fluid turbidity, variability in light\nsource, and unusual position of the placenta. This may lead to increased\nprocedural time and incomplete ablation, resulting in persistent TTTS.\nComputer-assisted intervention may help overcome these challenges by expanding\nthe fetoscopic field of view through video mosaicking and providing better\nvisualization of the vessel network. However, the research and development in\nthis domain remain limited due to unavailability of high-quality data to encode\nthe intra- and inter-procedure variability. Through the \\textit{Fetoscopic\nPlacental Vessel Segmentation and Registration (FetReg)} challenge, we present\na large-scale multi-centre dataset for the development of generalized and\nrobust semantic segmentation and video mosaicking algorithms for the fetal\nenvironment with a focus on creating drift-free mosaics from long duration\nfetoscopy videos. In this paper, we provide an overview of the FetReg dataset,\nchallenge tasks, evaluation metrics and baseline methods for both segmentation\nand registration. Baseline methods results on the FetReg dataset shows that our\ndataset poses interesting challenges, offering large opportunity for the\ncreation of novel methods and models through a community effort initiative\nguided by the FetReg challenge.",
          "link": "http://arxiv.org/abs/2106.05923",
          "publishedOn": "2021-06-17T15:44:16.763Z",
          "wordCount": 708,
          "title": "FetReg: Placental Vessel Segmentation and Registration in Fetoscopy Challenge Dataset. (arXiv:2106.05923v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.11014",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hong_M/0/1/0/all/0/1\">Min-Fong Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hao-Yun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Min-Hung Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yu-Syuan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuo_H/0/1/0/all/0/1\">Hsien-Kai Kuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsai_Y/0/1/0/all/0/1\">Yi-Min Tsai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hung-Jen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jou_K/0/1/0/all/0/1\">Kevin Jou</a>",
          "description": "Network spaces have been known as a critical factor in both handcrafted\nnetwork designs or defining search spaces for Neural Architecture Search (NAS).\nHowever, an effective space involves tremendous prior knowledge and/or manual\neffort, and additional constraints are required to discover efficiency-aware\narchitectures. In this paper, we define a new problem, Network Space Search\n(NSS), as searching for favorable network spaces instead of a single\narchitecture. We propose an NSS method to directly search for efficient-aware\nnetwork spaces automatically, reducing the manual effort and immense cost in\ndiscovering satisfactory ones. The resultant network spaces, named Elite\nSpaces, are discovered from Expanded Search Space with minimal human expertise\nimposed. The Pareto-efficient Elite Spaces are aligned with the Pareto front\nunder various complexity constraints and can be further served as NAS search\nspaces, benefiting differentiable NAS approaches (e.g. In CIFAR-100, an\naveragely 2.3% lower error rate and 3.7% closer to target constraint than the\nbaseline with around 90% fewer samples required to find satisfactory networks).\nMoreover, our NSS approach is capable of searching for superior spaces in\nfuture unexplored spaces, revealing great potential in searching for network\nspaces automatically. Website:\nhttps://minhungchen.netlify.app/publication/nss/.",
          "link": "http://arxiv.org/abs/2104.11014",
          "publishedOn": "2021-06-17T15:44:16.740Z",
          "wordCount": 697,
          "title": "Network Space Search for Pareto-Efficient Spaces. (arXiv:2104.11014v5 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05616",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1\">Yicheng Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yongqi Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jiahui Zhu</a>",
          "description": "Recovering 3D human pose from 2D joints is a highly unconstrained problem,\nespecially without any video or multi-view information. We present an\nunsupervised GAN-based model to recover 3D human pose from 2D joint locations\nextracted from a single image. Our model uses a GAN to learn the mapping of\ndistribution from 2D poses to 3D poses, not the simple 2D-3D correspondence.\nConsidering the reprojection constraint, our model can estimate the camera so\nthat we can reproject the estimated 3D pose to the original 2D pose. Based on\nthis reprojection method, we can rotate and reproject the generated pose to get\nour \"new\" 2D pose and then use a weight sharing generator to estimate the \"new\"\n3D pose and a \"new\" camera. Through the above estimation process, we can define\nthe single-view-multi-angle consistency loss during training to simulate\nmulti-view consistency, which means the 3D poses and cameras estimated from two\nangles of a single view should be able to be mixed to generate rich 2D\nreprojections, and the 2D reprojections reprojected from the same 3D pose\nshould be consistent. The experimental results on Human3.6M show that our\nmethod outperforms all the state-of-the-art methods, and results on\nMPI-INF-3DHP show that our method outperforms state-of-the-art by approximately\n15.0%.",
          "link": "http://arxiv.org/abs/2106.05616",
          "publishedOn": "2021-06-17T15:44:16.717Z",
          "wordCount": 653,
          "title": "SVMA: A GAN-based model for Monocular 3D Human Pose Estimation. (arXiv:2106.05616v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.09015",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Peng_S/0/1/0/all/0/1\">Shichong Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moazeni_A/0/1/0/all/0/1\">Alireza Moazeni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1\">Ke Li</a>",
          "description": "Deep generative models such as GANs have driven impressive advances in\nconditional image synthesis in recent years. A persistent challenge has been to\ngenerate diverse versions of output images from the same input image, due to\nthe problem of mode collapse: because only one ground truth output image is\ngiven per input image, only one mode of the conditional distribution is\nmodelled. In this paper, we focus on this problem of multimodal conditional\nimage synthesis and build on the recently proposed technique of Implicit\nMaximum Likelihood Estimation (IMLE). Prior IMLE-based methods required\ndifferent architectures for different tasks, which limit their applicability,\nand were lacking in fine details in the generated images. We propose CAM-Net, a\nunified architecture that can be applied to a broad range of tasks.\nAdditionally, it is capable of generating convincing high frequency details,\nachieving a reduction of the Frechet Inception Distance (FID) by up to 45.3%\ncompared to the baseline.",
          "link": "http://arxiv.org/abs/2106.09015",
          "publishedOn": "2021-06-17T01:58:45.215Z",
          "wordCount": 627,
          "title": "Cascading Modular Network (CAM-Net) for Multimodal Image Synthesis. (arXiv:2106.09015v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08761",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guerdan_L/0/1/0/all/0/1\">Luke Guerdan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raymond_A/0/1/0/all/0/1\">Alex Raymond</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gunes_H/0/1/0/all/0/1\">Hatice Gunes</a>",
          "description": "As machine learning approaches are increasingly used to augment human\ndecision-making, eXplainable Artificial Intelligence (XAI) research has\nexplored methods for communicating system behavior to humans. However, these\napproaches often fail to account for the emotional responses of humans as they\ninteract with explanations. Facial affect analysis, which examines human facial\nexpressions of emotions, is one promising lens for understanding how users\nengage with explanations. Therefore, in this work, we aim to (1) identify which\nfacial affect features are pronounced when people interact with XAI interfaces,\nand (2) develop a multitask feature embedding for linking facial affect signals\nwith participants' use of explanations. Our analyses and results show that the\noccurrence and values of facial AU1 and AU4, and Arousal are heightened when\nparticipants fail to use explanations effectively. This suggests that facial\naffect analysis should be incorporated into XAI to personalize explanations to\nindividuals' interaction styles and to adapt explanations based on the\ndifficulty of the task performed.",
          "link": "http://arxiv.org/abs/2106.08761",
          "publishedOn": "2021-06-17T01:58:45.117Z",
          "wordCount": 595,
          "title": "Toward Affective XAI: Facial Affect Analysis for Understanding Explainable Human-AI Interactions. (arXiv:2106.08761v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2012.00517",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Korpihalkola_J/0/1/0/all/0/1\">Joni Korpihalkola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sipola_T/0/1/0/all/0/1\">Tuomo Sipola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Puuska_S/0/1/0/all/0/1\">Samir Puuska</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kokkonen_T/0/1/0/all/0/1\">Tero Kokkonen</a>",
          "description": "Computer vision and machine learning can be used to automate various tasks in\ncancer diagnostic and detection. If an attacker can manipulate the automated\nprocessing, the results can be devastating and in the worst case lead to wrong\ndiagnosis and treatment. In this research, the goal is to demonstrate the use\nof one-pixel attacks in a real-life scenario with a real pathology dataset,\nTUPAC16, which consists of digitized whole-slide images. We attack against the\nIBM CODAIT's MAX breast cancer detector using adversarial images. These\nadversarial examples are found using differential evolution to perform the\none-pixel modification to the images in the dataset. The results indicate that\na minor one-pixel modification of a whole slide image under analysis can affect\nthe diagnosis by reversing the automatic diagnosis result. The attack poses a\nthreat from the cyber security perspective: the one-pixel method can be used as\nan attack vector by a motivated attacker.",
          "link": "http://arxiv.org/abs/2012.00517",
          "publishedOn": "2021-06-17T01:58:45.110Z",
          "wordCount": 632,
          "title": "One-Pixel Attack Deceives Computer-Assisted Diagnosis of Cancer. (arXiv:2012.00517v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08565",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aghdaie_P/0/1/0/all/0/1\">Poorya Aghdaie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhary_B/0/1/0/all/0/1\">Baaria Chaudhary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soleymani_S/0/1/0/all/0/1\">Sobhan Soleymani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dawson_J/0/1/0/all/0/1\">Jeremy Dawson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nasrabadi_N/0/1/0/all/0/1\">Nasser M. Nasrabadi</a>",
          "description": "This work investigates the well-known problem of morphing attacks, which has\ndrawn considerable attention in the biometrics community. Morphed images have\nexposed face recognition systems' susceptibility to false acceptance, resulting\nin dire consequences, especially for national security applications. To detect\nmorphing attacks, we propose a method which is based on a discriminative 2D\nDiscrete Wavelet Transform (2D-DWT). A discriminative wavelet sub-band can\nhighlight inconsistencies between a real and a morphed image. We observe that\nthere is a salient discrepancy between the entropy of a given sub-band in a\nbona fide image, and the same sub-band's entropy in a morphed sample.\nConsidering this dissimilarity between these two entropy values, we find the\nKullback-Leibler divergence between the two distributions, namely the entropy\nof the bona fide and the corresponding morphed images. The most discriminative\nwavelet sub-bands are those with the highest corresponding KL-divergence\nvalues. Accordingly, 22 sub-bands are selected as the most discriminative ones\nin terms of morph detection. We show that a Deep Neural Network (DNN) trained\non the 22 discriminative sub-bands can detect morphed samples precisely. Most\nimportantly, the effectiveness of our algorithm is validated through\nexperiments on three datasets: VISAPP17, LMA, and MorGAN. We also performed an\nablation study on the sub-band selection.",
          "link": "http://arxiv.org/abs/2106.08565",
          "publishedOn": "2021-06-17T01:58:45.062Z",
          "wordCount": 638,
          "title": "Detection of Morphed Face Images Using Discriminative Wavelet Sub-bands. (arXiv:2106.08565v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08795",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mirza_M/0/1/0/all/0/1\">Muhammad Jehanzeb Mirza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buerkle_C/0/1/0/all/0/1\">Cornelius Buerkle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jarquin_J/0/1/0/all/0/1\">Julio Jarquin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Opitz_M/0/1/0/all/0/1\">Michael Opitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oboril_F/0/1/0/all/0/1\">Fabian Oboril</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scholl_K/0/1/0/all/0/1\">Kay-Ulrich Scholl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bischof_H/0/1/0/all/0/1\">Horst Bischof</a>",
          "description": "State-of-the-art object detection systems for autonomous driving achieve\npromising results in clear weather conditions. However, such autonomous safety\ncritical systems also need to work in degrading weather conditions, such as\nrain, fog and snow. Unfortunately, most approaches evaluate only on the KITTI\ndataset, which consists only of clear weather scenes. In this paper we address\nthis issue and perform one of the most detailed evaluation on single and dual\nmodality architectures on data captured in real weather conditions. We analyse\nthe performance degradation of these architectures in degrading weather\nconditions. We demonstrate that an object detection architecture performing\ngood in clear weather might not be able to handle degrading weather conditions.\nWe also perform ablation studies on the dual modality architectures and show\ntheir limitations.",
          "link": "http://arxiv.org/abs/2106.08795",
          "publishedOn": "2021-06-17T01:58:45.055Z",
          "wordCount": 569,
          "title": "Robustness of Object Detectors in Degrading Weather Conditions. (arXiv:2106.08795v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08905",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qu_S/0/1/0/all/0/1\">Shuyi Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_Z/0/1/0/all/0/1\">Zhenxing Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1\">Kaizhu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jianke Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Protter_M/0/1/0/all/0/1\">Matan Protter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zimerman_G/0/1/0/all/0/1\">Gadi Zimerman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yinghui Xu</a>",
          "description": "Recent deep generative models have achieved promising performance in image\ninpainting. However, it is still very challenging for a neural network to\ngenerate realistic image details and textures, due to its inherent spectral\nbias. By our understanding of how artists work, we suggest to adopt a\n`structure first detail next' workflow for image inpainting. To this end, we\npropose to build a Pyramid Generator by stacking several sub-generators, where\nlower-layer sub-generators focus on restoring image structures while the\nhigher-layer sub-generators emphasize image details. Given an input image, it\nwill be gradually restored by going through the entire pyramid in a bottom-up\nfashion. Particularly, our approach has a learning scheme of progressively\nincreasing hole size, which allows it to restore large-hole images. In\naddition, our method could fully exploit the benefits of learning with\nhigh-resolution images, and hence is suitable for high-resolution image\ninpainting. Extensive experimental results on benchmark datasets have validated\nthe effectiveness of our approach compared with state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2106.08905",
          "publishedOn": "2021-06-17T01:58:45.039Z",
          "wordCount": 602,
          "title": "Structure First Detail Next: Image Inpainting with Pyramid Generator. (arXiv:2106.08905v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08615",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1\">Minhyeok Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1\">Sangwon Hwang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_C/0/1/0/all/0/1\">Chaewon Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sangyoun Lee</a>",
          "description": "Monocular depth estimation is an especially important task in robotics and\nautonomous driving, where 3D structural information is essential. However,\nextreme lighting conditions and complex surface objects make it difficult to\npredict depth in a single image. Therefore, to generate accurate depth maps, it\nis important for the model to learn structural information about the scene. We\npropose a novel Patch-Wise EdgeConv Module (PEM) and EdgeConv Attention Module\n(EAM) to solve the difficulty of monocular depth estimation. The proposed\nmodules extract structural information by learning the relationship between\nimage patches close to each other in space using edge convolution. Our method\nis evaluated on two popular datasets, the NYU Depth V2 and the KITTI Eigen\nsplit, achieving state-of-the-art performance. We prove that the proposed model\npredicts depth robustly in challenging scenes through various comparative\nexperiments.",
          "link": "http://arxiv.org/abs/2106.08615",
          "publishedOn": "2021-06-17T01:58:44.910Z",
          "wordCount": 570,
          "title": "EdgeConv with Attention Module for Monocular Depth Estimation. (arXiv:2106.08615v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.09017",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haoxiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Han Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>",
          "description": "Multi-task learning (MTL) aims to improve the generalization of several\nrelated tasks by learning them jointly. As a comparison, in addition to the\njoint training scheme, modern meta-learning allows unseen tasks with limited\nlabels during the test phase, in the hope of fast adaptation over them. Despite\nthe subtle difference between MTL and meta-learning in the problem formulation,\nboth learning paradigms share the same insight that the shared structure\nbetween existing training tasks could lead to better generalization and\nadaptation. In this paper, we take one important step further to understand the\nclose connection between these two learning paradigms, through both theoretical\nanalysis and empirical investigation. Theoretically, we first demonstrate that\nMTL shares the same optimization formulation with a class of gradient-based\nmeta-learning (GBML) algorithms. We then prove that for over-parameterized\nneural networks with sufficient depth, the learned predictive functions of MTL\nand GBML are close. In particular, this result implies that the predictions\ngiven by these two models are similar over the same unseen task. Empirically,\nwe corroborate our theoretical findings by showing that, with proper\nimplementation, MTL is competitive against state-of-the-art GBML algorithms on\na set of few-shot image classification benchmarks. Since existing GBML\nalgorithms often involve costly second-order bi-level optimization, our\nfirst-order MTL method is an order of magnitude faster on large-scale datasets\nsuch as mini-ImageNet. We believe this work could help bridge the gap between\nthese two learning paradigms, and provide a computationally efficient\nalternative to GBML that also supports fast task adaptation.",
          "link": "http://arxiv.org/abs/2106.09017",
          "publishedOn": "2021-06-17T01:58:44.019Z",
          "wordCount": 699,
          "title": "Bridging Multi-Task Learning and Meta-Learning: Towards Efficient Training and Effective Adaptation. (arXiv:2106.09017v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/1810.12941",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Baruch_E/0/1/0/all/0/1\">Elad Ben Baruch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keller_Y/0/1/0/all/0/1\">Yosi Keller</a>",
          "description": "In this work, we propose a novel Convolutional Neural Network (CNN)\narchitecture for the joint detection and matching of feature points in images\nacquired by different sensors using a single forward pass. The resulting\nfeature detector is tightly coupled with the feature descriptor, in contrast to\nclassical approaches (SIFT, etc.), where the detection phase precedes and\ndiffers from computing the descriptor. Our approach utilizes two CNN\nsubnetworks, the first being a Siamese CNN and the second, consisting of dual\nnon-weight-sharing CNNs. This allows simultaneous processing and fusion of the\njoint and disjoint cues in the multimodal image patches. The proposed approach\nis experimentally shown to outperform contemporary state-of-the-art schemes\nwhen applied to multiple datasets of multimodal images. It is also shown to\nprovide repeatable feature points detections across multisensor images,\noutperforming state-of-the-art detectors. To the best of our knowledge, it is\nthe first unified approach for the detection and matching of such images.",
          "link": "http://arxiv.org/abs/1810.12941",
          "publishedOn": "2021-06-17T01:58:43.503Z",
          "wordCount": 622,
          "title": "Joint detection and matching of feature points in multimodal images. (arXiv:1810.12941v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08505",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lanlan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuting Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1\">Jia Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1\">Stefano Soatto</a>",
          "description": "Recent work introduced progressive network growing as a promising way to ease\nthe training for large GANs, but the model design and architecture-growing\nstrategy still remain under-explored and needs manual design for different\nimage data. In this paper, we propose a method to dynamically grow a GAN during\ntraining, optimizing the network architecture and its parameters together with\nautomation. The method embeds architecture search techniques as an interleaving\nstep with gradient-based training to periodically seek the optimal\narchitecture-growing strategy for the generator and discriminator. It enjoys\nthe benefits of both eased training because of progressive growing and improved\nperformance because of broader architecture design space. Experimental results\ndemonstrate new state-of-the-art of image generation. Observations in the\nsearch procedure also provide constructive insights into the GAN model design\nsuch as generator-discriminator balance and convolutional layer choices.",
          "link": "http://arxiv.org/abs/2106.08505",
          "publishedOn": "2021-06-17T01:58:43.368Z",
          "wordCount": 567,
          "title": "Dynamically Grown Generative Adversarial Networks. (arXiv:2106.08505v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04274",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1\">Yicheng Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1\">Cheng Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yongqi Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jiahui Zhu</a>",
          "description": "3D human pose estimation is still a challenging problem despite the large\namount of work that has been done in this field. Generally, most methods\ndirectly use neural networks and ignore certain constraints (e.g., reprojection\nconstraints and joint angle and bone length constraints). This paper proposes a\nweakly supervised GAN-based model for 3D human pose estimation that considers\n3D information along with 2D information simultaneously, in which a\nreprojection network is employed to learn the mapping of the distribution from\n3D poses to 2D poses. In particular, we train the reprojection network and the\ngenerative adversarial network synchronously. Furthermore, inspired by the\ntypical kinematic chain space (KCS) matrix, we propose a weighted KCS matrix,\nwhich is added into the discriminator's input to impose joint angle and bone\nlength constraints. The experimental results on Human3.6M show that our method\noutperforms state-of-the-art methods by approximately 5.1\\%.",
          "link": "http://arxiv.org/abs/2106.04274",
          "publishedOn": "2021-06-17T01:58:43.315Z",
          "wordCount": 592,
          "title": "A Synchronized Reprojection-based Model for 3D Human Pose Estimation. (arXiv:2106.04274v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.07141",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ozbulak_U/0/1/0/all/0/1\">Utku Ozbulak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anzaku_E/0/1/0/all/0/1\">Esla Timothy Anzaku</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neve_W/0/1/0/all/0/1\">Wesley De Neve</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Messem_A/0/1/0/all/0/1\">Arnout Van Messem</a>",
          "description": "Although the adoption rate of deep neural networks (DNNs) has tremendously\nincreased in recent years, a solution for their vulnerability against\nadversarial examples has not yet been found. As a result, substantial research\nefforts are dedicated to fix this weakness, with many studies typically using a\nsubset of source images to generate adversarial examples, treating every image\nin this subset as equal. We demonstrate that, in fact, not every source image\nis equally suited for this kind of assessment. To do so, we devise a\nlarge-scale model-to-model transferability scenario for which we meticulously\nanalyze the properties of adversarial examples, generated from every suitable\nsource image in ImageNet by making use of two of the most frequently deployed\nattacks. In this transferability scenario, which involves seven distinct DNN\nmodels, including the recently proposed vision transformers, we reveal that it\nis possible to have a difference of up to $12.5\\%$ in model-to-model\ntransferability success, $1.01$ in average $L_2$ perturbation, and $0.03$\n($8/225$) in average $L_{\\infty}$ perturbation when $1,000$ source images are\nsampled randomly among all suitable candidates. We then take one of the first\nsteps in evaluating the robustness of images used to create adversarial\nexamples, proposing a number of simple but effective methods to identify\nunsuitable source images, thus making it possible to mitigate extreme cases in\nexperimentation and support high-quality benchmarking.",
          "link": "http://arxiv.org/abs/2106.07141",
          "publishedOn": "2021-06-17T01:58:43.309Z",
          "wordCount": 681,
          "title": "Selection of Source Images Heavily Influences the Effectiveness of Adversarial Attacks. (arXiv:2106.07141v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.09016",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yahui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sangineto_E/0/1/0/all/0/1\">Enver Sangineto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yajing Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bao_L/0/1/0/all/0/1\">Linchao Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Haoxian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sebe_N/0/1/0/all/0/1\">Nicu Sebe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lepri_B/0/1/0/all/0/1\">Bruno Lepri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nadai_M/0/1/0/all/0/1\">Marco De Nadai</a>",
          "description": "Image-to-Image (I2I) multi-domain translation models are usually evaluated\nalso using the quality of their semantic interpolation results. However,\nstate-of-the-art models frequently show abrupt changes in the image appearance\nduring interpolation, and usually perform poorly in interpolations across\ndomains. In this paper, we propose a new training protocol based on three\nspecific losses which help a translation network to learn a smooth and\ndisentangled latent style space in which: 1) Both intra- and inter-domain\ninterpolations correspond to gradual changes in the generated images and 2) The\ncontent of the source image is better preserved during the translation.\nMoreover, we propose a novel evaluation metric to properly measure the\nsmoothness of latent style space of I2I translation models. The proposed method\ncan be plugged into existing translation approaches, and our extensive\nexperiments on different datasets show that it can significantly boost the\nquality of the generated images and the graduality of the interpolations.",
          "link": "http://arxiv.org/abs/2106.09016",
          "publishedOn": "2021-06-17T01:58:43.303Z",
          "wordCount": 606,
          "title": "Smoothing the Disentangled Latent Style Space for Unsupervised Image-to-Image Translation. (arXiv:2106.09016v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08385",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Krishnan_P/0/1/0/all/0/1\">Praveen Krishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kovvuri_R/0/1/0/all/0/1\">Rama Kovvuri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pang_G/0/1/0/all/0/1\">Guan Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vassilev_B/0/1/0/all/0/1\">Boris Vassilev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hassner_T/0/1/0/all/0/1\">Tal Hassner</a>",
          "description": "We present a novel approach for disentangling the content of a text image\nfrom all aspects of its appearance. The appearance representation we derive can\nthen be applied to new content, for one-shot transfer of the source style to\nnew content. We learn this disentanglement in a self-supervised manner. Our\nmethod processes entire word boxes, without requiring segmentation of text from\nbackground, per-character processing, or making assumptions on string lengths.\nWe show results in different text domains which were previously handled by\nspecialized methods, e.g., scene text, handwritten text. To these ends, we make\na number of technical contributions: (1) We disentangle the style and content\nof a textual image into a non-parametric, fixed-dimensional vector. (2) We\npropose a novel approach inspired by StyleGAN but conditioned over the example\nstyle at different resolution and content. (3) We present novel self-supervised\ntraining criteria which preserve both source style and target content using a\npre-trained font classifier and text recognizer. Finally, (4) we also introduce\nImgur5K, a new challenging dataset for handwritten word images. We offer\nnumerous qualitative photo-realistic results of our method. We further show\nthat our method surpasses previous work in quantitative tests on scene text and\nhandwriting datasets, as well as in a user study.",
          "link": "http://arxiv.org/abs/2106.08385",
          "publishedOn": "2021-06-17T01:58:43.297Z",
          "wordCount": 645,
          "title": "TextStyleBrush: Transfer of Text Aesthetics from a Single Example. (arXiv:2106.08385v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2104.00447",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lyu_Z/0/1/0/all/0/1\">Zhaoyang Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1\">Minghao Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1\">Tong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_G/0/1/0/all/0/1\">Guodong Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kehuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_D/0/1/0/all/0/1\">Dahua Lin</a>",
          "description": "Recent works have shown that interval bound propagation (IBP) can be used to\ntrain verifiably robust neural networks. Reseachers observe an intriguing\nphenomenon on these IBP trained networks: CROWN, a bounding method based on\ntight linear relaxation, often gives very loose bounds on these networks. We\nalso observe that most neurons become dead during the IBP training process,\nwhich could hurt the representation capability of the network. In this paper,\nwe study the relationship between IBP and CROWN, and prove that CROWN is always\ntighter than IBP when choosing appropriate bounding lines. We further propose a\nrelaxed version of CROWN, linear bound propagation (LBP), that can be used to\nverify large networks to obtain lower verified errors than IBP. We also design\na new activation function, parameterized ramp function (ParamRamp), which has\nmore diversity of neuron status than ReLU. We conduct extensive experiments on\nMNIST, CIFAR-10 and Tiny-ImageNet with ParamRamp activation and achieve\nstate-of-the-art verified robustness. Code and the appendix are available at\nhttps://github.com/ZhaoyangLyu/VerifiablyRobustNN.",
          "link": "http://arxiv.org/abs/2104.00447",
          "publishedOn": "2021-06-17T01:58:43.273Z",
          "wordCount": 654,
          "title": "Towards Evaluating and Training Verifiably Robust Neural Networks. (arXiv:2104.00447v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08817",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Francois_A/0/1/0/all/0/1\">Anton Fran&#xe7;ois</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gori_P/0/1/0/all/0/1\">Pietro Gori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glaunes_J/0/1/0/all/0/1\">Joan Glaun&#xe8;s</a>",
          "description": "In this paper, we propose an implementation of both Large Deformation\nDiffeomorphic Metric Mapping (LDDMM) and Metamorphosis image registration using\na semi-Lagrangian scheme for geodesic shooting. We propose to solve both\nproblems as an inexact matching providing a single and unifying cost function.\nWe demonstrate that for image registration the use of a semi-Lagrangian scheme\nis more stable than a standard Eulerian scheme. Our GPU implementation is based\non PyTorch, which greatly simplifies and accelerates the computations thanks to\nits powerful automatic differentiation engine. It will be freely available at\nhttps://github.com/antonfrancois/Demeter_metamorphosis.",
          "link": "http://arxiv.org/abs/2106.08817",
          "publishedOn": "2021-06-17T01:58:43.234Z",
          "wordCount": 530,
          "title": "Metamorphic image registration using a semi-Lagrangian scheme. (arXiv:2106.08817v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2103.02854",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vonikakis_V/0/1/0/all/0/1\">Vassilios Vonikakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neo_D/0/1/0/all/0/1\">Dexter Neo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Winkler_S/0/1/0/all/0/1\">Stefan Winkler</a>",
          "description": "Emotion recognition and understanding is a vital component in human-machine\ninteraction. Dimensional models of affect such as those using valence and\narousal have advantages over traditional categorical ones due to the complexity\nof emotional states in humans. However, dimensional emotion annotations are\ndifficult and expensive to collect, therefore they are not as prevalent in the\naffective computing community. To address these issues, we propose a method to\ngenerate synthetic images from existing categorical emotion datasets using face\nmorphing as well as dimensional labels in the circumplex space with full\ncontrol over the resulting sample distribution, while achieving augmentation\nfactors of at least 20x or more.",
          "link": "http://arxiv.org/abs/2103.02854",
          "publishedOn": "2021-06-17T01:58:43.209Z",
          "wordCount": 580,
          "title": "Morphset:Augmenting categorical emotion datasets with dimensional affect labels using face morphing. (arXiv:2103.02854v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.05690",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dahiya_N/0/1/0/all/0/1\">Navdeep Dahiya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alam_S/0/1/0/all/0/1\">Sadegh R Alam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Pengpeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Si-Yuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yezzi_A/0/1/0/all/0/1\">Anthony Yezzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nadeem_S/0/1/0/all/0/1\">Saad Nadeem</a>",
          "description": "Purpose: In current clinical practice, noisy and artifact-ridden weekly\ncone-beam computed tomography (CBCT) images are only used for patient setup\nduring radiotherapy. Treatment planning is done once at the beginning of the\ntreatment using high-quality planning CT (pCT) images and manual contours for\norgans-at-risk (OARs) structures. If the quality of the weekly CBCT images can\nbe improved while simultaneously segmenting OAR structures, this can provide\ncritical information for adapting radiotherapy mid-treatment as well as for\nderiving biomarkers for treatment response. Methods: Using a novel\nphysics-based data augmentation strategy, we synthesize a large dataset of\nperfectly/inherently registered planning CT and synthetic-CBCT pairs for\nlocally advanced lung cancer patient cohort, which are then used in a multitask\n3D deep learning framework to simultaneously segment and translate real weekly\nCBCT images to high-quality planning CT-like images. Results: We compared the\nsynthetic CT and OAR segmentations generated by the model to real planning CT\nand manual OAR segmentations and showed promising results. The real week 1\n(baseline) CBCT images which had an average MAE of 162.77 HU compared to pCT\nimages are translated to synthetic CT images that exhibit a drastically\nimproved average MAE of 29.31 HU and average structural similarity of 92% with\nthe pCT images. The average DICE scores of the 3D organs-at-risk segmentations\nare: lungs 0.96, heart 0.88, spinal cord 0.83 and esophagus 0.66. Conclusions:\nWe demonstrate an approach to translate artifact-ridden CBCT images to high\nquality synthetic CT images while simultaneously generating good quality\nsegmentation masks for different organs-at-risk. This approach could allow\nclinicians to adjust treatment plans using only the routine low-quality CBCT\nimages, potentially improving patient outcomes.",
          "link": "http://arxiv.org/abs/2103.05690",
          "publishedOn": "2021-06-17T01:58:42.949Z",
          "wordCount": 743,
          "title": "Multitask 3D CBCT-to-CT Translation and Organs-at-Risk Segmentation Using Physics-Based Data Augmentation. (arXiv:2103.05690v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.10951",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hepburn_A/0/1/0/all/0/1\">Alexander Hepburn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santos_Rodriguez_R/0/1/0/all/0/1\">Raul Santos-Rodriguez</a>",
          "description": "Explaining the decisions of models is becoming pervasive in the image\nprocessing domain, whether it is by using post-hoc methods or by creating\ninherently interpretable models. While the widespread use of surrogate\nexplainers is a welcome addition to inspect and understand black-box models,\nassessing the robustness and reliability of the explanations is key for their\nsuccess. Additionally, whilst existing work in the explainability field\nproposes various strategies to address this problem, the challenges of working\nwith data in the wild is often overlooked. For instance, in image\nclassification, distortions to images can not only affect the predictions\nassigned by the model, but also the explanation. Given a clean and a distorted\nversion of an image, even if the prediction probabilities are similar, the\nexplanation may still be different. In this paper we propose a methodology to\nevaluate the effect of distortions in explanations by embedding perceptual\ndistances that tailor the neighbourhoods used to training surrogate explainers.\nWe also show that by operating in this way, we can make the explanations more\nrobust to distortions. We generate explanations for images in the Imagenet-C\ndataset and demonstrate how using a perceptual distances in the surrogate\nexplainer creates more coherent explanations for the distorted and reference\nimages.",
          "link": "http://arxiv.org/abs/2102.10951",
          "publishedOn": "2021-06-17T01:58:42.901Z",
          "wordCount": 682,
          "title": "Explainers in the Wild: Making Surrogate Explainers Robust to Distortions through Perception. (arXiv:2102.10951v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2001.09528",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jain_N/0/1/0/all/0/1\">Niharika Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Olmo_A/0/1/0/all/0/1\">Alberto Olmo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sengupta_S/0/1/0/all/0/1\">Sailik Sengupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manikonda_L/0/1/0/all/0/1\">Lydia Manikonda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kambhampati_S/0/1/0/all/0/1\">Subbarao Kambhampati</a>",
          "description": "In this paper, we show that popular Generative Adversarial Networks (GANs)\nexacerbate biases along the axes of gender and skin tone when given a skewed\ndistribution of face-shots. While practitioners celebrate synthetic data\ngeneration using GANs as an economical way to augment data for training\ndata-hungry machine learning models, it is unclear whether they recognize the\nperils of such techniques when applied to real world datasets biased along\nlatent dimensions. Specifically, we show that (1) traditional GANs further skew\nthe distribution of a dataset consisting of engineering faculty headshots,\ngenerating minority modes less often and of worse quality and (2)\nimage-to-image translation (conditional) GANs also exacerbate biases by\nlightening skin color of non-white faces and transforming female facial\nfeatures to be masculine when generating faces of engineering professors. Thus,\nour study is meant to serve as a cautionary tale.",
          "link": "http://arxiv.org/abs/2001.09528",
          "publishedOn": "2021-06-17T01:58:42.880Z",
          "wordCount": 638,
          "title": "Imperfect ImaGANation: Implications of GANs Exacerbating Biases on Facial Data Augmentation and Snapchat Selfie Lenses. (arXiv:2001.09528v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08503",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1\">Dora Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_A/0/1/0/all/0/1\">Angelina Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Russakovsky_O/0/1/0/all/0/1\">Olga Russakovsky</a>",
          "description": "Image captioning is an important task for benchmarking visual reasoning and\nfor enabling accessibility for people with vision impairments. However, as in\nmany machine learning settings, social biases can influence image captioning in\nundesirable ways. In this work, we study bias propagation pathways within image\ncaptioning, focusing specifically on the COCO dataset. Prior work has analyzed\ngender bias in captions using automatically-derived gender labels; here we\nexamine racial and intersectional biases using manual annotations. Our first\ncontribution is in annotating the perceived gender and skin color of 28,315 of\nthe depicted people after obtaining IRB approval. Using these annotations, we\ncompare racial biases present in both manual and automatically-generated image\ncaptions. We demonstrate differences in caption performance, sentiment, and\nword choice between images of lighter versus darker-skinned people. Further, we\nfind the magnitude of these differences to be greater in modern captioning\nsystems compared to older ones, thus leading to concerns that without proper\nconsideration and mitigation these differences will only become increasingly\nprevalent. Code and data is available at\nhttps://princetonvisualai.github.io/imagecaptioning-bias .",
          "link": "http://arxiv.org/abs/2106.08503",
          "publishedOn": "2021-06-17T01:58:42.865Z",
          "wordCount": 601,
          "title": "Understanding and Evaluating Racial Biases in Image Captioning. (arXiv:2106.08503v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2103.12040",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abualsaud_H/0/1/0/all/0/1\">Hala Abualsaud</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Sean Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_D/0/1/0/all/0/1\">David Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Situ_K/0/1/0/all/0/1\">Kenny Situ</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rangesh_A/0/1/0/all/0/1\">Akshay Rangesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trivedi_M/0/1/0/all/0/1\">Mohan M. Trivedi</a>",
          "description": "This study presents an approach to lane detection involving the prediction of\nbinary segmentation masks and per-pixel affinity fields. These affinity fields,\nalong with the binary masks, can then be used to cluster lane pixels\nhorizontally and vertically into corresponding lane instances in a\npost-processing step. This clustering is achieved through a simple row-by-row\ndecoding process with little overhead; such an approach allows LaneAF to detect\na variable number of lanes without assuming a fixed or maximum number of lanes.\nMoreover, this form of clustering is more interpretable in comparison to\nprevious visual clustering approaches, and can be analyzed to identify and\ncorrect sources of error. Qualitative and quantitative results obtained on\npopular lane detection datasets demonstrate the model's ability to detect and\ncluster lanes effectively and robustly. Our proposed approach sets a new\nstate-of-the-art on the challenging CULane dataset and the recently introduced\nUnsupervised LLAMAS dataset.",
          "link": "http://arxiv.org/abs/2103.12040",
          "publishedOn": "2021-06-17T01:58:42.840Z",
          "wordCount": 621,
          "title": "LaneAF: Robust Multi-Lane Detection with Affinity Fields. (arXiv:2103.12040v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.00623",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yixu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jie Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yongjian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Feiyue Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_R/0/1/0/all/0/1\">Rongrong Ji</a>",
          "description": "Previous studies have verified that the functionality of black-box models can\nbe stolen with full probability outputs. However, under the more practical\nhard-label setting, we observe that existing methods suffer from catastrophic\nperformance degradation. We argue this is due to the lack of rich information\nin the probability prediction and the overfitting caused by hard labels. To\nthis end, we propose a novel hard-label model stealing method termed\n\\emph{black-box dissector}, which consists of two erasing-based modules. One is\na CAM-driven erasing strategy that is designed to increase the information\ncapacity hidden in hard labels from the victim model. The other is a\nrandom-erasing-based self-knowledge distillation module that utilizes soft\nlabels from the substitute model to mitigate overfitting. Extensive experiments\non four widely-used datasets consistently demonstrate that our method\noutperforms state-of-the-art methods, with an improvement of at most $8.27\\%$.\nWe also validate the effectiveness and practical potential of our method on\nreal-world APIs and defense methods. Furthermore, our method promotes other\ndownstream tasks, \\emph{i.e.}, transfer adversarial attacks.",
          "link": "http://arxiv.org/abs/2105.00623",
          "publishedOn": "2021-06-17T01:58:42.779Z",
          "wordCount": 631,
          "title": "Black-Box Dissector: Towards Erasing-based Hard-Label Model Stealing Attack. (arXiv:2105.00623v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2002.02077",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rangesh_A/0/1/0/all/0/1\">Akshay Rangesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Bowen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trivedi_M/0/1/0/all/0/1\">Mohan M. Trivedi</a>",
          "description": "A driver's gaze is critical for determining their attention, state,\nsituational awareness, and readiness to take over control from partially\nautomated vehicles. Estimating the gaze direction is the most obvious way to\ngauge a driver's state under ideal conditions when limited to using\nnon-intrusive imaging sensors. Unfortunately, the vehicular environment\nintroduces a variety of challenges that are usually unaccounted for - harsh\nillumination, nighttime conditions, and reflective eyeglasses. Relying on head\npose alone under such conditions can prove to be unreliable and erroneous. In\nthis study, we offer solutions to address these problems encountered in the\nreal world. To solve issues with lighting, we demonstrate that using an\ninfrared camera with suitable equalization and normalization suffices. To\nhandle eyeglasses and their corresponding artifacts, we adopt image-to-image\ntranslation using generative adversarial networks to pre-process images prior\nto gaze estimation. Our proposed Gaze Preserving CycleGAN (GPCycleGAN) is\ntrained to preserve the driver's gaze while removing potential eyeglasses from\nface images. GPCycleGAN is based on the well-known CycleGAN approach - with the\naddition of a gaze classifier and a gaze consistency loss for additional\nsupervision. Our approach exhibits improved performance, interpretability,\nrobustness and superior qualitative results on challenging real-world datasets.",
          "link": "http://arxiv.org/abs/2002.02077",
          "publishedOn": "2021-06-17T01:58:42.757Z",
          "wordCount": 699,
          "title": "Gaze Preserving CycleGANs for Eyeglass Removal & Persistent Gaze Estimation. (arXiv:2002.02077v6 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.08147",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiaolong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_X/0/1/0/all/0/1\">Xiaohong Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_D/0/1/0/all/0/1\">Dihong Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_D/0/1/0/all/0/1\">Dong-Ming Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhifeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wei Liu</a>",
          "description": "Face recognition is an important yet challenging problem in computer vision.\nA major challenge in practical face recognition applications lies in\nsignificant variations between profile and frontal faces. Traditional\ntechniques address this challenge either by synthesizing frontal faces or by\npose invariant learning. In this paper, we propose a novel method with Lie\nalgebra theory to explore how face rotation in the 3D space affects the deep\nfeature generation process of convolutional neural networks (CNNs). We prove\nthat face rotation in the image space is equivalent to an additive residual\ncomponent in the feature space of CNNs, which is determined solely by the\nrotation. Based on this theoretical finding, we further design a Lie Algebraic\nResidual Network (LARNet) for tackling pose robust face recognition. Our LARNet\nconsists of a residual subnet for decoding rotation information from input face\nimages, and a gating subnet to learn rotation magnitude for controlling the\nstrength of the residual component contributing to the feature learning\nprocess. Comprehensive experimental evaluations on both frontal-profile face\ndatasets and general face recognition datasets convincingly demonstrate that\nour method consistently outperforms the state-of-the-art ones.",
          "link": "http://arxiv.org/abs/2103.08147",
          "publishedOn": "2021-06-17T01:58:42.751Z",
          "wordCount": 649,
          "title": "LARNet: Lie Algebra Residual Network for Face Recognition. (arXiv:2103.08147v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.15157",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ruixin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xingyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_K/0/1/0/all/0/1\">Kai Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xiaolin Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yuge Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shaoxin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jilin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Feiyue Huang</a>",
          "description": "Recent studies reveal that Convolutional Neural Networks (CNNs) are typically\nvulnerable to adversarial attacks, which pose a threat to security-sensitive\napplications. Many adversarial defense methods improve robustness at the cost\nof accuracy, raising the contradiction between standard and adversarial\naccuracies. In this paper, we observe an interesting phenomenon that feature\nstatistics change monotonically and smoothly w.r.t the rising of attacking\nstrength. Based on this observation, we propose the adaptive feature alignment\n(AFA) to generate features of arbitrary attacking strengths. Our method is\ntrained to automatically align features of arbitrary attacking strength. This\nis done by predicting a fusing weight in a dual-BN architecture. Unlike\nprevious works that need to either retrain the model or manually tune a\nhyper-parameters for different attacking strengths, our method can deal with\narbitrary attacking strengths with a single model without introducing any\nhyper-parameter. Importantly, our method improves the model robustness against\nadversarial samples without incurring much loss in standard accuracy.\nExperiments on CIFAR-10, SVHN, and tiny-ImageNet datasets demonstrate that our\nmethod outperforms the state-of-the-art under a wide range of attacking\nstrengths.",
          "link": "http://arxiv.org/abs/2105.15157",
          "publishedOn": "2021-06-17T01:58:42.744Z",
          "wordCount": 628,
          "title": "Adaptive Feature Alignment for Adversarial Training. (arXiv:2105.15157v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.06759",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Seker_M/0/1/0/all/0/1\">Mert Seker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mannisto_A/0/1/0/all/0/1\">Anssi M&#xe4;nnist&#xf6;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iosifidis_A/0/1/0/all/0/1\">Alexandros Iosifidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raitoharju_J/0/1/0/all/0/1\">Jenni Raitoharju</a>",
          "description": "The COVID-19 virus has caused a global pandemic since March 2020. The World\nHealth Organization (WHO) has provided guidelines on how to reduce the spread\nof the virus and one of the most important measures is social distancing.\nMaintaining a minimum of one meter distance from other people is strongly\nsuggested to reduce the risk of infection. This has created a strong interest\nin monitoring the social distances either as a safety measure or to study how\nthe measures have affected human behavior and country-wise differences in this.\nThe need for automatic social distance estimation algorithms is evident, but\nthere is no suitable test benchmark for such algorithms. Collecting images with\nmeasured ground-truth pair-wise distances between all the people using\ndifferent camera settings is cumbersome. Furthermore, performance evaluation\nfor social distance estimation algorithms is not straightforward and there is\nno widely accepted evaluation protocol. In this paper, we provide a dataset of\nvarying images with measured pair-wise social distances under different camera\npositionings and focal length values. We suggest a performance evaluation\nprotocol and provide a benchmark to easily evaluate social distance estimation\nalgorithms. We also propose a method for automatic social distance estimation.\nOur method takes advantage of object detection and human pose estimation. It\ncan be applied on any single image as long as focal length and sensor size\ninformation are known. The results on our benchmark are encouraging with 92%\nhuman detection rate and only 28.9% average error in distance estimation among\nthe detected people.",
          "link": "http://arxiv.org/abs/2103.06759",
          "publishedOn": "2021-06-17T01:58:42.733Z",
          "wordCount": 774,
          "title": "Automatic Social Distance Estimation From Images: Performance Evaluation, Test Benchmark, and Algorithm. (arXiv:2103.06759v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08856",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Szymanowicz_S/0/1/0/all/0/1\">Stanislaw Szymanowicz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Charles_J/0/1/0/all/0/1\">James Charles</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cipolla_R/0/1/0/all/0/1\">Roberto Cipolla</a>",
          "description": "Our objective is to detect anomalies in video while also automatically\nexplaining the reason behind the detector's response. In a practical sense,\nexplainability is crucial for this task as the required response to an anomaly\ndepends on its nature and severity. However, most leading methods (based on\ndeep neural networks) are not interpretable and hide the decision making\nprocess in uninterpretable feature representations. In an effort to tackle this\nproblem we make the following contributions: (1) we show how to build\ninterpretable feature representations suitable for detecting anomalies with\nstate of the art performance, (2) we propose an interpretable probabilistic\nanomaly detector which can describe the reason behind it's response using high\nlevel concepts, (3) we are the first to directly consider object interactions\nfor anomaly detection and (4) we propose a new task of explaining anomalies and\nrelease a large dataset for evaluating methods on this task. Our method\ncompetes well with the state of the art on public datasets while also providing\nanomaly explanation based on objects and their interactions.",
          "link": "http://arxiv.org/abs/2106.08856",
          "publishedOn": "2021-06-17T01:58:42.690Z",
          "wordCount": 616,
          "title": "X-MAN: Explaining multiple sources of anomalies in video. (arXiv:2106.08856v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08798",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Jongmin Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_H/0/1/0/all/0/1\">Hyeontaek Oh</a>",
          "description": "This paper addresses unsupervised person re-identification (Re-ID) using\nmulti-label prediction and classification based on graph-structural insight.\nOur method extracts features from person images and produces a graph that\nconsists of the features and a pairwise similarity of them as nodes and edges,\nrespectively. Based on the graph, the proposed graph structure based\nmulti-label prediction (GSMLP) method predicts multi-labels by considering the\npairwise similarity and the adjacency node distribution of each node. The\nmulti-labels created by GSMLP are applied to the proposed selective multi-label\nclassification (SMLC) loss. SMLC integrates a hard-sample mining scheme and a\nmulti-label classification. The proposed GSMLP and SMLC boost the performance\nof unsupervised person Re-ID without any pre-labelled dataset. Experimental\nresults justify the superiority of the proposed method in unsupervised person\nRe-ID by producing state-of-the-art performance. The source code for this paper\nis publicly available on 'https://github.com/uknownpioneer/GSMLP-SMLC.git'.",
          "link": "http://arxiv.org/abs/2106.08798",
          "publishedOn": "2021-06-17T01:58:42.664Z",
          "wordCount": 583,
          "title": "Unsupervised Person Re-identification via Multi-Label Prediction and Classification based on Graph-Structural Insight. (arXiv:2106.08798v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08749",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1\">Tianyun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1\">Juan Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheng_Q/0/1/0/all/0/1\">Qiang Sheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_J/0/1/0/all/0/1\">Jiaqi Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xirong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1\">Sheng Tang</a>",
          "description": "Rapid pace of generative models has brought about new threats to visual\nforensics such as malicious personation and digital copyright infringement,\nwhich promotes works on fake image attribution. Existing works on fake image\nattribution mainly rely on a direct classification framework. Without\nadditional supervision, the extracted features could include many\ncontent-relevant components and generalize poorly. Meanwhile, how to obtain an\ninterpretable GAN fingerprint to explain the decision remains an open question.\nAdopting a multi-task framework, we propose a GAN Fingerprint Disentangling\nNetwork (GFD-Net) to simultaneously disentangle the fingerprint from\nGAN-generated images and produce a content-irrelevant representation for fake\nimage attribution. A series of constraints are provided to guarantee the\nstability and discriminability of the fingerprint, which in turn helps\ncontent-irrelevant feature extraction. Further, we perform comprehensive\nanalysis on GAN fingerprint, providing some clues about the properties of GAN\nfingerprint and which factors dominate the fingerprint in GAN architecture.\nExperiments show that our GFD-Net achieves superior fake image attribution\nperformance in both closed-world and open-world testing. We also apply our\nmethod in binary fake image detection and exhibit a significant generalization\nability on unseen generators.",
          "link": "http://arxiv.org/abs/2106.08749",
          "publishedOn": "2021-06-17T01:58:42.651Z",
          "wordCount": 627,
          "title": "Learning to Disentangle GAN Fingerprint for Fake Image Attribution. (arXiv:2106.08749v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2012.09054",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zhou_H/0/1/0/all/0/1\">Huanyu Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_Q/0/1/0/all/0/1\">Qingjie Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_Y/0/1/0/all/0/1\">Yunhong Wang</a>",
          "description": "Pan-sharpening aims at fusing a low-resolution (LR) multi-spectral (MS) image\nand a high-resolution (HR) panchromatic (PAN) image acquired by a satellite to\ngenerate an HR MS image. Many deep learning based methods have been developed\nin the past few years. However, since there are no intended HR MS images as\nreferences for learning, almost all of the existing methods down-sample the MS\nand PAN images and regard the original MS images as targets to form a\nsupervised setting for training. These methods may perform well on the\ndown-scaled images, however, they generalize poorly to the full-resolution\nimages. To conquer this problem, we design an unsupervised framework that is\nable to learn directly from the full-resolution images without any\npreprocessing. The model is built based on a novel generative multi-adversarial\nnetwork. We use a two-stream generator to extract the modality-specific\nfeatures from the PAN and MS images, respectively, and develop a\ndual-discriminator to preserve the spectral and spatial information of the\ninputs when performing fusion. Furthermore, a novel loss function is introduced\nto facilitate training under the unsupervised setting. Experiments and\ncomparisons with other state-of-the-art methods on GaoFen-2 and QuickBird\nimages demonstrate that the proposed method can obtain much better fusion\nresults on the full-resolution images.",
          "link": "http://arxiv.org/abs/2012.09054",
          "publishedOn": "2021-06-17T01:58:42.627Z",
          "wordCount": 666,
          "title": "PGMAN: An Unsupervised Generative Multi-adversarial Network for Pan-sharpening. (arXiv:2012.09054v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.13342",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_N/0/1/0/all/0/1\">Naiyu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shan_Y/0/1/0/all/0/1\">Yanhu Shan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1\">Kaiqi Huang</a>",
          "description": "Panoptic segmentation (PS) is a complex scene understanding task that\nrequires providing high-quality segmentation for both thing objects and stuff\nregions. Previous methods handle these two classes with semantic and instance\nsegmentation modules separately, following with heuristic fusion or additional\nmodules to resolve the conflicts between the two outputs. This work simplifies\nthis pipeline of PS by consistently modeling the two classes with a novel PS\nframework, which extends a detection model with an extra module to predict\ncategory- and instance-aware pixel embedding (CIAE). CIAE is a novel pixel-wise\nembedding feature that encodes both semantic-classification and\ninstance-distinction information. At the inference process, PS results are\nsimply derived by assigning each pixel to a detected instance or a stuff class\naccording to the learned embedding. Our method not only demonstrates fast\ninference speed but also the first one-stage method to achieve comparable\nperformance to two-stage methods on the challenging COCO benchmark.",
          "link": "http://arxiv.org/abs/2009.13342",
          "publishedOn": "2021-06-17T01:58:42.617Z",
          "wordCount": 612,
          "title": "Learning Category- and Instance-Aware Pixel Embedding for Fast Panoptic Segmentation. (arXiv:2009.13342v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08829",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheema_G/0/1/0/all/0/1\">Gullal S. Cheema</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hakimov_S/0/1/0/all/0/1\">Sherzod Hakimov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muller_Budack_E/0/1/0/all/0/1\">Eric M&#xfc;ller-Budack</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ewerth_R/0/1/0/all/0/1\">Ralph Ewerth</a>",
          "description": "Opinion and sentiment analysis is a vital task to characterize subjective\ninformation in social media posts. In this paper, we present a comprehensive\nexperimental evaluation and comparison with six state-of-the-art methods, from\nwhich we have re-implemented one of them. In addition, we investigate different\ntextual and visual feature embeddings that cover different aspects of the\ncontent, as well as the recently introduced multimodal CLIP embeddings.\nExperimental results are presented for two different publicly available\nbenchmark datasets of tweets and corresponding images. In contrast to the\nevaluation methodology of previous work, we introduce a reproducible and fair\nevaluation scheme to make results comparable. Finally, we conduct an error\nanalysis to outline the limitations of the methods and possibilities for the\nfuture work.",
          "link": "http://arxiv.org/abs/2106.08829",
          "publishedOn": "2021-06-17T01:58:42.610Z",
          "wordCount": 583,
          "title": "A Fair and Comprehensive Comparison of Multimodal Tweet Sentiment Analysis Methods. (arXiv:2106.08829v1 [cs.SI])"
        },
        {
          "id": "http://arxiv.org/abs/2012.04293",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ates_T/0/1/0/all/0/1\">Tayfun Ates</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Atesoglu_M/0/1/0/all/0/1\">Muhammed Samil Atesoglu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yigit_C/0/1/0/all/0/1\">Cagatay Yigit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kesen_I/0/1/0/all/0/1\">Ilker Kesen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kobas_M/0/1/0/all/0/1\">Mert Kobas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erdem_E/0/1/0/all/0/1\">Erkut Erdem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erdem_A/0/1/0/all/0/1\">Aykut Erdem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goksun_T/0/1/0/all/0/1\">Tilbe Goksun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuret_D/0/1/0/all/0/1\">Deniz Yuret</a>",
          "description": "Humans are able to perceive, understand and reason about physical events.\nDeveloping models with similar physical understanding capabilities is a\nlong-standing goal of artificial intelligence. As a step towards this goal, in\nthis work, we introduce CRAFT, a new visual question answering dataset that\nrequires causal reasoning about physical forces and object interactions. It\ncontains 58K video and question pairs that are generated from 10K videos from\n20 different virtual environments, containing various objects in motion that\ninteract with each other and the scene. Two question categories from CRAFT\ninclude previously studied descriptive and counterfactual questions. Besides,\ninspired by the theories of force dynamics in cognitive linguistics, we\nintroduce new question categories that involve understanding the interactions\nof objects through the notions of cause, enable, and prevent. Our results\ndemonstrate that even though these tasks seem to be simple and intuitive for\nhumans, the evaluated baseline models, including existing state-of-the-art\nmethods, do not yet deal with the challenges posed in our benchmark dataset.",
          "link": "http://arxiv.org/abs/2012.04293",
          "publishedOn": "2021-06-17T01:58:42.604Z",
          "wordCount": 659,
          "title": "CRAFT: A Benchmark for Causal Reasoning About Forces and inTeractions. (arXiv:2012.04293v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08624",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_W/0/1/0/all/0/1\">Wenqing Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1\">Jiyang Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Weidong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1\">Zhanyu Ma</a>",
          "description": "With the complexity of the network structure, uncertainty inference has\nbecome an important task to improve the classification accuracy for artificial\nintelligence systems. For image classification tasks, we propose a structured\nDropConnect (SDC) framework to model the output of a deep neural network by a\nDirichlet distribution. We introduce a DropConnect strategy on weights in the\nfully connected layers during training. In test, we split the network into\nseveral sub-networks, and then model the Dirichlet distribution by match its\nmoments with the mean and variance of the outputs of these sub-networks. The\nentropy of the estimated Dirichlet distribution is finally utilized for\nuncertainty inference. In this paper, this framework is implemented on LeNet$5$\nand VGG$16$ models for misclassification detection and out-of-distribution\ndetection on MNIST and CIFAR-$10$ datasets. Experimental results show that the\nperformance of the proposed SDC can be comparable to other uncertainty\ninference methods. Furthermore, the SDC is adapted well to different network\nstructures with certain generalization capabilities and research prospects.",
          "link": "http://arxiv.org/abs/2106.08624",
          "publishedOn": "2021-06-17T01:58:42.598Z",
          "wordCount": 611,
          "title": "Structured DropConnect for Uncertainty Inference in Image Classification. (arXiv:2106.08624v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08816",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cao_Z/0/1/0/all/0/1\">Ziang Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1\">Changhong Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Junjie Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bowen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yiming Li</a>",
          "description": "Recently, the Siamese-based method has stood out from multitudinous tracking\nmethods owing to its state-of-the-art (SOTA) performance. Nevertheless, due to\nvarious special challenges in UAV tracking, \\textit{e.g.}, severe occlusion,\nand fast motion, most existing Siamese-based trackers hardly combine superior\nperformance with high efficiency. To this concern, in this paper, a novel\nattentional Siamese tracker (SiamAPN++) is proposed for real-time UAV tracking.\nBy virtue of the attention mechanism, the attentional aggregation network (AAN)\nis conducted with self-AAN and cross-AAN, raising the expression ability of\nfeatures eventually. The former AAN aggregates and models the self-semantic\ninterdependencies of the single feature map via spatial and channel dimensions.\nThe latter aims to aggregate the cross-interdependencies of different semantic\nfeatures including the location information of anchors. In addition, the dual\nfeatures version of the anchor proposal network is proposed to raise the\nrobustness of proposing anchors, increasing the perception ability to objects\nwith various scales. Experiments on two well-known authoritative benchmarks are\nconducted, where SiamAPN++ outperforms its baseline SiamAPN and other SOTA\ntrackers. Besides, real-world tests onboard a typical embedded platform\ndemonstrate that SiamAPN++ achieves promising tracking results with real-time\nspeed.",
          "link": "http://arxiv.org/abs/2106.08816",
          "publishedOn": "2021-06-17T01:58:42.591Z",
          "wordCount": 619,
          "title": "SiamAPN++: Siamese Attentional Aggregation Network for Real-Time UAV Tracking. (arXiv:2106.08816v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2103.05056",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cattaneo_D/0/1/0/all/0/1\">Daniele Cattaneo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vaghi_M/0/1/0/all/0/1\">Matteo Vaghi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valada_A/0/1/0/all/0/1\">Abhinav Valada</a>",
          "description": "Loop closure detection is an essential component of Simultaneous Localization\nand Mapping (SLAM) systems, which reduces the drift accumulated over time. Over\nthe years, several deep learning approaches have been proposed to address this\ntask, however their performance has been subpar compared to handcrafted\ntechniques, especially while dealing with reverse loops. In this paper, we\nintroduce the novel LCDNet that effectively detects loop closures in LiDAR\npoint clouds by simultaneously identifying previously visited places and\nestimating the 6-DoF relative transformation between the current scan and the\nmap. LCDNet is composed of a shared encoder, a place recognition head that\nextracts global descriptors, and a relative pose head that estimates the\ntransformation between two point clouds. We introduce a novel relative pose\nhead based on the unbalanced optimal transport theory that we implement in a\ndifferentiable manner to allow for end-to-end training. Extensive evaluations\nof LCDNet on multiple real-world autonomous driving datasets show that our\napproach outperforms state-of-the-art loop closure detection and point cloud\nregistration techniques by a large margin, especially while dealing with\nreverse loops. Moreover, we integrate our proposed loop closure detection\napproach into a LiDAR SLAM library to provide a complete mapping system and\ndemonstrate the generalization ability using different sensor setup in an\nunseen city.",
          "link": "http://arxiv.org/abs/2103.05056",
          "publishedOn": "2021-06-17T01:58:42.584Z",
          "wordCount": 675,
          "title": "LCDNet: Deep Loop Closure Detection and Point Cloud Registration for LiDAR SLAM. (arXiv:2103.05056v2 [cs.RO] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.09242",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1\">Sourya Dipta Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_N/0/1/0/all/0/1\">Nisarg A. Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dutta_S/0/1/0/all/0/1\">Saikat Dutta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_H/0/1/0/all/0/1\">Himanshu Kumar</a>",
          "description": "Custom and natural lighting conditions can be emulated in images of the scene\nduring post-editing. Extraordinary capabilities of the deep learning framework\ncan be utilized for such purpose. Deep image relighting allows automatic photo\nenhancement by illumination-specific retouching. Most of the state-of-the-art\nmethods for relighting are run-time intensive and memory inefficient. In this\npaper, we propose an efficient, real-time framework Deep Stacked Relighting\nNetwork (DSRN) for image relighting by utilizing the aggregated features from\ninput image at different scales. Our model is very lightweight with total size\nof about 42 MB and has an average inference time of about 0.0116s for image of\nresolution $1024 \\times 1024$ which is faster as compared to other multi-scale\nmodels. Our solution is quite robust for translating image color temperature\nfrom input image to target image and also performs moderately for light\ngradient generation with respect to the target image. Additionally, we show\nthat if images illuminated from opposite directions are used as input, the\nqualitative results improve over using a single input image.",
          "link": "http://arxiv.org/abs/2102.09242",
          "publishedOn": "2021-06-17T01:58:42.566Z",
          "wordCount": 637,
          "title": "DSRN: an Efficient Deep Network for Image Relighting. (arXiv:2102.09242v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.12077",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zaheer_M/0/1/0/all/0/1\">Muhammad Zaigham Zaheer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahmood_A/0/1/0/all/0/1\">Arif Mahmood</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Astrid_M/0/1/0/all/0/1\">Marcella Astrid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Seung-Ik Lee</a>",
          "description": "Learning to detect real-world anomalous events through video-level labels is\na challenging task due to the rare occurrence of anomalies as well as noise in\nthe labels. In this work, we propose a weakly supervised anomaly detection\nmethod which has manifold contributions including1) a random batch based\ntraining procedure to reduce inter-batch correlation, 2) a normalcy suppression\nmechanism to minimize anomaly scores of the normal regions of a video by taking\ninto account the overall information available in one training batch, and 3) a\nclustering distance based loss to contribute towards mitigating the label noise\nand to produce better anomaly representations by encouraging our model to\ngenerate distinct normal and anomalous clusters. The proposed method\nobtains83.03% and 89.67% frame-level AUC performance on the UCF Crime and\nShanghaiTech datasets respectively, demonstrating its superiority over the\nexisting state-of-the-art algorithms.",
          "link": "http://arxiv.org/abs/2011.12077",
          "publishedOn": "2021-06-17T01:58:42.537Z",
          "wordCount": 679,
          "title": "CLAWS: Clustering Assisted Weakly Supervised Learning with Normalcy Suppression for Anomalous Event Detection. (arXiv:2011.12077v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08917",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khan_N/0/1/0/all/0/1\">Numair Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Min H. Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tompkin_J/0/1/0/all/0/1\">James Tompkin</a>",
          "description": "We present a method to estimate dense depth by optimizing a sparse set of\npoints such that their diffusion into a depth map minimizes a multi-view\nreprojection error from RGB supervision. We optimize point positions, depths,\nand weights with respect to the loss by differential splatting that models\npoints as Gaussians with analytic transmittance. Further, we develop an\nefficient optimization routine that can simultaneously optimize the 50k+ points\nrequired for complex scene reconstruction. We validate our routine using ground\ntruth data and show high reconstruction quality. Then, we apply this to light\nfield and wider baseline images via self supervision, and show improvements in\nboth average and outlier error for depth maps diffused from inaccurate sparse\npoints. Finally, we compare qualitative and quantitative results to image\nprocessing and deep learning methods.",
          "link": "http://arxiv.org/abs/2106.08917",
          "publishedOn": "2021-06-17T01:58:42.529Z",
          "wordCount": 566,
          "title": "Differentiable Diffusion for Dense Depth Estimation from Multi-view Images. (arXiv:2106.08917v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2011.13681",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mani_A/0/1/0/all/0/1\">Arjun Mani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hinthorn_W/0/1/0/all/0/1\">Will Hinthorn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoo_N/0/1/0/all/0/1\">Nobline Yoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Russakovsky_O/0/1/0/all/0/1\">Olga Russakovsky</a>",
          "description": "Visual Question Answering (VQA) has become one of the key benchmarks of\nvisual recognition progress. Multiple VQA extensions have been explored to\nbetter simulate real-world settings: different question formulations, changing\ntraining and test distributions, conversational consistency in dialogues, and\nexplanation-based answering. In this work, we further expand this space by\nconsidering visual questions that include a spatial point of reference.\nPointing is a nearly universal gesture among humans, and real-world VQA is\nlikely to involve a gesture towards the target region.\n\nConcretely, we (1) introduce and motivate point-input questions as an\nextension of VQA, (2) define three novel classes of questions within this\nspace, and (3) for each class, introduce both a benchmark dataset and a series\nof baseline models to handle its unique challenges. There are two key\ndistinctions from prior work. First, we explicitly design the benchmarks to\nrequire the point input, i.e., we ensure that the visual question cannot be\nanswered accurately without the spatial reference. Second, we explicitly\nexplore the more realistic point spatial input rather than the standard but\nunnatural bounding box input. Through our exploration we uncover and address\nseveral visual recognition challenges, including the ability to infer human\nintent, reason both locally and globally about the image, and effectively\ncombine visual, language and spatial inputs. Code is available at:\nhttps://github.com/princetonvisualai/pointingqa .",
          "link": "http://arxiv.org/abs/2011.13681",
          "publishedOn": "2021-06-17T01:58:42.514Z",
          "wordCount": 678,
          "title": "Point and Ask: Incorporating Pointing into Visual Question Answering. (arXiv:2011.13681v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08752",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fuping Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_X/0/1/0/all/0/1\">Xiahai Zhuang</a>",
          "description": "Unsupervised domain adaptation is useful in medical image segmentation.\nParticularly, when ground truths of the target images are not available, domain\nadaptation can train a target-specific model by utilizing the existing labeled\nimages from other modalities. Most of the reported works mapped images of both\nthe source and target domains into a common latent feature space, and then\nreduced their discrepancy either implicitly with adversarial training or\nexplicitly by directly minimizing a discrepancy metric. In this work, we\npropose a new framework, where the latent features of both domains are driven\ntowards a common and parameterized variational form, whose conditional\ndistribution given the image is Gaussian. This is achieved by two networks\nbased on variational auto-encoders (VAEs) and a regularization for this\nvariational approximation. Both of the VAEs, each for one domain, contain a\nsegmentation module, where the source segmentation is trained in a supervised\nmanner, while the target one is trained unsupervisedly. We validated the\nproposed domain adaptation method using two cardiac segmentation tasks, i.e.,\nthe cross-modality (CT and MR) whole heart segmentation and the cross-sequence\ncardiac MR segmentation. Results show that the proposed method achieved better\naccuracies compared to two state-of-the-art approaches and demonstrated good\npotential for cardiac segmentation. Furthermore, the proposed explicit\nregularization was shown to be effective and efficient in narrowing down the\ndistribution gap between domains, which is useful for unsupervised domain\nadaptation. Our code and data has been released via\nhttps://zmiclab.github.io/projects.html.",
          "link": "http://arxiv.org/abs/2106.08752",
          "publishedOn": "2021-06-17T01:58:42.492Z",
          "wordCount": 674,
          "title": "Unsupervised Domain Adaptation with Variational Approximation for Cardiac Segmentation. (arXiv:2106.08752v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.09018",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1\">Mengde Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Han Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianfeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lijuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Fangyun Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_X/0/1/0/all/0/1\">Xiang Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zicheng Liu</a>",
          "description": "This paper presents an end-to-end semi-supervised object detection approach,\nin contrast to previous more complex multi-stage methods. The end-to-end\ntraining gradually improves pseudo label qualities during the curriculum, and\nthe more and more accurate pseudo labels in turn benefit object detection\ntraining. We also propose two simple yet effective techniques within this\nframework: a soft teacher mechanism where the classification loss of each\nunlabeled bounding box is weighed by the classification score produced by the\nteacher network; a box jittering approach to select reliable pseudo boxes for\nthe learning of box regression. On COCO benchmark, the proposed approach\noutperforms previous methods by a large margin under various labeling ratios,\ni.e. 1\\%, 5\\% and 10\\%. Moreover, our approach proves to perform also well when\nthe amount of labeled data is relatively large. For example, it can improve a\n40.9 mAP baseline detector trained using the full COCO training set by +3.6\nmAP, reaching 44.5 mAP, by leveraging the 123K unlabeled images of COCO. On the\nstate-of-the-art Swin Transformer-based object detector (58.9 mAP on test-dev),\nit can still significantly improve the detection accuracy by +1.5 mAP, reaching\n60.4 mAP, and improve the instance segmentation accuracy by +1.2 mAP, reaching\n52.4 mAP, pushing the new state-of-the-art.",
          "link": "http://arxiv.org/abs/2106.09018",
          "publishedOn": "2021-06-17T01:58:42.478Z",
          "wordCount": 642,
          "title": "End-to-End Semi-Supervised Object Detection with Soft Teacher. (arXiv:2106.09018v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08727",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zimmer_V/0/1/0/all/0/1\">Veronika A. Zimmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schnabel_J/0/1/0/all/0/1\">Julia A. Schnabel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_X/0/1/0/all/0/1\">Xiahai Zhuang</a>",
          "description": "Left atrial (LA) segmentation from late gadolinium enhanced magnetic\nresonance imaging (LGE MRI) is a crucial step needed for planning the treatment\nof atrial fibrillation. However, automatic LA segmentation from LGE MRI is\nstill challenging, due to the poor image quality, high variability in LA\nshapes, and unclear LA boundary. Though deep learning-based methods can provide\npromising LA segmentation results, they often generalize poorly to unseen\ndomains, such as data from different scanners and/or sites. In this work, we\ncollect 210 LGE MRIs from different centers with different levels of image\nquality. To evaluate the domain generalization ability of models on the LA\nsegmentation task, we employ four commonly used semantic segmentation networks\nfor the LA segmentation from multi-center LGE MRIs. Besides, we investigate\nthree domain generalization strategies, i.e., histogram matching, mutual\ninformation based disentangled representation, and random style transfer, where\na simple histogram matching is proved to be most effective.",
          "link": "http://arxiv.org/abs/2106.08727",
          "publishedOn": "2021-06-17T01:58:42.460Z",
          "wordCount": 594,
          "title": "AtrialGeneral: Domain Generalization for Left Atrial Segmentation of Multi-Center LGE MRIs. (arXiv:2106.08727v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08914",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Le_H/0/1/0/all/0/1\">Hung Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1\">Nancy F. Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoi_S/0/1/0/all/0/1\">Steven C.H. Hoi</a>",
          "description": "Video-grounded dialogue systems aim to integrate video understanding and\ndialogue understanding to generate responses that are relevant to both the\ndialogue and video context. Most existing approaches employ deep learning\nmodels and have achieved remarkable performance, given the relatively small\ndatasets available. However, the results are partly accomplished by exploiting\nbiases in the datasets rather than developing multimodal reasoning, resulting\nin limited generalization. In this paper, we propose a novel approach of\nCompositional Counterfactual Contrastive Learning ($C^3$) to develop\ncontrastive training between factual and counterfactual samples in\nvideo-grounded dialogues. Specifically, we design factual/counterfactual\nsampling based on the temporal steps in videos and tokens in dialogues and\npropose contrastive loss functions that exploit object-level or action-level\nvariance. Different from prior approaches, we focus on contrastive hidden state\nrepresentations among compositional output tokens to optimize the\nrepresentation space in a generation setting. We achieved promising performance\ngains on the Audio-Visual Scene-Aware Dialogues (AVSD) benchmark and showed the\nbenefits of our approach in grounding video and dialogue context.",
          "link": "http://arxiv.org/abs/2106.08914",
          "publishedOn": "2021-06-17T01:58:42.454Z",
          "wordCount": 608,
          "title": "$C^3$: Compositional Counterfactual Constrastive Learning for Video-grounded Dialogues. (arXiv:2106.08914v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2007.07978",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nielsen_A/0/1/0/all/0/1\">A. H. Nielsen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iosifidis_A/0/1/0/all/0/1\">A. Iosifidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karstoft_H/0/1/0/all/0/1\">H. Karstoft</a>",
          "description": "Forecasting the formation and development of clouds is a central element of\nmodern weather forecasting systems. Incorrect clouds forecasts can lead to\nmajor uncertainty in the overall accuracy of weather forecasts due to their\nintrinsic role in the Earth's climate system. Few studies have tackled this\nchallenging problem from a machine learning point-of-view due to a shortage of\nhigh-resolution datasets with many historical observations globally. In this\npaper, we present a novel satellite-based dataset called ``CloudCast''. It\nconsists of 70,080 images with 10 different cloud types for multiple layers of\nthe atmosphere annotated on a pixel level. The spatial resolution of the\ndataset is 928 x 1530 pixels (3x3 km per pixel) with 15-min intervals between\nframes for the period 2017-01-01 to 2018-12-31. All frames are centered and\nprojected over Europe. To supplement the dataset, we conduct an evaluation\nstudy with current state-of-the-art video prediction methods such as\nconvolutional long short-term memory networks, generative adversarial networks,\nand optical flow-based extrapolation methods. As the evaluation of video\nprediction is difficult in practice, we aim for a thorough evaluation in the\nspatial and temporal domain. Our benchmark models show promising results but\nwith ample room for improvement. This is the first publicly available\nglobal-scale dataset with high-resolution cloud types on a high temporal\ngranularity to the authors' best knowledge.",
          "link": "http://arxiv.org/abs/2007.07978",
          "publishedOn": "2021-06-17T01:58:42.448Z",
          "wordCount": 711,
          "title": "CloudCast: A Satellite-Based Dataset and Baseline for Forecasting Clouds. (arXiv:2007.07978v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.00430",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1\">Chengchao Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1\">Youtan Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinchao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xubin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1\">Jie Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_M/0/1/0/all/0/1\">Mingli Song</a>",
          "description": "Generative Adversarial Networks (GANs) have demonstrated unprecedented\nsuccess in various image generation tasks. The encouraging results, however,\ncome at the price of a cumbersome training process, during which the generator\nand discriminator are alternately updated in two stages. In this paper, we\ninvestigate a general training scheme that enables training GANs efficiently in\nonly one stage. Based on the adversarial losses of the generator and\ndiscriminator, we categorize GANs into two classes, Symmetric GANs and\nAsymmetric GANs, and introduce a novel gradient decomposition method to unify\nthe two, allowing us to train both classes in one stage and hence alleviate the\ntraining effort. We also computationally analyze the efficiency of the proposed\nmethod, and empirically demonstrate that, the proposed method yields a solid\n$1.5\\times$ acceleration across various datasets and network architectures.\nFurthermore, we show that the proposed method is readily applicable to other\nadversarial-training scenarios, such as data-free knowledge distillation. The\ncode is available at https://github.com/zju-vipa/OSGAN.",
          "link": "http://arxiv.org/abs/2103.00430",
          "publishedOn": "2021-06-17T01:58:42.440Z",
          "wordCount": 645,
          "title": "Training Generative Adversarial Networks in One Stage. (arXiv:2103.00430v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.00356",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Somraj_N/0/1/0/all/0/1\">Nagabhushan Somraj</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kashi_M/0/1/0/all/0/1\">Manoj Surya Kashi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Arun_S/0/1/0/all/0/1\">S. P. Arun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Soundararajan_R/0/1/0/all/0/1\">Rajiv Soundararajan</a>",
          "description": "The study of video prediction models is believed to be a fundamental approach\nto representation learning for videos. While a plethora of generative models\nfor predicting the future frame pixel values given the past few frames exist,\nthe quantitative evaluation of the predicted frames has been found to be\nextremely challenging. In this context, we introduce the problem of naturalness\nevaluation, which refers to how natural or realistic a predicted video looks.\nWe create the Indian Institute of Science VIdeo Naturalness Evaluation (IISc\nVINE) Database consisting of 300 videos, obtained by applying different\nprediction models on different datasets, and accompanying human opinion scores.\nWe collected subjective ratings of naturalness from 50 human participants for\nthese videos. Our subjective study reveals that human observers were highly\nconsistent in their judgments of naturalness. We benchmark several popularly\nused measures for evaluating video prediction and show that they do not\nadequately correlate with these subjective scores. We introduce two new\nfeatures to effectively capture naturalness, motion-compensated cosine\nsimilarities of deep features of predicted frames with past frames, and deep\nfeatures extracted from rescaled frame differences. We show that our feature\ndesign leads to state of the art naturalness prediction in accordance with\nhuman judgments on our IISc VINE Database. The database and code are publicly\navailable on our project website:\nhttps://nagabhushansn95.github.io/publications/2020/vine",
          "link": "http://arxiv.org/abs/2005.00356",
          "publishedOn": "2021-06-17T01:58:42.434Z",
          "wordCount": 693,
          "title": "A Naturalness Evaluation Database for Video Prediction Models. (arXiv:2005.00356v3 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08827",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ehsanpour_M/0/1/0/all/0/1\">Mahsa Ehsanpour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saleh_F/0/1/0/all/0/1\">Fatemeh Saleh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Savarese_S/0/1/0/all/0/1\">Silvio Savarese</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reid_I/0/1/0/all/0/1\">Ian Reid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rezatofighi_H/0/1/0/all/0/1\">Hamid Rezatofighi</a>",
          "description": "The availability of large-scale video action understanding datasets has\nfacilitated advances in the interpretation of visual scenes containing people.\nHowever, learning to recognize human activities in an unconstrained real-world\nenvironment, with potentially highly unbalanced and long-tailed distributed\ndata remains a significant challenge, not least owing to the lack of a\nreflective large-scale dataset. Most existing large-scale datasets are either\ncollected from a specific or constrained environment, e.g. kitchens or rooms,\nor video sharing platforms such as YouTube. In this paper, we introduce\nJRDB-Act, a multi-modal dataset, as an extension of the existing JRDB, which is\ncaptured by asocial mobile manipulator and reflects a real distribution of\nhuman daily life actions in a university campus environment. JRDB-Act has been\ndensely annotated with atomic actions, comprises over 2.8M action labels,\nconstituting a large-scale spatio-temporal action detection dataset. Each human\nbounding box is labelled with one pose-based action label and multiple\n(optional) interaction-based action labels. Moreover JRDB-Act comes with social\ngroup identification annotations conducive to the task of grouping individuals\nbased on their interactions in the scene to infer their social activities\n(common activities in each social group).",
          "link": "http://arxiv.org/abs/2106.08827",
          "publishedOn": "2021-06-17T01:58:42.411Z",
          "wordCount": 627,
          "title": "JRDB-Act: A Large-scale Multi-modal Dataset for Spatio-temporal Action, Social Group and Activity Detection. (arXiv:2106.08827v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2102.01955",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pang_Z/0/1/0/all/0/1\">Zhaoyang Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+OMay_C/0/1/0/all/0/1\">Callum Biggs O&#x27;May</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choksi_B/0/1/0/all/0/1\">Bhavin Choksi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+VanRullen_R/0/1/0/all/0/1\">Rufin VanRullen</a>",
          "description": "Modern feedforward convolutional neural networks (CNNs) can now solve some\ncomputer vision tasks at super-human levels. However, these networks only\nroughly mimic human visual perception. One difference from human vision is that\nthey do not appear to perceive illusory contours (e.g. Kanizsa squares) in the\nsame way humans do. Physiological evidence from visual cortex suggests that the\nperception of illusory contours could involve feedback connections. Would\nrecurrent feedback neural networks perceive illusory contours like humans? In\nthis work we equip a deep feedforward convolutional network with brain-inspired\nrecurrent dynamics. The network was first pretrained with an unsupervised\nreconstruction objective on a natural image dataset, to expose it to natural\nobject contour statistics. Then, a classification decision layer was added and\nthe model was finetuned on a form discrimination task: squares vs. randomly\noriented inducer shapes (no illusory contour). Finally, the model was tested\nwith the unfamiliar ''illusory contour'' configuration: inducer shapes oriented\nto form an illusory square. Compared with feedforward baselines, the iterative\n''predictive coding'' feedback resulted in more illusory contours being\nclassified as physical squares. The perception of the illusory contour was\nmeasurable in the luminance profile of the image reconstructions produced by\nthe model, demonstrating that the model really ''sees'' the illusion. Ablation\nstudies revealed that natural image pretraining and feedback error correction\nare both critical to the perception of the illusion. Finally we validated our\nconclusions in a deeper network (VGG): adding the same predictive coding\nfeedback dynamics again leads to the perception of illusory contours.",
          "link": "http://arxiv.org/abs/2102.01955",
          "publishedOn": "2021-06-17T01:58:42.399Z",
          "wordCount": 725,
          "title": "Predictive coding feedback results in perceived illusory contours in a recurrent neural network. (arXiv:2102.01955v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08936",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Murn_L/0/1/0/all/0/1\">Luka Murn</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Blasi_S/0/1/0/all/0/1\">Saverio Blasi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Smeaton_A/0/1/0/all/0/1\">Alan F. Smeaton</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mrak_M/0/1/0/all/0/1\">Marta Mrak</a>",
          "description": "The versatility of recent machine learning approaches makes them ideal for\nimprovement of next generation video compression solutions. Unfortunately,\nthese approaches typically bring significant increases in computational\ncomplexity and are difficult to interpret into explainable models, affecting\ntheir potential for implementation within practical video coding applications.\nThis paper introduces a novel explainable neural network-based inter-prediction\nscheme, to improve the interpolation of reference samples needed for fractional\nprecision motion compensation. The approach requires a single neural network to\nbe trained from which a full quarter-pixel interpolation filter set is derived,\nas the network is easily interpretable due to its linear structure. A novel\ntraining framework enables each network branch to resemble a specific\nfractional shift. This practical solution makes it very efficient to use\nalongside conventional video coding schemes. When implemented in the context of\nthe state-of-the-art Versatile Video Coding (VVC) test model, 0.77%, 1.27% and\n2.25% BD-rate savings can be achieved on average for lower resolution sequences\nunder the random access, low-delay B and low-delay P configurations,\nrespectively, while the complexity of the learned interpolation schemes is\nsignificantly reduced compared to the interpolation with full CNNs.",
          "link": "http://arxiv.org/abs/2106.08936",
          "publishedOn": "2021-06-17T01:58:42.374Z",
          "wordCount": 664,
          "title": "Improved CNN-based Learning of Interpolation Filters for Low-Complexity Inter Prediction in Video Coding. (arXiv:2106.08936v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08886",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_P/0/1/0/all/0/1\">Pengfei Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valanarasu_J/0/1/0/all/0/1\">Jeya Maria Jose Valanarasu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Puyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jinyuan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1\">Shanshan Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patel_V/0/1/0/all/0/1\">Vishal M. Patel</a>",
          "description": "Reconstructing magnetic resonance (MR) images from undersampled data is a\nchallenging problem due to various artifacts introduced by the under-sampling\noperation. Recent deep learning-based methods for MR image reconstruction\nusually leverage a generic auto-encoder architecture which captures low-level\nfeatures at the initial layers and high?level features at the deeper layers.\nSuch networks focus much on global features which may not be optimal to\nreconstruct the fully-sampled image. In this paper, we propose an\nOver-and-Under Complete Convolu?tional Recurrent Neural Network (OUCR), which\nconsists of an overcomplete and an undercomplete Convolutional Recurrent Neural\nNetwork(CRNN). The overcomplete branch gives special attention in learning\nlocal structures by restraining the receptive field of the network. Combining\nit with the undercomplete branch leads to a network which focuses more on\nlow-level features without losing out on the global structures. Extensive\nexperiments on two datasets demonstrate that the proposed method achieves\nsignificant improvements over the compressed sensing and popular deep\nlearning-based methods with less number of trainable parameters. Our code is\navailable at https://github.com/guopengf/OUCR.",
          "link": "http://arxiv.org/abs/2106.08886",
          "publishedOn": "2021-06-17T01:58:42.368Z",
          "wordCount": 608,
          "title": "Over-and-Under Complete Convolutional RNN for MRI Reconstruction. (arXiv:2106.08886v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2005.07662",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Friebel_A/0/1/0/all/0/1\">Adrian Friebel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johann_T/0/1/0/all/0/1\">Tim Johann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drasdo_D/0/1/0/all/0/1\">Dirk Drasdo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoehme_S/0/1/0/all/0/1\">Stefan Hoehme</a>",
          "description": "We present a novel approach that combines machine learning based interactive\nimage segmentation with a two-stage clustering method to identify similarly\ncolored images for efficient batch image segmentation by guided reuse of\nclassifiers. The segmentation task is formulated as a supervised machine\nlearning problem working on homogeneous groups of voxels termed supervoxels.\nClassifiers are interactively trained from sparse annotations in an iterative\nprocess of annotation refinement. Resulting models can be used for batch\nprocessing of previously unseen images. By clustering images into subsets of\nsimilar colorization, we identify a minimal set of prototype images and\ndemonstrate that using only classifiers trained on these prototype images for\ntheir color-cluster significantly improves the average segmentation performance\nof batch processing. The presented methods are applicable for almost any image\ntype and therefore represent a useful tool for image analysis tasks in general.",
          "link": "http://arxiv.org/abs/2005.07662",
          "publishedOn": "2021-06-17T01:58:42.361Z",
          "wordCount": 614,
          "title": "Guided interactive image segmentation using machine learning and color based data set clustering. (arXiv:2005.07662v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08970",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Souri_H/0/1/0/all/0/1\">Hossein Souri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldblum_M/0/1/0/all/0/1\">Micah Goldblum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fowl_L/0/1/0/all/0/1\">Liam Fowl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chellappa_R/0/1/0/all/0/1\">Rama Chellappa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1\">Tom Goldstein</a>",
          "description": "As the curation of data for machine learning becomes increasingly automated,\ndataset tampering is a mounting threat. Backdoor attackers tamper with training\ndata to embed a vulnerability in models that are trained on that data. This\nvulnerability is then activated at inference time by placing a \"trigger\" into\nthe model's input. Typical backdoor attacks insert the trigger directly into\nthe training data, although the presence of such an attack may be visible upon\ninspection. In contrast, the Hidden Trigger Backdoor Attack achieves poisoning\nwithout placing a trigger into the training data at all. However, this hidden\ntrigger attack is ineffective at poisoning neural networks trained from\nscratch. We develop a new hidden trigger attack, Sleeper Agent, which employs\ngradient matching, data selection, and target model re-training during the\ncrafting process. Sleeper Agent is the first hidden trigger backdoor attack to\nbe effective against neural networks trained from scratch. We demonstrate its\neffectiveness on ImageNet and in black-box settings. Our implementation code\ncan be found at https://github.com/hsouri/Sleeper-Agent.",
          "link": "http://arxiv.org/abs/2106.08970",
          "publishedOn": "2021-06-17T01:58:42.347Z",
          "wordCount": 613,
          "title": "Sleeper Agent: Scalable Hidden Trigger Backdoors for Neural Networks Trained from Scratch. (arXiv:2106.08970v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.04057",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Modas_A/0/1/0/all/0/1\">Apostolos Modas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xompero_A/0/1/0/all/0/1\">Alessio Xompero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanchez_Matilla_R/0/1/0/all/0/1\">Ricardo Sanchez-Matilla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frossard_P/0/1/0/all/0/1\">Pascal Frossard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cavallaro_A/0/1/0/all/0/1\">Andrea Cavallaro</a>",
          "description": "We investigate the problem of classifying - from a single image - the level\nof content in a cup or a drinking glass. This problem is made challenging by\nseveral ambiguities caused by transparencies, shape variations and partial\nocclusions, and by the availability of only small training datasets. In this\npaper, we tackle this problem with an appropriate strategy for transfer\nlearning. Specifically, we use adversarial training in a generic source dataset\nand then refine the training with a task-specific dataset. We also discuss and\nexperimentally evaluate several training strategies and their combination on a\nrange of container types of the CORSMAL Containers Manipulation dataset. We\nshow that transfer learning with adversarial training in the source domain\nconsistently improves the classification accuracy on the test set and limits\nthe overfitting of the classifier to specific features of the training data.",
          "link": "http://arxiv.org/abs/2102.04057",
          "publishedOn": "2021-06-17T01:58:42.334Z",
          "wordCount": 616,
          "title": "Improving filling level classification with adversarial training. (arXiv:2102.04057v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08851",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shaoxiong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+She_Y/0/1/0/all/0/1\">Yu She</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Romero_B/0/1/0/all/0/1\">Branden Romero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adelson_E/0/1/0/all/0/1\">Edward Adelson</a>",
          "description": "Vision-based tactile sensors have the potential to provide important contact\ngeometry to localize the objective with visual occlusion. However, it is\nchallenging to measure high-resolution 3D contact geometry for a compact robot\nfinger, to simultaneously meet optical and mechanical constraints. In this\nwork, we present the GelSight Wedge sensor, which is optimized to have a\ncompact shape for robot fingers, while achieving high-resolution 3D\nreconstruction. We evaluate the 3D reconstruction under different lighting\nconfigurations, and extend the method from 3 lights to 1 or 2 lights. We\ndemonstrate the flexibility of the design by shrinking the sensor to the size\nof a human finger for fine manipulation tasks. We also show the effectiveness\nand potential of the reconstructed 3D geometry for pose tracking in the 3D\nspace.",
          "link": "http://arxiv.org/abs/2106.08851",
          "publishedOn": "2021-06-17T01:58:42.317Z",
          "wordCount": 567,
          "title": "GelSight Wedge: Measuring High-Resolution 3D Contact Geometry with a Compact Robot Finger. (arXiv:2106.08851v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2009.04709",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lanfredi_R/0/1/0/all/0/1\">Ricardo Bigolin Lanfredi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Schroeder_J/0/1/0/all/0/1\">Joyce D. Schroeder</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tasdizen_T/0/1/0/all/0/1\">Tolga Tasdizen</a>",
          "description": "Adversarial training, especially projected gradient descent (PGD), has been a\nsuccessful approach for improving robustness against adversarial attacks. After\nadversarial training, gradients of models with respect to their inputs have a\npreferential direction. However, the direction of alignment is not\nmathematically well established, making it difficult to evaluate\nquantitatively. We propose a novel definition of this direction as the\ndirection of the vector pointing toward the closest point of the support of the\nclosest inaccurate class in decision space. To evaluate the alignment with this\ndirection after adversarial training, we apply a metric that uses generative\nadversarial networks to produce the smallest residual needed to change the\nclass present in the image. We show that PGD-trained models have a higher\nalignment than the baseline according to our definition, that our metric\npresents higher alignment values than a competing metric formulation, and that\nenforcing this alignment increases the robustness of models.",
          "link": "http://arxiv.org/abs/2009.04709",
          "publishedOn": "2021-06-17T01:58:42.311Z",
          "wordCount": 693,
          "title": "Quantifying the Preferential Direction of the Model Gradient in Adversarial Training With Projected Gradient Descent. (arXiv:2009.04709v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08808",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dufumier_B/0/1/0/all/0/1\">Benoit Dufumier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gori_P/0/1/0/all/0/1\">Pietro Gori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Victor_J/0/1/0/all/0/1\">Julie Victor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grigis_A/0/1/0/all/0/1\">Antoine Grigis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wessa_M/0/1/0/all/0/1\">Michel Wessa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brambilla_P/0/1/0/all/0/1\">Paolo Brambilla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Favre_P/0/1/0/all/0/1\">Pauline Favre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Polosan_M/0/1/0/all/0/1\">Mircea Polosan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McDonald_C/0/1/0/all/0/1\">Colm McDonald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piguet_C/0/1/0/all/0/1\">Camille Marie Piguet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duchesnay_E/0/1/0/all/0/1\">Edouard Duchesnay</a>",
          "description": "Traditional supervised learning with deep neural networks requires a\ntremendous amount of labelled data to converge to a good solution. For 3D\nmedical images, it is often impractical to build a large homogeneous annotated\ndataset for a specific pathology. Self-supervised methods offer a new way to\nlearn a representation of the images in an unsupervised manner with a neural\nnetwork. In particular, contrastive learning has shown great promises by\n(almost) matching the performance of fully-supervised CNN on vision tasks.\nNonetheless, this method does not take advantage of available meta-data, such\nas participant's age, viewed as prior knowledge. Here, we propose to leverage\ncontinuous proxy metadata, in the contrastive learning framework, by\nintroducing a new loss called y-Aware InfoNCE loss. Specifically, we improve\nthe positive sampling during pre-training by adding more positive examples with\nsimilar proxy meta-data with the anchor, assuming they share similar\ndiscriminative semantic features.With our method, a 3D CNN model pre-trained on\n$10^4$ multi-site healthy brain MRI scans can extract relevant features for\nthree classification tasks: schizophrenia, bipolar diagnosis and Alzheimer's\ndetection. When fine-tuned, it also outperforms 3D CNN trained from scratch on\nthese tasks, as well as state-of-the-art self-supervised methods. Our code is\nmade publicly available here.",
          "link": "http://arxiv.org/abs/2106.08808",
          "publishedOn": "2021-06-17T01:58:42.304Z",
          "wordCount": 661,
          "title": "Contrastive Learning with Continuous Proxy Meta-Data for 3D MRI Classification. (arXiv:2106.08808v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08992",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+DInverno_G/0/1/0/all/0/1\">Giuseppe Alessio D&#x27;Inverno</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bianchini_M/0/1/0/all/0/1\">Monica Bianchini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sampoli_M/0/1/0/all/0/1\">Maria Lucia Sampoli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scarselli_F/0/1/0/all/0/1\">Franco Scarselli</a>",
          "description": "Graph Neural Networks (GNNs) are a wide class of connectionist models for\ngraph processing. They perform an iterative message passing operation on each\nnode and its neighbors, to solve classification/ clustering tasks --- on some\nnodes or on the whole graph --- collecting all such messages, regardless of\ntheir order. Despite the differences among the various models belonging to this\nclass, most of them adopt the same computation scheme, based on a local\naggregation mechanism and, intuitively, the local computation framework is\nmainly responsible for the expressive power of GNNs. In this paper, we prove\nthat the Weisfeiler--Lehman test induces an equivalence relationship on the\ngraph nodes that exactly corresponds to the unfolding equivalence, defined on\nthe original GNN model. Therefore, the results on the expressive power of the\noriginal GNNs can be extended to general GNNs which, under mild conditions, can\nbe proved capable of approximating, in probability and up to any precision, any\nfunction on graphs that respects the unfolding equivalence.",
          "link": "http://arxiv.org/abs/2106.08992",
          "publishedOn": "2021-06-17T01:58:42.297Z",
          "wordCount": 611,
          "title": "An unifying point of view on expressive power of GNNs. (arXiv:2106.08992v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2011.09899",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuhang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_F/0/1/0/all/0/1\">Feng Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_R/0/1/0/all/0/1\">Ruihao Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_M/0/1/0/all/0/1\">Mingzhu Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1\">Xin Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1\">Fengwei Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1\">Shaoqing Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_S/0/1/0/all/0/1\">Shi Gu</a>",
          "description": "User data confidentiality protection is becoming a rising challenge in the\npresent deep learning research. Without access to data, conventional\ndata-driven model compression faces a higher risk of performance degradation.\nRecently, some works propose to generate images from a specific pretrained\nmodel to serve as training data. However, the inversion process only utilizes\nbiased feature statistics stored in one model and is from low-dimension to\nhigh-dimension. As a consequence, it inevitably encounters the difficulties of\ngeneralizability and inexact inversion, which leads to unsatisfactory\nperformance. To address these problems, we propose MixMix based on two simple\nyet effective techniques: (1) Feature Mixing: utilizes various models to\nconstruct a universal feature space for generalized inversion; (2) Data Mixing:\nmixes the synthesized images and labels to generate exact label information. We\nprove the effectiveness of MixMix from both theoretical and empirical\nperspectives. Extensive experiments show that MixMix outperforms existing\nmethods on the mainstream compression tasks, including quantization, knowledge\ndistillation, and pruning. Specifically, MixMix achieves up to 4% and 20%\naccuracy uplift on quantization and pruning, respectively, compared to existing\ndata-free compression work.",
          "link": "http://arxiv.org/abs/2011.09899",
          "publishedOn": "2021-06-17T01:58:42.280Z",
          "wordCount": 653,
          "title": "MixMix: All You Need for Data-Free Compression Are Feature and Data Mixing. (arXiv:2011.09899v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.08262",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Illing_B/0/1/0/all/0/1\">Bernd Illing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ventura_J/0/1/0/all/0/1\">Jean Ventura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bellec_G/0/1/0/all/0/1\">Guillaume Bellec</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gerstner_W/0/1/0/all/0/1\">Wulfram Gerstner</a>",
          "description": "Learning in the brain is poorly understood and learning rules that respect\nbiological constraints, yet yield deep hierarchical representations, are still\nunknown. Here, we propose a learning rule that takes inspiration from\nneuroscience and recent advances in self-supervised deep learning. Learning\nminimizes a simple layer-specific loss function and does not need to\nback-propagate error signals within or between layers. Instead, weight updates\nfollow a local, Hebbian, learning rule that only depends on pre- and\npost-synaptic neuronal activity, predictive dendritic input and widely\nbroadcasted modulation factors which are identical for large groups of neurons.\nThe learning rule applies contrastive predictive learning to a causal,\nbiological setting using saccades (i.e. rapid shifts in gaze direction). We\nfind that networks trained with this self-supervised and local rule build deep\nhierarchical representations of images, speech and video.",
          "link": "http://arxiv.org/abs/2010.08262",
          "publishedOn": "2021-06-17T01:58:42.274Z",
          "wordCount": 624,
          "title": "Local plasticity rules can learn deep representations using self-supervised contrastive predictions. (arXiv:2010.08262v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.09011",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cascante_Bonilla_P/0/1/0/all/0/1\">Paola Cascante-Bonilla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sekhon_A/0/1/0/all/0/1\">Arshdeep Sekhon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_Y/0/1/0/all/0/1\">Yanjun Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ordonez_V/0/1/0/all/0/1\">Vicente Ordonez</a>",
          "description": "Convolutional neural networks for visual recognition require large amounts of\ntraining samples and usually benefit from data augmentation. This paper\nproposes PatchMix, a data augmentation method that creates new samples by\ncomposing patches from pairs of images in a grid-like pattern. These new\nsamples' ground truth labels are set as proportional to the number of patches\nfrom each image. We then add a set of additional losses at the patch-level to\nregularize and to encourage good representations at both the patch and image\nlevels. A ResNet-50 model trained on ImageNet using PatchMix exhibits superior\ntransfer learning capabilities across a wide array of benchmarks. Although\nPatchMix can rely on random pairings and random grid-like patterns for mixing,\nwe explore evolutionary search as a guiding strategy to discover optimal\ngrid-like patterns and image pairing jointly. For this purpose, we conceive a\nfitness function that bypasses the need to re-train a model to evaluate each\nchoice. In this way, PatchMix outperforms a base model on CIFAR-10 (+1.91),\nCIFAR-100 (+5.31), Tiny Imagenet (+3.52), and ImageNet (+1.16) by significant\nmargins, also outperforming previous state-of-the-art pairwise augmentation\nstrategies.",
          "link": "http://arxiv.org/abs/2106.09011",
          "publishedOn": "2021-06-17T01:58:42.253Z",
          "wordCount": 619,
          "title": "Evolving Image Compositions for Feature Representation Learning. (arXiv:2106.09011v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08762",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rozumnyi_D/0/1/0/all/0/1\">Denys Rozumnyi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oswald_M/0/1/0/all/0/1\">Martin R. Oswald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferrari_V/0/1/0/all/0/1\">Vittorio Ferrari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pollefeys_M/0/1/0/all/0/1\">Marc Pollefeys</a>",
          "description": "We address the novel task of jointly reconstructing the 3D shape, texture,\nand motion of an object from a single motion-blurred image. While previous\napproaches address the deblurring problem only in the 2D image domain, our\nproposed rigorous modeling of all object properties in the 3D domain enables\nthe correct description of arbitrary object motion. This leads to significantly\nbetter image decomposition and sharper deblurring results. We model the\nobserved appearance of a motion-blurred object as a combination of the\nbackground and a 3D object with constant translation and rotation. Our method\nminimizes a loss on reconstructing the input image via differentiable rendering\nwith suitable regularizers. This enables estimating the textured 3D mesh of the\nblurred object with high fidelity. Our method substantially outperforms\ncompeting approaches on several benchmarks for fast moving objects deblurring.\nQualitative results show that the reconstructed 3D mesh generates high-quality\ntemporal super-resolution and novel views of the deblurred object.",
          "link": "http://arxiv.org/abs/2106.08762",
          "publishedOn": "2021-06-17T01:58:42.247Z",
          "wordCount": 600,
          "title": "Shape from Blur: Recovering Textured 3D Shape and Motion of Fast Moving Objects. (arXiv:2106.08762v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08897",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1\">Shuangyu Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_C/0/1/0/all/0/1\">Chengsong Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bagavathiannan_M/0/1/0/all/0/1\">Muthukumar Bagavathiannan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1\">Dezhen Song</a>",
          "description": "To enable robotic weed control, we develop algorithms to detect nutsedge weed\nfrom bermudagrass turf. Due to the similarity between the weed and the\nbackground turf, manual data labeling is expensive and error-prone.\nConsequently, directly applying deep learning methods for object detection\ncannot generate satisfactory results. Building on an instance detection\napproach (i.e. Mask R-CNN), we combine synthetic data with raw data to train\nthe network. We propose an algorithm to generate high fidelity synthetic data,\nadopting different levels of annotations to reduce labeling cost. Moreover, we\nconstruct a nutsedge skeleton-based probabilistic map (NSPM) as the neural\nnetwork input to reduce the reliance on pixel-wise precise labeling. We also\nmodify loss function from cross entropy to Kullback-Leibler divergence which\naccommodates uncertainty in the labeling process. We implement the proposed\nalgorithm and compare it with both Faster R-CNN and Mask R-CNN. The results\nshow that our design can effectively overcome the impact of imprecise and\ninsufficient training sample issues and significantly outperform the Faster\nR-CNN counterpart with a false negative rate of only 0.4%. In particular, our\napproach also reduces labeling time by 95% while achieving better performance\nif comparing with the original Mask R-CNN approach.",
          "link": "http://arxiv.org/abs/2106.08897",
          "publishedOn": "2021-06-17T01:58:42.230Z",
          "wordCount": 642,
          "title": "Toward Robotic Weed Control: Detection of Nutsedge Weed in Bermudagrass Turf Using Inaccurate and Insufficient Training Data. (arXiv:2106.08897v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08710",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1\">Jacky Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lam_K/0/1/0/all/0/1\">Kit-Yung Lam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_L/0/1/0/all/0/1\">Lik-Hang Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaoli Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hui_P/0/1/0/all/0/1\">Pan Hui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_X/0/1/0/all/0/1\">Xiang Su</a>",
          "description": "Mobile Augmented Reality (MAR) integrates computer-generated virtual objects\nwith physical environments for mobile devices. MAR systems enable users to\ninteract with MAR devices, such as smartphones and head-worn wearables, and\nperforms seamless transitions from the physical world to a mixed world with\ndigital entities. These MAR systems support user experiences by using MAR\ndevices to provide universal accessibility to digital contents. Over the past\n20 years, a number of MAR systems have been developed, however, the studies and\ndesign of MAR frameworks have not yet been systematically reviewed from the\nperspective of user-centric design. This article presents the first effort of\nsurveying existing MAR frameworks (count: 37) and further discusses the latest\nstudies on MAR through a top-down approach: 1) MAR applications; 2) MAR\nvisualisation techniques adaptive to user mobility and contexts; 3) systematic\nevaluation of MAR frameworks including supported platforms and corresponding\nfeatures such as tracking, feature extraction plus sensing capabilities; and 4)\nunderlying machine learning approaches supporting intelligent operations within\nMAR systems. Finally, we summarise the development of emerging research fields,\ncurrent state-of-the-art, and discuss the important open challenges and\npossible theoretical and technical directions. This survey aims to benefit both\nresearchers and MAR system developers alike.",
          "link": "http://arxiv.org/abs/2106.08710",
          "publishedOn": "2021-06-17T01:58:42.224Z",
          "wordCount": 658,
          "title": "Mobile Augmented Reality: User Interfaces, Frameworks, and Intelligence. (arXiv:2106.08710v1 [cs.HC])"
        },
        {
          "id": "http://arxiv.org/abs/2009.06808",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moraitis_T/0/1/0/all/0/1\">Timoleon Moraitis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sebastian_A/0/1/0/all/0/1\">Abu Sebastian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eleftheriou_E/0/1/0/all/0/1\">Evangelos Eleftheriou</a> (IBM Research - Zurich)",
          "description": "Biological neurons and their in-silico emulations for neuromorphic artificial\nintelligence (AI) use extraordinarily energy-efficient mechanisms, such as\nspike-based communication and local synaptic plasticity. It remains unclear\nwhether these neuronal mechanisms only offer efficiency or also underlie the\nsuperiority of biological intelligence. Here, we prove rigorously that, indeed,\nthe Bayes-optimal prediction and inference of randomly but continuously\ntransforming environments, a common natural setting, relies on short-term\nspike-timing-dependent plasticity, a hallmark of biological synapses. Further,\nthis dynamic Bayesian inference through plasticity enables circuits of the\ncerebral cortex in simulations to recognize previously unseen, highly distorted\ndynamic stimuli. Strikingly, this also introduces a biologically-modelled AI,\nthe first to overcome multiple limitations of deep learning and outperform\nartificial neural networks in a visual task. The cortical-like network is\nspiking and event-based, trained only with unsupervised and local plasticity,\non a small, narrow, and static training dataset, but achieves recognition of\nunseen, transformed, and dynamic data better than deep neural networks with\ncontinuous activations, trained with supervised backpropagation on the\ntransforming data. These results link short-term plasticity to high-level\ncortical function, suggest optimality of natural intelligence for natural\nenvironments, and repurpose neuromorphic AI from mere efficiency to\ncomputational supremacy altogether.",
          "link": "http://arxiv.org/abs/2009.06808",
          "publishedOn": "2021-06-17T01:58:42.206Z",
          "wordCount": 687,
          "title": "Optimality of short-term synaptic plasticity in modelling certain dynamic environments. (arXiv:2009.06808v2 [cs.NE] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08983",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Suleymanov_T/0/1/0/all/0/1\">Tarlan Suleymanov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gadd_M/0/1/0/all/0/1\">Matthew Gadd</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martini_D/0/1/0/all/0/1\">Daniele De Martini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Newman_P/0/1/0/all/0/1\">Paul Newman</a>",
          "description": "In this paper we present the Oxford Road Boundaries Dataset, designed for\ntraining and testing machine-learning-based road-boundary detection and\ninference approaches. We have hand-annotated two of the 10 km-long forays from\nthe Oxford Robotcar Dataset and generated from other forays several thousand\nfurther examples with semi-annotated road-boundary masks. To boost the number\nof training samples in this way, we used a vision-based localiser to project\nlabels from the annotated datasets to other traversals at different times and\nweather conditions. As a result, we release 62605 labelled samples, of which\n47639 samples are curated. Each of these samples contains both raw and\nclassified masks for left and right lenses. Our data contains images from a\ndiverse set of scenarios such as straight roads, parked cars, junctions, etc.\nFiles for download and tools for manipulating the labelled data are available\nat: oxford-robotics-institute.github.io/road-boundaries-dataset",
          "link": "http://arxiv.org/abs/2106.08983",
          "publishedOn": "2021-06-17T01:58:42.191Z",
          "wordCount": 589,
          "title": "The Oxford Road Boundaries Dataset. (arXiv:2106.08983v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2006.09373",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1\">Peijie Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_C/0/1/0/all/0/1\">Chirag Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1\">Anh Nguyen</a>",
          "description": "Adversarial training has been the topic of dozens of studies and a leading\nmethod for defending against adversarial attacks. Yet, it remains largely\nunknown (a) how adversarially-robust ImageNet classifiers (R classifiers)\ngeneralize to out-of-distribution examples; and (b) how their generalization\ncapability relates to their hidden representations. In this paper, we perform a\nthorough, systematic study to answer these two questions across AlexNet,\nGoogLeNet, and ResNet-50 architectures. We found that while standard ImageNet\nclassifiers have a strong texture bias, their R counterparts rely heavily on\nshapes. Remarkably, adversarial training induces three simplicity biases into\nhidden neurons in the process of 'robustifying' the network. That is, each\nconvolutional neuron in R networks often changes to detecting (1) pixel-wise\nsmoother patterns i.e. a mechanism that blocks high-frequency noise from\npassing through the network; (2) more lower-level features i.e. textures and\ncolors (instead of objects); and (3) fewer types of inputs. Our findings reveal\nthe interesting mechanisms that made networks more adversarially robust and\nalso explain some recent findings. Our findings reveal the interesting\nmechanisms that made networks more adversarially robust and also explain some\nrecent findings e.g. why R networks benefit from much larger capacity (Xie and\nYuille, 2020) and can act as a strong image prior in image synthesis (Santurkar\net al., 2019).",
          "link": "http://arxiv.org/abs/2006.09373",
          "publishedOn": "2021-06-17T01:58:42.186Z",
          "wordCount": 693,
          "title": "The shape and simplicity biases of adversarially robust ImageNet-trained CNNs. (arXiv:2006.09373v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.09003",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zha_J/0/1/0/all/0/1\">Jiajun Zha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1\">Yiran Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1\">Liang Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hartley_R/0/1/0/all/0/1\">Richard Hartley</a>",
          "description": "Attention has been proved to be an efficient mechanism to capture long-range\ndependencies. However, so far it has not been deployed in invertible networks.\nThis is due to the fact that in order to make a network invertible, every\ncomponent within the network needs to be a bijective transformation, but a\nnormal attention block is not. In this paper, we propose invertible attention\nthat can be plugged into existing invertible models. We mathematically and\nexperimentally prove that the invertibility of an attention model can be\nachieved by carefully constraining its Lipschitz constant. We validate the\ninvertibility of our invertible attention on image reconstruction task with 3\npopular datasets: CIFAR-10, SVHN, and CelebA. We also show that our invertible\nattention achieves similar performance in comparison with normal non-invertible\nattention on dense prediction tasks.",
          "link": "http://arxiv.org/abs/2106.09003",
          "publishedOn": "2021-06-17T01:58:42.143Z",
          "wordCount": 555,
          "title": "Invertible Attention. (arXiv:2106.09003v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2007.10817",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Foo_L/0/1/0/all/0/1\">Lin Geng Foo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jiamei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Binder_A/0/1/0/all/0/1\">Alexander Binder</a>",
          "description": "We consider the problem of segmenting cell nuclei instances from Hematoxylin\nand Eosin (H&E) stains with dot annotations only. While most recent works focus\non improving the segmentation quality, this is usually insufficient for\ninstance segmentation of cell instances clustered together or with a small\nsize. In this work, we propose a simple two-step post-processing procedure,\nSplit and Expand, that directly improves the conversion of segmentation maps to\ninstances. In the splitting step, we generate fine-grained cell instances from\nthe segmentation map with the guidance of cell-center predictions. For the\nexpansion step, we utilize Layer-wise Relevance Propagation (LRP) explanation\nresults to add small cells that are not captured in the segmentation map.\nAlthough we additionally train an output head to predict cell-centers, the\npost-processing procedure itself is not explicitly trained and is executed at\ninference-time only. A feature re-weighting loss based on LRP is proposed to\nimprove our method even further. We test our procedure on the MoNuSeg and TNBC\ndatasets and show quantitatively and qualitatively that our proposed method\nimproves object-level metrics substantially.",
          "link": "http://arxiv.org/abs/2007.10817",
          "publishedOn": "2021-06-17T01:58:42.082Z",
          "wordCount": 649,
          "title": "Split and Expand: An inference-time improvement for Weakly Supervised Cell Instance Segmentation. (arXiv:2007.10817v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08693",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tsaregorodtsev_A/0/1/0/all/0/1\">Alexander Tsaregorodtsev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belagiannis_V/0/1/0/all/0/1\">Vasileios Belagiannis</a>",
          "description": "We present an automated data augmentation approach for image classification.\nWe formulate the problem as Monte Carlo sampling where our goal is to\napproximate the optimal augmentation policies. We propose a particle filtering\nformulation to find optimal augmentation policies and their schedules during\nmodel training. Our performance measurement procedure relies on a validation\nsubset of our training set, while the policy transition model depends on a\nGaussian prior and an optional augmentation velocity parameter. In our\nexperiments, we show that our formulation for automated augmentation reaches\npromising results on CIFAR-10, CIFAR-100, and ImageNet datasets using the\nstandard network architectures for this problem. By comparing with the related\nwork, we also show that our method reaches a balance between the computational\ncost of policy search and the model performance.",
          "link": "http://arxiv.org/abs/2106.08693",
          "publishedOn": "2021-06-17T01:58:42.075Z",
          "wordCount": 555,
          "title": "ParticleAugment: Sampling-Based Data Augmentation. (arXiv:2106.08693v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2101.12616",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Freeman_I/0/1/0/all/0/1\">Ido Freeman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_K/0/1/0/all/0/1\">Kun Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kummert_A/0/1/0/all/0/1\">Anton Kummert</a>",
          "description": "The rising demand for Active Safety systems in automotive applications\nstresses the need for a reliable short to mid-term trajectory prediction.\nAnticipating the unfolding path of road users, one can act to increase the\noverall safety. In this work, we propose to train artificial neural networks\nfor movement understanding by predicting trajectories in their natural form, as\na function of time. Predicting polynomial coefficients allows us to increased\naccuracy and improve generalisation.",
          "link": "http://arxiv.org/abs/2101.12616",
          "publishedOn": "2021-06-17T01:58:42.068Z",
          "wordCount": 540,
          "title": "Polynomial Trajectory Predictions for Improved Learning Performance. (arXiv:2101.12616v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.01670",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tessera_K/0/1/0/all/0/1\">Kale-ab Tessera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hooker_S/0/1/0/all/0/1\">Sara Hooker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosman_B/0/1/0/all/0/1\">Benjamin Rosman</a>",
          "description": "Training sparse networks to converge to the same performance as dense neural\narchitectures has proven to be elusive. Recent work suggests that\ninitialization is the key. However, while this direction of research has had\nsome success, focusing on initialization alone appears to be inadequate. In\nthis paper, we take a broader view of training sparse networks and consider the\nrole of regularization, optimization, and architecture choices on sparse\nmodels. We propose a simple experimental framework, Same Capacity Sparse vs\nDense Comparison (SC-SDC), that allows for a fair comparison of sparse and\ndense networks. Furthermore, we propose a new measure of gradient flow,\nEffective Gradient Flow (EGF), that better correlates to performance in sparse\nnetworks. Using top-line metrics, SC-SDC and EGF, we show that default choices\nof optimizers, activation functions and regularizers used for dense networks\ncan disadvantage sparse networks. Based upon these findings, we show that\ngradient flow in sparse networks can be improved by reconsidering aspects of\nthe architecture design and the training regime. Our work suggests that\ninitialization is only one piece of the puzzle and taking a wider view of\ntailoring optimization to sparse networks yields promising results.",
          "link": "http://arxiv.org/abs/2102.01670",
          "publishedOn": "2021-06-17T01:58:42.062Z",
          "wordCount": 655,
          "title": "Keep the Gradients Flowing: Using Gradient Flow to Study Sparse Network Optimization. (arXiv:2102.01670v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08605",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ye_Z/0/1/0/all/0/1\">Zihan Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_F/0/1/0/all/0/1\">Fuyuan Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_F/0/1/0/all/0/1\">Fan Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Linyan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1\">Kaizhu Huang</a>",
          "description": "Using generative models to synthesize visual features from semantic\ndistribution is one of the most popular solutions to ZSL image classification\nin recent years. The triplet loss (TL) is popularly used to generate realistic\nvisual distributions from semantics by automatically searching discriminative\nrepresentations. However, the traditional TL cannot search reliable unseen\ndisentangled representations due to the unavailability of unseen classes in\nZSL. To alleviate this drawback, we propose in this work a multi-modal triplet\nloss (MMTL) which utilizes multimodal information to search a disentangled\nrepresentation space. As such, all classes can interplay which can benefit\nlearning disentangled class representations in the searched space. Furthermore,\nwe develop a novel model called Disentangling Class Representation Generative\nAdversarial Network (DCR-GAN) focusing on exploiting the disentangled\nrepresentations in training, feature synthesis, and final recognition stages.\nBenefiting from the disentangled representations, DCR-GAN could fit a more\nrealistic distribution over both seen and unseen features. Extensive\nexperiments show that our proposed model can lead to superior performance to\nthe state-of-the-arts on four benchmark datasets. Our code is available at\nhttps://github.com/FouriYe/DCRGAN-TMM.",
          "link": "http://arxiv.org/abs/2106.08605",
          "publishedOn": "2021-06-17T01:58:42.047Z",
          "wordCount": 616,
          "title": "Disentangling Semantic-to-visual Confusion for Zero-shot Learning. (arXiv:2106.08605v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08706",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Pandey_L/0/1/0/all/0/1\">Laxmi Pandey</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Arif_A/0/1/0/all/0/1\">Ahmed Sabbir Arif</a>",
          "description": "Speech sounds of spoken language are obtained by varying configuration of the\narticulators surrounding the vocal tract. They contain abundant information\nthat can be utilized to better understand the underlying mechanism of human\nspeech production. We propose a novel deep neural network-based learning\nframework that understands acoustic information in the variable-length sequence\nof vocal tract shaping during speech production, captured by real-time magnetic\nresonance imaging (rtMRI), and translate it into text. The proposed framework\ncomprises of spatiotemporal convolutions, a recurrent network, and the\nconnectionist temporal classification loss, trained entirely end-to-end. On the\nUSC-TIMIT corpus, the model achieved a 40.6% PER at sentence-level, much better\ncompared to the existing models. To the best of our knowledge, this is the\nfirst study that demonstrates the recognition of entire spoken sentence based\non an individual's articulatory motions captured by rtMRI video. We also\nperformed an analysis of variations in the geometry of articulation in each\nsub-regions of the vocal tract (i.e., pharyngeal, velar and dorsal, hard\npalate, labial constriction region) with respect to different emotions and\ngenders. Results suggest that each sub-regions distortion is affected by both\nemotion and gender.",
          "link": "http://arxiv.org/abs/2106.08706",
          "publishedOn": "2021-06-17T01:58:42.010Z",
          "wordCount": 656,
          "title": "Silent Speech and Emotion Recognition from Vocal Tract Shape Dynamics in Real-Time MRI. (arXiv:2106.08706v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08650",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Rui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1\">Yang Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zilong Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_P/0/1/0/all/0/1\">Pei Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_G/0/1/0/all/0/1\">Guozhong Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_G/0/1/0/all/0/1\">Gang Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_B/0/1/0/all/0/1\">Bin Fu</a>",
          "description": "This is a short technical report introducing the solution of the Team\nTCParser for Short-video Face Parsing Track of The 3rd Person in Context (PIC)\nWorkshop and Challenge at CVPR 2021. In this paper, we introduce a strong\nbackbone which is cross-window based Shuffle Transformer for presenting\naccurate face parsing representation. To further obtain the finer segmentation\nresults, especially on the edges, we introduce a Feature Alignment Aggregation\n(FAA) module. It can effectively relieve the feature misalignment issue caused\nby multi-resolution feature aggregation. Benefiting from the stronger backbone\nand better feature aggregation, the proposed method achieves 86.9519% score in\nthe Short-video Face Parsing track of the 3rd Person in Context (PIC) Workshop\nand Challenge, ranked the first place.",
          "link": "http://arxiv.org/abs/2106.08650",
          "publishedOn": "2021-06-17T01:58:41.996Z",
          "wordCount": 558,
          "title": "Shuffle Transformer with Feature Alignment for Video Face Parsing. (arXiv:2106.08650v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08617",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jianhua Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1\">Zhanyu Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Liang Wang</a>",
          "description": "In this work, we address the task of referring image segmentation (RIS),\nwhich aims at predicting a segmentation mask for the object described by a\nnatural language expression. Most existing methods focus on establishing\nunidirectional or directional relationships between visual and linguistic\nfeatures to associate two modalities together, while the multi-scale context is\nignored or insufficiently modeled. Multi-scale context is crucial to localize\nand segment those objects that have large scale variations during the\nmulti-modal fusion process. To solve this problem, we propose a simple yet\neffective Cascaded Multi-modal Fusion (CMF) module, which stacks multiple\natrous convolutional layers in parallel and further introduces a cascaded\nbranch to fuse visual and linguistic features. The cascaded branch can\nprogressively integrate multi-scale contextual information and facilitate the\nalignment of two modalities during the multi-modal fusion process. Experimental\nresults on four benchmark datasets demonstrate that our method outperforms most\nstate-of-the-art methods. Code is available at\nhttps://github.com/jianhua2022/CMF-Refseg.",
          "link": "http://arxiv.org/abs/2106.08617",
          "publishedOn": "2021-06-17T01:58:41.990Z",
          "wordCount": 588,
          "title": "CMF: Cascaded Multi-model Fusion for Referring Image Segmentation. (arXiv:2106.08617v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08713",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yueming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xiaolin Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_B/0/1/0/all/0/1\">Bing Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_T/0/1/0/all/0/1\">Tengfei Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1\">Xin Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhihui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1\">Yawei Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_H/0/1/0/all/0/1\">Haojin Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1\">Guoshan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1\">Pengfei Xu</a>",
          "description": "In an autonomous driving system, it is essential to recognize vehicles,\npedestrians and cyclists from images. Besides the high accuracy of the\nprediction, the requirement of real-time running brings new challenges for\nconvolutional network models. In this report, we introduce a real-time method\nto detect the 2D objects from images. We aggregate several popular one-stage\nobject detectors and train the models of variety input strategies\nindependently, to yield better performance for accurate multi-scale detection\nof each category, especially for small objects. For model acceleration, we\nleverage TensorRT to optimize the inference time of our detection pipeline. As\nshown in the leaderboard, our proposed detection framework ranks the 2nd place\nwith 75.00% L1 mAP and 69.72% L2 mAP in the real-time 2D detection track of the\nWaymo Open Dataset Challenges, while our framework achieves the latency of\n45.8ms/frame on an Nvidia Tesla V100 GPU.",
          "link": "http://arxiv.org/abs/2106.08713",
          "publishedOn": "2021-06-17T01:58:41.983Z",
          "wordCount": 597,
          "title": "2nd Place Solution for Waymo Open Dataset Challenge - Real-time 2D Object Detection. (arXiv:2106.08713v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08600",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Quande Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hongzheng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dou_Q/0/1/0/all/0/1\">Qi Dou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heng_P/0/1/0/all/0/1\">Pheng-Ann Heng</a>",
          "description": "Federated learning (FL) has emerged with increasing popularity to collaborate\ndistributed medical institutions for training deep networks. However, despite\nexisting FL algorithms only allow the supervised training setting, most\nhospitals in realistic usually cannot afford the intricate data labeling due to\nabsence of budget or expertise. This paper studies a practical yet challenging\nFL problem, named \\textit{Federated Semi-supervised Learning} (FSSL), which\naims to learn a federated model by jointly utilizing the data from both labeled\nand unlabeled clients (i.e., hospitals). We present a novel approach for this\nproblem, which improves over traditional consistency regularization mechanism\nwith a new inter-client relation matching scheme. The proposed learning scheme\nexplicitly connects the learning across labeled and unlabeled clients by\naligning their extracted disease relationships, thereby mitigating the\ndeficiency of task knowledge at unlabeled clients and promoting discriminative\ninformation from unlabeled samples. We validate our method on two large-scale\nmedical image classification datasets. The effectiveness of our method has been\ndemonstrated with the clear improvements over state-of-the-arts as well as the\nthorough ablation analysis on both tasks\\footnote{Code will be made available\nat \\url{https://github.com/liuquande/FedIRM}}.",
          "link": "http://arxiv.org/abs/2106.08600",
          "publishedOn": "2021-06-17T01:58:41.968Z",
          "wordCount": 617,
          "title": "Federated Semi-supervised Medical Image Classification via Inter-client Relation Matching. (arXiv:2106.08600v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08570",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wan_B/0/1/0/all/0/1\">Boyang Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1\">Wenhui Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1\">Yuming Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1\">Zhiyuan Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_G/0/1/0/all/0/1\">Guanqun Ding</a>",
          "description": "Anomaly detection has attracted considerable search attention. However,\nexisting anomaly detection databases encounter two major problems. Firstly,\nthey are limited in scale. Secondly, training sets contain only video-level\nlabels indicating the existence of an abnormal event during the full video\nwhile lacking annotations of precise time durations. To tackle these problems,\nwe contribute a new Large-scale Anomaly Detection (LAD) database as the\nbenchmark for anomaly detection in video sequences, which is featured in two\naspects. 1) It contains 2000 video sequences including normal and abnormal\nvideo clips with 14 anomaly categories including crash, fire, violence, etc.\nwith large scene varieties, making it the largest anomaly analysis database to\ndate. 2) It provides the annotation data, including video-level labels\n(abnormal/normal video, anomaly type) and frame-level labels (abnormal/normal\nvideo frame) to facilitate anomaly detection. Leveraging the above benefits\nfrom the LAD database, we further formulate anomaly detection as a\nfully-supervised learning problem and propose a multi-task deep neural network\nto solve it. We first obtain the local spatiotemporal contextual feature by\nusing an Inflated 3D convolutional (I3D) network. Then we construct a recurrent\nconvolutional neural network fed the local spatiotemporal contextual feature to\nextract the spatiotemporal contextual feature. With the global spatiotemporal\ncontextual feature, the anomaly type and score can be computed simultaneously\nby a multi-task neural network. Experimental results show that the proposed\nmethod outperforms the state-of-the-art anomaly detection methods on our\ndatabase and other public databases of anomaly detection. Codes are available\nat https://github.com/wanboyang/anomaly_detection_LAD2000.",
          "link": "http://arxiv.org/abs/2106.08570",
          "publishedOn": "2021-06-17T01:58:41.938Z",
          "wordCount": 688,
          "title": "Anomaly Detection in Video Sequences: A Benchmark and Computational Model. (arXiv:2106.08570v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08575",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nunn_E/0/1/0/all/0/1\">Eric J. Nunn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khadivi_P/0/1/0/all/0/1\">Pejman Khadivi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samavi_S/0/1/0/all/0/1\">Shadrokh Samavi</a>",
          "description": "Generative adversarial networks or GANs are a type of generative modeling\nframework. GANs involve a pair of neural networks engaged in a competition in\niteratively creating fake data, indistinguishable from the real data. One\nnotable application of GANs is developing fake human faces, also known as \"deep\nfakes,\" due to the deep learning algorithms at the core of the GAN framework.\nMeasuring the quality of the generated images is inherently subjective but\nattempts to objectify quality using standardized metrics have been made. One\nexample of objective metrics is the Frechet Inception Distance (FID), which\nmeasures the difference between distributions of feature vectors for two\nseparate datasets of images. There are situations that images with low\nperceptual qualities are not assigned appropriate FID scores. We propose to\nimprove the robustness of the evaluation process by integrating lower-level\nfeatures to cover a wider array of visual defects. Our proposed method\nintegrates three levels of feature abstractions to evaluate the quality of\ngenerated images. Experimental evaluations show better performance of the\nproposed method for distorted images.",
          "link": "http://arxiv.org/abs/2106.08575",
          "publishedOn": "2021-06-17T01:58:41.929Z",
          "wordCount": 612,
          "title": "Compound Frechet Inception Distance for Quality Assessment of GAN Created Images. (arXiv:2106.08575v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08599",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moon_H/0/1/0/all/0/1\">Hankyu Moon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_H/0/1/0/all/0/1\">Heng Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Didari_S/0/1/0/all/0/1\">Sima Didari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woo_J/0/1/0/all/0/1\">Jae Oh Woo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bangert_P/0/1/0/all/0/1\">Patrick Bangert</a>",
          "description": "We demonstrate that frequently appearing objects can be discovered by\ntraining randomly sampled patches from a small number of images (100 to 200) by\nself-supervision. Key to this approach is the pattern space, a latent space of\npatterns that represents all possible sub-images of the given image data. The\ndistance structure in the pattern space captures the co-occurrence of patterns\ndue to the frequent objects. The pattern space embedding is learned by\nminimizing the contrastive loss between randomly generated adjacent patches. To\nprevent the embedding from learning the background, we modulate the contrastive\nloss by color-based object saliency and background dissimilarity. The learned\ndistance structure serves as object memory, and the frequent objects are simply\ndiscovered by clustering the pattern vectors from the random patches sampled\nfor inference. Our image representation based on image patches naturally\nhandles the position and scale invariance property that is crucial to\nmulti-object discovery. The method has been proven surprisingly effective, and\nsuccessfully applied to finding multiple human faces and bodies from natural\nimages.",
          "link": "http://arxiv.org/abs/2106.08599",
          "publishedOn": "2021-06-17T01:58:41.922Z",
          "wordCount": 610,
          "title": "PatchNet: Unsupervised Object Discovery based on Patch Embedding. (arXiv:2106.08599v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08613",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Park_C/0/1/0/all/0/1\">Chaewon Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_M/0/1/0/all/0/1\">MyeongAh Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1\">Minhyeok Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sangyoun Lee</a>",
          "description": "Video anomaly detection has gained significant attention due to the\nincreasing requirements of automatic monitoring for surveillance videos.\nEspecially, the prediction based approach is one of the most studied methods to\ndetect anomalies by predicting frames that include abnormal events in the test\nset after learning with the normal frames of the training set. However, a lot\nof prediction networks are computationally expensive owing to the use of\npre-trained optical flow networks, or fail to detect abnormal situations\nbecause of their strong generative ability to predict even the anomalies. To\naddress these shortcomings, we propose spatial rotation transformation (SRT)\nand temporal mixing transformation (TMT) to generate irregular patch cuboids\nwithin normal frame cuboids in order to enhance the learning of normal\nfeatures. Additionally, the proposed patch transformation is used only during\nthe training phase, allowing our model to detect abnormal frames at fast speed\nduring inference. Our model is evaluated on three anomaly detection benchmarks,\nachieving competitive accuracy and surpassing all the previous works in terms\nof speed.",
          "link": "http://arxiv.org/abs/2106.08613",
          "publishedOn": "2021-06-17T01:58:41.911Z",
          "wordCount": 600,
          "title": "FastAno: Fast Anomaly Detection via Spatio-temporal Patch Transformation. (arXiv:2106.08613v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08590",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1\">Zhipeng Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaobing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1\">Shijian Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_S/0/1/0/all/0/1\">Shuai Yi</a>",
          "description": "Deep learning-based multi-source unsupervised domain adaptation (MUDA) has\nbeen actively studied in recent years. Compared with single-source unsupervised\ndomain adaptation (SUDA), domain shift in MUDA exists not only between the\nsource and target domains but also among multiple source domains. Most existing\nMUDA algorithms focus on extracting domain-invariant representations among all\ndomains whereas the task-specific decision boundaries among classes are largely\nneglected. In this paper, we propose an end-to-end trainable network that\nexploits domain Consistency Regularization for unsupervised Multi-source domain\nAdaptive classification (CRMA). CRMA aligns not only the distributions of each\npair of source and target domains but also that of all domains. For each pair\nof source and target domains, we employ an intra-domain consistency to\nregularize a pair of domain-specific classifiers to achieve intra-domain\nalignment. In addition, we design an inter-domain consistency that targets\njoint inter-domain alignment among all domains. To address different\nsimilarities between multiple source domains and the target domain, we design\nan authorization strategy that assigns different authorities to domain-specific\nclassifiers adaptively for optimal pseudo label prediction and self-training.\nExtensive experiments show that CRMA tackles unsupervised domain adaptation\neffectively under a multi-source setup and achieves superior adaptation\nconsistently across multiple MUDA datasets.",
          "link": "http://arxiv.org/abs/2106.08590",
          "publishedOn": "2021-06-17T01:58:41.895Z",
          "wordCount": 629,
          "title": "Domain Consistency Regularization for Unsupervised Multi-source Domain Adaptive Classification. (arXiv:2106.08590v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08512",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yueyu Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1\">Wenhan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Haofeng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiaying Liu</a>",
          "description": "Visual analytics have played an increasingly critical role in the Internet of\nThings, where massive visual signals have to be compressed and fed into\nmachines. But facing such big data and constrained bandwidth capacity, existing\nimage/video compression methods lead to very low-quality representations, while\nexisting feature compression techniques fail to support diversified visual\nanalytics applications/tasks with low-bit-rate representations. In this paper,\nwe raise and study the novel problem of supporting multiple machine vision\nanalytics tasks with the compressed visual representation, namely, the\ninformation compression problem in analytics taxonomy. By utilizing the\nintrinsic transferability among different tasks, our framework successfully\nconstructs compact and expressive representations at low bit-rates to support a\ndiversified set of machine vision tasks, including both high-level\nsemantic-related tasks and mid-level geometry analytic tasks. In order to\nimpose compactness in the representations, we propose a codebook-based\nhyperprior, which helps map the representation into a low-dimensional manifold.\nAs it well fits the signal structure of the deep visual feature, it facilitates\nmore accurate entropy estimation, and results in higher compression efficiency.\nWith the proposed framework and the codebook-based hyperprior, we further\ninvestigate the relationship of different task features owning different levels\nof abstraction granularity. Experimental results demonstrate that with the\nproposed scheme, a set of diversified tasks can be supported at a significantly\nlower bit-rate, compared with existing compression schemes.",
          "link": "http://arxiv.org/abs/2106.08512",
          "publishedOn": "2021-06-17T01:58:41.871Z",
          "wordCount": 653,
          "title": "Revisit Visual Representation in Analytics Taxonomy: A Compression Perspective. (arXiv:2106.08512v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08557",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Matsuo_H/0/1/0/all/0/1\">Hidetoshi Matsuo</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Nishio_M/0/1/0/all/0/1\">Mizuho Nishio</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Nogami_M/0/1/0/all/0/1\">Munenobu Nogami</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_F/0/1/0/all/0/1\">Feibi Zeng</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Kurimoto_T/0/1/0/all/0/1\">Takako Kurimoto</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Kaushik_S/0/1/0/all/0/1\">Sandeep Kaushik</a> (3), <a href=\"http://arxiv.org/find/cs/1/au:+Wiesinger_F/0/1/0/all/0/1\">Florian Wiesinger</a> (3), <a href=\"http://arxiv.org/find/cs/1/au:+Kono_A/0/1/0/all/0/1\">Atsushi K Kono</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Murakami_T/0/1/0/all/0/1\">Takamichi Murakami</a> (1) ((1) Department of Radiology, Kobe University Graduate School of Medicine, Kobe, Japan, (2) GE Healthcare, Hino, Japan and (3) GE Healthcare, Munich, Germany)",
          "description": "The integrated positron emission tomography/magnetic resonance imaging\n(PET/MRI) scanner facilitates the simultaneous acquisition of metabolic\ninformation via PET and morphological information with high soft-tissue\ncontrast using MRI. Although PET/MRI facilitates the capture of high-accuracy\nfusion images, its major drawback can be attributed to the difficulty\nencountered when performing attenuation correction, which is necessary for\nquantitative PET evaluation. The combined PET/MRI scanning requires the\ngeneration of attenuation-correction maps from MRI owing to no direct\nrelationship between the gamma-ray attenuation information and MRIs. While\nMRI-based bone-tissue segmentation can be readily performed for the head and\npelvis regions, the realization of accurate bone segmentation via chest CT\ngeneration remains a challenging task. This can be attributed to the\nrespiratory and cardiac motions occurring in the chest as well as its\nanatomically complicated structure and relatively thin bone cortex. This paper\npresents a means to minimise the anatomical structural changes without human\nannotation by adding structural constraints using a modality-independent\nneighbourhood descriptor (MIND) to a generative adversarial network (GAN) that\ncan transform unpaired images. The results obtained in this study revealed the\nproposed U-GAT-IT + MIND approach to outperform all other competing approaches.\nThe findings of this study hint towards possibility of synthesising clinically\nacceptable CT images from chest MRI without human annotation, thereby\nminimising the changes in the anatomical structure.",
          "link": "http://arxiv.org/abs/2106.08557",
          "publishedOn": "2021-06-17T01:58:41.862Z",
          "wordCount": 703,
          "title": "Unsupervised-learning-based method for chest MRI-CT transformation using structure constrained unsupervised generative attention networks. (arXiv:2106.08557v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08513",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kalayeh_M/0/1/0/all/0/1\">Mahdi M. Kalayeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamath_N/0/1/0/all/0/1\">Nagendra Kamath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lingyi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandrashekar_A/0/1/0/all/0/1\">Ashok Chandrashekar</a>",
          "description": "The abundance and ease of utilizing sound, along with the fact that auditory\nclues reveal so much about what happens in the scene, make the audio-visual\nspace a perfectly intuitive choice for self-supervised representation learning.\nHowever, the current literature suggests that training on \\textit{uncurated}\ndata yields considerably poorer representations compared to the\n\\textit{curated} alternatives collected in supervised manner, and the gap only\nnarrows when the volume of data significantly increases. Furthermore, the\nquality of learned representations is known to be heavily influenced by the\nsize and taxonomy of the curated datasets used for self-supervised training.\nThis begs the question of whether we are celebrating too early on catching up\nwith supervised learning when our self-supervised efforts still rely almost\nexclusively on curated data. In this paper, we study the efficacy of learning\nfrom Movies and TV Shows as forms of uncurated data for audio-visual\nself-supervised learning. We demonstrate that a simple model based on\ncontrastive learning, trained on a collection of movies and TV shows, not only\ndramatically outperforms more complex methods which are trained on orders of\nmagnitude larger uncurated datasets, but also performs very competitively with\nthe state-of-the-art that learns from large-scale curated data. We identify\nthat audiovisual patterns like the appearance of the main character or\nprominent scenes and mise-en-sc\\`ene which frequently occur through the whole\nduration of a movie, lead to an overabundance of easy negative instances in the\ncontrastive learning formulation. Capitalizing on such observation, we propose\na hierarchical sampling policy, which despite its simplicity, effectively\nimproves the performance, particularly when learning from TV shows which\nnaturally face less semantic diversity.",
          "link": "http://arxiv.org/abs/2106.08513",
          "publishedOn": "2021-06-17T01:58:41.855Z",
          "wordCount": 710,
          "title": "Watching Too Much Television is Good: Self-Supervised Audio-Visual Representation Learning from Movies and TV Shows. (arXiv:2106.08513v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08445",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dietrich_M/0/1/0/all/0/1\">Maximilian Dietrich</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Seidlitz_S/0/1/0/all/0/1\">Silvia Seidlitz</a> (2, 3), <a href=\"http://arxiv.org/find/cs/1/au:+Schreck_N/0/1/0/all/0/1\">Nicholas Schreck</a> (4), <a href=\"http://arxiv.org/find/cs/1/au:+Wiesenfarth_M/0/1/0/all/0/1\">Manuel Wiesenfarth</a> (4), <a href=\"http://arxiv.org/find/cs/1/au:+Godau_P/0/1/0/all/0/1\">Patrick Godau</a> (2, 3), <a href=\"http://arxiv.org/find/cs/1/au:+Tizabi_M/0/1/0/all/0/1\">Minu Tizabi</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Sellner_J/0/1/0/all/0/1\">Jan Sellner</a> (2, 3), <a href=\"http://arxiv.org/find/cs/1/au:+Marx_S/0/1/0/all/0/1\">Sebastian Marx</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Knodler_S/0/1/0/all/0/1\">Samuel Kn&#xf6;dler</a> (5), <a href=\"http://arxiv.org/find/cs/1/au:+Allers_M/0/1/0/all/0/1\">Michael M. Allers</a> (5), <a href=\"http://arxiv.org/find/cs/1/au:+Ayala_L/0/1/0/all/0/1\">Leonardo Ayala</a> (2, 7), <a href=\"http://arxiv.org/find/cs/1/au:+Schmidt_K/0/1/0/all/0/1\">Karsten Schmidt</a> (8), <a href=\"http://arxiv.org/find/cs/1/au:+Brenner_T/0/1/0/all/0/1\">Thorsten Brenner</a> (8), <a href=\"http://arxiv.org/find/cs/1/au:+Studier_Fischer_A/0/1/0/all/0/1\">Alexander Studier-Fischer</a> (5), <a href=\"http://arxiv.org/find/cs/1/au:+Nickel_F/0/1/0/all/0/1\">Felix Nickel</a> (5), <a href=\"http://arxiv.org/find/cs/1/au:+Muller_Stich_B/0/1/0/all/0/1\">Beat P. M&#xfc;ller-Stich</a> (5), <a href=\"http://arxiv.org/find/cs/1/au:+Kopp_Schneider_A/0/1/0/all/0/1\">Annette Kopp-Schneider</a> (4), <a href=\"http://arxiv.org/find/cs/1/au:+Weigand_M/0/1/0/all/0/1\">Markus A. Weigand</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Maier_Hein_L/0/1/0/all/0/1\">Lena Maier-Hein</a> (2, 6, 7) ((1) Department of Anesthesiology, Heidelberg University Hospital, Heidelberg, Germany, (2) Division of Computer Assisted Medical Interventions, German Cancer Research Center (DKFZ), Heidelberg, Germany, (3) HIDSS4Health - Helmholtz Information and Data Science School for Health, Karlsruhe/Heidelberg, Germany (4) Division of Biostatistics, German Cancer Research Center (DKFZ), Heidelberg, Germany, (5) Department of General, Visceral, and Transplantation Surgery, Heidelberg University Hospital, Heidelberg, Germany, (6) Faculty of Mathematics and Computer Science, Heidelberg University, Heidelberg, Germany, (7) Medical Faculty, Heidelberg University, Heidelberg, Germany, (8) Department of Anesthesiology and Intensive Care Medicine, University Hospital Essen, University Duisburg-Essen, Essen, Germany)",
          "description": "Sepsis is a leading cause of mortality and critical illness worldwide. While\nrobust biomarkers for early diagnosis are still missing, recent work indicates\nthat hyperspectral imaging (HSI) has the potential to overcome this bottleneck\nby monitoring microcirculatory alterations. Automated machine learning-based\ndiagnosis of sepsis based on HSI data, however, has not been explored to date.\nGiven this gap in the literature, we leveraged an existing data set to (1)\ninvestigate whether HSI-based automated diagnosis of sepsis is possible and (2)\nput forth a list of possible confounders relevant for HSI-based tissue\nclassification. While we were able to classify sepsis with an accuracy of over\n$98\\,\\%$ using the existing data, our research also revealed several subject-,\ntherapy- and imaging-related confounders that may lead to an overestimation of\nalgorithm performance when not balanced across the patient groups. We conclude\nthat further prospective studies, carefully designed with respect to these\nconfounders, are necessary to confirm the preliminary results obtained in this\nstudy.",
          "link": "http://arxiv.org/abs/2106.08445",
          "publishedOn": "2021-06-17T01:58:41.843Z",
          "wordCount": 770,
          "title": "Machine learning-based analysis of hyperspectral images for automated sepsis diagnosis. (arXiv:2106.08445v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08486",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chuah_W/0/1/0/all/0/1\">WeiQin Chuah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tennakoon_R/0/1/0/all/0/1\">Ruwan Tennakoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bab_Hadiashar_A/0/1/0/all/0/1\">Alireza Bab-Hadiashar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suter_D/0/1/0/all/0/1\">David Suter</a>",
          "description": "Learning-based stereo matching and depth estimation networks currently excel\non public benchmarks with impressive results. However, state-of-the-art\nnetworks often fail to generalize from synthetic imagery to more challenging\nreal data domains. This paper is an attempt to uncover hidden secrets of\nachieving domain robustness and in particular, discovering the important\ningredients of generalization success of stereo matching networks by analyzing\nthe effect of synthetic image learning on real data performance. We provide\nevidence that demonstrates that learning of features in the synthetic domain by\na stereo matching network is heavily influenced by two \"shortcuts\" presented in\nthe synthetic data: (1) identical local statistics (RGB colour features)\nbetween matching pixels in the synthetic stereo images and (2) lack of realism\nin synthetic textures on 3D objects simulated in game engines. We will show\nthat by removing such shortcuts, we can achieve domain robustness in the\nstate-of-the-art stereo matching frameworks and produce a remarkable\nperformance on multiple realistic datasets, despite the fact that the networks\nwere trained on synthetic data, only. Our experimental results point to the\nfact that eliminating shortcuts from the synthetic data is key to achieve\ndomain-invariant generalization between synthetic and real data domains.",
          "link": "http://arxiv.org/abs/2106.08486",
          "publishedOn": "2021-06-17T01:58:41.823Z",
          "wordCount": 640,
          "title": "Achieving Domain Robustness in Stereo Matching Networks by Removing Shortcut Learning. (arXiv:2106.08486v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08573",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Ying-Tian Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yuan-Chen Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yi-Xiao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Song-Hai Zhang</a>",
          "description": "In this paper, we present a novel implicit glyph shape representation, which\nmodels glyphs as shape primitives enclosed by quadratic curves, and naturally\nenables generating glyph images at arbitrary high resolutions. Experiments on\nfont reconstruction and interpolation tasks verified that this structured\nimplicit representation is suitable for describing both structure and style\nfeatures of glyphs. Furthermore, based on the proposed representation, we\ndesign a simple yet effective disentangled network for the challenging one-shot\nfont style transfer problem, and achieve the best results comparing to\nstate-of-the-art alternatives in both quantitative and qualitative comparisons.\nBenefit from this representation, our generated glyphs have the potential to be\nconverted to vector fonts through post-processing, reducing the gap between\nrasterized images and vector graphics. We hope this work can provide a powerful\ntool for 2D shape analysis and synthesis, and inspire further exploitation in\nimplicit representations for 2D shape modeling.",
          "link": "http://arxiv.org/abs/2106.08573",
          "publishedOn": "2021-06-17T01:58:41.817Z",
          "wordCount": 570,
          "title": "Learning Implicit Glyph Shape Representation. (arXiv:2106.08573v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08596",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huynh_V/0/1/0/all/0/1\">VanThong Huynh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_G/0/1/0/all/0/1\">Guee-Sang Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hyung-Jeong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Soo-Huyng Kim</a>",
          "description": "This paper presents an approach for Evoked Expressions from Videos (EEV)\nchallenge, which aims to predict evoked facial expressions from video. We take\nadvantage of pre-trained models on large-scale datasets in computer vision and\naudio signals to extract the deep representation of timestamps in the video. A\ntemporal convolution network, rather than an RNN like architecture, is used to\nexplore temporal relationships due to its advantage in memory consumption and\nparallelism. Furthermore, to address the missing annotations of some\ntimestamps, positional encoding is employed to ensure continuity of input data\nwhen discarding these timestamps during training. We achieved state-of-the-art\nresults on the EEV challenge with a Pearson correlation coefficient of 0.05477,\nthe first ranked performance in the EEV 2021 challenge.",
          "link": "http://arxiv.org/abs/2106.08596",
          "publishedOn": "2021-06-17T01:58:41.801Z",
          "wordCount": 578,
          "title": "Temporal Convolution Networks with Positional Encoding for Evoked Expression Estimation. (arXiv:2106.08596v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08462",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Voleti_V/0/1/0/all/0/1\">Vikram Voleti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Finlay_C/0/1/0/all/0/1\">Chris Finlay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oberman_A/0/1/0/all/0/1\">Adam Oberman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pal_C/0/1/0/all/0/1\">Christopher Pal</a>",
          "description": "Recent work has shown that Neural Ordinary Differential Equations (ODEs) can\nserve as generative models of images using the perspective of Continuous\nNormalizing Flows (CNFs). Such models offer exact likelihood calculation, and\ninvertible generation/density estimation. In this work we introduce a\nMulti-Resolution variant of such models (MRCNF), by characterizing the\nconditional distribution over the additional information required to generate a\nfine image that is consistent with the coarse image. We introduce a\ntransformation between resolutions that allows for no change in the log\nlikelihood. We show that this approach yields comparable likelihood values for\nvarious image datasets, with improved performance at higher resolutions, with\nfewer parameters, using only 1 GPU.",
          "link": "http://arxiv.org/abs/2106.08462",
          "publishedOn": "2021-06-17T01:58:41.795Z",
          "wordCount": 552,
          "title": "Multi-Resolution Continuous Normalizing Flows. (arXiv:2106.08462v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08543",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Woo_S/0/1/0/all/0/1\">Sangmin Woo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noh_J/0/1/0/all/0/1\">Junhyug Noh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1\">Kangil Kim</a>",
          "description": "In this work, we seek new insights into the underlying challenges of the\nScene Graph Generation (SGG) task. Quantitative and qualitative analysis of the\nVisual Genome dataset implies -- 1) Ambiguity: even if inter-object\nrelationship contains the same object (or predicate), they may not be visually\nor semantically similar, 2) Asymmetry: despite the nature of the relationship\nthat embodied the direction, it was not well addressed in previous studies, and\n3) Higher-order contexts: leveraging the identities of certain graph elements\ncan help to generate accurate scene graphs. Motivated by the analysis, we\ndesign a novel SGG framework, Local-to-Global Interaction Networks (LOGIN).\nLocally, interactions extract the essence between three instances - subject,\nobject, and background - while baking direction awareness into the network by\nconstraining the input order. Globally, interactions encode the contexts\nbetween every graph components -- nodes and edges. Also we introduce Attract &\nRepel loss which finely adjusts predicate embeddings. Our framework enables\npredicting the scene graph in a local-to-global manner by design, leveraging\nthe possible complementariness. To quantify how much LOGIN is aware of\nrelational direction, we propose a new diagnostic task called Bidirectional\nRelationship Classification (BRC). We see that LOGIN can successfully\ndistinguish relational direction than existing methods (in BRC task) while\nshowing state-of-the-art results on the Visual Genome benchmark (in SGG task).",
          "link": "http://arxiv.org/abs/2106.08543",
          "publishedOn": "2021-06-17T01:58:41.788Z",
          "wordCount": 675,
          "title": "Tackling the Challenges in Scene Graph Generation with Local-to-Global Interactions. (arXiv:2106.08543v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08499",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Junior_C/0/1/0/all/0/1\">Celso A. M. Lopes Junior</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Junior_R/0/1/0/all/0/1\">Ricardo B. das Neves Junior</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bezerra_B/0/1/0/all/0/1\">Byron L. D. Bezerra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Toselli_A/0/1/0/all/0/1\">Alejandro H. Toselli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Impedovo_D/0/1/0/all/0/1\">Donato Impedovo</a>",
          "description": "This paper describes the short-term competition on Components Segmentation\nTask of Document Photos that was prepared in the context of the 16th\nInternational Conference on Document Analysis and Recognition (ICDAR 2021).\nThis competition aims to bring together researchers working on the filed of\nidentification document image processing and provides them a suitable benchmark\nto compare their techniques on the component segmentation task of document\nimages. Three challenge tasks were proposed entailing different segmentation\nassignments to be performed on a provided dataset. The collected data are from\nseveral types of Brazilian ID documents, whose personal information was\nconveniently replaced. There were 16 participants whose results obtained for\nsome or all the three tasks show different rates for the adopted metrics, like\nDice Similarity Coefficient ranging from 0.06 to 0.99. Different Deep Learning\nmodels were applied by the entrants with diverse strategies to achieve the best\nresults in each of the tasks. Obtained results show that the current applied\nmethods for solving one of the proposed tasks (document boundary detection) are\nalready well stablished. However, for the other two challenge tasks (text zone\nand handwritten sign detection) research and development of more robust\napproaches are still required to achieve acceptable results.",
          "link": "http://arxiv.org/abs/2106.08499",
          "publishedOn": "2021-06-17T01:58:41.771Z",
          "wordCount": 659,
          "title": "ICDAR 2021 Competition on Components Segmentation Task of Document Photos. (arXiv:2106.08499v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08523",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chaofan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiaoshan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Changsheng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuhui Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1\">Zhe Ma</a>",
          "description": "Recently, the transductive graph-based methods have achieved great success in\nthe few-shot classification task. However, most existing methods ignore\nexploring the class-level knowledge that can be easily learned by humans from\njust a handful of samples. In this paper, we propose an Explicit Class\nKnowledge Propagation Network (ECKPN), which is composed of the comparison,\nsqueeze and calibration modules, to address this problem. Specifically, we\nfirst employ the comparison module to explore the pairwise sample relations to\nlearn rich sample representations in the instance-level graph. Then, we squeeze\nthe instance-level graph to generate the class-level graph, which can help\nobtain the class-level visual knowledge and facilitate modeling the relations\nof different classes. Next, the calibration module is adopted to characterize\nthe relations of the classes explicitly to obtain the more discriminative\nclass-level knowledge representations. Finally, we combine the class-level\nknowledge with the instance-level sample representations to guide the inference\nof the query samples. We conduct extensive experiments on four few-shot\nclassification benchmarks, and the experimental results show that the proposed\nECKPN significantly outperforms the state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2106.08523",
          "publishedOn": "2021-06-17T01:58:41.765Z",
          "wordCount": 619,
          "title": "ECKPN: Explicit Class Knowledge Propagation Network for Transductive Few-shot Learning. (arXiv:2106.08523v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08417",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ngiam_J/0/1/0/all/0/1\">Jiquan Ngiam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caine_B/0/1/0/all/0/1\">Benjamin Caine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasudevan_V/0/1/0/all/0/1\">Vijay Vasudevan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhengdong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiang_H/0/1/0/all/0/1\">Hao-Tien Lewis Chiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_J/0/1/0/all/0/1\">Jeffrey Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roelofs_R/0/1/0/all/0/1\">Rebecca Roelofs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bewley_A/0/1/0/all/0/1\">Alex Bewley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chenxi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venugopal_A/0/1/0/all/0/1\">Ashish Venugopal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weiss_D/0/1/0/all/0/1\">David Weiss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sapp_B/0/1/0/all/0/1\">Ben Sapp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhifeng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shlens_J/0/1/0/all/0/1\">Jonathon Shlens</a>",
          "description": "Predicting the future motion of multiple agents is necessary for planning in\ndynamic environments. This task is challenging for autonomous driving since\nagents (e.g., vehicles and pedestrians) and their associated behaviors may be\ndiverse and influence each other. Most prior work has focused on first\npredicting independent futures for each agent based on all past motion, and\nthen planning against these independent predictions. However, planning against\nfixed predictions can suffer from the inability to represent the future\ninteraction possibilities between different agents, leading to sub-optimal\nplanning. In this work, we formulate a model for predicting the behavior of all\nagents jointly in real-world driving environments in a unified manner. Inspired\nby recent language modeling approaches, we use a masking strategy as the query\nto our model, enabling one to invoke a single model to predict agent behavior\nin many ways, such as potentially conditioned on the goal or full future\ntrajectory of the autonomous vehicle or the behavior of other agents in the\nenvironment. Our model architecture fuses heterogeneous world state in a\nunified Transformer architecture by employing attention across road elements,\nagent interactions and time steps. We evaluate our approach on autonomous\ndriving datasets for behavior prediction, and achieve state-of-the-art\nperformance. Our work demonstrates that formulating the problem of behavior\nprediction in a unified architecture with a masking strategy may allow us to\nhave a single model that can perform multiple motion prediction and planning\nrelated tasks effectively.",
          "link": "http://arxiv.org/abs/2106.08417",
          "publishedOn": "2021-06-17T01:58:41.759Z",
          "wordCount": 703,
          "title": "Scene Transformer: A unified multi-task model for behavior prediction and planning. (arXiv:2106.08417v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08408",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_M/0/1/0/all/0/1\">Mingmin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Olsen_P/0/1/0/all/0/1\">Peder A. Olsen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandra_R/0/1/0/all/0/1\">Ranveer Chandra</a>",
          "description": "This paper presents a neural-network-based solution to recover pixels\noccluded by clouds in satellite images. We leverage radio frequency (RF)\nsignals in the ultra/super-high frequency band that penetrate clouds to help\nreconstruct the occluded regions in multispectral images. We introduce the\nfirst multi-modal multi-temporal cloud removal model. Our model uses publicly\navailable satellite observations and produces daily cloud-free images.\nExperimental results show that our system significantly outperforms baselines\nby 8dB in PSNR. We also demonstrate use cases of our system in digital\nagriculture, flood monitoring, and wildfire detection. We will release the\nprocessed dataset to facilitate future research.",
          "link": "http://arxiv.org/abs/2106.08408",
          "publishedOn": "2021-06-17T01:58:41.752Z",
          "wordCount": 522,
          "title": "Seeing Through Clouds in Satellite Images. (arXiv:2106.08408v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08493",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Junshen Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_E/0/1/0/all/0/1\">Eric Z. Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Terrence Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1\">Shanhui Sun</a>",
          "description": "Image registration plays an important role in medical image analysis.\nConventional optimization based methods provide an accurate estimation due to\nthe iterative process at the cost of expensive computation. Deep learning\nmethods such as learn-to-map are much faster but either iterative or\ncoarse-to-fine approach is required to improve accuracy for handling large\nmotions. In this work, we proposed to learn a registration optimizer via a\nmulti-scale neural ODE model. The inference consists of iterative gradient\nupdates similar to a conventional gradient descent optimizer but in a much\nfaster way, because the neural ODE learns from the training data to adapt the\ngradient efficiently at each iteration. Furthermore, we proposed to learn a\nmodal-independent similarity metric to address image appearance variations\nacross different image contrasts. We performed evaluations through extensive\nexperiments in the context of multi-contrast 3D MR images from both public and\nprivate data sources and demonstrate the superior performance of our proposed\nmethods.",
          "link": "http://arxiv.org/abs/2106.08493",
          "publishedOn": "2021-06-17T01:58:41.726Z",
          "wordCount": 587,
          "title": "Multi-scale Neural ODEs for 3D Medical Image Registration. (arXiv:2106.08493v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08497",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">Ruinian Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chu_F/0/1/0/all/0/1\">Fu-Jen Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vela_P/0/1/0/all/0/1\">Patricio A. Vela</a>",
          "description": "Contemporary grasp detection approaches employ deep learning to achieve\nrobustness to sensor and object model uncertainty. The two dominant approaches\ndesign either grasp-quality scoring or anchor-based grasp recognition networks.\nThis paper presents a different approach to grasp detection by treating it as\nkeypoint detection. The deep network detects each grasp candidate as a pair of\nkeypoints, convertible to the grasp representation g = {x, y, w, {\\theta}}^T,\nrather than a triplet or quartet of corner points. Decreasing the detection\ndifficulty by grouping keypoints into pairs boosts performance. To further\npromote dependencies between keypoints, the general non-local module is\nincorporated into the proposed learning framework. A final filtering strategy\nbased on discrete and continuous orientation prediction removes false\ncorrespondences and further improves grasp detection performance. GKNet, the\napproach presented here, achieves the best balance of accuracy and speed on the\nCornell and the abridged Jacquard dataset (96.9% and 98.39% at 41.67 and 23.26\nfps). Follow-up experiments on a manipulator evaluate GKNet using 4 types of\ngrasping experiments reflecting different nuisance sources: static grasping,\ndynamic grasping, grasping at varied camera angles, and bin picking. GKNet\noutperforms reference baselines in static and dynamic grasping experiments\nwhile showing robustness to varied camera viewpoints and bin picking\nexperiments. The results confirm the hypothesis that grasp keypoints are an\neffective output representation for deep grasp networks that provide robustness\nto expected nuisance factors.",
          "link": "http://arxiv.org/abs/2106.08497",
          "publishedOn": "2021-06-17T01:58:41.720Z",
          "wordCount": 662,
          "title": "GKNet: grasp keypoint network for grasp candidates detection. (arXiv:2106.08497v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08372",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ngo_A/0/1/0/all/0/1\">Anthony Ngo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bauer_M/0/1/0/all/0/1\">Max Paul Bauer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Resch_M/0/1/0/all/0/1\">Michael Resch</a>",
          "description": "With the increasing safety validation requirements for the release of a\nself-driving car, alternative approaches, such as simulation-based testing, are\nemerging in addition to conventional real-world testing. In order to rely on\nvirtual tests the employed sensor models have to be validated. For this reason,\nit is necessary to quantify the discrepancy between simulation and reality in\norder to determine whether a certain fidelity is sufficient for a desired\nintended use. There exists no sound method to measure this\nsimulation-to-reality gap of radar perception for autonomous driving. We\naddress this problem by introducing a multi-layered evaluation approach, which\nconsists of a combination of an explicit and an implicit sensor model\nevaluation. The former directly evaluates the realism of the synthetically\ngenerated sensor data, while the latter refers to an evaluation of a downstream\ntarget application. In order to demonstrate the method, we evaluated the\nfidelity of three typical radar model types (ideal, data-driven, ray\ntracing-based) and their applicability for virtually testing radar-based\nmulti-object tracking. We have shown the effectiveness of the proposed approach\nin terms of providing an in-depth sensor model assessment that renders existing\ndisparities visible and enables a realistic estimation of the overall model\nfidelity across different scenarios.",
          "link": "http://arxiv.org/abs/2106.08372",
          "publishedOn": "2021-06-17T01:58:41.714Z",
          "wordCount": 663,
          "title": "A Multi-Layered Approach for Measuring the Simulation-to-Reality Gap of Radar Perception for Autonomous Driving. (arXiv:2106.08372v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08366",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tamboli_D/0/1/0/all/0/1\">Dipesh Tamboli</a>",
          "description": "This document summarizes different visual explanations methods such as CAM,\nGrad-CAM, Localization using Multiple Instance Learning - Saliency-based\nmethods, Saliency-driven Class-Impressions, Muting pixels in input image -\nAdversarial methods and Activation visualization, Convolution filter\nvisualization - Feature-based methods. We have also shown the results produced\nby different methods and a comparison between CAM, GradCAM, and Guided\nBackpropagation.",
          "link": "http://arxiv.org/abs/2106.08366",
          "publishedOn": "2021-06-17T01:58:41.677Z",
          "wordCount": 482,
          "title": "Explaining decision of model from its prediction. (arXiv:2106.08366v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08382",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sagar_A/0/1/0/all/0/1\">Abhinav Sagar</a>",
          "description": "Attention mechanism of late has been quite popular in the computer vision\ncommunity. A lot of work has been done to improve the performance of the\nnetwork, although almost always it results in increased computational\ncomplexity. In this paper, we propose a new attention module that not only\nachieves the best performance but also has lesser parameters compared to most\nexisting models. Our attention module can easily be integrated with other\nconvolutional neural networks because of its lightweight nature. The proposed\nnetwork named Dual Multi Scale Attention Network (DMSANet) is comprised of two\nparts: the first part is used to extract features at various scales and\naggregate them, the second part uses spatial and channel attention modules in\nparallel to adaptively integrate local features with their global dependencies.\nWe benchmark our network performance for Image Classification on ImageNet\ndataset, Object Detection and Instance Segmentation both on MS COCO dataset.",
          "link": "http://arxiv.org/abs/2106.08382",
          "publishedOn": "2021-06-17T01:58:41.661Z",
          "wordCount": 583,
          "title": "DMSANet: Dual Multi Scale Attention Network. (arXiv:2106.08382v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10005",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">C.-H. Huck Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chhabra_M/0/1/0/all/0/1\">Mohit Chhabra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Y.-C. Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_Q/0/1/0/all/0/1\">Quan Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoshinaga_T/0/1/0/all/0/1\">Tomoaki Yoshinaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murakami_T/0/1/0/all/0/1\">Tomokazu Murakami</a>",
          "description": "Physical processes, camera movement, and unpredictable environmental\nconditions like the presence of dust can induce noise and artifacts in video\nfeeds. We observe that popular unsupervised MOT methods are dependent on\nnoise-free inputs. We show that the addition of a small amount of artificial\nrandom noise causes a sharp degradation in model performance on benchmark\nmetrics. We resolve this problem by introducing a robust unsupervised\nmulti-object tracking (MOT) model: AttU-Net. The proposed single-head attention\nmodel helps limit the negative impact of noise by learning visual\nrepresentations at different segment scales. AttU-Net shows better unsupervised\nMOT tracking performance over variational inference-based state-of-the-art\nbaselines. We evaluate our method in the MNIST-MOT and the Atari game video\nbenchmark. We also provide two extended video datasets: ``Kuzushiji-MNIST MOT''\nwhich consists of moving Japanese characters and ``Fashion-MNIST MOT'' to\nvalidate the effectiveness of the MOT models.",
          "link": "http://arxiv.org/abs/2105.10005",
          "publishedOn": "2021-06-16T01:21:07.143Z",
          "wordCount": 644,
          "title": "Robust Unsupervised Multi-Object Tracking in Noisy Environments. (arXiv:2105.10005v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.12589",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singh_J/0/1/0/all/0/1\">Jaskirat Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1\">Liang Zheng</a>",
          "description": "Generation of stroke-based non-photorealistic imagery, is an important\nproblem in the computer vision community. As an endeavor in this direction,\nsubstantial recent research efforts have been focused on teaching machines \"how\nto paint\", in a manner similar to a human painter. However, the applicability\nof previous methods has been limited to datasets with little variation in\nposition, scale and saliency of the foreground object. As a consequence, we\nfind that these methods struggle to cover the granularity and diversity\npossessed by real world images. To this end, we propose a Semantic Guidance\npipeline with 1) a bi-level painting procedure for learning the distinction\nbetween foreground and background brush strokes at training time. 2) We also\nintroduce invariance to the position and scale of the foreground object through\na neural alignment model, which combines object localization and spatial\ntransformer networks in an end to end manner, to zoom into a particular\nsemantic instance. 3) The distinguishing features of the in-focus object are\nthen amplified by maximizing a novel guided backpropagation based focus reward.\nThe proposed agent does not require any supervision on human stroke-data and\nsuccessfully handles variations in foreground object attributes, thus,\nproducing much higher quality canvases for the CUB-200 Birds and Stanford\nCars-196 datasets. Finally, we demonstrate the further efficacy of our method\non complex datasets with multiple foreground object instances by evaluating an\nextension of our method on the challenging Virtual-KITTI dataset. Source code\nand models are available at https://github.com/1jsingh/semantic-guidance.",
          "link": "http://arxiv.org/abs/2011.12589",
          "publishedOn": "2021-06-16T01:21:06.998Z",
          "wordCount": 728,
          "title": "Combining Semantic Guidance and Deep Reinforcement Learning For Generating Human Level Paintings. (arXiv:2011.12589v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.07333",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brima_Y/0/1/0/all/0/1\">Yusuf Brima</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tushar_M/0/1/0/all/0/1\">Mossadek Hossain Kamal Tushar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kabir_U/0/1/0/all/0/1\">Upama Kabir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Islam_T/0/1/0/all/0/1\">Tariqul Islam</a>",
          "description": "Magnetic Resonance Imaging (MRI) is a principal diagnostic approach used in\nthe field of radiology to create images of the anatomical and physiological\nstructure of patients. MRI is the prevalent medical imaging practice to find\nabnormalities in soft tissues. Traditionally they are analyzed by a radiologist\nto detect abnormalities in soft tissues, especially the brain. The process of\ninterpreting a massive volume of patient's MRI is laborious. Hence, the use of\nMachine Learning methodologies can aid in detecting abnormalities in soft\ntissues with considerable accuracy. In this research, we have curated a novel\ndataset and developed a framework that uses Deep Transfer Learning to perform a\nmulti-classification of tumors in the brain MRI images. In this paper, we\nadopted the Deep Residual Convolutional Neural Network (ResNet50) architecture\nfor the experiments along with discriminative learning techniques to train the\nmodel. Using the novel dataset and two publicly available MRI brain datasets,\nthis proposed approach attained a classification accuracy of 86.40% on the\ncurated dataset, 93.80% on the Harvard Whole Brain Atlas dataset, and 97.05%\naccuracy on the School of Biomedical Engineering dataset. Results of our\nexperiments significantly demonstrate our proposed framework for transfer\nlearning is a potential and effective method for brain tumor\nmulti-classification tasks.",
          "link": "http://arxiv.org/abs/2106.07333",
          "publishedOn": "2021-06-16T01:21:06.943Z",
          "wordCount": 701,
          "title": "Deep Transfer Learning for Brain Magnetic Resonance Image Multi-class Classification. (arXiv:2106.07333v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.08918",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+True_J/0/1/0/all/0/1\">Julian True</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_N/0/1/0/all/0/1\">Naimul Khan</a>",
          "description": "Despite the continued successes of computationally efficient deep neural\nnetwork architectures for video object detection, performance continually\narrives at the great trilemma of speed versus accuracy versus computational\nresources (pick two). Current attempts to exploit temporal information in video\ndata to overcome this trilemma are bottlenecked by the state-of-the-art in\nobject detection models. We present, a technique which performs video object\ndetection through the use of off-the-shelf object detectors alongside existing\noptical flow based motion estimation techniques in parallel. Through a set of\nexperiments on the benchmark MOT20 dataset, we demonstrate that our approach\nsignificantly reduces the baseline latency of any given object detector without\nsacrificing any accuracy. Further latency reduction, up to 25x lower than the\noriginal latency, can be achieved with minimal accuracy loss. MOVEX enables low\nlatency video object detection on common CPU based systems, thus allowing for\nhigh performance video object detection beyond the domain of GPU computing. The\ncode is available at https://github.com/juliantrue/movex.",
          "link": "http://arxiv.org/abs/2104.08918",
          "publishedOn": "2021-06-16T01:21:06.774Z",
          "wordCount": 607,
          "title": "Motion Vector Extrapolation for Video Object Detection. (arXiv:2104.08918v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.01604",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Joseph_V/0/1/0/all/0/1\">Vinu Joseph</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siddiqui_S/0/1/0/all/0/1\">Shoaib Ahmed Siddiqui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhaskara_A/0/1/0/all/0/1\">Aditya Bhaskara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gopalakrishnan_G/0/1/0/all/0/1\">Ganesh Gopalakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muralidharan_S/0/1/0/all/0/1\">Saurav Muralidharan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garland_M/0/1/0/all/0/1\">Michael Garland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_S/0/1/0/all/0/1\">Sheraz Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dengel_A/0/1/0/all/0/1\">Andreas Dengel</a>",
          "description": "With the rise in edge-computing devices, there has been an increasing demand\nto deploy energy and resource-efficient models. A large body of research has\nbeen devoted to developing methods that can reduce the size of the model\nconsiderably without affecting the standard metrics such as top-1 accuracy.\nHowever, these pruning approaches tend to result in a significant mismatch in\nother metrics such as fairness across classes and explainability. To combat\nsuch misalignment, we propose a novel multi-part loss function inspired by the\nknowledge-distillation literature. Through extensive experiments, we\ndemonstrate the effectiveness of our approach across different compression\nalgorithms, architectures, tasks as well as datasets. In particular, we obtain\nup to $4.1\\times$ reduction in the number of prediction mismatches between the\ncompressed and reference models, and up to $5.7\\times$ in cases where the\nreference model makes the correct prediction; all while making no changes to\nthe compression algorithm, and minor modifications to the loss function.\nFurthermore, we demonstrate how inducing simple alignment between the\npredictions of the models naturally improves the alignment on other metrics\nincluding fairness and attributions. Our framework can thus serve as a simple\nplug-and-play component for compression algorithms in the future.",
          "link": "http://arxiv.org/abs/2012.01604",
          "publishedOn": "2021-06-16T01:21:06.764Z",
          "wordCount": 673,
          "title": "Going Beyond Classification Accuracy Metrics in Model Compression. (arXiv:2012.01604v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.10086",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Navarro_J/0/1/0/all/0/1\">Julia Navarro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabater_N/0/1/0/all/0/1\">Neus Sabater</a>",
          "description": "Recently, learning methods have been designed to create Multiplane Images\n(MPIs) for view synthesis. While MPIs are extremely powerful and facilitate\nhigh quality renderings, a great amount of memory is required, making them\nimpractical for many applications. In this paper, we propose a learning method\nthat optimizes the available memory to render compact and adaptive MPIs. Our\nMPIs avoid redundant information and take into account the scene geometry to\ndetermine the depth sampling.",
          "link": "http://arxiv.org/abs/2102.10086",
          "publishedOn": "2021-06-16T01:21:06.729Z",
          "wordCount": 529,
          "title": "Compact and adaptive multiplane images for view synthesis. (arXiv:2102.10086v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.12321",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shu_T/0/1/0/all/0/1\">Tianmin Shu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhandwaldar_A/0/1/0/all/0/1\">Abhishek Bhandwaldar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_C/0/1/0/all/0/1\">Chuang Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_K/0/1/0/all/0/1\">Kevin A. Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shari Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gutfreund_D/0/1/0/all/0/1\">Dan Gutfreund</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spelke_E/0/1/0/all/0/1\">Elizabeth Spelke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1\">Joshua B. Tenenbaum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ullman_T/0/1/0/all/0/1\">Tomer D. Ullman</a>",
          "description": "For machine agents to successfully interact with humans in real-world\nsettings, they will need to develop an understanding of human mental life.\nIntuitive psychology, the ability to reason about hidden mental variables that\ndrive observable actions, comes naturally to people: even pre-verbal infants\ncan tell agents from objects, expecting agents to act efficiently to achieve\ngoals given constraints. Despite recent interest in machine agents that reason\nabout other agents, it is not clear if such agents learn or hold the core\npsychology principles that drive human reasoning. Inspired by cognitive\ndevelopment studies on intuitive psychology, we present a benchmark consisting\nof a large dataset of procedurally generated 3D animations, AGENT (Action,\nGoal, Efficiency, coNstraint, uTility), structured around four scenarios (goal\npreferences, action efficiency, unobserved constraints, and cost-reward\ntrade-offs) that probe key concepts of core intuitive psychology. We validate\nAGENT with human-ratings, propose an evaluation protocol emphasizing\ngeneralization, and compare two strong baselines built on Bayesian inverse\nplanning and a Theory of Mind neural network. Our results suggest that to pass\nthe designed tests of core intuitive psychology at human levels, a model must\nacquire or have built-in representations of how agents plan, combining utility\ncomputations and core knowledge of objects and physics.",
          "link": "http://arxiv.org/abs/2102.12321",
          "publishedOn": "2021-06-16T01:21:06.722Z",
          "wordCount": 697,
          "title": "AGENT: A Benchmark for Core Psychological Reasoning. (arXiv:2102.12321v3 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.11088",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wensheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yan Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miyazono_T/0/1/0/all/0/1\">Taiga Miyazono</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uchida_S/0/1/0/all/0/1\">Seiichi Uchida</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iwana_B/0/1/0/all/0/1\">Brian Kenji Iwana</a>",
          "description": "Book covers are intentionally designed and provide an introduction to a book.\nHowever, they typically require professional skills to design and produce the\ncover images. Thus, we propose a generative neural network that can produce\nbook covers based on an easy-to-use layout graph. The layout graph contains\nobjects such as text, natural scene objects, and solid color spaces. This\nlayout graph is embedded using a graph convolutional neural network and then\nused with a mask proposal generator and a bounding-box generator and filled\nusing an object proposal generator. Next, the objects are compiled into a\nsingle image and the entire network is trained using a combination of\nadversarial training, perceptual training, and reconstruction. Finally, a Style\nRetention Network (SRNet) is used to transfer the learned font style onto the\ndesired text. Using the proposed method allows for easily controlled and unique\nbook covers.",
          "link": "http://arxiv.org/abs/2105.11088",
          "publishedOn": "2021-06-16T01:21:06.692Z",
          "wordCount": 608,
          "title": "Towards Book Cover Design via Layout Graphs. (arXiv:2105.11088v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.11025",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1\">Abhishek Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chopra_A/0/1/0/all/0/1\">Ayush Chopra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_V/0/1/0/all/0/1\">Vivek Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garza_E/0/1/0/all/0/1\">Ethan Garza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_E/0/1/0/all/0/1\">Emily Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vepakomma_P/0/1/0/all/0/1\">Praneeth Vepakomma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raskar_R/0/1/0/all/0/1\">Ramesh Raskar</a>",
          "description": "Recent deep learning models have shown remarkable performance in image\nclassification. While these deep learning systems are getting closer to\npractical deployment, the common assumption made about data is that it does not\ncarry any sensitive information. This assumption may not hold for many\npractical cases, especially in the domain where an individual's personal\ninformation is involved, like healthcare and facial recognition systems. We\nposit that selectively removing features in this latent space can protect the\nsensitive information and provide a better privacy-utility trade-off.\nConsequently, we propose DISCO which learns a dynamic and data driven pruning\nfilter to selectively obfuscate sensitive information in the feature space. We\npropose diverse attack schemes for sensitive inputs \\& attributes and\ndemonstrate the effectiveness of DISCO against state-of-the-art methods through\nquantitative and qualitative evaluation. Finally, we also release an evaluation\nbenchmark dataset of 1 million sensitive representations to encourage rigorous\nexploration of novel attack schemes.",
          "link": "http://arxiv.org/abs/2012.11025",
          "publishedOn": "2021-06-16T01:21:06.676Z",
          "wordCount": 632,
          "title": "DISCO: Dynamic and Invariant Sensitive Channel Obfuscation for deep neural networks. (arXiv:2012.11025v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.07075",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Grubisic_I/0/1/0/all/0/1\">Ivan Grubi&#x161;i&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Orsic_M/0/1/0/all/0/1\">Marin Or&#x161;i&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Segvic_S/0/1/0/all/0/1\">Sini&#x161;a &#x160;egvi&#x107;</a>",
          "description": "Semi-supervised learning is especially interesting in the dense prediction\ncontext due to high cost of pixel-level ground truth. Unfortunately, most such\napproaches are evaluated on outdated architectures which hamper research due to\nvery slow training and high requirements on GPU RAM. We address this concern by\npresenting a simple and effective baseline which works very well both on\nstandard and efficient architectures. Our baseline is based on one-way\nconsistency and non-linear geometric and photometric perturbations. We show\nadvantage of perturbing only the student branch and present a plausible\nexplanation of such behaviour. Experiments on Cityscapes and CIFAR-10\ndemonstrate competitive performance with respect to prior work.",
          "link": "http://arxiv.org/abs/2106.07075",
          "publishedOn": "2021-06-16T01:21:06.669Z",
          "wordCount": 558,
          "title": "A baseline for semi-supervised learning of efficient semantic segmentation models. (arXiv:2106.07075v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.04879",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenxiao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Minghao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Shuai Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Long Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1\">Jinming Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Haifeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_D/0/1/0/all/0/1\">Deng Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiaofei He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wei Liu</a>",
          "description": "Most neural network pruning methods, such as filter-level and layer-level\nprunings, prune the network model along one dimension (depth, width, or\nresolution) solely to meet a computational budget. However, such a pruning\npolicy often leads to excessive reduction of that dimension, thus inducing a\nhuge accuracy loss. To alleviate this issue, we argue that pruning should be\nconducted along three dimensions comprehensively. For this purpose, our pruning\nframework formulates pruning as an optimization problem. Specifically, it first\ncasts the relationships between a certain model's accuracy and\ndepth/width/resolution into a polynomial regression and then maximizes the\npolynomial to acquire the optimal values for the three dimensions. Finally, the\nmodel is pruned along the three optimal dimensions accordingly. In this\nframework, since collecting too much data for training the regression is very\ntime-costly, we propose two approaches to lower the cost: 1) specializing the\npolynomial to ensure an accurate regression even with less training data; 2)\nemploying iterative pruning and fine-tuning to collect the data faster.\nExtensive experiments show that our proposed algorithm surpasses\nstate-of-the-art pruning algorithms and even neural architecture search-based\nalgorithms.",
          "link": "http://arxiv.org/abs/2010.04879",
          "publishedOn": "2021-06-16T01:21:06.659Z",
          "wordCount": 671,
          "title": "Accelerate CNNs from Three Dimensions: A Comprehensive Pruning Framework. (arXiv:2010.04879v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.12230",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jingzhao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Menon_A/0/1/0/all/0/1\">Aditya Menon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Veit_A/0/1/0/all/0/1\">Andreas Veit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhojanapalli_S/0/1/0/all/0/1\">Srinadh Bhojanapalli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Sanjiv Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sra_S/0/1/0/all/0/1\">Suvrit Sra</a>",
          "description": "The label shift problem refers to the supervised learning setting where the\ntrain and test label distributions do not match. Existing work addressing label\nshift usually assumes access to an \\emph{unlabelled} test sample. This sample\nmay be used to estimate the test label distribution, and to then train a\nsuitably re-weighted classifier. While approaches using this idea have proven\neffective, their scope is limited as it is not always feasible to access the\ntarget domain; further, they require repeated retraining if the model is to be\ndeployed in \\emph{multiple} test environments. Can one instead learn a\n\\emph{single} classifier that is robust to arbitrary label shifts from a broad\nfamily? In this paper, we answer this question by proposing a model that\nminimises an objective based on distributionally robust optimisation (DRO). We\nthen design and analyse a gradient descent-proximal mirror ascent algorithm\ntailored for large-scale problems to optimise the proposed objective. %, and\nestablish its convergence. Finally, through experiments on CIFAR-100 and\nImageNet, we show that our technique can significantly improve performance over\na number of baselines in settings where label shift is present.",
          "link": "http://arxiv.org/abs/2010.12230",
          "publishedOn": "2021-06-16T01:21:06.650Z",
          "wordCount": 656,
          "title": "Coping with Label Shift via Distributionally Robust Optimisation. (arXiv:2010.12230v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14713",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_M/0/1/0/all/0/1\">Mingbao Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuchao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuxin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Bohong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chao_F/0/1/0/all/0/1\">Fei Chao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mengdi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_R/0/1/0/all/0/1\">Rongrong Ji</a>",
          "description": "Though network sparsity emerges as a promising direction to overcome the\ndrastically increasing size of neural networks, it remains an open problem to\nconcurrently maintain model accuracy as well as achieve significant speedups on\ngeneral CPUs. In this paper, we propose one novel concept of $1\\times N$ block\nsparsity pattern (block pruning) to break this limitation. In particular,\nconsecutive $N$ output kernels with the same input channel index are grouped\ninto one block, which serves as a basic pruning granularity of our pruning\npattern. Our $1 \\times N$ sparsity pattern prunes these blocks considered\nunimportant. We also provide a workflow of filter rearrangement that first\nrearranges the weight matrix in the output channel dimension to derive more\ninfluential blocks for accuracy improvements, and then applies similar\nrearrangement to the next-layer weights in the input channel dimension to\nensure correct convolutional operations. Moreover, the output computation after\nour $1 \\times N$ block sparsity can be realized via a parallelized block-wise\nvectorized operation, leading to significant speedups on general CPUs-based\nplatforms. The efficacy of our pruning pattern is proved with experiments on\nILSVRC-2012. For example, in the case of 50% sparsity and $N=4$, our pattern\nobtains about 3.0% improvements over filter pruning in the top-1 accuracy of\nMobileNet-V2. Meanwhile, it obtains 56.04ms inference savings on Cortex-A7 CPU\nover weight pruning. Code is available at https://github.com/lmbxmu/1xN.",
          "link": "http://arxiv.org/abs/2105.14713",
          "publishedOn": "2021-06-16T01:21:06.630Z",
          "wordCount": 691,
          "title": "1$\\times$N Block Pattern for Network Sparsity. (arXiv:2105.14713v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.02887",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shiwei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_L/0/1/0/all/0/1\">Lu Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mocanu_D/0/1/0/all/0/1\">Decebal Constantin Mocanu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pechenizkiy_M/0/1/0/all/0/1\">Mykola Pechenizkiy</a>",
          "description": "In this paper, we introduce a new perspective on training deep neural\nnetworks capable of state-of-the-art performance without the need for the\nexpensive over-parameterization by proposing the concept of In-Time\nOver-Parameterization (ITOP) in sparse training. By starting from a random\nsparse network and continuously exploring sparse connectivities during\ntraining, we can perform an Over-Parameterization in the space-time manifold,\nclosing the gap in the expressibility between sparse training and dense\ntraining. We further use ITOP to understand the underlying mechanism of Dynamic\nSparse Training (DST) and indicate that the benefits of DST come from its\nability to consider across time all possible parameters when searching for the\noptimal sparse connectivity. As long as there are sufficient parameters that\nhave been reliably explored during training, DST can outperform the dense\nneural network by a large margin. We present a series of experiments to support\nour conjecture and achieve the state-of-the-art sparse training performance\nwith ResNet-50 on ImageNet. More impressively, our method achieves dominant\nperformance over the overparameterization-based sparse methods at extreme\nsparsity levels. When trained on CIFAR-100, our method can match the\nperformance of the dense model even at an extreme sparsity (98%). Code can be\nfound https://github.com/Shiweiliuiiiiiii/In-Time-Over-Parameterization.",
          "link": "http://arxiv.org/abs/2102.02887",
          "publishedOn": "2021-06-16T01:21:06.622Z",
          "wordCount": 713,
          "title": "Do We Actually Need Dense Over-Parameterization? In-Time Over-Parameterization in Sparse Training. (arXiv:2102.02887v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.01894",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sanabria_R/0/1/0/all/0/1\">Ramon Sanabria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Waters_A/0/1/0/all/0/1\">Austin Waters</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baldridge_J/0/1/0/all/0/1\">Jason Baldridge</a>",
          "description": "Speech-based image retrieval has been studied as a proxy for joint\nrepresentation learning, usually without emphasis on retrieval itself. As such,\nit is unclear how well speech-based retrieval can work in practice -- both in\nan absolute sense and versus alternative strategies that combine automatic\nspeech recognition (ASR) with strong text encoders. In this work, we\nextensively study and expand choices of encoder architectures, training\nmethodology (including unimodal and multimodal pretraining), and other factors.\nOur experiments cover different types of speech in three datasets: Flickr\nAudio, Places Audio, and Localized Narratives. Our best model configuration\nachieves large gains over state of the art, e.g., pushing recall-at-one from\n21.8% to 33.2% for Flickr Audio and 27.6% to 53.4% for Places Audio. We also\nshow our best speech-based models can match or exceed cascaded ASR-to-text\nencoding when speech is spontaneous, accented, or otherwise hard to\nautomatically transcribe.",
          "link": "http://arxiv.org/abs/2104.01894",
          "publishedOn": "2021-06-16T01:21:06.601Z",
          "wordCount": 631,
          "title": "Talk, Don't Write: A Study of Direct Speech-Based Image Retrieval. (arXiv:2104.01894v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.07049",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1\">Kangning Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yiqiu Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_N/0/1/0/all/0/1\">Nan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chledowski_J/0/1/0/all/0/1\">Jakub Ch&#x142;&#x119;dowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fernandez_Granda_C/0/1/0/all/0/1\">Carlos Fernandez-Granda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geras_K/0/1/0/all/0/1\">Krzysztof J. Geras</a>",
          "description": "In the last few years, deep learning classifiers have shown promising results\nin image-based medical diagnosis. However, interpreting the outputs of these\nmodels remains a challenge. In cancer diagnosis, interpretability can be\nachieved by localizing the region of the input image responsible for the\noutput, i.e. the location of a lesion. Alternatively, segmentation or detection\nmodels can be trained with pixel-wise annotations indicating the locations of\nmalignant lesions. Unfortunately, acquiring such labels is labor-intensive and\nrequires medical expertise. To overcome this difficulty, weakly-supervised\nlocalization can be utilized. These methods allow neural network classifiers to\noutput saliency maps highlighting the regions of the input most relevant to the\nclassification task (e.g. malignant lesions in mammograms) using only\nimage-level labels (e.g. whether the patient has cancer or not) during\ntraining. When applied to high-resolution images, existing methods produce\nlow-resolution saliency maps. This is problematic in applications in which\nsuspicious lesions are small in relation to the image size. In this work, we\nintroduce a novel neural network architecture to perform weakly-supervised\nsegmentation of high-resolution images. The proposed model selects regions of\ninterest via coarse-level localization, and then performs fine-grained\nsegmentation of those regions. We apply this model to breast cancer diagnosis\nwith screening mammography, and validate it on a large clinically-realistic\ndataset. Measured by Dice similarity score, our approach outperforms existing\nmethods by a large margin in terms of localization performance of benign and\nmalignant lesions, relatively improving the performance by 39.6% and 20.0%,\nrespectively. Code and the weights of some of the models are available at\nhttps://github.com/nyukat/GLAM",
          "link": "http://arxiv.org/abs/2106.07049",
          "publishedOn": "2021-06-16T01:21:06.580Z",
          "wordCount": 734,
          "title": "Weakly-supervised High-resolution Segmentation of Mammography Images for Breast Cancer Diagnosis. (arXiv:2106.07049v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.07639",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Balasubramanian_L/0/1/0/all/0/1\">Lakshman Balasubramanian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wurst_J/0/1/0/all/0/1\">Jonas Wurst</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Botsch_M/0/1/0/all/0/1\">Michael Botsch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_K/0/1/0/all/0/1\">Ke Deng</a>",
          "description": "Traffic scenario categorisation is an essential component of automated\ndriving, for e.\\,g., in motion planning algorithms and their validation.\nFinding new relevant scenarios without handcrafted steps reduce the required\nresources for the development of autonomous driving dramatically. In this work,\na method is proposed to address this challenge by introducing a clustering\ntechnique based on a novel data-adaptive similarity measure, called Random\nForest Activation Pattern (RFAP) similarity. The RFAP similarity is generated\nusing a tree encoding scheme in a Random Forest algorithm. The clustering\nmethod proposed in this work takes into account that there are labelled\nscenarios available and the information from the labelled scenarios can help to\nguide the clustering of unlabelled scenarios. It consists of three steps.\nFirst, a self-supervised Convolutional Neural Network~(CNN) is trained on all\navailable traffic scenarios using a defined self-supervised objective. Second,\nthe CNN is fine-tuned for classification of the labelled scenarios. Third,\nusing the labelled and unlabelled scenarios an iterative optimisation procedure\nis performed for clustering. In the third step at each epoch of the iterative\noptimisation, the CNN is used as a feature generator for an unsupervised Random\nForest. The trained forest, in turn, provides the RFAP similarity to adapt\niteratively the feature generation process implemented by the CNN. Extensive\nexperiments and ablation studies have been done on the highD dataset. The\nproposed method shows superior performance compared to baseline clustering\ntechniques.",
          "link": "http://arxiv.org/abs/2105.07639",
          "publishedOn": "2021-06-16T01:21:06.573Z",
          "wordCount": 709,
          "title": "Traffic Scenario Clustering by Iterative Optimisation of Self-Supervised Networks Using a Random Forest Activation Pattern Similarity. (arXiv:2105.07639v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.00877",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiaotian Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuwang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xuejin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_W/0/1/0/all/0/1\">Wenjun Zeng</a>",
          "description": "Human can infer the 3D geometry of a scene from a sketch instead of a\nrealistic image, which indicates that the spatial structure plays a fundamental\nrole in understanding the depth of scenes. We are the first to explore the\nlearning of a depth-specific structural representation, which captures the\nessential feature for depth estimation and ignores irrelevant style\ninformation. Our S2R-DepthNet (Synthetic to Real DepthNet) can be well\ngeneralized to unseen real-world data directly even though it is only trained\non synthetic data. S2R-DepthNet consists of: a) a Structure Extraction (STE)\nmodule which extracts a domaininvariant structural representation from an image\nby disentangling the image into domain-invariant structure and domain-specific\nstyle components, b) a Depth-specific Attention (DSA) module, which learns\ntask-specific knowledge to suppress depth-irrelevant structures for better\ndepth estimation and generalization, and c) a depth prediction module (DP) to\npredict depth from the depth-specific representation. Without access of any\nreal-world images, our method even outperforms the state-of-the-art\nunsupervised domain adaptation methods which use real-world images of the\ntarget domain for training. In addition, when using a small amount of labeled\nreal-world data, we achieve the state-ofthe-art performance under the\nsemi-supervised setting. The code and trained models are available at\nhttps://github.com/microsoft/S2R-DepthNet.",
          "link": "http://arxiv.org/abs/2104.00877",
          "publishedOn": "2021-06-16T01:21:06.566Z",
          "wordCount": 663,
          "title": "S2R-DepthNet: Learning a Generalizable Depth-specific Structural Representation. (arXiv:2104.00877v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.12690",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Heijden_B/0/1/0/all/0/1\">Bas van der Heijden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferranti_L/0/1/0/all/0/1\">Laura Ferranti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kober_J/0/1/0/all/0/1\">Jens Kober</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Babuska_R/0/1/0/all/0/1\">Robert Babuska</a>",
          "description": "This paper presents DeepKoCo, a novel model-based agent that learns a latent\nKoopman representation from images. This representation allows DeepKoCo to plan\nefficiently using linear control methods, such as linear model predictive\ncontrol. Compared to traditional agents, DeepKoCo is robust to task-irrelevant\ndynamics, thanks to the use of a tailored lossy autoencoder network that allows\nDeepKoCo to learn latent dynamics that reconstruct and predict only observed\ncosts, rather than all observed dynamics. As our results show, DeepKoCo\nachieves a similar final performance as traditional model-free methods on\ncomplex control tasks, while being considerably more robust to distractor\ndynamics, making the proposed agent more amenable for real-life applications.",
          "link": "http://arxiv.org/abs/2011.12690",
          "publishedOn": "2021-06-16T01:21:06.559Z",
          "wordCount": 581,
          "title": "DeepKoCo: Efficient latent planning with a robust Koopman representation. (arXiv:2011.12690v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.08482",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Angermann_C/0/1/0/all/0/1\">Christoph Angermann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jonsson_S/0/1/0/all/0/1\">Steinbj&#xf6;rn J&#xf3;nsson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haltmeier_M/0/1/0/all/0/1\">Markus Haltmeier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moravova_A/0/1/0/all/0/1\">Ad&#xe9;la Moravov&#xe1;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laubichler_C/0/1/0/all/0/1\">Christian Laubichler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiesling_C/0/1/0/all/0/1\">Constantin Kiesling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kober_M/0/1/0/all/0/1\">Martin Kober</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fimml_W/0/1/0/all/0/1\">Wolfgang Fimml</a>",
          "description": "Digitalization offers a large number of promising tools for large internal\ncombustion engines such as condition monitoring or condition-based maintenance.\nThis includes the status evaluation of key engine components such as cylinder\nliners, whose inner surfaces are subject to constant wear due to their movement\nrelative to the pistons. Existing state-of-the-art methods for quantifying wear\nrequire disassembly and cutting of the examined liner followed by a\nhigh-resolution microscopic surface depth measurement that quantitatively\nevaluates wear based on bearing load curves (also known as Abbott-Firestone\ncurves). Such reference methods are destructive, time-consuming and costly. The\ngoal of the research presented here is to develop nondestructive yet reliable\nmethods for quantifying the surface condition. A deep-learning framework is\nproposed that allows computation of the bearing load curves from reflection RGB\nimages of the liner surface that can be collected with a wide variety of simple\nimaging devices, without the need to remove and destroy the investigated liner.\nFor this purpose, a convolutional neural network is trained to predict the\nbearing load curve of the corresponding depth profile from the collected RGB\nimages, which in turn can be used for further wear evaluation. Training of the\nnetwork is performed using a custom-built database containing depth profiles\nand reflection images of liner surfaces of large gas engines. The results of\nthe proposed method are visually examined and quantified considering several\nprobabilistic distance metrics and comparison of roughness indicators between\nground truth and model predictions. The observed success of the proposed method\nsuggests its great potential for quantitative wear assessment on engines during\nservice directly on site.",
          "link": "http://arxiv.org/abs/2103.08482",
          "publishedOn": "2021-06-16T01:21:06.552Z",
          "wordCount": 733,
          "title": "Machine Learning for Nondestructive Wear Assessment in Large Internal Combustion Engines. (arXiv:2103.08482v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.09671",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liang_T/0/1/0/all/0/1\">Tailin Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glossner_J/0/1/0/all/0/1\">John Glossner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1\">Shaobo Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaotong Zhang</a>",
          "description": "Deep neural networks have been applied in many applications exhibiting\nextraordinary abilities in the field of computer vision. However, complex\nnetwork architectures challenge efficient real-time deployment and require\nsignificant computation resources and energy costs. These challenges can be\novercome through optimizations such as network compression. Network compression\ncan often be realized with little loss of accuracy. In some cases accuracy may\neven improve. This paper provides a survey on two types of network compression:\npruning and quantization. Pruning can be categorized as static if it is\nperformed offline or dynamic if it is performed at run-time. We compare pruning\ntechniques and describe criteria used to remove redundant computations. We\ndiscuss trade-offs in element-wise, channel-wise, shape-wise, filter-wise,\nlayer-wise and even network-wise pruning. Quantization reduces computations by\nreducing the precision of the datatype. Weights, biases, and activations may be\nquantized typically to 8-bit integers although lower bit width implementations\nare also discussed including binary neural networks. Both pruning and\nquantization can be used independently or combined. We compare current\ntechniques, analyze their strengths and weaknesses, present compressed network\naccuracy results on a number of frameworks, and provide practical guidance for\ncompressing networks.",
          "link": "http://arxiv.org/abs/2101.09671",
          "publishedOn": "2021-06-16T01:21:06.531Z",
          "wordCount": 668,
          "title": "Pruning and Quantization for Deep Neural Network Acceleration: A Survey. (arXiv:2101.09671v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.09451",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lo_S/0/1/0/all/0/1\">Shao-Yuan Lo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patel_V/0/1/0/all/0/1\">Vishal M. Patel</a>",
          "description": "Adversarial examples contain carefully crafted perturbations that can fool\ndeep neural networks (DNNs) into making wrong predictions. Enhancing the\nadversarial robustness of DNNs has gained considerable interest in recent\nyears. Although image transformation-based defenses were widely considered at\nan earlier time, most of them have been defeated by adaptive attacks. In this\npaper, we propose a new image transformation defense based on error diffusion\nhalftoning, and combine it with adversarial training to defend against\nadversarial examples. Error diffusion halftoning projects an image into a 1-bit\nspace and diffuses quantization error to neighboring pixels. This process can\nremove adversarial perturbations from a given image while maintaining\nacceptable image quality in the meantime in favor of recognition. Experimental\nresults demonstrate that the proposed method is able to improve adversarial\nrobustness even under advanced adaptive attacks, while most of the other image\ntransformation-based defenses do not. We show that a proper image\ntransformation can still be an effective defense approach. Code:\nhttps://github.com/shaoyuanlo/Halftoning-Defense",
          "link": "http://arxiv.org/abs/2101.09451",
          "publishedOn": "2021-06-16T01:21:06.523Z",
          "wordCount": 639,
          "title": "Error Diffusion Halftoning Against Adversarial Examples. (arXiv:2101.09451v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03152",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sener_F/0/1/0/all/0/1\">Fadime Sener</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chatterjee_D/0/1/0/all/0/1\">Dibyadip Chatterjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_A/0/1/0/all/0/1\">Angela Yao</a>",
          "description": "This technical report extends our work presented in [9] with more\nexperiments. In [9], we tackle long-term video understanding, which requires\nreasoning from current and past or future observations and raises several\nfundamental questions. How should temporal or sequential relationships be\nmodelled? What temporal extent of information and context needs to be\nprocessed? At what temporal scale should they be derived? [9] addresses these\nquestions with a flexible multi-granular temporal aggregation framework. In\nthis report, we conduct further experiments with this framework on different\ntasks and a new dataset, EPIC-KITCHENS-100.",
          "link": "http://arxiv.org/abs/2106.03152",
          "publishedOn": "2021-06-16T01:21:06.515Z",
          "wordCount": 529,
          "title": "Technical Report: Temporal Aggregate Representations. (arXiv:2106.03152v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.10762",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Murphy_R/0/1/0/all/0/1\">Robert A. Murphy</a>",
          "description": "Random field and random cluster theory are used to prove certain mathematical\nresults concerning the probability distribution of image pixel intensities\ncharacterized as generic $2D$ integer arrays. The size of the smallest bounded\nregion within an image is estimated for segmenting an image, from which, the\nequilibrium distribution of intensities can be recovered. From the estimated\nbounded regions, properties of the sub-optimal and equilibrium distributions of\nintensities are derived, which leads to an image compression methodology\nwhereby only slightly more than half of all pixels are required for a\nworst-case reconstruction of the original image. An example in unsupervised\nobject detection illustrates the mathematical results.",
          "link": "http://arxiv.org/abs/2104.10762",
          "publishedOn": "2021-06-16T01:21:06.508Z",
          "wordCount": 611,
          "title": "Image Segmentation, Compression and Reconstruction from Edge Distribution Estimation with Random Field and Random Cluster Theories. (arXiv:2104.10762v6 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1910.12019",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_H/0/1/0/all/0/1\">Huanhou Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1\">Jinglun Shi</a>",
          "description": "Automatically describing video content with text description is challenging\nbut important task, which has been attracting a lot of attention in computer\nvision community. Previous works mainly strive for the accuracy of the\ngenerated sentences, while ignoring the sentences diversity, which is\ninconsistent with human behavior. In this paper, we aim to caption each video\nwith multiple descriptions and propose a novel framework. Concretely, for a\ngiven video, the intermediate latent variables of conventional encode-decode\nprocess are utilized as input to the conditional generative adversarial network\n(CGAN) with the purpose of generating diverse sentences. We adopt different\nConvolutional Neural Networks (CNNs) as our generator that produces\ndescriptions conditioned on latent variables and discriminator that assesses\nthe quality of generated sentences. Simultaneously, a novel DCE metric is\ndesigned to assess the diverse captions. We evaluate our method on the\nbenchmark datasets, where it demonstrates its ability to generate diverse\ndescriptions and achieves superior results against other state-of-the-art\nmethods.",
          "link": "http://arxiv.org/abs/1910.12019",
          "publishedOn": "2021-06-16T01:21:06.484Z",
          "wordCount": 645,
          "title": "Diverse Video Captioning Through Latent Variable Expansion. (arXiv:1910.12019v6 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.00923",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tianshui Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pu_T/0/1/0/all/0/1\">Tao Pu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Hefeng Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yuan Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lingbo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1\">Liang Lin</a>",
          "description": "To address the problem of data inconsistencies among different facial\nexpression recognition (FER) datasets, many cross-domain FER methods (CD-FERs)\nhave been extensively devised in recent years. Although each declares to\nachieve superior performance, fair comparisons are lacking due to the\ninconsistent choices of the source/target datasets and feature extractors. In\nthis work, we first analyze the performance effect caused by these inconsistent\nchoices, and then re-implement some well-performing CD-FER and recently\npublished domain adaptation algorithms. We ensure that all these algorithms\nadopt the same source datasets and feature extractors for fair CD-FER\nevaluations. We find that most of the current leading algorithms use\nadversarial learning to learn holistic domain-invariant features to mitigate\ndomain shifts. However, these algorithms ignore local features, which are more\ntransferable across different datasets and carry more detailed content for\nfine-grained adaptation. To address these issues, we integrate graph\nrepresentation propagation with adversarial learning for cross-domain\nholistic-local feature co-adaptation by developing a novel adversarial graph\nrepresentation adaptation (AGRA) framework. Specifically, it first builds two\ngraphs to correlate holistic and local regions within each domain and across\ndifferent domains, respectively. Then, it extracts holistic-local features from\nthe input image and uses learnable per-class statistical distributions to\ninitialize the corresponding graph nodes. Finally, two stacked graph\nconvolution networks (GCNs) are adopted to propagate holistic-local features\nwithin each domain to explore their interaction and across different domains\nfor holistic-local feature co-adaptation. We conduct extensive and fair\nevaluations on several popular benchmarks and show that the proposed AGRA\nframework outperforms previous state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2008.00923",
          "publishedOn": "2021-06-16T01:21:06.432Z",
          "wordCount": 785,
          "title": "Cross-Domain Facial Expression Recognition: A Unified Evaluation Benchmark and Adversarial Graph Learning. (arXiv:2008.00923v7 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.04076",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qiang Li</a>",
          "description": "Visual attention is one of the most significant characteristics for selecting\nand understanding the outside redundancy world. The nature of complex scenes\nincludes enormous redundancy. The human vision system can not process all\ninformation simultaneously because of visual information bottleneck. The human\nvisual system mainly focuses on dominant parts of the scenes to reduce the\ninput visual redundancy information. It is commonly known as visual attention\nprediction or visual saliency map. This paper proposes a new psychophysical\nsaliency prediction architecture, WECSF, inspired by human low-level visual\ncortex function. The model consists of opponent color channels, wavelet\ntransform, wavelet energy map, and contrast sensitivity function for extracting\nlow-level image features and maximum approximation to the human visual system.\nThe proposed model is evaluated several datasets, including MIT1003, MIT300,\nTORONTO, SID4VAM and UCF Sports dataset to explain its efficiency. We also\nquantitatively and qualitatively compared the performance of saliency\nprediction with other state-of-the-art models. Our model achieved very stable\nand good performance. Second, we also confirmed that Fourier and\nspectral-inspired saliency prediction models achieved outperformance compared\nto other start-of-the-art non-neural networks and even deep neural network\nmodels on psychophysical synthesis images. Finally, the proposed model also can\nbe applied to spatial-temporal saliency prediction and got better performance.",
          "link": "http://arxiv.org/abs/2011.04076",
          "publishedOn": "2021-06-16T01:21:06.287Z",
          "wordCount": 715,
          "title": "A Psychophysical Oriented Saliency Map Prediction Model. (arXiv:2011.04076v9 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08295",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nagel_M/0/1/0/all/0/1\">Markus Nagel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fournarakis_M/0/1/0/all/0/1\">Marios Fournarakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amjad_R/0/1/0/all/0/1\">Rana Ali Amjad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bondarenko_Y/0/1/0/all/0/1\">Yelysei Bondarenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baalen_M/0/1/0/all/0/1\">Mart van Baalen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blankevoort_T/0/1/0/all/0/1\">Tijmen Blankevoort</a>",
          "description": "While neural networks have advanced the frontiers in many applications, they\noften come at a high computational cost. Reducing the power and latency of\nneural network inference is key if we want to integrate modern networks into\nedge devices with strict power and compute requirements. Neural network\nquantization is one of the most effective ways of achieving these savings but\nthe additional noise it induces can lead to accuracy degradation. In this white\npaper, we introduce state-of-the-art algorithms for mitigating the impact of\nquantization noise on the network's performance while maintaining low-bit\nweights and activations. We start with a hardware motivated introduction to\nquantization and then consider two main classes of algorithms: Post-Training\nQuantization (PTQ) and Quantization-Aware-Training (QAT). PTQ requires no\nre-training or labelled data and is thus a lightweight push-button approach to\nquantization. In most cases, PTQ is sufficient for achieving 8-bit quantization\nwith close to floating-point accuracy. QAT requires fine-tuning and access to\nlabeled training data but enables lower bit quantization with competitive\nresults. For both solutions, we provide tested pipelines based on existing\nliterature and extensive experimentation that lead to state-of-the-art\nperformance for common deep learning models and tasks.",
          "link": "http://arxiv.org/abs/2106.08295",
          "publishedOn": "2021-06-16T01:21:06.270Z",
          "wordCount": 630,
          "title": "A White Paper on Neural Network Quantization. (arXiv:2106.08295v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08170",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+DAmario_V/0/1/0/all/0/1\">Vanessa D&#x27;Amario</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sasaki_T/0/1/0/all/0/1\">Tomotake Sasaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boix_X/0/1/0/all/0/1\">Xavier Boix</a>",
          "description": "Neural Module Networks (NMNs) aim at Visual Question Answering (VQA) via\ncomposition of modules that tackle a sub-task. NMNs are a promising strategy to\nachieve systematic generalization, i.e. overcoming biasing factors in the\ntraining distribution. However, the aspects of NMNs that facilitate systematic\ngeneralization are not fully understood. In this paper, we demonstrate that the\nstage and the degree at which modularity is defined has large influence on\nsystematic generalization. In a series of experiments on three VQA datasets\n(MNIST with multiple attributes, SQOOP, and CLEVR-CoGenT), our results reveal\nthat tuning the degree of modularity in the network, especially at the image\nencoder stage, reaches substantially higher systematic generalization. These\nfindings lead to new NMN architectures that outperform previous ones in terms\nof systematic generalization.",
          "link": "http://arxiv.org/abs/2106.08170",
          "publishedOn": "2021-06-16T01:21:06.263Z",
          "wordCount": 557,
          "title": "How Modular Should Neural Module Networks Be for Systematic Generalization?. (arXiv:2106.08170v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08318",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Malinowski_M/0/1/0/all/0/1\">Mateusz Malinowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vytiniotis_D/0/1/0/all/0/1\">Dimitrios Vytiniotis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swirszcz_G/0/1/0/all/0/1\">Grzegorz Swirszcz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patraucean_V/0/1/0/all/0/1\">Viorica Patraucean</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carreira_J/0/1/0/all/0/1\">Joao Carreira</a>",
          "description": "How can neural networks be trained on large-volume temporal data efficiently?\nTo compute the gradients required to update parameters, backpropagation blocks\ncomputations until the forward and backward passes are completed. For temporal\nsignals, this introduces high latency and hinders real-time learning. It also\ncreates a coupling between consecutive layers, which limits model parallelism\nand increases memory consumption. In this paper, we build upon Sideways, which\navoids blocking by propagating approximate gradients forward in time, and we\npropose mechanisms for temporal integration of information based on different\nvariants of skip connections. We also show how to decouple computation and\ndelegate individual neural modules to different devices, allowing distributed\nand parallel training. The proposed Skip-Sideways achieves low latency\ntraining, model parallelism, and, importantly, is capable of extracting\ntemporal features, leading to more stable training and improved performance on\nreal-world action recognition video datasets such as HMDB51, UCF101, and the\nlarge-scale Kinetics-600. Finally, we also show that models trained with\nSkip-Sideways generate better future frames than Sideways models, and hence\nthey can better utilize motion cues.",
          "link": "http://arxiv.org/abs/2106.08318",
          "publishedOn": "2021-06-16T01:21:06.254Z",
          "wordCount": 632,
          "title": "Gradient Forward-Propagation for Large-Scale Temporal Video Modelling. (arXiv:2106.08318v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08017",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hengyuan Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Wenhao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yihao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1\">Dongliang He</a>",
          "description": "Legacy black-and-white photos are riddled with people's nostalgia and\nglorious memories of the past. To better relive the elapsed frozen moments, in\nthis paper, we present a deep exemplar-based image colorization approach named\nColor2Style to resurrect these grayscale image media by filling them with\nvibrant colors. Generally, for exemplar-based colorization, unsupervised and\nunpaired training are usually adopted, due to the difficulty of obtaining input\nand ground truth image pairs. To train an exemplar-based colorization model,\ncurrent algorithms usually strive to achieve two procedures: i) retrieving a\nlarge number of reference images with high similarity in advance, which is\ninevitably time-consuming and tedious; ii) designing complicated modules to\ntransfer the colors of the reference image to the grayscale image, by\ncalculating and leveraging the deep semantic correspondence between them (e.g.,\nnon-local operation). Contrary to the previous methods, we solve and simplify\nthe above two steps in one end-to-end learning procedure. First, we adopt a\nself-augmented self-reference training scheme, where the reference image is\ngenerated by graphical transformations from the original colorful one whereby\nthe training can be formulated in a paired manner. Second, instead of computing\ncomplex and inexplicable correspondence maps, our method exploits a simple yet\neffective deep feature modulation (DFM) module, which injects the color\nembeddings extracted from the reference image into the deep representations of\nthe input grayscale image. Such design is much more lightweight and\nintelligible, achieving appealing performance with real-time processing speed.\nMoreover, our model does not require multifarious loss functions and\nregularization terms like existing methods, but only two widely used loss\nfunctions. Codes and models will be available at\nhttps://github.com/zhaohengyuan1/Color2Style.",
          "link": "http://arxiv.org/abs/2106.08017",
          "publishedOn": "2021-06-16T01:21:06.233Z",
          "wordCount": 714,
          "title": "Color2Style: Real-Time Exemplar-Based Image Colorization with Self-Reference Learning and Deep Feature Modulation. (arXiv:2106.08017v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08320",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Li_Y/0/1/0/all/0/1\">Yazhe Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pogodin_R/0/1/0/all/0/1\">Roman Pogodin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sutherland_D/0/1/0/all/0/1\">Danica J. Sutherland</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gretton_A/0/1/0/all/0/1\">Arthur Gretton</a>",
          "description": "We approach self-supervised learning of image representations from a\nstatistical dependence perspective, proposing Self-Supervised Learning with the\nHilbert-Schmidt Independence Criterion (SSL-HSIC). SSL-HSIC maximizes\ndependence between representations of transformed versions of an image and the\nimage identity, while minimizing the kernelized variance of those features.\nThis self-supervised learning framework yields a new understanding of InfoNCE,\na variational lower bound on the mutual information (MI) between different\ntransformations. While the MI itself is known to have pathologies which can\nresult in meaningless representations being learned, its bound is much better\nbehaved: we show that it implicitly approximates SSL-HSIC (with a slightly\ndifferent regularizer). Our approach also gives us insight into BYOL, since\nSSL-HSIC similarly learns local neighborhoods of samples. SSL-HSIC allows us to\ndirectly optimize statistical dependence in time linear in the batch size,\nwithout restrictive data assumptions or indirect mutual information estimators.\nTrained with or without a target network, SSL-HSIC matches the current\nstate-of-the-art for standard linear evaluation on ImageNet, semi-supervised\nlearning and transfer to other classification and vision tasks such as semantic\nsegmentation, depth estimation and object recognition.",
          "link": "http://arxiv.org/abs/2106.08320",
          "publishedOn": "2021-06-16T01:21:06.223Z",
          "wordCount": 615,
          "title": "Self-Supervised Learning with Kernel Dependence Maximization. (arXiv:2106.08320v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07849",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Blakeney_C/0/1/0/all/0/1\">Cody Blakeney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huish_N/0/1/0/all/0/1\">Nathaniel Huish</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1\">Yan Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zong_Z/0/1/0/all/0/1\">Ziliang Zong</a>",
          "description": "In recent years the ubiquitous deployment of AI has posed great concerns in\nregards to algorithmic bias, discrimination, and fairness. Compared to\ntraditional forms of bias or discrimination caused by humans, algorithmic bias\ngenerated by AI is more abstract and unintuitive therefore more difficult to\nexplain and mitigate. A clear gap exists in the current literature on\nevaluating and mitigating bias in pruned neural networks. In this work, we\nstrive to tackle the challenging issues of evaluating, mitigating, and\nexplaining induced bias in pruned neural networks. Our paper makes three\ncontributions. First, we propose two simple yet effective metrics, Combined\nError Variance (CEV) and Symmetric Distance Error (SDE), to quantitatively\nevaluate the induced bias prevention quality of pruned models. Second, we\ndemonstrate that knowledge distillation can mitigate induced bias in pruned\nneural networks, even with unbalanced datasets. Third, we reveal that model\nsimilarity has strong correlations with pruning induced bias, which provides a\npowerful method to explain why bias occurs in pruned neural networks. Our code\nis available at https://github.com/codestar12/pruning-distilation-bias",
          "link": "http://arxiv.org/abs/2106.07849",
          "publishedOn": "2021-06-16T01:21:06.215Z",
          "wordCount": 616,
          "title": "Simon Says: Evaluating and Mitigating Bias in Pruned Neural Networks with Knowledge Distillation. (arXiv:2106.07849v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08269",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Henriques_L/0/1/0/all/0/1\">Luis Felipe Henriques</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Colcher_S/0/1/0/all/0/1\">S&#xe9;rgio Colcher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Milidiu_R/0/1/0/all/0/1\">Ruy Luiz Milidi&#xfa;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bulcao_A/0/1/0/all/0/1\">Andr&#xe9; Bulc&#xe3;o</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barros_P/0/1/0/all/0/1\">Pablo Barros</a>",
          "description": "Nowadays, subsurface salt body localization and delineation, also called\nsemantic segmentation of salt bodies, are among the most challenging\ngeophysicist tasks. Thus, identifying large salt bodies is notoriously tricky\nand is crucial for identifying hydrocarbon reservoirs and drill path planning.\nThis work proposes a Data Augmentation method based on training two generative\nmodels to augment the number of samples in a seismic image dataset for the\nsemantic segmentation of salt bodies. Our method uses deep learning models to\ngenerate pairs of seismic image patches and their respective salt masks for the\nData Augmentation. The first model is a Variational Autoencoder and is\nresponsible for generating patches of salt body masks. The second is a\nConditional Normalizing Flow model, which receives the generated masks as\ninputs and generates the associated seismic image patches. We evaluate the\nproposed method by comparing the performance of ten distinct state-of-the-art\nmodels for semantic segmentation, trained with and without the generated\naugmentations, in a dataset from two synthetic seismic images. The proposed\nmethodology yields an average improvement of 8.57% in the IoU metric across all\ncompared models. The best result is achieved by a DeeplabV3+ model variant,\nwhich presents an IoU score of 95.17% when trained with our augmentations.\nAdditionally, our proposal outperformed six selected data augmentation methods,\nand the most significant improvement in the comparison, of 9.77%, is achieved\nby composing our DA with augmentations from an elastic transformation. At last,\nwe show that the proposed method is adaptable for a larger context size by\nachieving results comparable to the obtained on the smaller context size.",
          "link": "http://arxiv.org/abs/2106.08269",
          "publishedOn": "2021-06-16T01:21:06.208Z",
          "wordCount": 719,
          "title": "Generating Data Augmentation samples for Semantic Segmentation of Salt Bodies in a Synthetic Seismic Image Dataset. (arXiv:2106.08269v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08061",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yutong Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jianwen Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Ziyuan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qing_Z/0/1/0/all/0/1\">Zhiwu Qing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shiwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_M/0/1/0/all/0/1\">Mingqian Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yue Gao</a>",
          "description": "This paper presents our solution to the AVA-Kinetics Crossover Challenge of\nActivityNet workshop at CVPR 2021. Our solution utilizes multiple types of\nrelation modeling methods for spatio-temporal action detection and adopts a\ntraining strategy to integrate multiple relation modeling in end-to-end\ntraining over the two large-scale video datasets. Learning with memory bank and\nfinetuning for long-tailed distribution are also investigated to further\nimprove the performance. In this paper, we detail the implementations of our\nsolution and provide experiments results and corresponding discussions. We\nfinally achieve 40.67 mAP on the test set of AVA-Kinetics.",
          "link": "http://arxiv.org/abs/2106.08061",
          "publishedOn": "2021-06-16T01:21:06.201Z",
          "wordCount": 526,
          "title": "Relation Modeling in Spatio-Temporal Action Localization. (arXiv:2106.08061v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08188",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chanti_D/0/1/0/all/0/1\">Dawood Al Chanti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mateus_D/0/1/0/all/0/1\">Diana Mateus</a>",
          "description": "This paper addresses the domain shift problem for segmentation. As a\nsolution, we propose OLVA, a novel and lightweight unsupervised domain\nadaptation method based on a Variational Auto-Encoder (VAE) and Optimal\nTransport (OT) theory. Thanks to the VAE, our model learns a shared\ncross-domain latent space that follows a normal distribution, which reduces the\ndomain shift. To guarantee valid segmentations, our shared latent space is\ndesigned to model the shape rather than the intensity variations. We further\nrely on an OT loss to match and align the remaining discrepancy between the two\ndomains in the latent space. We demonstrate OLVA's effectiveness for the\nsegmentation of multiple cardiac structures on the public Multi-Modality Whole\nHeart Segmentation (MM-WHS) dataset, where the source domain consists of\nannotated 3D MR images and the unlabelled target domain of 3D CTs. Our results\nshow remarkable improvements with an additional margin of 12.5\\% dice score\nover concurrent generative training approaches.",
          "link": "http://arxiv.org/abs/2106.08188",
          "publishedOn": "2021-06-16T01:21:06.181Z",
          "wordCount": 600,
          "title": "Optimal Latent Vector Alignment for Unsupervised Domain Adaptation in Medical Image Segmentation. (arXiv:2106.08188v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08322",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1\">Xiyang Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yinpeng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_B/0/1/0/all/0/1\">Bin Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Dongdong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Mengchen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1\">Lu Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lei Zhang</a>",
          "description": "The complex nature of combining localization and classification in object\ndetection has resulted in the flourished development of methods. Previous works\ntried to improve the performance in various object detection heads but failed\nto present a unified view. In this paper, we present a novel dynamic head\nframework to unify object detection heads with attentions. By coherently\ncombining multiple self-attention mechanisms between feature levels for\nscale-awareness, among spatial locations for spatial-awareness, and within\noutput channels for task-awareness, the proposed approach significantly\nimproves the representation ability of object detection heads without any\ncomputational overhead. Further experiments demonstrate that the effectiveness\nand efficiency of the proposed dynamic head on the COCO benchmark. With a\nstandard ResNeXt-101-DCN backbone, we largely improve the performance over\npopular object detectors and achieve a new state-of-the-art at 54.0 AP.\nFurthermore, with latest transformer backbone and extra data, we can push\ncurrent best COCO result to a new record at 60.6 AP. The code will be released\nat https://github.com/microsoft/DynamicHead.",
          "link": "http://arxiv.org/abs/2106.08322",
          "publishedOn": "2021-06-16T01:21:06.174Z",
          "wordCount": 605,
          "title": "Dynamic Head: Unifying Object Detection Heads with Attentions. (arXiv:2106.08322v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08301",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1\">Sheng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1\">Wei Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1\">Kaidi Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanzhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Songnan Li</a>",
          "description": "Compressing Deep Neural Network (DNN) models to alleviate the storage and\ncomputation requirements is essential for practical applications, especially\nfor resource limited devices. Although capable of reducing a reasonable amount\nof model parameters, previous unstructured or structured weight pruning methods\ncan hardly truly accelerate inference, either due to the poor hardware\ncompatibility of the unstructured sparsity or due to the low sparse rate of the\nstructurally pruned network. Aiming at reducing both storage and computation,\nas well as preserving the original task performance, we propose a generalized\nweight unification framework at a hardware compatible micro-structured level to\nachieve high amount of compression and acceleration. Weight coefficients of a\nselected micro-structured block are unified to reduce the storage and\ncomputation of the block without changing the neuron connections, which turns\nto a micro-structured pruning special case when all unified coefficients are\nset to zero, where neuron connections (hence storage and computation) are\ncompletely removed. In addition, we developed an effective training framework\nbased on the alternating direction method of multipliers (ADMM), which converts\nour complex constrained optimization into separately solvable subproblems.\nThrough iteratively optimizing the subproblems, the desired micro-structure can\nbe ensured with high compression ratio and low performance degradation. We\nextensively evaluated our method using a variety of benchmark models and\ndatasets for different applications. Experimental results demonstrate\nstate-of-the-art performance.",
          "link": "http://arxiv.org/abs/2106.08301",
          "publishedOn": "2021-06-16T01:21:06.167Z",
          "wordCount": 669,
          "title": "Efficient Micro-Structured Weight Unification for Neural Network Compression. (arXiv:2106.08301v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/1911.01529",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Blumenkamp_J/0/1/0/all/0/1\">Jan Blumenkamp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baude_A/0/1/0/all/0/1\">Andreas Baude</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laue_T/0/1/0/all/0/1\">Tim Laue</a>",
          "description": "Deep learning approaches have become the standard solution to many problems\nin computer vision and robotics, but obtaining sufficient training data in high\nenough quality is challenging, as human labor is error prone, time consuming,\nand expensive. Solutions based on simulation have become more popular in recent\nyears, but the gap between simulation and reality is still a major issue. In\nthis paper, we introduce a novel method for augmenting synthetic image data\nthrough unsupervised image-to-image translation by applying the style of real\nworld images to simulated images with open source frameworks. The generated\ndataset is combined with conventional augmentation methods and is then applied\nto a neural network model running in real-time on autonomous soccer robots. Our\nevaluation shows a significant improvement compared to models trained on images\ngenerated entirely in simulation.",
          "link": "http://arxiv.org/abs/1911.01529",
          "publishedOn": "2021-06-16T01:21:06.159Z",
          "wordCount": 599,
          "title": "Closing the Reality Gap with Unsupervised Sim-to-Real Image Translation. (arXiv:1911.01529v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08091",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ordun_C/0/1/0/all/0/1\">Catherine Ordun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raff_E/0/1/0/all/0/1\">Edward Raff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Purushotham_S/0/1/0/all/0/1\">Sanjay Purushotham</a>",
          "description": "Thermal images reveal medically important physiological information about\nhuman stress, signs of inflammation, and emotional mood that cannot be seen on\nvisible images. Providing a method to generate thermal faces from visible\nimages would be highly valuable for the telemedicine community in order to show\nthis medical information. To the best of our knowledge, there are limited works\non visible-to-thermal (VT) face translation, and many current works go the\nopposite direction to generate visible faces from thermal surveillance images\n(TV) for law enforcement applications. As a result, we introduce favtGAN, a VT\nGAN which uses the pix2pix image translation model with an auxiliary sensor\nlabel prediction network for generating thermal faces from visible images.\nSince most TV methods are trained on only one data source drawn from one\nthermal sensor, we combine datasets from faces and cityscapes. These combined\ndata are captured from similar sensors in order to bootstrap the training and\ntransfer learning task, especially valuable because visible-thermal face\ndatasets are limited. Experiments on these combined datasets show that favtGAN\ndemonstrates an increase in SSIM and PSNR scores of generated thermal faces,\ncompared to training on a single face dataset alone.",
          "link": "http://arxiv.org/abs/2106.08091",
          "publishedOn": "2021-06-16T01:21:06.152Z",
          "wordCount": 628,
          "title": "Generating Thermal Human Faces for Physiological Assessment Using Thermal Sensor Auxiliary Labels. (arXiv:2106.08091v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08285",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Prangemeier_T/0/1/0/all/0/1\">Tim Prangemeier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reich_C/0/1/0/all/0/1\">Christoph Reich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wildner_C/0/1/0/all/0/1\">Christian Wildner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koeppl_H/0/1/0/all/0/1\">Heinz Koeppl</a>",
          "description": "Time-lapse fluorescent microscopy (TLFM) combined with predictive\nmathematical modelling is a powerful tool to study the inherently dynamic\nprocesses of life on the single-cell level. Such experiments are costly,\ncomplex and labour intensive. A complimentary approach and a step towards\ncompletely in silico experiments, is to synthesise the imagery itself. Here, we\npropose Multi-StyleGAN as a descriptive approach to simulate time-lapse\nfluorescence microscopy imagery of living cells, based on a past experiment.\nThis novel generative adversarial network synthesises a multi-domain sequence\nof consecutive timesteps. We showcase Multi-StyleGAN on imagery of multiple\nlive yeast cells in microstructured environments and train on a dataset\nrecorded in our laboratory. The simulation captures underlying biophysical\nfactors and time dependencies, such as cell morphology, growth, physical\ninteractions, as well as the intensity of a fluorescent reporter protein. An\nimmediate application is to generate additional training and validation data\nfor feature extraction algorithms or to aid and expedite development of\nadvanced experimental techniques such as online monitoring or control of cells.\n\nCode and dataset is available at\nhttps://git.rwth-aachen.de/bcs/projects/tp/multi-stylegan.",
          "link": "http://arxiv.org/abs/2106.08285",
          "publishedOn": "2021-06-16T01:21:06.132Z",
          "wordCount": 640,
          "title": "Multi-StyleGAN: Towards Image-Based Simulation of Time-Lapse Live-Cell Microscopy. (arXiv:2106.08285v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2007.06837",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_N/0/1/0/all/0/1\">Nan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_X/0/1/0/all/0/1\">Xiaochun Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Duo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_D/0/1/0/all/0/1\">Dongrui Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1\">Zhimin Tang</a>",
          "description": "Many meta-learning methods are proposed for few-shot detection. However,\nprevious most methods have two main problems, poor detection APs, and strong\nbias because of imbalance and insufficient datasets. Previous works mainly\nalleviate these issues by additional datasets, multi-relation attention\nmechanisms and sub-modules. However, they require more cost. In this work, for\nmeta-learning, we find that the main challenges focus on related or irrelevant\nsemantic features between categories. Therefore, based on semantic features, we\npropose a Top-C classification loss (i.e., TCL-C) for classification task and a\ncategory-based grouping mechanism for category-based meta-features obtained by\nthe meta-model. The TCL-C exploits the true-label prediction and the most\nlikely C-1 false classification predictions to improve detection performance on\nfew-shot classes. According to similar appearance (i.e., visual appearance,\nshape, and limbs etc.) and environment in which objects often appear, the\ncategory-based grouping mechanism splits categories into disjoint groups to\nmake similar semantic features more compact between categories within a group\nand obtain more significant difference between groups, alleviating the strong\nbias problem and further improving detection APs. The whole training consists\nof the base model and the fine-tuning phases. According to grouping mechanism,\nwe group the meta-features vectors obtained by meta-model, so that the\ndistribution difference between groups is obvious, and the one within each\ngroup is less. Extensive experiments on Pascal VOC dataset demonstrate that\nours which combines the TCL-C with category-based grouping significantly\noutperforms previous state-of-the-art methods for few-shot detection. Compared\nwith previous competitive baseline, ours improves detection APs by almost 4%\nfor few-shot detection.",
          "link": "http://arxiv.org/abs/2007.06837",
          "publishedOn": "2021-06-16T01:21:06.125Z",
          "wordCount": 762,
          "title": "Top-Related Meta-Learning Method for Few-Shot Object Detection. (arXiv:2007.06837v6 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08323",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Edstedt_J/0/1/0/all/0/1\">Johan Edstedt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karlsson_J/0/1/0/all/0/1\">Johan Karlsson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benavente_F/0/1/0/all/0/1\">Francisca Benavente</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Novak_A/0/1/0/all/0/1\">Anette Novak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berg_A/0/1/0/all/0/1\">Amanda Berg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Felsberg_M/0/1/0/all/0/1\">Michael Felsberg</a>",
          "description": "Automatically identifying harmful content in video is an important task with\na wide range of applications. However, due to the difficulty of collecting\nhigh-quality labels as well as demanding computational requirements, the task\nhas not had a satisfying general approach. Typically, only small subsets of the\nproblem are considered, such as identifying violent content. In cases where the\ngeneral problem is tackled, rough approximations and simplifications are made\nto deal with the lack of labels and computational complexity. In this work, we\nidentify and tackle the two main obstacles. First, we create a dataset of\napproximately 4000 video clips, annotated by professionals in the field.\nSecondly, we demonstrate that advances in video recognition enable training\nmodels on our dataset that consider the full context of the scene. We conduct\nan in-depth study on our modeling choices and find that we greatly benefit from\ncombining the visual and audio modality and that pretraining on large-scale\nvideo recognition datasets and class balanced sampling further improves\nperformance. We additionally perform a qualitative study that reveals the\nheavily multi-modal nature of our dataset. Our dataset will be made available\nupon publication.",
          "link": "http://arxiv.org/abs/2106.08323",
          "publishedOn": "2021-06-16T01:21:06.118Z",
          "wordCount": 629,
          "title": "Is this Harmful? Learning to Predict Harmfulness Ratings from Video. (arXiv:2106.08323v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07959",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yibo Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1\">Yiming Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_Z/0/1/0/all/0/1\">Zhiyang Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haidi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_W/0/1/0/all/0/1\">Wenhua Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1\">Mingliang Xu</a>",
          "description": "Defect detection and classification technology has changed from traditional\nartificial visual inspection to current intelligent automated inspection, but\nmost of the current defect detection methods are training related detection\nmodels based on a data-driven approach, taking into account the difficulty of\ncollecting some sample data in the industrial field. We apply zero-shot\nlearning technology to the industrial field. Aiming at the problem of the\nexisting \"Latent Feature Guide Attribute Attention\" (LFGAA) zero-shot image\nclassification network, the output latent attributes and artificially defined\nattributes are different in the semantic space, which leads to the problem of\nmodel performance degradation, proposed an LGFAA network based on semantic\nfeedback, and improved model performance by constructing semantic embedded\nmodules and feedback mechanisms. At the same time, for the common domain shift\nproblem in zero-shot learning, based on the idea of co-training algorithm using\nthe difference information between different views of data to learn from each\nother, we propose an Ensemble Co-training algorithm, which adaptively reduces\nthe prediction error in image tag embedding from multiple angles. Various\nexperiments conducted on the zero-shot dataset and the cylinder liner dataset\nin the industrial field provide competitive results.",
          "link": "http://arxiv.org/abs/2106.07959",
          "publishedOn": "2021-06-16T01:21:06.111Z",
          "wordCount": 640,
          "title": "Zero-sample surface defect detection and classification based on semantic feedback neural network. (arXiv:2106.07959v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07881",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Reul_C/0/1/0/all/0/1\">Christian Reul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wick_C/0/1/0/all/0/1\">Christoph Wick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noth_M/0/1/0/all/0/1\">Maximilian N&#xf6;th</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buttner_A/0/1/0/all/0/1\">Andreas B&#xfc;ttner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wehner_M/0/1/0/all/0/1\">Maximilian Wehner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Springmann_U/0/1/0/all/0/1\">Uwe Springmann</a>",
          "description": "In order to apply Optical Character Recognition (OCR) to historical printings\nof Latin script fully automatically, we report on our efforts to construct a\nwidely-applicable polyfont recognition model yielding text with a Character\nError Rate (CER) around 2% when applied out-of-the-box. Moreover, we show how\nthis model can be further finetuned to specific classes of printings with\nlittle manual and computational effort. The mixed or polyfont model is trained\non a wide variety of materials, in terms of age (from the 15th to the 19th\ncentury), typography (various types of Fraktur and Antiqua), and languages\n(among others, German, Latin, and French). To optimize the results we combined\nestablished techniques of OCR training like pretraining, data augmentation, and\nvoting. In addition, we used various preprocessing methods to enrich the\ntraining data and obtain more robust models. We also implemented a two-stage\napproach which first trains on all available, considerably unbalanced data and\nthen refines the output by training on a selected more balanced subset.\nEvaluations on 29 previously unseen books resulted in a CER of 1.73%,\noutperforming a widely used standard model with a CER of 2.84% by almost 40%.\nTraining a more specialized model for some unseen Early Modern Latin books\nstarting from our mixed model led to a CER of 1.47%, an improvement of up to\n50% compared to training from scratch and up to 30% compared to training from\nthe aforementioned standard model. Our new mixed model is made openly available\nto the community.",
          "link": "http://arxiv.org/abs/2106.07881",
          "publishedOn": "2021-06-16T01:21:06.103Z",
          "wordCount": 693,
          "title": "Mixed Model OCR Training on Historical Latin Script for Out-of-the-Box Recognition and Finetuning. (arXiv:2106.07881v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2012.09760",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_K/0/1/0/all/0/1\">Kevin Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lijuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zicheng Liu</a>",
          "description": "We present a new method, called MEsh TRansfOrmer (METRO), to reconstruct 3D\nhuman pose and mesh vertices from a single image. Our method uses a transformer\nencoder to jointly model vertex-vertex and vertex-joint interactions, and\noutputs 3D joint coordinates and mesh vertices simultaneously. Compared to\nexisting techniques that regress pose and shape parameters, METRO does not rely\non any parametric mesh models like SMPL, thus it can be easily extended to\nother objects such as hands. We further relax the mesh topology and allow the\ntransformer self-attention mechanism to freely attend between any two vertices,\nmaking it possible to learn non-local relationships among mesh vertices and\njoints. With the proposed masked vertex modeling, our method is more robust and\neffective in handling challenging situations like partial occlusions. METRO\ngenerates new state-of-the-art results for human mesh reconstruction on the\npublic Human3.6M and 3DPW datasets. Moreover, we demonstrate the\ngeneralizability of METRO to 3D hand reconstruction in the wild, outperforming\nexisting state-of-the-art methods on FreiHAND dataset. Code and pre-trained\nmodels are available at https://github.com/microsoft/MeshTransformer.",
          "link": "http://arxiv.org/abs/2012.09760",
          "publishedOn": "2021-06-16T01:21:06.083Z",
          "wordCount": 642,
          "title": "End-to-End Human Pose and Mesh Reconstruction with Transformers. (arXiv:2012.09760v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.04262",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lo_S/0/1/0/all/0/1\">Shao-Yuan Lo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valanarasu_J/0/1/0/all/0/1\">Jeya Maria Jose Valanarasu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patel_V/0/1/0/all/0/1\">Vishal M. Patel</a>",
          "description": "Adversarial robustness of deep neural networks is an extensively studied\nproblem in the literature and various methods have been proposed to defend\nagainst adversarial images. However, only a handful of defense methods have\nbeen developed for defending against attacked videos. In this paper, we propose\na novel Over-and-Under complete restoration network for Defending against\nadversarial videos (OUDefend). Most restoration networks adopt an\nencoder-decoder architecture that first shrinks spatial dimension then expands\nit back. This approach learns undercomplete representations, which have large\nreceptive fields to collect global information but overlooks local details. On\nthe other hand, overcomplete representations have opposite properties. Hence,\nOUDefend is designed to balance local and global features by learning those two\nrepresentations. We attach OUDefend to target video recognition models as a\nfeature restoration block and train the entire network end-to-end. Experimental\nresults show that the defenses focusing on images may be ineffective to videos,\nwhile OUDefend enhances robustness against different types of adversarial\nvideos, ranging from additive attacks, multiplicative attacks to physically\nrealizable attacks. Code: https://github.com/shaoyuanlo/OUDefend",
          "link": "http://arxiv.org/abs/2012.04262",
          "publishedOn": "2021-06-16T01:21:06.062Z",
          "wordCount": 647,
          "title": "Overcomplete Representations Against Adversarial Videos. (arXiv:2012.04262v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.07916",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Duboudin_T/0/1/0/all/0/1\">Thomas Duboudin</a> (imagine), <a href=\"http://arxiv.org/find/cs/1/au:+Dellandrea_E/0/1/0/all/0/1\">Emmanuel Dellandr&#xe9;a</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abgrall_C/0/1/0/all/0/1\">Corentin Abgrall</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henaff_G/0/1/0/all/0/1\">Gilles H&#xe9;naff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Liming Chen</a>",
          "description": "Traditional deep learning algorithms often fail to generalize when they are\ntested outside of the domain of training data. Because data distributions can\nchange dynamically in real-life applications once a learned model is deployed,\nin this paper we are interested in single-source domain generalization (SDG)\nwhich aims to develop deep learning algorithms able to generalize from a single\ntraining domain where no information about the test domain is available at\ntraining time. Firstly, we design two simple MNISTbased SDG benchmarks, namely\nMNIST Color SDG-MP and MNIST Color SDG-UP, which highlight the two different\nfundamental SDG issues of increasing difficulties: 1) a class-correlated\npattern in the training domain is missing (SDG-MP), or 2) uncorrelated with the\nclass (SDG-UP), in the testing data domain. This is in sharp contrast with the\ncurrent domain generalization (DG) benchmarks which mix up different\ncorrelation and variation factors and thereby make hard to disentangle success\nor failure factors when benchmarking DG algorithms. We further evaluate several\nstate-of-the-art SDG algorithms through our simple benchmark, namely MNIST\nColor SDG-MP, and show that the issue SDG-MP is largely unsolved despite of a\ndecade of efforts in developing DG algorithms. Finally, we also propose a\npartially reversed contrastive loss to encourage intra-class diversity and find\nless strongly correlated patterns, to deal with SDG-MP and show that the\nproposed approach is very effective on our MNIST Color SDG-MP benchmark.",
          "link": "http://arxiv.org/abs/2106.07916",
          "publishedOn": "2021-06-16T01:21:06.047Z",
          "wordCount": 678,
          "title": "Encouraging Intra-Class Diversity Through a Reverse Contrastive Loss for Better Single-Source Domain Generalization. (arXiv:2106.07916v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08049",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Drozdowski_P/0/1/0/all/0/1\">Pawel Drozdowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rathgeb_C/0/1/0/all/0/1\">Christian Rathgeb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Busch_C/0/1/0/all/0/1\">Christoph Busch</a>",
          "description": "Recently, different researchers have found that the gallery composition of a\nface database can induce performance differentials to facial identification\nsystems in which a probe image is compared against up to all stored reference\nimages to reach a biometric decision. This negative effect is referred to as\n\"watchlist imbalance effect\". In this work, we present a method to\ntheoretically estimate said effect for a biometric identification system given\nits verification performance across demographic groups and the composition of\nthe used gallery. Further, we report results for identification experiments on\ndifferently composed demographic subsets, i.e. females and males, of the public\nacademic MORPH database using the open-source ArcFace face recognition system.\nIt is shown that the database composition has a huge impact on performance\ndifferentials in biometric identification systems, even if performance\ndifferentials are less pronounced in the verification scenario. This study\nrepresents the first detailed analysis of the watchlist imbalance effect which\nis expected to be of high interest for future research in the field of facial\nrecognition.",
          "link": "http://arxiv.org/abs/2106.08049",
          "publishedOn": "2021-06-16T01:21:05.982Z",
          "wordCount": 608,
          "title": "Demographic Fairness in Face Identification: The Watchlist Imbalance Effect. (arXiv:2106.08049v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08107",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Stucker_C/0/1/0/all/0/1\">Corinne Stucker</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Schindler_K/0/1/0/all/0/1\">Konrad Schindler</a>",
          "description": "Modern optical satellite sensors enable high-resolution stereo reconstruction\nfrom space. But the challenging imaging conditions when observing the Earth\nfrom space push stereo matching to its limits. In practice, the resulting\ndigital surface models (DSMs) are fairly noisy and often do not attain the\naccuracy needed for high-resolution applications such as 3D city modeling.\nArguably, stereo correspondence based on low-level image similarity is\ninsufficient and should be complemented with a-priori knowledge about the\nexpected surface geometry beyond basic local smoothness. To that end, we\nintroduce ResDepth, a convolutional neural network that learns such an\nexpressive geometric prior from example data. ResDepth refines an initial, raw\nstereo DSM while conditioning the refinement on the images. I.e., it acts as a\nsmart, learned post-processing filter and can seamlessly complement any stereo\nmatching pipeline. In a series of experiments, we find that the proposed method\nconsistently improves stereo DSMs both quantitatively and qualitatively. We\nshow that the prior encoded in the network weights captures meaningful\ngeometric characteristics of urban design, which also generalize across\ndifferent districts and even from one city to another. Moreover, we demonstrate\nthat, by training on a variety of stereo pairs, ResDepth can acquire a\nsufficient degree of invariance against variations in imaging conditions and\nacquisition geometry.",
          "link": "http://arxiv.org/abs/2106.08107",
          "publishedOn": "2021-06-16T01:21:05.973Z",
          "wordCount": 651,
          "title": "ResDepth: A Deep Prior For 3D Reconstruction From High-resolution Satellite Images. (arXiv:2106.08107v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07998",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Minderer_M/0/1/0/all/0/1\">Matthias Minderer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Djolonga_J/0/1/0/all/0/1\">Josip Djolonga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Romijnders_R/0/1/0/all/0/1\">Rob Romijnders</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hubis_F/0/1/0/all/0/1\">Frances Hubis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_X/0/1/0/all/0/1\">Xiaohua Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Houlsby_N/0/1/0/all/0/1\">Neil Houlsby</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_D/0/1/0/all/0/1\">Dustin Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lucic_M/0/1/0/all/0/1\">Mario Lucic</a>",
          "description": "Accurate estimation of predictive uncertainty (model calibration) is\nessential for the safe application of neural networks. Many instances of\nmiscalibration in modern neural networks have been reported, suggesting a trend\nthat newer, more accurate models produce poorly calibrated predictions. Here,\nwe revisit this question for recent state-of-the-art image classification\nmodels. We systematically relate model calibration and accuracy, and find that\nthe most recent models, notably those not using convolutions, are among the\nbest calibrated. Trends observed in prior model generations, such as decay of\ncalibration with distribution shift or model size, are less pronounced in\nrecent architectures. We also show that model size and amount of pretraining do\nnot fully explain these differences, suggesting that architecture is a major\ndeterminant of calibration properties.",
          "link": "http://arxiv.org/abs/2106.07998",
          "publishedOn": "2021-06-16T01:21:05.905Z",
          "wordCount": 560,
          "title": "Revisiting the Calibration of Modern Neural Networks. (arXiv:2106.07998v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07852",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhenyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1\">Yanhao Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1\">Renwang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tai_Y/0/1/0/all/0/1\">Ying Tai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1\">Yan Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jian Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chengjie Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jilin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Feiyue Huang</a>",
          "description": "Non-parametric face modeling aims to reconstruct 3D face only from images\nwithout shape assumptions. While plausible facial details are predicted, the\nmodels tend to over-depend on local color appearance and suffer from ambiguous\nnoise. To address such problem, this paper presents a novel Learning to\nAggregate and Personalize (LAP) framework for unsupervised robust 3D face\nmodeling. Instead of using controlled environment, the proposed method\nimplicitly disentangles ID-consistent and scene-specific face from\nunconstrained photo set. Specifically, to learn ID-consistent face, LAP\nadaptively aggregates intrinsic face factors of an identity based on a novel\ncurriculum learning approach with relaxed consistency loss. To adapt the face\nfor a personalized scene, we propose a novel attribute-refining network to\nmodify ID-consistent face with target attribute and details. Based on the\nproposed method, we make unsupervised 3D face modeling benefit from meaningful\nimage facial structure and possibly higher resolutions. Extensive experiments\non benchmarks show LAP recovers superior or competitive face shape and texture,\ncompared with state-of-the-art (SOTA) methods with or without prior and\nsupervision.",
          "link": "http://arxiv.org/abs/2106.07852",
          "publishedOn": "2021-06-16T01:21:05.888Z",
          "wordCount": 626,
          "title": "Learning to Aggregate and Personalize 3D Face from In-the-Wild Photo Collection. (arXiv:2106.07852v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08267",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gondere_M/0/1/0/all/0/1\">Mesay Samuel Gondere</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidt_Thieme_L/0/1/0/all/0/1\">Lars Schmidt-Thieme</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_D/0/1/0/all/0/1\">Durga Prasad Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scholz_R/0/1/0/all/0/1\">Randolf Scholz</a>",
          "description": "Handwritten digit recognition is one of the extensively studied area in\nmachine learning. Apart from the wider research on handwritten digit\nrecognition on MNIST dataset, there are many other research works on various\nscript recognition. However, it is not very common for multi-script digit\nrecognition which encourage the development of robust and multipurpose systems.\nAdditionally working on multi-script digit recognition enables multi-task\nlearning, considering the script classification as a related task for instance.\nIt is evident that multi-task learning improves model performance through\ninductive transfer using the information contained in related tasks. Therefore,\nin this study multi-script handwritten digit recognition using multi-task\nlearning will be investigated. As a specific case of demonstrating the solution\nto the problem, Amharic handwritten character recognition will also be\nexperimented. The handwritten digits of three scripts including Latin, Arabic\nand Kannada are studied to show that multi-task models with reformulation of\nthe individual tasks have shown promising results. In this study a novel way of\nusing the individual tasks predictions was proposed to help classification\nperformance and regularize the different loss for the purpose of the main task.\nThis finding has outperformed the baseline and the conventional multi-task\nlearning models. More importantly, it avoided the need for weighting the\ndifferent losses of the tasks, which is one of the challenges in multi-task\nlearning.",
          "link": "http://arxiv.org/abs/2106.08267",
          "publishedOn": "2021-06-16T01:21:05.878Z",
          "wordCount": 651,
          "title": "Multi-script Handwritten Digit Recognition Using Multi-task Learning. (arXiv:2106.08267v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08261",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bear_D/0/1/0/all/0/1\">Daniel M. Bear</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_E/0/1/0/all/0/1\">Elias Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mrowca_D/0/1/0/all/0/1\">Damian Mrowca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Binder_F/0/1/0/all/0/1\">Felix J. Binder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tung_H/0/1/0/all/0/1\">Hsiau-Yu Fish Tung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pramod_R/0/1/0/all/0/1\">R.T. Pramod</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holdaway_C/0/1/0/all/0/1\">Cameron Holdaway</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_S/0/1/0/all/0/1\">Sirui Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_K/0/1/0/all/0/1\">Kevin Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1\">Li Fei-Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanwisher_N/0/1/0/all/0/1\">Nancy Kanwisher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1\">Joshua B. Tenenbaum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamins_D/0/1/0/all/0/1\">Daniel L.K. Yamins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_J/0/1/0/all/0/1\">Judith E. Fan</a>",
          "description": "While machine learning algorithms excel at many challenging visual tasks, it\nis unclear that they can make predictions about commonplace real world physical\nevents. Here, we present a visual and physical prediction benchmark that\nprecisely measures this capability. In realistically simulating a wide variety\nof physical phenomena -- rigid and soft-body collisions, stable multi-object\nconfigurations, rolling and sliding, projectile motion -- our dataset presents\na more comprehensive challenge than existing benchmarks. Moreover, we have\ncollected human responses for our stimuli so that model predictions can be\ndirectly compared to human judgments. We compare an array of algorithms --\nvarying in their architecture, learning objective, input-output structure, and\ntraining data -- on their ability to make diverse physical predictions. We find\nthat graph neural networks with access to the physical state best capture human\nbehavior, whereas among models that receive only visual input, those with\nobject-centric representations or pretraining do best but fall far short of\nhuman accuracy. This suggests that extracting physically meaningful\nrepresentations of scenes is the main bottleneck to achieving human-like visual\nprediction. We thus demonstrate how our benchmark can identify areas for\nimprovement and measure progress on this key aspect of physical understanding.",
          "link": "http://arxiv.org/abs/2106.08261",
          "publishedOn": "2021-06-16T01:21:05.871Z",
          "wordCount": 664,
          "title": "Physion: Evaluating Physical Prediction from Vision in Humans and Machines. (arXiv:2106.08261v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07879",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Arefeen_M/0/1/0/all/0/1\">Md Adnan Arefeen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nimi_S/0/1/0/all/0/1\">Sumaiya Tabassum Nimi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Uddin_M/0/1/0/all/0/1\">Md Yusuf Sarwar Uddin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_Z/0/1/0/all/0/1\">Zhu Li</a>",
          "description": "In this paper, we propose a transfer-learning based model construction\ntechnique for the aerial scene classification problem. The core of our\ntechnique is a layer selection strategy, named ReLU-Based Feature Fusion\n(RBFF), that extracts feature maps from a pretrained CNN-based single-object\nimage classification model, namely MobileNetV2, and constructs a model for the\naerial scene classification task. RBFF stacks features extracted from the batch\nnormalization layer of a few selected blocks of MobileNetV2, where the\ncandidate blocks are selected based on the characteristics of the ReLU\nactivation layers present in those blocks. The feature vector is then\ncompressed into a low-dimensional feature space using dimension reduction\nalgorithms on which we train a low-cost SVM classifier for the classification\nof the aerial images. We validate our choice of selected features based on the\nsignificance of the extracted features with respect to our classification\npipeline. RBFF remarkably does not involve any training of the base CNN model\nexcept for a few parameters for the classifier, which makes the technique very\ncost-effective for practical deployments. The constructed model despite being\nlightweight outperforms several recently proposed models in terms of accuracy\nfor a number of aerial scene datasets.",
          "link": "http://arxiv.org/abs/2106.07879",
          "publishedOn": "2021-06-16T01:21:05.863Z",
          "wordCount": 647,
          "title": "A Lightweight ReLU-Based Feature Fusion for Aerial Scene Classification. (arXiv:2106.07879v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08254",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bao_H/0/1/0/all/0/1\">Hangbo Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_L/0/1/0/all/0/1\">Li Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>",
          "description": "We introduce a self-supervised vision representation model BEiT, which stands\nfor Bidirectional Encoder representation from Image Transformers. Following\nBERT developed in the natural language processing area, we propose a masked\nimage modeling task to pretrain vision Transformers. Specifically, each image\nhas two views in our pre-training, i.e, image patches (such as 16x16 pixels),\nand visual tokens (i.e., discrete tokens). We first \"tokenize\" the original\nimage into visual tokens. Then we randomly mask some image patches and fed them\ninto the backbone Transformer. The pre-training objective is to recover the\noriginal visual tokens based on the corrupted image patches. After pre-training\nBEiT, we directly fine-tune the model parameters on downstream tasks by\nappending task layers upon the pretrained encoder. Experimental results on\nimage classification and semantic segmentation show that our model achieves\ncompetitive results with previous pre-training methods. For example, base-size\nBEiT achieves 83.2% top-1 accuracy on ImageNet-1K, significantly outperforming\nfrom-scratch DeiT training (81.8%) with the same setup. Moreover, large-size\nBEiT obtains 86.3% only using ImageNet-1K, even outperforming ViT-L with\nsupervised pre-training on ImageNet-22K (85.2%). The code and pretrained models\nare available at https://aka.ms/beit.",
          "link": "http://arxiv.org/abs/2106.08254",
          "publishedOn": "2021-06-16T01:21:05.844Z",
          "wordCount": 625,
          "title": "BEiT: BERT Pre-Training of Image Transformers. (arXiv:2106.08254v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08038",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ashukha_A/0/1/0/all/0/1\">Arsenii Ashukha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Atanov_A/0/1/0/all/0/1\">Andrei Atanov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vetrov_D/0/1/0/all/0/1\">Dmitry Vetrov</a>",
          "description": "Averaging predictions over a set of models -- an ensemble -- is widely used\nto improve predictive performance and uncertainty estimation of deep learning\nmodels. At the same time, many machine learning systems, such as search,\nmatching, and recommendation systems, heavily rely on embeddings.\nUnfortunately, due to misalignment of features of independently trained models,\nembeddings, cannot be improved with a naive deep ensemble like approach. In\nthis work, we look at the ensembling of representations and propose mean\nembeddings with test-time augmentation (MeTTA) simple yet well-performing\nrecipe for ensembling representations. Empirically we demonstrate that MeTTA\nsignificantly boosts the quality of linear evaluation on ImageNet for both\nsupervised and self-supervised models. Even more exciting, we draw connections\nbetween MeTTA, image retrieval, and transformation invariant models. We believe\nthat spreading the success of ensembles to inference higher-quality\nrepresentations is the important step that will open many new applications of\nensembling.",
          "link": "http://arxiv.org/abs/2106.08038",
          "publishedOn": "2021-06-16T01:21:05.837Z",
          "wordCount": 580,
          "title": "Mean Embeddings with Test-Time Data Augmentation for Ensembling of Representations. (arXiv:2106.08038v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07903",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1\">Jaemoo Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_C/0/1/0/all/0/1\">Changyeon Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bae_J/0/1/0/all/0/1\">Jeongwoo Bae</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_M/0/1/0/all/0/1\">Myungjoo Kang</a>",
          "description": "Out-of-distribution (OOD) detection is an important task in machine learning\nsystems for ensuring their reliability and safety. Deep probabilistic\ngenerative models facilitate OOD detection by estimating the likelihood of a\ndata sample. However, such models frequently assign a suspiciously high\nlikelihood to a specific outlier. Several recent works have addressed this\nissue by training a neural network with auxiliary outliers, which are generated\nby perturbing the input data. In this paper, we discover that these approaches\nfail for certain OOD datasets. Thus, we suggest a new detection metric that\noperates without outlier exposure. We observe that our metric is robust to\ndiverse variations of an image compared to the previous outlier-exposing\nmethods. Furthermore, our proposed score requires neither auxiliary models nor\nadditional training. Instead, this paper utilizes the likelihood ratio\nstatistic in a new perspective to extract genuine properties from the given\nsingle deep probabilistic generative model. We also apply a novel numerical\napproximation to enable fast implementation. Finally, we demonstrate\ncomprehensive experiments on various probabilistic generative models and show\nthat our method achieves state-of-the-art performance.",
          "link": "http://arxiv.org/abs/2106.07903",
          "publishedOn": "2021-06-16T01:21:05.830Z",
          "wordCount": 612,
          "title": "Robust Out-of-Distribution Detection on Deep Probabilistic Generative Models. (arXiv:2106.07903v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08265",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roth_K/0/1/0/all/0/1\">Karsten Roth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pemula_L/0/1/0/all/0/1\">Latha Pemula</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zepeda_J/0/1/0/all/0/1\">Joaquin Zepeda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1\">Bernhard Sch&#xf6;lkopf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brox_T/0/1/0/all/0/1\">Thomas Brox</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gehler_P/0/1/0/all/0/1\">Peter Gehler</a>",
          "description": "Being able to spot defective parts is a critical component in large-scale\nindustrial manufacturing. A particular challenge that we address in this work\nis the cold-start problem: fit a model using nominal (non-defective) example\nimages only. While handcrafted solutions per class are possible, the goal is to\nbuild systems that work well simultaneously on many different tasks\nautomatically. The best peforming approaches combine embeddings from ImageNet\nmodels with an outlier detection model. In this paper, we extend on this line\nof work and propose PatchCore, which uses a maximally representative memory\nbank of nominal patch-features. PatchCore offers competitive inference times\nwhile achieving state-of-the-art performance for both detection and\nlocalization. On the standard dataset MVTec AD, PatchCore achieves an\nimage-level anomaly detection AUROC score of $99.1\\%$, more than halving the\nerror compared to the next best competitor. We further report competitive\nresults on two additional datasets and also find competitive results in the few\nsamples regime.",
          "link": "http://arxiv.org/abs/2106.08265",
          "publishedOn": "2021-06-16T01:21:05.822Z",
          "wordCount": 587,
          "title": "Towards Total Recall in Industrial Anomaly Detection. (arXiv:2106.08265v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08045",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hofer_T/0/1/0/all/0/1\">Timon H&#xf6;fer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shamsafar_F/0/1/0/all/0/1\">Faranak Shamsafar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benbarka_N/0/1/0/all/0/1\">Nuri Benbarka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zell_A/0/1/0/all/0/1\">Andreas Zell</a>",
          "description": "Bin picking is a core problem in industrial environments and robotics, with\nits main module as 6D pose estimation. However, industrial depth sensors have a\nlack of accuracy when it comes to small objects. Therefore, we propose a\nframework for pose estimation in highly cluttered scenes with small objects,\nwhich mainly relies on RGB data and makes use of depth information only for\npose refinement. In this work, we compare synthetic data generation approaches\nfor object detection and pose estimation and introduce a pose filtering\nalgorithm that determines the most accurate estimated poses. We will make our",
          "link": "http://arxiv.org/abs/2106.08045",
          "publishedOn": "2021-06-16T01:21:05.815Z",
          "wordCount": 545,
          "title": "Object detection and Autoencoder-based 6D pose estimation for highly cluttered Bin Picking. (arXiv:2106.08045v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08176",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Wood_D/0/1/0/all/0/1\">David A. Wood</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kafiabadi_S/0/1/0/all/0/1\">Sina Kafiabadi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Busaidi_A/0/1/0/all/0/1\">Ayisha Al Busaidi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Guilhem_E/0/1/0/all/0/1\">Emily Guilhem</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Montvila_A/0/1/0/all/0/1\">Antanas Montvila</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Agarwal_S/0/1/0/all/0/1\">Siddharth Agarwal</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lynch_J/0/1/0/all/0/1\">Jeremy Lynch</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Townend_M/0/1/0/all/0/1\">Matthew Townend</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Barker_G/0/1/0/all/0/1\">Gareth Barker</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ourselin_S/0/1/0/all/0/1\">Sebastien Ourselin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cole_J/0/1/0/all/0/1\">James H. Cole</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Booth_T/0/1/0/all/0/1\">Thomas C. Booth</a>",
          "description": "The growing demand for head magnetic resonance imaging (MRI) examinations,\nalong with a global shortage of radiologists, has led to an increase in the\ntime taken to report head MRI scans around the world. For many neurological\nconditions, this delay can result in increased morbidity and mortality. An\nautomated triaging tool could reduce reporting times for abnormal examinations\nby identifying abnormalities at the time of imaging and prioritizing the\nreporting of these scans. In this work, we present a convolutional neural\nnetwork for detecting clinically-relevant abnormalities in\n$\\text{T}_2$-weighted head MRI scans. Using a validated neuroradiology report\nclassifier, we generated a labelled dataset of 43,754 scans from two large UK\nhospitals for model training, and demonstrate accurate classification (area\nunder the receiver operating curve (AUC) = 0.943) on a test set of 800 scans\nlabelled by a team of neuroradiologists. Importantly, when trained on scans\nfrom only a single hospital the model generalized to scans from the other\nhospital ($\\Delta$AUC $\\leq$ 0.02). A simulation study demonstrated that our\nmodel would reduce the mean reporting time for abnormal examinations from 28\ndays to 14 days and from 9 days to 5 days at the two hospitals, demonstrating\nfeasibility for use in a clinical triage environment.",
          "link": "http://arxiv.org/abs/2106.08176",
          "publishedOn": "2021-06-16T01:21:05.796Z",
          "wordCount": 680,
          "title": "Automated triaging of head MRI examinations using convolutional neural networks. (arXiv:2106.08176v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08148",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yin_X/0/1/0/all/0/1\">Xiangnan Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1\">Di Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Z/0/1/0/all/0/1\">Zehua Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yunhong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Liming Chen</a>",
          "description": "Although much progress has been made recently in 3D face reconstruction, most\nprevious work has been devoted to predicting accurate and fine-grained 3D\nshapes. In contrast, relatively little work has focused on generating\nhigh-fidelity face textures. Compared with the prosperity of photo-realistic 2D\nface image generation, high-fidelity 3D face texture generation has yet to be\nstudied. In this paper, we proposed a novel UV map generation model that\npredicts the UV map from a single face image. The model consists of a UV\nsampler and a UV generator. By selectively sampling the input face image's\npixels and adjusting their relative locations, the UV sampler generates an\nincomplete UV map that could faithfully reconstruct the original face. Missing\ntextures in the incomplete UV map are further full-filled by the UV generator.\nThe training is based on pseudo ground truth blended by the 3DMM texture and\nthe input face texture, thus weakly supervised. To deal with the artifacts in\nthe imperfect pseudo UV map, multiple partial UV map discriminators are\nleveraged.",
          "link": "http://arxiv.org/abs/2106.08148",
          "publishedOn": "2021-06-16T01:21:05.789Z",
          "wordCount": 601,
          "title": "Weakly-Supervised Photo-realistic Texture Generation for 3D Face Reconstruction. (arXiv:2106.08148v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08174",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Avisdris_N/0/1/0/all/0/1\">Netanell Avisdris</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yehuda_B/0/1/0/all/0/1\">Bossmat Yehuda</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ben_Zvi_O/0/1/0/all/0/1\">Ori Ben-Zvi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Link_Sourani_D/0/1/0/all/0/1\">Daphna Link-Sourani</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ben_Sira_L/0/1/0/all/0/1\">Liat Ben-Sira</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Miller_E/0/1/0/all/0/1\">Elka Miller</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zharkov_E/0/1/0/all/0/1\">Elena Zharkov</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bashat_D/0/1/0/all/0/1\">Dafna Ben Bashat</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Joskowicz_L/0/1/0/all/0/1\">Leo Joskowicz</a>",
          "description": "Timely, accurate and reliable assessment of fetal brain development is\nessential to reduce short and long-term risks to fetus and mother. Fetal MRI is\nincreasingly used for fetal brain assessment. Three key biometric linear\nmeasurements important for fetal brain evaluation are Cerebral Biparietal\nDiameter (CBD), Bone Biparietal Diameter (BBD), and Trans-Cerebellum Diameter\n(TCD), obtained manually by expert radiologists on reference slices, which is\ntime consuming and prone to human error. The aim of this study was to develop a\nfully automatic method computing the CBD, BBD and TCD measurements from fetal\nbrain MRI. The input is fetal brain MRI volumes which may include the fetal\nbody and the mother's abdomen. The outputs are the measurement values and\nreference slices on which the measurements were computed. The method, which\nfollows the manual measurements principle, consists of five stages: 1)\ncomputation of a Region Of Interest that includes the fetal brain with an\nanisotropic 3D U-Net classifier; 2) reference slice selection with a\nConvolutional Neural Network; 3) slice-wise fetal brain structures segmentation\nwith a multiclass U-Net classifier; 4) computation of the fetal brain\nmidsagittal line and fetal brain orientation, and; 5) computation of the\nmeasurements. Experimental results on 214 volumes for CBD, BBD and TCD\nmeasurements yielded a mean $L_1$ difference of 1.55mm, 1.45mm and 1.23mm\nrespectively, and a Bland-Altman 95% confidence interval ($CI_{95}$) of 3.92mm,\n3.98mm and 2.25mm respectively. These results are similar to the manual\ninter-observer variability. The proposed automatic method for computing\nbiometric linear measurements of the fetal brain from MR imaging achieves human\nlevel performance. It has the potential of being a useful method for the\nassessment of fetal brain biometry in normal and pathological cases, and of\nimproving routine clinical practice.",
          "link": "http://arxiv.org/abs/2106.08174",
          "publishedOn": "2021-06-16T01:21:05.781Z",
          "wordCount": 755,
          "title": "Automatic linear measurements of the fetal brain on MRI with deep neural networks. (arXiv:2106.08174v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07867",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_M/0/1/0/all/0/1\">Mohit Agrawal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehrotra_P/0/1/0/all/0/1\">Pragyan Mehrotra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_R/0/1/0/all/0/1\">Rajesh Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_R/0/1/0/all/0/1\">Rajiv Ratn Shah</a>",
          "description": "Previous studies have demonstrated that commonly studied (vanilla)\ntouch-based continuous authentication systems (V-TCAS) are susceptible to\npopulation attack. This paper proposes a novel Generative Adversarial Network\nassisted TCAS (G-TCAS) framework, which showed more resilience to the\npopulation attack. G-TCAS framework was tested on a dataset of 117 users who\ninteracted with a smartphone and tablet pair. On average, the increase in the\nfalse accept rates (FARs) for V-TCAS was much higher (22%) than G-TCAS (13%)\nfor the smartphone. Likewise, the increase in the FARs for V-TCAS was 25%\ncompared to G-TCAS (6%) for the tablet.",
          "link": "http://arxiv.org/abs/2106.07867",
          "publishedOn": "2021-06-16T01:21:05.772Z",
          "wordCount": 554,
          "title": "Defending Touch-based Continuous Authentication Systems from Active Adversaries Using Generative Adversarial Networks. (arXiv:2106.07867v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07941",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Sen Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yidan Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_M/0/1/0/all/0/1\">Mingqiang Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_H/0/1/0/all/0/1\">Haoran Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yiping Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jonathan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiao-Ping Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_J/0/1/0/all/0/1\">Jing Qin</a>",
          "description": "We present a novel direction-aware feature-level frequency decomposition\nnetwork for single image deraining. Compared with existing solutions, the\nproposed network has three compelling characteristics. First, unlike previous\nalgorithms, we propose to perform frequency decomposition at feature-level\ninstead of image-level, allowing both low-frequency maps containing structures\nand high-frequency maps containing details to be continuously refined during\nthe training procedure. Second, we further establish communication channels\nbetween low-frequency maps and high-frequency maps to interactively capture\nstructures from high-frequency maps and add them back to low-frequency maps\nand, simultaneously, extract details from low-frequency maps and send them back\nto high-frequency maps, thereby removing rain streaks while preserving more\ndelicate features in the input image. Third, different from existing algorithms\nusing convolutional filters consistent in all directions, we propose a\ndirection-aware filter to capture the direction of rain streaks in order to\nmore effectively and thoroughly purge the input images of rain streaks. We\nextensively evaluate the proposed approach in three representative datasets and\nexperimental results corroborate our approach consistently outperforms\nstate-of-the-art deraining algorithms.",
          "link": "http://arxiv.org/abs/2106.07941",
          "publishedOn": "2021-06-16T01:21:05.759Z",
          "wordCount": 607,
          "title": "Direction-aware Feature-level Frequency Decomposition for Single Image Deraining. (arXiv:2106.07941v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07846",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Mingkun Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chun-Guang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1\">Jun Guo</a>",
          "description": "Unsupervised person re-identification (Re-ID) aims to match pedestrian images\nfrom different camera views in unsupervised setting. Existing methods for\nunsupervised person Re-ID are usually built upon the pseudo labels from\nclustering. However, the quality of clustering depends heavily on the quality\nof the learned features, which are overwhelmingly dominated by the colors in\nimages especially in the unsupervised setting. In this paper, we propose a\nCluster-guided Asymmetric Contrastive Learning (CACL) approach for unsupervised\nperson Re-ID, in which cluster structure is leveraged to guide the feature\nlearning in a properly designed asymmetric contrastive learning framework. To\nbe specific, we propose a novel cluster-level contrastive loss to help the\nsiamese network effectively mine the invariance in feature learning with\nrespect to the cluster structure within and between different data augmentation\nviews, respectively. Extensive experiments conducted on three benchmark\ndatasets demonstrate superior performance of our proposal.",
          "link": "http://arxiv.org/abs/2106.07846",
          "publishedOn": "2021-06-16T01:21:05.751Z",
          "wordCount": 570,
          "title": "Cluster-guided Asymmetric Contrastive Learning for Unsupervised Person Re-Identification. (arXiv:2106.07846v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07991",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Liu_R/0/1/0/all/0/1\">Risheng Liu</a>, <a href=\"http://arxiv.org/find/math/1/au:+Liu_X/0/1/0/all/0/1\">Xuan Liu</a>, <a href=\"http://arxiv.org/find/math/1/au:+Yuan_X/0/1/0/all/0/1\">Xiaoming Yuan</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zeng_S/0/1/0/all/0/1\">Shangzhi Zeng</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhang_J/0/1/0/all/0/1\">Jin Zhang</a>",
          "description": "Bi-level optimization model is able to capture a wide range of complex\nlearning tasks with practical interest. Due to the witnessed efficiency in\nsolving bi-level programs, gradient-based methods have gained popularity in the\nmachine learning community. In this work, we propose a new gradient-based\nsolution scheme, namely, the Bi-level Value-Function-based Interior-point\nMethod (BVFIM). Following the main idea of the log-barrier interior-point\nscheme, we penalize the regularized value function of the lower level problem\ninto the upper level objective. By further solving a sequence of differentiable\nunconstrained approximation problems, we consequently derive a sequential\nprogramming scheme. The numerical advantage of our scheme relies on the fact\nthat, when gradient methods are applied to solve the approximation problem, we\nsuccessfully avoid computing any expensive Hessian-vector or Jacobian-vector\nproduct. We prove the convergence without requiring any convexity assumption on\neither the upper level or the lower level objective. Experiments demonstrate\nthe efficiency of the proposed BVFIM on non-convex bi-level problems.",
          "link": "http://arxiv.org/abs/2106.07991",
          "publishedOn": "2021-06-16T01:21:05.732Z",
          "wordCount": 600,
          "title": "A Value-Function-based Interior-point Method for Non-convex Bi-level Optimization. (arXiv:2106.07991v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07910",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sharma_P/0/1/0/all/0/1\">Prasen Kumar Sharma</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bisht_I/0/1/0/all/0/1\">Ira Bisht</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sur_A/0/1/0/all/0/1\">Arijit Sur</a>",
          "description": "Underwater images, in general, suffer from low contrast and high color\ndistortions due to the non-uniform attenuation of the light as it propagates\nthrough the water. In addition, the degree of attenuation varies with the\nwavelength resulting in the asymmetric traversing of colors. Despite the\nprolific works for underwater image restoration (UIR) using deep learning, the\nabove asymmetricity has not been addressed in the respective network\nengineering. As the first novelty, this paper shows that attributing the right\nreceptive field size (context) based on the traversing range of the color\nchannel may lead to a substantial performance gain for the task of UIR.\nFurther, it is important to suppress the irrelevant multi-contextual features\nand increase the representational power of the model. Therefore, as a second\nnovelty, we have incorporated an attentive skip mechanism to adaptively refine\nthe learned multi-contextual features. The proposed framework, called Deep\nWaveNet, is optimized using the traditional pixel-wise and feature-based cost\nfunctions. An extensive set of experiments have been carried out to show the\nefficacy of the proposed scheme over existing best-published literature on\nbenchmark datasets. More importantly, we have demonstrated a comprehensive\nvalidation of enhanced images across various high-level vision tasks, e.g.,\nunderwater image semantic segmentation, and diver's 2D pose estimation. A\nsample video to exhibit our real-world performance is available at\n\\url{https://www.youtube.com/watch?v=8qtuegBdfac}.",
          "link": "http://arxiv.org/abs/2106.07910",
          "publishedOn": "2021-06-16T01:21:05.725Z",
          "wordCount": 687,
          "title": "Wavelength-based Attributed Deep Neural Network for Underwater Image Restoration. (arXiv:2106.07910v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08208",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Huang_F/0/1/0/all/0/1\">Feihu Huang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Li_J/0/1/0/all/0/1\">Junyi Li</a>, <a href=\"http://arxiv.org/find/math/1/au:+Huang_H/0/1/0/all/0/1\">Heng Huang</a>",
          "description": "Adaptive gradient methods have shown excellent performance for solving many\nmachine learning problems. Although multiple adaptive methods were recently\nstudied, they mainly focus on either empirical or theoretical aspects and also\nonly work for specific problems by using specific adaptive learning rates. It\nis desired to design a universal framework for practical algorithms of adaptive\ngradients with theoretical guarantee to solve general problems. To fill this\ngap, we propose a faster and universal framework of adaptive gradients (i.e.,\nSUPER-ADAM) by introducing a universal adaptive matrix that includes most\nexisting adaptive gradient forms. Moreover, our framework can flexibly\nintegrates the momentum and variance reduced techniques. In particular, our\nnovel framework provides the convergence analysis support for adaptive gradient\nmethods under the nonconvex setting. In theoretical analysis, we prove that our\nnew algorithm can achieve the best known complexity of\n$\\tilde{O}(\\epsilon^{-3})$ for finding an $\\epsilon$-stationary point of\nnonconvex optimization, which matches the lower bound for stochastic smooth\nnonconvex optimization. In numerical experiments, we employ various deep\nlearning tasks to validate that our algorithm consistently outperforms the\nexisting adaptive algorithms.",
          "link": "http://arxiv.org/abs/2106.08208",
          "publishedOn": "2021-06-16T01:21:05.665Z",
          "wordCount": 616,
          "title": "SUPER-ADAM: Faster and Universal Framework of Adaptive Gradients. (arXiv:2106.08208v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07833",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1\">Chengzeng You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hau_Z/0/1/0/all/0/1\">Zhongyuan Hau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Demetriou_S/0/1/0/all/0/1\">Soteris Demetriou</a>",
          "description": "LiDAR sensors are used widely in Autonomous Vehicles for better perceiving\nthe environment which enables safer driving decisions. Recent work has\ndemonstrated serious LiDAR spoofing attacks with alarming consequences. In\nparticular, model-level LiDAR spoofing attacks aim to inject fake depth\nmeasurements to elicit ghost objects that are erroneously detected by 3D Object\nDetectors, resulting in hazardous driving decisions. In this work, we explore\nthe use of motion as a physical invariant of genuine objects for detecting such\nattacks. Based on this, we propose a general methodology, 3D Temporal\nConsistency Check (3D-TC2), which leverages spatio-temporal information from\nmotion prediction to verify objects detected by 3D Object Detectors. Our\npreliminary design and implementation of a 3D-TC2 prototype demonstrates very\npromising performance, providing more than 98% attack detection rate with a\nrecall of 91% for detecting spoofed Vehicle (Car) objects, and is able to\nachieve real-time detection at 41Hz",
          "link": "http://arxiv.org/abs/2106.07833",
          "publishedOn": "2021-06-16T01:21:05.654Z",
          "wordCount": 600,
          "title": "Temporal Consistency Checks to Detect LiDAR Spoofing Attacks on Autonomous Vehicle Perception. (arXiv:2106.07833v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08233",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Czolbe_S/0/1/0/all/0/1\">Steffen Czolbe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feragen_A/0/1/0/all/0/1\">Aasa Feragen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krause_O/0/1/0/all/0/1\">Oswin Krause</a>",
          "description": "Geometric alignment appears in a variety of applications, ranging from domain\nadaptation, optimal transport, and normalizing flows in machine learning;\noptical flow and learned augmentation in computer vision and deformable\nregistration within biomedical imaging. A recurring challenge is the alignment\nof domains whose topology is not the same; a problem that is routinely ignored,\npotentially introducing bias in downstream analysis. As a first step towards\nsolving such alignment problems, we propose an unsupervised topological\ndifference detection algorithm. The model is based on a conditional variational\nauto-encoder and detects topological anomalies with regards to a reference\nalongside the registration step. We consider both a) topological changes in the\nimage under spatial variation and b) unexpected transformations. Our approach\nis validated on a proxy task of unsupervised anomaly detection in images.",
          "link": "http://arxiv.org/abs/2106.08233",
          "publishedOn": "2021-06-16T01:21:05.635Z",
          "wordCount": 573,
          "title": "Spot the Difference: Topological Anomaly Detection via Geometric Alignment. (arXiv:2106.08233v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07791",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Efe_U/0/1/0/all/0/1\">Ufuk Efe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ince_K/0/1/0/all/0/1\">Kutalmis Gokalp Ince</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alatan_A/0/1/0/all/0/1\">A. Aydin Alatan</a>",
          "description": "A novel image matching method is proposed that utilizes learned features\nextracted by an off-the-shelf deep neural network to obtain a promising\nperformance. The proposed method uses pre-trained VGG architecture as a feature\nextractor and does not require any additional training specific to improve\nmatching. Inspired by well-established concepts in the psychology area, such as\nthe Mental Rotation paradigm, an initial warping is performed as a result of a\npreliminary geometric transformation estimate. These estimates are simply based\non dense matching of nearest neighbors at the terminal layer of VGG network\noutputs of the images to be matched. After this initial alignment, the same\napproach is repeated again between reference and aligned images in a\nhierarchical manner to reach a good localization and matching performance. Our\nalgorithm achieves 0.57 and 0.80 overall scores in terms of Mean Matching\nAccuracy (MMA) for 1 pixel and 2 pixels thresholds respectively on Hpatches\ndataset, which indicates a better performance than the state-of-the-art.",
          "link": "http://arxiv.org/abs/2106.07791",
          "publishedOn": "2021-06-16T01:21:05.612Z",
          "wordCount": 603,
          "title": "DFM: A Performance Baseline for Deep Feature Matching. (arXiv:2106.07791v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08186",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hoang_D/0/1/0/all/0/1\">Dung Anh Hoang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Bo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chin_T/0/1/0/all/0/1\">Tat-Jun Chin</a>",
          "description": "Virtually all aspects of modern life depend on space technology. Thanks to\nthe great advancement of computer vision in general and deep learning-based\ntechniques in particular, over the decades, the world witnessed the growing use\nof deep learning in solving problems for space applications, such as\nself-driving robot, tracers, insect-like robot on cosmos and health monitoring\nof spacecraft. These are just some prominent examples that has advanced space\nindustry with the help of deep learning. However, the success of deep learning\nmodels requires a lot of training data in order to have decent performance,\nwhile on the other hand, there are very limited amount of publicly available\nspace datasets for the training of deep learning models. Currently, there is no\npublic datasets for space-based object detection or instance segmentation,\npartly because manually annotating object segmentation masks is very time\nconsuming as they require pixel-level labelling, not to mention the challenge\nof obtaining images from space. In this paper, we aim to fill this gap by\nreleasing a dataset for spacecraft detection, instance segmentation and part\nrecognition. The main contribution of this work is the development of the\ndataset using images of space stations and satellites, with rich annotations\nincluding bounding boxes of spacecrafts and masks to the level of object parts,\nwhich are obtained with a mixture of automatic processes and manual efforts. We\nalso provide evaluations with state-of-the-art methods in object detection and\ninstance segmentation as a benchmark for the dataset. The link for downloading\nthe proposed dataset can be found on\nhttps://github.com/Yurushia1998/SatelliteDataset.",
          "link": "http://arxiv.org/abs/2106.08186",
          "publishedOn": "2021-06-16T01:21:05.585Z",
          "wordCount": 687,
          "title": "A Spacecraft Dataset for Detection, Segmentation and Parts Recognition. (arXiv:2106.08186v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07847",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bao_Y/0/1/0/all/0/1\">Yujia Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1\">Shiyu Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barzilay_R/0/1/0/all/0/1\">Regina Barzilay</a>",
          "description": "We study transfer learning in the presence of spurious correlations. We\nexperimentally demonstrate that directly transferring the stable feature\nextractor learned on the source task may not eliminate these biases for the\ntarget task. However, we hypothesize that the unstable features in the source\ntask and those in the target task are directly related. By explicitly informing\nthe target classifier of the source task's unstable features, we can regularize\nthe biases in the target task. Specifically, we derive a representation that\nencodes the unstable features by contrasting different data environments in the\nsource task. On the target task, we cluster data from this representation, and\nachieve robustness by minimizing the worst-case risk across all clusters. We\nevaluate our method on both text and image classifications. Empirical results\ndemonstrate that our algorithm is able to maintain robustness on the target\ntask, outperforming the best baseline by 22.9% in absolute accuracy across 12\ntransfer settings. Our code is available at https://github.com/YujiaBao/Tofu.",
          "link": "http://arxiv.org/abs/2106.07847",
          "publishedOn": "2021-06-16T01:21:05.578Z",
          "wordCount": 601,
          "title": "Learning Stable Classifiers by Transferring Unstable Features. (arXiv:2106.07847v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08147",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ma_D/0/1/0/all/0/1\">Di Ma</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Afonso_M/0/1/0/all/0/1\">Mariana Afonso</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_F/0/1/0/all/0/1\">Fan Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bull_D/0/1/0/all/0/1\">David R. Bull</a>",
          "description": "Spatial resolution adaptation is a technique which has often been employed in\nvideo compression to enhance coding efficiency. This approach encodes a lower\nresolution version of the input video and reconstructs the original resolution\nduring decoding. Instead of using conventional up-sampling filters, recent work\nhas employed advanced super-resolution methods based on convolutional neural\nnetworks (CNNs) to further improve reconstruction quality. These approaches are\nusually trained to minimise pixel-based losses such as Mean-Squared Error\n(MSE), despite the fact that this type of loss metric does not correlate well\nwith subjective opinions. In this paper, a perceptually-inspired\nsuper-resolution approach (M-SRGAN) is proposed for spatial up-sampling of\ncompressed video using a modified CNN model, which has been trained using a\ngenerative adversarial network (GAN) on compressed content with perceptual loss\nfunctions. The proposed method was integrated with HEVC HM 16.20, and has been\nevaluated on the JVET Common Test Conditions (UHD test sequences) using the\nRandom Access configuration. The results show evident perceptual quality\nimprovement over the original HM 16.20, with an average bitrate saving of 35.6%\n(Bj{\\o}ntegaard Delta measurement) based on a perceptual quality metric, VMAF.",
          "link": "http://arxiv.org/abs/2106.08147",
          "publishedOn": "2021-06-16T01:21:05.563Z",
          "wordCount": 624,
          "title": "Perceptually-inspired super-resolution of compressed videos. (arXiv:2106.08147v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08112",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1\">Han-Jia Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1\">Da-Wei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_L/0/1/0/all/0/1\">Lanqing Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhenguo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1\">Xiu-Shen Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_D/0/1/0/all/0/1\">De-Chuan Zhan</a>",
          "description": "One single instance could possess multiple portraits and reveal diverse\nrelationships with others according to different contexts. Those ambiguities\nincrease the difficulty of learning a generalizable model when there exists one\nconcept or mixed concepts in a task. We propose a general approach Learning to\nDecompose Network (LeadNet) for both two cases, which contextualizes a model\nthrough meta-learning multiple maps for concepts discovery -- the\nrepresentations of instances are decomposed and adapted conditioned on the\ncontexts. Through taking a holistic view over multiple latent components over\ninstances in a sampled pseudo task, LeadNet learns to automatically select the\nright concept via incorporating those rich semantics inside and between\nobjects. LeadNet demonstrates its superiority in various applications,\nincluding exploring multiple views of confusing tasks, out-of-distribution\nrecognition, and few-shot image classification.",
          "link": "http://arxiv.org/abs/2106.08112",
          "publishedOn": "2021-06-16T01:21:05.552Z",
          "wordCount": 562,
          "title": "Contextualizing Multiple Tasks via Learning to Decompose. (arXiv:2106.08112v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07714",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yufei Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belkhir_N/0/1/0/all/0/1\">Nacim Belkhir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Angulo_J/0/1/0/all/0/1\">Jesus Angulo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_A/0/1/0/all/0/1\">Angela Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Franchi_G/0/1/0/all/0/1\">Gianni Franchi</a>",
          "description": "Deep Neural Networks (DNNs) are generated by sequentially performing linear\nand non-linear processes. Using a combination of linear and non-linear\nprocedures is critical for generating a sufficiently deep feature space. The\nmajority of non-linear operators are derivations of activation functions or\npooling functions. Mathematical morphology is a branch of mathematics that\nprovides non-linear operators for a variety of image processing problems. We\ninvestigate the utility of integrating these operations in an end-to-end deep\nlearning framework in this paper. DNNs are designed to acquire a realistic\nrepresentation for a particular job. Morphological operators give topological\ndescriptors that convey salient information about the shapes of objects\ndepicted in images. We propose a method based on meta-learning to incorporate\nmorphological operators into DNNs. The learned architecture demonstrates how\nour novel morphological operations significantly increase DNN performance on\nvarious tasks, including picture classification and edge detection.",
          "link": "http://arxiv.org/abs/2106.07714",
          "publishedOn": "2021-06-16T01:21:05.545Z",
          "wordCount": 584,
          "title": "Learning Deep Morphological Networks with Neural Architecture Search. (arXiv:2106.07714v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07822",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+McNeely_White_D/0/1/0/all/0/1\">David McNeely-White</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sattelberg_B/0/1/0/all/0/1\">Ben Sattelberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blanchard_N/0/1/0/all/0/1\">Nathaniel Blanchard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beveridge_R/0/1/0/all/0/1\">Ross Beveridge</a>",
          "description": "We present evidence that many common convolutional neural networks (CNNs)\ntrained for face verification learn functions that are nearly equivalent under\nrotation. More specifically, we demonstrate that one face verification model's\nembeddings (i.e. last--layer activations) can be compared directly to another\nmodel's embeddings after only a rotation or linear transformation, with little\nperformance penalty. This finding is demonstrated using IJB-C 1:1 verification\nacross the combinations of ten modern off-the-shelf CNN-based face verification\nmodels which vary in training dataset, CNN architecture, way of using angular\nloss, or some combination of the 3, and achieve a mean true accept rate of 0.96\nat a false accept rate of 0.01. When instead evaluating embeddings generated\nfrom two CNNs, where one CNN's embeddings are mapped with a linear\ntransformation, the mean true accept rate drops to 0.95 using the same\nverification paradigm. Restricting these linear maps to only perform rotation\nproduces a mean true accept rate of 0.91. These mappings' existence suggests\nthat a common representation is learned by models with variation in training or\nstructure. A discovery such as this likely has broad implications, and we\nprovide an application in which face embeddings can be de-anonymized using a\nlimited number of samples.",
          "link": "http://arxiv.org/abs/2106.07822",
          "publishedOn": "2021-06-16T01:21:05.524Z",
          "wordCount": 630,
          "title": "Canonical Face Embeddings. (arXiv:2106.07822v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07995",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Boney_R/0/1/0/all/0/1\">Rinu Boney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ilin_A/0/1/0/all/0/1\">Alexander Ilin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kannala_J/0/1/0/all/0/1\">Juho Kannala</a>",
          "description": "In many control problems that include vision, optimal controls can be\ninferred from the location of the objects in the scene. This information can be\nrepresented using keypoints, which is a list of spatial locations in the input\nimage. Previous works show that keypoint representations learned during\nunsupervised pre-training using encoder-decoder architectures can provide good\nfeatures for control tasks. In this paper, we show that it is possible to learn\nefficient keypoint representations end-to-end, without the need for\nunsupervised pre-training, decoders, or additional losses. Our proposed\narchitecture consists of a differentiable keypoint extractor that feeds the\ncoordinates of the estimated keypoints directly to a soft actor-critic agent.\nThe proposed algorithm yields performance competitive to the state-of-the art\non DeepMind Control Suite tasks.",
          "link": "http://arxiv.org/abs/2106.07995",
          "publishedOn": "2021-06-16T01:21:05.477Z",
          "wordCount": 558,
          "title": "End-to-End Learning of Keypoint Representations for Continuous Control from Images. (arXiv:2106.07995v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07955",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rizzo_M/0/1/0/all/0/1\">Matteo Rizzo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Conati_C/0/1/0/all/0/1\">Cristina Conati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jang_D/0/1/0/all/0/1\">Daesik Jang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Hui Hu</a>",
          "description": "Computational Colour Constancy (CCC) consists of estimating the colour of one\nor more illuminants in a scene and using them to remove unwanted chromatic\ndistortions. Much research has focused on illuminant estimation for CCC on\nsingle images, with few attempts of leveraging the temporal information\nintrinsic in sequences of correlated images (e.g., the frames in a video), a\ntask known as Temporal Colour Constancy (TCC). The state-of-the-art for TCC is\nTCCNet, a deep-learning architecture that uses a ConvLSTM for aggregating the\nencodings produced by CNN submodules for each image in a sequence. We extend\nthis architecture with different models obtained by (i) substituting the TCCNet\nsubmodules with C4, the state-of-the-art method for CCC targeting images; (ii)\nadding a cascading strategy to perform an iterative improvement of the estimate\nof the illuminant. We tested our models on the recently released TCC benchmark\nand achieved results that surpass the state-of-the-art. Analyzing the impact of\nthe number of frames involved in illuminant estimation on performance, we show\nthat it is possible to reduce inference time by training the models on few\nselected frames from the sequences while retaining comparable accuracy.",
          "link": "http://arxiv.org/abs/2106.07955",
          "publishedOn": "2021-06-16T01:21:05.462Z",
          "wordCount": 614,
          "title": "Cascading Convolutional Temporal Colour Constancy. (arXiv:2106.07955v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07807",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Islam_A/0/1/0/all/0/1\">Ashraful Islam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chun-Fu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panda_R/0/1/0/all/0/1\">Rameswar Panda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karlinsky_L/0/1/0/all/0/1\">Leonid Karlinsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feris_R/0/1/0/all/0/1\">Rogerio Feris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radke_R/0/1/0/all/0/1\">Richard J. Radke</a>",
          "description": "Most existing works in few-shot learning rely on meta-learning the network on\na large base dataset which is typically from the same domain as the target\ndataset. We tackle the problem of cross-domain few-shot learning where there is\na large shift between the base and target domain. The problem of cross-domain\nfew-shot recognition with unlabeled target data is largely unaddressed in the\nliterature. STARTUP was the first method that tackles this problem using\nself-training. However, it uses a fixed teacher pretrained on a labeled base\ndataset to create soft labels for the unlabeled target samples. As the base\ndataset and unlabeled dataset are from different domains, projecting the target\nimages in the class-domain of the base dataset with a fixed pretrained model\nmight be sub-optimal. We propose a simple dynamic distillation-based approach\nto facilitate unlabeled images from the novel/base dataset. We impose\nconsistency regularization by calculating predictions from the weakly-augmented\nversions of the unlabeled images from a teacher network and matching it with\nthe strongly augmented versions of the same images from a student network. The\nparameters of the teacher network are updated as exponential moving average of\nthe parameters of the student network. We show that the proposed network learns\nrepresentation that can be easily adapted to the target domain even though it\nhas not been trained with target-specific classes during the pretraining phase.\nOur model outperforms the current state-of-the art method by 4.4% for 1-shot\nand 3.6% for 5-shot classification in the BSCD-FSL benchmark, and also shows\ncompetitive performance on traditional in-domain few-shot learning task. Our\ncode will be available at: https://github.com/asrafulashiq/dynamic-cdfsl.",
          "link": "http://arxiv.org/abs/2106.07807",
          "publishedOn": "2021-06-16T01:21:05.443Z",
          "wordCount": 704,
          "title": "Dynamic Distillation Network for Cross-Domain Few-Shot Recognition with Unlabeled Data. (arXiv:2106.07807v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07905",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Rui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_Z/0/1/0/all/0/1\">Ziheng Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongyuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xuelong Li</a>",
          "description": "Deep neural network (DNN) generally takes thousands of iterations to optimize\nvia gradient descent and thus has a slow convergence. In addition, softmax, as\na decision layer, may ignore the distribution information of the data during\nclassification. Aiming to tackle the referred problems, we propose a novel\nmanifold neural network based on non-gradient optimization, i.e., the\nclosed-form solutions. Considering that the activation function is generally\ninvertible, we reconstruct the network via forward ridge regression and low\nrank backward approximation, which achieve the rapid convergence. Moreover, by\nunifying the flexible Stiefel manifold and adaptive support vector machine, we\ndevise the novel decision layer which efficiently fits the manifold structure\nof the data and label information. Consequently, a jointly non-gradient\noptimization method is designed to generate the network with closed-form\nresults. Eventually, extensive experiments validate the superior performance of\nthe model.",
          "link": "http://arxiv.org/abs/2106.07905",
          "publishedOn": "2021-06-16T01:21:05.436Z",
          "wordCount": 566,
          "title": "Non-Gradient Manifold Neural Network. (arXiv:2106.07905v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08073",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_G/0/1/0/all/0/1\">Guangze Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1\">Changhong Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Junjie Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_F/0/1/0/all/0/1\">Fuling Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_F/0/1/0/all/0/1\">Fangqiang Ding</a>",
          "description": "Unmanned aerial vehicle (UAV) based visual tracking has been confronted with\nnumerous challenges, e.g., object motion and occlusion. These challenges\ngenerally introduce unexpected mutations of target appearance and result in\ntracking failure. However, prevalent discriminative correlation filter (DCF)\nbased trackers are insensitive to target mutations due to a predefined label,\nwhich concentrates on merely the centre of the training region. Meanwhile,\nappearance mutations caused by occlusion or similar objects usually lead to the\ninevitable learning of wrong information. To cope with appearance mutations,\nthis paper proposes a novel DCF-based method to enhance the sensitivity and\nresistance to mutations with an adaptive hybrid label, i.e., MSCF. The ideal\nlabel is optimized jointly with the correlation filter and remains temporal\nconsistency. Besides, a novel measurement of mutations called mutation threat\nfactor (MTF) is applied to correct the label dynamically. Considerable\nexperiments are conducted on widely used UAV benchmarks. The results indicate\nthat the performance of MSCF tracker surpasses other 26 state-of-the-art\nDCF-based and deep-based trackers. With a real-time speed of _38 frames/s, the\nproposed approach is sufficient for UAV tracking commissions.",
          "link": "http://arxiv.org/abs/2106.08073",
          "publishedOn": "2021-06-16T01:21:05.429Z",
          "wordCount": 631,
          "title": "Mutation Sensitive Correlation Filter for Real-Time UAV Tracking with Adaptive Hybrid Label. (arXiv:2106.08073v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08021",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Akundi_P/0/1/0/all/0/1\">Prathyusha Akundi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gun_S/0/1/0/all/0/1\">Soumyasis Gun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sivaswamy_J/0/1/0/all/0/1\">Jayanthi Sivaswamy</a>",
          "description": "Melanoma is a leading cause of deaths due to skin cancer deaths and hence,\nearly and effective diagnosis of melanoma is of interest. Current approaches\nfor automated diagnosis of melanoma either use pattern recognition or\nanalytical recognition like ABCDE (asymmetry, border, color, diameter and\nevolving) criterion. In practice however, a differential approach wherein\noutliers (ugly duckling) are detected and used to evaluate nevi/lesions.\nIncorporation of differential recognition in Computer Aided Diagnosis (CAD)\nsystems has not been explored but can be beneficial as it can provide a\nclinical justification for the derived decision. We present a method for\nidentifying and quantifying ugly ducklings by performing Intra-Patient\nComparative Analysis (IPCA) of neighboring nevi. This is then incorporated in a\nCAD system design for melanoma detection. This design ensures flexibility to\nhandle cases where IPCA is not possible. Our experiments on a public dataset\nshow that the outlier information helps boost the sensitivity of detection by\nat least 4.1 % and specificity by 4.0 % to 8.9 %, depending on the use of a\nstrong (EfficientNet) or moderately strong (VGG or ResNet) classifier.",
          "link": "http://arxiv.org/abs/2106.08021",
          "publishedOn": "2021-06-16T01:21:05.404Z",
          "wordCount": 620,
          "title": "A Clinically Inspired Approach for Melanoma classification. (arXiv:2106.08021v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08009",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Black_A/0/1/0/all/0/1\">Alexander Black</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bui_T/0/1/0/all/0/1\">Tu Bui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mai_L/0/1/0/all/0/1\">Long Mai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_H/0/1/0/all/0/1\">Hailin Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Collomosse_J/0/1/0/all/0/1\">John Collomosse</a>",
          "description": "We present an algorithm for searching image collections using free-hand\nsketches that describe the appearance and relative positions of multiple\nobjects. Sketch based image retrieval (SBIR) methods predominantly match\nqueries containing a single, dominant object invariant to its position within\nan image. Our work exploits drawings as a concise and intuitive representation\nfor specifying entire scene compositions. We train a convolutional neural\nnetwork (CNN) to encode masked visual features from sketched objects, pooling\nthese into a spatial descriptor encoding the spatial relationships and\nappearances of objects in the composition. Training the CNN backbone as a\nSiamese network under triplet loss yields a metric search embedding for\nmeasuring compositional similarity which may be efficiently leveraged for\nvisual search by applying product quantization.",
          "link": "http://arxiv.org/abs/2106.08009",
          "publishedOn": "2021-06-16T01:21:05.395Z",
          "wordCount": 548,
          "title": "Compositional Sketch Search. (arXiv:2106.08009v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08042",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tseytlin_B/0/1/0/all/0/1\">Boris Tseytlin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Makarov_I/0/1/0/all/0/1\">Ilya Makarov</a>",
          "description": "We approach the problem of hotel recognition with deep metric learning. We\noverview the existing approaches and propose a modification to Contrastive loss\ncalled Contrastive-Triplet loss. We construct a robust pipeline for\nbenchmarking metric learning models and perform experiments on Hotels-50K and\nCUB200 datasets. Contrastive-Triplet loss is shown to achieve better retrieval\non Hotels-50k. We open-source our code.",
          "link": "http://arxiv.org/abs/2106.08042",
          "publishedOn": "2021-06-16T01:21:05.385Z",
          "wordCount": 491,
          "title": "Hotel Recognition via Latent Image Embedding. (arXiv:2106.08042v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08151",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Schneider_M/0/1/0/all/0/1\">Maja Schneider</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Broszeit_A/0/1/0/all/0/1\">Amelie Broszeit</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Korner_M/0/1/0/all/0/1\">Marco K&#xf6;rner</a>",
          "description": "We present EuroCrops, a dataset based on self-declared field annotations for\ntraining and evaluating methods for crop type classification and mapping,\ntogether with its process of acquisition and harmonisation. By this, we aim to\nenrich the research efforts and discussion for data-driven land cover\nclassification via Earth observation and remote sensing. Additionally, through\ninclusion of self-declarations gathered in the scope of subsidy control from\nall countries of the European Union (EU), this dataset highlights the\ndifficulties and pitfalls one comes across when operating on a transnational\nlevel. We, therefore, also introduce a new taxonomy scheme, HCAT-ID, that\naspires to capture all the aspects of reference data originating from\nadministrative and agency databases. To address researchers from both the\nremote sensing and the computer vision and machine learning communities, we\npublish the dataset in different formats and processing levels.",
          "link": "http://arxiv.org/abs/2106.08151",
          "publishedOn": "2021-06-16T01:21:05.378Z",
          "wordCount": 607,
          "title": "EuroCrops: A Pan-European Dataset for Time Series Crop Type Classification. (arXiv:2106.08151v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07817",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vonikakis_V/0/1/0/all/0/1\">Vassilios Vonikakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Winkler_S/0/1/0/all/0/1\">Stefan Winkler</a>",
          "description": "Despite their continued popularity, categorical approaches to affect\nrecognition have limitations, especially in real-life situations. Dimensional\nmodels of affect offer important advantages for the recognition of subtle\nexpressions and more fine-grained analysis. We introduce a simple but effective\nfacial expression analysis (FEA) system for dimensional affect, solely based on\ngeometric features and Partial Least Squares (PLS) regression. The system\njointly learns to estimate Arousal and Valence ratings from a set of facial\nimages. The proposed approach is robust, efficient, and exhibits comparable\nperformance to contemporary deep learning models, while requiring a fraction of\nthe computational resources.",
          "link": "http://arxiv.org/abs/2106.07817",
          "publishedOn": "2021-06-16T01:21:05.366Z",
          "wordCount": 531,
          "title": "Efficient Facial Expression Analysis For Dimensional Affect Recognition Using Geometric Features. (arXiv:2106.07817v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08094",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Wilde_B/0/1/0/all/0/1\">Bram de Wilde</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Broek_R/0/1/0/all/0/1\">Richard P. G. ten Broek</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huisman_H/0/1/0/all/0/1\">Henkjan Huisman</a>",
          "description": "Adhesions are an important cause of chronic pain following abdominal surgery.\nRecent developments in abdominal cine-MRI have enabled the non-invasive\ndiagnosis of adhesions. Adhesions are identified on cine-MRI by the absence of\nsliding motion during movement. Diagnosis and mapping of adhesions improves the\nmanagement of patients with pain. Detection of abdominal adhesions on cine-MRI\nis challenging from both a radiological and deep learning perspective. We focus\non classifying presence or absence of adhesions in sagittal abdominal cine-MRI\nseries. We experimented with spatio-temporal deep learning architectures\ncentered around a ConvGRU architecture. A hybrid architecture comprising a\nResNet followed by a ConvGRU model allows to classify a whole time-series.\nCompared to a stand-alone ResNet with a two time-point (inspiration/expiration)\ninput, we show an increase in classification performance (AUROC) from 0.74 to\n0.83 ($p<0.05$). Our full temporal classification approach adds only a small\namount (5%) of parameters to the entire architecture, which may be useful for\nother medical imaging problems with a temporal dimension.",
          "link": "http://arxiv.org/abs/2106.08094",
          "publishedOn": "2021-06-16T01:21:05.343Z",
          "wordCount": 612,
          "title": "Cine-MRI detection of abdominal adhesions with spatio-temporal deep learning. (arXiv:2106.08094v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08077",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lakshika_J/0/1/0/all/0/1\">Jayani P. G. Lakshika</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Talagala_T/0/1/0/all/0/1\">Thiyanga S. Talagala</a>",
          "description": "Plant species identification is time consuming, costly, and requires lots of\nefforts, and expertise knowledge. In recent, many researchers use deep learning\nmethods to classify plants directly using plant images. While deep learning\nmodels have achieved a great success, the lack of interpretability limit their\nwidespread application. To overcome this, we explore the use of interpretable,\nmeasurable and computer-aided features extracted from plant leaf images. Image\nprocessing is one of the most challenging, and crucial steps in\nfeature-extraction. The purpose of image processing is to improve the leaf\nimage by removing undesired distortion. The main image processing steps of our\nalgorithm involves: i) Convert original image to RGB (Red-Green-Blue) image,\nii) Gray scaling, iii) Gaussian smoothing, iv) Binary thresholding, v) Remove\nstalk, vi) Closing holes, and vii) Resize image. The next step after image\nprocessing is to extract features from plant leaf images. We introduced 52\ncomputationally efficient features to classify plant species. These features\nare mainly classified into four groups as: i) shape-based features, ii)\ncolor-based features, iii) texture-based features, and iv) scagnostic features.\nLength, width, area, texture correlation, monotonicity and scagnostics are to\nname few of them. We explore the ability of features to discriminate the\nclasses of interest under supervised learning and unsupervised learning\nsettings. For that, supervised dimensionality reduction technique, Linear\nDiscriminant Analysis (LDA), and unsupervised dimensionality reduction\ntechnique, Principal Component Analysis (PCA) are used to convert and visualize\nthe images from digital-image space to feature space. The results show that the\nfeatures are sufficient to discriminate the classes of interest under both\nsupervised and unsupervised learning settings.",
          "link": "http://arxiv.org/abs/2106.08077",
          "publishedOn": "2021-06-16T01:21:05.331Z",
          "wordCount": 700,
          "title": "Computer-aided Interpretable Features for Leaf Image Classification. (arXiv:2106.08077v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08059",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mueller_F/0/1/0/all/0/1\">Franziska Mueller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Davis_M/0/1/0/all/0/1\">Micah Davis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bernard_F/0/1/0/all/0/1\">Florian Bernard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sotnychenko_O/0/1/0/all/0/1\">Oleksandr Sotnychenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verschoor_M/0/1/0/all/0/1\">Mickeal Verschoor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Otaduy_M/0/1/0/all/0/1\">Miguel A. Otaduy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Casas_D/0/1/0/all/0/1\">Dan Casas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Theobalt_C/0/1/0/all/0/1\">Christian Theobalt</a>",
          "description": "We present a novel method for real-time pose and shape reconstruction of two\nstrongly interacting hands. Our approach is the first two-hand tracking\nsolution that combines an extensive list of favorable properties, namely it is\nmarker-less, uses a single consumer-level depth camera, runs in real time,\nhandles inter- and intra-hand collisions, and automatically adjusts to the\nuser's hand shape. In order to achieve this, we embed a recent parametric hand\npose and shape model and a dense correspondence predictor based on a deep\nneural network into a suitable energy minimization framework. For training the\ncorrespondence prediction network, we synthesize a two-hand dataset based on\nphysical simulations that includes both hand pose and shape annotations while\nat the same time avoiding inter-hand penetrations. To achieve real-time rates,\nwe phrase the model fitting in terms of a nonlinear least-squares problem so\nthat the energy can be optimized based on a highly efficient GPU-based\nGauss-Newton optimizer. We show state-of-the-art results in scenes that exceed\nthe complexity level demonstrated by previous work, including tight two-hand\ngrasps, significant inter-hand occlusions, and gesture interaction.",
          "link": "http://arxiv.org/abs/2106.08059",
          "publishedOn": "2021-06-16T01:21:05.322Z",
          "wordCount": 639,
          "title": "Real-time Pose and Shape Reconstruction of Two Interacting Hands With a Single Depth Camera. (arXiv:2106.08059v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07927",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ruf_B/0/1/0/all/0/1\">Boitumelo Ruf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohrs_J/0/1/0/all/0/1\">Jonas Mohrs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weinmann_M/0/1/0/all/0/1\">Martin Weinmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hinz_S/0/1/0/all/0/1\">Stefan Hinz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beyerer_J/0/1/0/all/0/1\">J&#xfc;rgen Beyerer</a>",
          "description": "With the emergence of low-cost robotic systems, such as unmanned aerial\nvehicle, the importance of embedded high-performance image processing has\nincreased. For a long time, FPGAs were the only processing hardware that were\ncapable of high-performance computing, while at the same time preserving a low\npower consumption, essential for embedded systems. However, the recently\nincreasing availability of embedded GPU-based systems, such as the NVIDIA\nJetson series, comprised of an ARM CPU and a NVIDIA Tegra GPU, allows for\nmassively parallel embedded computing on graphics hardware. With this in mind,\nwe propose an approach for real-time embedded stereo processing on ARM and\nCUDA-enabled devices, which is based on the popular and widely used Semi-Global\nMatching algorithm. In this, we propose an optimization of the algorithm for\nembedded CUDA GPUs, by using massively parallel computing, as well as using the\nNEON intrinsics to optimize the algorithm for vectorized SIMD processing on\nembedded ARM CPUs. We have evaluated our approach with different configurations\non two public stereo benchmark datasets to demonstrate that they can reach an\nerror rate as low as 3.3%. Furthermore, our experiments show that the fastest\nconfiguration of our approach reaches up to 46 FPS on VGA image resolution.\nFinally, in a use-case specific qualitative evaluation, we have evaluated the\npower consumption of our approach and deployed it on the DJI Manifold 2-G\nattached to a DJI Matrix 210v2 RTK unmanned aerial vehicle (UAV), demonstrating\nits suitability for real-time stereo processing onboard a UAV.",
          "link": "http://arxiv.org/abs/2106.07927",
          "publishedOn": "2021-06-16T01:21:05.250Z",
          "wordCount": 693,
          "title": "ReS2tAC -- UAV-Borne Real-Time SGM Stereo Optimized for Embedded ARM and CUDA Devices. (arXiv:2106.07927v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07861",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jae Myung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choe_J/0/1/0/all/0/1\">Junsuk Choe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akata_Z/0/1/0/all/0/1\">Zeynep Akata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_S/0/1/0/all/0/1\">Seong Joon Oh</a>",
          "description": "The class activation mapping, or CAM, has been the cornerstone of feature\nattribution methods for multiple vision tasks. Its simplicity and effectiveness\nhave led to wide applications in the explanation of visual predictions and\nweakly-supervised localization tasks. However, CAM has its own shortcomings.\nThe computation of attribution maps relies on ad-hoc calibration steps that are\nnot part of the training computational graph, making it difficult for us to\nunderstand the real meaning of the attribution values. In this paper, we\nimprove CAM by explicitly incorporating a latent variable encoding the location\nof the cue for recognition in the formulation, thereby subsuming the\nattribution map into the training computational graph. The resulting model,\nclass activation latent mapping, or CALM, is trained with the\nexpectation-maximization algorithm. Our experiments show that CALM identifies\ndiscriminative attributes for image classifiers more accurately than CAM and\nother visual attribution baselines. CALM also shows performance improvements\nover prior arts on the weakly-supervised object localization benchmarks. Our\ncode is available at https://github.com/naver-ai/calm.",
          "link": "http://arxiv.org/abs/2106.07861",
          "publishedOn": "2021-06-16T01:21:05.162Z",
          "wordCount": 602,
          "title": "Keep CALM and Improve Visual Feature Attribution. (arXiv:2106.07861v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07876",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_F/0/1/0/all/0/1\">Fengda Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_X/0/1/0/all/0/1\">Xiaojun Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1\">Xiaodan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yi-Dong Shen</a>",
          "description": "Vision-language Navigation (VLN) tasks require an agent to navigate\nstep-by-step while perceiving the visual observations and comprehending a\nnatural language instruction. Large data bias, which is caused by the disparity\nratio between the small data scale and large navigation space, makes the VLN\ntask challenging. Previous works have proposed various data augmentation\nmethods to reduce data bias. However, these works do not explicitly reduce the\ndata bias across different house scenes. Therefore, the agent would overfit to\nthe seen scenes and achieve poor navigation performance in the unseen scenes.\nTo tackle this problem, we propose the Random Environmental Mixup (REM) method,\nwhich generates cross-connected house scenes as augmented data via mixuping\nenvironment. Specifically, we first select key viewpoints according to the room\nconnection graph for each scene. Then, we cross-connect the key views of\ndifferent scenes to construct augmented scenes. Finally, we generate augmented\ninstruction-path pairs in the cross-connected scenes. The experimental results\non benchmark datasets demonstrate that our augmentation data via REM help the\nagent reduce its performance gap between the seen and unseen environment and\nimprove the overall performance, making our model the best existing approach on\nthe standard VLN benchmark.",
          "link": "http://arxiv.org/abs/2106.07876",
          "publishedOn": "2021-06-16T01:21:05.154Z",
          "wordCount": 620,
          "title": "Vision-Language Navigation with Random Environmental Mixup. (arXiv:2106.07876v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07880",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zandieh_A/0/1/0/all/0/1\">Amir Zandieh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_I/0/1/0/all/0/1\">Insu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Avron_H/0/1/0/all/0/1\">Haim Avron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shoham_N/0/1/0/all/0/1\">Neta Shoham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_C/0/1/0/all/0/1\">Chaewon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1\">Jinwoo Shin</a>",
          "description": "The Neural Tangent Kernel (NTK) characterizes the behavior of infinitely-wide\nneural networks trained under least squares loss by gradient descent. Recent\nworks also report that NTK regression can outperform finitely-wide neural\nnetworks trained on small-scale datasets. However, the computational complexity\nof kernel methods has limited its use in large-scale learning tasks. To\naccelerate learning with NTK, we design a near input-sparsity time\napproximation algorithm for NTK, by sketching the polynomial expansions of\narc-cosine kernels: our sketch for the convolutional counterpart of NTK (CNTK)\ncan transform any image using a linear runtime in the number of pixels.\nFurthermore, we prove a spectral approximation guarantee for the NTK matrix, by\ncombining random features (based on leverage score sampling) of the arc-cosine\nkernels with a sketching algorithm. We benchmark our methods on various\nlarge-scale regression and classification tasks and show that a linear\nregressor trained on our CNTK features matches the accuracy of exact CNTK on\nCIFAR-10 dataset while achieving 150x speedup.",
          "link": "http://arxiv.org/abs/2106.07880",
          "publishedOn": "2021-06-16T01:21:05.118Z",
          "wordCount": 609,
          "title": "Scaling Neural Tangent Kernels via Sketching and Random Features. (arXiv:2106.07880v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07862",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhongzhou Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lei Zhang</a>",
          "description": "Benefit from large-scale training data, recent advances in Siamese-based\nobject tracking have achieved compelling results on the normal sequences.\nWhilst Siamese-based trackers assume training and test data follow an identical\ndistribution. Suppose there is a set of foggy or rainy test sequences, it\ncannot be guaranteed that the trackers trained on the normal images perform\nwell on the data belonging to other domains. The problem of domain shift among\ntraining and test data has already been discussed in object detection and\nsemantic segmentation areas, which, however, has not been investigated for\nvisual tracking. To this end, based on SiamRPN++, we introduce a Domain\nAdaptive SiamRPN++, namely DASiamRPN++, to improve the cross-domain\ntransferability and robustness of a tracker. Inspired by A-distance theory, we\npresent two domain adaptive modules, Pixel Domain Adaptation (PDA) and Semantic\nDomain Adaptation (SDA). The PDA module aligns the feature maps of template and\nsearch region images to eliminate the pixel-level domain shift caused by\nweather, illumination, etc. The SDA module aligns the feature representations\nof the tracking target's appearance to eliminate the semantic-level domain\nshift. PDA and SDA modules reduce the domain disparity by learning domain\nclassifiers in an adversarial training manner. The domain classifiers enforce\nthe network to learn domain-invariant feature representations. Extensive\nexperiments are performed on the standard datasets of two different domains,\nincluding synthetic foggy and TIR sequences, which demonstrate the\ntransferability and domain adaptability of the proposed tracker.",
          "link": "http://arxiv.org/abs/2106.07862",
          "publishedOn": "2021-06-16T01:21:05.109Z",
          "wordCount": 667,
          "title": "Domain Adaptive SiamRPN++ for Object Tracking in the Wild. (arXiv:2106.07862v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07708",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Avram_R/0/1/0/all/0/1\">Robert Avram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Olgin_J/0/1/0/all/0/1\">Jeffrey E. Olgin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_A/0/1/0/all/0/1\">Alvin Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_Z/0/1/0/all/0/1\">Zeeshan Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verreault_Julien_L/0/1/0/all/0/1\">Louis Verreault-Julien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abreau_S/0/1/0/all/0/1\">Sean Abreau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_D/0/1/0/all/0/1\">Derek Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1\">Joseph E. Gonzalez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+So_D/0/1/0/all/0/1\">Derek Y. So</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soni_K/0/1/0/all/0/1\">Krishan Soni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tison_G/0/1/0/all/0/1\">Geoffrey H. Tison</a>",
          "description": "Coronary heart disease (CHD) is the leading cause of adult death in the\nUnited States and worldwide, and for which the coronary angiography procedure\nis the primary gateway for diagnosis and clinical management decisions. The\nstandard-of-care for interpretation of coronary angiograms depends upon ad-hoc\nvisual assessment by the physician operator. However, ad-hoc visual\ninterpretation of angiograms is poorly reproducible, highly variable and bias\nprone. Here we show for the first time that fully-automated angiogram\ninterpretation to estimate coronary artery stenosis is possible using a\nsequence of deep neural network algorithms. The algorithmic pipeline we\ndeveloped--called CathAI--achieves state-of-the art performance across the\nsequence of tasks required to accomplish automated interpretation of\nunselected, real-world angiograms. CathAI (Algorithms 1-2) demonstrated\npositive predictive value, sensitivity and F1 score of >=90% to identify the\nprojection angle overall and >=93% for left or right coronary artery angiogram\ndetection, the primary anatomic structures of interest. To predict obstructive\ncoronary artery stenosis (>=70% stenosis), CathAI (Algorithm 4) exhibited an\narea under the receiver operating characteristic curve (AUC) of 0.862 (95% CI:\n0.843-0.880). When externally validated in a healthcare system in another\ncountry, CathAI AUC was 0.869 (95% CI: 0.830-0.907) to predict obstructive\ncoronary artery stenosis. Our results demonstrate that multiple purpose-built\nneural networks can function in sequence to accomplish the complex series of\ntasks required for automated analysis of real-world angiograms. Deployment of\nCathAI may serve to increase standardization and reproducibility in coronary\nstenosis assessment, while providing a robust foundation to accomplish future\ntasks for algorithmic angiographic interpretation.",
          "link": "http://arxiv.org/abs/2106.07708",
          "publishedOn": "2021-06-16T01:21:05.088Z",
          "wordCount": 727,
          "title": "CathAI: Fully Automated Interpretation of Coronary Angiograms Using Neural Networks. (arXiv:2106.07708v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07853",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wan_L/0/1/0/all/0/1\">Lin Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1\">Zongyuan Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jing_Q/0/1/0/all/0/1\">Qianyan Jing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yehansen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_L/0/1/0/all/0/1\">Lijing Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhihang Li</a>",
          "description": "RGB-Infrared (IR) person re-identification aims to retrieve\nperson-of-interest between heterogeneous modalities, suffering from large\nmodality discrepancy caused by different sensory devices. Existing methods\nmainly focus on global-level modality alignment, whereas neglect sample-level\nmodality divergence to some extent, leading to performance degradation. This\npaper attempts to find RGB-IR ReID solutions from tackling sample-level\nmodality difference, and presents a Geometry-Guided Dual-Alignment learning\nframework (G$^2$DA), which jointly enhances modality-invariance and reinforces\ndiscriminability with human topological structure in features to boost the\noverall matching performance. Specifically, G$^2$DA extracts accurate body part\nfeatures with a pose estimator, serving as a semantic bridge complementing the\nmissing local details in global descriptor. Based on extracted local and global\nfeatures, a novel distribution constraint derived from optimal transport is\nintroduced to mitigate the modality gap in a fine-grained sample-level manner.\nBeyond pair-wise relations across two modalities, it additionally measures the\nstructural similarity of different parts, thus both multi-level features and\ntheir relations are kept consistent in the common feature space. Considering\nthe inherent human-topology information, we further advance a geometry-guided\ngraph learning module to refine each part features, where relevant regions can\nbe emphasized while meaningless ones are suppressed, effectively facilitating\nrobust feature learning. Extensive experiments on two standard benchmark\ndatasets validate the superiority of our proposed method, yielding competitive\nperformance over the state-of-the-art approaches.",
          "link": "http://arxiv.org/abs/2106.07853",
          "publishedOn": "2021-06-16T01:21:05.074Z",
          "wordCount": 663,
          "title": "G$^2$DA: Geometry-Guided Dual-Alignment Learning for RGB-Infrared Person Re-Identification. (arXiv:2106.07853v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07929",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jing_J/0/1/0/all/0/1\">Junfeng Jing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_T/0/1/0/all/0/1\">Tian Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Weichuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yongsheng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1\">Changming Sun</a>",
          "description": "Interest point detection is one of the most fundamental and critical problems\nin computer vision and image processing. In this paper, we carry out a\ncomprehensive review on image feature information (IFI) extraction techniques\nfor interest point detection. To systematically introduce how the existing\ninterest point detection methods extract IFI from an input image, we propose a\ntaxonomy of the IFI extraction techniques for interest point detection.\nAccording to this taxonomy, we discuss different types of IFI extraction\ntechniques for interest point detection. Furthermore, we identify the main\nunresolved issues related to the existing IFI extraction techniques for\ninterest point detection and any interest point detection methods that have not\nbeen discussed before. The existing popular datasets and evaluation standards\nare provided and the performances for eighteen state-of-the-art approaches are\nevaluated and discussed. Moreover, future research directions on IFI extraction\ntechniques for interest point detection are elaborated.",
          "link": "http://arxiv.org/abs/2106.07929",
          "publishedOn": "2021-06-16T01:21:05.064Z",
          "wordCount": 585,
          "title": "Image Feature Information Extraction for Interest Point Detection: A Comprehensive Review. (arXiv:2106.07929v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08005",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiankun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1\">Xiaolan Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_C/0/1/0/all/0/1\">Chibiao Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yirong Wu</a>",
          "description": "At present, the Synthetic Aperture Radar (SAR) image classification method\nbased on convolution neural network (CNN) has faced some problems such as poor\nnoise resistance and generalization ability. Spiking neural network (SNN) is\none of the core components of brain-like intelligence and has good application\nprospects. This article constructs a complete SAR image classifier based on\nunsupervised and supervised learning of SNN by using spike sequences with\ncomplex spatio-temporal information. We firstly expound the spiking neuron\nmodel, the receptive field of SNN, and the construction of spike sequence. Then\nwe put forward an unsupervised learning algorithm based on STDP and a\nsupervised learning algorithm based on gradient descent. The average\nclassification accuracy of single layer and bilayer unsupervised learning SNN\nin three categories images on MSTAR dataset is 80.8\\% and 85.1\\%, respectively.\nFurthermore, the convergent output spike sequences of unsupervised learning can\nbe used as teaching signals. Based on the TensorFlow framework, a single layer\nsupervised learning SNN is built from the bottom, and the classification\naccuracy reaches 90.05\\%. By comparing noise resistance and model parameters\nbetween SNNs and CNNs, the effectiveness and outstanding advantages of SNN are\nverified. Code to reproduce our experiments is available at\n\\url{https://github.com/Jiankun-chen/Supervised-SNN-with-GD}.",
          "link": "http://arxiv.org/abs/2106.08005",
          "publishedOn": "2021-06-16T01:21:05.053Z",
          "wordCount": 643,
          "title": "SAR Image Classification Based on Spiking Neural Network through Spike-Time Dependent Plasticity and Gradient Descent. (arXiv:2106.08005v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07856",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Diana Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prabhakara_A/0/1/0/all/0/1\">Akarsh Prabhakara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Munir_S/0/1/0/all/0/1\">Sirajum Munir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sankaranarayanan_A/0/1/0/all/0/1\">Aswin Sankaranarayanan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Swarun Kumar</a>",
          "description": "mmWave radars offer excellent depth resolution owing to their high bandwidth\nat mmWave radio frequencies. Yet, they suffer intrinsically from poor angular\nresolution, that is an order-of-magnitude worse than camera systems, and are\ntherefore not a capable 3-D imaging solution in isolation. We propose\nMetamoran, a system that combines the complimentary strengths of radar and\ncamera systems to obtain depth images at high azimuthal resolutions at\ndistances of several tens of meters with high accuracy, all from a single fixed\nvantage point. Metamoran enables rich long-range depth imaging outdoors with\napplications to roadside safety infrastructure, surveillance and wide-area\nmapping. Our key insight is to use the high azimuth resolution from cameras\nusing computer vision techniques, including image segmentation and monocular\ndepth estimation, to obtain object shapes and use these as priors for our novel\nspecular beamforming algorithm. We also design this algorithm to work in\ncluttered environments with weak reflections and in partially occluded\nscenarios. We perform a detailed evaluation of Metamoran's depth imaging and\nsensing capabilities in 200 diverse scenes at a major U.S. city. Our evaluation\nshows that Metamoran estimates the depth of an object up to 60~m away with a\nmedian error of 28~cm, an improvement of 13$\\times$ compared to a naive\nradar+camera baseline and 23$\\times$ compared to monocular depth estimation.",
          "link": "http://arxiv.org/abs/2106.07856",
          "publishedOn": "2021-06-16T01:21:05.043Z",
          "wordCount": 663,
          "title": "A Hybrid mmWave and Camera System for Long-Range Depth Imaging. (arXiv:2106.07856v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07696",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tatikonda_S/0/1/0/all/0/1\">Sinzith Tatikonda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nambiar_A/0/1/0/all/0/1\">Athira Nambiar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mittal_A/0/1/0/all/0/1\">Anurag Mittal</a>",
          "description": "Face is one of the predominant means of person recognition. In the process of\nageing, human face is prone to many factors such as time, attributes, weather\nand other subject specific variations. The impact of these factors were not\nwell studied in the literature of face aging. In this paper, we propose a novel\nholistic model in this regard viz., ``Face Age progression With Attribute\nManipulation (FAWAM)\", i.e. generating face images at different ages while\nsimultaneously varying attributes and other subject specific characteristics.\nWe address the task in a bottom-up manner, as two submodules i.e. face age\nprogression and face attribute manipulation. For face aging, we use an\nattribute-conscious face aging model with a pyramidal generative adversarial\nnetwork that can model age-specific facial changes while maintaining intrinsic\nsubject specific characteristics. For facial attribute manipulation, the age\nprocessed facial image is manipulated with desired attributes while preserving\nother details unchanged, leveraging an attribute generative adversarial network\narchitecture. We conduct extensive analysis in standard large scale datasets\nand our model achieves significant performance both quantitatively and\nqualitatively.",
          "link": "http://arxiv.org/abs/2106.07696",
          "publishedOn": "2021-06-16T01:21:04.986Z",
          "wordCount": 605,
          "title": "Face Age Progression With Attribute Manipulation. (arXiv:2106.07696v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07873",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Asnani_V/0/1/0/all/0/1\">Vishal Asnani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_X/0/1/0/all/0/1\">Xi Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hassner_T/0/1/0/all/0/1\">Tal Hassner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaoming Liu</a>",
          "description": "State-of-the-art (SOTA) Generative Models (GMs) can synthesize\nphoto-realistic images that are hard for humans to distinguish from genuine\nphotos. We propose to perform reverse engineering of GMs to infer the model\nhyperparameters from the images generated by these models. We define a novel\nproblem, \"model parsing\", as estimating GM network architectures and training\nloss functions by examining their generated images -- a task seemingly\nimpossible for human beings. To tackle this problem, we propose a framework\nwith two components: a Fingerprint Estimation Network (FEN), which estimates a\nGM fingerprint from a generated image by training with four constraints to\nencourage the fingerprint to have desired properties, and a Parsing Network\n(PN), which predicts network architecture and loss functions from the estimated\nfingerprints. To evaluate our approach, we collect a fake image dataset with\n$100$K images generated by $100$ GMs. Extensive experiments show encouraging\nresults in parsing the hyperparameters of the unseen models. Finally, our\nfingerprint estimation can be leveraged for deepfake detection and image\nattribution, as we show by reporting SOTA results on both the recent Celeb-DF\nand image attribution benchmarks.",
          "link": "http://arxiv.org/abs/2106.07873",
          "publishedOn": "2021-06-16T01:21:04.812Z",
          "wordCount": 624,
          "title": "Reverse Engineering of Generative Models: Inferring Model Hyperparameters from Generated Images. (arXiv:2106.07873v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07771",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1\">Jian Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chai_M/0/1/0/all/0/1\">Menglei Chai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woodford_O/0/1/0/all/0/1\">Oliver J. Woodford</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Olszewski_K/0/1/0/all/0/1\">Kyle Olszewski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tulyakov_S/0/1/0/all/0/1\">Sergey Tulyakov</a>",
          "description": "Human motion retargeting aims to transfer the motion of one person in a\n\"driving\" video or set of images to another person. Existing efforts leverage a\nlong training video from each target person to train a subject-specific motion\ntransfer model. However, the scalability of such methods is limited, as each\nmodel can only generate videos for the given target subject, and such training\nvideos are labor-intensive to acquire and process. Few-shot motion transfer\ntechniques, which only require one or a few images from a target, have recently\ndrawn considerable attention. Methods addressing this task generally use either\n2D or explicit 3D representations to transfer motion, and in doing so,\nsacrifice either accurate geometric modeling or the flexibility of an\nend-to-end learned representation. Inspired by the Transformable Bottleneck\nNetwork, which renders novel views and manipulations of rigid objects, we\npropose an approach based on an implicit volumetric representation of the image\ncontent, which can then be spatially manipulated using volumetric flow fields.\nWe address the challenging question of how to aggregate information across\ndifferent body poses, learning flow fields that allow for combining content\nfrom the appropriate regions of input images of highly non-rigid human subjects\nperforming complex motions into a single implicit volumetric representation.\nThis allows us to learn our 3D representation solely from videos of moving\npeople. Armed with both 3D object understanding and end-to-end learned\nrendering, this categorically novel representation delivers state-of-the-art\nimage generation quality, as shown by our quantitative and qualitative\nevaluations.",
          "link": "http://arxiv.org/abs/2106.07771",
          "publishedOn": "2021-06-16T01:21:04.784Z",
          "wordCount": 680,
          "title": "Flow Guided Transformable Bottleneck Networks for Motion Retargeting. (arXiv:2106.07771v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07770",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Butte_S/0/1/0/all/0/1\">Sujata Butte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vakanski_A/0/1/0/all/0/1\">Aleksandar Vakanski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duellman_K/0/1/0/all/0/1\">Kasia Duellman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haotian Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mirkouei_A/0/1/0/all/0/1\">Amin Mirkouei</a>",
          "description": "Recent research on the application of remote sensing and deep learning-based\nanalysis in precision agriculture demonstrated a potential for improved crop\nmanagement and reduced environmental impacts of agricultural production.\nDespite the promising results, the practical relevance of these technologies\nfor actual field deployment requires novel algorithms that are customized for\nanalysis of agricultural images and robust to implementation on natural field\nimagery. The paper presents an approach for analyzing aerial images of a potato\ncrop using deep neural networks. The main objective is to demonstrate automated\nspatial recognition of a healthy versus stressed crop at a plant level.\nSpecifically, we examine premature plant senescence resulting in drought stress\non Russet Burbank potato plants. The proposed deep learning model, named\nRetina-UNet-Ag, is a variant of Retina-UNet (Jaeger et al., 2018) and includes\nconnections from low-level semantic dense representation maps to the feature\npyramid network. The paper also introduces a dataset of field images acquired\nwith a Parrot Sequoia camera carried by a Solo unmanned aerial vehicle.\nExperimental validation demonstrated the ability for distinguishing healthy and\nstressed plants in field images, achieving an average Dice score coefficient of\n0.74. A comparison to related state-of-the-art deep learning models for object\ndetection revealed that the presented approach is effective for the task at\nhand. The method applied here is conducive toward the assessment and\nrecognition of potato crop stress (early plant senescence resulting from\ndrought stress in this case) in natural aerial field images collected under\nreal conditions.",
          "link": "http://arxiv.org/abs/2106.07770",
          "publishedOn": "2021-06-16T01:21:04.759Z",
          "wordCount": 692,
          "title": "Potato Crop Stress Identification in Aerial Images using Deep Learning-based Object Detection. (arXiv:2106.07770v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07732",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Changan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1\">Wei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harwath_D/0/1/0/all/0/1\">David Harwath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grauman_K/0/1/0/all/0/1\">Kristen Grauman</a>",
          "description": "Reverberation from audio reflecting off surfaces and objects in the\nenvironment not only degrades the quality of speech for human perception, but\nalso severely impacts the accuracy of automatic speech recognition. Prior work\nattempts to remove reverberation based on the audio modality only. Our idea is\nto learn to dereverberate speech from audio-visual observations. The visual\nenvironment surrounding a human speaker reveals important cues about the room\ngeometry, materials, and speaker location, all of which influence the precise\nreverberation effects in the audio stream. We introduce Visually-Informed\nDereverberation of Audio (VIDA), an end-to-end approach that learns to remove\nreverberation based on both the observed sounds and visual scene. In support of\nthis new task, we develop a large-scale dataset that uses realistic acoustic\nrenderings of speech in real-world 3D scans of homes offering a variety of room\nacoustics. Demonstrating our approach on both simulated and real imagery for\nspeech enhancement, speech recognition, and speaker identification, we show it\nachieves state-of-the-art performance and substantially improves over\ntraditional audio-only methods. Project page:\nthis http URL",
          "link": "http://arxiv.org/abs/2106.07732",
          "publishedOn": "2021-06-16T01:21:04.744Z",
          "wordCount": 602,
          "title": "Learning Audio-Visual Dereverberation. (arXiv:2106.07732v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07806",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Bridge_C/0/1/0/all/0/1\">Christopher P. Bridge</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gorman_C/0/1/0/all/0/1\">Chris Gorman</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pieper_S/0/1/0/all/0/1\">Steven Pieper</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Doyle_S/0/1/0/all/0/1\">Sean W. Doyle</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lennerz_J/0/1/0/all/0/1\">Jochen K. Lennerz</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kalpathy_Cramer_J/0/1/0/all/0/1\">Jayashree Kalpathy-Cramer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Clunie_D/0/1/0/all/0/1\">David A. Clunie</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fedorov_A/0/1/0/all/0/1\">Andriy Y. Fedorov</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Herrmann_M/0/1/0/all/0/1\">Markus D. Herrmann</a>",
          "description": "Machine learning is revolutionizing image-based diagnostics in pathology and\nradiology. ML models have shown promising results in research settings, but\ntheir lack of interoperability has been a major barrier for clinical\nintegration and evaluation. The DICOM a standard specifies Information Object\nDefinitions and Services for the representation and communication of digital\nimages and related information, including image-derived annotations and\nanalysis results. However, the complexity of the standard represents an\nobstacle for its adoption in the ML community and creates a need for software\nlibraries and tools that simplify working with data sets in DICOM format. Here\nwe present the highdicom library, which provides a high-level application\nprogramming interface for the Python programming language that abstracts\nlow-level details of the standard and enables encoding and decoding of\nimage-derived information in DICOM format in a few lines of Python code. The\nhighdicom library ties into the extensive Python ecosystem for image processing\nand machine learning. Simultaneously, by simplifying creation and parsing of\nDICOM-compliant files, highdicom achieves interoperability with the medical\nimaging systems that hold the data used to train and run ML models, and\nultimately communicate and store model outputs for clinical use. We demonstrate\nthrough experiments with slide microscopy and computed tomography imaging,\nthat, by bridging these two ecosystems, highdicom enables developers to train\nand evaluate state-of-the-art ML models in pathology and radiology while\nremaining compliant with the DICOM standard and interoperable with clinical\nsystems at all stages. To promote standardization of ML research and streamline\nthe ML model development and deployment process, we made the library available\nfree and open-source.",
          "link": "http://arxiv.org/abs/2106.07806",
          "publishedOn": "2021-06-16T01:21:04.724Z",
          "wordCount": 740,
          "title": "Highdicom: A Python library for standardized encoding of image annotations and machine learning model outputs in pathology and radiology. (arXiv:2106.07806v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04067",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shao_R/0/1/0/all/0/1\">Ruizhi Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_G/0/1/0/all/0/1\">Gaochang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yuemei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1\">Ying Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yebin Liu</a>",
          "description": "Cross-resolution image alignment is a key problem in multiscale gigapixel\nphotography, which requires to estimate homography matrix using images with\nlarge resolution gap. Existing deep homography methods concatenate the input\nimages or features, neglecting the explicit formulation of correspondences\nbetween them, which leads to degraded accuracy in cross-resolution challenges.\nIn this paper, we consider the cross-resolution homography estimation as a\nmultimodal problem, and propose a local transformer network embedded within a\nmultiscale structure to explicitly learn correspondences between the multimodal\ninputs, namely, input images with different resolutions. The proposed local\ntransformer adopts a local attention map specifically for each position in the\nfeature. By combining the local transformer with the multiscale structure, the\nnetwork is able to capture long-short range correspondences efficiently and\naccurately. Experiments on both the MS-COCO dataset and the real-captured\ncross-resolution dataset show that the proposed network outperforms existing\nstate-of-the-art feature-based and deep-learning-based homography estimation\nmethods, and is able to accurately align images under $10\\times$ resolution\ngap.",
          "link": "http://arxiv.org/abs/2106.04067",
          "publishedOn": "2021-06-15T22:41:25.275Z",
          "wordCount": 613,
          "title": "LocalTrans: A Multiscale Local Transformer Network for Cross-Resolution Homography Estimation. (arXiv:2106.04067v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06769",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Junfu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bi Wang</a>",
          "description": "Working memory (WM) is a basic part of human cognition, which plays an\nimportant role in the study of human cognitive load. Among various brain\nimaging techniques, electroencephalography has shown its advantage on easy\naccess and reliability. However, one of the critical challenges is that\nindividual difference may cause the ineffective results, especially when the\nestablished model meets an unfamiliar subject. In this work, we propose a\ncross-subject deep adaptation model with spatial attention (CS-DASA) to\ngeneralize the workload classifications across subjects. First, we transform\ntime-series EEG data into multi-frame EEG images incorporating more\nspatio-temporal information. First, the subject-shared module in CS-DASA\nreceives multi-frame EEG image data from both source and target subjects and\nlearns the common feature representations. Then, in subject-specific module,\nthe maximum mean discrepancy is implemented to measure the domain distribution\ndivergence in a reproducing kernel Hilbert space, which can add an effective\npenalty loss for domain adaptation. Additionally, the subject-to-subject\nspatial attention mechanism is employed to focus on the most discriminative\nspatial feature in EEG image data. Experiments conducted on a public WM EEG\ndataset containing 13 subjects show that the proposed model is capable of\nachieve better performance than existing state-of-the art methods.",
          "link": "http://arxiv.org/abs/2106.06769",
          "publishedOn": "2021-06-15T22:07:49.048Z",
          "wordCount": 632,
          "title": "Cross-Subject Domain Adaptation for Multi-Frame EEG Images. (arXiv:2106.06769v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06911",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lo_S/0/1/0/all/0/1\">Shaw-Hwa Lo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1\">Yiqiao Yin</a>",
          "description": "The field of Explainable Artificial Intelligence (XAI) aims to build\nexplainable and interpretable machine learning (or deep learning) methods\nwithout sacrificing prediction performance. Convolutional Neural Networks\n(CNNs) have been successful in making predictions, especially in image\nclassification. However, these famous deep learning models use tens of millions\nof parameters based on a large number of pre-trained filters which have been\nrepurposed from previous data sets. We propose a novel Interaction-based\nConvolutional Neural Network (ICNN) that does not make assumptions about the\nrelevance of local information. Instead, we use a model-free Influence Score\n(I-score) to directly extract the influential information from images to form\nimportant variable modules. We demonstrate that the proposed method produces\nstate-of-the-art prediction performance of 99.8% on a real-world data set\nclassifying COVID-19 Chest X-ray images without sacrificing the explanatory\npower of the model. This proposed design can efficiently screen COVID-19\npatients before human diagnosis, and will be the benchmark for addressing\nfuture XAI problems in large-scale data sets.",
          "link": "http://arxiv.org/abs/2106.06911",
          "publishedOn": "2021-06-15T01:45:20.380Z",
          "wordCount": 641,
          "title": "An Interaction-based Convolutional Neural Network (ICNN) Towards Better Understanding of COVID-19 X-ray Images. (arXiv:2106.06911v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.12924",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiang_J/0/1/0/all/0/1\">Jinxi Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhuowei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenji Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Q/0/1/0/all/0/1\">Qing Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shaoting Zhang</a>",
          "description": "Deep learning has demonstrated significant improvements in medical image\nsegmentation using a sufficiently large amount of training data with manual\nlabels. Acquiring well-representative labels requires expert knowledge and\nexhaustive labors. In this paper, we aim to boost the performance of\nsemi-supervised learning for medical image segmentation with limited labels\nusing a self-ensembling contrastive learning technique. To this end, we propose\nto train an encoder-decoder network at image-level with small amounts of\nlabeled images, and more importantly, we learn latent representations directly\nat feature-level by imposing contrastive loss on unlabeled images. This method\nstrengthens intra-class compactness and inter-class separability, so as to get\na better pixel classifier. Moreover, we devise a student encoder for online\nlearning and an exponential moving average version of it, called teacher\nencoder, to improve the performance iteratively in a self-ensembling manner. To\nconstruct contrastive samples with unlabeled images, two sampling strategies\nthat exploit structure similarity across medical images and utilize\npseudo-labels for construction, termed region-aware and anatomical-aware\ncontrastive sampling, are investigated. We conduct extensive experiments on an\nMRI and a CT segmentation dataset and demonstrate that in a limited label\nsetting, the proposed method achieves state-of-the-art performance. Moreover,\nthe anatomical-aware strategy that prepares contrastive samples on-the-fly\nusing pseudo-labels realizes better contrastive regularization on feature\nrepresentations.",
          "link": "http://arxiv.org/abs/2105.12924",
          "publishedOn": "2021-06-15T01:45:20.286Z",
          "wordCount": 668,
          "title": "Self-Ensembling Contrastive Learning for Semi-Supervised Medical Image Segmentation. (arXiv:2105.12924v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06856",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Quach_K/0/1/0/all/0/1\">Kha Gia Quach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_P/0/1/0/all/0/1\">Pha Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_H/0/1/0/all/0/1\">Huu Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Truong_T/0/1/0/all/0/1\">Thanh-Dat Truong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duong_C/0/1/0/all/0/1\">Chi Nhan Duong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_M/0/1/0/all/0/1\">Minh-Triet Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luu_K/0/1/0/all/0/1\">Khoa Luu</a>",
          "description": "Multi-Camera Multiple Object Tracking (MC-MOT) is a significant computer\nvision problem due to its emerging applicability in several real-world\napplications. Despite a large number of existing works, solving the data\nassociation problem in any MC-MOT pipeline is arguably one of the most\nchallenging tasks. Developing a robust MC-MOT system, however, is still highly\nchallenging due to many practical issues such as inconsistent lighting\nconditions, varying object movement patterns, or the trajectory occlusions of\nthe objects between the cameras. To address these problems, this work,\ntherefore, proposes a new Dynamic Graph Model with Link Prediction (DyGLIP)\napproach to solve the data association task. Compared to existing methods, our\nnew model offers several advantages, including better feature representations\nand the ability to recover from lost tracks during camera transitions.\nMoreover, our model works gracefully regardless of the overlapping ratios\nbetween the cameras. Experimental results show that we outperform existing\nMC-MOT algorithms by a large margin on several practical datasets. Notably, our\nmodel works favorably on online settings but can be extended to an incremental\napproach for large-scale datasets.",
          "link": "http://arxiv.org/abs/2106.06856",
          "publishedOn": "2021-06-15T01:45:20.274Z",
          "wordCount": 632,
          "title": "DyGLIP: A Dynamic Graph Model with Link Prediction for Accurate Multi-Camera Multiple Object Tracking. (arXiv:2106.06856v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06819",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sinha_A/0/1/0/all/0/1\">Abhishek Sinha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1\">Jiaming Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_C/0/1/0/all/0/1\">Chenlin Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ermon_S/0/1/0/all/0/1\">Stefano Ermon</a>",
          "description": "Conditional generative models of high-dimensional images have many\napplications, but supervision signals from conditions to images can be\nexpensive to acquire. This paper describes Diffusion-Decoding models with\nContrastive representations (D2C), a paradigm for training unconditional\nvariational autoencoders (VAEs) for few-shot conditional image generation. D2C\nuses a learned diffusion-based prior over the latent representations to improve\ngeneration and contrastive self-supervised learning to improve representation\nquality. D2C can adapt to novel generation tasks conditioned on labels or\nmanipulation constraints, by learning from as few as 100 labeled examples. On\nconditional generation from new labels, D2C achieves superior performance over\nstate-of-the-art VAEs and diffusion models. On conditional image manipulation,\nD2C generations are two orders of magnitude faster to produce over StyleGAN2\nones and are preferred by 50% - 60% of the human evaluators in a double-blind\nstudy.",
          "link": "http://arxiv.org/abs/2106.06819",
          "publishedOn": "2021-06-15T01:45:19.652Z",
          "wordCount": null,
          "title": "D2C: Diffusion-Denoising Models for Few-shot Conditional Generation. (arXiv:2106.06819v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06654",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Evtimov_I/0/1/0/all/0/1\">Ivan Evtimov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Covert_I/0/1/0/all/0/1\">Ian Covert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kusupati_A/0/1/0/all/0/1\">Aditya Kusupati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kohno_T/0/1/0/all/0/1\">Tadayoshi Kohno</a>",
          "description": "When data is publicly released for human consumption, it is unclear how to\nprevent its unauthorized usage for machine learning purposes. Successful model\ntraining may be preventable with carefully designed dataset modifications, and\nwe present a proof-of-concept approach for the image classification setting. We\npropose methods based on the notion of adversarial shortcuts, which encourage\nmodels to rely on non-robust signals rather than semantic features, and our\nexperiments demonstrate that these measures successfully prevent deep learning\nmodels from achieving high accuracy on real, unmodified data examples.",
          "link": "http://arxiv.org/abs/2106.06654",
          "publishedOn": "2021-06-15T01:45:19.642Z",
          "wordCount": null,
          "title": "Disrupting Model Training with Adversarial Shortcuts. (arXiv:2106.06654v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2104.10414",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1\">Zhong-Qiu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yao Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1\">Yuchen Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_W/0/1/0/all/0/1\">Weidong Tian</a>",
          "description": "Although deep convolution neural networks (DCNN) have achieved excellent\nperformance in human pose estimation, these networks often have a large number\nof parameters and computations, leading to the slow inference speed. For this\nissue, an effective solution is knowledge distillation, which transfers\nknowledge from a large pre-trained network (teacher) to a small network\n(student). However, there are some defects in the existing approaches: (I) Only\na single teacher is adopted, neglecting the potential that a student can learn\nfrom multiple teachers. (II) The human segmentation mask can be regarded as\nadditional prior information to restrict the location of keypoints, which is\nnever utilized. (III) A student with a small number of parameters cannot fully\nimitate heatmaps provided by datasets and teachers. (IV) There exists noise in\nheatmaps generated by teachers, which causes model degradation. To overcome\nthese defects, we propose an orderly dual-teacher knowledge distillation (ODKD)\nframework, which consists of two teachers with different capabilities.\nSpecifically, the weaker one (primary teacher, PT) is used to teach keypoints\ninformation, the stronger one (senior teacher, ST) is utilized to transfer\nsegmentation and keypoints information by adding the human segmentation mask.\nTaking dual-teacher together, an orderly learning strategy is proposed to\npromote knowledge absorbability. Moreover, we employ a binarization operation\nwhich further improves the learning ability of the student and reduces noise in\nheatmaps. Experimental results on COCO and OCHuman keypoints datasets show that\nour proposed ODKD can improve the performance of different lightweight models\nby a large margin, and HRNet-W16 equipped with ODKD achieves state-of-the-art\nperformance for lightweight human pose estimation.",
          "link": "http://arxiv.org/abs/2104.10414",
          "publishedOn": "2021-06-15T01:45:19.636Z",
          "wordCount": null,
          "title": "Orderly Dual-Teacher Knowledge Distillation for Lightweight Human Pose Estimation. (arXiv:2104.10414v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.04648",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_G/0/1/0/all/0/1\">Guihua Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chapman_A/0/1/0/all/0/1\">Adriane Chapman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_P/0/1/0/all/0/1\">Pei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_M/0/1/0/all/0/1\">Mingnan Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yingxue Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_D/0/1/0/all/0/1\">Dan Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hall_W/0/1/0/all/0/1\">Wendy Hall</a>",
          "description": "Zero-shot learning uses semantic attributes to connect the search space of\nunseen objects. In recent years, although the deep convolutional network brings\npowerful visual modeling capabilities to the ZSL task, its visual features have\nsevere pattern inertia and lack of representation of semantic relationships,\nwhich leads to severe bias and ambiguity. In response to this, we propose the\nGraph-based Visual-Semantic Entanglement Network to conduct graph modeling of\nvisual features, which is mapped to semantic attributes by using a knowledge\ngraph, it contains several novel designs: 1. it establishes a multi-path\nentangled network with the convolutional neural network (CNN) and the graph\nconvolutional network (GCN), which input the visual features from CNN to GCN to\nmodel the implicit semantic relations, then GCN feedback the graph modeled\ninformation to CNN features; 2. it uses attribute word vectors as the target\nfor the graph semantic modeling of GCN, which forms a self-consistent\nregression for graph modeling and supervise GCN to learn more personalized\nattribute relations; 3. it fuses and supplements the hierarchical\nvisual-semantic features refined by graph modeling into visual embedding. Our\nmethod outperforms state-of-the-art approaches on multiple representative ZSL\ndatasets: AwA2, CUB, and SUN by promoting the semantic linkage modelling of\nvisual features.",
          "link": "http://arxiv.org/abs/2006.04648",
          "publishedOn": "2021-06-15T01:45:19.617Z",
          "wordCount": null,
          "title": "Graph-based Visual-Semantic Entanglement Network for Zero-shot Image Recognition. (arXiv:2006.04648v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.02703",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1\">Tong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Ziwei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1\">Qingqiu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_D/0/1/0/all/0/1\">Dahua Lin</a>",
          "description": "Adversarial robustness has attracted extensive studies recently by revealing\nthe vulnerability and intrinsic characteristics of deep networks. However,\nexisting works on adversarial robustness mainly focus on balanced datasets,\nwhile real-world data usually exhibits a long-tailed distribution. To push\nadversarial robustness towards more realistic scenarios, in this work we\ninvestigate the adversarial vulnerability as well as defense under long-tailed\ndistributions. In particular, we first reveal the negative impacts induced by\nimbalanced data on both recognition performance and adversarial robustness,\nuncovering the intrinsic challenges of this problem. We then perform a\nsystematic study on existing long-tailed recognition methods in conjunction\nwith the adversarial training framework. Several valuable observations are\nobtained: 1) natural accuracy is relatively easy to improve, 2) fake gain of\nrobust accuracy exists under unreliable evaluation, and 3) boundary error\nlimits the promotion of robustness. Inspired by these observations, we propose\na clean yet effective framework, RoBal, which consists of two dedicated\nmodules, a scale-invariant classifier and data re-balancing via both margin\nengineering at training stage and boundary adjustment during inference.\nExtensive experiments demonstrate the superiority of our approach over other\nstate-of-the-art defense methods. To our best knowledge, we are the first to\ntackle adversarial robustness under long-tailed distributions, which we believe\nwould be a significant step towards real-world robustness. Our code is\navailable at: https://github.com/wutong16/Adversarial_Long-Tail .",
          "link": "http://arxiv.org/abs/2104.02703",
          "publishedOn": "2021-06-15T01:45:19.612Z",
          "wordCount": null,
          "title": "Adversarial Robustness under Long-Tailed Distribution. (arXiv:2104.02703v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1812.03664",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1\">Han-Jia Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Hexiang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_D/0/1/0/all/0/1\">De-Chuan Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sha_F/0/1/0/all/0/1\">Fei Sha</a>",
          "description": "Learning with limited data is a key challenge for visual recognition. Many\nfew-shot learning methods address this challenge by learning an instance\nembedding function from seen classes and apply the function to instances from\nunseen classes with limited labels. This style of transfer learning is\ntask-agnostic: the embedding function is not learned optimally discriminative\nwith respect to the unseen classes, where discerning among them leads to the\ntarget task. In this paper, we propose a novel approach to adapt the instance\nembeddings to the target classification task with a set-to-set function,\nyielding embeddings that are task-specific and are discriminative. We\nempirically investigated various instantiations of such set-to-set functions\nand observed the Transformer is most effective -- as it naturally satisfies key\nproperties of our desired model. We denote this model as FEAT (few-shot\nembedding adaptation w/ Transformer) and validate it on both the standard\nfew-shot classification benchmark and four extended few-shot learning settings\nwith essential use cases, i.e., cross-domain, transductive, generalized\nfew-shot learning, and low-shot learning. It archived consistent improvements\nover baseline models as well as previous methods and established the new\nstate-of-the-art results on two benchmarks.",
          "link": "http://arxiv.org/abs/1812.03664",
          "publishedOn": "2021-06-15T01:45:19.604Z",
          "wordCount": null,
          "title": "Few-Shot Learning via Embedding Adaptation with Set-to-Set Functions. (arXiv:1812.03664v6 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.06192",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hicsonmez_S/0/1/0/all/0/1\">Samet Hicsonmez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samet_N/0/1/0/all/0/1\">Nermin Samet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akbas_E/0/1/0/all/0/1\">Emre Akbas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duygulu_P/0/1/0/all/0/1\">Pinar Duygulu</a>",
          "description": "We introduce a new method for generating color images from sketches or edge\nmaps. Current methods either require some form of additional user-guidance or\nare limited to the \"paired\" translation approach. We argue that segmentation\ninformation could provide valuable guidance for sketch colorization. To this\nend, we propose to leverage semantic image segmentation, as provided by a\ngeneral purpose panoptic segmentation network, to create an additional\nadversarial loss function. Our loss function can be integrated to any baseline\nGAN model. Our method is not limited to datasets that contain segmentation\nlabels, and it can be trained for \"unpaired\" translation tasks. We show the\neffectiveness of our method on four different datasets spanning scene level\nindoor, outdoor, and children book illustration images using qualitative,\nquantitative and user study analysis. Our model improves its baseline up to 35\npoints on the FID metric. Our code and pretrained models can be found at\nhttps://github.com/giddyyupp/AdvSegLoss.",
          "link": "http://arxiv.org/abs/2102.06192",
          "publishedOn": "2021-06-15T01:45:19.589Z",
          "wordCount": null,
          "title": "Adversarial Segmentation Loss for Sketch Colorization. (arXiv:2102.06192v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.06969",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhengyan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_G/0/1/0/all/0/1\">Guangxuan Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yongwei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_T/0/1/0/all/0/1\">Tian Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_F/0/1/0/all/0/1\">Fanchao Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yasheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1\">Xin Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>",
          "description": "Pre-trained models (PTMs) have been widely used in various downstream tasks.\nThe parameters of PTMs are distributed on the Internet and may suffer backdoor\nattacks. In this work, we demonstrate the universal vulnerability of PTMs,\nwhere fine-tuned PTMs can be easily controlled by backdoor attacks in arbitrary\ndownstream tasks. Specifically, attackers can add a simple pre-training task,\nwhich restricts the output representations of trigger instances to pre-defined\nvectors, namely neuron-level backdoor attack (NeuBA). If the backdoor\nfunctionality is not eliminated during fine-tuning, the triggers can make the\nfine-tuned model predict fixed labels by pre-defined vectors. In the\nexperiments of both natural language processing (NLP) and computer vision (CV),\nwe show that NeuBA absolutely controls the predictions for trigger instances\nwithout any knowledge of downstream tasks. Finally, we apply several defense\nmethods to NeuBA and find that model pruning is a promising direction to resist\nNeuBA by excluding backdoored neurons. Our findings sound a red alarm for the\nwide use of PTMs. Our source code and models are available at\n\\url{https://github.com/thunlp/NeuBA}.",
          "link": "http://arxiv.org/abs/2101.06969",
          "publishedOn": "2021-06-15T01:45:19.587Z",
          "wordCount": null,
          "title": "Red Alarm for Pre-trained Models: Universal Vulnerability to Neuron-Level Backdoor Attacks. (arXiv:2101.06969v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06866",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Reddy_P/0/1/0/all/0/1\">Pradyumna Reddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhifei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fisher_M/0/1/0/all/0/1\">Matthew Fisher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_H/0/1/0/all/0/1\">Hailin Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhaowen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitra_N/0/1/0/all/0/1\">Niloy J. Mitra</a>",
          "description": "Fonts are ubiquitous across documents and come in a variety of styles. They\nare either represented in a native vector format or rasterized to produce fixed\nresolution images. In the first case, the non-standard representation prevents\nbenefiting from latest network architectures for neural representations; while,\nin the latter case, the rasterized representation, when encoded via networks,\nresults in loss of data fidelity, as font-specific discontinuities like edges\nand corners are difficult to represent using neural networks. Based on the\nobservation that complex fonts can be represented by a superposition of a set\nof simpler occupancy functions, we introduce \\textit{multi-implicits} to\nrepresent fonts as a permutation-invariant set of learned implict functions,\nwithout losing features (e.g., edges and corners). However, while\nmulti-implicits locally preserve font features, obtaining supervision in the\nform of ground truth multi-channel signals is a problem in itself. Instead, we\npropose how to train such a representation with only local supervision, while\nthe proposed neural architecture directly finds globally consistent\nmulti-implicits for font families. We extensively evaluate the proposed\nrepresentation for various tasks including reconstruction, interpolation, and\nsynthesis to demonstrate clear advantages with existing alternatives.\nAdditionally, the representation naturally enables glyph completion, wherein a\nsingle characteristic font is used to synthesize a whole font family in the\ntarget style.",
          "link": "http://arxiv.org/abs/2106.06866",
          "publishedOn": "2021-06-15T01:45:19.572Z",
          "wordCount": 643,
          "title": "A Multi-Implicit Neural Representation for Fonts. (arXiv:2106.06866v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10620",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yan_S/0/1/0/all/0/1\">Siming Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhenpei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1\">Chongyang Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Haibin Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vouga_E/0/1/0/all/0/1\">Etienne Vouga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1\">Qixing Huang</a>",
          "description": "This paper introduces HPNet, a novel deep-learning approach for segmenting a\n3D shape represented as a point cloud into primitive patches. The key to deep\nprimitive segmentation is learning a feature representation that can separate\npoints of different primitives. Unlike utilizing a single feature\nrepresentation, HPNet leverages hybrid representations that combine one learned\nsemantic descriptor, two spectral descriptors derived from predicted geometric\nparameters, as well as an adjacency matrix that encodes sharp edges. Moreover,\ninstead of merely concatenating the descriptors, HPNet optimally combines\nhybrid representations by learning combination weights. This weighting module\nbuilds on the entropy of input features. The output primitive segmentation is\nobtained from a mean-shift clustering module. Experimental results on benchmark\ndatasets ANSI and ABCParts show that HPNet leads to significant performance\ngains from baseline approaches.",
          "link": "http://arxiv.org/abs/2105.10620",
          "publishedOn": "2021-06-15T01:45:19.463Z",
          "wordCount": null,
          "title": "HPNet: Deep Primitive Segmentation Using Hybrid Representations. (arXiv:2105.10620v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1906.00460",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Malyshkin_V/0/1/0/all/0/1\">Vladislav Gennadievich Malyshkin</a>",
          "description": "Problems of interpolation, classification, and clustering are considered. In\nthe tenets of Radon--Nikodym approach $\\langle f(\\mathbf{x})\\psi^2 \\rangle /\n\\langle\\psi^2\\rangle$, where the $\\psi(\\mathbf{x})$ is a linear function on\ninput attributes, all the answers are obtained from a generalized eigenproblem\n$|f|\\psi^{[i]}\\rangle = \\lambda^{[i]} |\\psi^{[i]}\\rangle$. The solution to the\ninterpolation problem is a regular Radon-Nikodym derivative. The solution to\nthe classification problem requires prior and posterior probabilities that are\nobtained using the Lebesgue quadrature[1] technique. Whereas in a Bayesian\napproach new observations change only outcome probabilities, in the\nRadon-Nikodym approach not only outcome probabilities but also the probability\nspace $|\\psi^{[i]}\\rangle$ change with new observations. This is a remarkable\nfeature of the approach: both the probabilities and the probability space are\nconstructed from the data. The Lebesgue quadrature technique can be also\napplied to the optimal clustering problem. The problem is solved by\nconstructing a Gaussian quadrature on the Lebesgue measure. A distinguishing\nfeature of the Radon-Nikodym approach is the knowledge of the invariant group:\nall the answers are invariant relatively any non-degenerated linear transform\nof input vector $\\mathbf{x}$ components. A software product implementing the\nalgorithms of interpolation, classification, and optimal clustering is\navailable from the authors.",
          "link": "http://arxiv.org/abs/1906.00460",
          "publishedOn": "2021-06-15T01:45:19.457Z",
          "wordCount": null,
          "title": "On The Radon-Nikodym Spectral Approach With Optimal Clustering. (arXiv:1906.00460v16 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06579",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Venkatesha_Y/0/1/0/all/0/1\">Yeshwanth Venkatesha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Youngeun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tassiulas_L/0/1/0/all/0/1\">Leandros Tassiulas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panda_P/0/1/0/all/0/1\">Priyadarshini Panda</a>",
          "description": "As neural networks get widespread adoption in resource-constrained embedded\ndevices, there is a growing need for low-power neural systems. Spiking Neural\nNetworks (SNNs)are emerging to be an energy-efficient alternative to the\ntraditional Artificial Neural Networks (ANNs) which are known to be\ncomputationally intensive. From an application perspective, as federated\nlearning involves multiple energy-constrained devices, there is a huge scope to\nleverage energy efficiency provided by SNNs. Despite its importance, there has\nbeen little attention on training SNNs on a large-scale distributed system like\nfederated learning. In this paper, we bring SNNs to a more realistic federated\nlearning scenario. Specifically, we propose a federated learning framework for\ndecentralized and privacy-preserving training of SNNs. To validate the proposed\nfederated learning framework, we experimentally evaluate the advantages of SNNs\non various aspects of federated learning with CIFAR10 and CIFAR100 benchmarks.\nWe observe that SNNs outperform ANNs in terms of overall accuracy by over 15%\nwhen the data is distributed across a large number of clients in the federation\nwhile providing up to5.3x energy efficiency. In addition to efficiency, we also\nanalyze the sensitivity of the proposed federated SNN framework to data\ndistribution among the clients, stragglers, and gradient noise and perform a\ncomprehensive comparison with ANNs.",
          "link": "http://arxiv.org/abs/2106.06579",
          "publishedOn": "2021-06-15T01:45:19.397Z",
          "wordCount": null,
          "title": "Federated Learning with Spiking Neural Networks. (arXiv:2106.06579v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06847",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1\">Jiezhang Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yawei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1\">Luc Van Gool</a>",
          "description": "Video super-resolution (VSR), with the aim to restore a high-resolution video\nfrom its corresponding low-resolution version, is a spatial-temporal sequence\nprediction problem. Recently, Transformer has been gaining popularity due to\nits parallel computing ability for sequence-to-sequence modeling. Thus, it\nseems to be straightforward to apply the vision Transformer to solve VSR.\nHowever, the typical block design of Transformer with a fully connected\nself-attention layer and a token-wise feed-forward layer does not fit well for\nVSR due to the following two reasons. First, the fully connected self-attention\nlayer neglects to exploit the data locality because this layer relies on linear\nlayers to compute attention maps. Second, the token-wise feed-forward layer\nlacks the feature alignment which is important for VSR since this layer\nindependently processes each of the input token embeddings without any\ninteraction among them. In this paper, we make the first attempt to adapt\nTransformer for VSR. Specifically, to tackle the first issue, we present a\nspatial-temporal convolutional self-attention layer with a theoretical\nunderstanding to exploit the locality information. For the second issue, we\ndesign a bidirectional optical flow-based feed-forward layer to discover the\ncorrelations across different video frames and also align features. Extensive\nexperiments on several benchmark datasets demonstrate the effectiveness of our\nproposed method. The code will be available at\nhttps://github.com/caojiezhang/VSR-Transformer.",
          "link": "http://arxiv.org/abs/2106.06847",
          "publishedOn": "2021-06-15T01:45:19.384Z",
          "wordCount": 636,
          "title": "Video Super-Resolution Transformer. (arXiv:2106.06847v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00305",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ruis_F/0/1/0/all/0/1\">Frank Ruis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burghouts_G/0/1/0/all/0/1\">Gertjan Burghouts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bucur_D/0/1/0/all/0/1\">Doina Bucur</a>",
          "description": "Humans are good at compositional zero-shot reasoning; someone who has never\nseen a zebra before could nevertheless recognize one when we tell them it looks\nlike a horse with black and white stripes. Machine learning systems, on the\nother hand, usually leverage spurious correlations in the training data, and\nwhile such correlations can help recognize objects in context, they hurt\ngeneralization. To be able to deal with underspecified datasets while still\nleveraging contextual clues during classification, we propose ProtoProp, a\nnovel prototype propagation graph method. First we learn prototypical\nrepresentations of objects (e.g., zebra) that are conditionally independent\nw.r.t. their attribute labels (e.g., stripes) and vice versa. Next we propagate\nthe independent prototypes through a compositional graph, to learn\ncompositional prototypes of novel attribute-object combinations that reflect\nthe dependencies of the target distribution. The method does not rely on any\nexternal data, such as class hierarchy graphs or pretrained word embeddings. We\nevaluate our approach on AO-Clever, a synthetic and strongly visual dataset\nwith clean labels, and UT-Zappos, a noisy real-world dataset of fine-grained\nshoe types. We show that in the generalized compositional zero-shot setting we\noutperform state-of-the-art results, and through ablations we show the\nimportance of each part of the method and their contribution to the final\nresults.",
          "link": "http://arxiv.org/abs/2106.00305",
          "publishedOn": "2021-06-15T01:45:19.291Z",
          "wordCount": null,
          "title": "Independent Prototype Propagation for Zero-Shot Compositionality. (arXiv:2106.00305v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.00268",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Lei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xinyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Li Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1\">Minghan Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jun Li</a>",
          "description": "3D object detection with a single image is an essential and challenging task\nfor autonomous driving. Recently, keypoint-based monocular 3D object detection\nhas made tremendous progress and achieved great speed-accuracy trade-off.\nHowever, there still exists a huge gap with LIDAR-based methods in terms of\naccuracy. To improve their performance without sacrificing efficiency, we\npropose a sort of lightweight feature pyramid network called Lite-FPN to\nachieve multi-scale feature fusion in an effective and efficient way, which can\nboost the multi-scale detection capability of keypoint-based detectors.\nBesides, the misalignment between classification score and localization\nprecision is further relieved by introducing a novel regression loss named\nattention loss. With the proposed loss, predictions with high confidence but\npoor localization are treated with more attention during the training phase.\nComparative experiments based on several state-of-the-art keypoint-based\ndetectors on the KITTI dataset show that our proposed methods manage to achieve\nsignificant improvements in both accuracy and frame rate. The code and\npretrained models will be released at\n\\url{https://github.com/yanglei18/Lite-FPN}.",
          "link": "http://arxiv.org/abs/2105.00268",
          "publishedOn": "2021-06-15T01:45:19.277Z",
          "wordCount": 629,
          "title": "Lite-FPN for Keypoint-based Monocular 3D Object Detection. (arXiv:2105.00268v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.11092",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ye_Y/0/1/0/all/0/1\">Yuanxin Ye</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_C/0/1/0/all/0/1\">Chao Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhu_B/0/1/0/all/0/1\">Bai Zhu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+He_Y/0/1/0/all/0/1\">Youquan He</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jia_H/0/1/0/all/0/1\">Huarong Jia</a>",
          "description": "Co-registering the Sentinel-1 SAR and Sentinel-2 optical data of European\nSpace Agency (ESA) is of great importance for many remote sensing applications.\nHowever, we find that there are evident misregistration shifts between the\nSentinel-1 SAR and Sentinel-2 optical images that are directly downloaded from\nthe official website. To address that, this paper presents a fast and effective\nregistration method for the two types of images. In the proposed method, a\nblock-based scheme is first designed to extract evenly distributed interest\npoints. Then the correspondences are detected by using the similarity of\nstructural features between the SAR and optical images, where the three\ndimension (3D) phase correlation (PC) is used as the similarity measure for\naccelerating image matching. Finally, the obtained correspondences are employed\nto measure the misregistration shifts between the images. Moreover, to\neliminate the misregistration, we use some representative geometric\ntransformation models such as polynomial models, projective models, and\nrational function models for the co-registration of the two types of images,\nand compare and analyze their registration accuracy under different numbers of\ncontrol points and different terrains. Six pairs of the Sentinel-1 SAR L1 and\nSentinel-2 optical L1C images covering three different terrains are tested in\nour experiments. Experimental results show that the proposed method can achieve\nprecise correspondences between the images, and the 3rd. Order polynomial\nachieves the most satisfactory registration results. Its registration accuracy\nof the flat areas is less than 1.0 10m pixels, and that of the hilly areas is\nabout 1.5 10m pixels, and that of the mountainous areas is between 1.7 and 2.3\n10m pixels, which significantly improves the co-registration accuracy of the\nSentinel-1 SAR and Sentinel-2 optical images.",
          "link": "http://arxiv.org/abs/2005.11092",
          "publishedOn": "2021-06-15T01:45:19.241Z",
          "wordCount": 734,
          "title": "Improving Co-registration for Sentinel-1 SAR and Sentinel-2 Optical images. (arXiv:2005.11092v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06743",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Varmazyar_H/0/1/0/all/0/1\">Hadi Varmazyar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yousefi_Banaem_H/0/1/0/all/0/1\">Hossein Yousefi-Banaem</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Malekzadeh_S/0/1/0/all/0/1\">Saber Malekzadeh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gharehaghaji_N/0/1/0/all/0/1\">Nahideh Gharehaghaji</a>",
          "description": "Background: Alzheimers disease is a progressive neurodegenerative disorder\nand the main cause of dementia in aging. Hippocampus is prone to changes in the\nearly stages of Alzheimers disease. Detection and observation of the\nhippocampus changes using magnetic resonance imaging (MRI) before the onset of\nAlzheimers disease leads to the faster preventive and therapeutic measures.\nObjective: The aim of this study was the segmentation of the hippocampus in\nmagnetic resonance (MR) images of Alzheimers patients using deep machine\nlearning method. Methods: U-Net architecture of convolutional neural network\nwas proposed to segment the hippocampus in the real MRI data. The MR images of\nthe 100 and 35 patients available in Alzheimers disease Neuroimaging Initiative\n(ADNI) dataset, was used for the train and test of the model, respectively. The\nperformance of the proposed method was compared with manual segmentation by\nmeasuring the similarity metrics. Results: The desired segmentation achieved\nafter 10 iterations. A Dice similarity coefficient (DSC) = 92.3%, sensitivity =\n96.5%, positive predicted value (PPV) = 90.4%, and Intersection over Union\n(IoU) value for the train 92.94 and test 92.93 sets were obtained which are\nacceptable. Conclusion: The proposed approach is promising and can be extended\nin the prognosis of Alzheimers disease by the prediction of the hippocampus\nvolume changes in the early stage of the disease.",
          "link": "http://arxiv.org/abs/2106.06743",
          "publishedOn": "2021-06-15T01:45:19.102Z",
          "wordCount": 674,
          "title": "Hippocampus segmentation in magnetic resonance images of Alzheimer's patients using Deep machine learning. (arXiv:2106.06743v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2101.04230",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singla_S/0/1/0/all/0/1\">Sumedha Singla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pollack_B/0/1/0/all/0/1\">Brian Pollack</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wallace_S/0/1/0/all/0/1\">Stephen Wallace</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Batmanghelich_K/0/1/0/all/0/1\">Kayhan Batmanghelich</a>",
          "description": "We propose a BlackBox \\emph{Counterfactual Explainer} that is explicitly\ndeveloped for medical imaging applications. Classical approaches (e.g. saliency\nmaps) assessing feature importance do not explain \\emph{how} and \\emph{why}\nvariations in a particular anatomical region is relevant to the outcome, which\nis crucial for transparent decision making in healthcare application. Our\nframework explains the outcome by gradually \\emph{exaggerating} the semantic\neffect of the given outcome label. Given a query input to a classifier,\nGenerative Adversarial Networks produce a progressive set of perturbations to\nthe query image that gradually changes the posterior probability from its\noriginal class to its negation. We design the loss function to ensure that\nessential and potentially relevant details, such as support devices, are\npreserved in the counterfactually generated images. We provide an extensive\nevaluation of different classification tasks on the chest X-Ray images. Our\nexperiments show that a counterfactually generated visual explanation is\nconsistent with the disease's clinical relevant measurements, both\nquantitatively and qualitatively.",
          "link": "http://arxiv.org/abs/2101.04230",
          "publishedOn": "2021-06-15T01:45:19.036Z",
          "wordCount": 624,
          "title": "Explaining the Black-box Smoothly- A Counterfactual Approach. (arXiv:2101.04230v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.12854",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Wu_Z/0/1/0/all/0/1\">Zhaolong Wu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhang_S/0/1/0/all/0/1\">Shuwen Zhang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Wang_W/0/1/0/all/0/1\">Wei Li Wang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ma_Y/0/1/0/all/0/1\">Yinping Ma</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Dong_Y/0/1/0/all/0/1\">Yuanchen Dong</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Mao_Y/0/1/0/all/0/1\">Youdong Mao</a>",
          "description": "The 2.5-MDa 26S proteasome maintains proteostasis and regulates myriad\ncellular processes. How polyubiquitylated substrate interactions regulate\nproteasome activity is not understood. Here we introduce a deep manifold\nlearning framework, named AlphaCryo4D, which enables atomic-level cryogenic\nelectron microscopy (cryo-EM) reconstructions of nonequilibrium conformational\ncontinuum and reconstitutes hidden dynamics of proteasome autoregulation in the\nact of substrate degradation. AlphaCryo4D integrates 3D deep residual learning\nwith manifold embedding of free-energy landscapes, which directs 3D clustering\nvia an energy-based particle-voting algorithm. In blind assessments using\nsimulated heterogeneous cryo-EM datasets, AlphaCryo4D achieved 3D\nclassification accuracy three times that of conventional method and\nreconstructed continuous conformational changes of a 130-kDa protein at\nsub-3-angstrom resolution. By using AlphaCryo4D to analyze a single\nexperimental cryo-EM dataset, we identified 64 conformers of the\nsubstrate-bound human 26S proteasome, revealing conformational entanglement of\ntwo regulatory particles in the doubly capped holoenzymes and their energetic\ndifferences with singly capped ones. Novel ubiquitin-binding sites are\ndiscovered on the RPN2, RPN10 and Alpha5 subunits to remodel polyubiquitin\nchains for deubiquitylation and recycle. Importantly, AlphaCryo4D choreographs\nsingle-nucleotide-exchange dynamics of proteasomal AAA-ATPase motor during\ntranslocation initiation, which upregulates proteolytic activity by\nallosterically promoting nucleophilic attack. Our systemic analysis illuminates\na grand hierarchical allostery for proteasome autoregulation.",
          "link": "http://arxiv.org/abs/2012.12854",
          "publishedOn": "2021-06-15T01:45:18.985Z",
          "wordCount": 671,
          "title": "Deep manifold learning reveals hidden dynamics of proteasome autoregulation. (arXiv:2012.12854v2 [q-bio.QM] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06560",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1\">Mingyu Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lian_X/0/1/0/all/0/1\">Xiaochen Lian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Linjie Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Peng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1\">Xiaojie Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1\">Zhiwu Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_P/0/1/0/all/0/1\">Ping Luo</a>",
          "description": "High-resolution representations (HR) are essential for dense prediction tasks\nsuch as segmentation, detection, and pose estimation. Learning HR\nrepresentations is typically ignored in previous Neural Architecture Search\n(NAS) methods that focus on image classification. This work proposes a novel\nNAS method, called HR-NAS, which is able to find efficient and accurate\nnetworks for different tasks, by effectively encoding multiscale contextual\ninformation while maintaining high-resolution representations. In HR-NAS, we\nrenovate the NAS search space as well as its searching strategy. To better\nencode multiscale image contexts in the search space of HR-NAS, we first\ncarefully design a lightweight transformer, whose computational complexity can\nbe dynamically changed with respect to different objective functions and\ncomputation budgets. To maintain high-resolution representations of the learned\nnetworks, HR-NAS adopts a multi-branch architecture that provides convolutional\nencoding of multiple feature resolutions, inspired by HRNet. Last, we proposed\nan efficient fine-grained search strategy to train HR-NAS, which effectively\nexplores the search space, and finds optimal architectures given various tasks\nand computation resources. HR-NAS is capable of achieving state-of-the-art\ntrade-offs between performance and FLOPs for three dense prediction tasks and\nan image classification task, given only small computational budgets. For\nexample, HR-NAS surpasses SqueezeNAS that is specially designed for semantic\nsegmentation while improving efficiency by 45.9%. Code is available at\nhttps://github.com/dingmyu/HR-NAS",
          "link": "http://arxiv.org/abs/2106.06560",
          "publishedOn": "2021-06-15T01:45:18.890Z",
          "wordCount": 659,
          "title": "HR-NAS: Searching Efficient High-Resolution Neural Architectures with Lightweight Transformers. (arXiv:2106.06560v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06817",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1\">Yize Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patney_A/0/1/0/all/0/1\">Anjul Patney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bovik_A/0/1/0/all/0/1\">Alan Bovik</a>",
          "description": "Virtual Reality is regaining attention due to recent advancements in hardware\ntechnology. Immersive images / videos are becoming widely adopted to carry\nomnidirectional visual information. However, due to the requirements for higher\nspatial and temporal resolution of real video data, immersive videos require\nsignificantly larger bandwidth consumption. To reduce stresses on bandwidth,\nfoveated video compression is regaining popularity, whereby the space-variant\nspatial resolution of the retina is exploited. Towards advancing the progress\nof foveated video compression, we propose a full reference (FR) foveated image\nquality assessment algorithm, which we call foveated entropic differencing\n(FED), which employs the natural scene statistics of bandpass responses by\napplying differences of local entropies weighted by a foveation-based error\nsensitivity function. We evaluate the proposed algorithm by measuring the\ncorrelations of the predictions that FED makes against human judgements on the\nnewly created 2D and 3D LIVE-FBT-FCVR databases for Virtual Reality (VR). The\nperformance of the proposed algorithm yields state-of-the-art as compared with\nother existing full reference algorithms. Software for FED has been made\navailable at: this http URL",
          "link": "http://arxiv.org/abs/2106.06817",
          "publishedOn": "2021-06-15T01:45:18.857Z",
          "wordCount": 600,
          "title": "Evaluating Foveated Video Quality Using Entropic Differencing. (arXiv:2106.06817v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2012.03408",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wen_X/0/1/0/all/0/1\">Xin Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_P/0/1/0/all/0/1\">Peng Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1\">Zhizhong Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yan-Pei Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_P/0/1/0/all/0/1\">Pengfei Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_W/0/1/0/all/0/1\">Wen Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yu-Shen Liu</a>",
          "description": "The task of point cloud completion aims to predict the missing part for an\nincomplete 3D shape. A widely used strategy is to generate a complete point\ncloud from the incomplete one. However, the unordered nature of point clouds\nwill degrade the generation of high-quality 3D shapes, as the detailed topology\nand structure of discrete points are hard to be captured by the generative\nprocess only using a latent code. In this paper, we address the above problem\nby reconsidering the completion task from a new perspective, where we formulate\nthe prediction as a point cloud deformation process. Specifically, we design a\nnovel neural network, named PMP-Net, to mimic the behavior of an earth mover.\nIt moves each point of the incomplete input to complete the point cloud, where\nthe total distance of point moving paths (PMP) should be shortest. Therefore,\nPMP-Net predicts a unique point moving path for each point according to the\nconstraint of total point moving distances. As a result, the network learns a\nstrict and unique correspondence on point-level, which can capture the detailed\ntopology and structure relationships between the incomplete shape and the\ncomplete target, and thus improves the quality of the predicted complete shape.\nWe conduct comprehensive experiments on Completion3D and PCN datasets, which\ndemonstrate our advantages over the state-of-the-art point cloud completion\nmethods.",
          "link": "http://arxiv.org/abs/2012.03408",
          "publishedOn": "2021-06-15T01:45:18.828Z",
          "wordCount": 704,
          "title": "PMP-Net: Point Cloud Completion by Learning Multi-step Point Moving Paths. (arXiv:2012.03408v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.09670",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Croce_F/0/1/0/all/0/1\">Francesco Croce</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andriushchenko_M/0/1/0/all/0/1\">Maksym Andriushchenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sehwag_V/0/1/0/all/0/1\">Vikash Sehwag</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Debenedetti_E/0/1/0/all/0/1\">Edoardo Debenedetti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Flammarion_N/0/1/0/all/0/1\">Nicolas Flammarion</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiang_M/0/1/0/all/0/1\">Mung Chiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mittal_P/0/1/0/all/0/1\">Prateek Mittal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hein_M/0/1/0/all/0/1\">Matthias Hein</a>",
          "description": "As a research community, we are still lacking a systematic understanding of\nthe progress on adversarial robustness, which often makes it hard to identify\nthe most promising ideas in training robust models. A key challenge in\nbenchmarking robustness is that its evaluation is often error-prone, leading to\noverestimation of the true robustness of models. While adaptive attacks\ndesigned for a particular defense are a potential solution, they have to be\nhighly customized for particular models, which makes it difficult to compare\ndifferent methods. Our goal is to instead establish a standardized benchmark of\nadversarial robustness, which as accurately as possible reflects the robustness\nof the considered models within a reasonable computational budget. To evaluate\nthe robustness of models for our benchmark, we consider AutoAttack, an ensemble\nof white- and black-box attacks which was recently shown in a large-scale study\nto improve almost all robustness evaluations compared to the original\npublications. We also impose some restrictions on the admitted models to rule\nout defenses that only make gradient-based attacks ineffective without\nimproving actual robustness. Our leaderboard, hosted at\nhttps://robustbench.github.io/, contains evaluations of 90+ models and aims at\nreflecting the current state of the art on a set of well-defined tasks in\n$\\ell_\\infty$- and $\\ell_2$-threat models and on common corruptions, with\npossible extensions in the future. Additionally, we open-source the library\nhttps://github.com/RobustBench/robustbench that provides unified access to 60+\nrobust models to facilitate their downstream applications. Finally, based on\nthe collected models, we analyze the impact of robustness on the performance on\ndistribution shifts, calibration, out-of-distribution detection, fairness,\nprivacy leakage, smoothness, and transferability.",
          "link": "http://arxiv.org/abs/2010.09670",
          "publishedOn": "2021-06-15T01:45:18.388Z",
          "wordCount": 763,
          "title": "RobustBench: a standardized adversarial robustness benchmark. (arXiv:2010.09670v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06742",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Feng_C/0/1/0/all/0/1\">Chun-Mei Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1\">Yunlu Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_H/0/1/0/all/0/1\">Huazhu Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Li Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yong Xu</a>",
          "description": "The core problem of Magnetic Resonance Imaging (MRI) is the trade off between\nacceleration and image quality. Image reconstruction and super-resolution are\ntwo crucial techniques in Magnetic Resonance Imaging (MRI). Current methods are\ndesigned to perform these tasks separately, ignoring the correlations between\nthem. In this work, we propose an end-to-end task transformer network\n(T$^2$Net) for joint MRI reconstruction and super-resolution, which allows\nrepresentations and feature transmission to be shared between multiple task to\nachieve higher-quality, super-resolved and motion-artifacts-free images from\nhighly undersampled and degenerated MRI data. Our framework combines both\nreconstruction and super-resolution, divided into two sub-branches, whose\nfeatures are expressed as queries and keys. Specifically, we encourage joint\nfeature learning between the two tasks, thereby transferring accurate task\ninformation. We first use two separate CNN branches to extract task-specific\nfeatures. Then, a task transformer module is designed to embed and synthesize\nthe relevance between the two tasks. Experimental results show that our\nmulti-task model significantly outperforms advanced sequential methods, both\nquantitatively and qualitatively.",
          "link": "http://arxiv.org/abs/2106.06742",
          "publishedOn": "2021-06-15T01:45:18.279Z",
          "wordCount": 611,
          "title": "Task Transformer Network for Joint MRI Reconstruction and Super-Resolution. (arXiv:2106.06742v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00671",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khazatsky_A/0/1/0/all/0/1\">Alexander Khazatsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nair_A/0/1/0/all/0/1\">Ashvin Nair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jing_D/0/1/0/all/0/1\">Daniel Jing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1\">Sergey Levine</a>",
          "description": "A generalist robot equipped with learned skills must be able to perform many\ntasks in many different environments. However, zero-shot generalization to new\nsettings is not always possible. When the robot encounters a new environment or\nobject, it may need to finetune some of its previously learned skills to\naccommodate this change. But crucially, previously learned behaviors and models\nshould still be suitable to accelerate this relearning. In this paper, we aim\nto study how generative models of possible outcomes can allow a robot to learn\nvisual representations of affordances, so that the robot can sample potentially\npossible outcomes in new situations, and then further train its policy to\nachieve those outcomes. In effect, prior data is used to learn what kinds of\noutcomes may be possible, such that when the robot encounters an unfamiliar\nsetting, it can sample potential outcomes from its model, attempt to reach\nthem, and thereby update both its skills and its outcome model. This approach,\nvisuomotor affordance learning (VAL), can be used to train goal-conditioned\npolicies that operate on raw image inputs, and can rapidly learn to manipulate\nnew objects via our proposed affordance-directed exploration scheme. We show\nthat VAL can utilize prior data to solve real-world tasks such drawer opening,\ngrasping, and placing objects in new scenes with only five minutes of online\nexperience in the new scene.",
          "link": "http://arxiv.org/abs/2106.00671",
          "publishedOn": "2021-06-15T01:45:18.003Z",
          "wordCount": 696,
          "title": "What Can I Do Here? Learning New Skills by Imagining Visual Affordances. (arXiv:2106.00671v2 [cs.RO] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.12100",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Chen_X/0/1/0/all/0/1\">Xiang Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huang_Y/0/1/0/all/0/1\">Yufeng Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_L/0/1/0/all/0/1\">Lei Xu</a>",
          "description": "Rain streaks bring serious blurring and visual quality degradation, which\noften vary in size, direction and density. Current CNN-based methods achieve\nencouraging performance, while are limited to depict rain characteristics and\nrecover image details in the poor visibility environment. To address these\nissues, we present a Multi-scale Hourglass Hierarchical Fusion Network\n(MH2F-Net) in end-to-end manner, to exactly captures rain streak features with\nmulti-scale extraction, hierarchical distillation and information aggregation.\nFor better extracting the features, a novel Multi-scale Hourglass Extraction\nBlock (MHEB) is proposed to get local and global features across different\nscales through down- and up-sample process. Besides, a Hierarchical Attentive\nDistillation Block (HADB) then employs the dual attention feature responses to\nadaptively recalibrate the hierarchical features and eliminate the redundant\nones. Further, we introduce a Residual Projected Feature Fusion (RPFF) strategy\nto progressively discriminate feature learning and aggregate different features\ninstead of directly concatenating or adding. Extensive experiments on both\nsynthetic and real rainy datasets demonstrate the effectiveness of the designed\nMH2F-Net by comparing with recent state-of-the-art deraining algorithms. Our\nsource code will be available on the GitHub:\nhttps://github.com/cxtalk/MH2F-Net.",
          "link": "http://arxiv.org/abs/2104.12100",
          "publishedOn": "2021-06-15T01:45:17.405Z",
          "wordCount": 642,
          "title": "Multi-Scale Hourglass Hierarchical Fusion Network for Single Image Deraining. (arXiv:2104.12100v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2001.06372",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sumbul_G/0/1/0/all/0/1\">Gencer Sumbul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_J/0/1/0/all/0/1\">Jian Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kreuziger_T/0/1/0/all/0/1\">Tristan Kreuziger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marcelino_F/0/1/0/all/0/1\">Filipe Marcelino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Costa_H/0/1/0/all/0/1\">Hugo Costa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benevides_P/0/1/0/all/0/1\">Pedro Benevides</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caetano_M/0/1/0/all/0/1\">Mario Caetano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Demir_B/0/1/0/all/0/1\">Beg&#xfc;m Demir</a>",
          "description": "This paper presents BigEarthNet that is a large-scale Sentinel-2\nmultispectral image dataset with a new class nomenclature to advance deep\nlearning (DL) studies in remote sensing (RS). BigEarthNet is made up of 590,326\nimage patches annotated with multi-labels provided by the CORINE Land Cover\n(CLC) map of 2018 based on its most thematic detailed Level-3 class\nnomenclature. Initial research demonstrates that some CLC classes are\nchallenging to be accurately described by considering only Sentinel-2 images.\nTo increase the effectiveness of BigEarthNet, in this paper we introduce an\nalternative class-nomenclature to allow DL models for better learning and\ndescribing the complex spatial and spectral information content of the\nSentinel-2 images. This is achieved by interpreting and arranging the CLC\nLevel-3 nomenclature based on the properties of Sentinel-2 images in a new\nnomenclature of 19 classes. Then, the new class-nomenclature of BigEarthNet is\nused within state-of-the-art DL models in the context of multi-label\nclassification. Results show that the models trained from scratch on\nBigEarthNet outperform those pre-trained on ImageNet, especially in relation to\nsome complex classes including agriculture, other vegetated and natural\nenvironments. All DL models are made publicly available at\nthis http URL, offering an important resource to guide future\nprogress on RS image analysis.",
          "link": "http://arxiv.org/abs/2001.06372",
          "publishedOn": "2021-06-15T01:45:17.272Z",
          "wordCount": 705,
          "title": "BigEarthNet Dataset with A New Class-Nomenclature for Remote Sensing Image Understanding. (arXiv:2001.06372v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06992",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Feihong_L/0/1/0/all/0/1\">Liu Feihong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Junwei_Y/0/1/0/all/0/1\">Yang Junwei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiaowei_H/0/1/0/all/0/1\">He Xiaowei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luping_Z/0/1/0/all/0/1\">Zhou Luping</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jun_F/0/1/0/all/0/1\">Feng Jun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dinggang_S/0/1/0/all/0/1\">Shen Dinggang</a>",
          "description": "Being complex-valued and low in signal-to-noise ratios, magnitude-based\ndiffusion MRI is confounded by the noise-floor that falsely elevates signal\nmagnitude and incurs bias to the commonly used diffusion indices, such as\nfractional anisotropy (FA). To avoid noise-floor, most existing phase\ncorrection methods explore improving filters to estimate the noise-free\nbackground phase. In this work, after diving into the phase correction\nprocedures, we argue that even a perfect filter is insufficient for phase\ncorrection because the correction procedures are incapable of distinguishing\nsign-symbols of noise, resulting in artifacts (\\textit{i.e.}, arbitrary signal\nloss). With this insight, we generalize the definition of noise-floor to a\ncomplex polar coordinate system and propose a calibration procedure that could\nconveniently distinguish noise sign symbols. The calibration procedure is\nconceptually simple and easy to implement without relying on any external\ntechnique while keeping distinctly effective.",
          "link": "http://arxiv.org/abs/2106.06992",
          "publishedOn": "2021-06-15T01:45:17.265Z",
          "wordCount": 585,
          "title": "Is Perfect Filtering Enough Leading to Perfect Phase Correction for dMRI data?. (arXiv:2106.06992v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2006.09179",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Buzzicotti_M/0/1/0/all/0/1\">M. Buzzicotti</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Bonaccorso_F/0/1/0/all/0/1\">F. Bonaccorso</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Leoni_P/0/1/0/all/0/1\">P. Clark Di Leoni</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Biferale_L/0/1/0/all/0/1\">L. Biferale</a>",
          "description": "We study the applicability of tools developed by the computer vision\ncommunity for features learning and semantic image inpainting to perform data\nreconstruction of fluid turbulence configurations. The aim is twofold. First,\nwe explore on a quantitative basis, the capability of Convolutional Neural\nNetworks embedded in a Deep Generative Adversarial Model (Deep-GAN) to generate\nmissing data in turbulence, a paradigmatic high dimensional chaotic system. In\nparticular, we investigate their use in reconstructing two-dimensional damaged\nsnapshots extracted from a large database of numerical configurations of 3d\nturbulence in the presence of rotation, a case with multi-scale random features\nwhere both large-scale organised structures and small-scale highly intermittent\nand non-Gaussian fluctuations are present. Second, following a reverse\nengineering approach, we aim to rank the input flow properties (features) in\nterms of their qualitative and quantitative importance to obtain a better set\nof reconstructed fields. We present two approaches both based on Context\nEncoders. The first one infers the missing data via a minimization of the L2\npixel-wise reconstruction loss, plus a small adversarial penalisation. The\nsecond searches for the closest encoding of the corrupted flow configuration\nfrom a previously trained generator. Finally, we present a comparison with a\ndifferent data assimilation tool, based on Nudging, an equation-informed\nunbiased protocol, well known in the numerical weather prediction community.\nThe TURB-Rot database, this http URL, of roughly 300K 2d\nturbulent images is released and details on how to download it are given.",
          "link": "http://arxiv.org/abs/2006.09179",
          "publishedOn": "2021-06-15T01:45:17.173Z",
          "wordCount": 723,
          "title": "Reconstruction of turbulent data with deep generative models for semantic inpainting from TURB-Rot database. (arXiv:2006.09179v2 [physics.flu-dyn] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06980",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Panicker_M/0/1/0/all/0/1\">Mahesh Raveendranatha Panicker</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_Y/0/1/0/all/0/1\">Yale Tung Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+M_G/0/1/0/all/0/1\">Gayathri M</a>, <a href=\"http://arxiv.org/find/eess/1/au:+N_M/0/1/0/all/0/1\">Madhavanunni A N</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Narayan_K/0/1/0/all/0/1\">Kiran Vishnu Narayan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kesavadas_C/0/1/0/all/0/1\">C Kesavadas</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Vinod_A/0/1/0/all/0/1\">A P Vinod</a>",
          "description": "Ultrasound is fast becoming an inevitable diagnostic tool for regular and\ncontinuous monitoring of the lung with the recent outbreak of COVID-19. In this\nwork, a novel approach is presented to extract acoustic propagation-based\nfeatures to automatically highlight the region below pleura, which is an\nimportant landmark in lung ultrasound (LUS). Subsequently, a multichannel input\nformed by using the acoustic physics-based feature maps is fused to train a\nneural network, referred to as LUSNet, to classify the LUS images into five\nclasses of varying severity of lung infection to track the progression of\nCOVID-19. In order to ensure that the proposed approach is agnostic to the type\nof acquisition, the LUSNet, which consists of a U-net architecture is trained\nin an unsupervised manner with the acoustic feature maps to ensure that the\nencoder-decoder architecture is learning features in the pleural region of\ninterest. A novel combination of the U-net output and the U-net encoder output\nis employed for the classification of severity of infection in the lung. A\ndetailed analysis of the proposed approach on LUS images over the infection to\nfull recovery period of ten confirmed COVID-19 subjects shows an average\nfive-fold cross-validation accuracy, sensitivity, and specificity of 97%, 93%,\nand 98% respectively over 5000 frames of COVID-19 videos. The analysis also\nshows that, when the input dataset is limited and diverse as in the case of\nCOVID-19 pandemic, an aided effort of combining acoustic propagation-based\nfeatures along with the gray scale images, as proposed in this work, improves\nthe performance of the neural network significantly and also aids the labelling\nand triaging process.",
          "link": "http://arxiv.org/abs/2106.06980",
          "publishedOn": "2021-06-15T01:45:17.157Z",
          "wordCount": 790,
          "title": "An Approach Towards Physics Informed Lung Ultrasound Image Scoring Neural Network for Diagnostic Assistance in COVID-19. (arXiv:2106.06980v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.08949",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Feng_C/0/1/0/all/0/1\">Chun-Mei Feng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fu_H/0/1/0/all/0/1\">Huazhu Fu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yuan_S/0/1/0/all/0/1\">Shuhao Yuan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_Y/0/1/0/all/0/1\">Yong Xu</a>",
          "description": "Super-resolution (SR) plays a crucial role in improving the image quality of\nmagnetic resonance imaging (MRI). MRI produces multi-contrast images and can\nprovide a clear display of soft tissues. However, current super-resolution\nmethods only employ a single contrast, or use a simple multi-contrast fusion\nmechanism, ignoring the rich relations among different contrasts, which are\nvaluable for improving SR. In this work, we propose a multi-stage integration\nnetwork (i.e., MINet) for multi-contrast MRI SR, which explicitly models the\ndependencies between multi-contrast images at different stages to guide image\nSR. In particular, our MINet first learns a hierarchical feature representation\nfrom multiple convolutional stages for each of different-contrast image.\nSubsequently, we introduce a multi-stage integration module to mine the\ncomprehensive relations between the representations of the multi-contrast\nimages. Specifically, the module matches each representation with all other\nfeatures, which are integrated in terms of their similarities to obtain an\nenriched representation. Extensive experiments on fastMRI and real-world\nclinical datasets demonstrate that 1) our MINet outperforms state-of-the-art\nmulti-contrast SR methods in terms of various metrics and 2) our multi-stage\nintegration module is able to excavate complex interactions among\nmulti-contrast features at different stages, leading to improved target-image\nquality.",
          "link": "http://arxiv.org/abs/2105.08949",
          "publishedOn": "2021-06-15T01:45:17.001Z",
          "wordCount": 668,
          "title": "Multi-Contrast MRI Super-Resolution via a Multi-Stage Integration Network. (arXiv:2105.08949v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09356",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rezaei_S/0/1/0/all/0/1\">Seyed Saeed Changiz Rezaei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_F/0/1/0/all/0/1\">Fred X. Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_D/0/1/0/all/0/1\">Di Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salameh_M/0/1/0/all/0/1\">Mohammad Salameh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mills_K/0/1/0/all/0/1\">Keith Mills</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lian_S/0/1/0/all/0/1\">Shuo Lian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1\">Wei Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jui_S/0/1/0/all/0/1\">Shangling Jui</a>",
          "description": "Despite the empirical success of neural architecture search (NAS) in deep\nlearning applications, the optimality, reproducibility and cost of NAS schemes\nremain hard to assess. In this paper, we propose Generative Adversarial NAS\n(GA-NAS) with theoretically provable convergence guarantees, promoting\nstability and reproducibility in neural architecture search. Inspired by\nimportance sampling, GA-NAS iteratively fits a generator to previously\ndiscovered top architectures, thus increasingly focusing on important parts of\na large search space. Furthermore, we propose an efficient adversarial learning\napproach, where the generator is trained by reinforcement learning based on\nrewards provided by a discriminator, thus being able to explore the search\nspace without evaluating a large number of architectures. Extensive experiments\nshow that GA-NAS beats the best published results under several cases on three\npublic NAS benchmarks. In the meantime, GA-NAS can handle ad-hoc search\nconstraints and search spaces. We show that GA-NAS can be used to improve\nalready optimized baselines found by other NAS methods, including EfficientNet\nand ProxylessNAS, in terms of ImageNet accuracy or the number of parameters, in\ntheir original search space.",
          "link": "http://arxiv.org/abs/2105.09356",
          "publishedOn": "2021-06-15T01:45:16.975Z",
          "wordCount": 655,
          "title": "Generative Adversarial Neural Architecture Search. (arXiv:2105.09356v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06726",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1\">Xuan Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1\">Tianshu Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaomin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1\">Jiali Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Minghui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Ming Liu</a>",
          "description": "Regularization and data augmentation methods have been widely used and become\nincreasingly indispensable in deep learning training. Researchers who devote\nthemselves to this have considered various possibilities. But so far, there has\nbeen little discussion about regularizing outputs of the model. This paper\nbegins with empirical observations that better performances are significantly\nassociated with output distributions, that have smaller average values and\nvariances. By audaciously assuming there is causality involved, we propose a\nnovel regularization term, called Output Decay, that enforces the model to\nassign smaller and similar output values on each class. Though being\ncounter-intuitive, such a small modification result in a remarkable improvement\non performance. Extensive experiments demonstrate the wide applicability,\nversatility, and compatibility of Output Decay.",
          "link": "http://arxiv.org/abs/2106.06726",
          "publishedOn": "2021-06-15T01:45:16.943Z",
          "wordCount": 559,
          "title": "Go Small and Similar: A Simple Output Decay Brings Better Performance. (arXiv:2106.06726v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2103.07838",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wen_X/0/1/0/all/0/1\">Xin Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1\">Zhizhong Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yan-Pei Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_P/0/1/0/all/0/1\">Pengfei Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_W/0/1/0/all/0/1\">Wen Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yu-Shen Liu</a>",
          "description": "In this paper, we present a novel unpaired point cloud completion network,\nnamed Cycle4Completion, to infer the complete geometries from a partial 3D\nobject. Previous unpaired completion methods merely focus on the learning of\ngeometric correspondence from incomplete shapes to complete shapes, and ignore\nthe learning in the reverse direction, which makes them suffer from low\ncompletion accuracy due to the limited 3D shape understanding ability. To\naddress this problem, we propose two simultaneous cycle transformations between\nthe latent spaces of complete shapes and incomplete ones. The insight of cycle\ntransformation is to promote networks to understand 3D shapes by learning to\ngenerate complete or incomplete shapes from their complementary ones.\nSpecifically, the first cycle transforms shapes from incomplete domain to\ncomplete domain, and then projects them back to the incomplete domain. This\nprocess learns the geometric characteristic of complete shapes, and maintains\nthe shape consistency between the complete prediction and the incomplete input.\nSimilarly, the inverse cycle transformation starts from complete domain to\nincomplete domain, and goes back to complete domain to learn the characteristic\nof incomplete shapes. We provide a comprehensive evaluation in experiments,\nwhich shows that our model with the learned bidirectional geometry\ncorrespondence outperforms state-of-the-art unpaired completion methods.",
          "link": "http://arxiv.org/abs/2103.07838",
          "publishedOn": "2021-06-15T01:45:16.919Z",
          "wordCount": 679,
          "title": "Cycle4Completion: Unpaired Point Cloud Completion using Cycle Transformation with Missing Region Coding. (arXiv:2103.07838v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1904.01636",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vorontsov_E/0/1/0/all/0/1\">Eugene Vorontsov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Molchanov_P/0/1/0/all/0/1\">Pavlo Molchanov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beckham_C/0/1/0/all/0/1\">Christopher Beckham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kautz_J/0/1/0/all/0/1\">Jan Kautz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kadoury_S/0/1/0/all/0/1\">Samuel Kadoury</a>",
          "description": "Often in medical imaging, it is prohibitively challenging to produce enough\nboundary annotations to train deep neural networks for accurate tumor\nsegmentation. We propose the use of weak labels about whether an image presents\ntumor or whether it is absent to extend training over images that lack these\nannotations. Specifically, we propose a semi-supervised framework that employs\nunpaired image-to-image translation between two domains, presence vs. absence\nof cancer, as the unsupervised objective. We conjecture that translation helps\nsegmentation -- both require the target to be separated from the background. We\nencode images into two codes: one that is common to both domains and one that\nis unique to the presence domain. Decoding from the common code yields healthy\nimages; decoding with the addition of the unique code produces a residual\nchange to this image that adds cancer. Translation proceeds from presence to\nabsence and vice versa. In the first case, the tumor is re-added to the image\nand we successfully exploit the residual decoder to also perform segmentation.\nIn the second case, unique codes are sampled, producing a distribution of\npossible tumors. To validate the method, we created challenging synthetic tasks\nand tumor segmentation datasets from public BRATS (brain, MRI) and LitS (liver,\nCT) datasets. We show a clear improvement (0.83 Dice on brain, 0.74 on liver)\nover baseline semi-supervised training with autoencoding (0.73, 0.66) and a\nmean teacher approach (0.75, 0.69), demonstrating the ability to generalize\nfrom smaller distributions of annotated samples.",
          "link": "http://arxiv.org/abs/1904.01636",
          "publishedOn": "2021-06-15T01:45:16.892Z",
          "wordCount": 721,
          "title": "Towards annotation-efficient segmentation via image-to-image translation. (arXiv:1904.01636v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.06810",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yuandong Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xinlei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganguli_S/0/1/0/all/0/1\">Surya Ganguli</a>",
          "description": "While contrastive approaches of self-supervised learning (SSL) learn\nrepresentations by minimizing the distance between two augmented views of the\nsame data point (positive pairs) and maximizing views from different data\npoints (negative pairs), recent \\emph{non-contrastive} SSL (e.g., BYOL and\nSimSiam) show remarkable performance {\\it without} negative pairs, with an\nextra learnable predictor and a stop-gradient operation. A fundamental question\narises: why do these methods not collapse into trivial representations? We\nanswer this question via a simple theoretical study and propose a novel\napproach, DirectPred, that \\emph{directly} sets the linear predictor based on\nthe statistics of its inputs, without gradient training. On ImageNet, it\nperforms comparably with more complex two-layer non-linear predictors that\nemploy BatchNorm and outperforms a linear predictor by $2.5\\%$ in 300-epoch\ntraining (and $5\\%$ in 60-epoch). DirectPred is motivated by our theoretical\nstudy of the nonlinear learning dynamics of non-contrastive SSL in simple\nlinear networks. Our study yields conceptual insights into how non-contrastive\nSSL methods learn, how they avoid representational collapse, and how multiple\nfactors, like predictor networks, stop-gradients, exponential moving averages,\nand weight decay all come into play. Our simple theory recapitulates the\nresults of real-world ablation studies in both STL-10 and ImageNet. Code is\nreleased\\footnote{\\url{https://github.com/facebookresearch/luckmatters/tree/master/ssl}}.",
          "link": "http://arxiv.org/abs/2102.06810",
          "publishedOn": "2021-06-15T01:45:16.878Z",
          "wordCount": 664,
          "title": "Understanding self-supervised Learning Dynamics without Contrastive Pairs. (arXiv:2102.06810v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06716",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_A/0/1/0/all/0/1\">Ailiang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Bingzhi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jiayu Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_G/0/1/0/all/0/1\">Guangming Lu</a>",
          "description": "Automatic medical image segmentation has made great progress benefit from the\ndevelopment of deep learning. However, most existing methods are based on\nconvolutional neural networks (CNNs), which fail to build long-range\ndependencies and global context connections due to the limitation of receptive\nfield in convolution operation. Inspired by the success of Transformer in\nmodeling the long-range contextual information, some researchers have expended\nconsiderable efforts in designing the robust variants of Transformer-based\nU-Net. Moreover, the patch division used in vision transformers usually ignores\nthe pixel-level intrinsic structural features inside each patch. To alleviate\nthese problems, we propose a novel deep medical image segmentation framework\ncalled Dual Swin Transformer U-Net (DS-TransUNet), which might be the first\nattempt to concurrently incorporate the advantages of hierarchical Swin\nTransformer into both encoder and decoder of the standard U-shaped architecture\nto enhance the semantic segmentation quality of varying medical images. Unlike\nmany prior Transformer-based solutions, the proposed DS-TransUNet first adopts\ndual-scale encoder subnetworks based on Swin Transformer to extract the coarse\nand fine-grained feature representations of different semantic scales. As the\ncore component for our DS-TransUNet, a well-designed Transformer Interactive\nFusion (TIF) module is proposed to effectively establish global dependencies\nbetween features of different scales through the self-attention mechanism.\nFurthermore, we also introduce the Swin Transformer block into decoder to\nfurther explore the long-range contextual information during the up-sampling\nprocess. Extensive experiments across four typical tasks for medical image\nsegmentation demonstrate the effectiveness of DS-TransUNet, and show that our\napproach significantly outperforms the state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2106.06716",
          "publishedOn": "2021-06-15T01:45:16.856Z",
          "wordCount": 681,
          "title": "DS-TransUNet:Dual Swin Transformer U-Net for Medical Image Segmentation. (arXiv:2106.06716v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2101.12242",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Adis_P/0/1/0/all/0/1\">Philipp Adis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Horst_N/0/1/0/all/0/1\">Nicolas Horst</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wien_M/0/1/0/all/0/1\">Mathias Wien</a>",
          "description": "LiDAR odometry (LO) describes the task of finding an alignment of subsequent\nLiDAR point clouds. This alignment can be used to estimate the motion of the\nplatform where the LiDAR sensor is mounted on. Currently, on the well-known\nKITTI Vision Benchmark Suite state-of-the-art algorithms are non-learning\napproaches. We propose a network architecture that learns LO by directly\nprocessing 3D point clouds. It is trained on the KITTI dataset in an end-to-end\nmanner without the necessity of pre-defining corresponding pairs of points. An\nevaluation on the KITTI Vision Benchmark Suite shows similar performance to a\npreviously published work, DeepCLR [1], even though our model uses only around\n3.56% of the number of network parameters thereof. Furthermore, a plane point\nextraction is applied which leads to a marginal performance decrease while\nsimultaneously reducing the input size by up to 50%.",
          "link": "http://arxiv.org/abs/2101.12242",
          "publishedOn": "2021-06-15T01:45:16.786Z",
          "wordCount": 594,
          "title": "D3DLO: Deep 3D LiDAR Odometry. (arXiv:2101.12242v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.14372",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hering_A/0/1/0/all/0/1\">Alessa Hering</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hager_S/0/1/0/all/0/1\">Stephanie H&#xe4;ger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moltz_J/0/1/0/all/0/1\">Jan Moltz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lessmann_N/0/1/0/all/0/1\">Nikolas Lessmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heldmann_S/0/1/0/all/0/1\">Stefan Heldmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ginneken_B/0/1/0/all/0/1\">Bram van Ginneken</a>",
          "description": "Deep-learning-based registration methods emerged as a fast alternative to\nconventional registration methods. However, these methods often still cannot\nachieve the same performance as conventional registration methods because they\nare either limited to small deformation or they fail to handle a superposition\nof large and small deformations without producing implausible deformation\nfields with foldings inside.\n\nIn this paper, we identify important strategies of conventional registration\nmethods for lung registration and successfully developed the deep-learning\ncounterpart. We employ a Gaussian-pyramid-based multilevel framework that can\nsolve the image registration optimization in a coarse-to-fine fashion.\nFurthermore, we prevent foldings of the deformation field and restrict the\ndeterminant of the Jacobian to physiologically meaningful values by combining a\nvolume change penalty with a curvature regularizer in the loss function.\nKeypoint correspondences are integrated to focus on the alignment of smaller\nstructures.\n\nWe perform an extensive evaluation to assess the accuracy, the robustness,\nthe plausibility of the estimated deformation fields, and the transferability\nof our registration approach. We show that it achieves state-of-the-art results\non the COPDGene dataset compared to conventional registration method with much\nshorter execution time. In our experiments on the DIRLab exhale to inhale lung\nregistration, we demonstrate substantial improvements (TRE below $1.2$ mm) over\nother deep learning methods. Our algorithm is publicly available at\nhttps://grand-challenge.org/algorithms/deep-learning-based-ct-lung-registration/.",
          "link": "http://arxiv.org/abs/2011.14372",
          "publishedOn": "2021-06-15T01:45:16.771Z",
          "wordCount": 680,
          "title": "CNN-based Lung CT Registration with Multiple Anatomical Constraints. (arXiv:2011.14372v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06684",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mazumder_J/0/1/0/all/0/1\">Joy Mazumder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zand_M/0/1/0/all/0/1\">Mohsen Zand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Greenspan_M/0/1/0/all/0/1\">Michael Greenspan</a>",
          "description": "This work presents a novel approach to improve the results of pose estimation\nby detecting and distinguishing between the occurrence of True and False\nPositive results. It achieves this by training a binary classifier on the\noutput of an arbitrary pose estimation algorithm, and returns a binary label\nindicating the validity of the result. We demonstrate that our approach\nimproves upon a state-of-the-art pose estimation result on the Sil\\'eane\ndataset, outperforming a variation of the alternative CullNet method by 4.15%\nin average class accuracy and 0.73% in overall accuracy at validation. Applying\nour method can also improve the pose estimation average precision results of\nOp-Net by 6.06% on average.",
          "link": "http://arxiv.org/abs/2106.06684",
          "publishedOn": "2021-06-15T01:45:16.750Z",
          "wordCount": 573,
          "title": "Multistream ValidNet: Improving 6D Object Pose Estimation by Automatic Multistream Validation. (arXiv:2106.06684v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06924",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chang_C/0/1/0/all/0/1\">Ching-Chun Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Sisheng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Echizen_I/0/1/0/all/0/1\">Isao Echizen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanchez_V/0/1/0/all/0/1\">Victor Sanchez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chang-Tsun Li</a>",
          "description": "Deep-learning\\textendash{centric} reversible steganography has emerged as a\npromising research paradigm. A direct way of applying deep learning to\nreversible steganography is to construct a pair of encoder and decoder, whose\nparameters are trained jointly, thereby learning the steganographic system as a\nwhole. This end-to-end framework, however, falls short of the reversibility\nrequirement because it is difficult for this kind of monolithic system, as a\nblack box, to create or duplicate intricate reversible mechanisms. In response\nto this issue, a recent approach is to carve up the steganographic system and\nwork on modules independently. In particular, neural networks are deployed in\nan analytics module to learn the data distribution, while an established\nmechanism is called upon to handle the remaining tasks. In this paper, we\ninvestigate the modular framework and deploy deep neural networks in a\nreversible steganographic scheme referred to as prediction-error modulation, in\nwhich an analytics module serves the purpose of pixel intensity prediction. The\nprimary focus of this study is on deep-learning\\textendash{based} context-aware\npixel intensity prediction. We address the unsolved issues reported in related\nliterature, including the impact of pixel initialisation on prediction accuracy\nand the influence of uncertainty propagation in dual-layer embedding.\nFurthermore, we establish a connection between context-aware pixel intensity\nprediction and low-level computer vision and analyse the performance of several\nadvanced neural networks.",
          "link": "http://arxiv.org/abs/2106.06924",
          "publishedOn": "2021-06-15T01:45:16.735Z",
          "wordCount": 652,
          "title": "Deep Learning for Reversible Steganography: Principles and Insights. (arXiv:2106.06924v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2004.00202",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Choi_C/0/1/0/all/0/1\">Chiho Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1\">Joon Hee Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malla_S/0/1/0/all/0/1\">Srikanth Malla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiachen Li</a>",
          "description": "Predicting future trajectories of traffic agents in highly interactive\nenvironments is an essential and challenging problem for the safe operation of\nautonomous driving systems. On the basis of the fact that self-driving vehicles\nare equipped with various types of sensors (e.g., LiDAR scanner, RGB camera,\nradar, etc.), we propose a Cross-Modal Embedding framework that aims to benefit\nfrom the use of multiple input modalities. At training time, our model learns\nto embed a set of complementary features in a shared latent space by jointly\noptimizing the objective functions across different types of input data. At\ntest time, a single input modality (e.g., LiDAR data) is required to generate\npredictions from the input perspective (i.e., in the LiDAR space), while taking\nadvantages from the model trained with multiple sensor modalities. An extensive\nevaluation is conducted to show the efficacy of the proposed framework using\ntwo benchmark driving datasets.",
          "link": "http://arxiv.org/abs/2004.00202",
          "publishedOn": "2021-06-15T01:45:16.697Z",
          "wordCount": 629,
          "title": "Shared Cross-Modal Trajectory Prediction for Autonomous Driving. (arXiv:2004.00202v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.08175",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xuanhong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1\">Xirui Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1\">Naiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_T/0/1/0/all/0/1\">Ting Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_B/0/1/0/all/0/1\">Bingbing Ni</a>",
          "description": "Though significant progress has been made in artistic style transfer,\nsemantic information is usually difficult to be preserved in a fine-grained\nlocally consistent manner by most existing methods, especially when multiple\nartists styles are required to transfer within one single model. To circumvent\nthis issue, we propose a Stroke Control Multi-Artist Style Transfer framework.\nOn the one hand, we develop a multi-condition single-generator structure which\nfirst performs multi-artist style transfer. On the one hand, we design an\nAnisotropic Stroke Module (ASM) which realizes the dynamic adjustment of\nstyle-stroke between the non-trivial and the trivial regions. ASM endows the\nnetwork with the ability of adaptive semantic-consistency among various styles.\nOn the other hand, we present an novel Multi-Scale Projection Discriminator} to\nrealize the texture-level conditional generation. In contrast to the\nsingle-scale conditional discriminator, our discriminator is able to capture\nmulti-scale texture clue to effectively distinguish a wide range of artistic\nstyles. Extensive experimental results well demonstrate the feasibility and\neffectiveness of our approach. Our framework can transform a photograph into\ndifferent artistic style oil painting via only ONE single model. Furthermore,\nthe results are with distinctive artistic style and retain the anisotropic\nsemantic information. The code is already available on github:\nhttps://github.com/neuralchen/ASMAGAN.",
          "link": "http://arxiv.org/abs/2010.08175",
          "publishedOn": "2021-06-15T01:45:16.677Z",
          "wordCount": 673,
          "title": "Anisotropic Stroke Control for Multiple Artists Style Transfer. (arXiv:2010.08175v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.01750",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singla_S/0/1/0/all/0/1\">Sahil Singla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nushi_B/0/1/0/all/0/1\">Besmira Nushi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_S/0/1/0/all/0/1\">Shital Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamar_E/0/1/0/all/0/1\">Ece Kamar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Horvitz_E/0/1/0/all/0/1\">Eric Horvitz</a>",
          "description": "Traditional evaluation metrics for learned models that report aggregate\nscores over a test set are insufficient for surfacing important and informative\npatterns of failure over features and instances. We introduce and study a\nmethod aimed at characterizing and explaining failures by identifying visual\nattributes whose presence or absence results in poor performance. In\ndistinction to previous work that relies upon crowdsourced labels for visual\nattributes, we leverage the representation of a separate robust model to\nextract interpretable features and then harness these features to identify\nfailure modes. We further propose a visualization method aimed at enabling\nhumans to understand the meaning encoded in such features and we test the\ncomprehensibility of the features. An evaluation of the methods on the ImageNet\ndataset demonstrates that: (i) the proposed workflow is effective for\ndiscovering important failure modes, (ii) the visualization techniques help\nhumans to understand the extracted features, and (iii) the extracted insights\ncan assist engineers with error analysis and debugging.",
          "link": "http://arxiv.org/abs/2012.01750",
          "publishedOn": "2021-06-15T01:45:16.660Z",
          "wordCount": 636,
          "title": "Understanding Failures of Deep Networks via Robust Feature Extraction. (arXiv:2012.01750v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06583",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Speth_J/0/1/0/all/0/1\">Jeremy Speth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vance_N/0/1/0/all/0/1\">Nathan Vance</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Czajka_A/0/1/0/all/0/1\">Adam Czajka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bowyer_K/0/1/0/all/0/1\">Kevin W. Bowyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wright_D/0/1/0/all/0/1\">Diane Wright</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Flynn_P/0/1/0/all/0/1\">Patrick Flynn</a>",
          "description": "We present the Deception Detection and Physiological Monitoring (DDPM)\ndataset and initial baseline results on this dataset. Our application context\nis an interview scenario in which the interviewee attempts to deceive the\ninterviewer on selected responses. The interviewee is recorded in RGB,\nnear-infrared, and long-wave infrared, along with cardiac pulse, blood\noxygenation, and audio. After collection, data were annotated for\ninterviewer/interviewee, curated, ground-truthed, and organized into train /\ntest parts for a set of canonical deception detection experiments. Baseline\nexperiments found random accuracy for micro-expressions as an indicator of\ndeception, but that saccades can give a statistically significant response. We\nalso estimated subject heart rates from face videos (remotely) with a mean\nabsolute error as low as 3.16 bpm. The database contains almost 13 hours of\nrecordings of 70 subjects, and over 8 million visible-light, near-infrared, and\nthermal video frames, along with appropriate meta, audio and pulse oximeter\ndata. To our knowledge, this is the only collection offering recordings of five\nmodalities in an interview scenario that can be used in both deception\ndetection and remote photoplethysmography research.",
          "link": "http://arxiv.org/abs/2106.06583",
          "publishedOn": "2021-06-15T01:45:16.646Z",
          "wordCount": 633,
          "title": "Deception Detection and Remote Physiological Monitoring: A Dataset and Baseline Experimental Results. (arXiv:2106.06583v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06778",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ye_L/0/1/0/all/0/1\">Longqing Ye</a>",
          "description": "Convolutional networks (ConvNets) have shown impressive capability to solve\nvarious vision tasks. Nevertheless, the trade-off between performance and\nefficiency is still a challenge for a feasible model deployment on\nresource-constrained platforms. In this paper, we introduce a novel concept\ntermed multi-path fully connected pattern (MPFC) to rethink the\ninterdependencies of topology pattern, accuracy and efficiency for ConvNets.\nInspired by MPFC, we further propose a dual-branch module named dynamic clone\ntransformer (DCT) where one branch generates multiple replicas from inputs and\nanother branch reforms those clones through a series of difference vectors\nconditional on inputs itself to produce more variants. This operation allows\nthe self-expansion of channel-wise information in a data-driven way with little\ncomputational cost while providing sufficient learning capacity, which is a\npotential unit to replace computationally expensive pointwise convolution as an\nexpansion layer in the bottleneck structure.",
          "link": "http://arxiv.org/abs/2106.06778",
          "publishedOn": "2021-06-15T01:45:16.602Z",
          "wordCount": 567,
          "title": "Dynamic Clone Transformer for Efficient Convolutional Neural Netwoks. (arXiv:2106.06778v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06703",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gadd_M/0/1/0/all/0/1\">Matthew Gadd</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martini_D/0/1/0/all/0/1\">Daniele De Martini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Newman_P/0/1/0/all/0/1\">Paul Newman</a>",
          "description": "We learn, in an unsupervised way, an embedding from sequences of radar images\nthat is suitable for solving place recognition problem using complex radar\ndata. We experiment on 280 km of data and show performance exceeding\nstate-of-the-art supervised approaches, localising correctly 98.38% of the time\nwhen using just the nearest database candidate.",
          "link": "http://arxiv.org/abs/2106.06703",
          "publishedOn": "2021-06-15T01:45:16.596Z",
          "wordCount": 512,
          "title": "Unsupervised Place Recognition with Deep Embedding Learning over Radar Videos. (arXiv:2106.06703v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2102.07074",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yifan Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1\">Shiyu Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhangyang Wang</a>",
          "description": "The recent explosive interest on transformers has suggested their potential\nto become powerful ``universal\" models for computer vision tasks, such as\nclassification, detection, and segmentation. While those attempts mainly study\nthe discriminative models, we explore transformers on some more notoriously\ndifficult vision tasks, e.g., generative adversarial networks (GANs). Our goal\nis to conduct the first pilot study in building a GAN completely free of\nconvolutions, using only pure transformer-based architectures. Our vanilla GAN\narchitecture, dubbed TransGAN, consists of a memory-friendly transformer-based\ngenerator that progressively increases feature resolution, and correspondingly\na multi-scale discriminator to capture simultaneously semantic contexts and\nlow-level textures. On top of them, we introduce the new module of grid\nself-attention for alleviating the memory bottleneck further, in order to scale\nup TransGAN to high-resolution generation. We also develop a unique training\nrecipe including a series of techniques that can mitigate the training\ninstability issues of TransGAN, such as data augmentation, modified\nnormalization, and relative position encoding. Our best architecture achieves\nhighly competitive performance compared to current state-of-the-art GANs using\nconvolutional backbones. Specifically, TransGAN sets new state-of-the-art\ninception score of 10.43 and FID of 18.28 on STL-10, outperforming StyleGAN-V2.\nWhen it comes to higher-resolution (e.g. 256 x 256) generation tasks, such as\non CelebA-HQ and LSUN-Church, TransGAN continues to produce diverse visual\nexamples with high fidelity and impressive texture details. In addition, we\ndive deep into the transformer-based generation models to understand how their\nbehaviors differ from convolutional ones, by visualizing training dynamics. The\ncode is available at https://github.com/VITA-Group/TransGAN.",
          "link": "http://arxiv.org/abs/2102.07074",
          "publishedOn": "2021-06-15T01:45:16.538Z",
          "wordCount": 729,
          "title": "TransGAN: Two Pure Transformers Can Make One Strong GAN, and That Can Scale Up. (arXiv:2102.07074v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.14512",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liang_K/0/1/0/all/0/1\">Kaizhao Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jacky Y. Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koyejo_O/0/1/0/all/0/1\">Oluwasanmi Koyejo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>",
          "description": "Knowledge transferability, or transfer learning, has been widely adopted to\nallow a pre-trained model in the source domain to be effectively adapted to\ndownstream tasks in the target domain. It is thus important to explore and\nunderstand the factors affecting knowledge transferability. In this paper, as\nthe first work, we analyze and demonstrate the connections between knowledge\ntransferability and another important phenomenon--adversarial transferability,\n\\emph{i.e.}, adversarial examples generated against one model can be\ntransferred to attack other models. Our theoretical studies show that\nadversarial transferability indicates knowledge transferability and vice versa.\nMoreover, based on the theoretical insights, we propose two practical\nadversarial transferability metrics to characterize this process, serving as\nbidirectional indicators between adversarial and knowledge transferability. We\nconduct extensive experiments for different scenarios on diverse datasets,\nshowing a positive correlation between adversarial transferability and\nknowledge transferability. Our findings will shed light on future research\nabout effective knowledge transfer learning and adversarial transferability\nanalyses.",
          "link": "http://arxiv.org/abs/2006.14512",
          "publishedOn": "2021-06-15T01:45:16.524Z",
          "wordCount": 628,
          "title": "Uncovering the Connections Between Adversarial Transferability and Knowledge Transferability. (arXiv:2006.14512v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06971",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hao_H/0/1/0/all/0/1\">Hou Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yingkun_H/0/1/0/all/0/1\">Hou Yingkun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuxuan_S/0/1/0/all/0/1\">Shi Yuxuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benzheng_W/0/1/0/all/0/1\">Wei Benzheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jun_X/0/1/0/all/0/1\">Xu Jun</a>",
          "description": "Retinex model has been applied to low-light image enhancement in many\nexisting methods. More appropriate decomposition of a low-light image can help\nachieve better image enhancement. In this paper, we propose a new pixel-level\nnon-local Haar transform based illumination and reflectance decomposition\nmethod (NLHD). The unique low-frequency coefficient of Haar transform on each\nsimilar pixel group is used to reconstruct the illumination component, and the\nrest of all high-frequency coefficients are employed to reconstruct the\nreflectance component. The complete similarity of pixels in a matched similar\npixel group and the simple separable Haar transform help to obtain more\nappropriate image decomposition; thus, the image is hardly sharpened in the\nimage brightness enhancement procedure. The exponential transform and\nlogarithmic transform are respectively implemented on the illumination\ncomponent. Then a minimum fusion strategy on the results of these two\ntransforms is utilized to achieve more natural illumination component\nenhancement. It can alleviate the mosaic artifacts produced in the darker\nregions by the exponential transform with a gamma value less than 1 and reduce\ninformation loss caused by excessive enhancement of the brighter regions due to\nthe logarithmic transform. Finally, the Retinex model is applied to the\nenhanced illumination and reflectance to achieve image enhancement. We also\ndevelop a local noise level estimation based noise suppression method and a\nnon-local saturation reduction based color deviation correction method. These\ntwo methods can respectively attenuate noise or color deviation usually\npresented in the enhanced results of the extremely dark low-light images.\nExperiments on benchmark datasets show that the proposed method can achieve\nbetter low-light image enhancement results on subjective and objective\nevaluations than most existing methods.",
          "link": "http://arxiv.org/abs/2106.06971",
          "publishedOn": "2021-06-15T01:45:16.448Z",
          "wordCount": 712,
          "title": "NLHD: A Pixel-Level Non-Local Retinex Model for Low-Light Image Enhancement. (arXiv:2106.06971v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06887",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gu_C/0/1/0/all/0/1\">Cheng Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Learned_Miller_E/0/1/0/all/0/1\">Erik Learned-Miller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheldon_D/0/1/0/all/0/1\">Daniel Sheldon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gallego_G/0/1/0/all/0/1\">Guillermo Gallego</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bideau_P/0/1/0/all/0/1\">Pia Bideau</a>",
          "description": "Event cameras, inspired by biological vision systems, provide a natural and\ndata efficient representation of visual information. Visual information is\nacquired in the form of events that are triggered by local brightness changes.\nEach pixel location of the camera's sensor records events asynchronously and\nindependently with very high temporal resolution. However, because most\nbrightness changes are triggered by relative motion of the camera and the\nscene, the events recorded at a single sensor location seldom correspond to the\nsame world point. To extract meaningful information from event cameras, it is\nhelpful to register events that were triggered by the same underlying world\npoint. In this work we propose a new model of event data that captures its\nnatural spatio-temporal structure. We start by developing a model for aligned\nevent data. That is, we develop a model for the data as though it has been\nperfectly registered already. In particular, we model the aligned data as a\nspatio-temporal Poisson point process. Based on this model, we develop a\nmaximum likelihood approach to registering events that are not yet aligned.\nThat is, we find transformations of the observed events that make them as\nlikely as possible under our model. In particular we extract the camera\nrotation that leads to the best event alignment. We show new state of the art\naccuracy for rotational velocity estimation on the DAVIS 240C dataset. In\naddition, our method is also faster and has lower computational complexity than\nseveral competing methods.",
          "link": "http://arxiv.org/abs/2106.06887",
          "publishedOn": "2021-06-15T01:45:16.386Z",
          "wordCount": 689,
          "title": "The Spatio-Temporal Poisson Point Process: A Simple Model for the Alignment of Event Camera Data. (arXiv:2106.06887v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06733",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yi Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yanfei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jingguang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Guocai Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_K/0/1/0/all/0/1\">Kai Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yefeng Zheng</a>",
          "description": "Radiation therapy treatment planning is a complex process, as the target dose\nprescription and normal tissue sparing are conflicting objectives. Automated\nand accurate dose prediction for radiation therapy planning is in high demand.\nIn this study, we propose a novel learning-based ensemble approach, named\nLE-NAS, which integrates neural architecture search (NAS) with knowledge\ndistillation for 3D radiotherapy dose prediction. Specifically, the prediction\nnetwork first exhaustively searches each block from enormous architecture\nspace. Then, multiple architectures are selected with promising performance and\ndiversity. To reduce the inference time, we adopt the teacher-student paradigm\nby treating the combination of diverse outputs from multiple searched networks\nas supervisions to guide the student network training. In addition, we apply\nadversarial learning to optimize the student network to recover the knowledge\nin teacher networks. To the best of our knowledge, we are the first to\ninvestigate the combination of NAS and knowledge distillation. The proposed\nmethod has been evaluated on the public OpenKBP dataset, and experimental\nresults demonstrate the effectiveness of our method and its superior\nperformance to the state-of-the-art method.",
          "link": "http://arxiv.org/abs/2106.06733",
          "publishedOn": "2021-06-15T01:45:16.362Z",
          "wordCount": 613,
          "title": "LE-NAS: Learning-based Ensenble with NAS for Dose Prediction. (arXiv:2106.06733v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06804",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Barbiero_P/0/1/0/all/0/1\">Pietro Barbiero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ciravegna_G/0/1/0/all/0/1\">Gabriele Ciravegna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giannini_F/0/1/0/all/0/1\">Francesco Giannini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lio_P/0/1/0/all/0/1\">Pietro Li&#xf3;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gori_M/0/1/0/all/0/1\">Marco Gori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Melacci_S/0/1/0/all/0/1\">Stefano Melacci</a>",
          "description": "Explainable artificial intelligence has rapidly emerged since lawmakers have\nstarted requiring interpretable models for safety-critical domains.\nConcept-based neural networks have arisen as explainable-by-design methods as\nthey leverage human-understandable symbols (i.e. concepts) to predict class\nmemberships. However, most of these approaches focus on the identification of\nthe most relevant concepts but do not provide concise, formal explanations of\nhow such concepts are leveraged by the classifier to make predictions. In this\npaper, we propose a novel end-to-end differentiable approach enabling the\nextraction of logic explanations from neural networks using the formalism of\nFirst-Order Logic. The method relies on an entropy-based criterion which\nautomatically identifies the most relevant concepts. We consider four different\ncase studies to demonstrate that: (i) this entropy-based criterion enables the\ndistillation of concise logic explanations in safety-critical domains from\nclinical data to computer vision; (ii) the proposed approach outperforms\nstate-of-the-art white-box models in terms of classification accuracy.",
          "link": "http://arxiv.org/abs/2106.06804",
          "publishedOn": "2021-06-15T01:45:16.341Z",
          "wordCount": 591,
          "title": "Entropy-based Logic Explanations of Neural Networks. (arXiv:2106.06804v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2008.06910",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zanfir_A/0/1/0/all/0/1\">Andrei Zanfir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bazavan_E/0/1/0/all/0/1\">Eduard Gabriel Bazavan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zanfir_M/0/1/0/all/0/1\">Mihai Zanfir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freeman_W/0/1/0/all/0/1\">William T. Freeman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sukthankar_R/0/1/0/all/0/1\">Rahul Sukthankar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sminchisescu_C/0/1/0/all/0/1\">Cristian Sminchisescu</a>",
          "description": "We present deep neural network methodology to reconstruct the 3d pose and\nshape of people, given an input RGB image. We rely on a recently introduced,\nexpressivefull body statistical 3d human model, GHUM, trained end-to-end, and\nlearn to reconstruct its pose and shape state in a self-supervised regime.\nCentral to our methodology, is a learning to learn and optimize approach,\nreferred to as HUmanNeural Descent (HUND), which avoids both second-order\ndifferentiation when training the model parameters,and expensive state gradient\ndescent in order to accurately minimize a semantic differentiable rendering\nloss at test time. Instead, we rely on novel recurrent stages to update the\npose and shape parameters such that not only losses are minimized effectively,\nbut the process is meta-regularized in order to ensure end-progress. HUND's\nsymmetry between training and testing makes it the first 3d human sensing\narchitecture to natively support different operating regimes including\nself-supervised ones. In diverse tests, we show that HUND achieves very\ncompetitive results in datasets like H3.6M and 3DPW, aswell as good quality 3d\nreconstructions for complex imagery collected in-the-wild.",
          "link": "http://arxiv.org/abs/2008.06910",
          "publishedOn": "2021-06-15T01:45:16.329Z",
          "wordCount": 649,
          "title": "Neural Descent for Visual 3D Human Pose and Shape. (arXiv:2008.06910v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06637",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1\">Yan Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ravikumar_N/0/1/0/all/0/1\">Nishant Ravikumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frangi_A/0/1/0/all/0/1\">Alejandro F Frangi</a>",
          "description": "Image registration is a fundamental building block for various applications\nin medical image analysis. To better explore the correlation between the fixed\nand moving images and improve registration performance, we propose a novel deep\nlearning network, Co-Attention guided Registration Network (CAR-Net). CAR-Net\nemploys a co-attention block to learn a new representation of the inputs, which\ndrives the registration of the fixed and moving images. Experiments on UK\nBiobank cardiac cine-magnetic resonance image data demonstrate that CAR-Net\nobtains higher registration accuracy and smoother deformation fields than\nstate-of-the-art unsupervised registration methods, while achieving comparable\nor better registration performance than corresponding weakly-supervised\nvariants. In addition, our approach can provide critical structural information\nof the input fixed and moving images simultaneously in a completely\nunsupervised manner.",
          "link": "http://arxiv.org/abs/2106.06637",
          "publishedOn": "2021-06-15T01:45:16.323Z",
          "wordCount": 561,
          "title": "CAR-Net: Unsupervised Co-Attention Guided Registration Network for Joint Registration and Structure Learning. (arXiv:2106.06637v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06882",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vedder_K/0/1/0/all/0/1\">Kyle Vedder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eaton_E/0/1/0/all/0/1\">Eric Eaton</a>",
          "description": "Bird's Eye View (BEV) is a popular representation for processing 3D point\nclouds, and by its nature is fundamentally sparse. Motivated by the\ncomputational limitations of mobile robot platforms, we take a fast\nhigh-performance BEV 3D object detector - PointPillars - and modify its\nbackbone to exploit this sparsity, leading to decreased runtimes. We present\npreliminary results demonstrating decreased runtimes with either the same\nperformance or a modest decrease in performance, which we anticipate will be\nremedied by model specific hyperparameter tuning. Our work is a first step\ntowards a new class of 3D object detectors that exploit sparsity throughout\ntheir entire pipeline in order to reduce runtime and resource usage while\nmaintaining good detection performance.",
          "link": "http://arxiv.org/abs/2106.06882",
          "publishedOn": "2021-06-15T01:45:16.254Z",
          "wordCount": 546,
          "title": "Sparse PointPillars: Exploiting Sparsity in Birds-Eye-View Object Detection. (arXiv:2106.06882v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06650",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vo_H/0/1/0/all/0/1\">Huy V. Vo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sizikova_E/0/1/0/all/0/1\">Elena Sizikova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmid_C/0/1/0/all/0/1\">Cordelia Schmid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perez_P/0/1/0/all/0/1\">Patrick P&#xe9;rez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ponce_J/0/1/0/all/0/1\">Jean Ponce</a>",
          "description": "Existing approaches to unsupervised object discovery (UOD) do not scale up to\nlarge datasets without approximations which compromise their performance. We\npropose a novel formulation of UOD as a ranking problem, amenable to the\narsenal of distributed methods available for eigenvalue problems and link\nanalysis. Extensive experiments with COCO and OpenImages demonstrate that, in\nthe single-object discovery setting where a single prominent object is sought\nin each image, the proposed LOD (Large-scale Object Discovery) approach is on\npar with, or better than the state of the art for medium-scale datasets (up to\n120K images), and over 37% better than the only other algorithms capable of\nscaling up to 1.7M images. In the multi-object discovery setting where multiple\nobjects are sought in each image, the proposed LOD is over 14% better in\naverage precision (AP) than all other methods for datasets ranging from 20K to\n1.7M images.",
          "link": "http://arxiv.org/abs/2106.06650",
          "publishedOn": "2021-06-15T01:45:16.226Z",
          "wordCount": 574,
          "title": "Large-Scale Unsupervised Object Discovery. (arXiv:2106.06650v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2103.10626",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sharma_Y/0/1/0/all/0/1\">Yash Sharma</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shrivastava_A/0/1/0/all/0/1\">Aman Shrivastava</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ehsan_L/0/1/0/all/0/1\">Lubaina Ehsan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Moskaluk_C/0/1/0/all/0/1\">Christopher A. Moskaluk</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Syed_S/0/1/0/all/0/1\">Sana Syed</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Brown_D/0/1/0/all/0/1\">Donald E. Brown</a>",
          "description": "In recent years, the availability of digitized Whole Slide Images (WSIs) has\nenabled the use of deep learning-based computer vision techniques for automated\ndisease diagnosis. However, WSIs present unique computational and algorithmic\nchallenges. WSIs are gigapixel-sized ($\\sim$100K pixels), making them\ninfeasible to be used directly for training deep neural networks. Also, often\nonly slide-level labels are available for training as detailed annotations are\ntedious and can be time-consuming for experts. Approaches using\nmultiple-instance learning (MIL) frameworks have been shown to overcome these\nchallenges. Current state-of-the-art approaches divide the learning framework\ninto two decoupled parts: a convolutional neural network (CNN) for encoding the\npatches followed by an independent aggregation approach for slide-level\nprediction. In this approach, the aggregation step has no bearing on the\nrepresentations learned by the CNN encoder. We have proposed an end-to-end\nframework that clusters the patches from a WSI into ${k}$-groups, samples\n${k}'$ patches from each group for training, and uses an adaptive attention\nmechanism for slide level prediction; Cluster-to-Conquer (C2C). We have\ndemonstrated that dividing a WSI into clusters can improve the model training\nby exposing it to diverse discriminative features extracted from the patches.\nWe regularized the clustering mechanism by introducing a KL-divergence loss\nbetween the attention weights of patches in a cluster and the uniform\ndistribution. The framework is optimized end-to-end on slide-level\ncross-entropy, patch-level cross-entropy, and KL-divergence loss\n(Implementation: https://github.com/YashSharma/C2C).",
          "link": "http://arxiv.org/abs/2103.10626",
          "publishedOn": "2021-06-15T01:45:15.952Z",
          "wordCount": 711,
          "title": "Cluster-to-Conquer: A Framework for End-to-End Multi-Instance Learning for Whole Slide Image Classification. (arXiv:2103.10626v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03210",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yaman_D/0/1/0/all/0/1\">Dogucan Yaman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ekenel_H/0/1/0/all/0/1\">Haz&#x131;m Kemal Ekenel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Waibel_A/0/1/0/all/0/1\">Alexander Waibel</a>",
          "description": "Portrait matting is an important research problem with a wide range of\napplications, such as video conference app, image/video editing, and\npost-production. The goal is to predict an alpha matte that identifies the\neffect of each pixel on the foreground subject. Traditional approaches and most\nof the existing works utilized an additional input, e.g., trimap, background\nimage, to predict alpha matte. However, providing additional input is not\nalways practical. Besides, models are too sensitive to these additional inputs.\nIn this paper, we introduce an additional input-free approach to perform\nportrait matting using Generative Adversarial Nets (GANs). We divide the main\ntask into two subtasks. For this, we propose a segmentation network for the\nperson segmentation and the alpha generation network for alpha matte\nprediction. While the segmentation network takes an input image and produces a\ncoarse segmentation map, the alpha generation network utilizes the same input\nimage as well as a coarse segmentation map that is produced by the segmentation\nnetwork to predict the alpha matte. Besides, we present a segmentation encoding\nblock to downsample the coarse segmentation map and provide feature\nrepresentation to the residual block. Furthermore, we propose border loss to\npenalize only the borders of the subject separately which is more likely to be\nchallenging and we also adapt perceptual loss for portrait matting. To train\nthe proposed system, we combine two different popular training datasets to\nimprove the amount of data as well as diversity to address domain shift\nproblems in the inference time. We tested our model on three different\nbenchmark datasets, namely Adobe Image Matting dataset, Portrait Matting\ndataset, and Distinctions dataset. The proposed method outperformed the MODNet\nmethod that also takes a single input.",
          "link": "http://arxiv.org/abs/2106.03210",
          "publishedOn": "2021-06-15T01:45:15.916Z",
          "wordCount": 729,
          "title": "Alpha Matte Generation from Single Input for Portrait Matting. (arXiv:2106.03210v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.03230",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zbontar_J/0/1/0/all/0/1\">Jure Zbontar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jing_L/0/1/0/all/0/1\">Li Jing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Misra_I/0/1/0/all/0/1\">Ishan Misra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+LeCun_Y/0/1/0/all/0/1\">Yann LeCun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deny_S/0/1/0/all/0/1\">St&#xe9;phane Deny</a>",
          "description": "Self-supervised learning (SSL) is rapidly closing the gap with supervised\nmethods on large computer vision benchmarks. A successful approach to SSL is to\nlearn embeddings which are invariant to distortions of the input sample.\nHowever, a recurring issue with this approach is the existence of trivial\nconstant solutions. Most current methods avoid such solutions by careful\nimplementation details. We propose an objective function that naturally avoids\ncollapse by measuring the cross-correlation matrix between the outputs of two\nidentical networks fed with distorted versions of a sample, and making it as\nclose to the identity matrix as possible. This causes the embedding vectors of\ndistorted versions of a sample to be similar, while minimizing the redundancy\nbetween the components of these vectors. The method is called Barlow Twins,\nowing to neuroscientist H. Barlow's redundancy-reduction principle applied to a\npair of identical networks. Barlow Twins does not require large batches nor\nasymmetry between the network twins such as a predictor network, gradient\nstopping, or a moving average on the weight updates. Intriguingly it benefits\nfrom very high-dimensional output vectors. Barlow Twins outperforms previous\nmethods on ImageNet for semi-supervised classification in the low-data regime,\nand is on par with current state of the art for ImageNet classification with a\nlinear classifier head, and for transfer tasks of classification and object\ndetection.",
          "link": "http://arxiv.org/abs/2103.03230",
          "publishedOn": "2021-06-15T01:45:15.887Z",
          "wordCount": 717,
          "title": "Barlow Twins: Self-Supervised Learning via Redundancy Reduction. (arXiv:2103.03230v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.05068",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chun_S/0/1/0/all/0/1\">Sanghyuk Chun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_S/0/1/0/all/0/1\">Seong Joon Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rezende_R/0/1/0/all/0/1\">Rafael Sampaio de Rezende</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalantidis_Y/0/1/0/all/0/1\">Yannis Kalantidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Larlus_D/0/1/0/all/0/1\">Diane Larlus</a>",
          "description": "Cross-modal retrieval methods build a common representation space for samples\nfrom multiple modalities, typically from the vision and the language domains.\nFor images and their captions, the multiplicity of the correspondences makes\nthe task particularly challenging. Given an image (respectively a caption),\nthere are multiple captions (respectively images) that equally make sense. In\nthis paper, we argue that deterministic functions are not sufficiently powerful\nto capture such one-to-many correspondences. Instead, we propose to use\nProbabilistic Cross-Modal Embedding (PCME), where samples from the different\nmodalities are represented as probabilistic distributions in the common\nembedding space. Since common benchmarks such as COCO suffer from\nnon-exhaustive annotations for cross-modal matches, we propose to additionally\nevaluate retrieval on the CUB dataset, a smaller yet clean database where all\npossible image-caption pairs are annotated. We extensively ablate PCME and\ndemonstrate that it not only improves the retrieval performance over its\ndeterministic counterpart but also provides uncertainty estimates that render\nthe embeddings more interpretable. Code is available at\nhttps://github.com/naver-ai/pcme",
          "link": "http://arxiv.org/abs/2101.05068",
          "publishedOn": "2021-06-15T01:45:15.867Z",
          "wordCount": 639,
          "title": "Probabilistic Embeddings for Cross-Modal Retrieval. (arXiv:2101.05068v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.05980",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Feng_C/0/1/0/all/0/1\">Chun-Mei Feng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_Z/0/1/0/all/0/1\">Zhanyuan Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fu_H/0/1/0/all/0/1\">Huazhu Fu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_Y/0/1/0/all/0/1\">Yong Xu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_J/0/1/0/all/0/1\">Jian Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shao_L/0/1/0/all/0/1\">Ling Shao</a>",
          "description": "Magnetic resonance (MR) image acquisition is an inherently prolonged process,\nwhose acceleration has long been the subject of research. This is commonly\nachieved by obtaining multiple undersampled images, simultaneously, through\nparallel imaging. In this paper, we propose the Dual-Octave Network (DONet),\nwhich is capable of learning multi-scale spatial-frequency features from both\nthe real and imaginary components of MR data, for fast parallel MR image\nreconstruction. More specifically, our DONet consists of a series of\nDual-Octave convolutions (Dual-OctConv), which are connected in a dense manner\nfor better reuse of features. In each Dual-OctConv, the input feature maps and\nconvolutional kernels are first split into two components (ie, real and\nimaginary), and then divided into four groups according to their spatial\nfrequencies. Then, our Dual-OctConv conducts intra-group information updating\nand inter-group information exchange to aggregate the contextual information\nacross different groups. Our framework provides three appealing benefits: (i)\nIt encourages information interaction and fusion between the real and imaginary\ncomponents at various spatial frequencies to achieve richer representational\ncapacity. (ii) The dense connections between the real and imaginary groups in\neach Dual-OctConv make the propagation of features more efficient by feature\nreuse. (iii) DONet enlarges the receptive field by learning multiple\nspatial-frequency features of both the real and imaginary components. Extensive\nexperiments on two popular datasets (ie, clinical knee and fastMRI), under\ndifferent undersampling patterns and acceleration factors, demonstrate the\nsuperiority of our model in accelerated parallel MR image reconstruction.",
          "link": "http://arxiv.org/abs/2105.05980",
          "publishedOn": "2021-06-15T01:45:15.761Z",
          "wordCount": 717,
          "title": "DONet: Dual-Octave Network for Fast MR Image Reconstruction. (arXiv:2105.05980v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06988",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhangy_W/0/1/0/all/0/1\">Weichuan Zhangy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liuy_X/0/1/0/all/0/1\">Xuefang Liuy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_Z/0/1/0/all/0/1\">Zhe Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yongsheng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1\">Changming Sun</a>",
          "description": "Metric-based few-shot fine-grained image classification (FSFGIC) aims to\nlearn a transferable feature embedding network by estimating the similarities\nbetween query images and support classes from very few examples. In this work,\nwe propose, for the first time, to introduce the non-linear data projection\nconcept into the design of FSFGIC architecture in order to address the limited\nsample problem in few-shot learning and at the same time to increase the\ndiscriminability of the model for fine-grained image classification.\nSpecifically, we first design a feature re-abstraction embedding network that\nhas the ability to not only obtain the required semantic features for effective\nmetric learning but also re-enhance such features with finer details from input\nimages. Then the descriptors of the query images and the support classes are\nprojected into different non-linear spaces in our proposed similarity metric\nlearning network to learn discriminative projection factors. This design can\neffectively operate in the challenging and restricted condition of a FSFGIC\ntask for making the distance between the samples within the same class smaller\nand the distance between samples from different classes larger and for reducing\nthe coupling relationship between samples from different categories.\nFurthermore, a novel similarity measure based on the proposed non-linear data\nproject is presented for evaluating the relationships of feature information\nbetween a query image and a support set. It is worth to note that our proposed\narchitecture can be easily embedded into any episodic training mechanisms for\nend-to-end training from scratch. Extensive experiments on FSFGIC tasks\ndemonstrate the superiority of the proposed methods over the state-of-the-art\nbenchmarks.",
          "link": "http://arxiv.org/abs/2106.06988",
          "publishedOn": "2021-06-15T01:45:15.709Z",
          "wordCount": 701,
          "title": "NDPNet: A novel non-linear data projection network for few-shot fine-gained image classification. (arXiv:2106.06988v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.15134",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wen_Z/0/1/0/all/0/1\">Zixin Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuanzhi Li</a>",
          "description": "How can neural networks trained by contrastive learning extract features from\nthe unlabeled data? Why does contrastive learning usually need much stronger\ndata augmentations than supervised learning to ensure good representations?\nThese questions involve both the optimization and statistical aspects of deep\nlearning, but can hardly be answered by analyzing supervised learning, where\nthe target functions are the highest pursuit. Indeed, in self-supervised\nlearning, it is inevitable to relate to the optimization/generalization of\nneural networks to how they can encode the latent structures in the data, which\nwe refer to as the feature learning process.\n\nIn this work, we formally study how contrastive learning learns the feature\nrepresentations for neural networks by analyzing its feature learning process.\nWe consider the case where our data are comprised of two types of features: the\nmore semantically aligned sparse features which we want to learn from, and the\nother dense features we want to avoid. Theoretically, we prove that contrastive\nlearning using $\\mathbf{ReLU}$ networks provably learns the desired sparse\nfeatures if proper augmentations are adopted. We present an underlying\nprinciple called $\\textbf{feature decoupling}$ to explain the effects of\naugmentations, where we theoretically characterize how augmentations can reduce\nthe correlations of dense features between positive samples while keeping the\ncorrelations of sparse features intact, thereby forcing the neural networks to\nlearn from the self-supervision of sparse features. Empirically, we verified\nthat the feature decoupling principle matches the underlying mechanism of\ncontrastive learning in practice.",
          "link": "http://arxiv.org/abs/2105.15134",
          "publishedOn": "2021-06-15T01:45:15.691Z",
          "wordCount": 703,
          "title": "Toward Understanding the Feature Learning Process of Self-supervised Contrastive Learning. (arXiv:2105.15134v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1906.06514",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongsong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1\">Jian Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_B/0/1/0/all/0/1\">Bin Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jiashi Feng</a>",
          "description": "Human motion prediction, which aims to predict future human poses given past\nposes, has recently seen increased interest. Many recent approaches are based\non Recurrent Neural Networks (RNN) which model human poses with exponential\nmaps. These approaches neglect the pose velocity as well as temporal relation\nof different poses, and tend to converge to the mean pose or fail to generate\nnatural-looking poses. We therefore propose a novel Position-Velocity Recurrent\nEncoder-Decoder (PVRED) for human motion prediction, which makes full use of\npose velocities and temporal positional information. A temporal position\nembedding method is presented and a Position-Velocity RNN (PVRNN) is proposed.\nWe also emphasize the benefits of quaternion parameterization of poses and\ndesign a novel trainable Quaternion Transformation (QT) layer, which is\ncombined with a robust loss function during training. We provide quantitative\nresults for both short-term prediction in the future 0.5 seconds and long-term\nprediction in the future 0.5 to 1 seconds. Experiments on several benchmarks\nshow that our approach considerably outperforms the state-of-the-art methods.\nIn addition, qualitative visualizations in the future 4 seconds show that our\napproach could predict future human-like and meaningful poses in very long time\nhorizons. Code is publicly available on GitHub:\n\\textcolor{red}{https://github.com/hongsong-wang/PVRNN}.",
          "link": "http://arxiv.org/abs/1906.06514",
          "publishedOn": "2021-06-15T01:45:15.508Z",
          "wordCount": 659,
          "title": "PVRED: A Position-Velocity Recurrent Encoder-Decoder for Human Motion Prediction. (arXiv:1906.06514v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03743",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Labatie_A/0/1/0/all/0/1\">Antoine Labatie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Masters_D/0/1/0/all/0/1\">Dominic Masters</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eaton_Rosen_Z/0/1/0/all/0/1\">Zach Eaton-Rosen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luschi_C/0/1/0/all/0/1\">Carlo Luschi</a>",
          "description": "We investigate the reasons for the performance degradation incurred with\nbatch-independent normalization. We find that the prototypical techniques of\nlayer normalization and instance normalization both induce the appearance of\nfailure modes in the neural network's pre-activations: (i) layer normalization\ninduces a collapse towards channel-wise constant functions; (ii) instance\nnormalization induces a lack of variability in instance statistics, symptomatic\nof an alteration of the expressivity. To alleviate failure mode (i) without\naggravating failure mode (ii), we introduce the technique \"Proxy Normalization\"\nthat normalizes post-activations using a proxy distribution. When combined with\nlayer normalization or group normalization, this batch-independent\nnormalization emulates batch normalization's behavior and consistently matches\nor exceeds its performance.",
          "link": "http://arxiv.org/abs/2106.03743",
          "publishedOn": "2021-06-15T01:45:15.459Z",
          "wordCount": 565,
          "title": "Proxy-Normalizing Activations to Match Batch Normalization while Removing Batch Dependence. (arXiv:2106.03743v2 [cs.LG] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.02523",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ochal_M/0/1/0/all/0/1\">Mateusz Ochal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patacchiola_M/0/1/0/all/0/1\">Massimiliano Patacchiola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Storkey_A/0/1/0/all/0/1\">Amos Storkey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vazquez_J/0/1/0/all/0/1\">Jose Vazquez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Sen Wang</a>",
          "description": "Few-Shot Learning (FSL) algorithms are commonly trained through Meta-Learning\n(ML), which exposes models to batches of tasks sampled from a meta-dataset to\nmimic tasks seen during evaluation. However, the standard training procedures\noverlook the real-world dynamics where classes commonly occur at different\nfrequencies. While it is generally understood that class imbalance harms the\nperformance of supervised methods, limited research examines the impact of\nimbalance on the FSL evaluation task. Our analysis compares 10 state-of-the-art\nmeta-learning and FSL methods on different imbalance distributions and\nrebalancing techniques. Our results reveal that 1) some FSL methods display a\nnatural disposition against imbalance while most other approaches produce a\nperformance drop by up to 17\\% compared to the balanced task without the\nappropriate mitigation; 2) contrary to popular belief, many meta-learning\nalgorithms will not automatically learn to balance from exposure to imbalanced\ntraining tasks; 3) classical rebalancing strategies, such as random\noversampling, can still be very effective, leading to state-of-the-art\nperformances and should not be overlooked; 4) FSL methods are more robust\nagainst meta-dataset imbalance than imbalance at the task-level with a similar\nimbalance ratio ($\\rho<20$), with the effect holding even in long-tail datasets\nunder a larger imbalance ($\\rho=65$).",
          "link": "http://arxiv.org/abs/2101.02523",
          "publishedOn": "2021-06-15T01:45:15.417Z",
          "wordCount": 677,
          "title": "Few-Shot Learning with Class Imbalance. (arXiv:2101.02523v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.13504",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liao_P/0/1/0/all/0/1\">Peiyuan Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Han Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1\">Keyulu Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaakkola_T/0/1/0/all/0/1\">Tommi Jaakkola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gordon_G/0/1/0/all/0/1\">Geoffrey Gordon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jegelka_S/0/1/0/all/0/1\">Stefanie Jegelka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1\">Ruslan Salakhutdinov</a>",
          "description": "While the advent of Graph Neural Networks (GNNs) has greatly improved node\nand graph representation learning in many applications, the neighborhood\naggregation scheme exposes additional vulnerabilities to adversaries seeking to\nextract node-level information about sensitive attributes. In this paper, we\nstudy the problem of protecting sensitive attributes by information obfuscation\nwhen learning with graph structured data. We propose a framework to locally\nfilter out pre-determined sensitive attributes via adversarial training with\nthe total variation and the Wasserstein distance. Our method creates a strong\ndefense against inference attacks, while only suffering small loss in task\nperformance. Theoretically, we analyze the effectiveness of our framework\nagainst a worst-case adversary, and characterize an inherent trade-off between\nmaximizing predictive accuracy and minimizing information leakage. Experiments\nacross multiple datasets from recommender systems, knowledge graphs and quantum\nchemistry demonstrate that the proposed approach provides a robust defense\nacross various graph structures and tasks, while producing competitive GNN\nencoders for downstream tasks.",
          "link": "http://arxiv.org/abs/2009.13504",
          "publishedOn": "2021-06-15T01:45:15.403Z",
          "wordCount": 667,
          "title": "Information Obfuscation of Graph Neural Networks. (arXiv:2009.13504v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.12672",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lo_S/0/1/0/all/0/1\">Shaw-Hwa Lo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1\">Yiqiao Yin</a>",
          "description": "In the field of eXplainable AI (XAI), robust ``blackbox'' algorithms such as\nConvolutional Neural Networks (CNNs) are known for making high prediction\nperformance. However, the ability to explain and interpret these algorithms\nstill require innovation in the understanding of influential and, more\nimportantly, explainable features that directly or indirectly impact the\nperformance of predictivity. A number of methods existing in literature focus\non visualization techniques but the concepts of explainability and\ninterpretability still require rigorous definition. In view of the above needs,\nthis paper proposes an interaction-based methodology -- Influence Score\n(I-score) -- to screen out the noisy and non-informative variables in the\nimages hence it nourishes an environment with explainable and interpretable\nfeatures that are directly associated to feature predictivity. We apply the\nproposed method on a real world application in Pneumonia Chest X-ray Image data\nset and produced state-of-the-art results. We demonstrate how to apply the\nproposed approach for more general big data problems by improving the\nexplainability and interpretability without sacrificing the prediction\nperformance. The contribution of this paper opens a novel angle that moves the\ncommunity closer to the future pipelines of XAI problems.",
          "link": "http://arxiv.org/abs/2104.12672",
          "publishedOn": "2021-06-15T01:45:15.383Z",
          "wordCount": 656,
          "title": "A Novel Interaction-based Methodology Towards Explainable AI with Better Understanding of Pneumonia Chest X-ray Images. (arXiv:2104.12672v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.05077",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chrysos_G/0/1/0/all/0/1\">Grigorios G Chrysos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Georgopoulos_M/0/1/0/all/0/1\">Markos Georgopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panagakis_Y/0/1/0/all/0/1\">Yannis Panagakis</a>",
          "description": "Generative modeling has evolved to a notable field of machine learning. Deep\npolynomial neural networks (PNNs) have demonstrated impressive results in\nunsupervised image generation, where the task is to map an input vector (i.e.,\nnoise) to a synthesized image. However, the success of PNNs has not been\nreplicated in conditional generation tasks, such as super-resolution. Existing\nPNNs focus on single-variable polynomial expansions which do not fare well to\ntwo-variable inputs, i.e., the noise variable and the conditional variable. In\nthis work, we introduce a general framework, called CoPE, that enables a\npolynomial expansion of two input variables and captures their auto- and\ncross-correlations. We exhibit how CoPE can be trivially augmented to accept an\narbitrary number of input variables. CoPE is evaluated in five tasks\n(class-conditional generation, inverse problems, edges-to-image translation,\nimage-to-image translation, attribute-guided generation) involving eight\ndatasets. The thorough evaluation suggests that CoPE can be useful for tackling\ndiverse conditional generation tasks.",
          "link": "http://arxiv.org/abs/2104.05077",
          "publishedOn": "2021-06-15T01:45:15.327Z",
          "wordCount": 612,
          "title": "CoPE: Conditional image generation using Polynomial Expansions. (arXiv:2104.05077v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.10884",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cai_H/0/1/0/all/0/1\">Hongxiang Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jun Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1\">Yichao Xiong</a>",
          "description": "The prevalent perspectives of scene text recognition are from sequence to\nsequence (seq2seq) and segmentation. Nevertheless, the former is composed of\nmany components which makes implementation and deployment complicated, while\nthe latter requires character level annotations that is expensive. In this\npaper, we revisit classification perspective that models scene text recognition\nas an image classification problem. Classification perspective has a simple\npipeline and only needs word level annotations. We revive classification\nperspective by devising a scene text recognition model named as CSTR, which\nperforms as well as methods from other perspectives. The CSTR model consists of\nCPNet (classification perspective network) and SPPN (separated conv with global\naverage pooling prediction network). CSTR is as simple as image classification\nmodel like ResNet \\cite{he2016deep} which makes it easy to implement and\ndeploy. We demonstrate the effectiveness of the classification perspective on\nscene text recognition with extensive experiments. Futhermore, CSTR achieves\nnearly state-of-the-art performance on six public benchmarks including regular\ntext, irregular text. The code will be available at\nhttps://github.com/Media-Smart/vedastr.",
          "link": "http://arxiv.org/abs/2102.10884",
          "publishedOn": "2021-06-15T01:45:15.321Z",
          "wordCount": 635,
          "title": "Revisiting Classification Perspective on Scene Text Recognition. (arXiv:2102.10884v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.03716",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_W/0/1/0/all/0/1\">Wuxinlin Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_C/0/1/0/all/0/1\">Chenhui Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1\">Zhiqiang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1\">Yaohui Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhiru Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1\">Zhuo Feng</a>",
          "description": "A black-box spectral method is introduced for evaluating the adversarial\nrobustness of a given machine learning (ML) model. Our approach, named SPADE,\nexploits bijective distance mapping between the input/output graphs constructed\nfor approximating the manifolds corresponding to the input/output data. By\nleveraging the generalized Courant-Fischer theorem, we propose a SPADE score\nfor evaluating the adversarial robustness of a given model, which is proved to\nbe an upper bound of the best Lipschitz constant under the manifold setting. To\nreveal the most non-robust data samples highly vulnerable to adversarial\nattacks, we develop a spectral graph embedding procedure leveraging dominant\ngeneralized eigenvectors. This embedding step allows assigning each data sample\na robustness score that can be further harnessed for more effective adversarial\ntraining. Our experiments show the proposed SPADE method leads to promising\nempirical results for neural network models that are adversarially trained with\nthe MNIST and CIFAR-10 data sets.",
          "link": "http://arxiv.org/abs/2102.03716",
          "publishedOn": "2021-06-15T01:45:15.281Z",
          "wordCount": 635,
          "title": "SPADE: A Spectral Method for Black-Box Adversarial Robustness Evaluation. (arXiv:2102.03716v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.05522",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiashun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Huazhe Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jingwei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Sifei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaolong Wang</a>",
          "description": "Synthesizing 3D human motion plays an important role in many graphics\napplications as well as understanding human activity. While many efforts have\nbeen made on generating realistic and natural human motion, most approaches\nneglect the importance of modeling human-scene interactions and affordance. On\nthe other hand, affordance reasoning (e.g., standing on the floor or sitting on\nthe chair) has mainly been studied with static human pose and gestures, and it\nhas rarely been addressed with human motion. In this paper, we propose to\nbridge human motion synthesis and scene affordance reasoning. We present a\nhierarchical generative framework to synthesize long-term 3D human motion\nconditioning on the 3D scene structure. Building on this framework, we further\nenforce multiple geometry constraints between the human mesh and scene point\nclouds via optimization to improve realistic synthesis. Our experiments show\nsignificant improvements over previous approaches on generating natural and\nphysically plausible human motion in a scene.",
          "link": "http://arxiv.org/abs/2012.05522",
          "publishedOn": "2021-06-15T01:45:15.214Z",
          "wordCount": 617,
          "title": "Synthesizing Long-Term 3D Human Motion and Interaction in 3D Scenes. (arXiv:2012.05522v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.08524",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Garcia_Salguero_M/0/1/0/all/0/1\">Mercedes Garcia-Salguero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_Jimenez_J/0/1/0/all/0/1\">Javier Gonzalez-Jimenez</a>",
          "description": "This work contributes an efficient algorithm to compute the Relative Pose\nproblem (RPp) between calibrated cameras and certify the optimality of the\nsolution, given a set of pair-wise feature correspondences affected by noise\nand probably corrupted by wrong matches. We propose a family of certifiers that\nis shown to increase the ratio of detected optimal solutions. This set of\ncertifiers is incorporated into a fast essential matrix estimation pipeline\nthat, given any initial guess for the RPp, refines it iteratively on the\nproduct space of 3D rotations and 2-sphere. In addition, this fast certifiable\npipeline is integrated into a robust framework that combines Graduated\nNon-convexity and the Black-Rangarajan duality between robust functions and\nline processes.\n\nWe proved through extensive experiments on synthetic and real data that the\nproposed framework provides a fast and robust relative pose estimation. We make\nthe code publicly available\n\\url{https://github.com/mergarsal/FastCertRelPose.git}.",
          "link": "http://arxiv.org/abs/2101.08524",
          "publishedOn": "2021-06-15T01:45:15.205Z",
          "wordCount": 609,
          "title": "Fast and Robust Certifiable Estimation of the Relative Pose Between Two Calibrated Cameras. (arXiv:2101.08524v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.01158",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tushar_F/0/1/0/all/0/1\">Fakrul Islam Tushar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DAnniballe_V/0/1/0/all/0/1\">Vincent M. D&#x27;Anniballe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_R/0/1/0/all/0/1\">Rui Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mazurowski_M/0/1/0/all/0/1\">Maciej A. Mazurowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_W/0/1/0/all/0/1\">Wanyi Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samei_E/0/1/0/all/0/1\">Ehsan Samei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubin_G/0/1/0/all/0/1\">Geoffrey D. Rubin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lo_J/0/1/0/all/0/1\">Joseph Y. Lo</a>",
          "description": "Background: Training deep learning classifiers typically requires massive\namounts of manual annotation. Weak supervision may leverage existing medical\ndata to classify multiple diseases and organ systems. Purpose: To design\nmulti-disease classifiers for body computed tomography (CT) scans using\nautomatically extracted labels from radiology text reports. Materials &\nMethods: This retrospective study deployed rule-based algorithms to extract\n19,255 disease labels from reports of 13,667 body CT scans of 12,092 subjects\nfor training. Using a 3D DenseVNet, three organ systems were segmented:\nlungs/pleura, liver/gallbladder, and kidneys/ureters. For each organ, a 3D\nconvolutional neural network classified normality versus four common diseases.\nTesting was performed on an additional 2,158 CT volumes relative to 2,875\nmanually derived reference labels. Results: Manual validation of the extracted\nlabels confirmed 91 to 99% accuracy. Performance using the receiver operating\ncharacteristic area under the curve (AUC) for lungs/pleura labels were as\nfollows: atelectasis 0.77 (95% CI: 0.74 to 0.81), nodule 0.65 (0.61 to 0.69),\nemphysema 0.89 (0.86 to 0.92), effusion 0.97 (0.96 to 0.98), and normal 0.89\n(0.87 to 0.91). For liver/gallbladder: stone 0.62 (0.56 to 0.67), lesion 0.73\n(0.69 to 0.77), dilation 0.87 (0.84 to 0.90), fatty 0.89 (0.86 to 0.92), and\nnormal 0.82 (0.78 to 0.85). For kidneys/ureters: stone 0.83 (0.79 to 0.87),\natrophy 0.92 (0.89 to 0.94), lesion 0.68 (0.64 to 0.72), cyst 0.70 (0.66 to\n0.73), and normal 0.79 (0.75 to 0.83). Conclusion: Weakly supervised deep\nlearning classifiers leveraged massive amounts of unannotated body CT data to\nclassify multiple organ systems and diverse diseases.",
          "link": "http://arxiv.org/abs/2008.01158",
          "publishedOn": "2021-06-15T01:45:15.197Z",
          "wordCount": 749,
          "title": "Multi-Disease Classification of 13,667 Body CT Scans Using Weakly Supervised Deep Learning. (arXiv:2008.01158v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.01458",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1\">Shitong Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1\">Wei Hu</a>",
          "description": "We present a probabilistic model for point cloud generation, which is\nfundamental for various 3D vision tasks such as shape completion, upsampling,\nsynthesis and data augmentation. Inspired by the diffusion process in\nnon-equilibrium thermodynamics, we view points in point clouds as particles in\na thermodynamic system in contact with a heat bath, which diffuse from the\noriginal distribution to a noise distribution. Point cloud generation thus\namounts to learning the reverse diffusion process that transforms the noise\ndistribution to the distribution of a desired shape. Specifically, we propose\nto model the reverse diffusion process for point clouds as a Markov chain\nconditioned on certain shape latent. We derive the variational bound in closed\nform for training and provide implementations of the model. Experimental\nresults demonstrate that our model achieves competitive performance in point\ncloud generation and auto-encoding. The code is available at\n\\url{https://github.com/luost26/diffusion-point-cloud}.",
          "link": "http://arxiv.org/abs/2103.01458",
          "publishedOn": "2021-06-15T01:45:15.162Z",
          "wordCount": 602,
          "title": "Diffusion Probabilistic Models for 3D Point Cloud Generation. (arXiv:2103.01458v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06965",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fenglin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_C/0/1/0/all/0/1\">Changchang Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_S/0/1/0/all/0/1\">Shen Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Ping Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xu Sun</a>",
          "description": "Recently, chest X-ray report generation, which aims to automatically generate\ndescriptions of given chest X-ray images, has received growing research\ninterests. The key challenge of chest X-ray report generation is to accurately\ncapture and describe the abnormal regions. In most cases, the normal regions\ndominate the entire chest X-ray image, and the corresponding descriptions of\nthese normal regions dominate the final report. Due to such data bias,\nlearning-based models may fail to attend to abnormal regions. In this work, to\neffectively capture and describe abnormal regions, we propose the Contrastive\nAttention (CA) model. Instead of solely focusing on the current input image,\nthe CA model compares the current input image with normal images to distill the\ncontrastive information. The acquired contrastive information can better\nrepresent the visual features of abnormal regions. According to the experiments\non the public IU-X-ray and MIMIC-CXR datasets, incorporating our CA into\nseveral existing models can boost their performance across most metrics. In\naddition, according to the analysis, the CA model can help existing models\nbetter attend to the abnormal regions and provide more accurate descriptions\nwhich are crucial for an interpretable diagnosis. Specifically, we achieve the\nstate-of-the-art results on the two public datasets.",
          "link": "http://arxiv.org/abs/2106.06965",
          "publishedOn": "2021-06-15T01:45:15.131Z",
          "wordCount": 669,
          "title": "Contrastive Attention for Automatic Chest X-ray Report Generation. (arXiv:2106.06965v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2008.13305",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhijian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xin_J/0/1/0/all/0/1\">Jack Xin</a>",
          "description": "Deep Neural Networks (DNNs) needs to be both efficient and robust for\npractical uses. Quantization and structure simplification are promising ways to\nadapt DNNs to mobile devices, and adversarial training is the most popular\nmethod to make DNNs robust. In this work, we try to obtain both features by\napplying a convergent relaxation quantization algorithm, Binary-Relax (BR), to\na robust adversarial-trained model, ResNets Ensemble via Feynman-Kac Formalism\n(EnResNet). We also discover that high precision, such as ternary (tnn) and\n4-bit, quantization will produce sparse DNNs. However, this sparsity is\nunstructured under advarsarial training. To solve the problems that adversarial\ntraining jeopardizes DNNs' accuracy on clean images and the struture of\nsparsity, we design a trade-off loss function that helps DNNs preserve their\nnatural accuracy and improve the channel sparsity. With our trade-off loss\nfunction, we achieve both goals with no reduction of resistance under weak\nattacks and very minor reduction of resistance under strong attcks. Together\nwith quantized EnResNet with trade-off loss function, we provide robust models\nthat have high efficiency.",
          "link": "http://arxiv.org/abs/2008.13305",
          "publishedOn": "2021-06-15T01:45:15.114Z",
          "wordCount": 637,
          "title": "An Integrated Approach to Produce Robust Models with High Efficiency. (arXiv:2008.13305v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.13052",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chu_Z/0/1/0/all/0/1\">Zhendong Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jing Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongning Wang</a>",
          "description": "Crowdsourcing provides a practical way to obtain large amounts of labeled\ndata at a low cost. However, the annotation quality of annotators varies\nconsiderably, which imposes new challenges in learning a high-quality model\nfrom the crowdsourced annotations. In this work, we provide a new perspective\nto decompose annotation noise into common noise and individual noise and\ndifferentiate the source of confusion based on instance difficulty and\nannotator expertise on a per-instance-annotator basis. We realize this new\ncrowdsourcing model by an end-to-end learning solution with two types of noise\nadaptation layers: one is shared across annotators to capture their commonly\nshared confusions, and the other one is pertaining to each annotator to realize\nindividual confusion. To recognize the source of noise in each annotation, we\nuse an auxiliary network to choose the two noise adaptation layers with respect\nto both instances and annotators. Extensive experiments on both synthesized and\nreal-world benchmarks demonstrate the effectiveness of our proposed common\nnoise adaptation solution.",
          "link": "http://arxiv.org/abs/2012.13052",
          "publishedOn": "2021-06-15T01:45:15.093Z",
          "wordCount": 624,
          "title": "Learning from Crowds by Modeling Common Confusions. (arXiv:2012.13052v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06987",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Tripathi_A/0/1/0/all/0/1\">Arpan Tripathi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Panicker_M/0/1/0/all/0/1\">Mahesh Raveendranatha Panicker</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hareendranathan_A/0/1/0/all/0/1\">Abhilash R Hareendranathan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_Y/0/1/0/all/0/1\">Yale Tung Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jaremko_J/0/1/0/all/0/1\">Jacob L Jaremko</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Narayan_K/0/1/0/all/0/1\">Kiran Vishnu Narayan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+C_K/0/1/0/all/0/1\">Kesavadas C</a>",
          "description": "Lung ultrasound (LUS) is an increasingly popular diagnostic imaging modality\nfor continuous and periodic monitoring of lung infection, given its advantages\nof non-invasiveness, non-ionizing nature, portability and easy disinfection.\nThe major landmarks assessed by clinicians for triaging using LUS are pleura, A\nand B lines. There have been many efforts for the automatic detection of these\nlandmarks. However, restricting to a few pre-defined landmarks may not reveal\nthe actual imaging biomarkers particularly in case of new pathologies like\nCOVID-19. Rather, the identification of key landmarks should be driven by data\ngiven the availability of a plethora of neural network algorithms. This work is\na first of its kind attempt towards unsupervised detection of the key LUS\nlandmarks in LUS videos of COVID-19 subjects during various stages of\ninfection. We adapted the relatively newer approach of transporter neural\nnetworks to automatically mark and track pleura, A and B lines based on their\nperiodic motion and relatively stable appearance in the videos. Initial results\non unsupervised pleura detection show an accuracy of 91.8% employing 1081 LUS\nvideo frames.",
          "link": "http://arxiv.org/abs/2106.06987",
          "publishedOn": "2021-06-15T01:45:15.073Z",
          "wordCount": 688,
          "title": "Learning the Imaging Landmarks: Unsupervised Key point Detection in Lung Ultrasound Videos. (arXiv:2106.06987v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2008.05221",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_M/0/1/0/all/0/1\">Manish Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_P/0/1/0/all/0/1\">Puneet Agrawal</a>",
          "description": "In recent years, the fields of natural language processing (NLP) and\ninformation retrieval (IR) have made tremendous progress thanksto deep learning\nmodels like Recurrent Neural Networks (RNNs), Gated Recurrent Units (GRUs) and\nLong Short-Term Memory (LSTMs)networks, and Transformer [120] based models like\nBidirectional Encoder Representations from Transformers (BERT) [24],\nGenerativePre-training Transformer (GPT-2) [94], Multi-task Deep Neural Network\n(MT-DNN) [73], Extra-Long Network (XLNet) [134], Text-to-text transfer\ntransformer (T5) [95], T-NLG [98] and GShard [63]. But these models are\nhumongous in size. On the other hand,real world applications demand small model\nsize, low response times and low computational power wattage. In this survey,\nwediscuss six different types of methods (Pruning, Quantization, Knowledge\nDistillation, Parameter Sharing, Tensor Decomposition, andSub-quadratic\nTransformer based methods) for compression of such models to enable their\ndeployment in real industry NLP projects.Given the critical need of building\napplications with efficient and small models, and the large amount of recently\npublished work inthis area, we believe that this survey organizes the plethora\nof work done by the 'deep learning for NLP' community in the past fewyears and\npresents it as a coherent story.",
          "link": "http://arxiv.org/abs/2008.05221",
          "publishedOn": "2021-06-15T01:45:15.047Z",
          "wordCount": 675,
          "title": "Compression of Deep Learning Models for Text: A Survey. (arXiv:2008.05221v4 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1912.07812",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1\">Guangyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Etemad_A/0/1/0/all/0/1\">Ali Etemad</a>",
          "description": "Driver vigilance estimation is an important task for transportation safety.\nWearable and portable brain-computer interface devices provide a powerful means\nfor real-time monitoring of the vigilance level of drivers to help with\navoiding distracted or impaired driving. In this paper, we propose a novel\nmultimodal architecture for in-vehicle vigilance estimation from\nElectroencephalogram and Electrooculogram. To enable the system to focus on the\nmost salient parts of the learned multimodal representations, we propose an\narchitecture composed of a capsule attention mechanism following a deep Long\nShort-Term Memory (LSTM) network. Our model learns hierarchical dependencies in\nthe data through the LSTM and capsule feature representation layers. To better\nexplore the discriminative ability of the learned representations, we study the\neffect of the proposed capsule attention mechanism including the number of\ndynamic routing iterations as well as other parameters. Experiments show the\nrobustness of our method by outperforming other solutions and baseline\ntechniques, setting a new state-of-the-art. We then provide an analysis on\ndifferent frequency bands and brain regions to evaluate their suitability for\ndriver vigilance estimation. Lastly, an analysis on the role of capsule\nattention, multimodality, and robustness to noise is performed, highlighting\nthe advantages of our approach.",
          "link": "http://arxiv.org/abs/1912.07812",
          "publishedOn": "2021-06-15T01:45:15.006Z",
          "wordCount": 700,
          "title": "Capsule Attention for Multimodal EEG-EOG Representation Learning with Application to Driver Vigilance Estimation. (arXiv:1912.07812v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.09453",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hossain_M/0/1/0/all/0/1\">Md Tahmid Hossain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teng_S/0/1/0/all/0/1\">Shyh Wei Teng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sohel_F/0/1/0/all/0/1\">Ferdous Sohel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_G/0/1/0/all/0/1\">Guojun Lu</a>",
          "description": "Convolutional Neural Network's (CNN's) performance disparity on clean and\ncorrupted datasets has recently come under scrutiny. In this work, we analyse\ncommon corruptions in the frequency domain, i.e., High Frequency corruptions\n(HFc, e.g., noise) and Low Frequency corruptions (LFc, e.g., blur). Although a\nsimple solution to HFc is low-pass filtering, ReLU -- a widely used Activation\nFunction (AF), does not have any filtering mechanism. In this work, we instill\nlow-pass filtering into the AF (LP-ReLU) to improve robustness against HFc. To\ndeal with LFc, we complement LP-ReLU with Discrete Cosine Transform based\naugmentation. LP-ReLU, coupled with DCT augmentation, enables a deep network to\ntackle the entire spectrum of corruption. We use CIFAR-10-C and Tiny ImageNet-C\nfor evaluation and demonstrate improvements of 5% and 7.3% in accuracy\nrespectively, compared to the State-Of-The-Art (SOTA). We further evaluate our\nmethod's stability on a variety of perturbations in CIFAR-10-P and Tiny\nImageNet-P, achieving new SOTA in these experiments as well. To further\nstrengthen our understanding regarding CNN's lack of robustness, a decision\nspace visualisation process is proposed and presented in this work.",
          "link": "http://arxiv.org/abs/2007.09453",
          "publishedOn": "2021-06-15T01:45:14.986Z",
          "wordCount": 647,
          "title": "Robust Image Classification Using A Low-Pass Activation Function and DCT Augmentation. (arXiv:2007.09453v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06963",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fenglin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_S/0/1/0/all/0/1\">Shen Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_W/0/1/0/all/0/1\">Wei Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1\">Yuexian Zou</a>",
          "description": "Automatically generating radiology reports can improve current clinical\npractice in diagnostic radiology. On one hand, it can relieve radiologists from\nthe heavy burden of report writing; On the other hand, it can remind\nradiologists of abnormalities and avoid the misdiagnosis and missed diagnosis.\nYet, this task remains a challenging job for data-driven neural networks, due\nto the serious visual and textual data biases. To this end, we propose a\nPosterior-and-Prior Knowledge Exploring-and-Distilling approach (PPKED) to\nimitate the working patterns of radiologists, who will first examine the\nabnormal regions and assign the disease topic tags to the abnormal regions, and\nthen rely on the years of prior medical knowledge and prior working experience\naccumulations to write reports. Thus, the PPKED includes three modules:\nPosterior Knowledge Explorer (PoKE), Prior Knowledge Explorer (PrKE) and\nMulti-domain Knowledge Distiller (MKD). In detail, PoKE explores the posterior\nknowledge, which provides explicit abnormal visual regions to alleviate visual\ndata bias; PrKE explores the prior knowledge from the prior medical knowledge\ngraph (medical knowledge) and prior radiology reports (working experience) to\nalleviate textual data bias. The explored knowledge is distilled by the MKD to\ngenerate the final reports. Evaluated on MIMIC-CXR and IU-Xray datasets, our\nmethod is able to outperform previous state-of-the-art models on these two\ndatasets.",
          "link": "http://arxiv.org/abs/2106.06963",
          "publishedOn": "2021-06-15T01:45:14.960Z",
          "wordCount": 656,
          "title": "Exploring and Distilling Posterior and Prior Knowledge for Radiology Report Generation. (arXiv:2106.06963v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06966",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Huapeng Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gui_J/0/1/0/all/0/1\">Jie Gui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwok_J/0/1/0/all/0/1\">James T. Kwok</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1\">Zhihui Wei</a>",
          "description": "Recently, convolutional neural network (CNN) based image super-resolution\n(SR) methods have achieved significant performance improvement. However, most\nCNN-based methods mainly focus on feed-forward architecture design and neglect\nto explore the feedback mechanism, which usually exists in the human visual\nsystem. In this paper, we propose feedback pyramid attention networks (FPAN) to\nfully exploit the mutual dependencies of features. Specifically, a novel\nfeedback connection structure is developed to enhance low-level feature\nexpression with high-level information. In our method, the output of each layer\nin the first stage is also used as the input of the corresponding layer in the\nnext state to re-update the previous low-level filters. Moreover, we introduce\na pyramid non-local structure to model global contextual information in\ndifferent scales and improve the discriminative representation of the network.\nExtensive experimental results on various datasets demonstrate the superiority\nof our FPAN in comparison with the state-of-the-art SR methods.",
          "link": "http://arxiv.org/abs/2106.06966",
          "publishedOn": "2021-06-15T01:45:14.927Z",
          "wordCount": 581,
          "title": "Feedback Pyramid Attention Networks for Single Image Super-Resolution. (arXiv:2106.06966v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06744",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yujiao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jie Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xiaoshui Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_S/0/1/0/all/0/1\">Sai Ho Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_S/0/1/0/all/0/1\">Steven Weidong Su</a>",
          "description": "Lung cancer is the leading cause of cancer death worldwide. The critical\nreason for the deaths is delayed diagnosis and poor prognosis. With the\naccelerated development of deep learning techniques, it has been successfully\napplied extensively in many real-world applications, including health sectors\nsuch as medical image interpretation and disease diagnosis. By combining more\nmodalities that being engaged in the processing of information, multimodal\nlearning can extract better features and improve predictive ability. The\nconventional methods for lung cancer survival analysis normally utilize\nclinical data and only provide a statistical probability. To improve the\nsurvival prediction accuracy and help prognostic decision-making in clinical\npractice for medical experts, we for the first time propose a multimodal deep\nlearning method for non-small cell lung cancer (NSCLC) survival analysis, named\nDeepMMSA. This method leverages CT images in combination with clinical data,\nenabling the abundant information hold within medical images to be associate\nwith lung cancer survival information. We validate our method on the data of\n422 NSCLC patients from The Cancer Imaging Archive (TCIA). Experimental results\nsupport our hypothesis that there is an underlying relationship between\nprognostic information and radiomic images. Besides, quantitative results\nshowing that the established multimodal model can be applied to traditional\nmethod and has the potential to break bottleneck of existing methods and\nincrease the the percentage of concordant pairs(right predicted pairs) in\noverall population by 4%.",
          "link": "http://arxiv.org/abs/2106.06744",
          "publishedOn": "2021-06-15T01:45:14.921Z",
          "wordCount": 679,
          "title": "DeepMMSA: A Novel Multimodal Deep Learning Method for Non-small Cell Lung Cancer Survival Analysis. (arXiv:2106.06744v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06921",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1\">Sixing Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_P/0/1/0/all/0/1\">Phuong Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anwar_A/0/1/0/all/0/1\">Ali Anwar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jannesari_A/0/1/0/all/0/1\">Ali Jannesari</a>",
          "description": "Federated Learning~(FL) has emerged as a new paradigm of training machine\nlearning models without sacrificing data security and privacy. Learning models\nat edge devices such as cell phones is one of the most common use case of FL.\nHowever, the limited computing power and energy constraints of edge devices\nhinder the adoption of FL for both model training and deployment, especially\nfor the resource-hungry Deep Neural Networks~(DNNs). To this end, many model\ncompression methods have been proposed and network pruning is among the most\nwell-known. However, a pruning policy for a given model is highly\ndataset-dependent, which is not suitable for non-Independent and Identically\nDistributed~(Non-IID) FL edge devices. In this paper, we present an adaptive\npruning scheme for edge devices in an FL system, which applies dataset-aware\ndynamic pruning for inference acceleration on Non-IID datasets. Our evaluation\nshows that the proposed method accelerates inference by $2\\times$~($50\\%$ FLOPs\nreduction) while maintaining the model's quality on edge devices.",
          "link": "http://arxiv.org/abs/2106.06921",
          "publishedOn": "2021-06-15T01:45:14.914Z",
          "wordCount": 585,
          "title": "Adaptive Dynamic Pruning for Non-IID Federated Learning. (arXiv:2106.06921v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2009.06701",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sato_T/0/1/0/all/0/1\">Takami Sato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1\">Junjie Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_N/0/1/0/all/0/1\">Ningfei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1\">Yunhan Jack Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1\">Xue Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qi Alfred Chen</a>",
          "description": "Automated Lane Centering (ALC) systems are convenient and widely deployed\ntoday, but also highly security and safety critical. In this work, we are the\nfirst to systematically study the security of state-of-the-art deep learning\nbased ALC systems in their designed operational domains under physical-world\nadversarial attacks. We formulate the problem with a safety-critical attack\ngoal, and a novel and domain-specific attack vector: dirty road patches. To\nsystematically generate the attack, we adopt an optimization-based approach and\novercome domain-specific design challenges such as camera frame\ninter-dependencies due to attack-influenced vehicle control, and the lack of\nobjective function design for lane detection models.\n\nWe evaluate our attack on a production ALC using 80 scenarios from real-world\ndriving traces. The results show that our attack is highly effective with over\n97.5% success rates and less than 0.903 sec average success time, which is\nsubstantially lower than the average driver reaction time. This attack is also\nfound (1) robust to various real-world factors such as lighting conditions and\nview angles, (2) general to different model designs, and (3) stealthy from the\ndriver's view. To understand the safety impacts, we conduct experiments using\nsoftware-in-the-loop simulation and attack trace injection in a real vehicle.\nThe results show that our attack can cause a 100% collision rate in different\nscenarios, including when tested with common safety features such as automatic\nemergency braking. We also evaluate and discuss defenses.",
          "link": "http://arxiv.org/abs/2009.06701",
          "publishedOn": "2021-06-15T01:45:14.895Z",
          "wordCount": 726,
          "title": "Dirty Road Can Attack: Security of Deep Learning based Automated Lane Centering under Physical-World Attack. (arXiv:2009.06701v2 [cs.CR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06649",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Thuy C. Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_T/0/1/0/all/0/1\">Tuan N. Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Phan_N/0/1/0/all/0/1\">Nam LH. Phan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_C/0/1/0/all/0/1\">Chuong H. Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamazaki_M/0/1/0/all/0/1\">Masayuki Yamazaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamanaka_M/0/1/0/all/0/1\">Masao Yamanaka</a>",
          "description": "Video Instance Segmentation (VIS) is a multi-task problem performing\ndetection, segmentation, and tracking simultaneously. Extended from image set\napplications, video data additionally induces the temporal information, which,\nif handled appropriately, is very useful to identify and predict object\nmotions. In this work, we design a unified model to mutually learn these tasks.\nSpecifically, we propose two modules, named Temporally Correlated Instance\nSegmentation (TCIS) and Bidirectional Tracking (BiTrack), to take the benefit\nof the temporal correlation between the object's instance masks across adjacent\nframes. On the other hand, video data is often redundant due to the frame's\noverlap. Our analysis shows that this problem is particularly severe for the\nYoutubeVOS-VIS2021 data. Therefore, we propose a Multi-Source Data (MSD)\ntraining mechanism to compensate for the data deficiency. By combining these\ntechniques with a bag of tricks, the network performance is significantly\nboosted compared to the baseline, and outperforms other methods by a\nconsiderable margin on the YoutubeVOS-VIS 2019 and 2021 datasets.",
          "link": "http://arxiv.org/abs/2106.06649",
          "publishedOn": "2021-06-15T01:45:14.875Z",
          "wordCount": 604,
          "title": "1st Place Solution for YouTubeVOS Challenge 2021:Video Instance Segmentation. (arXiv:2106.06649v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06896",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yunhao Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mengmeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianbu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1\">Weiwei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_R/0/1/0/all/0/1\">Ran Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_Q/0/1/0/all/0/1\">Qian Du</a>",
          "description": "The monitoring of coastal wetlands is of great importance to the protection\nof marine and terrestrial ecosystems. However, due to the complex environment,\nsevere vegetation mixture, and difficulty of access, it is impossible to\naccurately classify coastal wetlands and identify their species with\ntraditional classifiers. Despite the integration of multisource remote sensing\ndata for performance enhancement, there are still challenges with acquiring and\nexploiting the complementary merits from multisource data. In this paper, the\nDeepwise Feature Interaction Network (DFINet) is proposed for wetland\nclassification. A depthwise cross attention module is designed to extract\nself-correlation and cross-correlation from multisource feature pairs. In this\nway, meaningful complementary information is emphasized for classification.\nDFINet is optimized by coordinating consistency loss, discrimination loss, and\nclassification loss. Accordingly, DFINet reaches the standard solution-space\nunder the regularity of loss functions, while the spatial consistency and\nfeature discrimination are preserved. Comprehensive experimental results on two\nhyperspectral and multispectral wetland datasets demonstrate that the proposed\nDFINet outperforms other competitive methods in terms of overall accuracy.",
          "link": "http://arxiv.org/abs/2106.06896",
          "publishedOn": "2021-06-15T01:45:14.837Z",
          "wordCount": 621,
          "title": "Hyperspectral and Multispectral Classification for Coastal Wetland Using Depthwise Feature Interaction Network. (arXiv:2106.06896v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06718",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Vago_N/0/1/0/all/0/1\">Nicol&#xf2; Oreste Pinciroli Vago</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Hameed_I/0/1/0/all/0/1\">Ibrahim A. Hameed</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Kachelriess_M/0/1/0/all/0/1\">Michael Kachelriess</a>",
          "description": "The presence of non-zero helicity in intergalactic magnetic fields is a\nsmoking gun for their primordial origin since they have to be generated by\nprocesses that break CP invariance. As an experimental signature for the\npresence of helical magnetic fields, an estimator $Q$ based on the triple\nscalar product of the wave-vectors of photons generated in electromagnetic\ncascades from, e.g., TeV blazars, has been suggested previously. We propose to\napply deep learning to helicity classification employing Convolutional Neural\nNetworks and show that this method outperforms the $Q$ estimator.",
          "link": "http://arxiv.org/abs/2106.06718",
          "publishedOn": "2021-06-15T01:45:14.776Z",
          "wordCount": 567,
          "title": "Using Convolutional Neural Networks for the Helicity Classification of Magnetic Fields. (arXiv:2106.06718v1 [astro-ph.HE])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06927",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rojas_Gomez_R/0/1/0/all/0/1\">Renan A. Rojas-Gomez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeh_R/0/1/0/all/0/1\">Raymond A. Yeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Do_M/0/1/0/all/0/1\">Minh N. Do</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1\">Anh Nguyen</a>",
          "description": "Recent research in adversarially robust classifiers suggests their\nrepresentations tend to be aligned with human perception, which makes them\nattractive for image synthesis and restoration applications. Despite favorable\nempirical results on a few downstream tasks, their advantages are limited to\nslow and sensitive optimization-based techniques. Moreover, their use on\ngenerative models remains unexplored. This work proposes the use of robust\nrepresentations as a perceptual primitive for feature inversion models, and\nshow its benefits with respect to standard non-robust image features. We\nempirically show that adopting robust representations as an image prior\nsignificantly improves the reconstruction accuracy of CNN-based feature\ninversion models. Furthermore, it allows reconstructing images at multiple\nscales out-of-the-box. Following these findings, we propose an\nencoding-decoding network based on robust representations and show its\nadvantages for applications such as anomaly detection, style transfer and image\ndenoising.",
          "link": "http://arxiv.org/abs/2106.06927",
          "publishedOn": "2021-06-15T01:45:14.712Z",
          "wordCount": 577,
          "title": "Inverting Adversarially Robust Networks for Image Synthesis. (arXiv:2106.06927v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06801",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pandey_P/0/1/0/all/0/1\">Prashant Pandey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pai_A/0/1/0/all/0/1\">Ajey Pai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhatt_N/0/1/0/all/0/1\">Nisarg Bhatt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_P/0/1/0/all/0/1\">Prasenjit Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Makharia_G/0/1/0/all/0/1\">Govind Makharia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+AP_P/0/1/0/all/0/1\">Prathosh AP</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mausam/0/1/0/all/0/1\">Mausam</a>",
          "description": "Contrastive Learning (CL) is a recent representation learning approach, which\nachieves promising results by encouraging inter-class separability and\nintra-class compactness in learned image representations. Because medical\nimages often contain multiple classes of interest per image, a standard\nimage-level CL for these images is not applicable. In this work, we present a\nnovel semi-supervised 2D medical segmentation solution that applies CL on image\npatches, instead of full images. These patches are meaningfully constructed\nusing the semantic information of different classes obtained via pseudo\nlabeling. We also propose a novel consistency regularization scheme, which\nworks in synergy with contrastive learning. It addresses the problem of\nconfirmation bias often observed in semi-supervised settings, and encourages\nbetter clustering in the feature space. We evaluate our method on four public\nmedical segmentation datasets along with a novel histopathology dataset that we\nintroduce. Our method obtains consistent improvements over the state-of-the-art\nsemi-supervised segmentation approaches for all datasets.",
          "link": "http://arxiv.org/abs/2106.06801",
          "publishedOn": "2021-06-15T01:45:14.702Z",
          "wordCount": 588,
          "title": "Contrastive Semi-Supervised Learning for 2D Medical Image Segmentation. (arXiv:2106.06801v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06946",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Horvath_M/0/1/0/all/0/1\">Mikl&#xf3;s Z. Horv&#xe1;th</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muller_M/0/1/0/all/0/1\">Mark Niklas M&#xfc;ller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fischer_M/0/1/0/all/0/1\">Marc Fischer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vechev_M/0/1/0/all/0/1\">Martin Vechev</a>",
          "description": "Randomized Smoothing (RS) is a promising method for obtaining robustness\ncertificates by evaluating a base model under noise. In this work we: (i)\ntheoretically motivate why ensembles are a particularly suitable choice as base\nmodels for RS, and (ii) empirically confirm this choice, obtaining state of the\nart results in multiple settings. The key insight of our work is that the\nreduced variance of ensembles over the perturbations introduced in RS leads to\nsignificantly more consistent classifications for a given input, in turn\nleading to substantially increased certifiable radii for difficult samples. We\nalso introduce key optimizations which enable an up to 50-fold decrease in\nsample complexity of RS, thus drastically reducing its computational overhead.\nExperimentally, we show that ensembles of only 3 to 10 classifiers consistently\nimprove on the strongest single model with respect to their average certified\nradius (ACR) by 5% to 21% on both CIFAR-10 and ImageNet. On the latter, we\nachieve a state-of-the-art ACR of 1.11. We release all code and models required\nto reproduce our results upon publication.",
          "link": "http://arxiv.org/abs/2106.06946",
          "publishedOn": "2021-06-15T01:45:14.670Z",
          "wordCount": 608,
          "title": "Boosting Randomized Smoothing with Variance Reduced Classifiers. (arXiv:2106.06946v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06792",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gu_L/0/1/0/all/0/1\">Lingyun Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhaokui Wang</a>",
          "description": "Visual surface inspection is a challenging task owing to the highly diverse\nappearance of target surfaces and defective regions. Previous attempts heavily\nrely on vast quantities of training examples with manual annotation. However,\nin some practical cases, it is difficult to obtain a large number of samples\nfor inspection. To combat it, we propose a hierarchical texture-perceiving\ngenerative adversarial network (HTP-GAN) that is learned from the one-shot\nnormal image in an unsupervised scheme. Specifically, the HTP-GAN contains a\npyramid of convolutional GANs that can capture the global structure and\nfine-grained representation of an image simultaneously. This innovation helps\ndistinguishing defective surface regions from normal ones. In addition, in the\ndiscriminator, a texture-perceiving module is devised to capture the spatially\ninvariant representation of normal image via directional convolutions, making\nit more sensitive to defective areas. Experiments on a variety of datasets\nconsistently demonstrate the effectiveness of our method.",
          "link": "http://arxiv.org/abs/2106.06792",
          "publishedOn": "2021-06-15T01:45:14.642Z",
          "wordCount": 584,
          "title": "A One-Shot Texture-Perceiving Generative Adversarial Network for Unsupervised Surface Inspection. (arXiv:2106.06792v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06942",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qing_Z/0/1/0/all/0/1\">Zhiwu Qing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Ziyuan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yutong Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shiwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jianwen Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_M/0/1/0/all/0/1\">Mingqian Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1\">Changxin Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ang_M/0/1/0/all/0/1\">Marcelo H. Ang Jr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sang_N/0/1/0/all/0/1\">Nong Sang</a>,",
          "description": "This technical report analyzes an egocentric video action detection method we\nused in the 2021 EPIC-KITCHENS-100 competition hosted in CVPR2021 Workshop. The\ngoal of our task is to locate the start time and the end time of the action in\nthe long untrimmed video, and predict action category. We adopt sliding window\nstrategy to generate proposals, which can better adapt to short-duration\nactions. In addition, we show that classification and proposals are conflict in\nthe same network. The separation of the two tasks boost the detection\nperformance with high efficiency. By simply employing these strategy, we\nachieved 16.10\\% performance on the test set of EPIC-KITCHENS-100 Action\nDetection challenge using a single model, surpassing the baseline method by\n11.7\\% in terms of average mAP.",
          "link": "http://arxiv.org/abs/2106.06942",
          "publishedOn": "2021-06-15T01:45:14.636Z",
          "wordCount": 570,
          "title": "A Stronger Baseline for Ego-Centric Action Detection. (arXiv:2106.06942v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06672",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shenao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Li Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhifeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wei Liu</a>",
          "description": "Capturing contextual dependencies has proven useful to improve the\nrepresentational power of deep neural networks. Recent approaches that focus on\nmodeling global context, such as self-attention and non-local operation,\nachieve this goal by enabling unconstrained pairwise interactions between\nelements. In this work, we consider learning representations for deformable\nobjects which can benefit from context exploitation by modeling the structural\ndependencies that the data intrinsically possesses. To this end, we provide a\nnovel structure-regularized attention mechanism, which formalizes feature\ninteraction as structural factorization through the use of a pair of\nlight-weight operations. The instantiated building blocks can be directly\nincorporated into modern convolutional neural networks, to boost the\nrepresentational power in an efficient manner. Comprehensive studies on\nmultiple tasks and empirical comparisons with modern attention mechanisms\ndemonstrate the gains brought by our method in terms of both performance and\nmodel complexity. We further investigate its effect on feature representations,\nshowing that our trained models can capture diversified representations\ncharacterizing object parts without resorting to extra supervision.",
          "link": "http://arxiv.org/abs/2106.06672",
          "publishedOn": "2021-06-15T01:45:14.628Z",
          "wordCount": 611,
          "title": "Structure-Regularized Attention for Deformable Object Representation. (arXiv:2106.06672v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06736",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brousmiche_M/0/1/0/all/0/1\">Mathilde Brousmiche</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rouat_J/0/1/0/all/0/1\">Jean Rouat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dupont_S/0/1/0/all/0/1\">St&#xe9;phane Dupont</a>",
          "description": "Event classification is inherently sequential and multimodal. Therefore, deep\nneural models need to dynamically focus on the most relevant time window and/or\nmodality of a video. In this study, we propose the Multi-level Attention Fusion\nnetwork (MAFnet), an architecture that can dynamically fuse visual and audio\ninformation for event recognition. Inspired by prior studies in neuroscience,\nwe couple both modalities at different levels of visual and audio paths.\nFurthermore, the network dynamically highlights a modality at a given time\nwindow relevant to classify events. Experimental results in AVE (Audio-Visual\nEvent), UCF51, and Kinetics-Sounds datasets show that the approach can\neffectively improve the accuracy in audio-visual event classification. Code is\navailable at: https://github.com/numediart/MAFnet",
          "link": "http://arxiv.org/abs/2106.06736",
          "publishedOn": "2021-06-15T01:45:14.617Z",
          "wordCount": 555,
          "title": "Multi-level Attention Fusion Network for Audio-visual Event Recognition. (arXiv:2106.06736v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06620",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Taghanaki_S/0/1/0/all/0/1\">Saeid Asgari Taghanaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_K/0/1/0/all/0/1\">Kristy Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khasahmadi_A/0/1/0/all/0/1\">Amir Khasahmadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_A/0/1/0/all/0/1\">Anirudh Goyal</a>",
          "description": "A fundamental challenge in artificial intelligence is learning useful\nrepresentations of data that yield good performance on a downstream task,\nwithout overfitting to spurious input features. Extracting such task-relevant\npredictive information is particularly difficult for real-world datasets. In\nthis work, we propose Contrastive Input Morphing (CIM), a representation\nlearning framework that learns input-space transformations of the data to\nmitigate the effect of irrelevant input features on downstream performance. Our\nmethod leverages a perceptual similarity metric via a triplet loss to ensure\nthat the transformation preserves task-relevant information.Empirically, we\ndemonstrate the efficacy of our approach on tasks which typically suffer from\nthe presence of spurious correlations: classification with nuisance\ninformation, out-of-distribution generalization, and preservation of subgroup\naccuracies. We additionally show that CIM is complementary to other mutual\ninformation-based representation learning techniques, and demonstrate that it\nimproves the performance of variational information bottleneck (VIB) when used\ntogether.",
          "link": "http://arxiv.org/abs/2106.06620",
          "publishedOn": "2021-06-15T01:45:14.594Z",
          "wordCount": 580,
          "title": "Robust Representation Learning via Perceptual Similarity Metrics. (arXiv:2106.06620v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06960",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cui_M/0/1/0/all/0/1\">Mengmeng Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jinjin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Liang Wang</a>",
          "description": "Attention-based encoder-decoder framework is widely used in the scene text\nrecognition task. However, for the current state-of-the-art(SOTA) methods,\nthere is room for improvement in terms of the efficient usage of local visual\nand global context information of the input text image, as well as the robust\ncorrelation between the scene processing module(encoder) and the text\nprocessing module(decoder). In this paper, we propose a Representation and\nCorrelation Enhanced Encoder-Decoder Framework(RCEED) to address these\ndeficiencies and break performance bottleneck. In the encoder module, local\nvisual feature, global context feature, and position information are aligned\nand fused to generate a small-size comprehensive feature map. In the decoder\nmodule, two methods are utilized to enhance the correlation between scene and\ntext feature space. 1) The decoder initialization is guided by the holistic\nfeature and global glimpse vector exported from the encoder. 2) The feature\nenriched glimpse vector produced by the Multi-Head General Attention is used to\nassist the RNN iteration and the character prediction at each time step.\nMeanwhile, we also design a Layernorm-Dropout LSTM cell to improve model's\ngeneralization towards changeable texts. Extensive experiments on the\nbenchmarks demonstrate the advantageous performance of RCEED in scene text\nrecognition tasks, especially the irregular ones.",
          "link": "http://arxiv.org/abs/2106.06960",
          "publishedOn": "2021-06-15T01:45:14.574Z",
          "wordCount": 639,
          "title": "Representation and Correlation Enhanced Encoder-Decoder Framework for Scene Text Recognition. (arXiv:2106.06960v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06593",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1\">Kedan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chong_M/0/1/0/all/0/1\">Min jin Chong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jeffrey Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jingen Liu</a>",
          "description": "Virtual try-on methods aim to generate images of fashion models wearing\narbitrary combinations of garments. This is a challenging task because the\ngenerated image must appear realistic and accurately display the interaction\nbetween garments. Prior works produce images that are filled with artifacts and\nfail to capture important visual details necessary for commercial applications.\nWe propose Outfit Visualization Net (OVNet) to capture these important details\n(e.g. buttons, shading, textures, realistic hemlines, and interactions between\ngarments) and produce high quality multiple-garment virtual try-on images.\nOVNet consists of 1) a semantic layout generator and 2) an image generation\npipeline using multiple coordinated warps. We train the warper to output\nmultiple warps using a cascade loss, which refines each successive warp to\nfocus on poorly generated regions of a previous warp and yields consistent\nimprovements in detail. In addition, we introduce a method for matching outfits\nwith the most suitable model and produce significant improvements for both our\nand other previous try-on methods. Through quantitative and qualitative\nanalysis, we demonstrate our method generates substantially higher-quality\nstudio images compared to prior works for multi-garment outfits. An interactive\ninterface powered by this method has been deployed on fashion e-commerce\nwebsites and received overwhelmingly positive feedback.",
          "link": "http://arxiv.org/abs/2106.06593",
          "publishedOn": "2021-06-15T01:45:14.568Z",
          "wordCount": 653,
          "title": "Toward Accurate and Realistic Outfits Visualization with Attention to Details. (arXiv:2106.06593v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06685",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Picot_M/0/1/0/all/0/1\">Marine Picot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Messina_F/0/1/0/all/0/1\">Francisco Messina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boudiaf_M/0/1/0/all/0/1\">Malik Boudiaf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Labeau_F/0/1/0/all/0/1\">Fabrice Labeau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ayed_I/0/1/0/all/0/1\">Ismail Ben Ayed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piantanida_P/0/1/0/all/0/1\">Pablo Piantanida</a>",
          "description": "Adversarial robustness has become a topic of growing interest in machine\nlearning since it was observed that neural networks tend to be brittle. We\npropose an information-geometric formulation of adversarial defense and\nintroduce FIRE, a new Fisher-Rao regularization for the categorical\ncross-entropy loss, which is based on the geodesic distance between natural and\nperturbed input features. Based on the information-geometric properties of the\nclass of softmax distributions, we derive an explicit characterization of the\nFisher-Rao Distance (FRD) for the binary and multiclass cases, and draw some\ninteresting properties as well as connections with standard regularization\nmetrics. Furthermore, for a simple linear and Gaussian model, we show that all\nPareto-optimal points in the accuracy-robustness region can be reached by FIRE\nwhile other state-of-the-art methods fail. Empirically, we evaluate the\nperformance of various classifiers trained with the proposed loss on standard\ndatasets, showing up to 2\\% of improvements in terms of robustness while\nreducing the training time by 20\\% over the best-performing methods.",
          "link": "http://arxiv.org/abs/2106.06685",
          "publishedOn": "2021-06-15T01:45:14.557Z",
          "wordCount": 595,
          "title": "Adversarial Robustness via Fisher-Rao Regularization. (arXiv:2106.06685v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06959",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1\">Jaewoong Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_C/0/1/0/all/0/1\">Changyeon Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Junho Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jung Ho Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_G/0/1/0/all/0/1\">Geonho Hwang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_M/0/1/0/all/0/1\">Myungjoo Kang</a>",
          "description": "In this paper, we propose a method to find local-geometry-aware traversal\ndirections on the intermediate latent space of Generative Adversarial Networks\n(GANs). These directions are defined as an ordered basis of tangent space at a\nlatent code. Motivated by the intrinsic sparsity of the latent space, the basis\nis discovered by solving the low-rank approximation problem of the differential\nof the partial network. Moreover, the local traversal basis leads to a natural\niterative traversal on the latent space. Iterative Curve-Traversal shows stable\ntraversal on images, since the trajectory of latent code stays close to the\nlatent space even under the strong perturbations compared to the linear\ntraversal. This stability provides far more diverse variations of the given\nimage. Although the proposed method can be applied to various GAN models, we\nfocus on the W-space of the StyleGAN2, which is renowned for showing the better\ndisentanglement of the latent factors of variation. Our quantitative and\nqualitative analysis provides evidence showing that the W-space is still\nglobally warped while showing a certain degree of global consistency of\ninterpretable variation. In particular, we introduce some metrics on the\nGrassmannian manifolds to quantify the global warpage of the W-space and the\nsubspace traversal to test the stability of traversal directions.",
          "link": "http://arxiv.org/abs/2106.06959",
          "publishedOn": "2021-06-15T01:45:14.537Z",
          "wordCount": 662,
          "title": "Do Not Escape From the Manifold: Discovering the Local Coordinates on the Latent Space of GANs. (arXiv:2106.06959v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06623",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kalra_S/0/1/0/all/0/1\">Shivam Kalra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adnan_M/0/1/0/all/0/1\">Mohammed Adnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hemati_S/0/1/0/all/0/1\">Sobhan Hemati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dehkharghanian_T/0/1/0/all/0/1\">Taher Dehkharghanian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahnamayan_S/0/1/0/all/0/1\">Shahryar Rahnamayan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tizhoosh_H/0/1/0/all/0/1\">Hamid Tizhoosh</a>",
          "description": "Deep learning methods such as convolutional neural networks (CNNs) are\ndifficult to directly utilize to analyze whole slide images (WSIs) due to the\nlarge image dimensions. We overcome this limitation by proposing a novel\ntwo-stage approach. First, we extract a set of representative patches (called\nmosaic) from a WSI. Each patch of a mosaic is encoded to a feature vector using\na deep network. The feature extractor model is fine-tuned using hierarchical\ntarget labels of WSIs, i.e., anatomic site and primary diagnosis. In the second\nstage, a set of encoded patch-level features from a WSI is used to compute the\nprimary diagnosis probability through the proposed Pay Attention with Focus\nscheme, an attention-weighted averaging of predicted probabilities for all\npatches of a mosaic modulated by a trainable focal factor. Experimental results\nshow that the proposed model can be robust, and effective for the\nclassification of WSIs.",
          "link": "http://arxiv.org/abs/2106.06623",
          "publishedOn": "2021-06-15T01:45:14.510Z",
          "wordCount": 596,
          "title": "Pay Attention with Focus: A Novel Learning Scheme for Classification of Whole Slide Images. (arXiv:2106.06623v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06664",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Fu_Y/0/1/0/all/0/1\">Yanwei Fu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhao_L/0/1/0/all/0/1\">Lei Zhao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zheng_H/0/1/0/all/0/1\">Haojie Zheng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sun_Q/0/1/0/all/0/1\">Qiang Sun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_L/0/1/0/all/0/1\">Li Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_H/0/1/0/all/0/1\">Hong Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xie_J/0/1/0/all/0/1\">Jiao Xie</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xue_X/0/1/0/all/0/1\">Xiangyang Xue</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_F/0/1/0/all/0/1\">Feng Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1\">Yuan Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pei_Y/0/1/0/all/0/1\">Yantao Pei</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_J/0/1/0/all/0/1\">Jianmin Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_X/0/1/0/all/0/1\">Xiuqi Wu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zheng_Y/0/1/0/all/0/1\">Yanhua Zheng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gu1_H/0/1/0/all/0/1\">Hongxia Tian Mengwei Gu1</a>",
          "description": "It is still nontrivial to develop a new fast COVID-19 screening method with\nthe easier access and lower cost, due to the technical and cost limitations of\nthe current testing methods in the medical resource-poor districts. On the\nother hand, there are more and more ocular manifestations that have been\nreported in the COVID-19 patients as growing clinical evidence[1]. This\ninspired this project. We have conducted the joint clinical research since\nJanuary 2021 at the ShiJiaZhuang City, Heibei province, China, which approved\nby the ethics committee of The fifth hospital of ShiJiaZhuang of Hebei Medical\nUniversity. We undertake several blind tests of COVID-19 patients by Union\nHospital, Tongji Medical College, Huazhong University of Science and\nTechnology, Wuhan, China. Meantime as an important part of the ongoing globally\nCOVID-19 eye test program by AIMOMICS since February 2020, we propose a new\nfast screening method of analyzing the eye-region images, captured by common\nCCD and CMOS cameras. This could reliably make a rapid risk screening of\nCOVID-19 with the sustainable stable high performance in different countries\nand races. Our model for COVID-19 rapid prescreening have the merits of the\nlower cost, fully self-performed, non-invasive, importantly real-time, and thus\nenables the continuous health surveillance. We further implement it as the open\naccessible APIs, and provide public service to the world. Our pilot experiments\nshow that our model is ready to be usable to all kinds of surveillance\nscenarios, such as infrared temperature measurement device at airports and\nstations, or directly pushing to the target people groups smartphones as a\npackaged application.",
          "link": "http://arxiv.org/abs/2106.06664",
          "publishedOn": "2021-06-15T01:45:14.491Z",
          "wordCount": 764,
          "title": "Rapid COVID-19 Risk Screening by Eye-region Manifestations. (arXiv:2106.06664v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06592",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Munoz_I/0/1/0/all/0/1\">Ignacio Mu&#xf1;oz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bolt_A/0/1/0/all/0/1\">Alfredo Bolt</a>",
          "description": "Introduction: Mobile apps, through artificial vision, are capable of\nrecognizing vegetable species in real time. However, the existing species\nrecognition apps do not take in consideration the wide variety of endemic and\nnative (Chilean) species, which leads to wrong species predictions. This study\nintroduces the development of a chilean species dataset and an optimized\nclassification model implemented to a mobile app. Method: the data set was\nbuilt by putting together pictures of several species captured on the field and\nby selecting some pictures available from other datasets available online.\nConvolutional neural networks were used in order to develop the images\nprediction models. The networks were trained by performing a sensitivity\nanalysis, validating with k-fold cross validation and performing tests with\ndifferent hyper-parameters, optimizers, convolutional layers, and learning\nrates in order to identify and choose the best models and then put them\ntogether in one classification model. Results: The final data set was\ncompounded by 46 species, including native species, endemic and exotic from\nChile, with 6120 training pictures and 655 testing pictures. The best models\nwere implemented on a mobile app, obtaining a 95% correct prediction rate with\nrespect to the set of tests. Conclusion: The app developed in this study is\ncapable of classifying species with a high level of accuracy, depending on the\nstate of the art of the artificial vision and it can also show relevant\ninformation related to the classified species.",
          "link": "http://arxiv.org/abs/2106.06592",
          "publishedOn": "2021-06-15T01:45:14.465Z",
          "wordCount": 680,
          "title": "Dise\\~no y desarrollo de aplicaci\\'on m\\'ovil para la clasificaci\\'on de flora nativa chilena utilizando redes neuronales convolucionales. (arXiv:2106.06592v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06939",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Min_S/0/1/0/all/0/1\">Shaobo Min</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_Q/0/1/0/all/0/1\">Qi Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_H/0/1/0/all/0/1\">Hongtao Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_C/0/1/0/all/0/1\">Chuang Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongdong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jingdong Wang</a>",
          "description": "Cross-modal correlation provides an inherent supervision for video\nunsupervised representation learning. Existing methods focus on distinguishing\ndifferent video clips by visual and audio representations. We human visual\nperception could attend to regions where sounds are made, and our auditory\nperception could also ground their frequencies of sounding objects, which we\ncall bidirectional local correspondence. Such supervision is intuitive but not\nwell explored in the contrastive learning framework. This paper introduces a\npretext task, Cross-Modal Attention Consistency (CMAC), for exploring the\nbidirectional local correspondence property. The CMAC approach aims to align\nthe regional attention generated purely from the visual signal with the target\nattention generated under the guidance of acoustic signal, and do a similar\nalignment for frequency grounding on the acoustic attention. Accompanied by a\nremoulded cross-modal contrastive loss where we consider additional\nwithin-modal interactions, the CMAC approach works effectively for enforcing\nthe bidirectional alignment. Extensive experiments on six downstream benchmarks\ndemonstrate that CMAC can improve the state-of-the-art performance on both\nvisual and audio modalities.",
          "link": "http://arxiv.org/abs/2106.06939",
          "publishedOn": "2021-06-15T01:45:14.438Z",
          "wordCount": 596,
          "title": "Cross-Modal Attention Consistency for Video-Audio Unsupervised Learning. (arXiv:2106.06939v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06561",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chong_M/0/1/0/all/0/1\">Min Jin Chong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Forsyth_D/0/1/0/all/0/1\">David Forsyth</a>",
          "description": "We show how to learn a map that takes a content code, derived from a face\nimage, and a randomly chosen style code to an anime image. We derive an\nadversarial loss from our simple and effective definitions of style and\ncontent. This adversarial loss guarantees the map is diverse -- a very wide\nrange of anime can be produced from a single content code. Under plausible\nassumptions, the map is not just diverse, but also correctly represents the\nprobability of an anime, conditioned on an input face. In contrast, current\nmultimodal generation procedures cannot capture the complex styles that appear\nin anime. Extensive quantitative experiments support the idea the map is\ncorrect. Extensive qualitative results show that the method can generate a much\nmore diverse range of styles than SOTA comparisons. Finally, we show that our\nformalization of content and style allows us to perform video to video\ntranslation without ever training on videos.",
          "link": "http://arxiv.org/abs/2106.06561",
          "publishedOn": "2021-06-15T01:45:14.431Z",
          "wordCount": 609,
          "title": "GANs N' Roses: Stable, Controllable, Diverse Image to Image Translation (works for videos too!). (arXiv:2106.06561v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06629",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tan_J/0/1/0/all/0/1\">Jiaqi Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1\">Weijie Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_A/0/1/0/all/0/1\">Angel X. Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Savva_M/0/1/0/all/0/1\">Manolis Savva</a>",
          "description": "Despite recent progress in depth sensing and 3D reconstruction, mirror\nsurfaces are a significant source of errors. To address this problem, we create\nthe Mirror3D dataset: a 3D mirror plane dataset based on three RGBD datasets\n(Matterport3D, NYUv2 and ScanNet) containing 7,011 mirror instance masks and 3D\nplanes. We then develop Mirror3DNet: a module that refines raw sensor depth or\nestimated depth to correct errors on mirror surfaces. Our key idea is to\nestimate the 3D mirror plane based on RGB input and surrounding depth context,\nand use this estimate to directly regress mirror surface depth. Our experiments\nshow that Mirror3DNet significantly mitigates errors from a variety of input\ndepth data, including raw sensor depth and depth estimation or completion\nmethods.",
          "link": "http://arxiv.org/abs/2106.06629",
          "publishedOn": "2021-06-15T01:45:14.389Z",
          "wordCount": 564,
          "title": "Mirror3D: Depth Refinement for Mirror Surfaces. (arXiv:2106.06629v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06694",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tsutsui_S/0/1/0/all/0/1\">Satoshi Tsutsui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crandall_D/0/1/0/all/0/1\">David Crandall</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1\">Chen Yu</a>",
          "description": "We analyze egocentric views of attended objects from infants. This paper\nshows 1) empirical evidence that children's egocentric views have more diverse\ndistributions compared to adults' views, 2) we can computationally simulate the\ninfants' distribution, and 3) the distribution is beneficial for training more\ngeneralized image classifiers not only for infant egocentric vision but for\nthird-person computer vision.",
          "link": "http://arxiv.org/abs/2106.06694",
          "publishedOn": "2021-06-15T01:45:14.222Z",
          "wordCount": 509,
          "title": "Reverse-engineer the Distributional Structure of Infant Egocentric Views for Training Generalizable Image Classifiers. (arXiv:2106.06694v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06908",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chenxin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_Q/0/1/0/all/0/1\">Qi Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_X/0/1/0/all/0/1\">Xinghao Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yue Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_D/0/1/0/all/0/1\">Dong Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yizhou Yu</a>",
          "description": "Medical imaging datasets usually exhibit domain shift due to the variations\nof scanner vendors, imaging protocols, etc. This raises the concern about the\ngeneralization capacity of machine learning models. Domain generalization (DG),\nwhich aims to learn a model from multiple source domains such that it can be\ndirectly generalized to unseen test domains, seems particularly promising to\nmedical imaging community. To address DG, recent model-agnostic meta-learning\n(MAML) has been introduced, which transfers the knowledge from previous\ntraining tasks to facilitate the learning of novel testing tasks. However, in\nclinical practice, there are usually only a few annotated source domains\navailable, which decreases the capacity of training task generation and thus\nincreases the risk of overfitting to training tasks in the paradigm. In this\npaper, we propose a novel DG scheme of episodic training with task augmentation\non medical imaging classification. Based on meta-learning, we develop the\nparadigm of episodic training to construct the knowledge transfer from episodic\ntraining-task simulation to the real testing task of DG. Motivated by the\nlimited number of source domains in real-world medical deployment, we consider\nthe unique task-level overfitting and we propose task augmentation to enhance\nthe variety during training task generation to alleviate it. With the\nestablished learning framework, we further exploit a novel meta-objective to\nregularize the deep embedding of training domains. To validate the\neffectiveness of the proposed method, we perform experiments on\nhistopathological images and abdominal CT images.",
          "link": "http://arxiv.org/abs/2106.06908",
          "publishedOn": "2021-06-15T01:45:14.157Z",
          "wordCount": 682,
          "title": "Domain Generalization on Medical Imaging Classification using Episodic Training with Task Augmentation. (arXiv:2106.06908v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06795",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Karim_M/0/1/0/all/0/1\">Mohammed Asad Karim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verma_V/0/1/0/all/0/1\">Vinay Kumar Verma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_P/0/1/0/all/0/1\">Pravendra Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Namboodiri_V/0/1/0/all/0/1\">Vinay Namboodiri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rai_P/0/1/0/all/0/1\">Piyush Rai</a>",
          "description": "We propose a novel approach for class incremental online learning in a\nlimited data setting. This problem setting is challenging because of the\nfollowing constraints: (1) Classes are given incrementally, which necessitates\na class incremental learning approach; (2) Data for each class is given in an\nonline fashion, i.e., each training example is seen only once during training;\n(3) Each class has very few training examples; and (4) We do not use or assume\naccess to any replay/memory to store data from previous classes. Therefore, in\nthis setting, we have to handle twofold problems of catastrophic forgetting and\noverfitting. In our approach, we learn robust representations that are\ngeneralizable across tasks without suffering from the problems of catastrophic\nforgetting and overfitting to accommodate future classes with limited samples.\nOur proposed method leverages the meta-learning framework with knowledge\nconsolidation. The meta-learning framework helps the model for rapid learning\nwhen samples appear in an online fashion. Simultaneously, knowledge\nconsolidation helps to learn a robust representation against forgetting under\nonline updates to facilitate future learning. Our approach significantly\noutperforms other methods on several benchmarks.",
          "link": "http://arxiv.org/abs/2106.06795",
          "publishedOn": "2021-06-15T01:45:14.118Z",
          "wordCount": 631,
          "title": "Knowledge Consolidation based Class Incremental Online Learning with Limited Data. (arXiv:2106.06795v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2010.05690",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+B_L/0/1/0/all/0/1\">Lalith Bharadwaj B</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boddeda_R/0/1/0/all/0/1\">Rohit Boddeda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+K_S/0/1/0/all/0/1\">Sai Vardhan K</a>, <a href=\"http://arxiv.org/find/cs/1/au:+G_M/0/1/0/all/0/1\">Madhu G</a>",
          "description": "The issue of COVID-19, increasing with a massive mortality rate. This led to\nthe WHO declaring it as a pandemic. In this situation, it is crucial to perform\nefficient and fast diagnosis. The reverse transcript polymerase chain reaction\n(RTPCR) test is conducted to detect the presence of SARS-CoV-2. This test is\ntime-consuming and instead chest CT (or Chest X-ray) can be used for a fast and\naccurate diagnosis. Automated diagnosis is considered to be important as it\nreduces human effort and provides accurate and low-cost tests. The\ncontributions of our research are three-fold. First, it is aimed to analyse the\nbehaviour and performance of variant vision models ranging from Inception to\nNAS networks with the appropriate fine-tuning procedure. Second, the behaviour\nof these models is visually analysed by plotting CAMs for individual networks\nand determining classification performance with AUCROC curves. Thirdly, stacked\nensembles techniques are imparted to provide higher generalisation on combining\nthe fine-tuned models, in which six ensemble neural networks are designed by\ncombining the existing fine-tuned networks. Implying these stacked ensembles\nprovides a great generalization to the models. The ensemble model designed by\ncombining all the fine-tuned networks obtained a state-of-the-art accuracy\nscore of 99.17%. The precision and recall for the COVID-19 class are 99.99% and\n89.79% respectively, which resembles the robustness of the stacked ensembles.",
          "link": "http://arxiv.org/abs/2010.05690",
          "publishedOn": "2021-06-14T01:38:53.136Z",
          "wordCount": 741,
          "title": "COVID-19 Classification Using Staked Ensembles: A Comprehensive Analysis. (arXiv:2010.05690v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1904.03116",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Souri_Y/0/1/0/all/0/1\">Yaser Souri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fayyaz_M/0/1/0/all/0/1\">Mohsen Fayyaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Minciullo_L/0/1/0/all/0/1\">Luca Minciullo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Francesca_G/0/1/0/all/0/1\">Gianpiero Francesca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gall_J/0/1/0/all/0/1\">Juergen Gall</a>",
          "description": "Action segmentation is the task of predicting the actions for each frame of a\nvideo. As obtaining the full annotation of videos for action segmentation is\nexpensive, weakly supervised approaches that can learn only from transcripts\nare appealing. In this paper, we propose a novel end-to-end approach for weakly\nsupervised action segmentation based on a two-branch neural network. The two\nbranches of our network predict two redundant but different representations for\naction segmentation and we propose a novel mutual consistency (MuCon) loss that\nenforces the consistency of the two redundant representations. Using the MuCon\nloss together with a loss for transcript prediction, our proposed approach\nachieves the accuracy of state-of-the-art approaches while being $14$ times\nfaster to train and $20$ times faster during inference. The MuCon loss proves\nbeneficial even in the fully supervised setting.",
          "link": "http://arxiv.org/abs/1904.03116",
          "publishedOn": "2021-06-14T01:38:53.101Z",
          "wordCount": 638,
          "title": "Fast Weakly Supervised Action Segmentation Using Mutual Consistency. (arXiv:1904.03116v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06485",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Weichen Chen</a> (1) <a href=\"http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1\">Xinyi Yu</a> (1) <a href=\"http://arxiv.org/find/cs/1/au:+Ou_L/0/1/0/all/0/1\">Linlin Ou</a> (1) ((1) Collage of Information Engineering, Zhejiang University of Technology, Hangzhou, China)",
          "description": "Pedestrian attribute recognition in surveillance scenarios is still a\nchallenging task due to inaccurate localization of specific attributes. In this\npaper, we propose a novel view-attribute localization method based on attention\n(VALA), which relies on the strong relevance between attributes and views to\ncapture specific view-attributes and to localize attribute-corresponding areas\nby attention mechanism. A specific view-attribute is composed by the extracted\nattribute feature and four view scores which are predicted by view predictor as\nthe confidences for attribute from different views. View-attribute is then\ndelivered back to shallow network layers for supervising deep feature\nextraction. To explore the location of a view-attribute, regional attention is\nintroduced to aggregate spatial information of the input attribute feature in\nheight and width direction for constraining the image into a narrow range.\nMoreover, the inter-channel dependency of view-feature is embedded in the above\ntwo spatial directions. An attention attribute-specific region is gained after\nfining the narrow range by balancing the ratio of channel dependencies between\nheight and width branches. The final view-attribute recognition outcome is\nobtained by combining the output of regional attention with the view scores\nfrom view predictor. Experiments on three wide datasets (RAP, RAPv2, PETA, and\nPA-100K) demonstrate the effectiveness of our approach compared with\nstate-of-the-art methods.",
          "link": "http://arxiv.org/abs/2106.06485",
          "publishedOn": "2021-06-14T01:38:53.070Z",
          "wordCount": 654,
          "title": "Pedestrian Attribute Recognition in Video Surveillance Scenarios Based on View-attribute Attention Localization. (arXiv:2106.06485v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2102.04906",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1\">Yizeng Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1\">Gao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1\">Shiji Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Le Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Honghui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yulin Wang</a>",
          "description": "Dynamic neural network is an emerging research topic in deep learning.\nCompared to static models which have fixed computational graphs and parameters\nat the inference stage, dynamic networks can adapt their structures or\nparameters to different inputs, leading to notable advantages in terms of\naccuracy, computational efficiency, adaptiveness, etc. In this survey, we\ncomprehensively review this rapidly developing area by dividing dynamic\nnetworks into three main categories: 1) instance-wise dynamic models that\nprocess each instance with data-dependent architectures or parameters; 2)\nspatial-wise dynamic networks that conduct adaptive computation with respect to\ndifferent spatial locations of image data and 3) temporal-wise dynamic models\nthat perform adaptive inference along the temporal dimension for sequential\ndata such as videos and texts. The important research problems of dynamic\nnetworks, e.g., architecture design, decision making scheme, optimization\ntechnique and applications, are reviewed systematically. Finally, we discuss\nthe open problems in this field together with interesting future research\ndirections.",
          "link": "http://arxiv.org/abs/2102.04906",
          "publishedOn": "2021-06-14T01:38:53.062Z",
          "wordCount": 618,
          "title": "Dynamic Neural Networks: A Survey. (arXiv:2102.04906v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06321",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bana_T/0/1/0/all/0/1\">Tejas Bana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Loya_J/0/1/0/all/0/1\">Jatan Loya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulkarni_S/0/1/0/all/0/1\">Siddhant Kulkarni</a>",
          "description": "Studies involving colourising images has been garnering researchers' keen\nattention over time, assisted by significant advances in various Machine\nLearning techniques and compute power availability. Traditionally, colourising\nimages have been an intricate task that gave a substantial degree of freedom\nduring the assignment of chromatic information. In our proposed method, we\nattempt to colourise images using Vision Transformer - Inception - Generative\nAdversarial Network (ViT-I-GAN), which has an Inception-v3 fusion embedding in\nthe generator. For a stable and robust network, we have used Vision Transformer\n(ViT) as the discriminator. We trained the model on the Unsplash and the COCO\ndataset for demonstrating the improvement made by the Inception-v3 embedding.\nWe have compared the results between ViT-GANs with and without Inception-v3\nembedding.",
          "link": "http://arxiv.org/abs/2106.06321",
          "publishedOn": "2021-06-14T01:38:53.052Z",
          "wordCount": 547,
          "title": "ViT-Inception-GAN for Image Colourising. (arXiv:2106.06321v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2010.15560",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Wei_J/0/1/0/all/0/1\">Jiahong Wei</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fan_Z/0/1/0/all/0/1\">Zhun Fan</a>",
          "description": "Recently, many methods based on hand-designed convolutional neural networks\n(CNNs) have achieved promising results in automatic retinal vessel\nsegmentation. However, these CNNs remain constrained in capturing retinal\nvessels in complex fundus images. To improve their segmentation performance,\nthese CNNs tend to have many parameters, which may lead to overfitting and high\ncomputational complexity. Moreover, the manual design of competitive CNNs is\ntime-consuming and requires extensive empirical knowledge. Herein, a novel\nautomated design method, called Genetic U-Net, is proposed to generate a\nU-shaped CNN that can achieve better retinal vessel segmentation but with fewer\narchitecture-based parameters, thereby addressing the above issues. First, we\ndevised a condensed but flexible search space based on a U-shaped\nencoder-decoder. Then, we used an improved genetic algorithm to identify\nbetter-performing architectures in the search space and investigated the\npossibility of finding a superior network architecture with fewer parameters.\nThe experimental results show that the architecture obtained using the proposed\nmethod offered a superior performance with less than 1% of the number of the\noriginal U-Net parameters in particular and with significantly fewer parameters\nthan other state-of-the-art models. Furthermore, through in-depth investigation\nof the experimental results, several effective operations and patterns of\nnetworks to generate superior retinal vessel segmentations were identified.",
          "link": "http://arxiv.org/abs/2010.15560",
          "publishedOn": "2021-06-14T01:38:53.045Z",
          "wordCount": 686,
          "title": "Genetic U-Net: Automatically Designed Deep Networks for Retinal Vessel Segmentation Using a Genetic Algorithm. (arXiv:2010.15560v4 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02078",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sridhar_K/0/1/0/all/0/1\">Kaustubh Sridhar</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sokolsky_O/0/1/0/all/0/1\">Oleg Sokolsky</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lee_I/0/1/0/all/0/1\">Insup Lee</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Weimer_J/0/1/0/all/0/1\">James Weimer</a>",
          "description": "Improving adversarial robustness of neural networks remains a major\nchallenge. Fundamentally, training a network is a parameter estimation problem.\nIn adaptive control theory, maintaining persistency of excitation (PoE) is\nintegral to ensuring convergence of parameter estimates in dynamical systems to\ntheir robust optima. In this work, we show that network training using gradient\ndescent is equivalent to a dynamical system parameter estimation problem.\nLeveraging this relationship, we prove a sufficient condition for PoE of\ngradient descent is achieved when the learning rate is less than the inverse of\nthe Lipschitz constant of the gradient of loss function. We provide an\nefficient technique for estimating the corresponding Lipschitz constant using\nextreme value theory and demonstrate that by only scaling the learning rate\nschedule we can increase adversarial accuracy by up to 15% points on benchmark\ndatasets. Our approach also universally increases the adversarial accuracy by\n0.1% to 0.3% points in various state-of-the-art adversarially trained models on\nthe AutoAttack benchmark, where every small margin of improvement is\nsignificant.",
          "link": "http://arxiv.org/abs/2106.02078",
          "publishedOn": "2021-06-14T01:38:53.036Z",
          "wordCount": 630,
          "title": "Robust Learning via Persistency of Excitation. (arXiv:2106.02078v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06133",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1\">Yixiao Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1\">Yu Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hongsheng Li</a>",
          "description": "Unsupervised object re-identification targets at learning discriminative\nrepresentations for object retrieval without any annotations. Clustering-based\nmethods conduct training with the generated pseudo labels and currently\ndominate this research direction. However, they still suffer from the issue of\npseudo label noise. To tackle the challenge, we propose to properly estimate\npseudo label similarities between consecutive training generations with\nclustering consensus and refine pseudo labels with temporally propagated and\nensembled pseudo labels. To the best of our knowledge, this is the first\nattempt to leverage the spirit of temporal ensembling to improve classification\nwith dynamically changing classes over generations. The proposed pseudo label\nrefinery strategy is simple yet effective and can be seamlessly integrated into\nexisting clustering-based unsupervised re-identification methods. With our\nproposed approach, state-of-the-art method can be further boosted with up to\n8.8% mAP improvements on the challenging MSMT17 dataset.",
          "link": "http://arxiv.org/abs/2106.06133",
          "publishedOn": "2021-06-14T01:38:53.018Z",
          "wordCount": 581,
          "title": "Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification. (arXiv:2106.06133v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2006.04988",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Voynov_A/0/1/0/all/0/1\">Andrey Voynov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morozov_S/0/1/0/all/0/1\">Stanislav Morozov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Babenko_A/0/1/0/all/0/1\">Artem Babenko</a>",
          "description": "The recent rise of unsupervised and self-supervised learning has dramatically\nreduced the dependency on labeled data, providing effective image\nrepresentations for transfer to downstream vision tasks. Furthermore, recent\nworks employed these representations in a fully unsupervised setup for image\nclassification, reducing the need for human labels on the fine-tuning stage as\nwell. This work demonstrates that large-scale unsupervised models can also\nperform a more challenging object segmentation task, requiring neither\npixel-level nor image-level labeling. Namely, we show that recent unsupervised\nGANs allow to differentiate between foreground/background pixels, providing\nhigh-quality saliency masks. By extensive comparison on standard benchmarks, we\noutperform existing unsupervised alternatives for object segmentation,\nachieving new state-of-the-art.",
          "link": "http://arxiv.org/abs/2006.04988",
          "publishedOn": "2021-06-14T01:38:53.010Z",
          "wordCount": 568,
          "title": "Object Segmentation Without Labels with Large-Scale Generative Models. (arXiv:2006.04988v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2002.11318",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kamath_S/0/1/0/all/0/1\">Sandesh Kamath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deshpande_A/0/1/0/all/0/1\">Amit Deshpande</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Subrahmanyam_K/0/1/0/all/0/1\">K V Subrahmanyam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balasubramanian_V/0/1/0/all/0/1\">Vineeth N Balasubramanian</a>",
          "description": "(Non-)robustness of neural networks to small, adversarial pixel-wise\nperturbations, and as more recently shown, to even random spatial\ntransformations (e.g., translations, rotations) entreats both theoretical and\nempirical understanding. Spatial robustness to random translations and\nrotations is commonly attained via equivariant models (e.g., StdCNNs, GCNNs)\nand training augmentation, whereas adversarial robustness is typically achieved\nby adversarial training. In this paper, we prove a quantitative trade-off\nbetween spatial and adversarial robustness in a simple statistical setting. We\ncomplement this empirically by showing that: (a) as the spatial robustness of\nequivariant models improves by training augmentation with progressively larger\ntransformations, their adversarial robustness worsens progressively, and (b) as\nthe state-of-the-art robust models are adversarially trained with progressively\nlarger pixel-wise perturbations, their spatial robustness drops progressively.\nTowards achieving pareto-optimality in this trade-off, we propose a method\nbased on curriculum learning that trains gradually on more difficult\nperturbations (both spatial and adversarial) to improve spatial and adversarial\nrobustness simultaneously.",
          "link": "http://arxiv.org/abs/2002.11318",
          "publishedOn": "2021-06-14T01:38:53.003Z",
          "wordCount": 689,
          "title": "Can we have it all? On the Trade-off between Spatial and Adversarial Robustness of Neural Networks. (arXiv:2002.11318v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06442",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Su_X/0/1/0/all/0/1\">Xiu Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_S/0/1/0/all/0/1\">Shan You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_M/0/1/0/all/0/1\">Mingkai Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Fei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_C/0/1/0/all/0/1\">Chen Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Changshui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chang Xu</a>",
          "description": "In one-shot weight sharing for NAS, the weights of each operation (at each\nlayer) are supposed to be identical for all architectures (paths) in the\nsupernet. However, this rules out the possibility of adjusting operation\nweights to cater for different paths, which limits the reliability of the\nevaluation results. In this paper, instead of counting on a single supernet, we\nintroduce $K$-shot supernets and take their weights for each operation as a\ndictionary. The operation weight for each path is represented as a convex\ncombination of items in a dictionary with a simplex code. This enables a matrix\napproximation of the stand-alone weight matrix with a higher rank ($K>1$). A\n\\textit{simplex-net} is introduced to produce architecture-customized code for\neach path. As a result, all paths can adaptively learn how to share weights in\nthe $K$-shot supernets and acquire corresponding weights for better evaluation.\n$K$-shot supernets and simplex-net can be iteratively trained, and we further\nextend the search to the channel dimension. Extensive experiments on benchmark\ndatasets validate that K-shot NAS significantly improves the evaluation\naccuracy of paths and thus brings in impressive performance improvements.",
          "link": "http://arxiv.org/abs/2106.06442",
          "publishedOn": "2021-06-14T01:38:52.995Z",
          "wordCount": 631,
          "title": "K-shot NAS: Learnable Weight-Sharing for NAS with K-shot Supernets. (arXiv:2106.06442v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03640",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Masters_D/0/1/0/all/0/1\">Dominic Masters</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Labatie_A/0/1/0/all/0/1\">Antoine Labatie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eaton_Rosen_Z/0/1/0/all/0/1\">Zach Eaton-Rosen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luschi_C/0/1/0/all/0/1\">Carlo Luschi</a>",
          "description": "Much recent research has been dedicated to improving the efficiency of\ntraining and inference for image classification. This effort has commonly\nfocused on explicitly improving theoretical efficiency, often measured as\nImageNet validation accuracy per FLOP. These theoretical savings have, however,\nproven challenging to achieve in practice, particularly on high-performance\ntraining accelerators.\n\nIn this work, we focus on improving the practical efficiency of the\nstate-of-the-art EfficientNet models on a new class of accelerator, the\nGraphcore IPU. We do this by extending this family of models in the following\nways: (i) generalising depthwise convolutions to group convolutions; (ii)\nadding proxy-normalized activations to match batch normalization performance\nwith batch-independent statistics; (iii) reducing compute by lowering the\ntraining resolution and inexpensively fine-tuning at higher resolution. We find\nthat these three methods improve the practical efficiency for both training and\ninference. Our code will be made available online.",
          "link": "http://arxiv.org/abs/2106.03640",
          "publishedOn": "2021-06-14T01:38:52.986Z",
          "wordCount": 605,
          "title": "Making EfficientNet More Efficient: Exploring Batch-Independent Normalization, Group Convolutions and Reduced Resolution Training. (arXiv:2106.03640v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06181",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Anisimov_Y/0/1/0/all/0/1\">Yuriy Anisimov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reis_G/0/1/0/all/0/1\">Gerd Reis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stricker_D/0/1/0/all/0/1\">Didier Stricker</a>",
          "description": "The ability to create an accurate three-dimensional reconstruction of a\ncaptured scene draws attention to the principles of light fields. This paper\npresents an approach for light field camera calibration and rectification,\nbased on pairwise pattern-based parameters extraction. It is followed by a\ncorrespondence-based algorithm for camera parameters refinement from arbitrary\nscenes using the triangulation filter and nonlinear optimization. The\neffectiveness of our approach is validated on both real and synthetic data.",
          "link": "http://arxiv.org/abs/2106.06181",
          "publishedOn": "2021-06-14T01:38:52.979Z",
          "wordCount": 513,
          "title": "Calibration and Auto-Refinement for Light Field Cameras. (arXiv:2106.06181v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2009.00100",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Young-min Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_Y/0/1/0/all/0/1\">Young-chul Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_K/0/1/0/all/0/1\">Kwangjin Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeon_M/0/1/0/all/0/1\">Moongu Jeon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Seong-Whan Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pedrycz_W/0/1/0/all/0/1\">Witold Pedrycz</a>",
          "description": "In this paper, we propose a highly practical fully online multi-object\ntracking and segmentation (MOTS) method that uses instance segmentation results\nas an input. The proposed method is based on the Gaussian mixture probability\nhypothesis density (GMPHD) filter, a hierarchical data association (HDA), and a\nmask-based affinity fusion (MAF) model to achieve high-performance online\ntracking. The HDA consists of two associations: segment-to-track and\ntrack-to-track associations. One affinity, for position and motion, is computed\nby using the GMPHD filter, and the other affinity, for appearance is computed\nby using the responses from a single object tracker such as a kernalized\ncorrelation filter. These two affinities are simply fused by using a\nscore-level fusion method such as min-max normalization referred to as MAF. In\naddition, to reduce the number of false positive segments, we adopt mask\nIoU-based merging (mask merging). The proposed MOTS framework with the key\nmodules: HDA, MAF, and mask merging, is easily extensible to simultaneously\ntrack multiple types of objects with CPU only execution in parallel processing.\nIn addition, the developed framework only requires simple parameter tuning\nunlike many existing MOTS methods that need intensive hyperparameter\noptimization. In the experiments on the two popular MOTS datasets, the key\nmodules show some improvements. For instance, ID-switch decreases by more than\nhalf compared to a baseline method in the training sets. In conclusion, our\ntracker achieves state-of-the-art MOTS performance in the test sets.",
          "link": "http://arxiv.org/abs/2009.00100",
          "publishedOn": "2021-06-14T01:38:52.960Z",
          "wordCount": 708,
          "title": "Online Multi-Object Tracking and Segmentation with GMPHD Filter and Mask-based Affinity Fusion. (arXiv:2009.00100v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06250",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Mingxiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_Z/0/1/0/all/0/1\">Zhanguo Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1\">Haonan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1\">Bitao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhuang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_L/0/1/0/all/0/1\">Liufang Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhecheng Wang</a>",
          "description": "Most of the achievements in artificial intelligence so far were accomplished\nby supervised learning which requires numerous annotated training data and thus\ncosts innumerable manpower for labeling. Unsupervised learning is one of the\neffective solutions to overcome such difficulties. In our work, we propose\nAugNet, a new deep learning training paradigm to learn image features from a\ncollection of unlabeled pictures. We develop a method to construct the\nsimilarities between pictures as distance metrics in the embedding space by\nleveraging the inter-correlation between augmented versions of samples. Our\nexperiments demonstrate that the method is able to represent the image in low\ndimensional space and performs competitively in downstream tasks such as image\nclassification and image similarity comparison. Specifically, we achieved over\n60% and 27% accuracy on the STL10 and CIFAR100 datasets with unsupervised\nclustering, respectively. Moreover, unlike many deep-learning-based image\nretrieval algorithms, our approach does not require access to external\nannotated datasets to train the feature extractor, but still shows comparable\nor even better feature representation ability and easy-to-use characteristics.\nIn our evaluations, the method outperforms all the state-of-the-art image\nretrieval algorithms on some out-of-domain image datasets. The code for the\nmodel implementation is available at\nhttps://github.com/chenmingxiang110/AugNet.",
          "link": "http://arxiv.org/abs/2106.06250",
          "publishedOn": "2021-06-14T01:38:52.951Z",
          "wordCount": 637,
          "title": "AugNet: End-to-End Unsupervised Visual Representation Learning with Image Augmentation. (arXiv:2106.06250v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06439",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singh_D/0/1/0/all/0/1\">Divakar Singh</a>",
          "description": "The unprecedented growth in the easy availability of photo-editing tools has\nendangered the power of digital images.An image was supposed to be worth more\nthan a thousand words,but now this can be said only if it can be authenticated\northe integrity of the image can be proved to be intact. In thispaper, we\npropose a digital image forensic technique for JPEG images. It can detect any\nforgery in the image if the forged portion called a ghost image is having a\ncompression quality different from that of the cover image. It is based on\nresaving the JPEG image at different JPEG qualities, and the detection of the\nforged portion is maximum when it is saved at the same JPEG quality as the\ncover image. Also, we can precisely predictthe JPEG quality of the cover image\nby analyzing the similarity using Structural Similarity Index Measure (SSIM) or\nthe energyof the images. The first maxima in SSIM or the first minima inenergy\ncorrespond to the cover image JPEG quality. We created adataset for varying\nJPEG compression qualities of the ghost and the cover images and validated the\nscalability of the experimental results.We also, experimented with varied\nattack scenarios, e.g. high-quality ghost image embedded in low quality of\ncover image,low-quality ghost image embedded in high-quality of cover image,and\nghost image and cover image both at the same quality.The proposed method is\nable to localize the tampered portions accurately even for forgeries as small\nas 10x10 sized pixel blocks.Our technique is also robust against other attack\nscenarios like copy-move forgery, inserting text into image, rescaling\n(zoom-out/zoom-in) ghost image and then pasting on cover image.",
          "link": "http://arxiv.org/abs/2106.06439",
          "publishedOn": "2021-06-14T01:38:52.944Z",
          "wordCount": 709,
          "title": "An Image Forensic Technique Based on JPEG Ghosts. (arXiv:2106.06439v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06489",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liong_G/0/1/0/all/0/1\">Gen-Bing Liong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+See_J/0/1/0/all/0/1\">John See</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_L/0/1/0/all/0/1\">Lai-Kuan Wong</a>",
          "description": "Facial expressions vary from the visible to the subtle. In recent years, the\nanalysis of micro-expressions $-$ a natural occurrence resulting from the\nsuppression of one's true emotions, has drawn the attention of researchers with\na broad range of potential applications. However, spotting microexpressions in\nlong videos becomes increasingly challenging when intertwined with normal or\nmacro-expressions. In this paper, we propose a shallow optical flow\nthree-stream CNN (SOFTNet) model to predict a score that captures the\nlikelihood of a frame being in an expression interval. By fashioning the\nspotting task as a regression problem, we introduce pseudo-labeling to\nfacilitate the learning process. We demonstrate the efficacy and efficiency of\nthe proposed approach on the recent MEGC 2020 benchmark, where state-of-the-art\nperformance is achieved on CAS(ME)$^{2}$ with equally promising results on SAMM\nLong Videos.",
          "link": "http://arxiv.org/abs/2106.06489",
          "publishedOn": "2021-06-14T01:38:52.930Z",
          "wordCount": 591,
          "title": "Shallow Optical Flow Three-Stream CNN for Macro- and Micro-Expression Spotting from Long Videos. (arXiv:2106.06489v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06129",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vasu_P/0/1/0/all/0/1\">Pavan Kumar Anasosalu Vasu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saxena_S/0/1/0/all/0/1\">Shreyas Saxena</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuzel_O/0/1/0/all/0/1\">Oncel Tuzel</a>",
          "description": "Recent works have shown that deep neural networks benefit from multi-task\nlearning by learning a shared representation across several related tasks.\nHowever, performance of such systems depend on relative weighting between\nvarious losses involved during training. Prior works on loss weighting schemes\nassume that instances are equally easy or hard for all tasks. In order to break\nthis assumption, we let the training process dictate the optimal weighting of\ntasks for every instance in the dataset. More specifically, we equip every\ninstance in the dataset with a set of learnable parameters (instance-level task\nparameters) where the cardinality is equal to the number of tasks learned by\nthe model. These parameters model the weighting of each task for an instance.\nThey are updated by gradient descent and do not require hand-crafted rules. We\nconduct extensive experiments on SURREAL and CityScapes datasets, for human\nshape and pose estimation, depth estimation and semantic segmentation tasks. In\nthese tasks, our approach outperforms recent dynamic loss weighting approaches,\ne.g. reducing surface estimation errors by 8.97% on SURREAL. When applied to\ndatasets where one or more tasks can have noisy annotations, the proposed\nmethod learns to prioritize learning from clean labels for a given task, e.g.\nreducing surface estimation errors by up to 60%. We also show that we can\nreliably detect corrupt labels for a given task as a by-product from learned\ninstance-level task parameters.",
          "link": "http://arxiv.org/abs/2106.06129",
          "publishedOn": "2021-06-14T01:38:52.911Z",
          "wordCount": 665,
          "title": "Instance-Level Task Parameters: A Robust Multi-task Weighting Framework. (arXiv:2106.06129v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2102.09808",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Iuzzolino_M/0/1/0/all/0/1\">Michael L. Iuzzolino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mozer_M/0/1/0/all/0/1\">Michael C. Mozer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_S/0/1/0/all/0/1\">Samy Bengio</a>",
          "description": "Although deep feedforward neural networks share some characteristics with the\nprimate visual system, a key distinction is their dynamics. Deep nets typically\noperate in serial stages wherein each layer completes its computation before\nprocessing begins in subsequent layers. In contrast, biological systems have\ncascaded dynamics: information propagates from neurons at all layers in\nparallel but transmission occurs gradually over time, leading to speed-accuracy\ntrade offs even in feedforward architectures. We explore the consequences of\nbiologically inspired parallel hardware by constructing cascaded ResNets in\nwhich each residual block has propagation delays but all blocks update in\nparallel in a stateful manner. Because information transmitted through skip\nconnections avoids delays, the functional depth of the architecture increases\nover time, yielding anytime predictions that improve with internal-processing\ntime. We introduce a temporal-difference training loss that achieves a strictly\nsuperior speed-accuracy profile over standard losses and enables the cascaded\narchitecture to outperform state-of-the-art anytime-prediction methods. The\ncascaded architecture has intriguing properties, including: it classifies\ntypical instances more rapidly than atypical instances; it is more robust to\nboth persistent and transient noise than is a conventional ResNet; and its\ntime-varying output trace provides a signal that can be exploited to improve\ninformation processing and inference.",
          "link": "http://arxiv.org/abs/2102.09808",
          "publishedOn": "2021-06-14T01:38:52.905Z",
          "wordCount": 676,
          "title": "Improving Anytime Prediction with Parallel Cascaded Networks and a Temporal-Difference Loss. (arXiv:2102.09808v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06440",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Michalkiewicz_M/0/1/0/all/0/1\">Mateusz Michalkiewicz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsogkas_S/0/1/0/all/0/1\">Stavros Tsogkas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parisot_S/0/1/0/all/0/1\">Sarah Parisot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baktashmotlagh_M/0/1/0/all/0/1\">Mahsa Baktashmotlagh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eriksson_A/0/1/0/all/0/1\">Anders Eriksson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belilovsky_E/0/1/0/all/0/1\">Eugene Belilovsky</a>",
          "description": "The impressive performance of deep convolutional neural networks in\nsingle-view 3D reconstruction suggests that these models perform non-trivial\nreasoning about the 3D structure of the output space. Recent work has\nchallenged this belief, showing that, on standard benchmarks, complex\nencoder-decoder architectures perform similarly to nearest-neighbor baselines\nor simple linear decoder models that exploit large amounts of per-category\ndata. However, building large collections of 3D shapes for supervised training\nis a laborious process; a more realistic and less constraining task is\ninferring 3D shapes for categories with few available training examples,\ncalling for a model that can successfully generalize to novel object classes.\nIn this work we experimentally demonstrate that naive baselines fail in this\nfew-shot learning setting, in which the network must learn informative shape\npriors for inference of new categories. We propose three ways to learn a\nclass-specific global shape prior, directly from data. Using these techniques,\nwe are able to capture multi-scale information about the 3D shape, and account\nfor intra-class variability by virtue of an implicit compositional structure.\nExperiments on the popular ShapeNet dataset show that our method outperforms a\nzero-shot baseline by over 40%, and the current state-of-the-art by over 10%,\nin terms of relative performance, in the few-shot setting.12",
          "link": "http://arxiv.org/abs/2106.06440",
          "publishedOn": "2021-06-14T01:38:52.898Z",
          "wordCount": 655,
          "title": "Learning Compositional Shape Priors for Few-Shot 3D Reconstruction. (arXiv:2106.06440v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06471",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xingyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_M/0/1/0/all/0/1\">Muchao Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_Q/0/1/0/all/0/1\">Quanzeng You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_F/0/1/0/all/0/1\">Fenglong Ma</a>",
          "description": "Medical report generation is one of the most challenging tasks in medical\nimage analysis. Although existing approaches have achieved promising results,\nthey either require a predefined template database in order to retrieve\nsentences or ignore the hierarchical nature of medical report generation. To\naddress these issues, we propose MedWriter that incorporates a novel\nhierarchical retrieval mechanism to automatically extract both report and\nsentence-level templates for clinically accurate report generation. MedWriter\nfirst employs the Visual-Language Retrieval~(VLR) module to retrieve the most\nrelevant reports for the given images. To guarantee the logical coherence\nbetween sentences, the Language-Language Retrieval~(LLR) module is introduced\nto retrieve relevant sentences based on the previous generated description. At\nlast, a language decoder fuses image features and features from retrieved\nreports and sentences to generate meaningful medical reports. We verified the\neffectiveness of our model by automatic evaluation and human evaluation on two\ndatasets, i.e., Open-I and MIMIC-CXR.",
          "link": "http://arxiv.org/abs/2106.06471",
          "publishedOn": "2021-06-14T01:38:52.891Z",
          "wordCount": 592,
          "title": "Writing by Memorizing: Hierarchical Retrieval-based Medical Report Generation. (arXiv:2106.06471v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2103.06304",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Parcalabescu_L/0/1/0/all/0/1\">Letitia Parcalabescu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trost_N/0/1/0/all/0/1\">Nils Trost</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frank_A/0/1/0/all/0/1\">Anette Frank</a>",
          "description": "The last years have shown rapid developments in the field of multimodal\nmachine learning, combining e.g., vision, text or speech. In this position\npaper we explain how the field uses outdated definitions of multimodality that\nprove unfit for the machine learning era. We propose a new task-relative\ndefinition of (multi)modality in the context of multimodal machine learning\nthat focuses on representations and information that are relevant for a given\nmachine learning task. With our new definition of multimodality we aim to\nprovide a missing foundation for multimodal research, an important component of\nlanguage grounding and a crucial milestone towards NLU.",
          "link": "http://arxiv.org/abs/2103.06304",
          "publishedOn": "2021-06-14T01:38:52.885Z",
          "wordCount": 582,
          "title": "What is Multimodality?. (arXiv:2103.06304v3 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.05918",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jia_C/0/1/0/all/0/1\">Chao Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yinfei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1\">Ye Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yi-Ting Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parekh_Z/0/1/0/all/0/1\">Zarana Parekh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pham_H/0/1/0/all/0/1\">Hieu Pham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1\">Quoc V. Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sung_Y/0/1/0/all/0/1\">Yunhsuan Sung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duerig_T/0/1/0/all/0/1\">Tom Duerig</a>",
          "description": "Pre-trained representations are becoming crucial for many NLP and perception\ntasks. While representation learning in NLP has transitioned to training on raw\ntext without human annotations, visual and vision-language representations\nstill rely heavily on curated training datasets that are expensive or require\nexpert knowledge. For vision applications, representations are mostly learned\nusing datasets with explicit class labels such as ImageNet or OpenImages. For\nvision-language, popular datasets like Conceptual Captions, MSCOCO, or CLIP all\ninvolve a non-trivial data collection (and cleaning) process. This costly\ncuration process limits the size of datasets and hence hinders the scaling of\ntrained models. In this paper, we leverage a noisy dataset of over one billion\nimage alt-text pairs, obtained without expensive filtering or post-processing\nsteps in the Conceptual Captions dataset. A simple dual-encoder architecture\nlearns to align visual and language representations of the image and text pairs\nusing a contrastive loss. We show that the scale of our corpus can make up for\nits noise and leads to state-of-the-art representations even with such a simple\nlearning scheme. Our visual representation achieves strong performance when\ntransferred to classification tasks such as ImageNet and VTAB. The aligned\nvisual and language representations enables zero-shot image classification and\nalso set new state-of-the-art results on Flickr30K and MSCOCO image-text\nretrieval benchmarks, even when compared with more sophisticated\ncross-attention models. The representations also enable cross-modality search\nwith complex text and text + image queries.",
          "link": "http://arxiv.org/abs/2102.05918",
          "publishedOn": "2021-06-14T01:38:52.868Z",
          "wordCount": 733,
          "title": "Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision. (arXiv:2102.05918v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06420",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Al_Kaabi_K/0/1/0/all/0/1\">Karrar Al-Kaabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monsefi_R/0/1/0/all/0/1\">Reza Monsefi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zabihzadeh_D/0/1/0/all/0/1\">Davood Zabihzadeh</a>",
          "description": "Metric learning algorithms aim to learn a distance function that brings the\nsemantically similar data items together and keeps dissimilar ones at a\ndistance. The traditional Mahalanobis distance learning is equivalent to find a\nlinear projection. In contrast, Deep Metric Learning (DML) methods are proposed\nthat automatically extract features from data and learn a non-linear\ntransformation from input space to a semantically embedding space. Recently,\nmany DML methods are proposed focused to enhance the discrimination power of\nthe learned metric by providing novel sampling strategies or loss functions.\nThis approach is very helpful when both the training and test examples are\ncoming from the same set of categories. However, it is less effective in many\napplications of DML such as image retrieval and person-reidentification. Here,\nthe DML should learn general semantic concepts from observed classes and employ\nthem to rank or identify objects from unseen categories. Neglecting the\ngeneralization ability of the learned representation and just emphasizing to\nlearn a more discriminative embedding on the observed classes may lead to the\noverfitting problem. To address this limitation, we propose a framework to\nenhance the generalization power of existing DML methods in a Zero-Shot\nLearning (ZSL) setting by general yet discriminative representation learning\nand employing a class adversarial neural network. To learn a more general\nrepresentation, we propose to employ feature maps of intermediate layers in a\ndeep neural network and enhance their discrimination power through an attention\nmechanism. Besides, a class adversarial network is utilized to enforce the deep\nmodel to seek class invariant features for the DML task. We evaluate our work\non widely used machine vision datasets in a ZSL setting.",
          "link": "http://arxiv.org/abs/2106.06420",
          "publishedOn": "2021-06-14T01:38:52.861Z",
          "wordCount": 744,
          "title": "A Framework to Enhance Generalization of Deep Metric Learning methods using General Discriminative Feature Learning and Class Adversarial Neural Networks. (arXiv:2106.06420v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06047",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qu_L/0/1/0/all/0/1\">Liangqiong Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yuyin Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1\">Paul Pu Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1\">Yingda Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Feifei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1\">Li Fei-Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adeli_E/0/1/0/all/0/1\">Ehsan Adeli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubin_D/0/1/0/all/0/1\">Daniel Rubin</a>",
          "description": "Federated learning is an emerging research paradigm enabling collaborative\ntraining of machine learning models among different organizations while keeping\ndata private at each institution. Despite recent progress, there remain\nfundamental challenges such as lack of convergence and potential for\ncatastrophic forgetting in federated learning across real-world heterogeneous\ndevices. In this paper, we demonstrate that attention-based architectures\n(e.g., Transformers) are fairly robust to distribution shifts and hence improve\nfederated learning over heterogeneous data. Concretely, we conduct the first\nrigorous empirical investigation of different neural architectures across a\nrange of federated algorithms, real-world benchmarks, and heterogeneous data\nsplits. Our experiments show that simply replacing convolutional networks with\nTransformers can greatly reduce catastrophic forgetting of previous devices,\naccelerate convergence, and reach a better global model, especially when\ndealing with heterogeneous data. We will release our code and pretrained models\nat https://github.com/Liangqiong/ViT-FL-main to encourage future exploration in\nrobust architectures as an alternative to current research efforts on the\noptimization front.",
          "link": "http://arxiv.org/abs/2106.06047",
          "publishedOn": "2021-06-14T01:38:52.854Z",
          "wordCount": 602,
          "title": "Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning. (arXiv:2106.06047v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2006.03204",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Petsiuk_V/0/1/0/all/0/1\">Vitali Petsiuk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_R/0/1/0/all/0/1\">Rajiv Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manjunatha_V/0/1/0/all/0/1\">Varun Manjunatha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morariu_V/0/1/0/all/0/1\">Vlad I. Morariu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehra_A/0/1/0/all/0/1\">Ashutosh Mehra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ordonez_V/0/1/0/all/0/1\">Vicente Ordonez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saenko_K/0/1/0/all/0/1\">Kate Saenko</a>",
          "description": "We propose D-RISE, a method for generating visual explanations for the\npredictions of object detectors. Utilizing the proposed similarity metric that\naccounts for both localization and categorization aspects of object detection\nallows our method to produce saliency maps that show image areas that most\naffect the prediction. D-RISE can be considered \"black-box\" in the software\ntesting sense, as it only needs access to the inputs and outputs of an object\ndetector. Compared to gradient-based methods, D-RISE is more general and\nagnostic to the particular type of object detector being tested, and does not\nneed knowledge of the inner workings of the model. We show that D-RISE can be\neasily applied to different object detectors including one-stage detectors such\nas YOLOv3 and two-stage detectors such as Faster-RCNN. We present a detailed\nanalysis of the generated visual explanations to highlight the utilization of\ncontext and possible biases learned by object detectors.",
          "link": "http://arxiv.org/abs/2006.03204",
          "publishedOn": "2021-06-14T01:38:52.847Z",
          "wordCount": 633,
          "title": "Black-box Explanation of Object Detectors via Saliency Maps. (arXiv:2006.03204v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06415",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hormann_S/0/1/0/all/0/1\">Stefan H&#xf6;rmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zeyuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Knoche_M/0/1/0/all/0/1\">Martin Knoche</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teepe_T/0/1/0/all/0/1\">Torben Teepe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rigoll_G/0/1/0/all/0/1\">Gerhard Rigoll</a>",
          "description": "Photos of faces captured in unconstrained environments, such as large crowds,\nstill constitute challenges for current face recognition approaches as often\nfaces are occluded by objects or people in the foreground. However, few studies\nhave addressed the task of recognizing partial faces. In this paper, we propose\na novel approach to partial face recognition capable of recognizing faces with\ndifferent occluded areas. We achieve this by combining attentional pooling of a\nResNet's intermediate feature maps with a separate aggregation module. We\nfurther adapt common losses to partial faces in order to ensure that the\nattention maps are diverse and handle occluded parts. Our thorough analysis\ndemonstrates that we outperform all baselines under multiple benchmark\nprotocols, including naturally and synthetically occluded partial faces. This\nsuggests that our method successfully focuses on the relevant parts of the\noccluded face.",
          "link": "http://arxiv.org/abs/2106.06415",
          "publishedOn": "2021-06-14T01:38:52.839Z",
          "wordCount": 570,
          "title": "Attention-based Partial Face Recognition. (arXiv:2106.06415v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2104.13840",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chu_X/0/1/0/all/0/1\">Xiangxiang Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Z/0/1/0/all/0/1\">Zhi Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuqing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Bo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_H/0/1/0/all/0/1\">Haibing Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1\">Xiaolin Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_H/0/1/0/all/0/1\">Huaxia Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1\">Chunhua Shen</a>",
          "description": "Very recently, a variety of vision transformer architectures for dense\nprediction tasks have been proposed and they show that the design of spatial\nattention is critical to their success in these tasks. In this work, we revisit\nthe design of the spatial attention and demonstrate that a carefully-devised\nyet simple spatial attention mechanism performs favourably against the\nstate-of-the-art schemes. As a result, we propose two vision transformer\narchitectures, namely, Twins-PCPVT and Twins-SVT. Our proposed architectures\nare highly-efficient and easy to implement, only involving matrix\nmultiplications that are highly optimized in modern deep learning frameworks.\nMore importantly, the proposed architectures achieve excellent performance on a\nwide range of visual tasks including imagelevel classification as well as dense\ndetection and segmentation. The simplicity and strong performance suggest that\nour proposed architectures may serve as stronger backbones for many vision\ntasks. Our code will be released soon at\nhttps://github.com/Meituan-AutoML/Twins .",
          "link": "http://arxiv.org/abs/2104.13840",
          "publishedOn": "2021-06-14T01:38:52.820Z",
          "wordCount": 656,
          "title": "Twins: Revisiting the Design of Spatial Attention in Vision Transformers. (arXiv:2104.13840v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06056",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiawei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Linyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Huichen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaolu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shuang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>",
          "description": "Boundary based blackbox attack has been recognized as practical and\neffective, given that an attacker only needs to access the final model\nprediction. However, the query efficiency of it is in general high especially\nfor high dimensional image data. In this paper, we show that such efficiency\nhighly depends on the scale at which the attack is applied, and attacking at\nthe optimal scale significantly improves the efficiency. In particular, we\npropose a theoretical framework to analyze and show three key characteristics\nto improve the query efficiency. We prove that there exists an optimal scale\nfor projective gradient estimation. Our framework also explains the\nsatisfactory performance achieved by existing boundary black-box attacks. Based\non our theoretical framework, we propose Progressive-Scale enabled projective\nBoundary Attack (PSBA) to improve the query efficiency via progressive scaling\ntechniques. In particular, we employ Progressive-GAN to optimize the scale of\nprojections, which we call PSBA-PGAN. We evaluate our approach on both spatial\nand frequency scales. Extensive experiments on MNIST, CIFAR-10, CelebA, and\nImageNet against different models including a real-world face recognition API\nshow that PSBA-PGAN significantly outperforms existing baseline attacks in\nterms of query efficiency and attack success rate. We also observe relatively\nstable optimal scales for different models and datasets. The code is publicly\navailable at https://github.com/AI-secure/PSBA.",
          "link": "http://arxiv.org/abs/2106.06056",
          "publishedOn": "2021-06-14T01:38:52.811Z",
          "wordCount": 656,
          "title": "Progressive-Scale Boundary Blackbox Attack via Projective Gradient Estimation. (arXiv:2106.06056v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2011.09065",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Nettekoven_A/0/1/0/all/0/1\">Alexander Nettekoven</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fish_S/0/1/0/all/0/1\">Scott Fish</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Beaman_J/0/1/0/all/0/1\">Joseph Beaman</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Topcu_U/0/1/0/all/0/1\">Ufuk Topcu</a>",
          "description": "An increasing number of laser powder bed fusion machines use off-axis\ninfrared cameras to improve online monitoring and data-driven control\ncapabilities. However, there is still a severe lack of algorithmic solutions to\nproperly process the infrared images from these cameras that has led to several\nkey limitations: a lack of online monitoring capabilities for the laser tracks,\ninsufficient pre-processing of the infrared images for data-driven methods, and\nlarge memory requirements for storing the infrared images. To address these\nlimitations, we study over 30 segmentation algorithms that segment each\ninfrared image into a foreground and background. By evaluating each algorithm\nbased on its segmentation accuracy, computational speed, and spatter detection\ncharacteristics, we identify promising algorithmic solutions. The identified\nalgorithms can be readily applied to the laser powder bed fusion machines to\naddress each of the above limitations and thus, significantly improve process\ncontrol.",
          "link": "http://arxiv.org/abs/2011.09065",
          "publishedOn": "2021-06-14T01:38:52.804Z",
          "wordCount": 617,
          "title": "Towards Online Monitoring and Data-driven Control: A Study of Segmentation Algorithms for Laser Powder Bed Fusion Processes. (arXiv:2011.09065v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10446",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chan_K/0/1/0/all/0/1\">Kwan Ho Ryan Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yaodong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1\">Chong You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_H/0/1/0/all/0/1\">Haozhi Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wright_J/0/1/0/all/0/1\">John Wright</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yi Ma</a>",
          "description": "This work attempts to provide a plausible theoretical framework that aims to\ninterpret modern deep (convolutional) networks from the principles of data\ncompression and discriminative representation. We argue that for\nhigh-dimensional multi-class data, the optimal linear discriminative\nrepresentation maximizes the coding rate difference between the whole dataset\nand the average of all the subsets. We show that the basic iterative gradient\nascent scheme for optimizing the rate reduction objective naturally leads to a\nmulti-layer deep network, named ReduNet, which shares common characteristics of\nmodern deep networks. The deep layered architectures, linear and nonlinear\noperators, and even parameters of the network are all explicitly constructed\nlayer-by-layer via forward propagation, although they are amenable to\nfine-tuning via back propagation. All components of so-obtained ``white-box''\nnetwork have precise optimization, statistical, and geometric interpretation.\nMoreover, all linear operators of the so-derived network naturally become\nmulti-channel convolutions when we enforce classification to be rigorously\nshift-invariant. The derivation in the invariant setting suggests a trade-off\nbetween sparsity and invariance, and also indicates that such a deep\nconvolution network is significantly more efficient to construct and learn in\nthe spectral domain. Our preliminary simulations and experiments clearly verify\nthe effectiveness of both the rate reduction objective and the associated\nReduNet. All code and data are available at https://github.com/Ma-Lab-Berkeley.",
          "link": "http://arxiv.org/abs/2105.10446",
          "publishedOn": "2021-06-14T01:38:52.796Z",
          "wordCount": 723,
          "title": "ReduNet: A White-box Deep Network from the Principle of Maximizing Rate Reduction. (arXiv:2105.10446v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06482",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kaya_E/0/1/0/all/0/1\">Emre Can Kaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tabus_I/0/1/0/all/0/1\">Ioan Tabus</a>",
          "description": "This paper describes a novel lossless point cloud compression algorithm that\nuses a neural network for estimating the coding probabilities for the occupancy\nstatus of voxels, depending on wide three dimensional contexts around the voxel\nto be encoded. The point cloud is represented as an octree, with each\nresolution layer being sequentially encoded and decoded using arithmetic\ncoding, starting from the lowest resolution, until the final resolution is\nreached. The occupancy probability of each voxel of the splitting pattern at\neach node of the octree is modeled by a neural network, having at its input the\nalready encoded occupancy status of several octree nodes (belonging to the past\nand current resolutions), corresponding to a 3D context surrounding the node to\nbe encoded. The algorithm has a fast and a slow version, the fast version\nselecting differently several voxels of the context, which allows an increased\nparallelization by sending larger batches of templates to be estimated by the\nneural network, at both encoder and decoder. The proposed algorithms yield\nstate-of-the-art results on benchmark datasets. The implementation will be made\navailable at https://github.com/marmus12/nnctx",
          "link": "http://arxiv.org/abs/2106.06482",
          "publishedOn": "2021-06-14T01:38:52.789Z",
          "wordCount": 637,
          "title": "Neural Network Modeling of Probabilities for Coding the Octree Representation of Point Clouds. (arXiv:2106.06482v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06340",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1\">Renwang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xuanhong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_B/0/1/0/all/0/1\">Bingbing Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1\">Yanhao Ge</a>",
          "description": "We propose an efficient framework, called Simple Swap (SimSwap), aiming for\ngeneralized and high fidelity face swapping. In contrast to previous approaches\nthat either lack the ability to generalize to arbitrary identity or fail to\npreserve attributes like facial expression and gaze direction, our framework is\ncapable of transferring the identity of an arbitrary source face into an\narbitrary target face while preserving the attributes of the target face. We\novercome the above defects in the following two ways. First, we present the ID\nInjection Module (IIM) which transfers the identity information of the source\nface into the target face at feature level. By using this module, we extend the\narchitecture of an identity-specific face swapping algorithm to a framework for\narbitrary face swapping. Second, we propose the Weak Feature Matching Loss\nwhich efficiently helps our framework to preserve the facial attributes in an\nimplicit way. Extensive experiments on wild faces demonstrate that our SimSwap\nis able to achieve competitive identity performance while preserving attributes\nbetter than previous state-of-the-art methods. The code is already available on\ngithub: https://github.com/neuralchen/SimSwap.",
          "link": "http://arxiv.org/abs/2106.06340",
          "publishedOn": "2021-06-14T01:38:52.769Z",
          "wordCount": 630,
          "title": "SimSwap: An Efficient Framework For High Fidelity Face Swapping. (arXiv:2106.06340v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2006.04647",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mellor_J/0/1/0/all/0/1\">Joseph Mellor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turner_J/0/1/0/all/0/1\">Jack Turner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Storkey_A/0/1/0/all/0/1\">Amos Storkey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crowley_E/0/1/0/all/0/1\">Elliot J. Crowley</a>",
          "description": "The time and effort involved in hand-designing deep neural networks is\nimmense. This has prompted the development of Neural Architecture Search (NAS)\ntechniques to automate this design. However, NAS algorithms tend to be slow and\nexpensive; they need to train vast numbers of candidate networks to inform the\nsearch process. This could be alleviated if we could partially predict a\nnetwork's trained accuracy from its initial state. In this work, we examine the\noverlap of activations between datapoints in untrained networks and motivate\nhow this can give a measure which is usefully indicative of a network's trained\nperformance. We incorporate this measure into a simple algorithm that allows us\nto search for powerful networks without any training in a matter of seconds on\na single GPU, and verify its effectiveness on NAS-Bench-101, NAS-Bench-201,\nNATS-Bench, and Network Design Spaces. Our approach can be readily combined\nwith more expensive search methods; we examine a simple adaptation of\nregularised evolutionary search. Code for reproducing our experiments is\navailable at https://github.com/BayesWatch/nas-without-training.",
          "link": "http://arxiv.org/abs/2006.04647",
          "publishedOn": "2021-06-14T01:38:52.761Z",
          "wordCount": 649,
          "title": "Neural Architecture Search without Training. (arXiv:2006.04647v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06237",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zhou_C/0/1/0/all/0/1\">Chenhong Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_F/0/1/0/all/0/1\">Feng Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gong_C/0/1/0/all/0/1\">Chen Gong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_T/0/1/0/all/0/1\">Tongliang Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Han_B/0/1/0/all/0/1\">Bo Han</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cheung_W/0/1/0/all/0/1\">William Cheung</a>",
          "description": "In semantic segmentation, we aim to train a pixel-level classifier to assign\ncategory labels to all pixels in an image, where labeled training images and\nunlabeled test images are from the same distribution and share the same label\nset. However, in an open world, the unlabeled test images probably contain\nunknown categories and have different distributions from the labeled images.\nHence, in this paper, we consider a new, more realistic, and more challenging\nproblem setting where the pixel-level classifier has to be trained with labeled\nimages and unlabeled open-world images -- we name it open world semantic\nsegmentation (OSS). In OSS, the trained classifier is expected to identify\nunknown-class pixels and classify known-class pixels well. To solve OSS, we\nfirst investigate which distribution that unknown-class pixels obey. Then,\nmotivated by the goodness-of-fit test, we use statistical measurements to show\nhow a pixel fits the distribution of an unknown class and select highly-fitted\npixels to form the unknown region in each image. Eventually, we propose an\nend-to-end learning framework, known-region-aware domain alignment (KRADA), to\ndistinguish unknown classes while aligning distributions of known classes in\nlabeled and unlabeled open-world images. The effectiveness of KRADA has been\nverified on two synthetic tasks and one COVID-19 segmentation task.",
          "link": "http://arxiv.org/abs/2106.06237",
          "publishedOn": "2021-06-14T01:38:52.734Z",
          "wordCount": 698,
          "title": "KRADA: Known-region-aware Domain Alignment for Open World Semantic Segmentation. (arXiv:2106.06237v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06523",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Citron_R/0/1/0/all/0/1\">Robert I. Citron</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Jenniskens_P/0/1/0/all/0/1\">Peter Jenniskens</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Watkins_C/0/1/0/all/0/1\">Christopher Watkins</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Sinha_S/0/1/0/all/0/1\">Sravanthi Sinha</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Shah_A/0/1/0/all/0/1\">Amar Shah</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Raissi_C/0/1/0/all/0/1\">Chedy Raissi</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Devillepoix_H/0/1/0/all/0/1\">Hadrien Devillepoix</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Albers_J/0/1/0/all/0/1\">Jim Albers</a>",
          "description": "The recovery of freshly fallen meteorites from tracked and triangulated\nmeteors is critical to determining their source asteroid families. However,\nlocating meteorite fragments in strewn fields remains a challenge with very few\nmeteorites being recovered from the meteors triangulated in past and ongoing\nmeteor camera networks. We examined if locating meteorites can be automated\nusing machine learning and an autonomous drone. Drones can be programmed to fly\na grid search pattern and take systematic pictures of the ground over a large\nsurvey area. Those images can be analyzed using a machine learning classifier\nto identify meteorites in the field among many other features. Here, we\ndescribe a proof-of-concept meteorite classifier that deploys off-line a\ncombination of different convolution neural networks to recognize meteorites\nfrom images taken by drones in the field. The system was implemented in a\nconceptual drone setup and tested in the suspected strewn field of a recent\nmeteorite fall near Walker Lake, Nevada.",
          "link": "http://arxiv.org/abs/2106.06523",
          "publishedOn": "2021-06-14T01:38:52.579Z",
          "wordCount": 620,
          "title": "Recovery of Meteorites Using an Autonomous Drone and Machine Learning. (arXiv:2106.06523v1 [astro-ph.EP])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06073",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roth_N/0/1/0/all/0/1\">Nicolas Roth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bideau_P/0/1/0/all/0/1\">Pia Bideau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hellwich_O/0/1/0/all/0/1\">Olaf Hellwich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rolfs_M/0/1/0/all/0/1\">Martin Rolfs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Obermayer_K/0/1/0/all/0/1\">Klaus Obermayer</a>",
          "description": "Visually exploring the world around us is not a passive process. Instead, we\nactively explore the world and acquire visual information over time. Here, we\npresent a new model for simulating human eye-movement behavior in dynamic\nreal-world scenes. We model this active scene exploration as a sequential\ndecision making process. We adapt the popular drift-diffusion model (DDM) for\nperceptual decision making and extend it towards multiple options, defined by\nobjects present in the scene. For each possible choice, the model integrates\nevidence over time and a decision (saccadic eye movement) is triggered as soon\nas evidence crosses a decision threshold. Drawing this explicit connection\nbetween decision making and object-based scene perception is highly relevant in\nthe context of active viewing, where decisions are made continuously while\ninteracting with an external environment. We validate our model with a\ncarefully designed ablation study and explore influences of our model\nparameters. A comparison on the VidCom dataset supports the plausibility of the\nproposed approach.",
          "link": "http://arxiv.org/abs/2106.06073",
          "publishedOn": "2021-06-14T01:38:52.552Z",
          "wordCount": 608,
          "title": "A modular framework for object-based saccadic decisions in dynamic scenes. (arXiv:2106.06073v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06072",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Llerena_J/0/1/0/all/0/1\">Jeffri M. Llerena</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeni_L/0/1/0/all/0/1\">Luis Felipe Zeni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kristen_L/0/1/0/all/0/1\">Lucas N. Kristen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_C/0/1/0/all/0/1\">Claudio Jung</a>",
          "description": "Most object detection methods use bounding boxes to encode and represent the\nobject shape and location. In this work, we explore a fuzzy representation of\nobject regions using Gaussian distributions, which provides an implicit binary\nrepresentation as (potentially rotated) ellipses. We also present a similarity\nmeasure for the Gaussian distributions based on the Hellinger Distance, which\ncan be viewed as a Probabilistic Intersection-over-Union (ProbIoU). Our\nexperimental results show that the proposed Gaussian representations are closer\nto annotated segmentation masks in publicly available datasets, and that loss\nfunctions based on ProbIoU can be successfully used to regress the parameters\nof the Gaussian representation. Furthermore, we present a simple mapping scheme\nfrom traditional (or rotated) bounding boxes to Gaussian representations,\nallowing the proposed ProbIoU-based losses to be seamlessly integrated into any\nobject detector.",
          "link": "http://arxiv.org/abs/2106.06072",
          "publishedOn": "2021-06-14T01:38:52.544Z",
          "wordCount": 567,
          "title": "Gaussian Bounding Boxes and Probabilistic Intersection-over-Union for Object Detection. (arXiv:2106.06072v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06007",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ba_Y/0/1/0/all/0/1\">Yunhao Ba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karinca_K/0/1/0/all/0/1\">Kerim Doruk Karinca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bozkurt_O/0/1/0/all/0/1\">Oyku Deniz Bozkurt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kadambi_A/0/1/0/all/0/1\">Achuta Kadambi</a>",
          "description": "Camera-based remote photoplethysmography (rPPG) provides a non-contact way to\nmeasure physiological signals (e.g., heart rate) using facial videos. Recent\ndeep learning architectures have improved the accuracy of such physiological\nmeasurement significantly, yet they are restricted by the diversity of the\nannotated videos. The existing datasets MMSE-HR, AFRL, and UBFC-RPPG contain\nroughly 10%, 0%, and 5% of dark-skinned subjects respectively. The unbalanced\ntraining sets result in a poor generalization capability to unseen subjects and\nlead to unwanted bias toward different demographic groups. In Western academia,\nit is regrettably difficult in a university setting to collect data on these\ndark-skinned subjects. Here we show a first attempt to overcome the lack of\ndark-skinned subjects by synthetic augmentation. A joint optimization framework\nis utilized to translate real videos from light-skinned subjects to dark skin\ntones while retaining their pulsatile signals. In the experiment, our method\nexhibits around 31% reduction in mean absolute error for the dark-skinned group\nand 46% improvement on bias mitigation for all the groups, as compared with the\nprevious work trained with just real samples.",
          "link": "http://arxiv.org/abs/2106.06007",
          "publishedOn": "2021-06-14T01:38:52.510Z",
          "wordCount": 615,
          "title": "Overcoming Difficulty in Obtaining Dark-skinned Subjects for Remote-PPG by Synthetic Augmentation. (arXiv:2106.06007v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06112",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jingyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jiaxing Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1\">Shijian Lu</a>",
          "description": "Unsupervised domain adaptation (UDA) aims to learn a well-performed model in\nan unlabeled target domain by leveraging labeled data from one or multiple\nrelated source domains. It remains a great challenge due to 1) the lack of\nannotations in the target domain and 2) the rich discrepancy between the\ndistributions of source and target data. We propose Spectral UDA (SUDA), an\nefficient yet effective UDA technique that works in the spectral space and is\ngeneric across different visual recognition tasks in detection, classification\nand segmentation. SUDA addresses UDA challenges from two perspectives. First,\nit mitigates inter-domain discrepancies by a spectrum transformer (ST) that\nmaps source and target images into spectral space and learns to enhance\ndomain-invariant spectra while suppressing domain-variant spectra\nsimultaneously. To this end, we design novel adversarial multi-head spectrum\nattention that leverages contextual information to identify domain-variant and\ndomain-invariant spectra effectively. Second, it mitigates the lack of\nannotations in target domain by introducing multi-view spectral learning which\naims to learn comprehensive yet confident target representations by maximizing\nthe mutual information among multiple ST augmentations capturing different\nspectral views of each target sample. Extensive experiments over different\nvisual tasks (e.g., detection, classification and segmentation) show that SUDA\nachieves superior accuracy and it is also complementary with state-of-the-art\nUDA methods with consistent performance boosts but little extra computation.",
          "link": "http://arxiv.org/abs/2106.06112",
          "publishedOn": "2021-06-14T01:38:52.493Z",
          "wordCount": 642,
          "title": "Spectral Unsupervised Domain Adaptation for Visual Recognition. (arXiv:2106.06112v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06351",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Geus_D/0/1/0/all/0/1\">Daan de Geus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meletis_P/0/1/0/all/0/1\">Panagiotis Meletis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1\">Chenyang Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_X/0/1/0/all/0/1\">Xiaoxiao Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dubbelman_G/0/1/0/all/0/1\">Gijs Dubbelman</a>",
          "description": "In this work, we introduce the new scene understanding task of Part-aware\nPanoptic Segmentation (PPS), which aims to understand a scene at multiple\nlevels of abstraction, and unifies the tasks of scene parsing and part parsing.\nFor this novel task, we provide consistent annotations on two commonly used\ndatasets: Cityscapes and Pascal VOC. Moreover, we present a single metric to\nevaluate PPS, called Part-aware Panoptic Quality (PartPQ). For this new task,\nusing the metric and annotations, we set multiple baselines by merging results\nof existing state-of-the-art methods for panoptic segmentation and part\nsegmentation. Finally, we conduct several experiments that evaluate the\nimportance of the different levels of abstraction in this single task.",
          "link": "http://arxiv.org/abs/2106.06351",
          "publishedOn": "2021-06-14T01:38:52.486Z",
          "wordCount": 545,
          "title": "Part-aware Panoptic Segmentation. (arXiv:2106.06351v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06158",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gad_A/0/1/0/all/0/1\">Ahmed Fawzy Gad</a>",
          "description": "This paper introduces PyGAD, an open-source easy-to-use Python library for\nbuilding the genetic algorithm. PyGAD supports a wide range of parameters to\ngive the user control over everything in its life cycle. This includes, but is\nnot limited to, population, gene value range, gene data type, parent selection,\ncrossover, and mutation. PyGAD is designed as a general-purpose optimization\nlibrary that allows the user to customize the fitness function. Its usage\nconsists of 3 main steps: build the fitness function, create an instance of the\npygad.GA class, and calling the pygad.GA.run() method. The library supports\ntraining deep learning models created either with PyGAD itself or with\nframeworks like Keras and PyTorch. Given its stable state, PyGAD is also in\nactive development to respond to the user's requested features and enhancement\nreceived on GitHub https://github.com/ahmedfgad/GeneticAlgorithmPython. PyGAD\ncomes with documentation https://pygad.readthedocs.io for further details and\nexamples.",
          "link": "http://arxiv.org/abs/2106.06158",
          "publishedOn": "2021-06-14T01:38:52.479Z",
          "wordCount": 587,
          "title": "PyGAD: An Intuitive Genetic Algorithm Python Library. (arXiv:2106.06158v1 [cs.NE])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06505",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Garcia_R/0/1/0/all/0/1\">R. Gallardo Garc&#xed;a</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_S/0/1/0/all/0/1\">S. Jarqu&#xed;n Rodr&#xed;guez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martinez_B/0/1/0/all/0/1\">B. Beltr&#xe1;n Mart&#xed;nez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gracidas_C/0/1/0/all/0/1\">C. Hern&#xe1;ndez Gracidas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torres_R/0/1/0/all/0/1\">R. Mart&#xed;nez Torres</a>",
          "description": "This work presents twelve fine-tuned deep learning architectures to solve the\nbacterial classification problem over the Digital Image of Bacterial Species\nDataset. The base architectures were mainly published as mobile or efficient\nsolutions to the ImageNet challenge, and all experiments presented in this work\nconsisted of making several modifications to the original designs, in order to\nmake them able to solve the bacterial classification problem by using\nfine-tuning and transfer learning techniques. This work also proposes a novel\ndata augmentation technique for this dataset, which is based on the idea of\nartificial zooming, strongly increasing the performance of every tested\narchitecture, even doubling it in some cases. In order to get robust and\ncomplete evaluations, all experiments were performed with 10-fold\ncross-validation and evaluated with five different metrics: top-1 and top-5\naccuracy, precision, recall, and F1 score. This paper presents a complete\ncomparison of the twelve different architectures, cross-validated with the\noriginal and the augmented version of the dataset, the results are also\ncompared with several literature methods. Overall, eight of the eleven\narchitectures surpassed the 0.95 scores in top-1 accuracy with our data\naugmentation method, being 0.9738 the highest top-1 accuracy. The impact of the\ndata augmentation technique is reported with relative improvement scores.",
          "link": "http://arxiv.org/abs/2106.06505",
          "publishedOn": "2021-06-14T01:38:52.472Z",
          "wordCount": 688,
          "title": "Efficient Deep Learning Architectures for Fast Identification of Bacterial Strains in Resource-Constrained Devices. (arXiv:2106.06505v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2006.15327",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bar_A/0/1/0/all/0/1\">Amir Bar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Herzig_R/0/1/0/all/0/1\">Roei Herzig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaolong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rohrbach_A/0/1/0/all/0/1\">Anna Rohrbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chechik_G/0/1/0/all/0/1\">Gal Chechik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Darrell_T/0/1/0/all/0/1\">Trevor Darrell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Globerson_A/0/1/0/all/0/1\">Amir Globerson</a>",
          "description": "Videos of actions are complex signals containing rich compositional structure\nin space and time. Current video generation methods lack the ability to\ncondition the generation on multiple coordinated and potentially simultaneous\ntimed actions. To address this challenge, we propose to represent the actions\nin a graph structure called Action Graph and present the new ``Action Graph To\nVideo'' synthesis task. Our generative model for this task (AG2Vid)\ndisentangles motion and appearance features, and by incorporating a scheduling\nmechanism for actions facilitates a timely and coordinated video generation. We\ntrain and evaluate AG2Vid on the CATER and Something-Something V2 datasets, and\nshow that the resulting videos have better visual quality and semantic\nconsistency compared to baselines. Finally, our model demonstrates zero-shot\nabilities by synthesizing novel compositions of the learned actions. For code\nand pretrained models, see the project page https://roeiherz.github.io/AG2Video",
          "link": "http://arxiv.org/abs/2006.15327",
          "publishedOn": "2021-06-14T01:38:52.447Z",
          "wordCount": 631,
          "title": "Compositional Video Synthesis with Action Graphs. (arXiv:2006.15327v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.07466",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roldao_L/0/1/0/all/0/1\">Luis Roldao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Charette_R/0/1/0/all/0/1\">Raoul de Charette</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verroust_Blondet_A/0/1/0/all/0/1\">Anne Verroust-Blondet</a>",
          "description": "Semantic Scene Completion (SSC) aims to jointly estimate the complete\ngeometry and semantics of a scene, assuming partial sparse input. In the last\nyears following the multiplication of large-scale 3D datasets, SSC has gained\nsignificant momentum in the research community because it holds unresolved\nchallenges. Specifically, SSC lies in the ambiguous completion of large\nunobserved areas and the weak supervision signal of the ground truth. This led\nto a substantially increasing number of papers on the matter. This survey aims\nto identify, compare and analyze the techniques providing a critical analysis\nof the SSC literature on both methods and datasets. Throughout the paper, we\nprovide an in-depth analysis of the existing works covering all choices made by\nthe authors while highlighting the remaining avenues of research. SSC\nperformance of the SoA on the most popular datasets is also evaluated and\nanalyzed.",
          "link": "http://arxiv.org/abs/2103.07466",
          "publishedOn": "2021-06-14T01:38:52.440Z",
          "wordCount": 600,
          "title": "3D Semantic Scene Completion: a Survey. (arXiv:2103.07466v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.08844",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jinghan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boloor_A/0/1/0/all/0/1\">Adith Boloor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakrabarti_A/0/1/0/all/0/1\">Ayan Chakrabarti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vorobeychik_Y/0/1/0/all/0/1\">Yevgeniy Vorobeychik</a>",
          "description": "There is considerable evidence that deep neural networks are vulnerable to\nadversarial perturbations applied directly to their digital inputs. However, it\nremains an open question whether this translates to vulnerabilities in real\nsystems. For example, an attack on self-driving cars would in practice entail\nmodifying the driving environment, which then impacts the video inputs to the\ncar's controller, thereby indirectly leading to incorrect driving decisions.\nSuch attacks require accounting for system dynamics and tracking viewpoint\nchanges. We propose a scalable approach for finding adversarial modifications\nof a simulated autonomous driving environment using a differentiable\napproximation for the mapping from environmental modifications (rectangles on\nthe road) to the corresponding video inputs to the controller neural network.\nGiven the parameters of the rectangles, our proposed differentiable mapping\ncomposites them onto pre-recorded video streams of the original environment,\naccounting for geometric and color variations. Moreover, we propose a multiple\ntrajectory sampling approach that enables our attacks to be robust to a car's\nself-correcting behavior. When combined with a neural network-based controller,\nour approach allows the design of adversarial modifications through end-to-end\ngradient-based optimization. Using the Carla autonomous driving simulator, we\nshow that our approach is significantly more scalable and far more effective at\nidentifying autonomous vehicle vulnerabilities in simulation experiments than a\nstate-of-the-art approach based on Bayesian Optimization.",
          "link": "http://arxiv.org/abs/2010.08844",
          "publishedOn": "2021-06-14T01:38:52.433Z",
          "wordCount": 694,
          "title": "Finding Physical Adversarial Examples for Autonomous Driving with Fast and Differentiable Image Compositing. (arXiv:2010.08844v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.06868",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Quenum_J/0/1/0/all/0/1\">Jerome Quenum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Kehan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zakhor_A/0/1/0/all/0/1\">Avideh Zakhor</a>",
          "description": "Object detection in Ultra High-Resolution (UHR) images has long been a\nchallenging problem in computer vision due to the varying scales of the\ntargeted objects. When it comes to barcode detection, resizing UHR input images\nto smaller sizes often leads to the loss of pertinent information, while\nprocessing them directly is highly inefficient and computationally expensive.\nIn this paper, we propose using semantic segmentation to achieve a fast and\naccurate detection of barcodes of various scales in UHR images. Our pipeline\ninvolves a modified Region Proposal Network (RPN) on images of size greater\nthan 10k$\\times$10k and a newly proposed Y-Net segmentation network, followed\nby a post-processing workflow for fitting a bounding box around each segmented\nbarcode mask. The end-to-end system has a latency of 16 milliseconds, which is\n$2.5\\times$ faster than YOLOv4 and $5.9\\times$ faster than Mask R-CNN. In terms\nof accuracy, our method outperforms YOLOv4 and Mask R-CNN by a $mAP$ of 5.5%\nand 47.1% respectively, on a synthetic dataset. We have made available the\ngenerated synthetic barcode dataset and its code at\nthis http URL",
          "link": "http://arxiv.org/abs/2102.06868",
          "publishedOn": "2021-06-14T01:38:52.419Z",
          "wordCount": 656,
          "title": "Fast, Accurate Barcode Detection in Ultra High-Resolution Images. (arXiv:2102.06868v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.04061",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xintao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Honglun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shan_Y/0/1/0/all/0/1\">Ying Shan</a>",
          "description": "Blind face restoration usually relies on facial priors, such as facial\ngeometry prior or reference prior, to restore realistic and faithful details.\nHowever, very low-quality inputs cannot offer accurate geometric prior while\nhigh-quality references are inaccessible, limiting the applicability in\nreal-world scenarios. In this work, we propose GFP-GAN that leverages rich and\ndiverse priors encapsulated in a pretrained face GAN for blind face\nrestoration. This Generative Facial Prior (GFP) is incorporated into the face\nrestoration process via novel channel-split spatial feature transform layers,\nwhich allow our method to achieve a good balance of realness and fidelity.\nThanks to the powerful generative facial prior and delicate designs, our\nGFP-GAN could jointly restore facial details and enhance colors with just a\nsingle forward pass, while GAN inversion methods require expensive\nimage-specific optimization at inference. Extensive experiments show that our\nmethod achieves superior performance to prior art on both synthetic and\nreal-world datasets.",
          "link": "http://arxiv.org/abs/2101.04061",
          "publishedOn": "2021-06-14T01:38:52.402Z",
          "wordCount": 618,
          "title": "Towards Real-World Blind Face Restoration with Generative Facial Prior. (arXiv:2101.04061v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06313",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1\">Lixiang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jianke Zhu</a>",
          "description": "It is challenging to directly estimate the geometry of human from a single\nimage due to the high diversity and complexity of body shapes with the various\nclothing styles. Most of model-based approaches are limited to predict the\nshape and pose of a minimally clothed body with over-smoothing surface.\nAlthough capturing the fine detailed geometries, the model-free methods are\nlack of the fixed mesh topology. To address these issues, we propose a novel\ntopology-preserved human reconstruction approach by bridging the gap between\nmodel-based and model-free human reconstruction. We present an end-to-end\nneural network that simultaneously predicts the pixel-aligned implicit surface\nand the explicit mesh model built by graph convolutional neural network.\nMoreover, an extra graph convolutional neural network is employed to estimate\nthe vertex offsets between the implicit surface and parametric mesh model.\nFinally, we suggest an efficient implicit registration method to refine the\nneural network output in implicit space. Experiments on DeepHuman dataset\nshowed that our approach is effective.",
          "link": "http://arxiv.org/abs/2106.06313",
          "publishedOn": "2021-06-14T01:38:52.395Z",
          "wordCount": 588,
          "title": "Bridge the Gap Between Model-based and Model-free Human Reconstruction. (arXiv:2106.06313v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2104.02710",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jennifer J. Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karigo_T/0/1/0/all/0/1\">Tomomi Karigo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_D/0/1/0/all/0/1\">Dipam Chakraborty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohanty_S/0/1/0/all/0/1\">Sharada P. Mohanty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wild_B/0/1/0/all/0/1\">Benjamin Wild</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Q/0/1/0/all/0/1\">Quan Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anderson_D/0/1/0/all/0/1\">David J. Anderson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perona_P/0/1/0/all/0/1\">Pietro Perona</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yue_Y/0/1/0/all/0/1\">Yisong Yue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kennedy_A/0/1/0/all/0/1\">Ann Kennedy</a>",
          "description": "Multi-agent behavior modeling aims to understand the interactions that occur\nbetween agents. We present a multi-agent dataset from behavioral neuroscience,\nthe Caltech Mouse Social Interactions (CalMS21) Dataset. Our dataset consists\nof trajectory data of social interactions, recorded from videos of freely\nbehaving mice in a standard resident-intruder assay. To help accelerate\nbehavioral studies, the CalMS21 dataset provides benchmarks to evaluate the\nperformance of automated behavior classification methods in three settings: (1)\nfor training on large behavioral datasets all annotated by a single annotator,\n(2) for style transfer to learn inter-annotator differences in behavior\ndefinitions, and (3) for learning of new behaviors of interest given limited\ntraining data. The dataset consists of 6 million frames of unlabeled tracked\nposes of interacting mice, as well as over 1 million frames with tracked poses\nand corresponding frame-level behavior annotations. The challenge of our\ndataset is to be able to classify behaviors accurately using both labeled and\nunlabeled tracking data, as well as being able to generalize to new settings.",
          "link": "http://arxiv.org/abs/2104.02710",
          "publishedOn": "2021-06-14T01:38:52.388Z",
          "wordCount": 662,
          "title": "The Multi-Agent Behavior Dataset: Mouse Dyadic Social Interactions. (arXiv:2104.02710v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06307",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nazir_U/0/1/0/all/0/1\">Usman Nazir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">He Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taj_M/0/1/0/all/0/1\">Murtaza Taj</a>",
          "description": "In this survey paper, we analyze image based graph neural networks and\npropose a three-step classification approach. We first convert the image into\nsuperpixels using the Quickshift algorithm so as to reduce 30% of the input\ndata. The superpixels are subsequently used to generate a region adjacency\ngraph. Finally, the graph is passed through a state-of-art graph convolutional\nneural network to get classification scores. We also analyze the spatial and\nspectral convolution filtering techniques in graph neural networks.\nSpectral-based models perform better than spatial-based models and classical\nCNN with lesser compute cost.",
          "link": "http://arxiv.org/abs/2106.06307",
          "publishedOn": "2021-06-14T01:38:52.381Z",
          "wordCount": 522,
          "title": "Survey of Image Based Graph Neural Networks. (arXiv:2106.06307v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06533",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bhattad_A/0/1/0/all/0/1\">Anand Bhattad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dundar_A/0/1/0/all/0/1\">Aysegul Dundar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Guilin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_A/0/1/0/all/0/1\">Andrew Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Catanzaro_B/0/1/0/all/0/1\">Bryan Catanzaro</a>",
          "description": "Humans can easily infer the underlying 3D geometry and texture of an object\nonly from a single 2D image. Current computer vision methods can do this, too,\nbut suffer from view generalization problems - the models inferred tend to make\npoor predictions of appearance in novel views. As for generalization problems\nin machine learning, the difficulty is balancing single-view accuracy (cf.\ntraining error; bias) with novel view accuracy (cf. test error; variance). We\ndescribe a class of models whose geometric rigidity is easily controlled to\nmanage this tradeoff. We describe a cycle consistency loss that improves view\ngeneralization (roughly, a model from a generated view should predict the\noriginal view well). View generalization of textures requires that models share\ntexture information, so a car seen from the back still has headlights because\nother cars have headlights. We describe a cycle consistency loss that\nencourages model textures to be aligned, so as to encourage sharing. We compare\nour method against the state-of-the-art method and show both qualitative and\nquantitative improvements.",
          "link": "http://arxiv.org/abs/2106.06533",
          "publishedOn": "2021-06-14T01:38:52.374Z",
          "wordCount": 620,
          "title": "View Generalization for Single Image Textured 3D Models. (arXiv:2106.06533v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06418",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jansson_Y/0/1/0/all/0/1\">Ylva Jansson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lindeberg_T/0/1/0/all/0/1\">Tony Lindeberg</a>",
          "description": "The ability to handle large scale variations is crucial for many real world\nvisual tasks. A straightforward approach for handling scale in a deep network\nis to process an image at several scales simultaneously in a set of scale\nchannels. Scale invariance can then, in principle, be achieved by using weight\nsharing between the scale channels together with max or average pooling over\nthe outputs from the scale channels. The ability of such scale channel networks\nto generalise to scales not present in the training set over significant scale\nranges has, however, not previously been explored.\n\nIn this paper, we present a systematic study of this methodology by\nimplementing different types of scale channel networks and evaluating their\nability to generalise to previously unseen scales. We develop a formalism for\nanalysing the covariance and invariance properties of scale channel networks,\nand explore how different design choices, unique to scaling transformations,\naffect the overall performance of scale channel networks. We first show that\ntwo previously proposed scale channel network designs do not generalise well to\nscales not present in the training set. We explain theoretically and\ndemonstrate experimentally why generalisation fails in these cases.\n\nWe then propose a new type of foveated scale channel architecture}, where the\nscale channels process increasingly larger parts of the image with decreasing\nresolution. This new type of scale channel network is shown to generalise\nextremely well, provided sufficient image resolution and the absence of\nboundary effects. Our proposed FovMax and FovAvg networks perform almost\nidentically over a scale range of 8, also when training on single scale\ntraining data, and do also give improved performance when learning from\ndatasets with large scale variations in the small sample regime.",
          "link": "http://arxiv.org/abs/2106.06418",
          "publishedOn": "2021-06-14T01:38:52.368Z",
          "wordCount": 734,
          "title": "Scale-invariant scale-channel networks: Deep networks that generalise to previously unseen scales. (arXiv:2106.06418v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2102.07753",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Seidenschwarz_J/0/1/0/all/0/1\">Jenny Seidenschwarz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elezi_I/0/1/0/all/0/1\">Ismail Elezi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leal_Taixe_L/0/1/0/all/0/1\">Laura Leal-Taix&#xe9;</a>",
          "description": "The goal of metric learning is to learn a function that maps samples to a\nlower-dimensional space where similar samples lie closer than dissimilar ones.\nParticularly, deep metric learning utilizes neural networks to learn such a\nmapping. Most approaches rely on losses that only take the relations between\npairs or triplets of samples into account, which either belong to the same\nclass or two different classes. However, these methods do not explore the\nembedding space in its entirety. To this end, we propose an approach based on\nmessage passing networks that takes all the relations in a mini-batch into\naccount. We refine embedding vectors by exchanging messages among all samples\nin a given batch allowing the training process to be aware of its overall\nstructure. Since not all samples are equally important to predict a decision\nboundary, we use an attention mechanism during message passing to allow samples\nto weigh the importance of each neighbor accordingly. We achieve\nstate-of-the-art results on clustering and image retrieval on the CUB-200-2011,\nCars196, Stanford Online Products, and In-Shop Clothes datasets. To facilitate\nfurther research, we make available the code and the models at\nhttps://github.com/dvl-tum/intra_batch_connections.",
          "link": "http://arxiv.org/abs/2102.07753",
          "publishedOn": "2021-06-14T01:38:52.339Z",
          "wordCount": 667,
          "title": "Learning Intra-Batch Connections for Deep Metric Learning. (arXiv:2102.07753v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06234",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Castellano_G/0/1/0/all/0/1\">Giovanna Castellano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vessio_G/0/1/0/all/0/1\">Gennaro Vessio</a>",
          "description": "Clustering artworks is difficult for several reasons. On the one hand,\nrecognizing meaningful patterns based on domain knowledge and visual perception\nis extremely hard. On the other hand, applying traditional clustering and\nfeature reduction techniques to the highly dimensional pixel space can be\nineffective. To address these issues, in this paper we propose DELIUS: a DEep\nlearning approach to cLustering vIsUal artS. The method uses a pre-trained\nconvolutional network to extract features and then feeds these features into a\ndeep embedded clustering model, where the task of mapping the raw input data to\na latent space is jointly optimized with the task of finding a set of cluster\ncentroids in this latent space. Quantitative and qualitative experimental\nresults show the effectiveness of the proposed method. DELIUS can be useful for\nseveral tasks related to art analysis, in particular visual link retrieval and\nhistorical knowledge discovery in painting datasets.",
          "link": "http://arxiv.org/abs/2106.06234",
          "publishedOn": "2021-06-14T01:38:52.333Z",
          "wordCount": 578,
          "title": "A deep learning approach to clustering visual arts. (arXiv:2106.06234v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06011",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yibo Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haidi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1\">Yiming Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shunyao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1\">Mingliang Xu</a>",
          "description": "With the development of deep learning, the single super-resolution image\nreconstruction network models are becoming more and more complex. Small changes\nin hyperparameters of the models have a greater impact on model performance. In\nthe existing works, experts have gradually explored a set of optimal model\nparameters based on empirical values or performing brute-force search. In this\npaper, we introduce a new super-resolution image reconstruction generative\nadversarial network framework, and a Bayesian optimization method used to\noptimizing the hyperparameters of the generator and discriminator. The\ngenerator is made by self-calibrated convolution, and discriminator is made by\nconvolution lays. We have defined the hyperparameters such as the number of\nnetwork layers and the number of neurons. Our method adopts Bayesian\noptimization as a optimization policy of GAN in our model. Not only can find\nthe optimal hyperparameter solution automatically, but also can construct a\nsuper-resolution image reconstruction network, reducing the manual workload.\nExperiments show that Bayesian optimization can search the optimal solution\nearlier than the other two optimization algorithms.",
          "link": "http://arxiv.org/abs/2106.06011",
          "publishedOn": "2021-06-14T01:38:52.326Z",
          "wordCount": 619,
          "title": "A self-adapting super-resolution structures framework for automatic design of GAN. (arXiv:2106.06011v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/1909.04810",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kumra_S/0/1/0/all/0/1\">Sulabh Kumra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_S/0/1/0/all/0/1\">Shirin Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sahin_F/0/1/0/all/0/1\">Ferat Sahin</a>",
          "description": "In this paper, we present a modular robotic system to tackle the problem of\ngenerating and performing antipodal robotic grasps for unknown objects from\nn-channel image of the scene. We propose a novel Generative Residual\nConvolutional Neural Network (GR-ConvNet) model that can generate robust\nantipodal grasps from n-channel input at real-time speeds (~20ms). We evaluate\nthe proposed model architecture on standard datasets and a diverse set of\nhousehold objects. We achieved state-of-the-art accuracy of 97.7% and 94.6% on\nCornell and Jacquard grasping datasets respectively. We also demonstrate a\ngrasp success rate of 95.4% and 93% on household and adversarial objects\nrespectively using a 7 DoF robotic arm.",
          "link": "http://arxiv.org/abs/1909.04810",
          "publishedOn": "2021-06-14T01:38:52.310Z",
          "wordCount": 596,
          "title": "Antipodal Robotic Grasping using Generative Residual Convolutional Neural Network. (arXiv:1909.04810v4 [cs.RO] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.05501",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qin_H/0/1/0/all/0/1\">Haotong Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_Z/0/1/0/all/0/1\">Zhongang Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mingyuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1\">Yifu Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Haiyu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_S/0/1/0/all/0/1\">Shuai Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xianglong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1\">Hao Su</a>",
          "description": "To alleviate the resource constraint for real-time point cloud applications\nthat run on edge devices, in this paper we present BiPointNet, the first model\nbinarization approach for efficient deep learning on point clouds. We discover\nthat the immense performance drop of binarized models for point clouds mainly\nstems from two challenges: aggregation-induced feature homogenization that\nleads to a degradation of information entropy, and scale distortion that\nhinders optimization and invalidates scale-sensitive structures. With\ntheoretical justifications and in-depth analysis, our BiPointNet introduces\nEntropy-Maximizing Aggregation (EMA) to modulate the distribution before\naggregation for the maximum information entropy, and Layer-wise Scale Recovery\n(LSR) to efficiently restore feature representation capacity. Extensive\nexperiments show that BiPointNet outperforms existing binarization methods by\nconvincing margins, at the level even comparable with the full precision\ncounterpart. We highlight that our techniques are generic, guaranteeing\nsignificant improvements on various fundamental tasks and mainstream backbones.\nMoreover, BiPointNet gives an impressive 14.7x speedup and 18.9x storage saving\non real-world resource-constrained devices.",
          "link": "http://arxiv.org/abs/2010.05501",
          "publishedOn": "2021-06-14T01:38:52.303Z",
          "wordCount": 645,
          "title": "BiPointNet: Binary Neural Network for Point Clouds. (arXiv:2010.05501v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1908.01961",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meka_A/0/1/0/all/0/1\">Abhimitra Meka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shafiei_M/0/1/0/all/0/1\">Mohammad Shafiei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zollhoefer_M/0/1/0/all/0/1\">Michael Zollhoefer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Richardt_C/0/1/0/all/0/1\">Christian Richardt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Theobalt_C/0/1/0/all/0/1\">Christian Theobalt</a>",
          "description": "We propose the first approach for the decomposition of a monocular color\nvideo into direct and indirect illumination components in real time. We\nretrieve, in separate layers, the contribution made to the scene appearance by\nthe scene reflectance, the light sources and the reflections from various\ncoherent scene regions to one another. Existing techniques that invert global\nlight transport require image capture under multiplexed controlled lighting, or\nonly enable the decomposition of a single image at slow off-line frame rates.\nIn contrast, our approach works for regular videos and produces temporally\ncoherent decomposition layers at real-time frame rates. At the core of our\napproach are several sparsity priors that enable the estimation of the\nper-pixel direct and indirect illumination layers based on a small set of\njointly estimated base reflectance colors. The resulting variational\ndecomposition problem uses a new formulation based on sparse and dense sets of\nnon-linear equations that we solve efficiently using a novel alternating\ndata-parallel optimization strategy. We evaluate our approach qualitatively and\nquantitatively, and show improvements over the state of the art in this field,\nin both quality and runtime. In addition, we demonstrate various real-time\nappearance editing applications for videos with consistent illumination.",
          "link": "http://arxiv.org/abs/1908.01961",
          "publishedOn": "2021-06-14T01:38:52.296Z",
          "wordCount": 655,
          "title": "Real-Time Global Illumination Decomposition of Videos. (arXiv:1908.01961v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06360",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shen_F/0/1/0/all/0/1\">Feihong Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_P/0/1/0/all/0/1\">Ping Hu</a>",
          "description": "zero-shot learning is an essential part of computer vision. As a classical\ndownstream task, zero-shot semantic segmentation has been studied because of\nits applicant value. One of the popular zero-shot semantic segmentation methods\nis based on the generative model Most new proposed works added structures on\nthe same architecture to enhance this model. However, we found that, from the\nview of causal inference, the result of the original model has been influenced\nby spurious statistical relationships. Thus the performance of the prediction\nshows severe bias. In this work, we consider counterfactual methods to avoid\nthe confounder in the original model. Based on this method, we proposed a new\nframework for zero-shot semantic segmentation. Our model is compared with\nbaseline models on two real-world datasets, Pascal-VOC and Pascal-Context. The\nexperiment results show proposed models can surpass previous confounded models\nand can still make use of additional structures to improve the performance. We\nalso design a simple structure based on Graph Convolutional Networks (GCN) in\nthis work.",
          "link": "http://arxiv.org/abs/2106.06360",
          "publishedOn": "2021-06-14T01:38:52.289Z",
          "wordCount": 598,
          "title": "Conterfactual Generative Zero-Shot Semantic Segmentation. (arXiv:2106.06360v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2101.12690",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Costain_T/0/1/0/all/0/1\">Theo W. Costain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prisacariu_V/0/1/0/all/0/1\">Victor Adrian Prisacariu</a>",
          "description": "Neural implicit representations have shown substantial improvements in\nefficiently storing 3D data, when compared to conventional formats. However,\nthe focus of existing work has mainly been on storage and subsequent\nreconstruction. In this work, we show that training neural representations for\nreconstruction tasks alongside conventional tasks can produce more general\nencodings that admit equal quality reconstructions to single task training,\nwhilst improving results on conventional tasks when compared to single task\nencodings. We reformulate the semantic segmentation task, creating a more\nrepresentative task for implicit representation contexts, and through\nmulti-task experiments on reconstruction, classification, and segmentation,\nshow our approach learns feature rich encodings that admit equal performance\nfor each task.",
          "link": "http://arxiv.org/abs/2101.12690",
          "publishedOn": "2021-06-14T01:38:52.283Z",
          "wordCount": 559,
          "title": "Towards Generalising Neural Implicit Representations. (arXiv:2101.12690v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.11456",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_J/0/1/0/all/0/1\">Jiahong Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adeli_E/0/1/0/all/0/1\">Ehsan Adeli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pohl_K/0/1/0/all/0/1\">Kilian M. Pohl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1\">Qingyu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaharchuk_G/0/1/0/all/0/1\">Greg Zaharchuk</a>",
          "description": "Multi-modal MRIs are widely used in neuroimaging applications since different\nMR sequences provide complementary information about brain structures. Recent\nworks have suggested that multi-modal deep learning analysis can benefit from\nexplicitly disentangling anatomical (shape) and modality (appearance)\ninformation into separate image presentations. In this work, we challenge\nmainstream strategies by showing that they do not naturally lead to\nrepresentation disentanglement both in theory and in practice. To address this\nissue, we propose a margin loss that regularizes the similarity in\nrelationships of the representations across subjects and modalities. To enable\nrobust training, we further use a conditional convolution to design a single\nmodel for encoding images of all modalities. Lastly, we propose a fusion\nfunction to combine the disentangled anatomical representations as a set of\nmodality-invariant features for downstream tasks. We evaluate the proposed\nmethod on three multi-modal neuroimaging datasets. Experiments show that our\nproposed method can achieve superior disentangled representations compared to\nexisting disentanglement strategies. Results also indicate that the fused\nanatomical representation has potential in the downstream task of zero-dose PET\nreconstruction and brain tumor segmentation. The code is available at\n\\url{https://github.com/ouyangjiahong/representation-disentanglement}.",
          "link": "http://arxiv.org/abs/2102.11456",
          "publishedOn": "2021-06-14T01:38:52.242Z",
          "wordCount": 658,
          "title": "Representation Disentanglement for Multi-modal brain MR Analysis. (arXiv:2102.11456v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06059",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roy_P/0/1/0/all/0/1\">Pankaj Raj Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bilodeau_G/0/1/0/all/0/1\">Guillaume-Alexandre Bilodeau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seoud_L/0/1/0/all/0/1\">Lama Seoud</a>",
          "description": "We present a local anomaly detection method in videos. As opposed to most\nexisting methods that are computationally expensive and are not very\ngeneralizable across different video scenes, we propose an adversarial\nframework that learns the temporal local appearance variations by predicting\nthe appearance of a normally behaving object in the next frame of a scene by\nonly relying on its current and past appearances. In the presence of an\nabnormally behaving object, the reconstruction error between the real and the\npredicted next appearance of that object indicates the likelihood of an\nanomaly. Our method is competitive with the existing state-of-the-art while\nbeing significantly faster for both training and inference and being better at\ngeneralizing to unseen video scenes.",
          "link": "http://arxiv.org/abs/2106.06059",
          "publishedOn": "2021-06-14T01:38:52.219Z",
          "wordCount": 556,
          "title": "Predicting Next Local Appearance for Video Anomaly Detection. (arXiv:2106.06059v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06509",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ji_Z/0/1/0/all/0/1\">Zhong Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1\">Kexin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haoran Wang</a>",
          "description": "Image-text matching plays a central role in bridging the semantic gap between\nvision and language. The key point to achieve precise visual-semantic alignment\nlies in capturing the fine-grained cross-modal correspondence between image and\ntext. Most previous methods rely on single-step reasoning to discover the\nvisual-semantic interactions, which lacks the ability of exploiting the\nmulti-level information to locate the hierarchical fine-grained relevance.\nDifferent from them, in this work, we propose a step-wise hierarchical\nalignment network (SHAN) that decomposes image-text matching into multi-step\ncross-modal reasoning process. Specifically, we first achieve local-to-local\nalignment at fragment level, following by performing global-to-local and\nglobal-to-global alignment at context level sequentially. This progressive\nalignment strategy supplies our model with more complementary and sufficient\nsemantic clues to understand the hierarchical correlations between image and\ntext. The experimental results on two benchmark datasets demonstrate the\nsuperiority of our proposed method.",
          "link": "http://arxiv.org/abs/2106.06509",
          "publishedOn": "2021-06-14T01:38:52.171Z",
          "wordCount": 572,
          "title": "Step-Wise Hierarchical Alignment Network for Image-Text Matching. (arXiv:2106.06509v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06403",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tavakoli_H/0/1/0/all/0/1\">Hooman Tavakoli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walunj_S/0/1/0/all/0/1\">Snehal Walunj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pahlevannejad_P/0/1/0/all/0/1\">Parsha Pahlevannejad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plociennik_C/0/1/0/all/0/1\">Christiane Plociennik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruskowski_M/0/1/0/all/0/1\">Martin Ruskowski</a>",
          "description": "Detecting small objects in video streams of head-worn augmented reality\ndevices in near real-time is a huge challenge: training data is typically\nscarce, the input video stream can be of limited quality, and small objects are\nnotoriously hard to detect. In industrial scenarios, however, it is often\npossible to leverage contextual knowledge for the detection of small objects.\nFurthermore, CAD data of objects are typically available and can be used to\ngenerate synthetic training data. We describe a near real-time small object\ndetection pipeline for egocentric perception in a manual assembly scenario: We\ngenerate a training data set based on CAD data and realistic backgrounds in\nUnity. We then train a YOLOv4 model for a two-stage detection process: First,\nthe context is recognized, then the small object of interest is detected. We\nevaluate our pipeline on the augmented reality device Microsoft Hololens 2.",
          "link": "http://arxiv.org/abs/2106.06403",
          "publishedOn": "2021-06-14T01:38:52.139Z",
          "wordCount": 600,
          "title": "Small Object Detection for Near Real-Time Egocentric Perception in a Manual Assembly Scenario. (arXiv:2106.06403v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06195",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1\">Xing Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Hezheng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xiangyu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1\">Fan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_D/0/1/0/all/0/1\">Dong Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhongyuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_N/0/1/0/all/0/1\">Nian Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Honglin Liu</a>",
          "description": "The task of multi-label image classification is to recognize all the object\nlabels presented in an image. Though advancing for years, small objects,\nsimilar objects and objects with high conditional probability are still the\nmain bottlenecks of previous convolutional neural network(CNN) based models,\nlimited by convolutional kernels' representational capacity. Recent vision\ntransformer networks utilize the self-attention mechanism to extract the\nfeature of pixel granularity, which expresses richer local semantic\ninformation, while is insufficient for mining global spatial dependence. In\nthis paper, we point out the three crucial problems that CNN-based methods\nencounter and explore the possibility of conducting specific transformer\nmodules to settle them. We put forward a Multi-label Transformer\narchitecture(MlTr) constructed with windows partitioning, in-window pixel\nattention, cross-window attention, particularly improving the performance of\nmulti-label image classification tasks. The proposed MlTr shows\nstate-of-the-art results on various prevalent multi-label datasets such as\nMS-COCO, Pascal-VOC, and NUS-WIDE with 88.5%, 95.8%, and 65.5% respectively.\nThe code will be available soon at https://github.com/starmemda/MlTr/",
          "link": "http://arxiv.org/abs/2106.06195",
          "publishedOn": "2021-06-14T01:38:52.084Z",
          "wordCount": 594,
          "title": "MlTr: Multi-label Classification with Transformer. (arXiv:2106.06195v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06138",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ruan_L/0/1/0/all/0/1\">Ludan Ruan</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jieting Chen</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yuqing Song</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Shizhe Chen</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Q/0/1/0/all/0/1\">Qin Jin</a> (1) ((1) Renmin University of China, (2) INRIA)",
          "description": "Entities Object Localization (EOL) aims to evaluate how grounded or faithful\na description is, which consists of caption generation and object grounding.\nPrevious works tackle this problem by jointly training the two modules in a\nframework, which limits the complexity of each module. Therefore, in this work,\nwe propose to divide these two modules into two stages and improve them\nrespectively to boost the whole system performance. For the caption generation,\nwe propose a Unified Multi-modal Pre-training Model (UMPM) to generate event\ndescriptions with rich objects for better localization. For the object\ngrounding, we fine-tune the state-of-the-art detection model MDETR and design a\npost processing method to make the grounding results more faithful. Our overall\nsystem achieves the state-of-the-art performances on both sub-tasks in Entities\nObject Localization challenge at Activitynet 2021, with 72.57 localization\naccuracy on the testing set of sub-task I and 0.2477 F1_all_per_sent on the\nhidden testing set of sub-task II.",
          "link": "http://arxiv.org/abs/2106.06138",
          "publishedOn": "2021-06-14T01:38:52.076Z",
          "wordCount": 606,
          "title": "Team RUC_AIM3 Technical Report at ActivityNet 2021: Entities Object Localization. (arXiv:2106.06138v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06027",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1\">Mingkang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tianlong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhangyang Wang</a>",
          "description": "Sparse adversarial attacks can fool deep neural networks (DNNs) by only\nperturbing a few pixels (regularized by l_0 norm). Recent efforts combine it\nwith another l_infty imperceptible on the perturbation magnitudes. The\nresultant sparse and imperceptible attacks are practically relevant, and\nindicate an even higher vulnerability of DNNs that we usually imagined.\nHowever, such attacks are more challenging to generate due to the optimization\ndifficulty by coupling the l_0 regularizer and box constraints with a\nnon-convex objective. In this paper, we address this challenge by proposing a\nhomotopy algorithm, to jointly tackle the sparsity and the perturbation bound\nin one unified framework. Each iteration, the main step of our algorithm is to\noptimize an l_0-regularized adversarial loss, by leveraging the nonmonotone\nAccelerated Proximal Gradient Method (nmAPG) for nonconvex programming; it is\nfollowed by an l_0 change control step, and an optional post-attack step\ndesigned to escape bad local minima. We also extend the algorithm to handling\nthe structural sparsity regularizer. We extensively examine the effectiveness\nof our proposed homotopy attack for both targeted and non-targeted attack\nscenarios, on CIFAR-10 and ImageNet datasets. Compared to state-of-the-art\nmethods, our homotopy attack leads to significantly fewer perturbations, e.g.,\nreducing 42.91% on CIFAR-10 and 75.03% on ImageNet (average case, targeted\nattack), at similar maximal perturbation magnitudes, when still achieving 100%\nattack success rates. Our codes are available at:\nhttps://github.com/VITA-Group/SparseADV_Homotopy.",
          "link": "http://arxiv.org/abs/2106.06027",
          "publishedOn": "2021-06-14T01:38:52.042Z",
          "wordCount": 662,
          "title": "Sparse and Imperceptible Adversarial Attack via a Homotopy Algorithm. (arXiv:2106.06027v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06012",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Laakom_F/0/1/0/all/0/1\">Firas Laakom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raitoharju_J/0/1/0/all/0/1\">Jenni Raitoharju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iosifidis_A/0/1/0/all/0/1\">Alexandros Iosifidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gabbouj_M/0/1/0/all/0/1\">Moncef Gabbouj</a>",
          "description": "Neural networks are composed of multiple layers arranged in a hierarchical\nstructure jointly trained with a gradient-based optimization, where the errors\nare back-propagated from the last layer back to the first one. At each\noptimization step, neurons at a given layer receive feedback from neurons\nbelonging to higher layers of the hierarchy. In this paper, we propose to\ncomplement this traditional 'between-layer' feedback with additional\n'within-layer' feedback to encourage diversity of the activations within the\nsame layer. To this end, we measure the pairwise similarity between the outputs\nof the neurons and use it to model the layer's overall diversity. By penalizing\nsimilarities and promoting diversity, we encourage each neuron to learn a\ndistinctive representation and, thus, to enrich the data representation learned\nwithin the layer and to increase the total capacity of the model. We\ntheoretically study how the within-layer activation diversity affects the\ngeneralization performance of a neural network and prove that increasing the\ndiversity of hidden activations reduces the estimation error. In addition to\nthe theoretical guarantees, we present an empirical study on three datasets\nconfirming that the proposed approach enhances the performance of\nstate-of-the-art neural network models and decreases the generalization gap.",
          "link": "http://arxiv.org/abs/2106.06012",
          "publishedOn": "2021-06-14T01:38:52.035Z",
          "wordCount": 628,
          "title": "Within-layer Diversity Reduces Generalization Gap. (arXiv:2106.06012v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06159",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gan_Y/0/1/0/all/0/1\">Yanhai Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1\">Xinghui Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Huiyu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_F/0/1/0/all/0/1\">Feng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1\">Junyu Dong</a>",
          "description": "Clustering is one of the fundamental tasks in computer vision and pattern\nrecognition. Recently, deep clustering methods (algorithms based on deep\nlearning) have attracted wide attention with their impressive performance. Most\nof these algorithms combine deep unsupervised representation learning and\nstandard clustering together. However, the separation of representation\nlearning and clustering will lead to suboptimal solutions because the two-stage\nstrategy prevents representation learning from adapting to subsequent tasks\n(e.g., clustering according to specific cues). To overcome this issue, efforts\nhave been made in the dynamic adaption of representation and cluster\nassignment, whereas current state-of-the-art methods suffer from heuristically\nconstructed objectives with representation and cluster assignment alternatively\noptimized. To further standardize the clustering problem, we audaciously\nformulate the objective of clustering as finding a precise feature as the cue\nfor cluster assignment. Based on this, we propose a general-purpose deep\nclustering framework which radically integrates representation learning and\nclustering into a single pipeline for the first time. The proposed framework\nexploits the powerful ability of recently developed generative models for\nlearning intrinsic features, and imposes an entropy minimization on the\ndistribution of the cluster assignment by a dedicated variational algorithm.\nExperimental results show that the performance of the proposed method is\nsuperior, or at least comparable to, the state-of-the-art methods on the\nhandwritten digit recognition, fashion recognition, face recognition and object\nrecognition benchmark datasets.",
          "link": "http://arxiv.org/abs/2106.06159",
          "publishedOn": "2021-06-14T01:38:52.014Z",
          "wordCount": 659,
          "title": "Learning the Precise Feature for Cluster Assignment. (arXiv:2106.06159v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05974",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Riquelme_C/0/1/0/all/0/1\">Carlos Riquelme</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Puigcerver_J/0/1/0/all/0/1\">Joan Puigcerver</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mustafa_B/0/1/0/all/0/1\">Basil Mustafa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neumann_M/0/1/0/all/0/1\">Maxim Neumann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jenatton_R/0/1/0/all/0/1\">Rodolphe Jenatton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pinto_A/0/1/0/all/0/1\">Andr&#xe9; Susano Pinto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keysers_D/0/1/0/all/0/1\">Daniel Keysers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Houlsby_N/0/1/0/all/0/1\">Neil Houlsby</a>",
          "description": "Sparsely-gated Mixture of Experts networks (MoEs) have demonstrated excellent\nscalability in Natural Language Processing. In Computer Vision, however, almost\nall performant networks are \"dense\", that is, every input is processed by every\nparameter. We present a Vision MoE (V-MoE), a sparse version of the Vision\nTransformer, that is scalable and competitive with the largest dense networks.\nWhen applied to image recognition, V-MoE matches the performance of\nstate-of-the-art networks, while requiring as little as half of the compute at\ninference time. Further, we propose an extension to the routing algorithm that\ncan prioritize subsets of each input across the entire batch, leading to\nadaptive per-image compute. This allows V-MoE to trade-off performance and\ncompute smoothly at test-time. Finally, we demonstrate the potential of V-MoE\nto scale vision models, and train a 15B parameter model that attains 90.35% on\nImageNet.",
          "link": "http://arxiv.org/abs/2106.05974",
          "publishedOn": "2021-06-14T01:38:51.987Z",
          "wordCount": 589,
          "title": "Scaling Vision with Sparse Mixture of Experts. (arXiv:2106.05974v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06020",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weiler_M/0/1/0/all/0/1\">Maurice Weiler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Forre_P/0/1/0/all/0/1\">Patrick Forr&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verlinde_E/0/1/0/all/0/1\">Erik Verlinde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1\">Max Welling</a>",
          "description": "Motivated by the vast success of deep convolutional networks, there is a\ngreat interest in generalizing convolutions to non-Euclidean manifolds. A major\ncomplication in comparison to flat spaces is that it is unclear in which\nalignment a convolution kernel should be applied on a manifold. The underlying\nreason for this ambiguity is that general manifolds do not come with a\ncanonical choice of reference frames (gauge). Kernels and features therefore\nhave to be expressed relative to arbitrary coordinates. We argue that the\nparticular choice of coordinatization should not affect a network's inference\n-- it should be coordinate independent. A simultaneous demand for coordinate\nindependence and weight sharing is shown to result in a requirement on the\nnetwork to be equivariant under local gauge transformations (changes of local\nreference frames). The ambiguity of reference frames depends thereby on the\nG-structure of the manifold, such that the necessary level of gauge\nequivariance is prescribed by the corresponding structure group G. Coordinate\nindependent convolutions are proven to be equivariant w.r.t. those isometries\nthat are symmetries of the G-structure. The resulting theory is formulated in a\ncoordinate free fashion in terms of fiber bundles. To exemplify the design of\ncoordinate independent convolutions, we implement a convolutional network on\nthe M\\\"obius strip. The generality of our differential geometric formulation of\nconvolutional networks is demonstrated by an extensive literature review which\nexplains a large number of Euclidean CNNs, spherical CNNs and CNNs on general\nsurfaces as specific instances of coordinate independent convolutions.",
          "link": "http://arxiv.org/abs/2106.06020",
          "publishedOn": "2021-06-14T01:38:51.971Z",
          "wordCount": 710,
          "title": "Coordinate Independent Convolutional Networks -- Isometry and Gauge Equivariant Convolutions on Riemannian Manifolds. (arXiv:2106.06020v1 [cs.LG])"
        }
      ]
    },
    {
      "title": "cs.LG updates on arXiv.org",
      "feedUrl": "http://export.arxiv.org/rss/cs.LG",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2106.08937",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Annabi_L/0/1/0/all/0/1\">Louis Annabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pitti_A/0/1/0/all/0/1\">Alexandre Pitti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quoy_M/0/1/0/all/0/1\">Mathias Quoy</a>",
          "description": "As a phenomenon in dynamical systems allowing autonomous switching between\nstable behaviors, chaotic itinerancy has gained interest in neurorobotics\nresearch. In this study, we draw a connection between this phenomenon and the\npredictive coding theory by showing how a recurrent neural network implementing\npredictive coding can generate neural trajectories similar to chaotic\nitinerancy in the presence of input noise. We propose two scenarios generating\nrandom and past-independent attractor switching trajectories using our model.",
          "link": "http://arxiv.org/abs/2106.08937",
          "publishedOn": "2021-06-17T16:16:41.906Z",
          "wordCount": 505,
          "title": "A Predictive Coding Account for Chaotic Itinerancy. (arXiv:2106.08937v1 [cs.NE])"
        },
        {
          "id": "http://arxiv.org/abs/2104.11014",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hong_M/0/1/0/all/0/1\">Min-Fong Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hao-Yun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Min-Hung Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yu-Syuan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuo_H/0/1/0/all/0/1\">Hsien-Kai Kuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsai_Y/0/1/0/all/0/1\">Yi-Min Tsai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hung-Jen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jou_K/0/1/0/all/0/1\">Kevin Jou</a>",
          "description": "Network spaces have been known as a critical factor in both handcrafted\nnetwork designs or defining search spaces for Neural Architecture Search (NAS).\nHowever, an effective space involves tremendous prior knowledge and/or manual\neffort, and additional constraints are required to discover efficiency-aware\narchitectures. In this paper, we define a new problem, Network Space Search\n(NSS), as searching for favorable network spaces instead of a single\narchitecture. We propose an NSS method to directly search for efficient-aware\nnetwork spaces automatically, reducing the manual effort and immense cost in\ndiscovering satisfactory ones. The resultant network spaces, named Elite\nSpaces, are discovered from Expanded Search Space with minimal human expertise\nimposed. The Pareto-efficient Elite Spaces are aligned with the Pareto front\nunder various complexity constraints and can be further served as NAS search\nspaces, benefiting differentiable NAS approaches (e.g. In CIFAR-100, an\naveragely 2.3% lower error rate and 3.7% closer to target constraint than the\nbaseline with around 90% fewer samples required to find satisfactory networks).\nMoreover, our NSS approach is capable of searching for superior spaces in\nfuture unexplored spaces, revealing great potential in searching for network\nspaces automatically. Website:\nhttps://minhungchen.netlify.app/publication/nss/.",
          "link": "http://arxiv.org/abs/2104.11014",
          "publishedOn": "2021-06-17T15:44:17.182Z",
          "wordCount": 697,
          "title": "Network Space Search for Pareto-Efficient Spaces. (arXiv:2104.11014v5 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05923",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bano_S/0/1/0/all/0/1\">Sophia Bano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Casella_A/0/1/0/all/0/1\">Alessandro Casella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasconcelos_F/0/1/0/all/0/1\">Francisco Vasconcelos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moccia_S/0/1/0/all/0/1\">Sara Moccia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Attilakos_G/0/1/0/all/0/1\">George Attilakos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wimalasundera_R/0/1/0/all/0/1\">Ruwan Wimalasundera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+David_A/0/1/0/all/0/1\">Anna L. David</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paladini_D/0/1/0/all/0/1\">Dario Paladini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deprest_J/0/1/0/all/0/1\">Jan Deprest</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Momi_E/0/1/0/all/0/1\">Elena De Momi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mattos_L/0/1/0/all/0/1\">Leonardo S. Mattos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stoyanov_D/0/1/0/all/0/1\">Danail Stoyanov</a>",
          "description": "Fetoscopy laser photocoagulation is a widely used procedure for the treatment\nof Twin-to-Twin Transfusion Syndrome (TTTS), that occur in mono-chorionic\nmultiple pregnancies due to placental vascular anastomoses. This procedure is\nparticularly challenging due to limited field of view, poor manoeuvrability of\nthe fetoscope, poor visibility due to fluid turbidity, variability in light\nsource, and unusual position of the placenta. This may lead to increased\nprocedural time and incomplete ablation, resulting in persistent TTTS.\nComputer-assisted intervention may help overcome these challenges by expanding\nthe fetoscopic field of view through video mosaicking and providing better\nvisualization of the vessel network. However, the research and development in\nthis domain remain limited due to unavailability of high-quality data to encode\nthe intra- and inter-procedure variability. Through the \\textit{Fetoscopic\nPlacental Vessel Segmentation and Registration (FetReg)} challenge, we present\na large-scale multi-centre dataset for the development of generalized and\nrobust semantic segmentation and video mosaicking algorithms for the fetal\nenvironment with a focus on creating drift-free mosaics from long duration\nfetoscopy videos. In this paper, we provide an overview of the FetReg dataset,\nchallenge tasks, evaluation metrics and baseline methods for both segmentation\nand registration. Baseline methods results on the FetReg dataset shows that our\ndataset poses interesting challenges, offering large opportunity for the\ncreation of novel methods and models through a community effort initiative\nguided by the FetReg challenge.",
          "link": "http://arxiv.org/abs/2106.05923",
          "publishedOn": "2021-06-17T15:44:17.153Z",
          "wordCount": 708,
          "title": "FetReg: Placental Vessel Segmentation and Registration in Fetoscopy Challenge Dataset. (arXiv:2106.05923v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05739",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Domingo_Enrich_C/0/1/0/all/0/1\">Carles Domingo-Enrich</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mroueh_Y/0/1/0/all/0/1\">Youssef Mroueh</a>",
          "description": "Several works in implicit and explicit generative modeling empirically\nobserved that feature-learning discriminators outperform fixed-kernel\ndiscriminators in terms of the sample quality of the models. We provide\nseparation results between probability metrics with fixed-kernel and\nfeature-learning discriminators using the function classes $\\mathcal{F}_2$ and\n$\\mathcal{F}_1$ respectively, which were developed to study overparametrized\ntwo-layer neural networks. In particular, we construct pairs of distributions\nover hyper-spheres that can not be discriminated by fixed kernel\n$(\\mathcal{F}_2)$ integral probability metric (IPM) and Stein discrepancy (SD)\nin high dimensions, but that can be discriminated by their feature learning\n($\\mathcal{F}_1$) counterparts. To further study the separation we provide\nlinks between the $\\mathcal{F}_1$ and $\\mathcal{F}_2$ IPMs with sliced\nWasserstein distances. Our work suggests that fixed-kernel discriminators\nperform worse than their feature learning counterparts because their\ncorresponding metrics are weaker.",
          "link": "http://arxiv.org/abs/2106.05739",
          "publishedOn": "2021-06-17T15:44:17.143Z",
          "wordCount": 586,
          "title": "Separation Results between Fixed-Kernel and Feature-Learning Probability Metrics. (arXiv:2106.05739v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05426",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Antonello_R/0/1/0/all/0/1\">Richard Antonello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turek_J/0/1/0/all/0/1\">Javier Turek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vo_V/0/1/0/all/0/1\">Vy Vo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huth_A/0/1/0/all/0/1\">Alexander Huth</a>",
          "description": "How related are the representations learned by neural language models,\ntranslation models, and language tagging tasks? We answer this question by\nadapting an encoder-decoder transfer learning method from computer vision to\ninvestigate the structure among 100 different feature spaces extracted from\nhidden representations of various networks trained on language tasks. This\nmethod reveals a low-dimensional structure where language models and\ntranslation models smoothly interpolate between word embeddings, syntactic and\nsemantic tasks, and future word embeddings. We call this low-dimensional\nstructure a language representation embedding because it encodes the\nrelationships between representations needed to process language for a variety\nof NLP tasks. We find that this representation embedding can predict how well\neach individual feature space maps to human brain responses to natural language\nstimuli recorded using fMRI. Additionally, we find that the principal dimension\nof this structure can be used to create a metric which highlights the brain's\nnatural language processing hierarchy. This suggests that the embedding\ncaptures some part of the brain's natural language representation structure.",
          "link": "http://arxiv.org/abs/2106.05426",
          "publishedOn": "2021-06-17T15:44:17.131Z",
          "wordCount": 628,
          "title": "Low-Dimensional Structure in the Space of Language Representations is Reflected in Brain Responses. (arXiv:2106.05426v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.14193",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Chen_W/0/1/0/all/0/1\">Wen-Hua Chen</a>",
          "description": "This paper presents stability analysis tools for model predictive control\n(MPC) with and without terminal weight. Stability analysis of MPC with a\nlimited horizon but without terminal weight is a long-standing open problem. By\nusing a modified value function as an Lyapunov function candidate and the\nprinciple of optimality, this paper establishes stability conditions for this\ntype of widely spread MPC algorithms. A new stability guaranteed MPC algorithm\nwithout terminal weight (MPCS) is presented. With the help of designing a new\nsublevel set defined by the value function of one-step ahead stage cost,\nconditions for checking its recursive feasibility and stability of the proposed\nMPC algorithm are presented. The new stability condition and the derived MPCS\novercome the difficulties arising in the existing terminal weight based MPC\nframework, including the need of searching a suitable terminal weight and\npossible poor performance caused by an inappropriate terminal weight. This work\nis further extended to MPC with a terminal weight for the completeness.\nNumerical examples are presented to demonstrate the effectiveness of the\nproposed tool, whereas the existing stability analysis tools are either not\napplicable or lead to quite conservative results. It shows that the proposed\ntools offer a number of mechanisms to achieve stability: adjusting state and/or\ncontrol weights, extending the length of horizon, and adding a simple extra\nconstraint on the first or second state in the optimisation.",
          "link": "http://arxiv.org/abs/2011.14193",
          "publishedOn": "2021-06-17T01:58:46.948Z",
          "wordCount": 688,
          "title": "Model Predictive Control with and without Terminal Weight: Stability and Algorithms. (arXiv:2011.14193v2 [eess.SY] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02331",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Tanaka_K/0/1/0/all/0/1\">Keitaro Tanaka</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sawata_R/0/1/0/all/0/1\">Ryosuke Sawata</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Takahashi_S/0/1/0/all/0/1\">Shusuke Takahashi</a>",
          "description": "This paper presents a new deep clustering (DC) method called manifold-aware\nDC (M-DC) that can enhance hyperspace utilization more effectively than the\noriginal DC. The original DC has a limitation in that a pair of two speakers\nhas to be embedded having an orthogonal relationship due to its use of the\none-hot vector-based loss function, while our method derives a unique loss\nfunction aimed at maximizing the target angle in the hyperspace based on the\nnature of a regular simplex. Our proposed loss imposes a higher penalty than\nthe original DC when the speaker is assigned incorrectly. The change from DC to\nM-DC can be easily achieved by rewriting just one term in the loss function of\nDC, without any other modifications to the network architecture or model\nparameters. As such, our method has high practicability because it does not\naffect the original inference part. The experimental results show that the\nproposed method improves the performances of the original DC and its expansion\nmethod.",
          "link": "http://arxiv.org/abs/2106.02331",
          "publishedOn": "2021-06-17T01:58:46.936Z",
          "wordCount": 628,
          "title": "Manifold-Aware Deep Clustering: Maximizing Angles between Embedding Vectors Based on Regular Simplex. (arXiv:2106.02331v2 [eess.AS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.08319",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Galvez_R/0/1/0/all/0/1\">Rafa G&#xe1;lvez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moonsamy_V/0/1/0/all/0/1\">Veelasha Moonsamy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diaz_C/0/1/0/all/0/1\">Claudia Diaz</a>",
          "description": "In this paper we present LiM (\"Less is More\"), a malware classification\nframework that leverages Federated Learning to detect and classify malicious\napps in a privacy-respecting manner. Information about newly installed apps is\nkept locally on users' devices, so that the provider cannot infer which apps\nwere installed by users. At the same time, input from all users is taken into\naccount in the federated learning process and they all benefit from better\nclassification performance. A key challenge of this setting is that users do\nnot have access to the ground truth (i.e. they cannot correctly identify\nwhether an app is malicious). To tackle this, LiM uses a safe semi-supervised\nensemble that maximizes classification accuracy with respect to a baseline\nclassifier trained by the service provider (i.e. the cloud). We implement LiM\nand show that the cloud server has F1 score of 95%, while clients have perfect\nrecall with only 1 false positive in >100 apps, using a dataset of 25K clean\napps and 25K malicious apps, 200 users and 50 rounds of federation.\nFurthermore, we conduct a security analysis and demonstrate that LiM is robust\nagainst both poisoning attacks by adversaries who control half of the clients,\nand inference attacks performed by an honest-but-curious cloud server. Further\nexperiments with MaMaDroid's dataset confirm resistance against poisoning\nattacks and a performance improvement due to the federation.",
          "link": "http://arxiv.org/abs/2007.08319",
          "publishedOn": "2021-06-17T01:58:46.932Z",
          "wordCount": 703,
          "title": "Less is More: A privacy-respecting Android malware classifier using Federated Learning. (arXiv:2007.08319v3 [cs.CR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.06274",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Korencic_D/0/1/0/all/0/1\">Damir Koren&#x10d;i&#x107;</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Ristov_S/0/1/0/all/0/1\">Strahil Ristov</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Repar_J/0/1/0/all/0/1\">Jelena Repar</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Snajder_J/0/1/0/all/0/1\">Jan &#x160;najder</a> (2) ((1) Rudjer Bo&#x161;kovi&#x107; Institute, Croatia, (2) University of Zagreb, Faculty of Electrical Engineering and Computing, Croatia)",
          "description": "Topic models are widely used unsupervised models of text capable of learning\ntopics - weighted lists of words and documents - from large collections of text\ndocuments. When topic models are used for discovery of topics in text\ncollections, a question that arises naturally is how well the model-induced\ntopics correspond to topics of interest to the analyst. In this paper we\nrevisit and extend a so far neglected approach to topic model evaluation based\non measuring topic coverage - computationally matching model topics with a set\nof reference topics that models are expected to uncover. The approach is well\nsuited for analyzing models' performance in topic discovery and for large-scale\nanalysis of both topic models and measures of model quality. We propose new\nmeasures of coverage and evaluate, in a series of experiments, different types\nof topic models on two distinct text domains for which interest for topic\ndiscovery exists. The experiments include evaluation of model quality, analysis\nof coverage of distinct topic categories, and the analysis of the relationship\nbetween coverage and other methods of topic model evaluation. The contributions\nof the paper include new measures of coverage, insights into both topic models\nand other methods of model evaluation, and the datasets and code for\nfacilitating future research of both topic coverage and other approaches to\ntopic model evaluation.",
          "link": "http://arxiv.org/abs/2012.06274",
          "publishedOn": "2021-06-17T01:58:46.925Z",
          "wordCount": 741,
          "title": "A Topic Coverage Approach to Evaluation of Topic Models. (arXiv:2012.06274v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.09000",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Yang_X/0/1/0/all/0/1\">Xin Yang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhang_N/0/1/0/all/0/1\">Ning Zhang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Wang_D/0/1/0/all/0/1\">Donglin Wang</a>",
          "description": "The objective of this study is to derive functional networks for the autism\nspectrum disorder (ASD) population using the group ICA and dictionary learning\nmodel together and to classify ASD and typically developing (TD) participants\nusing the functional connectivity calculated from the derived functional\nnetworks. In our experiments, the ASD functional networks were derived from\nresting-state functional magnetic resonance imaging (rs-fMRI) data. We\ndownloaded a total of 120 training samples, including 58 ASD and 62 TD\nparticipants, which were obtained from the public repository: Autism Brain\nImaging Data Exchange I (ABIDE I). Our methodology and results have five main\nparts. First, we utilize a group ICA model to extract functional networks from\nthe ASD group and rank the top 20 regions of interest (ROIs). Second, we\nutilize a dictionary learning model to extract functional networks from the ASD\ngroup and rank the top 20 ROIs. Third, we merged the 40 selected ROIs from the\ntwo models together as the ASD functional networks. Fourth, we generate three\ncorresponding masks based on the 20 selected ROIs from group ICA, the 20 ROIs\nselected from dictionary learning, and the 40 combined ROIs selected from both.\nFinally, we extract ROIs for all training samples using the above three masks,\nand the calculated functional connectivity was used as features for ASD and TD\nclassification. The classification results showed that the functional networks\nderived from ICA and dictionary learning together outperform those derived from\na single ICA model or a single dictionary learning model.",
          "link": "http://arxiv.org/abs/2106.09000",
          "publishedOn": "2021-06-17T01:58:46.920Z",
          "wordCount": 701,
          "title": "Deriving Autism Spectrum Disorder Functional Networks from RS-FMRI Data using Group ICA and Dictionary Learning. (arXiv:2106.09000v1 [q-bio.NC])"
        },
        {
          "id": "http://arxiv.org/abs/2102.08570",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Miller_J/0/1/0/all/0/1\">John Miller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perdomo_J/0/1/0/all/0/1\">Juan C. Perdomo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zrnic_T/0/1/0/all/0/1\">Tijana Zrnic</a>",
          "description": "In performative prediction, predictions guide decision-making and hence can\ninfluence the distribution of future data. To date, work on performative\nprediction has focused on finding performatively stable models, which are the\nfixed points of repeated retraining. However, stable solutions can be far from\noptimal when evaluated in terms of the performative risk, the loss experienced\nby the decision maker when deploying a model. In this paper, we shift attention\nbeyond performative stability and focus on optimizing the performative risk\ndirectly. We identify a natural set of properties of the loss function and\nmodel-induced distribution shift under which the performative risk is convex, a\nproperty which does not follow from convexity of the loss alone. Furthermore,\nwe develop algorithms that leverage our structural assumptions to optimize the\nperformative risk with better sample efficiency than generic methods for\nderivative-free convex optimization.",
          "link": "http://arxiv.org/abs/2102.08570",
          "publishedOn": "2021-06-17T01:58:46.914Z",
          "wordCount": 596,
          "title": "Outside the Echo Chamber: Optimizing the Performative Risk. (arXiv:2102.08570v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.03622",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1\">Colin Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_K/0/1/0/all/0/1\">Kendrick Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yining Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1\">Tengyu Ma</a>",
          "description": "Self-training algorithms, which train a model to fit pseudolabels predicted\nby another previously-learned model, have been very successful for learning\nwith unlabeled data using neural networks. However, the current theoretical\nunderstanding of self-training only applies to linear models. This work\nprovides a unified theoretical analysis of self-training with deep networks for\nsemi-supervised learning, unsupervised domain adaptation, and unsupervised\nlearning. At the core of our analysis is a simple but realistic \"expansion\"\nassumption, which states that a low probability subset of the data must expand\nto a neighborhood with large probability relative to the subset. We also assume\nthat neighborhoods of examples in different classes have minimal overlap. We\nprove that under these assumptions, the minimizers of population objectives\nbased on self-training and input-consistency regularization will achieve high\naccuracy with respect to ground-truth labels. By using off-the-shelf\ngeneralization bounds, we immediately convert this result to sample complexity\nguarantees for neural nets that are polynomial in the margin and Lipschitzness.\nOur results help explain the empirical successes of recently proposed\nself-training algorithms which use input consistency regularization.",
          "link": "http://arxiv.org/abs/2010.03622",
          "publishedOn": "2021-06-17T01:58:46.909Z",
          "wordCount": 659,
          "title": "Theoretical Analysis of Self-Training with Deep Networks on Unlabeled Data. (arXiv:2010.03622v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08936",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Murn_L/0/1/0/all/0/1\">Luka Murn</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Blasi_S/0/1/0/all/0/1\">Saverio Blasi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Smeaton_A/0/1/0/all/0/1\">Alan F. Smeaton</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mrak_M/0/1/0/all/0/1\">Marta Mrak</a>",
          "description": "The versatility of recent machine learning approaches makes them ideal for\nimprovement of next generation video compression solutions. Unfortunately,\nthese approaches typically bring significant increases in computational\ncomplexity and are difficult to interpret into explainable models, affecting\ntheir potential for implementation within practical video coding applications.\nThis paper introduces a novel explainable neural network-based inter-prediction\nscheme, to improve the interpolation of reference samples needed for fractional\nprecision motion compensation. The approach requires a single neural network to\nbe trained from which a full quarter-pixel interpolation filter set is derived,\nas the network is easily interpretable due to its linear structure. A novel\ntraining framework enables each network branch to resemble a specific\nfractional shift. This practical solution makes it very efficient to use\nalongside conventional video coding schemes. When implemented in the context of\nthe state-of-the-art Versatile Video Coding (VVC) test model, 0.77%, 1.27% and\n2.25% BD-rate savings can be achieved on average for lower resolution sequences\nunder the random access, low-delay B and low-delay P configurations,\nrespectively, while the complexity of the learned interpolation schemes is\nsignificantly reduced compared to the interpolation with full CNNs.",
          "link": "http://arxiv.org/abs/2106.08936",
          "publishedOn": "2021-06-17T01:58:46.903Z",
          "wordCount": 664,
          "title": "Improved CNN-based Learning of Interpolation Filters for Low-Complexity Inter Prediction in Video Coding. (arXiv:2106.08936v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08946",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1\">Xiaopeng Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Shuai Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jacobson_G/0/1/0/all/0/1\">Guy Jacobson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jana_R/0/1/0/all/0/1\">Rittwik Jana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsu_W/0/1/0/all/0/1\">Wen-Ling Hsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Talasila_M/0/1/0/all/0/1\">Manoop Talasila</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aftab_S/0/1/0/all/0/1\">Syed Anwar Aftab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borcea_C/0/1/0/all/0/1\">Cristian Borcea</a>",
          "description": "Fine-grained location prediction on smart phones can be used to improve\napp/system performance. Application scenarios include video quality adaptation\nas a function of the 5G network quality at predicted user locations, and\naugmented reality apps that speed up content rendering based on predicted user\nlocations. Such use cases require prediction error in the same range as the GPS\nerror, and no existing works on location prediction can achieve this level of\naccuracy. We present a system for fine-grained location prediction (FGLP) of\nmobile users, based on GPS traces collected on the phones. FGLP has two\ncomponents: a federated learning framework and a prediction model. The\nframework runs on the phones of the users and also on a server that coordinates\nlearning from all users in the system. FGLP represents the user location data\nas relative points in an abstract 2D space, which enables learning across\ndifferent physical spaces. The model merges Bidirectional Long Short-Term\nMemory (BiLSTM) and Convolutional Neural Networks (CNN), where BiLSTM learns\nthe speed and direction of the mobile users, and CNN learns information such as\nuser movement preferences. FGLP uses federated learning to protect user privacy\nand reduce bandwidth consumption. Our experimental results, using a dataset\nwith over 600,000 users, demonstrate that FGLP outperforms baseline models in\nterms of prediction accuracy. We also demonstrate that FGLP works well in\nconjunction with transfer learning, which enables model reusability. Finally,\nbenchmark results on several types of Android phones demonstrate FGLP's\nfeasibility in real life.",
          "link": "http://arxiv.org/abs/2106.08946",
          "publishedOn": "2021-06-17T01:58:46.882Z",
          "wordCount": 690,
          "title": "FGLP: A Federated Fine-Grained Location Prediction System for Mobile Users. (arXiv:2106.08946v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08898",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinyi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Haiqin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1\">Liang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mo_Y/0/1/0/all/0/1\">Yang Mo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1\">Jianping Shen</a>",
          "description": "Recently developed large pre-trained language models, e.g., BERT, have\nachieved remarkable performance in many downstream natural language processing\napplications. These pre-trained language models often contain hundreds of\nmillions of parameters and suffer from high computation and latency in\nreal-world applications. It is desirable to reduce the computation overhead of\nthe models for fast training and inference while keeping the model performance\nin downstream applications. Several lines of work utilize knowledge\ndistillation to compress the teacher model to a smaller student model. However,\nthey usually discard the teacher's knowledge when in inference. Differently, in\nthis paper, we propose RefBERT to leverage the knowledge learned from the\nteacher, i.e., facilitating the pre-computed BERT representation on the\nreference sample and compressing BERT into a smaller student model. To\nguarantee our proposal, we provide theoretical justification on the loss\nfunction and the usage of reference samples. Significantly, the theoretical\nresult shows that including the pre-computed teacher's representations on the\nreference samples indeed increases the mutual information in learning the\nstudent model. Finally, we conduct the empirical evaluation and show that our\nRefBERT can beat the vanilla TinyBERT over 8.1\\% and achieves more than 94\\% of\nthe performance of $\\BERTBASE$ on the GLUE benchmark. Meanwhile, RefBERT is\n7.4x smaller and 9.5x faster on inference than BERT$_{\\rm BASE}$.",
          "link": "http://arxiv.org/abs/2106.08898",
          "publishedOn": "2021-06-17T01:58:46.875Z",
          "wordCount": 652,
          "title": "RefBERT: Compressing BERT by Referencing to Pre-computed Representations. (arXiv:2106.08898v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2012.11662",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gillen_S/0/1/0/all/0/1\">Sean Gillen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Byl_K/0/1/0/all/0/1\">Katie Byl</a>",
          "description": "A key limitation in using various modern methods of machine learning in\ndeveloping feedback control policies is the lack of appropriate methodologies\nto analyze their long-term dynamics, in terms of making any sort of guarantees\n(even statistically) about robustness. The central reasons for this are largely\ndue to the so-called curse of dimensionality, combined with the black-box\nnature of the resulting control policies themselves. This paper aims at the\nfirst of these issues. Although the full state space of a system may be quite\nlarge in dimensionality, it is a common feature of most model-based control\nmethods that the resulting closed-loop systems demonstrate dominant dynamics\nthat are rapidly driven to some lower-dimensional sub-space within. In this\nwork we argue that the dimensionality of this subspace is captured by tools\nfrom fractal geometry, namely various notions of a fractional dimension. We\nthen show that the dimensionality of trajectories induced by model free\nreinforcement learning agents can be influenced adding a post processing\nfunction to the agents reward signal. We verify that the dimensionality\nreduction is robust to noise being added to the system and show that that the\nmodified agents are more actually more robust to noise and push disturbances in\ngeneral for the systems we examined.",
          "link": "http://arxiv.org/abs/2012.11662",
          "publishedOn": "2021-06-17T01:58:46.865Z",
          "wordCount": 661,
          "title": "Explicitly Encouraging Low Fractional Dimensional Trajectories Via Reinforcement Learning. (arXiv:2012.11662v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.02400",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xuefeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tongliang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1\">Bo Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1\">Gang Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masashi Sugiyama</a>",
          "description": "In label-noise learning, the transition matrix plays a key role in building\nstatistically consistent classifiers. Existing consistent estimators for the\ntransition matrix have been developed by exploiting anchor points. However, the\nanchor-point assumption is not always satisfied in real scenarios. In this\npaper, we propose an end-to-end framework for solving label-noise learning\nwithout anchor points, in which we simultaneously optimize two objectives: the\ncross entropy loss between the noisy label and the predicted probability by the\nneural network, and the volume of the simplex formed by the columns of the\ntransition matrix. Our proposed framework can identify the transition matrix if\nthe clean class-posterior probabilities are sufficiently scattered. This is by\nfar the mildest assumption under which the transition matrix is provably\nidentifiable and the learned classifier is statistically consistent.\nExperimental results on benchmark datasets demonstrate the effectiveness and\nrobustness of the proposed method.",
          "link": "http://arxiv.org/abs/2102.02400",
          "publishedOn": "2021-06-17T01:58:46.844Z",
          "wordCount": 607,
          "title": "Provably End-to-end Label-Noise Learning without Anchor Points. (arXiv:2102.02400v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.09004",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Dietrich_F/0/1/0/all/0/1\">Felix Dietrich</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Makeev_A/0/1/0/all/0/1\">Alexei Makeev</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Kevrekidis_G/0/1/0/all/0/1\">George Kevrekidis</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Evangelou_N/0/1/0/all/0/1\">Nikolaos Evangelou</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Bertalan_T/0/1/0/all/0/1\">Tom Bertalan</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Reich_S/0/1/0/all/0/1\">Sebastian Reich</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Kevrekidis_I/0/1/0/all/0/1\">Ioannis G. Kevrekidis</a>",
          "description": "We identify effective stochastic differential equations (SDE) for coarse\nobservables of fine-grained particle- or agent-based simulations; these SDE\nthen provide coarse surrogate models of the fine scale dynamics. We approximate\nthe drift and diffusivity functions in these effective SDE through neural\nnetworks, which can be thought of as effective stochastic ResNets. The loss\nfunction is inspired by, and embodies, the structure of established stochastic\nnumerical integrators (here, Euler-Maruyama and Milstein); our approximations\ncan thus benefit from error analysis of these underlying numerical schemes.\nThey also lend themselves naturally to \"physics-informed\" gray-box\nidentification when approximate coarse models, such as mean field equations,\nare available. Our approach does not require long trajectories, works on\nscattered snapshot data, and is designed to naturally handle different time\nsteps per snapshot. We consider both the case where the coarse collective\nobservables are known in advance, as well as the case where they must be found\nin a data-driven manner.",
          "link": "http://arxiv.org/abs/2106.09004",
          "publishedOn": "2021-06-17T01:58:46.836Z",
          "wordCount": 607,
          "title": "Learning effective stochastic differential equations from microscopic simulations: combining stochastic numerics and deep learning. (arXiv:2106.09004v1 [physics.comp-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08881",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1\">Junhui Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ritov_Y/0/1/0/all/0/1\">Ya&#x27;acov Ritov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1\">Linda Zhao</a>",
          "description": "Large-scale modern data often involves estimation and testing for\nhigh-dimensional unknown parameters. It is desirable to identify the sparse\nsignals, ``the needles in the haystack'', with accuracy and false discovery\ncontrol. However, the unprecedented complexity and heterogeneity in modern data\nstructure require new machine learning tools to effectively exploit\ncommonalities and to robustly adjust for both sparsity and heterogeneity. In\naddition, estimates for high-dimensional parameters often lack uncertainty\nquantification. In this paper, we propose a novel Spike-and-Nonparametric\nmixture prior (SNP) -- a spike to promote the sparsity and a nonparametric\nstructure to capture signals. In contrast to the state-of-the-art methods, the\nproposed methods solve the estimation and testing problem at once with several\nmerits: 1) an accurate sparsity estimation; 2) point estimates with\nshrinkage/soft-thresholding property; 3) credible intervals for uncertainty\nquantification; 4) an optimal multiple testing procedure that controls false\ndiscovery rate. Our method exhibits promising empirical performance on both\nsimulated data and a gene expression case study.",
          "link": "http://arxiv.org/abs/2106.08881",
          "publishedOn": "2021-06-17T01:58:46.823Z",
          "wordCount": 592,
          "title": "Nonparametric Empirical Bayes Estimation and Testing for Sparse and Heteroscedastic Signals. (arXiv:2106.08881v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08746",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tekgul_B/0/1/0/all/0/1\">Buse G.A. Tekgul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shelly Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marchal_S/0/1/0/all/0/1\">Samuel Marchal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asokan_N/0/1/0/all/0/1\">N. Asokan</a>",
          "description": "Recent work has discovered that deep reinforcement learning (DRL) policies\nare vulnerable to adversarial examples. These attacks mislead the policy of DRL\nagents by perturbing the state of the environment observed by agents. They are\nfeasible in principle but too slow to fool DRL policies in real time. We\npropose a new attack to fool DRL policies that is both effective and efficient\nenough to be mounted in real time. We utilize the Universal Adversarial\nPerturbation (UAP) method to compute effective perturbations independent of the\nindividual inputs to which they are applied. Via an extensive evaluation using\nAtari 2600 games, we show that our technique is effective, as it fully degrades\nthe performance of both deterministic and stochastic policies (up to 100%, even\nwhen the $l_\\infty$ bound on the perturbation is as small as 0.005). We also\nshow that our attack is efficient, incurring an online computational cost of\n0.027ms on average. It is faster compared to the response time (0.6ms on\naverage) of agents with different DRL policies, and considerably faster than\nprior attacks (2.7ms on average). Furthermore, we demonstrate that known\ndefenses are ineffective against universal perturbations. We propose an\neffective detection technique which can form the basis for robust defenses\nagainst attacks based on universal perturbations.",
          "link": "http://arxiv.org/abs/2106.08746",
          "publishedOn": "2021-06-17T01:58:46.812Z",
          "wordCount": 646,
          "title": "Real-time Attacks Against Deep Reinforcement Learning Policies. (arXiv:2106.08746v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08971",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1\">Fan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alva_S/0/1/0/all/0/1\">Sahan Suresh Alva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiahao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xia Hu</a>",
          "description": "Counterfactuals, serving as one of the emerging type of model\ninterpretations, have recently received attention from both researchers and\npractitioners. Counterfactual explanations formalize the exploration of\n``what-if'' scenarios, and are an instance of example-based reasoning using a\nset of hypothetical data samples. Counterfactuals essentially show how the\nmodel decision alters with input perturbations. Existing methods for generating\ncounterfactuals are mainly algorithm-based, which are time-inefficient and\nassume the same counterfactual universe for different queries. To address these\nlimitations, we propose a Model-based Counterfactual Synthesizer (MCS)\nframework for interpreting machine learning models. We first analyze the\nmodel-based counterfactual process and construct a base synthesizer using a\nconditional generative adversarial net (CGAN). To better approximate the\ncounterfactual universe for those rare queries, we novelly employ the umbrella\nsampling technique to conduct the MCS framework training. Besides, we also\nenhance the MCS framework by incorporating the causal dependence among\nattributes with model inductive bias, and validate its design correctness from\nthe causality identification perspective. Experimental results on several\ndatasets demonstrate the effectiveness as well as efficiency of our proposed\nMCS framework, and verify the advantages compared with other alternatives.",
          "link": "http://arxiv.org/abs/2106.08971",
          "publishedOn": "2021-06-17T01:58:46.798Z",
          "wordCount": 614,
          "title": "Model-Based Counterfactual Synthesizer for Interpretation. (arXiv:2106.08971v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2103.04000",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Hengyuan Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lerer_A/0/1/0/all/0/1\">Adam Lerer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_B/0/1/0/all/0/1\">Brandon Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1\">David Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pineda_L/0/1/0/all/0/1\">Luis Pineda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brown_N/0/1/0/all/0/1\">Noam Brown</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Foerster_J/0/1/0/all/0/1\">Jakob Foerster</a>",
          "description": "The standard problem setting in Dec-POMDPs is self-play, where the goal is to\nfind a set of policies that play optimally together. Policies learned through\nself-play may adopt arbitrary conventions and implicitly rely on multi-step\nreasoning based on fragile assumptions about other agents' actions and thus\nfail when paired with humans or independently trained agents at test time. To\naddress this, we present off-belief learning (OBL). At each timestep OBL agents\nfollow a policy $\\pi_1$ that is optimized assuming past actions were taken by a\ngiven, fixed policy ($\\pi_0$), but assuming that future actions will be taken\nby $\\pi_1$. When $\\pi_0$ is uniform random, OBL converges to an optimal policy\nthat does not rely on inferences based on other agents' behavior (an optimal\ngrounded policy). OBL can be iterated in a hierarchy, where the optimal policy\nfrom one level becomes the input to the next, thereby introducing multi-level\ncognitive reasoning in a controlled manner. Unlike existing approaches, which\nmay converge to any equilibrium policy, OBL converges to a unique policy,\nmaking it suitable for zero-shot coordination (ZSC). OBL can be scaled to\nhigh-dimensional settings with a fictitious transition mechanism and shows\nstrong performance in both a toy-setting and the benchmark human-AI & ZSC\nproblem Hanabi.",
          "link": "http://arxiv.org/abs/2103.04000",
          "publishedOn": "2021-06-17T01:58:46.782Z",
          "wordCount": 657,
          "title": "Off-Belief Learning. (arXiv:2103.04000v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08968",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ray_A/0/1/0/all/0/1\">Arnob Ray</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_T/0/1/0/all/0/1\">Tanujit Chakraborty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_D/0/1/0/all/0/1\">Dibakar Ghosh</a>",
          "description": "The remarkable flexibility and adaptability of both deep learning models and\nensemble methods have led to the proliferation for their application in\nunderstanding many physical phenomena. Traditionally, these two techniques have\nlargely been treated as independent methodologies in practical applications.\nThis study develops an optimized ensemble deep learning (OEDL) framework\nwherein these two machine learning techniques are jointly used to achieve\nsynergistic improvements in model accuracy, stability, scalability, and\nreproducibility prompting a new wave of applications in the forecasting of\ndynamics. Unpredictability is considered as one of the key features of chaotic\ndynamics, so forecasting such dynamics of nonlinear systems is a relevant issue\nin the scientific community. It becomes more challenging when the prediction of\nextreme events is the focus issue for us. In this circumstance, the proposed\nOEDL model based on a best convex combination of feed-forward neural networks,\nreservoir computing, and long short-term memory can play a key role in\nadvancing predictions of dynamics consisting of extreme events. The combined\nframework can generate the best out-of-sample performance than the individual\ndeep learners and standard ensemble framework for both numerically simulated\nand real world data sets. We exhibit the outstanding performance of the OEDL\nframework for forecasting extreme events generated from Lienard-type system,\nprediction of COVID-19 cases in Brazil, dengue cases in San Juan, and sea\nsurface temperature in Nino 3.4 region.",
          "link": "http://arxiv.org/abs/2106.08968",
          "publishedOn": "2021-06-17T01:58:46.776Z",
          "wordCount": 710,
          "title": "Optimized ensemble deep learning framework for scalable forecasting of dynamics containing extreme events. (arXiv:2106.08968v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2012.09421",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zimmer_M/0/1/0/all/0/1\">Matthieu Zimmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glanois_C/0/1/0/all/0/1\">Claire Glanois</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siddique_U/0/1/0/all/0/1\">Umer Siddique</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weng_P/0/1/0/all/0/1\">Paul Weng</a>",
          "description": "We consider the problem of learning fair policies in (deep) cooperative\nmulti-agent reinforcement learning (MARL). We formalize it in a principled way\nas the problem of optimizing a welfare function that explicitly encodes two\nimportant aspects of fairness: efficiency and equity. As a solution method, we\npropose a novel neural network architecture, which is composed of two\nsub-networks specifically designed for taking into account the two aspects of\nfairness. In experiments, we demonstrate the importance of the two sub-networks\nfor fair optimization. Our overall approach is general as it can accommodate\nany (sub)differentiable welfare function. Therefore, it is compatible with\nvarious notions of fairness that have been proposed in the literature (e.g.,\nlexicographic maximin, generalized Gini social welfare function, proportional\nfairness). Our solution method is generic and can be implemented in various\nMARL settings: centralized training and decentralized execution, or fully\ndecentralized. Finally, we experimentally validate our approach in various\ndomains and show that it can perform much better than previous methods.",
          "link": "http://arxiv.org/abs/2012.09421",
          "publishedOn": "2021-06-17T01:58:46.767Z",
          "wordCount": 638,
          "title": "Learning Fair Policies in Decentralized Cooperative Multi-Agent Reinforcement Learning. (arXiv:2012.09421v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08928",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ennis_M/0/1/0/all/0/1\">Michaela Ennis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kozachkov_L/0/1/0/all/0/1\">Leo Kozachkov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Slotine_J/0/1/0/all/0/1\">Jean-Jacques Slotine</a>",
          "description": "Advanced applications of modern machine learning will likely involve\ncombinations of trained networks, as are already used in spectacular systems\nsuch as DeepMind's AlphaGo. Recursively building such combinations in an\neffective and stable fashion while also allowing for continual refinement of\nthe individual networks - as nature does for biological networks - will require\nnew analysis tools. This paper takes a step in this direction by establishing\ncontraction properties of broad classes of nonlinear recurrent networks and\nneural ODEs, and showing how these quantified properties allow in turn to\nrecursively construct stable networks of networks in a systematic fashion. The\nresults can also be used to stably combine recurrent networks and physical\nsystems with quantified contraction properties. Similarly, they may be applied\nto modular computational models of cognition.",
          "link": "http://arxiv.org/abs/2106.08928",
          "publishedOn": "2021-06-17T01:58:46.760Z",
          "wordCount": 567,
          "title": "Recursive Construction of Stable Assemblies of Recurrent Neural Networks. (arXiv:2106.08928v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08914",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Le_H/0/1/0/all/0/1\">Hung Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1\">Nancy F. Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoi_S/0/1/0/all/0/1\">Steven C.H. Hoi</a>",
          "description": "Video-grounded dialogue systems aim to integrate video understanding and\ndialogue understanding to generate responses that are relevant to both the\ndialogue and video context. Most existing approaches employ deep learning\nmodels and have achieved remarkable performance, given the relatively small\ndatasets available. However, the results are partly accomplished by exploiting\nbiases in the datasets rather than developing multimodal reasoning, resulting\nin limited generalization. In this paper, we propose a novel approach of\nCompositional Counterfactual Contrastive Learning ($C^3$) to develop\ncontrastive training between factual and counterfactual samples in\nvideo-grounded dialogues. Specifically, we design factual/counterfactual\nsampling based on the temporal steps in videos and tokens in dialogues and\npropose contrastive loss functions that exploit object-level or action-level\nvariance. Different from prior approaches, we focus on contrastive hidden state\nrepresentations among compositional output tokens to optimize the\nrepresentation space in a generation setting. We achieved promising performance\ngains on the Audio-Visual Scene-Aware Dialogues (AVSD) benchmark and showed the\nbenefits of our approach in grounding video and dialogue context.",
          "link": "http://arxiv.org/abs/2106.08914",
          "publishedOn": "2021-06-17T01:58:46.725Z",
          "wordCount": 608,
          "title": "$C^3$: Compositional Counterfactual Constrastive Learning for Video-grounded Dialogues. (arXiv:2106.08914v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08961",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_N/0/1/0/all/0/1\">Nan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1\">Zepeng Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jianfeng Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Askari_H/0/1/0/all/0/1\">Hassan Askari</a>",
          "description": "Estimation of the longitudinal slip ratio of tires is important in boosting\nthe control performance of the vehicle under driving and braking conditions. In\nthis paper, the slip ratio is estimated using four machine learning algorithms\n(Neural Network, Gradient Boosting Machine, Random Forest and Support Vector\nMachine) based on the acceleration signals from the tri-axial MEMS\naccelerometers utilized in the intelligent tire system. The experimental data\nare collected through the MTS experimental platform. The corresponding\nacceleration signals within the tire contact patch are extracted after\nfiltering to be used for the training the aforesaid machine learning\nalgorithms. A comparison is provided between the implemented ML algorithms\nusing a 10-fold CV. NRMS errors in the CV results indicate that NN has the\nhighest accuracy in comparison with other techniques. The NRSM errors of NN,\nGBM, RF, and SVM are 2.59\\%, 3.30\\%, 4.21\\%, and 5.34\\%, respectively. Among\nthese techniques, GBM has a more stable results as it has the smallest output\nvariance. The present study with the fusion of intelligent tire system and\nmachine learning algorithms paves the way for the accurate estimation of tire\nslip ratio, which is critical for the development of reliable vehicle control\nalgorithms.",
          "link": "http://arxiv.org/abs/2106.08961",
          "publishedOn": "2021-06-17T01:58:46.709Z",
          "wordCount": 631,
          "title": "Intelligent Tire-Based Slip Ratio Estimation Using Different Machine Learning Algorithms. (arXiv:2106.08961v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08855",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Beugnot_G/0/1/0/all/0/1\">Gaspard Beugnot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mairal_J/0/1/0/all/0/1\">Julien Mairal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rudi_A/0/1/0/all/0/1\">Alessandro Rudi</a>",
          "description": "The theory of spectral filtering is a remarkable tool to understand the\nstatistical properties of learning with kernels. For least squares, it allows\nto derive various regularization schemes that yield faster convergence rates of\nthe excess risk than with Tikhonov regularization. This is typically achieved\nby leveraging classical assumptions called source and capacity conditions,\nwhich characterize the difficulty of the learning task. In order to understand\nestimators derived from other loss functions, Marteau-Ferey et al. have\nextended the theory of Tikhonov regularization to generalized self concordant\nloss functions (GSC), which contain, e.g., the logistic loss. In this paper, we\ngo a step further and show that fast and optimal rates can be achieved for GSC\nby using the iterated Tikhonov regularization scheme, which is intrinsically\nrelated to the proximal point method in optimization, and overcomes the\nlimitation of the classical Tikhonov regularization.",
          "link": "http://arxiv.org/abs/2106.08855",
          "publishedOn": "2021-06-17T01:58:46.703Z",
          "wordCount": 578,
          "title": "Beyond Tikhonov: Faster Learning with Self-Concordant Losses via Iterative Regularization. (arXiv:2106.08855v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08901",
          "author": "<a href=\"http://arxiv.org/find/econ/1/au:+Hopp_D/0/1/0/all/0/1\">Daniel Hopp</a>",
          "description": "Artificial neural networks (ANNs) have been the catalyst to numerous advances\nin a variety of fields and disciplines in recent years. Their impact on\neconomics, however, has been comparatively muted. One type of ANN, the long\nshort-term memory network (LSTM), is particularly wellsuited to deal with\neconomic time-series. Here, the architecture's performance and characteristics\nare evaluated in comparison with the dynamic factor model (DFM), currently a\npopular choice in the field of economic nowcasting. LSTMs are found to produce\nsuperior results to DFMs in the nowcasting of three separate variables; global\nmerchandise export values and volumes, and global services exports. Further\nadvantages include their ability to handle large numbers of input features in a\nvariety of time frequencies. A disadvantage is the inability to ascribe\ncontributions of input features to model outputs, common to all ANNs. In order\nto facilitate continued applied research of the methodology by avoiding the\nneed for any knowledge of deep-learning libraries, an accompanying Python\nlibrary was developed using PyTorch, https://pypi.org/project/nowcast-lstm/.",
          "link": "http://arxiv.org/abs/2106.08901",
          "publishedOn": "2021-06-17T01:58:46.697Z",
          "wordCount": 594,
          "title": "Economic Nowcasting with Long Short-Term Memory Artificial Neural Networks (LSTM). (arXiv:2106.08901v1 [econ.EM])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08888",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Petri_G/0/1/0/all/0/1\">Guido Petri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stanley_M/0/1/0/all/0/1\">Michael H. Stanley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hon_A/0/1/0/all/0/1\">Alec B. Hon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_A/0/1/0/all/0/1\">Alexander Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xenopoulos_P/0/1/0/all/0/1\">Peter Xenopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silva_C/0/1/0/all/0/1\">Cl&#xe1;udio Silva</a>",
          "description": "Many esports use a pick and ban process to define the parameters of a match\nbefore it starts. In Counter-Strike: Global Offensive (CSGO) matches, two teams\nfirst pick and ban maps, or virtual worlds, to play. Teams typically ban and\npick maps based on a variety of factors, such as banning maps which they do not\npractice, or choosing maps based on the team's recent performance. We introduce\na contextual bandit framework to tackle the problem of map selection in CSGO\nand to investigate teams' pick and ban decision-making. Using a data set of\nover 3,500 CSGO matches and over 25,000 map selection decisions, we consider\ndifferent framings for the problem, different contexts, and different reward\nmetrics. We find that teams have suboptimal map choice policies with respect to\nboth picking and banning. We also define an approach for rewarding bans, which\nhas not been explored in the bandit setting, and find that incorporating ban\nrewards improves model performance. Finally, we determine that usage of our\nmodel could improve teams' predicted map win probability by up to 11% and raise\noverall match win probabilities by 19.8% for evenly-matched teams.",
          "link": "http://arxiv.org/abs/2106.08888",
          "publishedOn": "2021-06-17T01:58:46.673Z",
          "wordCount": 632,
          "title": "Bandit Modeling of Map Selection in Counter-Strike: Global Offensive. (arXiv:2106.08888v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2103.00039",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kairouz_P/0/1/0/all/0/1\">Peter Kairouz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McMahan_B/0/1/0/all/0/1\">Brendan McMahan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1\">Shuang Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thakkar_O/0/1/0/all/0/1\">Om Thakkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thakurta_A/0/1/0/all/0/1\">Abhradeep Thakurta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zheng Xu</a>",
          "description": "We consider training models with differential privacy (DP) using mini-batch\ngradients. The existing state-of-the-art, Differentially Private Stochastic\nGradient Descent (DP-SGD), requires privacy amplification by sampling or\nshuffling to obtain the best privacy/accuracy/computation trade-offs.\nUnfortunately, the precise requirements on exact sampling and shuffling can be\nhard to obtain in important practical scenarios, particularly federated\nlearning (FL). We design and analyze a DP variant of\nFollow-The-Regularized-Leader (DP-FTRL) that compares favorably (both\ntheoretically and empirically) to amplified DP-SGD, while allowing for much\nmore flexible data access patterns. DP-FTRL does not use any form of privacy\namplification.\n\nThe code is available at\nhttps://github.com/google-research/federated/tree/master/dp_ftrl and\nhttps://github.com/google-research/DP-FTRL .",
          "link": "http://arxiv.org/abs/2103.00039",
          "publishedOn": "2021-06-17T01:58:46.610Z",
          "wordCount": 572,
          "title": "Practical and Private (Deep) Learning without Sampling or Shuffling. (arXiv:2103.00039v2 [cs.CR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08970",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Souri_H/0/1/0/all/0/1\">Hossein Souri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldblum_M/0/1/0/all/0/1\">Micah Goldblum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fowl_L/0/1/0/all/0/1\">Liam Fowl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chellappa_R/0/1/0/all/0/1\">Rama Chellappa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1\">Tom Goldstein</a>",
          "description": "As the curation of data for machine learning becomes increasingly automated,\ndataset tampering is a mounting threat. Backdoor attackers tamper with training\ndata to embed a vulnerability in models that are trained on that data. This\nvulnerability is then activated at inference time by placing a \"trigger\" into\nthe model's input. Typical backdoor attacks insert the trigger directly into\nthe training data, although the presence of such an attack may be visible upon\ninspection. In contrast, the Hidden Trigger Backdoor Attack achieves poisoning\nwithout placing a trigger into the training data at all. However, this hidden\ntrigger attack is ineffective at poisoning neural networks trained from\nscratch. We develop a new hidden trigger attack, Sleeper Agent, which employs\ngradient matching, data selection, and target model re-training during the\ncrafting process. Sleeper Agent is the first hidden trigger backdoor attack to\nbe effective against neural networks trained from scratch. We demonstrate its\neffectiveness on ImageNet and in black-box settings. Our implementation code\ncan be found at https://github.com/hsouri/Sleeper-Agent.",
          "link": "http://arxiv.org/abs/2106.08970",
          "publishedOn": "2021-06-17T01:58:46.568Z",
          "wordCount": 613,
          "title": "Sleeper Agent: Scalable Hidden Trigger Backdoors for Neural Networks Trained from Scratch. (arXiv:2106.08970v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2012.15492",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zengin_R/0/1/0/all/0/1\">Rahman Salim Zengin</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Sezer_V/0/1/0/all/0/1\">Volkan Sezer</a> (1) ((1) Istanbul Technical University)",
          "description": "Voronoi tessellations are used to partition the Euclidean space into\npolyhedral regions, which are called Voronoi cells. Labeling the Voronoi cells\nwith the class information, we can map any classification problem into a\nVoronoi tessellation. In this way, the classification problem changes into a\nquery of just finding the enclosing Voronoi cell. In order to accomplish this\ntask, we have developed a new algorithm which generates a labeled Voronoi\ntessellation that partitions the training data into polyhedral regions and\nobtains interclass boundaries as an indirect result. It is called Supervised\nk-Voxels or in short Super-k. We are introducing Super-k as a foundational new\nalgorithm and opening the possibility of a new family of algorithms. In this\npaper, it is shown via comparisons on certain datasets that the Super-k\nalgorithm has the potential of providing comparable performance of the\nwell-known SVM family of algorithms with less complexity.",
          "link": "http://arxiv.org/abs/2012.15492",
          "publishedOn": "2021-06-17T01:58:46.497Z",
          "wordCount": 625,
          "title": "Super-k: A Piecewise Linear Classifier Based on Voronoi Tessellations. (arXiv:2012.15492v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.06706",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yuhao Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qing_Y/0/1/0/all/0/1\">Ye Qing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_J/0/1/0/all/0/1\">Jiancheng Lv</a>",
          "description": "Petabytes of data are generated each day by emerging Internet of Things\n(IoT), but only few of them can be finally collected and used for Machine\nLearning (ML) purposes due to the apprehension of data & privacy leakage, which\nseriously retarding ML's growth. To alleviate this problem, Federated learning\nis proposed to perform model training by multiple clients' combined data\nwithout the dataset sharing within the cluster. Nevertheless, federated\nlearning introduces massive communication overhead as the synchronized data in\neach epoch is of the same size as the model, and thereby leading to a low\ncommunication efficiency. Consequently, variant methods mainly focusing on the\ncommunication rounds reduction and data compression are proposed to reduce the\ncommunication overhead of federated learning. In this paper, we propose\nOverlap-FedAvg, a framework that parallels the model training phase with model\nuploading & downloading phase, so that the latter phase can be totally covered\nby the former phase. Compared to vanilla FedAvg, Overlap-FedAvg is further\ndeveloped with a hierarchical computing strategy, a data compensation mechanism\nand a nesterov accelerated gradients~(NAG) algorithm. Besides, Overlap-FedAvg\nis orthogonal to many other compression methods so that they can be applied\ntogether to maximize the utilization of the cluster. Furthermore, the\ntheoretical analysis is provided to prove the convergence of the proposed\nOverlap-FedAvg framework. Extensive experiments on both conventional and\nrecurrent tasks with multiple models and datasets also demonstrate that the\nproposed Overlap-FedAvg framework substantially boosts the federated learning\nprocess.",
          "link": "http://arxiv.org/abs/2012.06706",
          "publishedOn": "2021-06-17T01:58:46.455Z",
          "wordCount": 698,
          "title": "Communication-Efficient Federated Learning with Compensated Overlap-FedAvg. (arXiv:2012.06706v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.09899",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuhang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_F/0/1/0/all/0/1\">Feng Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_R/0/1/0/all/0/1\">Ruihao Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_M/0/1/0/all/0/1\">Mingzhu Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1\">Xin Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1\">Fengwei Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1\">Shaoqing Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_S/0/1/0/all/0/1\">Shi Gu</a>",
          "description": "User data confidentiality protection is becoming a rising challenge in the\npresent deep learning research. Without access to data, conventional\ndata-driven model compression faces a higher risk of performance degradation.\nRecently, some works propose to generate images from a specific pretrained\nmodel to serve as training data. However, the inversion process only utilizes\nbiased feature statistics stored in one model and is from low-dimension to\nhigh-dimension. As a consequence, it inevitably encounters the difficulties of\ngeneralizability and inexact inversion, which leads to unsatisfactory\nperformance. To address these problems, we propose MixMix based on two simple\nyet effective techniques: (1) Feature Mixing: utilizes various models to\nconstruct a universal feature space for generalized inversion; (2) Data Mixing:\nmixes the synthesized images and labels to generate exact label information. We\nprove the effectiveness of MixMix from both theoretical and empirical\nperspectives. Extensive experiments show that MixMix outperforms existing\nmethods on the mainstream compression tasks, including quantization, knowledge\ndistillation, and pruning. Specifically, MixMix achieves up to 4% and 20%\naccuracy uplift on quantization and pruning, respectively, compared to existing\ndata-free compression work.",
          "link": "http://arxiv.org/abs/2011.09899",
          "publishedOn": "2021-06-17T01:58:46.236Z",
          "wordCount": null,
          "title": "MixMix: All You Need for Data-Free Compression Are Feature and Data Mixing. (arXiv:2011.09899v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03609",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Grosnit_A/0/1/0/all/0/1\">Antoine Grosnit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tutunov_R/0/1/0/all/0/1\">Rasul Tutunov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maraval_A/0/1/0/all/0/1\">Alexandre Max Maraval</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Griffiths_R/0/1/0/all/0/1\">Ryan-Rhys Griffiths</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cowen_Rivers_A/0/1/0/all/0/1\">Alexander I. Cowen-Rivers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Lin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1\">Lin Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_W/0/1/0/all/0/1\">Wenlong Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhitang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peters_J/0/1/0/all/0/1\">Jan Peters</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bou_Ammar_H/0/1/0/all/0/1\">Haitham Bou-Ammar</a>",
          "description": "We introduce a method based on deep metric learning to perform Bayesian\noptimisation over high-dimensional, structured input spaces using variational\nautoencoders (VAEs). By extending ideas from supervised deep metric learning,\nwe address a longstanding problem in high-dimensional VAE Bayesian\noptimisation, namely how to enforce a discriminative latent space as an\ninductive bias. Importantly, we achieve such an inductive bias using just 1% of\nthe available labelled data relative to previous work, highlighting the sample\nefficiency of our approach. As a theoretical contribution, we present a proof\nof vanishing regret for our method. As an empirical contribution, we present\nstate-of-the-art results on real-world high-dimensional black-box optimisation\nproblems including property-guided molecule generation. It is the hope that the\nresults presented in this paper can act as a guiding principle for realising\neffective high-dimensional Bayesian optimisation.",
          "link": "http://arxiv.org/abs/2106.03609",
          "publishedOn": "2021-06-17T01:58:46.235Z",
          "wordCount": null,
          "title": "High-Dimensional Bayesian Optimisation with Variational Autoencoders and Deep Metric Learning. (arXiv:2106.03609v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.01933",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Grieger_N/0/1/0/all/0/1\">Niklas Grieger</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Schwabedal_J/0/1/0/all/0/1\">Justus T. C. Schwabedal</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Wendel_S/0/1/0/all/0/1\">Stefanie Wendel</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ritze_Y/0/1/0/all/0/1\">Yvonne Ritze</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Bialonski_S/0/1/0/all/0/1\">Stephan Bialonski</a>",
          "description": "Reliable automation of the labor-intensive manual task of scoring animal\nsleep can facilitate the analysis of long-term sleep studies. In recent years,\ndeep-learning-based systems, which learn optimal features from the data,\nincreased scoring accuracies for the classical sleep stages of Wake, REM, and\nNon-REM. Meanwhile, it has been recognized that the statistics of transitional\nstages such as pre-REM, found between Non-REM and REM, may hold additional\ninsight into the physiology of sleep and are now under vivid investigation. We\npropose a classification system based on a simple neural network architecture\nthat scores the classical stages as well as pre-REM sleep in mice. When\nrestricted to the classical stages, the optimized network showed\nstate-of-the-art classification performance with an out-of-sample F1 score of\n0.95 in male C57BL/6J mice. When unrestricted, the network showed lower F1\nscores on pre-REM (0.5) compared to the classical stages. The result is\ncomparable to previous attempts to score transitional stages in other species\nsuch as transition sleep in rats or N1 sleep in humans. Nevertheless, we\nobserved that the sequence of predictions including pre-REM typically\ntransitioned from Non-REM to REM reflecting sleep dynamics observed by human\nscorers. Our findings provide further evidence for the difficulty of scoring\ntransitional sleep stages, likely because such stages of sleep are\nunder-represented in typical data sets or show large inter-scorer variability.\nWe further provide our source code and an online platform to run predictions\nwith our trained network.",
          "link": "http://arxiv.org/abs/2105.01933",
          "publishedOn": "2021-06-17T01:58:46.222Z",
          "wordCount": 715,
          "title": "Automated scoring of pre-REM sleep in mice with deep learning. (arXiv:2105.01933v2 [q-bio.QM] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.08262",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Illing_B/0/1/0/all/0/1\">Bernd Illing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ventura_J/0/1/0/all/0/1\">Jean Ventura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bellec_G/0/1/0/all/0/1\">Guillaume Bellec</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gerstner_W/0/1/0/all/0/1\">Wulfram Gerstner</a>",
          "description": "Learning in the brain is poorly understood and learning rules that respect\nbiological constraints, yet yield deep hierarchical representations, are still\nunknown. Here, we propose a learning rule that takes inspiration from\nneuroscience and recent advances in self-supervised deep learning. Learning\nminimizes a simple layer-specific loss function and does not need to\nback-propagate error signals within or between layers. Instead, weight updates\nfollow a local, Hebbian, learning rule that only depends on pre- and\npost-synaptic neuronal activity, predictive dendritic input and widely\nbroadcasted modulation factors which are identical for large groups of neurons.\nThe learning rule applies contrastive predictive learning to a causal,\nbiological setting using saccades (i.e. rapid shifts in gaze direction). We\nfind that networks trained with this self-supervised and local rule build deep\nhierarchical representations of images, speech and video.",
          "link": "http://arxiv.org/abs/2010.08262",
          "publishedOn": "2021-06-17T01:58:46.215Z",
          "wordCount": null,
          "title": "Local plasticity rules can learn deep representations using self-supervised contrastive predictions. (arXiv:2010.08262v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06998",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Louboutin_M/0/1/0/all/0/1\">Mathias Louboutin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siahkoohi_A/0/1/0/all/0/1\">Ali Siahkoohi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rongrong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Herrmann_F/0/1/0/all/0/1\">Felix J. Herrmann</a>",
          "description": "Thanks to the combination of state-of-the-art accelerators and highly\noptimized open software frameworks, there has been tremendous progress in the\nperformance of deep neural networks. While these developments have been\nresponsible for many breakthroughs, progress towards solving large-scale\nproblems, such as video encoding and semantic segmentation in 3D, is hampered\nbecause access to on-premise memory is often limited. Instead of relying on\n(optimal) checkpointing or invertibility of the network layers -- to recover\nthe activations during backpropagation -- we propose to approximate the\ngradient of convolutional layers in neural networks with a multi-channel\nrandomized trace estimation technique. Compared to other methods, this approach\nis simple, amenable to analyses, and leads to a greatly reduced memory\nfootprint. Even though the randomized trace estimation introduces stochasticity\nduring training, we argue that this is of little consequence as long as the\ninduced errors are of the same order as errors in the gradient due to the use\nof stochastic gradient descent. We discuss the performance of networks trained\nwith stochastic backpropagation and how the error can be controlled while\nmaximizing memory usage and minimizing computational overhead.",
          "link": "http://arxiv.org/abs/2106.06998",
          "publishedOn": "2021-06-17T01:58:46.215Z",
          "wordCount": null,
          "title": "Low-memory stochastic backpropagation with multi-channel randomized trace estimation. (arXiv:2106.06998v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1910.09991",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fausti_F/0/1/0/all/0/1\">Fabrizio De Fausti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pugliese_F/0/1/0/all/0/1\">Francesco Pugliese</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zardetto_D/0/1/0/all/0/1\">Diego Zardetto</a>",
          "description": "In recent years, the interest in Big Data sources has been steadily growing\nwithin the Official Statistic community. The Italian National Institute of\nStatistics (Istat) is currently carrying out several Big Data pilot studies.\nOne of these studies, the ICT Big Data pilot, aims at exploiting massive\namounts of textual data automatically scraped from the websites of Italian\nenterprises in order to predict a set of target variables (e.g. e-commerce)\nthat are routinely observed by the traditional ICT Survey. In this paper, we\nshow that Deep Learning techniques can successfully address this problem.\nEssentially, we tackle a text classification task: an algorithm must learn to\ninfer whether an Italian enterprise performs e-commerce from the textual\ncontent of its website. To reach this goal, we developed a sophisticated\nprocessing pipeline and evaluated its performance through extensive\nexperiments. Our pipeline uses Convolutional Neural Networks and relies on Word\nEmbeddings to encode raw texts into grayscale images (i.e. normalized numeric\nmatrices). Web-scraped texts are huge and have very low signal to noise ratio:\nto overcome these issues, we adopted a framework known as False Positive\nReduction, which has seldom (if ever) been applied before to text\nclassification tasks. Several original contributions enable our processing\npipeline to reach good classification results. Empirical evidence shows that\nour proposal outperforms all the alternative Machine Learning solutions already\ntested in Istat for the same task.",
          "link": "http://arxiv.org/abs/1910.09991",
          "publishedOn": "2021-06-17T01:58:46.203Z",
          "wordCount": 714,
          "title": "Towards Automated Website Classification by Deep Learning. (arXiv:1910.09991v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1908.05978",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lisboa_P/0/1/0/all/0/1\">Paulo J. G. Lisboa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ortega_Martorell_S/0/1/0/all/0/1\">Sandra Ortega-Martorell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cashman_S/0/1/0/all/0/1\">Sadie Cashman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Olier_I/0/1/0/all/0/1\">Ivan Olier</a>",
          "description": "Among interpretable machine learning methods, the class of Generalised\nAdditive Neural Networks (GANNs) is referred to as Self-Explaining Neural\nNetworks (SENN) because of the linear dependence on explicit functions of the\ninputs. In binary classification this shows the precise weight that each input\ncontributes towards the logit. The nomogram is a graphical representation of\nthese weights. We show that functions of individual and pairs of variables can\nbe derived from a functional Analysis of Variance (ANOVA) representation,\nenabling an efficient feature selection to be carried by application of the\nlogistic Lasso. This process infers the structure of GANNs which otherwise\nneeds to be predefined. As this method is particularly suited for tabular data,\nit starts by fitting a generic flexible model, in this case a Multi-layer\nPerceptron (MLP) to which the ANOVA decomposition is applied. This has the\nfurther advantage that the resulting GANN can be replicated as a SENN, enabling\nfurther refinement of the univariate and bivariate component functions to take\nplace. The component functions are partial responses hence the SENN is a\npartial response network. The Partial Response Network (PRN) is equally as\ntransparent as a traditional logistic regression model, but capable of\nnon-linear classification with comparable or superior performance to the\noriginal MLP. In other words, the PRN is a fully interpretable representation\nof the MLP, at the level of univariate and bivariate effects. The performance\nof the PRN is shown to be competitive for benchmark data, against\nstate-of-the-art machine learning methods including GBM, SVM and Random\nForests. It is also compared with spline-based Sparse Additive Models (SAM)\nshowing that a semi-parametric representation of the GAM as a neural network\ncan be as effective as the SAM though less constrained by the need to set\nspline nodes.",
          "link": "http://arxiv.org/abs/1908.05978",
          "publishedOn": "2021-06-17T01:58:46.197Z",
          "wordCount": null,
          "title": "The Partial Response Network: a neural network nomogram. (arXiv:1908.05978v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08918",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Grigsby_J/0/1/0/all/0/1\">Jake Grigsby</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoo_J/0/1/0/all/0/1\">Jin Yong Yoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_Y/0/1/0/all/0/1\">Yanjun Qi</a>",
          "description": "Model-free off-policy actor-critic methods are an efficient solution to\ncomplex continuous control tasks. However, these algorithms rely on a number of\ndesign tricks and many hyperparameters, making their applications to new\ndomains difficult and computationally expensive. This paper creates an\nevolutionary approach that automatically tunes these design decisions and\neliminates the RL-specific hyperparameters from the Soft Actor-Critic\nalgorithm. Our design is sample efficient and provides practical advantages\nover baseline approaches, including improved exploration, generalization over\nmultiple control frequencies, and a robust ensemble of high-performance\npolicies. Empirically, we show that our agent outperforms well-tuned\nhyperparameter settings in popular benchmarks from the DeepMind Control Suite.\nWe then apply it to new control tasks to find high-performance solutions with\nminimal compute and research effort.",
          "link": "http://arxiv.org/abs/2106.08918",
          "publishedOn": "2021-06-17T01:58:46.195Z",
          "wordCount": null,
          "title": "Towards Automatic Actor-Critic Solutions to Continuous Control. (arXiv:2106.08918v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2103.06759",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Seker_M/0/1/0/all/0/1\">Mert Seker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mannisto_A/0/1/0/all/0/1\">Anssi M&#xe4;nnist&#xf6;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iosifidis_A/0/1/0/all/0/1\">Alexandros Iosifidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raitoharju_J/0/1/0/all/0/1\">Jenni Raitoharju</a>",
          "description": "The COVID-19 virus has caused a global pandemic since March 2020. The World\nHealth Organization (WHO) has provided guidelines on how to reduce the spread\nof the virus and one of the most important measures is social distancing.\nMaintaining a minimum of one meter distance from other people is strongly\nsuggested to reduce the risk of infection. This has created a strong interest\nin monitoring the social distances either as a safety measure or to study how\nthe measures have affected human behavior and country-wise differences in this.\nThe need for automatic social distance estimation algorithms is evident, but\nthere is no suitable test benchmark for such algorithms. Collecting images with\nmeasured ground-truth pair-wise distances between all the people using\ndifferent camera settings is cumbersome. Furthermore, performance evaluation\nfor social distance estimation algorithms is not straightforward and there is\nno widely accepted evaluation protocol. In this paper, we provide a dataset of\nvarying images with measured pair-wise social distances under different camera\npositionings and focal length values. We suggest a performance evaluation\nprotocol and provide a benchmark to easily evaluate social distance estimation\nalgorithms. We also propose a method for automatic social distance estimation.\nOur method takes advantage of object detection and human pose estimation. It\ncan be applied on any single image as long as focal length and sensor size\ninformation are known. The results on our benchmark are encouraging with 92%\nhuman detection rate and only 28.9% average error in distance estimation among\nthe detected people.",
          "link": "http://arxiv.org/abs/2103.06759",
          "publishedOn": "2021-06-17T01:58:46.187Z",
          "wordCount": 774,
          "title": "Automatic Social Distance Estimation From Images: Performance Evaluation, Test Benchmark, and Algorithm. (arXiv:2103.06759v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08505",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lanlan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuting Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1\">Jia Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1\">Stefano Soatto</a>",
          "description": "Recent work introduced progressive network growing as a promising way to ease\nthe training for large GANs, but the model design and architecture-growing\nstrategy still remain under-explored and needs manual design for different\nimage data. In this paper, we propose a method to dynamically grow a GAN during\ntraining, optimizing the network architecture and its parameters together with\nautomation. The method embeds architecture search techniques as an interleaving\nstep with gradient-based training to periodically seek the optimal\narchitecture-growing strategy for the generator and discriminator. It enjoys\nthe benefits of both eased training because of progressive growing and improved\nperformance because of broader architecture design space. Experimental results\ndemonstrate new state-of-the-art of image generation. Observations in the\nsearch procedure also provide constructive insights into the GAN model design\nsuch as generator-discriminator balance and convolutional layer choices.",
          "link": "http://arxiv.org/abs/2106.08505",
          "publishedOn": "2021-06-17T01:58:46.180Z",
          "wordCount": 567,
          "title": "Dynamically Grown Generative Adversarial Networks. (arXiv:2106.08505v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08900",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gonon_L/0/1/0/all/0/1\">Lukas Gonon</a>",
          "description": "This article investigates the use of random feature neural networks for\nlearning Kolmogorov partial (integro-)differential equations associated to\nBlack-Scholes and more general exponential L\\'evy models. Random feature neural\nnetworks are single-hidden-layer feedforward neural networks in which only the\noutput weights are trainable. This makes training particularly simple, but (a\npriori) reduces expressivity. Interestingly, this is not the case for\nBlack-Scholes type PDEs, as we show here. We derive bounds for the prediction\nerror of random neural networks for learning sufficiently non-degenerate\nBlack-Scholes type models. A full error analysis is provided and it is shown\nthat the derived bounds do not suffer from the curse of dimensionality. We also\ninvestigate an application of these results to basket options and validate the\nbounds numerically.\n\nThese results prove that neural networks are able to \\textit{learn} solutions\nto Black-Scholes type PDEs without the curse of dimensionality. In addition,\nthis provides an example of a relevant learning problem in which random feature\nneural networks are provably efficient.",
          "link": "http://arxiv.org/abs/2106.08900",
          "publishedOn": "2021-06-17T01:58:46.167Z",
          "wordCount": null,
          "title": "Random feature neural networks learn Black-Scholes type PDEs without curse of dimensionality. (arXiv:2106.08900v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08601",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hou_L/0/1/0/all/0/1\">Liang Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1\">Huawei Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Q/0/1/0/all/0/1\">Qi Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1\">Xueqi Cheng</a>",
          "description": "Recently, transformation-based self-supervised learning has been applied to\ngenerative adversarial networks (GANs) to mitigate the catastrophic forgetting\nproblem of discriminator by learning stable representations. However, the\nseparate self-supervised tasks in existing self-supervised GANs cause an\ninconsistent goal with generative modeling due to the learning of the generator\nfrom their generator distribution-agnostic classifiers. To address this issue,\nwe propose a novel self-supervised GANs framework with label augmentation,\ni.e., augmenting the GAN labels (real or fake) with the self-supervised\npseudo-labels. In particular, the discriminator and the self-supervised\nclassifier are unified to learn a single task that predicts the augmented label\nsuch that the discriminator/classifier is aware of the generator distribution,\nwhile the generator tries to confuse the discriminator/classifier by optimizing\nthe discrepancy between the transformed real and generated distributions.\nTheoretically, we prove that the generator, at the equilibrium point, converges\nto replicate the data distribution. Empirically, we demonstrate that the\nproposed method significantly outperforms competitive baselines on both\ngenerative modeling and representation learning across benchmark datasets.",
          "link": "http://arxiv.org/abs/2106.08601",
          "publishedOn": "2021-06-17T01:58:46.166Z",
          "wordCount": 582,
          "title": "Self-supervised GANs with Label Augmentation. (arXiv:2106.08601v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08685",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chiu_C/0/1/0/all/0/1\">Ching-Yu Chiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_A/0/1/0/all/0/1\">Alvin Wen-Yu Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yi-Hsuan Yang</a>",
          "description": "This paper presents a novel system architecture that integrates blind source\nseparation with joint beat and downbeat tracking in musical audio signals. The\nsource separation module segregates the percussive and non-percussive\ncomponents of the input signal, over which beat and downbeat tracking are\nperformed separately and then the results are aggregated with a learnable\nfusion mechanism. This way, the system can adaptively determine how much the\ntracking result for an input signal should depend on the input's percussive or\nnon-percussive components. Evaluation on four testing sets that feature\ndifferent levels of presence of drum sounds shows that the new architecture\nconsistently outperforms the widely-adopted baseline architecture that does not\nemploy source separation.",
          "link": "http://arxiv.org/abs/2106.08685",
          "publishedOn": "2021-06-17T01:58:46.160Z",
          "wordCount": null,
          "title": "Drum-Aware Ensemble Architecture for Improved Joint Musical Beat and Downbeat Tracking. (arXiv:2106.08685v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08551",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Meng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1\">Cong Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Limei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yaochen Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1\">Hao Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Youzhi Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zhao Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shenglong Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1\">Shuiwang Ji</a>",
          "description": "Molecular property prediction is gaining increasing attention due to its\ndiverse applications. One task of particular interests and importance is to\npredict quantum chemical properties without 3D equilibrium structures. This is\npractically favorable since obtaining 3D equilibrium structures requires\nextremely expensive calculations. In this work, we design a deep graph neural\nnetwork to predict quantum properties by directly learning from 2D molecular\ngraphs. In addition, we propose a 3D graph neural network to learn from\nlow-cost conformer sets, which can be obtained with open-source tools using an\naffordable budget. We employ our methods to participate in the 2021 KDD Cup on\nOGB Large-Scale Challenge (OGB-LSC), which aims to predict the HOMO-LUMO energy\ngap of molecules. Final evaluation results reveal that we are one of the\nwinners with a mean absolute error of 0.1235 on the holdout test set. Our\nimplementation is available as part of the MoleculeX package\n(https://github.com/divelab/MoleculeX).",
          "link": "http://arxiv.org/abs/2106.08551",
          "publishedOn": "2021-06-17T01:58:46.159Z",
          "wordCount": 606,
          "title": "Fast Quantum Property Prediction via Deeper 2D and 3D Graph Networks. (arXiv:2106.08551v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2104.02748",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ro_J/0/1/0/all/0/1\">Jae Ro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Mingqing Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mathews_R/0/1/0/all/0/1\">Rajiv Mathews</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohri_M/0/1/0/all/0/1\">Mehryar Mohri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suresh_A/0/1/0/all/0/1\">Ananda Theertha Suresh</a>",
          "description": "In distributed learning settings such as federated learning, the training\nalgorithm can be potentially biased towards different clients. Mohri et al.\n(2019) proposed a domain-agnostic learning algorithm, where the model is\noptimized for any target distribution formed by a mixture of the client\ndistributions in order to overcome this bias. They further proposed an\nalgorithm for the cross-silo federated learning setting, where the number of\nclients is small. We consider this problem in the cross-device setting, where\nthe number of clients is much larger. We propose a communication-efficient\ndistributed algorithm called Agnostic Federated Averaging (or AgnosticFedAvg)\nto minimize the domain-agnostic objective proposed in Mohri et al. (2019),\nwhich is amenable to other private mechanisms such as secure aggregation. We\nhighlight two types of naturally occurring domains in federated learning and\nargue that AgnosticFedAvg performs well on both. To demonstrate the practical\neffectiveness of AgnosticFedAvg, we report positive results for large-scale\nlanguage modeling tasks in both simulation and live experiments, where the\nlatter involves training language models for Spanish virtual keyboard for\nmillions of user devices.",
          "link": "http://arxiv.org/abs/2104.02748",
          "publishedOn": "2021-06-17T01:58:46.159Z",
          "wordCount": null,
          "title": "Communication-Efficient Agnostic Federated Averaging. (arXiv:2104.02748v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08414",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bedi_A/0/1/0/all/0/1\">Amrit Singh Bedi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parayil_A/0/1/0/all/0/1\">Anjaly Parayil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Junyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mengdi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koppel_A/0/1/0/all/0/1\">Alec Koppel</a>",
          "description": "Reinforcement learning is a framework for interactive decision-making with\nincentives sequentially revealed across time without a system dynamics model.\nDue to its scaling to continuous spaces, we focus on policy search where one\niteratively improves a parameterized policy with stochastic policy gradient\n(PG) updates. In tabular Markov Decision Problems (MDPs), under persistent\nexploration and suitable parameterization, global optimality may be obtained.\nBy contrast, in continuous space, the non-convexity poses a pathological\nchallenge as evidenced by existing convergence results being mostly limited to\nstationarity or arbitrary local extrema. To close this gap, we step towards\npersistent exploration in continuous space through policy parameterizations\ndefined by distributions of heavier tails defined by tail-index parameter\nalpha, which increases the likelihood of jumping in state space. Doing so\ninvalidates smoothness conditions of the score function common to PG. Thus, we\nestablish how the convergence rate to stationarity depends on the policy's tail\nindex alpha, a Holder continuity parameter, integrability conditions, and an\nexploration tolerance parameter introduced here for the first time. Further, we\ncharacterize the dependence of the set of local maxima on the tail index\nthrough an exit and transition time analysis of a suitably defined Markov\nchain, identifying that policies associated with Levy Processes of a heavier\ntail converge to wider peaks. This phenomenon yields improved stability to\nperturbations in supervised learning, which we corroborate also manifests in\nimproved performance of policy search, especially when myopic and farsighted\nincentives are misaligned.",
          "link": "http://arxiv.org/abs/2106.08414",
          "publishedOn": "2021-06-17T01:58:46.152Z",
          "wordCount": null,
          "title": "On the Sample Complexity and Metastability of Heavy-tailed Policy Search in Continuous Control. (arXiv:2106.08414v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2104.00447",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lyu_Z/0/1/0/all/0/1\">Zhaoyang Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1\">Minghao Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1\">Tong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_G/0/1/0/all/0/1\">Guodong Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kehuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_D/0/1/0/all/0/1\">Dahua Lin</a>",
          "description": "Recent works have shown that interval bound propagation (IBP) can be used to\ntrain verifiably robust neural networks. Reseachers observe an intriguing\nphenomenon on these IBP trained networks: CROWN, a bounding method based on\ntight linear relaxation, often gives very loose bounds on these networks. We\nalso observe that most neurons become dead during the IBP training process,\nwhich could hurt the representation capability of the network. In this paper,\nwe study the relationship between IBP and CROWN, and prove that CROWN is always\ntighter than IBP when choosing appropriate bounding lines. We further propose a\nrelaxed version of CROWN, linear bound propagation (LBP), that can be used to\nverify large networks to obtain lower verified errors than IBP. We also design\na new activation function, parameterized ramp function (ParamRamp), which has\nmore diversity of neuron status than ReLU. We conduct extensive experiments on\nMNIST, CIFAR-10 and Tiny-ImageNet with ParamRamp activation and achieve\nstate-of-the-art verified robustness. Code and the appendix are available at\nhttps://github.com/ZhaoyangLyu/VerifiablyRobustNN.",
          "link": "http://arxiv.org/abs/2104.00447",
          "publishedOn": "2021-06-17T01:58:46.146Z",
          "wordCount": null,
          "title": "Towards Evaluating and Training Verifiably Robust Neural Networks. (arXiv:2104.00447v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.02482",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sani_N/0/1/0/all/0/1\">Numair Sani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malinsky_D/0/1/0/all/0/1\">Daniel Malinsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shpitser_I/0/1/0/all/0/1\">Ilya Shpitser</a>",
          "description": "We propose to explain the behavior of black-box prediction methods (e.g.,\ndeep neural networks trained on image pixel data) using causal graphical\nmodels. Specifically, we explore learning the structure of a causal graph where\nthe nodes represent prediction outcomes along with a set of macro-level\n\"interpretable\" features, while allowing for arbitrary unmeasured confounding\namong these variables. The resulting graph may indicate which of the\ninterpretable features, if any, are possible causes of the prediction outcome\nand which may be merely associated with prediction outcomes due to confounding.\nThe approach is motivated by a counterfactual theory of causal explanation\nwherein good explanations point to factors that are \"difference-makers\" in an\ninterventionist sense. The resulting analysis may be useful in algorithm\nauditing and evaluation, by identifying features which make a causal difference\nto the algorithm's output.",
          "link": "http://arxiv.org/abs/2006.02482",
          "publishedOn": "2021-06-17T01:58:46.133Z",
          "wordCount": 606,
          "title": "Explaining the Behavior of Black-Box Prediction Algorithms with Causal Learning. (arXiv:2006.02482v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1902.04251",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Min_S/0/1/0/all/0/1\">Seungki Min</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maglaras_C/0/1/0/all/0/1\">Costis Maglaras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moallemi_C/0/1/0/all/0/1\">Ciamac C. Moallemi</a>",
          "description": "We consider a finite-horizon multi-armed bandit (MAB) problem in a Bayesian\nsetting, for which we propose an information relaxation sampling framework.\nWith this framework, we define an intuitive family of control policies that\ninclude Thompson sampling (TS) and the Bayesian optimal policy as endpoints.\nAnalogous to TS, which, at each decision epoch pulls an arm that is best with\nrespect to the randomly sampled parameters, our algorithms sample entire future\nreward realizations and take the corresponding best action. However, this is\ndone in the presence of \"penalties\" that seek to compensate for the\navailability of future information.\n\nWe develop several novel policies and performance bounds for MAB problems\nthat vary in terms of improving performance and increasing computational\ncomplexity between the two endpoints. Our policies can be viewed as natural\ngeneralizations of TS that simultaneously incorporate knowledge of the time\nhorizon and explicitly consider the exploration-exploitation trade-off. We\nprove associated structural results on performance bounds and suboptimality\ngaps. Numerical experiments suggest that this new class of policies perform\nwell, in particular in settings where the finite time horizon introduces\nsignificant exploration-exploitation tension into the problem. Finally,\ninspired by the finite-horizon Gittins index, we propose an index policy that\nbuilds on our framework that particularly outperforms the state-of-the-art\nalgorithms in our numerical experiments.",
          "link": "http://arxiv.org/abs/1902.04251",
          "publishedOn": "2021-06-17T01:58:46.116Z",
          "wordCount": 665,
          "title": "Thompson Sampling with Information Relaxation Penalties. (arXiv:1902.04251v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.07655",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Price_I/0/1/0/all/0/1\">Ilan Price</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tanner_J/0/1/0/all/0/1\">Jared Tanner</a>",
          "description": "That neural networks may be pruned to high sparsities and retain high\naccuracy is well established. Recent research efforts focus on pruning\nimmediately after initialization so as to allow the computational savings\nafforded by sparsity to extend to the training process. In this work, we\nintroduce a new `DCT plus Sparse' layer architecture, which maintains\ninformation propagation and trainability even with as little as 0.01% trainable\nkernel parameters remaining. We show that standard training of networks built\nwith these layers, and pruned at initialization, achieves state-of-the-art\naccuracy for extreme sparsities on a variety of benchmark network architectures\nand datasets. Moreover, these results are achieved using only simple heuristics\nto determine the locations of the trainable parameters in the network, and thus\nwithout having to initially store or compute with the full, unpruned network,\nas is required by competing prune-at-initialization algorithms. Switching from\nstandard sparse layers to DCT plus Sparse layers does not increase the storage\nfootprint of a network and incurs only a small additional computational\noverhead.",
          "link": "http://arxiv.org/abs/2102.07655",
          "publishedOn": "2021-06-17T01:58:46.110Z",
          "wordCount": 648,
          "title": "Dense for the Price of Sparse: Improved Performance of Sparsely Initialized Networks via a Subspace Offset. (arXiv:2102.07655v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08372",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ngo_A/0/1/0/all/0/1\">Anthony Ngo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bauer_M/0/1/0/all/0/1\">Max Paul Bauer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Resch_M/0/1/0/all/0/1\">Michael Resch</a>",
          "description": "With the increasing safety validation requirements for the release of a\nself-driving car, alternative approaches, such as simulation-based testing, are\nemerging in addition to conventional real-world testing. In order to rely on\nvirtual tests the employed sensor models have to be validated. For this reason,\nit is necessary to quantify the discrepancy between simulation and reality in\norder to determine whether a certain fidelity is sufficient for a desired\nintended use. There exists no sound method to measure this\nsimulation-to-reality gap of radar perception for autonomous driving. We\naddress this problem by introducing a multi-layered evaluation approach, which\nconsists of a combination of an explicit and an implicit sensor model\nevaluation. The former directly evaluates the realism of the synthetically\ngenerated sensor data, while the latter refers to an evaluation of a downstream\ntarget application. In order to demonstrate the method, we evaluated the\nfidelity of three typical radar model types (ideal, data-driven, ray\ntracing-based) and their applicability for virtually testing radar-based\nmulti-object tracking. We have shown the effectiveness of the proposed approach\nin terms of providing an in-depth sensor model assessment that renders existing\ndisparities visible and enables a realistic estimation of the overall model\nfidelity across different scenarios.",
          "link": "http://arxiv.org/abs/2106.08372",
          "publishedOn": "2021-06-17T01:58:46.104Z",
          "wordCount": 663,
          "title": "A Multi-Layered Approach for Measuring the Simulation-to-Reality Gap of Radar Perception for Autonomous Driving. (arXiv:2106.08372v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08564",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xuan_Q/0/1/0/all/0/1\">Qi Xuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_K/0/1/0/all/0/1\">Kunfeng Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jinchao Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhuangzhi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1\">Dongwei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1\">Shilian Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiaoniu Yang</a>",
          "description": "Our digital world is full of time series and graphs which capture the various\naspects of many complex systems. Traditionally, there are respective methods in\nprocessing these two different types of data, e.g., Recurrent Neural Network\n(RNN) and Graph Neural Network (GNN), while in recent years, time series could\nbe mapped to graphs by using the techniques such as Visibility Graph (VG), so\nthat researchers can use graph algorithms to mine the knowledge in time series.\nSuch mapping methods establish a bridge between time series and graphs, and\nhave high potential to facilitate the analysis of various real-world time\nseries. However, the VG method and its variants are just based on fixed rules\nand thus lack of flexibility, largely limiting their application in reality. In\nthis paper, we propose an Adaptive Visibility Graph (AVG) algorithm that can\nadaptively map time series into graphs, based on which we further establish an\nend-to-end classification framework AVGNet, by utilizing GNN model DiffPool as\nthe classifier. We then adopt AVGNet for radio signal modulation classification\nwhich is an important task in the field of wireless communication. The\nsimulations validate that AVGNet outperforms a series of advanced deep learning\nmethods, achieving the state-of-the-art performance in this task.",
          "link": "http://arxiv.org/abs/2106.08564",
          "publishedOn": "2021-06-17T01:58:46.098Z",
          "wordCount": 642,
          "title": "Adaptive Visibility Graph Neural Network and It's Application in Modulation Classification. (arXiv:2106.08564v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2103.10415",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yao_H/0/1/0/all/0/1\">Huihan Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Ying Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_Q/0/1/0/all/0/1\">Qinyuan Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1\">Xisen Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>",
          "description": "Pre-trained language models have been successful on text classification\ntasks, but are prone to learning spurious correlations from biased datasets,\nand are thus vulnerable when making inferences in a new domain. Prior works\nreveal such spurious patterns via post-hoc explanation algorithms which compute\nthe importance of input features. Further, the model is regularized to align\nthe importance scores with human knowledge, so that the unintended model\nbehaviors are eliminated. However, such a regularization technique lacks\nflexibility and coverage, since only importance scores towards a pre-defined\nlist of features are adjusted, while more complex human knowledge such as\nfeature interaction and pattern generalization can hardly be incorporated. In\nthis work, we propose to refine a learned language model for a target domain by\ncollecting human-provided compositional explanations regarding observed biases.\nBy parsing these explanations into executable logic rules, the human-specified\nrefinement advice from a small set of explanations can be generalized to more\ntraining examples. We additionally introduce a regularization term allowing\nadjustments for both importance and interaction of features to better rectify\nmodel behavior. We demonstrate the effectiveness of the proposed approach on\ntwo text classification tasks by showing improved performance in target domain\nas well as improved model fairness after refinement.",
          "link": "http://arxiv.org/abs/2103.10415",
          "publishedOn": "2021-06-17T01:58:46.079Z",
          "wordCount": 663,
          "title": "Refining Language Models with Compositional Explanations. (arXiv:2103.10415v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.07537",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Diamandis_T/0/1/0/all/0/1\">Theo Diamandis</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Eldar_Y/0/1/0/all/0/1\">Yonina C. Eldar</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fallah_A/0/1/0/all/0/1\">Alireza Fallah</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Farnia_F/0/1/0/all/0/1\">Farzan Farnia</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ozdaglar_A/0/1/0/all/0/1\">Asuman Ozdaglar</a>",
          "description": "Multi-modal distributions are commonly used to model clustered data in\nstatistical learning tasks. In this paper, we consider the Mixed Linear\nRegression (MLR) problem. We propose an optimal transport-based framework for\nMLR problems, Wasserstein Mixed Linear Regression (WMLR), which minimizes the\nWasserstein distance between the learned and target mixture regression models.\nThrough a model-based duality analysis, WMLR reduces the underlying MLR task to\na nonconvex-concave minimax optimization problem, which can be provably solved\nto find a minimax stationary point by the Gradient Descent Ascent (GDA)\nalgorithm. In the special case of mixtures of two linear regression models, we\nshow that WMLR enjoys global convergence and generalization guarantees. We\nprove that WMLR's sample complexity grows linearly with the dimension of data.\nFinally, we discuss the application of WMLR to the federated learning task\nwhere the training samples are collected by multiple agents in a network.\nUnlike the Expectation Maximization algorithm, WMLR directly extends to the\ndistributed, federated learning setting. We support our theoretical results\nthrough several numerical experiments, which highlight our framework's ability\nto handle the federated learning setting with mixture models.",
          "link": "http://arxiv.org/abs/2106.07537",
          "publishedOn": "2021-06-17T01:58:46.072Z",
          "wordCount": 647,
          "title": "A Wasserstein Minimax Framework for Mixed Linear Regression. (arXiv:2106.07537v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03969",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Boix_Adsera_E/0/1/0/all/0/1\">Enric Boix-Adsera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bresler_G/0/1/0/all/0/1\">Guy Bresler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koehler_F/0/1/0/all/0/1\">Frederic Koehler</a>",
          "description": "We consider the problem of learning a tree-structured Ising model from data,\nsuch that subsequent predictions computed using the model are accurate.\nConcretely, we aim to learn a model such that posteriors $P(X_i|X_S)$ for small\nsets of variables $S$ are accurate. Since its introduction more than 50 years\nago, the Chow-Liu algorithm, which efficiently computes the maximum likelihood\ntree, has been the benchmark algorithm for learning tree-structured graphical\nmodels. A bound on the sample complexity of the Chow-Liu algorithm with respect\nto the prediction-centric local total variation loss was shown in [BK19]. While\nthose results demonstrated that it is possible to learn a useful model even\nwhen recovering the true underlying graph is impossible, their bound depends on\nthe maximum strength of interactions and thus does not achieve the\ninformation-theoretic optimum. In this paper, we introduce a new algorithm that\ncarefully combines elements of the Chow-Liu algorithm with tree metric\nreconstruction methods to efficiently and optimally learn tree Ising models\nunder a prediction-centric loss. Our algorithm is robust to model\nmisspecification and adversarial corruptions. In contrast, we show that the\ncelebrated Chow-Liu algorithm can be arbitrarily suboptimal.",
          "link": "http://arxiv.org/abs/2106.03969",
          "publishedOn": "2021-06-17T01:58:46.066Z",
          "wordCount": 649,
          "title": "Chow-Liu++: Optimal Prediction-Centric Learning of Tree Ising Models. (arXiv:2106.03969v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08922",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Higuchi_Y/0/1/0/all/0/1\">Yosuke Higuchi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Moritz_N/0/1/0/all/0/1\">Niko Moritz</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Roux_J/0/1/0/all/0/1\">Jonathan Le Roux</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hori_T/0/1/0/all/0/1\">Takaaki Hori</a>",
          "description": "Pseudo-labeling (PL) has been shown to be effective in semi-supervised\nautomatic speech recognition (ASR), where a base model is self-trained with\npseudo-labels generated from unlabeled data. While PL can be further improved\nby iteratively updating pseudo-labels as the model evolves, most of the\nprevious approaches involve inefficient retraining of the model or intricate\ncontrol of the label update. We present momentum pseudo-labeling (MPL), a\nsimple yet effective strategy for semi-supervised ASR. MPL consists of a pair\nof online and offline models that interact and learn from each other, inspired\nby the mean teacher method. The online model is trained to predict\npseudo-labels generated on the fly by the offline model. The offline model\nmaintains a momentum-based moving average of the online model. MPL is performed\nin a single training process and the interaction between the two models\neffectively helps them reinforce each other to improve the ASR performance. We\napply MPL to an end-to-end ASR model based on the connectionist temporal\nclassification. The experimental results demonstrate that MPL effectively\nimproves over the base model and is scalable to different semi-supervised\nscenarios with varying amounts of data or domain mismatch.",
          "link": "http://arxiv.org/abs/2106.08922",
          "publishedOn": "2021-06-17T01:58:46.060Z",
          "wordCount": 630,
          "title": "Momentum Pseudo-Labeling for Semi-Supervised Speech Recognition. (arXiv:2106.08922v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2001.09528",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jain_N/0/1/0/all/0/1\">Niharika Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Olmo_A/0/1/0/all/0/1\">Alberto Olmo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sengupta_S/0/1/0/all/0/1\">Sailik Sengupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manikonda_L/0/1/0/all/0/1\">Lydia Manikonda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kambhampati_S/0/1/0/all/0/1\">Subbarao Kambhampati</a>",
          "description": "In this paper, we show that popular Generative Adversarial Networks (GANs)\nexacerbate biases along the axes of gender and skin tone when given a skewed\ndistribution of face-shots. While practitioners celebrate synthetic data\ngeneration using GANs as an economical way to augment data for training\ndata-hungry machine learning models, it is unclear whether they recognize the\nperils of such techniques when applied to real world datasets biased along\nlatent dimensions. Specifically, we show that (1) traditional GANs further skew\nthe distribution of a dataset consisting of engineering faculty headshots,\ngenerating minority modes less often and of worse quality and (2)\nimage-to-image translation (conditional) GANs also exacerbate biases by\nlightening skin color of non-white faces and transforming female facial\nfeatures to be masculine when generating faces of engineering professors. Thus,\nour study is meant to serve as a cautionary tale.",
          "link": "http://arxiv.org/abs/2001.09528",
          "publishedOn": "2021-06-17T01:58:46.054Z",
          "wordCount": 638,
          "title": "Imperfect ImaGANation: Implications of GANs Exacerbating Biases on Facial Data Augmentation and Snapchat Selfie Lenses. (arXiv:2001.09528v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08415",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mahmud_J/0/1/0/all/0/1\">Junayed Mahmud</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faisal_F/0/1/0/all/0/1\">Fahim Faisal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arnob_R/0/1/0/all/0/1\">Raihan Islam Arnob</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anastasopoulos_A/0/1/0/all/0/1\">Antonios Anastasopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moran_K/0/1/0/all/0/1\">Kevin Moran</a>",
          "description": "Automated source code summarization is a popular software engineering\nresearch topic wherein machine translation models are employed to \"translate\"\ncode snippets into relevant natural language descriptions. Most evaluations of\nsuch models are conducted using automatic reference-based metrics. However,\ngiven the relatively large semantic gap between programming languages and\nnatural language, we argue that this line of research would benefit from a\nqualitative investigation into the various error modes of current\nstate-of-the-art models. Therefore, in this work, we perform both a\nquantitative and qualitative comparison of three recently proposed source code\nsummarization models. In our quantitative evaluation, we compare the models\nbased on the smoothed BLEU-4, METEOR, and ROUGE-L machine translation metrics,\nand in our qualitative evaluation, we perform a manual open-coding of the most\ncommon errors committed by the models when compared to ground truth captions.\nOur investigation reveals new insights into the relationship between\nmetric-based performance and model prediction errors grounded in an empirically\nderived error taxonomy that can be used to drive future research efforts",
          "link": "http://arxiv.org/abs/2106.08415",
          "publishedOn": "2021-06-17T01:58:46.039Z",
          "wordCount": 651,
          "title": "Code to Comment Translation: A Comparative Study on Model Effectiveness & Errors. (arXiv:2106.08415v1 [cs.SE])"
        },
        {
          "id": "http://arxiv.org/abs/2006.15368",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brandfonbrener_D/0/1/0/all/0/1\">David Brandfonbrener</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Whitney_W/0/1/0/all/0/1\">William F. Whitney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranganath_R/0/1/0/all/0/1\">Rajesh Ranganath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bruna_J/0/1/0/all/0/1\">Joan Bruna</a>",
          "description": "Recent results in supervised learning suggest that while overparameterized\nmodels have the capacity to overfit, they in fact generalize quite well. We ask\nwhether the same phenomenon occurs for offline contextual bandits. Our results\nare mixed. Value-based algorithms benefit from the same generalization behavior\nas overparameterized supervised learning, but policy-based algorithms do not.\nWe show that this discrepancy is due to the \\emph{action-stability} of their\nobjectives. An objective is action-stable if there exists a prediction\n(action-value vector or action distribution) which is optimal no matter which\naction is observed. While value-based objectives are action-stable,\npolicy-based objectives are unstable. We formally prove upper bounds on the\nregret of overparameterized value-based learning and lower bounds on the regret\nfor policy-based algorithms. In our experiments with large neural networks,\nthis gap between action-stable value-based objectives and unstable policy-based\nobjectives leads to significant performance differences.",
          "link": "http://arxiv.org/abs/2006.15368",
          "publishedOn": "2021-06-17T01:58:46.033Z",
          "wordCount": 629,
          "title": "Offline Contextual Bandits with Overparameterized Models. (arXiv:2006.15368v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.09188",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1\">Chen Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lou_K/0/1/0/all/0/1\">Kexin Lou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhengyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_M/0/1/0/all/0/1\">Mingqi Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mantini_D/0/1/0/all/0/1\">Dante Mantini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Quanying Liu</a>",
          "description": "EEG source localization is an important technical issue in EEG analysis.\nDespite many numerical methods existed for EEG source localization, they all\nrely on strong priors and the deep sources are intractable. Here we propose a\ndeep learning framework using spatial basis function decomposition for EEG\nsource localization. This framework combines the edge sparsity prior and\nGaussian source basis, called Edge Sparse Basis Network (ESBN). The performance\nof ESBN is validated by both synthetic data and real EEG data during motor\ntasks. The results suggest that the supervised ESBN outperforms the traditional\nnumerical methods in synthetic data and the unsupervised fine-tuning provides\nmore focal and accurate localizations in real data. Our proposed deep learning\nframework can be extended to account for other source priors, and the real-time\nproperty of ESBN can facilitate the applications of EEG in brain-computer\ninterfaces and clinics.",
          "link": "http://arxiv.org/abs/2102.09188",
          "publishedOn": "2021-06-17T01:58:46.028Z",
          "wordCount": 618,
          "title": "Edge Sparse Basis Network: A Deep Learning Framework for EEG Source Localization. (arXiv:2102.09188v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08502",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Altschuler_J/0/1/0/all/0/1\">Jason M. Altschuler</a>, <a href=\"http://arxiv.org/find/math/1/au:+Chewi_S/0/1/0/all/0/1\">Sinho Chewi</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gerber_P/0/1/0/all/0/1\">Patrik Gerber</a>, <a href=\"http://arxiv.org/find/math/1/au:+Stromme_A/0/1/0/all/0/1\">Austin J. Stromme</a>",
          "description": "We study first-order optimization algorithms for computing the barycenter of\nGaussian distributions with respect to the optimal transport metric. Although\nthe objective is geodesically non-convex, Riemannian GD empirically converges\nrapidly, in fact faster than off-the-shelf methods such as Euclidean GD and SDP\nsolvers. This stands in stark contrast to the best-known theoretical results\nfor Riemannian GD, which depend exponentially on the dimension. In this work,\nwe prove new geodesic convexity results which provide stronger control of the\niterates, yielding a dimension-free convergence rate. Our techniques also\nenable the analysis of two related notions of averaging, the\nentropically-regularized barycenter and the geometric median, providing the\nfirst convergence guarantees for Riemannian GD for these problems.",
          "link": "http://arxiv.org/abs/2106.08502",
          "publishedOn": "2021-06-17T01:58:46.022Z",
          "wordCount": 554,
          "title": "Averaging on the Bures-Wasserstein manifold: dimension-free convergence of gradient descent. (arXiv:2106.08502v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08658",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shengli Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_W/0/1/0/all/0/1\">Weimin Ding</a>",
          "description": "Ensemble classifiers have been investigated by many in the artificial\nintelligence and machine learning community. Majority voting and weighted\nmajority voting are two commonly used combination schemes in ensemble learning.\nHowever, understanding of them is incomplete at best, with some properties even\nmisunderstood. In this paper, we present a group of properties of these two\nschemes formally under a dataset-level geometric framework. Two key factors,\nevery component base classifier's performance and dissimilarity between each\npair of component classifiers are evaluated by the same metric - the Euclidean\ndistance. Consequently, ensembling becomes a deterministic problem and the\nperformance of an ensemble can be calculated directly by a formula. We prove\nseveral theorems of interest and explain their implications for ensembles. In\nparticular, we compare and contrast the effect of the number of component\nclassifiers on these two types of ensemble schemes. Empirical investigation is\nalso conducted to verify the theoretical results when other metrics such as\naccuracy are used. We believe that the results from this paper are very useful\nfor us to understand the fundamental properties of these two combination\nschemes and the principles of ensemble classifiers in general. The results are\nalso helpful for us to investigate some issues in ensemble classifiers, such as\nensemble performance prediction, selecting a small number of base classifiers\nto obtain efficient and effective ensembles.",
          "link": "http://arxiv.org/abs/2106.08658",
          "publishedOn": "2021-06-17T01:58:46.016Z",
          "wordCount": 656,
          "title": "A Dataset-Level Geometric Framework for Ensemble Classifiers. (arXiv:2106.08658v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2006.09373",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1\">Peijie Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_C/0/1/0/all/0/1\">Chirag Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1\">Anh Nguyen</a>",
          "description": "Adversarial training has been the topic of dozens of studies and a leading\nmethod for defending against adversarial attacks. Yet, it remains largely\nunknown (a) how adversarially-robust ImageNet classifiers (R classifiers)\ngeneralize to out-of-distribution examples; and (b) how their generalization\ncapability relates to their hidden representations. In this paper, we perform a\nthorough, systematic study to answer these two questions across AlexNet,\nGoogLeNet, and ResNet-50 architectures. We found that while standard ImageNet\nclassifiers have a strong texture bias, their R counterparts rely heavily on\nshapes. Remarkably, adversarial training induces three simplicity biases into\nhidden neurons in the process of 'robustifying' the network. That is, each\nconvolutional neuron in R networks often changes to detecting (1) pixel-wise\nsmoother patterns i.e. a mechanism that blocks high-frequency noise from\npassing through the network; (2) more lower-level features i.e. textures and\ncolors (instead of objects); and (3) fewer types of inputs. Our findings reveal\nthe interesting mechanisms that made networks more adversarially robust and\nalso explain some recent findings. Our findings reveal the interesting\nmechanisms that made networks more adversarially robust and also explain some\nrecent findings e.g. why R networks benefit from much larger capacity (Xie and\nYuille, 2020) and can act as a strong image prior in image synthesis (Santurkar\net al., 2019).",
          "link": "http://arxiv.org/abs/2006.09373",
          "publishedOn": "2021-06-17T01:58:45.997Z",
          "wordCount": 693,
          "title": "The shape and simplicity biases of adversarially robust ImageNet-trained CNNs. (arXiv:2006.09373v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04426",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roller_S/0/1/0/all/0/1\">Stephen Roller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sukhbaatar_S/0/1/0/all/0/1\">Sainbayar Sukhbaatar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szlam_A/0/1/0/all/0/1\">Arthur Szlam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weston_J/0/1/0/all/0/1\">Jason Weston</a>",
          "description": "We investigate the training of sparse layers that use different parameters\nfor different inputs based on hashing in large Transformer models.\nSpecifically, we modify the feedforward layer to hash to different sets of\nweights depending on the current token, over all tokens in the sequence. We\nshow that this procedure either outperforms or is competitive with\nlearning-to-route mixture-of-expert methods such as Switch Transformers and\nBASE Layers, while requiring no routing parameters or extra terms in the\nobjective function such as a load balancing loss, and no sophisticated\nassignment algorithm. We study the performance of different hashing techniques,\nhash sizes and input features, and show that balanced and random hashes focused\non the most local features work best, compared to either learning clusters or\nusing longer-range context. We show our approach works well both on large\nlanguage modeling and dialogue tasks, and on downstream fine-tuning tasks.",
          "link": "http://arxiv.org/abs/2106.04426",
          "publishedOn": "2021-06-17T01:58:45.991Z",
          "wordCount": 587,
          "title": "Hash Layers For Large Sparse Models. (arXiv:2106.04426v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.02960",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+White_C/0/1/0/all/0/1\">Colin White</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nolen_S/0/1/0/all/0/1\">Sam Nolen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Savani_Y/0/1/0/all/0/1\">Yash Savani</a>",
          "description": "Neural architecture search (NAS) has seen a steep rise in interest over the\nlast few years. Many algorithms for NAS consist of searching through a space of\narchitectures by iteratively choosing an architecture, evaluating its\nperformance by training it, and using all prior evaluations to come up with the\nnext choice. The evaluation step is noisy - the final accuracy varies based on\nthe random initialization of the weights. Prior work has focused on devising\nnew search algorithms to handle this noise, rather than quantifying or\nunderstanding the level of noise in architecture evaluations. In this work, we\nshow that (1) the simplest hill-climbing algorithm is a powerful baseline for\nNAS, and (2), when the noise in popular NAS benchmark datasets is reduced to a\nminimum, hill-climbing to outperforms many popular state-of-the-art algorithms.\nWe further back up this observation by showing that the number of local minima\nis substantially reduced as the noise decreases, and by giving a theoretical\ncharacterization of the performance of local search in NAS. Based on our\nfindings, for NAS research we suggest (1) using local search as a baseline, and\n(2) denoising the training pipeline when possible.",
          "link": "http://arxiv.org/abs/2005.02960",
          "publishedOn": "2021-06-17T01:58:45.984Z",
          "wordCount": 654,
          "title": "Exploring the Loss Landscape in Neural Architecture Search. (arXiv:2005.02960v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08720",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Semret_N/0/1/0/all/0/1\">Nemo Semret</a>",
          "description": "We present a fully automated model for in-season crop yield prediction,\ndesigned to work where there is a dearth of sub-national \"ground truth\"\ninformation. Our approach relies primarily on satellite data and is\ncharacterized by careful feature engineering combined with a simple regression\nmodel. As such, it can work almost anywhere in the world. Applying it to 10\ndifferent crop-country pairs (5 cereals -- corn, wheat, sorghum, barley and\nmillet, in 2 countries -- Ethiopia and Kenya), we achieve RMSEs of 5\\%-10\\% for\npredictions 9 months into the year, and 7\\%-14\\% for predictions 3 months into\nthe year. The model outputs daily forecasts for the final yield of the current\nyear. It is trained using approximately 4 million data points for each\ncrop-country pair. These consist of: historical country-level annual yields,\ncrop calendars, crop cover, NDVI, temperature, rainfall, and\nevapotransporation.",
          "link": "http://arxiv.org/abs/2106.08720",
          "publishedOn": "2021-06-17T01:58:45.976Z",
          "wordCount": 569,
          "title": "Predicting crop yields with little ground truth: A simple statistical model for in-season forecasting. (arXiv:2106.08720v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2103.06271",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khazraei_A/0/1/0/all/0/1\">Amir Khazraei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hallyburton_S/0/1/0/all/0/1\">Spencer Hallyburton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Q/0/1/0/all/0/1\">Qitong Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pajic_M/0/1/0/all/0/1\">Miroslav Pajic</a>",
          "description": "This work focuses on the use of deep learning for vulnerability analysis of\ncyber-physical systems (CPS). Specifically, we consider a control architecture\nwidely used in CPS (e.g., robotics), where the low-level control is based on\ne.g., the extended Kalman filter (EKF) and an anomaly detector. To facilitate\nanalyzing the impact potential sensing attacks could have, our objective is to\ndevelop learning-enabled attack generators capable of designing stealthy\nattacks that maximally degrade system operation. We show how such problem can\nbe cast within a learning-based grey-box framework where parts of the runtime\ninformation are known to the attacker, and introduce two models based on\nfeed-forward neural networks (FNN); both models are trained offline, using a\ncost function that combines the attack effects on the estimation error and the\nresidual signal used for anomaly detection, so that the trained models are\ncapable of recursively generating such effective sensor attacks in real-time.\nThe effectiveness of the proposed methods is illustrated on several case\nstudies.",
          "link": "http://arxiv.org/abs/2103.06271",
          "publishedOn": "2021-06-17T01:58:45.969Z",
          "wordCount": 623,
          "title": "Learning-Based Vulnerability Analysis of Cyber-Physical Systems. (arXiv:2103.06271v2 [cs.CR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.07932",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rizoiu_M/0/1/0/all/0/1\">Marian-Andrei Rizoiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soen_A/0/1/0/all/0/1\">Alexander Soen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shidi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_L/0/1/0/all/0/1\">Leanne Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Calderon_P/0/1/0/all/0/1\">Pio Calderon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Menon_A/0/1/0/all/0/1\">Aditya Krishna Menon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_L/0/1/0/all/0/1\">Lexing Xie</a>",
          "description": "This work builds a novel point process and tools to use the Hawkes process\nwith interval-censored data. Such data records the aggregated counts of events\nsolely during specific time intervals -- such as the number of patients\nadmitted to the hospital or the volume of vehicles passing traffic loop\ndetectors -- and not the exact occurrence time of the events. First, we\nestablish the Mean Behavior Poisson (MBP) process, a novel Poisson process with\na direct parameter correspondence to the popular self-exciting Hawkes process.\nThe event intensity function of the MBP is the expected intensity over all\npossible Hawkes realizations with the same parameter set. We fit MBP in the\ninterval-censored setting using an interval-censored Poisson log-likelihood\n(IC-LL). We use the parameter equivalence to uncover the parameters of the\nassociated Hawkes process. Second, we introduce two novel exogenous functions\nto distinguish the exogenous from the endogenous events. We propose the\nmulti-impulse exogenous function when the exogenous events are observed as\nevent time and the latent homogeneous Poisson process exogenous function when\nthe exogenous events are presented as interval-censored volumes. Third, we\nprovide several approximation methods to estimate the intensity and compensator\nfunction of MBP when no analytical solution exists. Fourth and finally, we\nconnect the interval-censored loss of MBP to a broader class of Bregman\ndivergence-based functions. Using the connection, we show that the current\nstate of the art in popularity estimation (Hawkes Intensity Process (HIP)\n(Rizoiu et al.,2017b)) is a particular case of the MBP process. We verify our\nmodels through empirical testing on synthetic data and real-world data. We find\nthat on real-world datasets that ourMBP process outperforms HIP for the task of\npopularity prediction.",
          "link": "http://arxiv.org/abs/2104.07932",
          "publishedOn": "2021-06-17T01:58:45.963Z",
          "wordCount": 739,
          "title": "Interval-censored Hawkes processes. (arXiv:2104.07932v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.14471",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Terry_J/0/1/0/all/0/1\">J. K. Terry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Black_B/0/1/0/all/0/1\">Benjamin Black</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grammel_N/0/1/0/all/0/1\">Nathaniel Grammel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jayakumar_M/0/1/0/all/0/1\">Mario Jayakumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hari_A/0/1/0/all/0/1\">Ananth Hari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sullivan_R/0/1/0/all/0/1\">Ryan Sullivan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santos_L/0/1/0/all/0/1\">Luis Santos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perez_R/0/1/0/all/0/1\">Rodrigo Perez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Horsch_C/0/1/0/all/0/1\">Caroline Horsch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dieffendahl_C/0/1/0/all/0/1\">Clemens Dieffendahl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Williams_N/0/1/0/all/0/1\">Niall L. Williams</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lokesh_Y/0/1/0/all/0/1\">Yashas Lokesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ravi_P/0/1/0/all/0/1\">Praveen Ravi</a>",
          "description": "This paper introduces the PettingZoo library and the accompanying Agent\nEnvironment Cycle (\"AEC\") games model. PettingZoo is a library of diverse sets\nof multi-agent environments with a universal, elegant Python API. PettingZoo\nwas developed with the goal of accelerating research in Multi-Agent\nReinforcement Learning (\"MARL\"), by making work more interchangeable,\naccessible and reproducible akin to what OpenAI's Gym library did for\nsingle-agent reinforcement learning. PettingZoo's API, while inheriting many\nfeatures of Gym, is unique amongst MARL APIs in that it's based around the\nnovel AEC games model. We argue, in part through case studies on major problems\nin popular MARL environments, that the popular game models are poor conceptual\nmodels of the games commonly used with MARL, that they promote severe bugs that\nare hard to detect, and that the AEC games model addresses these problems.",
          "link": "http://arxiv.org/abs/2009.14471",
          "publishedOn": "2021-06-17T01:58:45.947Z",
          "wordCount": 649,
          "title": "PettingZoo: Gym for Multi-Agent Reinforcement Learning. (arXiv:2009.14471v6 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08703",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chiu_C/0/1/0/all/0/1\">Ching-Yu Chiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ching_J/0/1/0/all/0/1\">Joann Ching</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsiao_W/0/1/0/all/0/1\">Wen-Yi Hsiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yu-Hua Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_A/0/1/0/all/0/1\">Alvin Wen-Yu Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yi-Hsuan Yang</a>",
          "description": "Due to advances in deep learning, the performance of automatic beat and\ndownbeat tracking in musical audio signals has seen great improvement in recent\nyears. In training such deep learning based models, data augmentation has been\nfound an important technique. However, existing data augmentation methods for\nthis task mainly target at balancing the distribution of the training data with\nrespect to their tempo. In this paper, we investigate another approach for data\naugmentation, to account for the composition of the training data in terms of\nthe percussive and non-percussive sound sources. Specifically, we propose to\nemploy a blind drum separation model to segregate the drum and non-drum sounds\nfrom each training audio signal, filtering out training signals that are\ndrumless, and then use the obtained drum and non-drum stems to augment the\ntraining data. We report experiments on four completely unseen test sets,\nvalidating the effectiveness of the proposed method, and accordingly the\nimportance of drum sound composition in the training data for beat and downbeat\ntracking.",
          "link": "http://arxiv.org/abs/2106.08703",
          "publishedOn": "2021-06-17T01:58:45.941Z",
          "wordCount": null,
          "title": "Source Separation-based Data Augmentation for Improved Joint Beat and Downbeat Tracking. (arXiv:2106.08703v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2101.03735",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wang_B/0/1/0/all/0/1\">Bo Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Xie_W/0/1/0/all/0/1\">Wei Xie</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Martagan_T/0/1/0/all/0/1\">Tugce Martagan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Akcay_A/0/1/0/all/0/1\">Alp Akcay</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ravenstein_B/0/1/0/all/0/1\">Bram van Ravenstein</a>",
          "description": "In biopharmaceutical manufacturing, fermentation processes play a critical\nrole on productivity and profit. A fermentation process uses living cells with\ncomplex biological mechanisms, and this leads to high variability in the\nprocess outputs. By building on the biological mechanisms of protein and\nimpurity growth, we introduce a stochastic model to characterize the\naccumulation of the protein and impurity levels in the fermentation process.\nHowever, a common challenge in industry is the availability of only very\nlimited amount of data especially in the development and early stage of\nproduction. This adds an additional layer of uncertainty, referred to as model\nrisk, due to the difficulty of estimating the model parameters with limited\ndata. In this paper, we study the harvesting decision for a fermentation\nprocess under model risk. In particular, we adopt a Bayesian approach to update\nthe unknown parameters of the growth-rate distributions, and use the resulting\nposterior distributions to characterize the impact of model risk on\nfermentation output variability. The harvesting problem is formulated as a\nMarkov decision process model with knowledge states that summarize the\nposterior distributions and hence incorporate the model risk in\ndecision-making. The resulting model is solved by using a reinforcement\nlearning algorithm based on Bayesian sparse sampling. We provide analytical\nresults on the structure of the optimal policy and its objective function, and\nexplicitly study the impact of model risk on harvesting decisions. Our case\nstudies at MSD Animal Health demonstrate that the proposed model and solution\napproach improve the harvesting decisions in real life by achieving\nsubstantially higher average output from a fermentation batch along with lower\nbatch-to-batch variability.",
          "link": "http://arxiv.org/abs/2101.03735",
          "publishedOn": "2021-06-17T01:58:45.933Z",
          "wordCount": 727,
          "title": "Optimizing Biomanufacturing Harvesting Decisions under Limited Historical Data. (arXiv:2101.03735v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08700",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kang_S/0/1/0/all/0/1\">SeongKu Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_J/0/1/0/all/0/1\">Junyoung Hwang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kweon_W/0/1/0/all/0/1\">Wonbin Kweon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Hwanjo Yu</a>",
          "description": "Recommender Systems (RS) have employed knowledge distillation which is a\nmodel compression technique training a compact student model with the knowledge\ntransferred from a pre-trained large teacher model. Recent work has shown that\ntransferring knowledge from the teacher's intermediate layer significantly\nimproves the recommendation quality of the student. However, they transfer the\nknowledge of individual representation point-wise and thus have a limitation in\nthat primary information of RS lies in the relations in the representation\nspace. This paper proposes a new topology distillation approach that guides the\nstudent by transferring the topological structure built upon the relations in\nthe teacher space. We first observe that simply making the student learn the\nwhole topological structure is not always effective and even degrades the\nstudent's performance. We demonstrate that because the capacity of the student\nis highly limited compared to that of the teacher, learning the whole\ntopological structure is daunting for the student. To address this issue, we\npropose a novel method named Hierarchical Topology Distillation (HTD) which\ndistills the topology hierarchically to cope with the large capacity gap. Our\nextensive experiments on real-world datasets show that the proposed method\nsignificantly outperforms the state-of-the-art competitors. We also provide\nin-depth analyses to ascertain the benefit of distilling the topology for RS.",
          "link": "http://arxiv.org/abs/2106.08700",
          "publishedOn": "2021-06-17T01:58:45.925Z",
          "wordCount": 642,
          "title": "Topology Distillation for Recommender System. (arXiv:2106.08700v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08541",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yi Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1\">Aiguo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_K/0/1/0/all/0/1\">Ke Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_L/0/1/0/all/0/1\">Ling Tian</a>",
          "description": "Nowadays, Graph Neural Networks (GNNs) following the Message Passing paradigm\nbecome the dominant way to learn on graphic data. Models in this paradigm have\nto spend extra space to look up adjacent nodes with adjacency matrices and\nextra time to aggregate multiple messages from adjacent nodes. To address this\nissue, we develop a method called LinkDist that distils self-knowledge from\nconnected node pairs into a Multi-Layer Perceptron (MLP) without the need to\naggregate messages. Experiment with 8 real-world datasets shows the MLP derived\nfrom LinkDist can predict the label of a node without knowing its adjacencies\nbut achieve comparable accuracy against GNNs in the contexts of semi- and\nfull-supervised node classification. Moreover, LinkDist benefits from its\nNon-Message Passing paradigm that we can also distil self-knowledge from\narbitrarily sampled node pairs in a contrastive way to further boost the\nperformance of LinkDist.",
          "link": "http://arxiv.org/abs/2106.08541",
          "publishedOn": "2021-06-17T01:58:45.914Z",
          "wordCount": 584,
          "title": "Distilling Self-Knowledge From Contrastive Links to Classify Graph Nodes Without Passing Messages. (arXiv:2106.08541v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08334",
          "author": "<a href=\"http://arxiv.org/find/hep-ph/1/au:+Araz_J/0/1/0/all/0/1\">Jack Y. Araz</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Spannowsky_M/0/1/0/all/0/1\">Michael Spannowsky</a>",
          "description": "Tensor Networks are non-trivial representations of high-dimensional tensors,\noriginally designed to describe quantum many-body systems. We show that Tensor\nNetworks are ideal vehicles to connect quantum mechanical concepts to machine\nlearning techniques, thereby facilitating an improved interpretability of\nneural networks. This study presents the discrimination of top quark signal\nover QCD background processes using a Matrix Product State classifier. We show\nthat entanglement entropy can be used to interpret what a network learns, which\ncan be used to reduce the complexity of the network and feature space without\nloss of generality or performance. For the optimisation of the network, we\ncompare the Density Matrix Renormalization Group (DMRG) algorithm to stochastic\ngradient descent (SGD) and propose a joined training algorithm to harness the\nexplainability of DMRG with the efficiency of SGD.",
          "link": "http://arxiv.org/abs/2106.08334",
          "publishedOn": "2021-06-17T01:58:45.884Z",
          "wordCount": 586,
          "title": "Quantum-inspired event reconstruction with Tensor Networks: Matrix Product States. (arXiv:2106.08334v1 [hep-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2101.12616",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Freeman_I/0/1/0/all/0/1\">Ido Freeman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_K/0/1/0/all/0/1\">Kun Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kummert_A/0/1/0/all/0/1\">Anton Kummert</a>",
          "description": "The rising demand for Active Safety systems in automotive applications\nstresses the need for a reliable short to mid-term trajectory prediction.\nAnticipating the unfolding path of road users, one can act to increase the\noverall safety. In this work, we propose to train artificial neural networks\nfor movement understanding by predicting trajectories in their natural form, as\na function of time. Predicting polynomial coefficients allows us to increased\naccuracy and improve generalisation.",
          "link": "http://arxiv.org/abs/2101.12616",
          "publishedOn": "2021-06-17T01:58:45.875Z",
          "wordCount": 540,
          "title": "Polynomial Trajectory Predictions for Improved Learning Performance. (arXiv:2101.12616v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.11970",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wang_J/0/1/0/all/0/1\">Jie Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gao_R/0/1/0/all/0/1\">Rui Gao</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Xie_Y/0/1/0/all/0/1\">Yao Xie</a>",
          "description": "We develop a projected Wasserstein distance for the two-sample test, a\nfundamental problem in statistics and machine learning: given two sets of\nsamples, to determine whether they are from the same distribution. In\nparticular, we aim to circumvent the curse of dimensionality in Wasserstein\ndistance: when the dimension is high, it has diminishing testing power, which\nis inherently due to the slow concentration property of Wasserstein metrics in\nthe high dimension space. A key contribution is to couple optimal projection to\nfind the low dimensional linear mapping to maximize the Wasserstein distance\nbetween projected probability distributions. We characterize the theoretical\nproperty of the finite-sample convergence rate on IPMs and present practical\nalgorithms for computing this metric. Numerical examples validate our\ntheoretical results.",
          "link": "http://arxiv.org/abs/2010.11970",
          "publishedOn": "2021-06-17T01:58:45.869Z",
          "wordCount": 588,
          "title": "Two-sample Test using Projected Wasserstein Distance: Breaking the Curse of Dimensionality. (arXiv:2010.11970v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08992",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+DInverno_G/0/1/0/all/0/1\">Giuseppe Alessio D&#x27;Inverno</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bianchini_M/0/1/0/all/0/1\">Monica Bianchini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sampoli_M/0/1/0/all/0/1\">Maria Lucia Sampoli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scarselli_F/0/1/0/all/0/1\">Franco Scarselli</a>",
          "description": "Graph Neural Networks (GNNs) are a wide class of connectionist models for\ngraph processing. They perform an iterative message passing operation on each\nnode and its neighbors, to solve classification/ clustering tasks --- on some\nnodes or on the whole graph --- collecting all such messages, regardless of\ntheir order. Despite the differences among the various models belonging to this\nclass, most of them adopt the same computation scheme, based on a local\naggregation mechanism and, intuitively, the local computation framework is\nmainly responsible for the expressive power of GNNs. In this paper, we prove\nthat the Weisfeiler--Lehman test induces an equivalence relationship on the\ngraph nodes that exactly corresponds to the unfolding equivalence, defined on\nthe original GNN model. Therefore, the results on the expressive power of the\noriginal GNNs can be extended to general GNNs which, under mild conditions, can\nbe proved capable of approximating, in probability and up to any precision, any\nfunction on graphs that respects the unfolding equivalence.",
          "link": "http://arxiv.org/abs/2106.08992",
          "publishedOn": "2021-06-17T01:58:45.863Z",
          "wordCount": 611,
          "title": "An unifying point of view on expressive power of GNNs. (arXiv:2106.08992v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01357",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bortoli_V/0/1/0/all/0/1\">Valentin De Bortoli</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Thornton_J/0/1/0/all/0/1\">James Thornton</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Heng_J/0/1/0/all/0/1\">Jeremy Heng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Doucet_A/0/1/0/all/0/1\">Arnaud Doucet</a>",
          "description": "Progressively applying Gaussian noise transforms complex data distributions\nto approximately Gaussian. Reversing this dynamic defines a generative model.\nWhen the forward noising process is given by a Stochastic Differential Equation\n(SDE), Song et al. (2021) demonstrate how the time inhomogeneous drift of the\nassociated reverse-time SDE may be estimated using score-matching. A limitation\nof this approach is that the forward-time SDE must be run for a sufficiently\nlong time for the final distribution to be approximately Gaussian. In contrast,\nsolving the Schr\\\"odinger Bridge problem (SB), i.e. an entropy-regularized\noptimal transport problem on path spaces, yields diffusions which generate\nsamples from the data distribution in finite time. We present Diffusion SB\n(DSB), an original approximation of the Iterative Proportional Fitting (IPF)\nprocedure to solve the SB problem, and provide theoretical analysis along with\ngenerative modeling experiments. The first DSB iteration recovers the\nmethodology proposed by Song et al. (2021), with the flexibility of using\nshorter time intervals, as subsequent DSB iterations reduce the discrepancy\nbetween the final-time marginal of the forward (resp. backward) SDE with\nrespect to the prior (resp. data) distribution. Beyond generative modeling, DSB\noffers a widely applicable computational optimal transport tool as the\ncontinuous state-space analogue of the popular Sinkhorn algorithm (Cuturi,\n2013).",
          "link": "http://arxiv.org/abs/2106.01357",
          "publishedOn": "2021-06-17T01:58:45.856Z",
          "wordCount": 662,
          "title": "Diffusion Schr\\\"odinger Bridge with Applications to Score-Based Generative Modeling. (arXiv:2106.01357v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08981",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Salazar_D/0/1/0/all/0/1\">Domingos S. P. Salazar</a>",
          "description": "Self-supervised learning (SSL) of energy based models has an intuitive\nrelation to equilibrium thermodynamics because the softmax layer, mapping\nenergies to probabilities, is a Gibbs distribution. However, in what way SSL is\na thermodynamic process? We show that some SSL paradigms behave as a\nthermodynamic composite system formed by representations and self-labels in\ncontact with a nonequilibrium reservoir. Moreover, this system is subjected to\nusual thermodynamic cycles, such as adiabatic expansion and isochoric heating,\nresulting in a generalized Gibbs ensemble (GGE). In this picture, we show that\nlearning is seen as a demon that operates in cycles using feedback measurements\nto extract negative work from the system. As applications, we examine some SSL\nalgorithms using this idea.",
          "link": "http://arxiv.org/abs/2106.08981",
          "publishedOn": "2021-06-17T01:58:45.847Z",
          "wordCount": 544,
          "title": "Nonequilibrium thermodynamics of self-supervised learning. (arXiv:2106.08981v1 [cond-mat.stat-mech])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08352",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Mohan_D/0/1/0/all/0/1\">Devang S Ram Mohan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hu_V/0/1/0/all/0/1\">Vivian Hu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Teh_T/0/1/0/all/0/1\">Tian Huey Teh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Torresquintero_A/0/1/0/all/0/1\">Alexandra Torresquintero</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wallis_C/0/1/0/all/0/1\">Christopher G. R. Wallis</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Staib_M/0/1/0/all/0/1\">Marlene Staib</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Foglianti_L/0/1/0/all/0/1\">Lorenzo Foglianti</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gao_J/0/1/0/all/0/1\">Jiameng Gao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+King_S/0/1/0/all/0/1\">Simon King</a>",
          "description": "Text does not fully specify the spoken form, so text-to-speech models must be\nable to learn from speech data that vary in ways not explained by the\ncorresponding text. One way to reduce the amount of unexplained variation in\ntraining data is to provide acoustic information as an additional learning\nsignal. When generating speech, modifying this acoustic information enables\nmultiple distinct renditions of a text to be produced.\n\nSince much of the unexplained variation is in the prosody, we propose a model\nthat generates speech explicitly conditioned on the three primary acoustic\ncorrelates of prosody: $F_{0}$, energy and duration. The model is flexible\nabout how the values of these features are specified: they can be externally\nprovided, or predicted from text, or predicted then subsequently modified.\n\nCompared to a model that employs a variational auto-encoder to learn\nunsupervised latent features, our model provides more interpretable,\ntemporally-precise, and disentangled control. When automatically predicting the\nacoustic features from text, it generates speech that is more natural than that\nfrom a Tacotron 2 model with reference encoder. Subsequent human-in-the-loop\nmodification of the predicted acoustic features can significantly further\nincrease naturalness.",
          "link": "http://arxiv.org/abs/2106.08352",
          "publishedOn": "2021-06-17T01:58:45.827Z",
          "wordCount": 656,
          "title": "Ctrl-P: Temporal Control of Prosodic Variation for Speech Synthesis. (arXiv:2106.08352v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08413",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1\">Lily Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perrault_A/0/1/0/all/0/1\">Andrew Perrault</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_F/0/1/0/all/0/1\">Fei Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Haipeng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tambe_M/0/1/0/all/0/1\">Milind Tambe</a>",
          "description": "Green security domains feature defenders who plan patrols in the face of\nuncertainty about the adversarial behavior of poachers, illegal loggers, and\nillegal fishers. Importantly, the deterrence effect of patrols on adversaries'\nfuture behavior makes patrol planning a sequential decision-making problem.\nTherefore, we focus on robust sequential patrol planning for green security\nfollowing the minimax regret criterion, which has not been considered in the\nliterature. We formulate the problem as a game between the defender and nature\nwho controls the parameter values of the adversarial behavior and design an\nalgorithm MIRROR to find a robust policy. MIRROR uses two reinforcement\nlearning-based oracles and solves a restricted game considering limited\ndefender strategies and parameter values. We evaluate MIRROR on real-world\npoaching data.",
          "link": "http://arxiv.org/abs/2106.08413",
          "publishedOn": "2021-06-17T01:58:45.817Z",
          "wordCount": 573,
          "title": "Robust Reinforcement Learning Under Minimax Regret for Green Security. (arXiv:2106.08413v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08548",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mohammadinejad_S/0/1/0/all/0/1\">Sara Mohammadinejad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deshmukh_J/0/1/0/all/0/1\">Jyotirmy V. Deshmukh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nenzi_L/0/1/0/all/0/1\">Laura Nenzi</a>",
          "description": "The Internet-of-Things, complex sensor networks, multi-agent cyber-physical\nsystems are all examples of spatially distributed systems that continuously\nevolve in time. Such systems generate huge amounts of spatio-temporal data, and\nsystem designers are often interested in analyzing and discovering structure\nwithin the data. There has been considerable interest in learning causal and\nlogical properties of temporal data using logics such as Signal Temporal Logic\n(STL); however, there is limited work on discovering such relations on\nspatio-temporal data. We propose the first set of algorithms for unsupervised\nlearning for spatio-temporal data. Our method does automatic feature extraction\nfrom the spatio-temporal data by projecting it onto the parameter space of a\nparametric spatio-temporal reach and escape logic (PSTREL). We propose an\nagglomerative hierarchical clustering technique that guarantees that each\ncluster satisfies a distinct STREL formula. We show that our method generates\nSTREL formulas of bounded description complexity using a novel decision-tree\napproach which generalizes previous unsupervised learning techniques for Signal\nTemporal Logic. We demonstrate the effectiveness of our approach on case\nstudies from diverse domains such as urban transportation, epidemiology, green\ninfrastructure, and air quality monitoring.",
          "link": "http://arxiv.org/abs/2106.08548",
          "publishedOn": "2021-06-17T01:58:45.810Z",
          "wordCount": 607,
          "title": "Mining Interpretable Spatio-temporal Logic Properties for Spatially Distributed Systems. (arXiv:2106.08548v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07141",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ozbulak_U/0/1/0/all/0/1\">Utku Ozbulak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anzaku_E/0/1/0/all/0/1\">Esla Timothy Anzaku</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neve_W/0/1/0/all/0/1\">Wesley De Neve</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Messem_A/0/1/0/all/0/1\">Arnout Van Messem</a>",
          "description": "Although the adoption rate of deep neural networks (DNNs) has tremendously\nincreased in recent years, a solution for their vulnerability against\nadversarial examples has not yet been found. As a result, substantial research\nefforts are dedicated to fix this weakness, with many studies typically using a\nsubset of source images to generate adversarial examples, treating every image\nin this subset as equal. We demonstrate that, in fact, not every source image\nis equally suited for this kind of assessment. To do so, we devise a\nlarge-scale model-to-model transferability scenario for which we meticulously\nanalyze the properties of adversarial examples, generated from every suitable\nsource image in ImageNet by making use of two of the most frequently deployed\nattacks. In this transferability scenario, which involves seven distinct DNN\nmodels, including the recently proposed vision transformers, we reveal that it\nis possible to have a difference of up to $12.5\\%$ in model-to-model\ntransferability success, $1.01$ in average $L_2$ perturbation, and $0.03$\n($8/225$) in average $L_{\\infty}$ perturbation when $1,000$ source images are\nsampled randomly among all suitable candidates. We then take one of the first\nsteps in evaluating the robustness of images used to create adversarial\nexamples, proposing a number of simple but effective methods to identify\nunsuitable source images, thus making it possible to mitigate extreme cases in\nexperimentation and support high-quality benchmarking.",
          "link": "http://arxiv.org/abs/2106.07141",
          "publishedOn": "2021-06-17T01:58:45.797Z",
          "wordCount": 681,
          "title": "Selection of Source Images Heavily Influences the Effectiveness of Adversarial Attacks. (arXiv:2106.07141v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.12937",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_R/0/1/0/all/0/1\">Ruoming Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jing Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Li Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yang Zhou</a>",
          "description": "Recently, linear regression models, such as EASE and SLIM, have shown to\noften produce rather competitive results against more sophisticated deep\nlearning models. On the other side, the (weighted) matrix factorization\napproaches have been popular choices for recommendation in the past and widely\nadopted in the industry. In this work, we aim to theoretically understand the\nrelationship between these two approaches, which are the cornerstones of\nmodel-based recommendations. Through the derivation and analysis of the\nclosed-form solutions for two basic regression and matrix factorization\napproaches, we found these two approaches are indeed inherently related but\nalso diverge in how they \"scale-down\" the singular values of the original\nuser-item interaction matrix. This analysis also helps resolve the questions\nrelated to the regularization parameter range and model complexities. We\nfurther introduce a new learning algorithm in searching (hyper)parameters for\nthe closed-form solution and utilize it to discover the nearby models of the\nexisting solutions. The experimental results demonstrate that the basic models\nand their closed-form solutions are indeed quite competitive against the\nstate-of-the-art models, thus, confirming the validity of studying the basic\nmodels. The effectiveness of exploring the nearby models are also\nexperimentally validated.",
          "link": "http://arxiv.org/abs/2105.12937",
          "publishedOn": "2021-06-17T01:58:45.779Z",
          "wordCount": 663,
          "title": "Towards a Better Understanding of Linear Models for Recommendation. (arXiv:2105.12937v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.10204",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tabaghi_P/0/1/0/all/0/1\">Puoya Tabaghi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chien_E/0/1/0/all/0/1\">Eli Chien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_C/0/1/0/all/0/1\">Chao Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_J/0/1/0/all/0/1\">Jianhao Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Milenkovic_O/0/1/0/all/0/1\">Olgica Milenkovi&#x107;</a>",
          "description": "Embedding methods for product spaces are powerful techniques for\nlow-distortion and low-dimensional representation of complex data structures.\nNevertheless, little is known regarding downstream learning and optimization\nproblems in such spaces. Here, we address the problem of linear classification\nin a product space form -- a mix of Euclidean, spherical, and hyperbolic\nspaces. First, we describe new formulations for linear classifiers on a\nRiemannian manifold using geodesics and Riemannian metrics which generalize\nstraight lines and inner products in vector spaces, respectively. Second, we\nprove that linear classifiers in $d$-dimensional space forms of any curvature\nhave the same expressive power, i.e., they can shatter exactly $d+1$ points.\nThird, we formalize linear classifiers in product space forms, describe the\nfirst corresponding perceptron and SVM classification algorithms, and establish\nrigorous convergence results for the former. We support our theoretical\nfindings with simulation results on several datasets, including synthetic data,\nCIFAR-100, MNIST, Omniglot, and single-cell RNA sequencing data. The results\nshow that learning methods applied to small-dimensional embeddings in product\nspace forms outperform their algorithmic counterparts in each space form.",
          "link": "http://arxiv.org/abs/2102.10204",
          "publishedOn": "2021-06-17T01:58:45.767Z",
          "wordCount": 630,
          "title": "Linear Classifiers in Product Space Forms. (arXiv:2102.10204v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.00107",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Wei_L/0/1/0/all/0/1\">Linchuan Wei</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gomez_A/0/1/0/all/0/1\">Andres Gomez</a>, <a href=\"http://arxiv.org/find/math/1/au:+Kucukyavuz_S/0/1/0/all/0/1\">Simge Kucukyavuz</a>",
          "description": "Motivated by modern regression applications, in this paper, we study the\nconvexification of a class of convex optimization problems with indicator\nvariables and combinatorial constraints on the indicators. Unlike most of the\nprevious work on convexification of sparse regression problems, we\nsimultaneously consider the nonlinear non-separable objective, indicator\nvariables, and combinatorial constraints. Specifically, we give the convex hull\ndescription of the epigraph of the composition of a one-dimensional convex\nfunction and an affine function under arbitrary combinatorial constraints. As\nspecial cases of this result, we derive ideal convexifications for problems\nwith hierarchy, multi-collinearity, and sparsity constraints. Moreover, we also\ngive a short proof that for a separable objective function, the perspective\nreformulation is ideal independent from the constraints of the problem. Our\ncomputational experiments with regression problems under hierarchy constraints\non real datasets demonstrate the potential of the proposed approach in\nimproving the relaxation quality without significant computational overhead.",
          "link": "http://arxiv.org/abs/2007.00107",
          "publishedOn": "2021-06-17T01:58:45.759Z",
          "wordCount": 598,
          "title": "Ideal formulations for constrained convex optimization problems with indicator variables. (arXiv:2007.00107v2 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08396",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Eden_T/0/1/0/all/0/1\">Talya Eden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Indyk_P/0/1/0/all/0/1\">Piotr Indyk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narayanan_S/0/1/0/all/0/1\">Shyam Narayanan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubinfeld_R/0/1/0/all/0/1\">Ronitt Rubinfeld</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silwal_S/0/1/0/all/0/1\">Sandeep Silwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wagner_T/0/1/0/all/0/1\">Tal Wagner</a>",
          "description": "We consider the problem of estimating the number of distinct elements in a\nlarge data set (or, equivalently, the support size of the distribution induced\nby the data set) from a random sample of its elements. The problem occurs in\nmany applications, including biology, genomics, computer systems and\nlinguistics. A line of research spanning the last decade resulted in algorithms\nthat estimate the support up to $ \\pm \\varepsilon n$ from a sample of size\n$O(\\log^2(1/\\varepsilon) \\cdot n/\\log n)$, where $n$ is the data set size.\nUnfortunately, this bound is known to be tight, limiting further improvements\nto the complexity of this problem. In this paper we consider estimation\nalgorithms augmented with a machine-learning-based predictor that, given any\nelement, returns an estimation of its frequency. We show that if the predictor\nis correct up to a constant approximation factor, then the sample complexity\ncan be reduced significantly, to \\[ \\ \\log (1/\\varepsilon) \\cdot\nn^{1-\\Theta(1/\\log(1/\\varepsilon))}. \\] We evaluate the proposed algorithms on\na collection of data sets, using the neural-network based estimators from {Hsu\net al, ICLR'19} as predictors. Our experiments demonstrate substantial (up to\n3x) improvements in the estimation accuracy compared to the state of the art\nalgorithm.",
          "link": "http://arxiv.org/abs/2106.08396",
          "publishedOn": "2021-06-17T01:58:45.726Z",
          "wordCount": 646,
          "title": "Learning-based Support Estimation in Sublinear Time. (arXiv:2106.08396v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.08866",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Vijaykumar_S/0/1/0/all/0/1\">Suhas Vijaykumar</a>",
          "description": "Offset Rademacher complexities have been shown to imply sharp, data-dependent\nupper bounds for the square loss in a broad class of problems including\nimproper statistical learning and online learning. We show that in the\nstatistical setting, the offset complexity upper bound can be generalized to\nany loss satisfying a certain uniform convexity condition. Amazingly, this\ncondition is shown to also capture exponential concavity and self-concordance,\nuniting several apparently disparate results. By a unified geometric argument,\nthese bounds translate directly to improper learning in a non-convex class\nusing Audibert's \"star algorithm.\" As applications, we recover the optimal\nrates for proper and improper learning with the $p$-loss, $1 < p < \\infty$ and\nshow that improper variants of empirical risk minimization can attain fast\nrates for logistic regression and other generalized linear models.",
          "link": "http://arxiv.org/abs/2105.08866",
          "publishedOn": "2021-06-17T01:58:45.720Z",
          "wordCount": 563,
          "title": "Localization, Convexity, and Star Aggregation. (arXiv:2105.08866v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08448",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cohen_Addad_V/0/1/0/all/0/1\">Vincent Cohen-Addad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lattanzi_S/0/1/0/all/0/1\">Silvio Lattanzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitrovic_S/0/1/0/all/0/1\">Slobodan Mitrovi&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Norouzi_Fard_A/0/1/0/all/0/1\">Ashkan Norouzi-Fard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parotsidis_N/0/1/0/all/0/1\">Nikos Parotsidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tarnawski_J/0/1/0/all/0/1\">Jakub Tarnawski</a>",
          "description": "Correlation clustering is a central topic in unsupervised learning, with many\napplications in ML and data mining. In correlation clustering, one receives as\ninput a signed graph and the goal is to partition it to minimize the number of\ndisagreements. In this work we propose a massively parallel computation (MPC)\nalgorithm for this problem that is considerably faster than prior work. In\nparticular, our algorithm uses machines with memory sublinear in the number of\nnodes in the graph and returns a constant approximation while running only for\na constant number of rounds. To the best of our knowledge, our algorithm is the\nfirst that can provably approximate a clustering problem on graphs using only a\nconstant number of MPC rounds in the sublinear memory regime. We complement our\nanalysis with an experimental analysis of our techniques.",
          "link": "http://arxiv.org/abs/2106.08448",
          "publishedOn": "2021-06-17T01:58:45.700Z",
          "wordCount": 581,
          "title": "Correlation Clustering in Constant Many Parallel Rounds. (arXiv:2106.08448v1 [cs.DS])"
        },
        {
          "id": "http://arxiv.org/abs/2012.00517",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Korpihalkola_J/0/1/0/all/0/1\">Joni Korpihalkola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sipola_T/0/1/0/all/0/1\">Tuomo Sipola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Puuska_S/0/1/0/all/0/1\">Samir Puuska</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kokkonen_T/0/1/0/all/0/1\">Tero Kokkonen</a>",
          "description": "Computer vision and machine learning can be used to automate various tasks in\ncancer diagnostic and detection. If an attacker can manipulate the automated\nprocessing, the results can be devastating and in the worst case lead to wrong\ndiagnosis and treatment. In this research, the goal is to demonstrate the use\nof one-pixel attacks in a real-life scenario with a real pathology dataset,\nTUPAC16, which consists of digitized whole-slide images. We attack against the\nIBM CODAIT's MAX breast cancer detector using adversarial images. These\nadversarial examples are found using differential evolution to perform the\none-pixel modification to the images in the dataset. The results indicate that\na minor one-pixel modification of a whole slide image under analysis can affect\nthe diagnosis by reversing the automatic diagnosis result. The attack poses a\nthreat from the cyber security perspective: the one-pixel method can be used as\nan attack vector by a motivated attacker.",
          "link": "http://arxiv.org/abs/2012.00517",
          "publishedOn": "2021-06-17T01:58:45.694Z",
          "wordCount": 632,
          "title": "One-Pixel Attack Deceives Computer-Assisted Diagnosis of Cancer. (arXiv:2012.00517v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08382",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sagar_A/0/1/0/all/0/1\">Abhinav Sagar</a>",
          "description": "Attention mechanism of late has been quite popular in the computer vision\ncommunity. A lot of work has been done to improve the performance of the\nnetwork, although almost always it results in increased computational\ncomplexity. In this paper, we propose a new attention module that not only\nachieves the best performance but also has lesser parameters compared to most\nexisting models. Our attention module can easily be integrated with other\nconvolutional neural networks because of its lightweight nature. The proposed\nnetwork named Dual Multi Scale Attention Network (DMSANet) is comprised of two\nparts: the first part is used to extract features at various scales and\naggregate them, the second part uses spatial and channel attention modules in\nparallel to adaptively integrate local features with their global dependencies.\nWe benchmark our network performance for Image Classification on ImageNet\ndataset, Object Detection and Instance Segmentation both on MS COCO dataset.",
          "link": "http://arxiv.org/abs/2106.08382",
          "publishedOn": "2021-06-17T01:58:45.686Z",
          "wordCount": 583,
          "title": "DMSANet: Dual Multi Scale Attention Network. (arXiv:2106.08382v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08477",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Rongpeng Li</a>",
          "description": "Online reinforcement learning (RL) has been widely applied in information\nprocessing scenarios, which usually exhibit much uncertainty due to the\nintrinsic randomness of channels and service demands. In this paper, we\nconsider an un-discounted RL in general Markov decision processes (MDPs) with\nboth endogeneous and exogeneous uncertainty, where both the rewards and state\ntransition probability are unknown to the RL agent and evolve with the time as\nlong as their respective variations do not exceed certain dynamic budget (i.e.,\nupper bound). We first develop a variation-aware Bernstein-based upper\nconfidence reinforcement learning (VB-UCRL), which we allow to restart\naccording to a schedule dependent on the variations. We successfully overcome\nthe challenges due to the exogeneous uncertainty and establish a regret bound\nof saving at most $\\sqrt{S}$ or $S^{\\frac{1}{6}}T^{\\frac{1}{12}}$ compared with\nthe latest results in the literature, where $S$ denotes the state size of the\nMDP and $T$ indicates the iteration index of learning steps.",
          "link": "http://arxiv.org/abs/2106.08477",
          "publishedOn": "2021-06-17T01:58:45.615Z",
          "wordCount": 595,
          "title": "Fundamental Limits of Reinforcement Learning in Environment with Endogeneous and Exogeneous Uncertainty. (arXiv:2106.08477v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2104.02125",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Chojnacka_R/0/1/0/all/0/1\">Roza Chojnacka</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pelecanos_J/0/1/0/all/0/1\">Jason Pelecanos</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_Q/0/1/0/all/0/1\">Quan Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Moreno_I/0/1/0/all/0/1\">Ignacio Lopez Moreno</a>",
          "description": "In this paper, we describe SpeakerStew - a hybrid system to perform speaker\nverification on 46 languages. Two core ideas were explored in this system: (1)\nPooling training data of different languages together for multilingual\ngeneralization and reducing development cycles; (2) A novel triage mechanism\nbetween text-dependent and text-independent models to reduce runtime cost and\nexpected latency. To the best of our knowledge, this is the first study of\nspeaker verification systems at the scale of 46 languages. The problem is\nframed from the perspective of using a smart speaker device with interactions\nconsisting of a wake-up keyword (text-dependent) followed by a speech query\n(text-independent). Experimental evidence suggests that training on multiple\nlanguages can generalize to unseen varieties while maintaining performance on\nseen varieties. We also found that it can reduce computational requirements for\ntraining models by an order of magnitude. Furthermore, during model inference\non English data, we observe that leveraging a triage framework can reduce the\nnumber of calls to the more computationally expensive text-independent system\nby 73% (and reduce latency by 59%) while maintaining an EER no worse than the\ntext-independent setup.",
          "link": "http://arxiv.org/abs/2104.02125",
          "publishedOn": "2021-06-17T01:58:45.188Z",
          "wordCount": 670,
          "title": "SpeakerStew: Scaling to Many Languages with a Triaged Multilingual Text-Dependent and Text-Independent Speaker Verification System. (arXiv:2104.02125v3 [eess.AS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08376",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Carmichael_Z/0/1/0/all/0/1\">Zachariah Carmichael</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scheirer_W/0/1/0/all/0/1\">Walter J. Scheirer</a>",
          "description": "Many applications of data-driven models demand transparency of decisions,\nespecially in health care, criminal justice, and other high-stakes\nenvironments. Modern trends in machine learning research have led to algorithms\nthat are increasingly intricate to the degree that they are considered to be\nblack boxes. In an effort to reduce the opacity of decisions, methods have been\nproposed to construe the inner workings of such models in a\nhuman-comprehensible manner. These post hoc techniques are described as being\nuniversal explainers - capable of faithfully augmenting decisions with\nalgorithmic insight. Unfortunately, there is little agreement about what\nconstitutes a \"good\" explanation. Moreover, current methods of explanation\nevaluation are derived from either subjective or proxy means. In this work, we\npropose a framework for the evaluation of post hoc explainers on ground truth\nthat is directly derived from the additive structure of a model. We demonstrate\nthe efficacy of the framework in understanding explainers by evaluating popular\nexplainers on thousands of synthetic and several real-world tasks. The\nframework unveils that explanations may be accurate but misattribute the\nimportance of individual features.",
          "link": "http://arxiv.org/abs/2106.08376",
          "publishedOn": "2021-06-17T01:58:45.163Z",
          "wordCount": 615,
          "title": "On the Objective Evaluation of Post Hoc Explainers. (arXiv:2106.08376v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08462",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Voleti_V/0/1/0/all/0/1\">Vikram Voleti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Finlay_C/0/1/0/all/0/1\">Chris Finlay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oberman_A/0/1/0/all/0/1\">Adam Oberman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pal_C/0/1/0/all/0/1\">Christopher Pal</a>",
          "description": "Recent work has shown that Neural Ordinary Differential Equations (ODEs) can\nserve as generative models of images using the perspective of Continuous\nNormalizing Flows (CNFs). Such models offer exact likelihood calculation, and\ninvertible generation/density estimation. In this work we introduce a\nMulti-Resolution variant of such models (MRCNF), by characterizing the\nconditional distribution over the additional information required to generate a\nfine image that is consistent with the coarse image. We introduce a\ntransformation between resolutions that allows for no change in the log\nlikelihood. We show that this approach yields comparable likelihood values for\nvarious image datasets, with improved performance at higher resolutions, with\nfewer parameters, using only 1 GPU.",
          "link": "http://arxiv.org/abs/2106.08462",
          "publishedOn": "2021-06-17T01:58:45.157Z",
          "wordCount": 552,
          "title": "Multi-Resolution Continuous Normalizing Flows. (arXiv:2106.08462v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08387",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiefeng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yang Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tianqi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lao_Q/0/1/0/all/0/1\">Qicheng Lao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yingyu Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jha_S/0/1/0/all/0/1\">Somesh Jha</a>",
          "description": "There has been emerging interest to use transductive learning for adversarial\nrobustness (Goldwasser et al., NeurIPS 2020; Wu et al., ICML 2020). Compared to\ntraditional \"test-time\" defenses, these defense mechanisms \"dynamically\nretrain\" the model based on test time input via transductive learning; and\ntheoretically, attacking these defenses boils down to bilevel optimization,\nwhich seems to raise the difficulty for adaptive attacks. In this paper, we\nfirst formalize and analyze modeling aspects of transductive robustness. Then,\nwe propose the principle of attacking model space for solving bilevel attack\nobjectives, and present an instantiation of the principle which breaks previous\ntransductive defenses. These attacks thus point to significant difficulties in\nthe use of transductive learning to improve adversarial robustness. To this\nend, we present new theoretical and empirical evidence in support of the\nutility of transductive learning.",
          "link": "http://arxiv.org/abs/2106.08387",
          "publishedOn": "2021-06-17T01:58:45.149Z",
          "wordCount": 566,
          "title": "Towards Adversarial Robustness via Transductive Learning. (arXiv:2106.08387v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08641",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schrouff_J/0/1/0/all/0/1\">Jessica Schrouff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baur_S/0/1/0/all/0/1\">Sebastien Baur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_S/0/1/0/all/0/1\">Shaobo Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mincu_D/0/1/0/all/0/1\">Diana Mincu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Loreaux_E/0/1/0/all/0/1\">Eric Loreaux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blanes_R/0/1/0/all/0/1\">Ralph Blanes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wexler_J/0/1/0/all/0/1\">James Wexler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karthikesalingam_A/0/1/0/all/0/1\">Alan Karthikesalingam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_B/0/1/0/all/0/1\">Been Kim</a>",
          "description": "Interpretability techniques aim to provide the rationale behind a model's\ndecision, typically by explaining either an individual prediction (local\nexplanation, e.g. `why is this patient diagnosed with this condition') or a\nclass of predictions (global explanation, e.g. `why are patients diagnosed with\nthis condition in general'). While there are many methods focused on either\none, few frameworks can provide both local and global explanations in a\nconsistent manner. In this work, we combine two powerful existing techniques,\none local (Integrated Gradients, IG) and one global (Testing with Concept\nActivation Vectors), to provide local, and global concept-based explanations.\nWe first validate our idea using two synthetic datasets with a known ground\ntruth, and further demonstrate with a benchmark natural image dataset. We test\nour method with various concepts, target classes, model architectures and IG\nbaselines. We show that our method improves global explanations over TCAV when\ncompared to ground truth, and provides useful insights. We hope our work\nprovides a step towards building bridges between many existing local and global\nmethods to get the best of both worlds.",
          "link": "http://arxiv.org/abs/2106.08641",
          "publishedOn": "2021-06-17T01:58:45.134Z",
          "wordCount": 616,
          "title": "Best of both worlds: local and global explanations with human-understandable concepts. (arXiv:2106.08641v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08443",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ghojogh_B/0/1/0/all/0/1\">Benyamin Ghojogh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ghodsi_A/0/1/0/all/0/1\">Ali Ghodsi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Karray_F/0/1/0/all/0/1\">Fakhri Karray</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Crowley_M/0/1/0/all/0/1\">Mark Crowley</a>",
          "description": "This is a tutorial and survey paper on kernels, kernel methods, and related\nfields. We start with reviewing the history of kernels in functional analysis\nand machine learning. Then, Mercer kernel, Hilbert and Banach spaces,\nReproducing Kernel Hilbert Space (RKHS), Mercer's theorem and its proof,\nfrequently used kernels, kernel construction from distance metric, important\nclasses of kernels (including bounded, integrally positive definite, universal,\nstationary, and characteristic kernels), kernel centering and normalization,\nand eigenfunctions are explained in detail. Then, we introduce types of use of\nkernels in machine learning including kernel methods (such as kernel support\nvector machines), kernel learning by semi-definite programming, Hilbert-Schmidt\nindependence criterion, maximum mean discrepancy, kernel mean embedding, and\nkernel dimensionality reduction. We also cover rank and factorization of kernel\nmatrix as well as the approximation of eigenfunctions and kernels using the\nNystr{\\\"o}m method. This paper can be useful for various fields of science\nincluding machine learning, dimensionality reduction, functional analysis in\nmathematics, and mathematical physics in quantum mechanics.",
          "link": "http://arxiv.org/abs/2106.08443",
          "publishedOn": "2021-06-17T01:58:45.097Z",
          "wordCount": 633,
          "title": "Reproducing Kernel Hilbert Space, Mercer's Theorem, Eigenfunctions, Nystr\\\"om Method, and Use of Kernels in Machine Learning: Tutorial and Survey. (arXiv:2106.08443v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.09017",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haoxiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Han Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>",
          "description": "Multi-task learning (MTL) aims to improve the generalization of several\nrelated tasks by learning them jointly. As a comparison, in addition to the\njoint training scheme, modern meta-learning allows unseen tasks with limited\nlabels during the test phase, in the hope of fast adaptation over them. Despite\nthe subtle difference between MTL and meta-learning in the problem formulation,\nboth learning paradigms share the same insight that the shared structure\nbetween existing training tasks could lead to better generalization and\nadaptation. In this paper, we take one important step further to understand the\nclose connection between these two learning paradigms, through both theoretical\nanalysis and empirical investigation. Theoretically, we first demonstrate that\nMTL shares the same optimization formulation with a class of gradient-based\nmeta-learning (GBML) algorithms. We then prove that for over-parameterized\nneural networks with sufficient depth, the learned predictive functions of MTL\nand GBML are close. In particular, this result implies that the predictions\ngiven by these two models are similar over the same unseen task. Empirically,\nwe corroborate our theoretical findings by showing that, with proper\nimplementation, MTL is competitive against state-of-the-art GBML algorithms on\na set of few-shot image classification benchmarks. Since existing GBML\nalgorithms often involve costly second-order bi-level optimization, our\nfirst-order MTL method is an order of magnitude faster on large-scale datasets\nsuch as mini-ImageNet. We believe this work could help bridge the gap between\nthese two learning paradigms, and provide a computationally efficient\nalternative to GBML that also supports fast task adaptation.",
          "link": "http://arxiv.org/abs/2106.09017",
          "publishedOn": "2021-06-17T01:58:45.091Z",
          "wordCount": 699,
          "title": "Bridging Multi-Task Learning and Meta-Learning: Towards Efficient Training and Effective Adaptation. (arXiv:2106.09017v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08377",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Liyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jafarnia_Jahromi_M/0/1/0/all/0/1\">Mehdi Jafarnia-Jahromi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_R/0/1/0/all/0/1\">Rahul Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1\">Haipeng Luo</a>",
          "description": "We introduce a generic template for developing regret minimization algorithms\nin the Stochastic Shortest Path (SSP) model, which achieves minimax optimal\nregret as long as certain properties are ensured. The key of our analysis is a\nnew technique called implicit finite-horizon approximation, which approximates\nthe SSP model by a finite-horizon counterpart only in the analysis without\nexplicit implementation. Using this template, we develop two new algorithms:\nthe first one is model-free (the first in the literature to our knowledge) and\nminimax optimal under strictly positive costs; the second one is model-based\nand minimax optimal even with zero-cost state-action pairs, matching the best\nexisting result from [Tarbouriech et al., 2021b]. Importantly, both algorithms\nadmit highly sparse updates, making them computationally more efficient than\nall existing algorithms. Moreover, both can be made completely parameter-free.",
          "link": "http://arxiv.org/abs/2106.08377",
          "publishedOn": "2021-06-17T01:58:45.086Z",
          "wordCount": 567,
          "title": "Implicit Finite-Horizon Approximation and Efficient Optimal Algorithms for Stochastic Shortest Path. (arXiv:2106.08377v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08774",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gottwald_M/0/1/0/all/0/1\">Martin Gottwald</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Gronauer_S/0/1/0/all/0/1\">Sven Gronauer</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1\">Hao Shen</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Diepold_K/0/1/0/all/0/1\">Klaus Diepold</a> (1) ((1) Technical University of Munich, (2) fortiss)",
          "description": "Recent development of Deep Reinforcement Learning has demonstrated superior\nperformance of neural networks in solving challenging problems with large or\neven continuous state spaces. One specific approach is to deploy neural\nnetworks to approximate value functions by minimising the Mean Squared Bellman\nError function. Despite great successes of Deep Reinforcement Learning,\ndevelopment of reliable and efficient numerical algorithms to minimise the\nBellman Error is still of great scientific interest and practical demand. Such\na challenge is partially due to the underlying optimisation problem being\nhighly non-convex or using incorrect gradient information as done in\nSemi-Gradient algorithms. In this work, we analyse the Mean Squared Bellman\nError from a smooth optimisation perspective combined with a Residual Gradient\nformulation. Our contribution is two-fold.\n\nFirst, we analyse critical points of the error function and provide technical\ninsights on the optimisation procure and design choices for neural networks.\nWhen the existence of global minima is assumed and the objective fulfils\ncertain conditions we can eliminate suboptimal local minima when using\nover-parametrised neural networks. We can construct an efficient Approximate\nNewton's algorithm based on our analysis and confirm theoretical properties of\nthis algorithm such as being locally quadratically convergent to a global\nminimum numerically.\n\nSecond, we demonstrate feasibility and generalisation capabilities of the\nproposed algorithm empirically using continuous control problems and provide a\nnumerical verification of our critical point analysis. We outline the short\ncoming of Semi-Gradients. To benefit from an approximate Newton's algorithm\ncomplete derivatives of the Mean Squared Bellman error must be considered\nduring training.",
          "link": "http://arxiv.org/abs/2106.08774",
          "publishedOn": "2021-06-17T01:58:45.080Z",
          "wordCount": 700,
          "title": "Analysis and Optimisation of Bellman Residual Errors with Neural Function Approximation. (arXiv:2106.08774v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08848",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1\">Zhengzheng Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Z/0/1/0/all/0/1\">Ziyue Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_X/0/1/0/all/0/1\">Xuehai Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dharejo_F/0/1/0/all/0/1\">Fayaz Ali Dharejo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yuanchun Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1\">Yi Du</a>",
          "description": "Data augmentation aims to generate new and synthetic features from the\noriginal data, which can identify a better representation of data and improve\nthe performance and generalizability of downstream tasks. However, data\naugmentation for graph-based models remains a challenging problem, as graph\ndata is more complex than traditional data, which consists of two features with\ndifferent properties: graph topology and node attributes. In this paper, we\nstudy the problem of graph data augmentation for Graph Convolutional Network\n(GCN) in the context of improving the node embeddings for semi-supervised node\nclassification. Specifically, we conduct cosine similarity based cross\noperation on the original features to create new graph features, including new\nnode attributes and new graph topologies, and we combine them as new pairwise\ninputs for specific GCNs. Then, we propose an attentional integrating model to\nweighted sum the hidden node embeddings encoded by these GCNs into the final\nnode embeddings. We also conduct a disparity constraint on these hidden node\nembeddings when training to ensure that non-redundant information is captured\nfrom different features. Experimental results on five real-world datasets show\nthat our method improves the classification accuracy with a clear margin (+2.5%\n- +84.2%) than the original GCN model.",
          "link": "http://arxiv.org/abs/2106.08848",
          "publishedOn": "2021-06-17T01:58:45.074Z",
          "wordCount": 654,
          "title": "Data Augmentation for Graph Convolutional Network on Semi-Supervised Classification. (arXiv:2106.08848v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2009.08452",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bhatia_S/0/1/0/all/0/1\">Siddharth Bhatia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1\">Rui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hooi_B/0/1/0/all/0/1\">Bryan Hooi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_M/0/1/0/all/0/1\">Minji Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_K/0/1/0/all/0/1\">Kijung Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faloutsos_C/0/1/0/all/0/1\">Christos Faloutsos</a>",
          "description": "Given a stream of graph edges from a dynamic graph, how can we assign anomaly\nscores to edges in an online manner, for the purpose of detecting unusual\nbehavior, using constant time and memory? Existing approaches aim to detect\nindividually surprising edges. In this work, we propose MIDAS, which focuses on\ndetecting microcluster anomalies, or suddenly arriving groups of suspiciously\nsimilar edges, such as lockstep behavior, including denial of service attacks\nin network traffic data. We further propose MIDAS-F, to solve the problem by\nwhich anomalies are incorporated into the algorithm's internal states, creating\na `poisoning' effect that can allow future anomalies to slip through\nundetected. MIDAS-F introduces two modifications: 1) We modify the anomaly\nscoring function, aiming to reduce the `poisoning' effect of newly arriving\nedges; 2) We introduce a conditional merge step, which updates the algorithm's\ndata structures after each time tick, but only if the anomaly score is below a\nthreshold value, also to reduce the `poisoning' effect. Experiments show that\nMIDAS-F has significantly higher accuracy than MIDAS. MIDAS has the following\nproperties: (a) it detects microcluster anomalies while providing theoretical\nguarantees about its false positive probability; (b) it is online, thus\nprocessing each edge in constant time and constant memory, and also processes\nthe data orders-of-magnitude faster than state-of-the-art approaches; (c) it\nprovides up to 62% higher ROC-AUC than state-of-the-art approaches.",
          "link": "http://arxiv.org/abs/2009.08452",
          "publishedOn": "2021-06-17T01:58:45.068Z",
          "wordCount": 696,
          "title": "Real-Time Anomaly Detection in Edge Streams. (arXiv:2009.08452v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.05056",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cattaneo_D/0/1/0/all/0/1\">Daniele Cattaneo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vaghi_M/0/1/0/all/0/1\">Matteo Vaghi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valada_A/0/1/0/all/0/1\">Abhinav Valada</a>",
          "description": "Loop closure detection is an essential component of Simultaneous Localization\nand Mapping (SLAM) systems, which reduces the drift accumulated over time. Over\nthe years, several deep learning approaches have been proposed to address this\ntask, however their performance has been subpar compared to handcrafted\ntechniques, especially while dealing with reverse loops. In this paper, we\nintroduce the novel LCDNet that effectively detects loop closures in LiDAR\npoint clouds by simultaneously identifying previously visited places and\nestimating the 6-DoF relative transformation between the current scan and the\nmap. LCDNet is composed of a shared encoder, a place recognition head that\nextracts global descriptors, and a relative pose head that estimates the\ntransformation between two point clouds. We introduce a novel relative pose\nhead based on the unbalanced optimal transport theory that we implement in a\ndifferentiable manner to allow for end-to-end training. Extensive evaluations\nof LCDNet on multiple real-world autonomous driving datasets show that our\napproach outperforms state-of-the-art loop closure detection and point cloud\nregistration techniques by a large margin, especially while dealing with\nreverse loops. Moreover, we integrate our proposed loop closure detection\napproach into a LiDAR SLAM library to provide a complete mapping system and\ndemonstrate the generalization ability using different sensor setup in an\nunseen city.",
          "link": "http://arxiv.org/abs/2103.05056",
          "publishedOn": "2021-06-17T01:58:45.014Z",
          "wordCount": 675,
          "title": "LCDNet: Deep Loop Closure Detection and Point Cloud Registration for LiDAR SLAM. (arXiv:2103.05056v2 [cs.RO] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08419",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Digani_J/0/1/0/all/0/1\">Jagrit Digani</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Hon_P/0/1/0/all/0/1\">Phillip Hon</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Davoyan_A/0/1/0/all/0/1\">Artur R. Davoyan</a>",
          "description": "Photonic inverse design has emerged as an indispensable engineering tool for\ncomplex optical systems. In many instances it is important to optimize for both\nmaterial and geometry configurations, which results in complex non-smooth\nsearch spaces with multiple local minima. Finding solutions approaching global\noptimum may present a computationally intractable task. Here, we develop a\nframework that allows expediting the search of solutions close to global\noptimum on complex optimization spaces. We study the way representative black\nbox optimization algorithms work, including genetic algorithm (GA), particle\nswarm optimization (PSO), simulated annealing (SA), and mesh adaptive direct\nsearch (NOMAD). We then propose and utilize a two-step approach that identifies\nbest performance algorithms on arbitrarily complex search spaces. We reveal a\nconnection between the search space complexity and algorithm performance and\nfind that PSO and NOMAD consistently deliver better performance for mixed\ninteger problems encountered in photonic inverse design, particularly with the\naccount of material combinations. Our results differ from a commonly\nanticipated advantage of GA. Our findings will foster more efficient design of\nphotonic systems with optimal performance.",
          "link": "http://arxiv.org/abs/2106.08419",
          "publishedOn": "2021-06-17T01:58:45.006Z",
          "wordCount": 616,
          "title": "A Framework for Discovering Optimal Solutions in Photonic Inverse Design. (arXiv:2106.08419v1 [physics.optics])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08630",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hayeon Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sewoong Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chong_S/0/1/0/all/0/1\">Song Chong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1\">Sung Ju Hwang</a>",
          "description": "For deployment, neural architecture search should be hardware-aware, in order\nto satisfy the device-specific constraints (e.g., memory usage, latency and\nenergy consumption) and enhance the model efficiency. Existing methods on\nhardware-aware NAS collect a large number of samples (e.g., accuracy and\nlatency) from a target device, either builds a lookup table or a latency\nestimator. However, such approach is impractical in real-world scenarios as\nthere exist numerous devices with different hardware specifications, and\ncollecting samples from such a large number of devices will require prohibitive\ncomputational and monetary cost. To overcome such limitations, we propose\nHardware-adaptive Efficient Latency Predictor (HELP), which formulates the\ndevice-specific latency estimation problem as a meta-learning problem, such\nthat we can estimate the latency of a model's performance for a given task on\nan unseen device with a few samples. To this end, we introduce novel hardware\nembeddings to embed any devices considering them as black-box functions that\noutput latencies, and meta-learn the hardware-adaptive latency predictor in a\ndevice-dependent manner, using the hardware embeddings. We validate the\nproposed HELP for its latency estimation performance on unseen platforms, on\nwhich it achieves high estimation performance with as few as 10 measurement\nsamples, outperforming all relevant baselines. We also validate end-to-end NAS\nframeworks using HELP against ones without it, and show that it largely reduces\nthe total time cost of the base NAS method, in latency-constrained settings.",
          "link": "http://arxiv.org/abs/2106.08630",
          "publishedOn": "2021-06-17T01:58:44.993Z",
          "wordCount": 655,
          "title": "HELP: Hardware-Adaptive Efficient Latency Predictor for NAS via Meta-Learning. (arXiv:2106.08630v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.09015",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Peng_S/0/1/0/all/0/1\">Shichong Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moazeni_A/0/1/0/all/0/1\">Alireza Moazeni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1\">Ke Li</a>",
          "description": "Deep generative models such as GANs have driven impressive advances in\nconditional image synthesis in recent years. A persistent challenge has been to\ngenerate diverse versions of output images from the same input image, due to\nthe problem of mode collapse: because only one ground truth output image is\ngiven per input image, only one mode of the conditional distribution is\nmodelled. In this paper, we focus on this problem of multimodal conditional\nimage synthesis and build on the recently proposed technique of Implicit\nMaximum Likelihood Estimation (IMLE). Prior IMLE-based methods required\ndifferent architectures for different tasks, which limit their applicability,\nand were lacking in fine details in the generated images. We propose CAM-Net, a\nunified architecture that can be applied to a broad range of tasks.\nAdditionally, it is capable of generating convincing high frequency details,\nachieving a reduction of the Frechet Inception Distance (FID) by up to 45.3%\ncompared to the baseline.",
          "link": "http://arxiv.org/abs/2106.09015",
          "publishedOn": "2021-06-17T01:58:44.978Z",
          "wordCount": 627,
          "title": "Cascading Modular Network (CAM-Net) for Multimodal Image Synthesis. (arXiv:2106.09015v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/1907.12207",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lemhadri_I/0/1/0/all/0/1\">Ismael Lemhadri</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ruan_F/0/1/0/all/0/1\">Feng Ruan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Abraham_L/0/1/0/all/0/1\">Louis Abraham</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tibshirani_R/0/1/0/all/0/1\">Robert Tibshirani</a>",
          "description": "Much work has been done recently to make neural networks more interpretable,\nand one obvious approach is to arrange for the network to use only a subset of\nthe available features. In linear models, Lasso (or $\\ell_1$-regularized)\nregression assigns zero weights to the most irrelevant or redundant features,\nand is widely used in data science. However the Lasso only applies to linear\nmodels. Here we introduce LassoNet, a neural network framework with global\nfeature selection. Our approach enforces a hierarchy: specifically a feature\ncan participate in a hidden unit only if its linear representative is active.\nUnlike other approaches to feature selection for neural nets, our method uses a\nmodified objective function with constraints, and so integrates feature\nselection with the parameter learning directly. As a result, it delivers an\nentire regularization path of solutions with a range of feature sparsity. On\nsystematic experiments, LassoNet significantly outperforms state-of-the-art\nmethods for feature selection and regression. The LassoNet method uses\nprojected proximal gradient descent, and generalizes directly to deep networks.\nIt can be implemented by adding just a few lines of code to a standard neural\nnetwork.",
          "link": "http://arxiv.org/abs/1907.12207",
          "publishedOn": "2021-06-17T01:58:44.962Z",
          "wordCount": 725,
          "title": "LassoNet: A Neural Network with Feature Sparsity. (arXiv:1907.12207v10 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.04261",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yikai Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xingyu Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chenwei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_A/0/1/0/all/0/1\">Annie Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_R/0/1/0/all/0/1\">Rong Ge</a>",
          "description": "Hessian captures important properties of the deep neural network loss\nlandscape. Previous works have observed low rank structure in the Hessians of\nneural networks. We make several new observations about the top eigenspace of\nlayer-wise Hessian: top eigenspaces for different models have surprisingly high\noverlap, and top eigenvectors form low rank matrices when they are reshaped\ninto the same shape as the corresponding weight matrix. Towards formally\nexplaining such structures of the Hessian, we show that the new eigenspace\nstructure can be explained by approximating the Hessian using Kronecker\nfactorization; we also prove the low rank structure for random data at random\ninitialization for over-parametrized two-layer neural nets. Our new\nunderstanding can explain why some of these structures become weaker when the\nnetwork is trained with batch normalization. The Kronecker factorization also\nleads to better explicit generalization bounds.",
          "link": "http://arxiv.org/abs/2010.04261",
          "publishedOn": "2021-06-17T01:58:44.943Z",
          "wordCount": 657,
          "title": "Dissecting Hessian: Understanding Common Structure of Hessian in Neural Networks. (arXiv:2010.04261v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.04229",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Kasim_M/0/1/0/all/0/1\">Muhammad F. Kasim</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Vinko_S/0/1/0/all/0/1\">Sam M. Vinko</a>",
          "description": "Improving the predictive capability of molecular properties in ab initio\nsimulations is essential for advanced material discovery. Despite recent\nprogress making use of machine learning, utilizing deep neural networks to\nimprove quantum chemistry modelling remains severely limited by the scarcity\nand heterogeneity of appropriate experimental data. Here we show how training a\nneural network to replace the exchange-correlation functional within a\nfully-differentiable three-dimensional Kohn-Sham density functional theory\n(DFT) framework can greatly improve simulation accuracy. Using only eight\nexperimental data points on diatomic molecules, our trained\nexchange-correlation networks enable improved prediction accuracy of\natomization energies across a collection of 104 molecules containing new bonds\nand atoms that are not present in the training dataset.",
          "link": "http://arxiv.org/abs/2102.04229",
          "publishedOn": "2021-06-17T01:58:44.918Z",
          "wordCount": 586,
          "title": "Learning the exchange-correlation functional from nature with fully differentiable density functional theory. (arXiv:2102.04229v4 [physics.chem-ph] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.05072",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Courts_J/0/1/0/all/0/1\">Jarrad Courts</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wills_A/0/1/0/all/0/1\">Adrian Wills</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Schon_T/0/1/0/all/0/1\">Thomas Sch&#xf6;n</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ninness_B/0/1/0/all/0/1\">Brett Ninness</a>",
          "description": "This paper considers parameter estimation for nonlinear state-space models,\nwhich is an important but challenging problem. We address this challenge by\nemploying a variational inference (VI) approach, which is a principled method\nthat has deep connections to maximum likelihood estimation. This VI approach\nultimately provides estimates of the model as solutions to an optimisation\nproblem, which is deterministic, tractable and can be solved using standard\noptimisation tools. A specialisation of this approach for systems with additive\nGaussian noise is also detailed. The proposed method is examined numerically on\na range of simulated and real examples focusing on the robustness to parameter\ninitialisation; additionally, favourable comparisons are performed against\nstate-of-the-art alternatives.",
          "link": "http://arxiv.org/abs/2012.05072",
          "publishedOn": "2021-06-17T01:58:44.902Z",
          "wordCount": 564,
          "title": "Variational System Identification for Nonlinear State-Space Models. (arXiv:2012.05072v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.08541",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Xiu_Z/0/1/0/all/0/1\">Zidi Xiu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tao_C/0/1/0/all/0/1\">Chenyang Tao</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gao_M/0/1/0/all/0/1\">Michael Gao</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Davis_C/0/1/0/all/0/1\">Connor Davis</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Goldstein_B/0/1/0/all/0/1\">Benjamin A. Goldstein</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Henao_R/0/1/0/all/0/1\">Ricardo Henao</a>",
          "description": "Combining the increasing availability and abundance of healthcare data and\nthe current advances in machine learning methods have created renewed\nopportunities to improve clinical decision support systems. However, in\nhealthcare risk prediction applications, the proportion of cases with the\ncondition (label) of interest is often very low relative to the available\nsample size. Though very prevalent in healthcare, such imbalanced\nclassification settings are also common and challenging in many other\nscenarios. So motivated, we propose a variational disentanglement approach to\nsemi-parametrically learn from rare events in heavily imbalanced classification\nproblems. Specifically, we leverage the imposed extreme-distribution behavior\non a latent space to extract information from low-prevalence events, and\ndevelop a robust prediction arm that joins the merits of the generalized\nadditive model and isotonic neural nets. Results on synthetic studies and\ndiverse real-world datasets, including mortality prediction on a COVID-19\ncohort, demonstrate that the proposed approach outperforms existing\nalternatives.",
          "link": "http://arxiv.org/abs/2009.08541",
          "publishedOn": "2021-06-17T01:58:44.852Z",
          "wordCount": 670,
          "title": "Variational Disentanglement for Rare Event Modeling. (arXiv:2009.08541v5 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.01681",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Liu_C/0/1/0/all/0/1\">Chang Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sun_X/0/1/0/all/0/1\">Xinwei Sun</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_J/0/1/0/all/0/1\">Jindong Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tang_H/0/1/0/all/0/1\">Haoyue Tang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_T/0/1/0/all/0/1\">Tao Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Qin_T/0/1/0/all/0/1\">Tao Qin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chen_W/0/1/0/all/0/1\">Wei Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liu_T/0/1/0/all/0/1\">Tie-Yan Liu</a>",
          "description": "Conventional supervised learning methods, especially deep ones, are found to\nbe sensitive to out-of-distribution (OOD) examples, largely because the learned\nrepresentation mixes the semantic factor with the variation factor due to their\ndomain-specific correlation, while only the semantic factor causes the output.\nTo address the problem, we propose a Causal Semantic Generative model (CSG)\nbased on a causal reasoning so that the two factors are modeled separately, and\ndevelop methods for OOD prediction from a single training domain, which is\ncommon and challenging. The methods are based on the causal invariance\nprinciple, with a novel design for both efficient learning and easy prediction.\nTheoretically, we prove that under certain conditions, CSG can identify the\nsemantic factor by fitting training data, and this semantic-identification\nguarantees the boundedness of OOD generalization error and the success of\nadaptation. Empirical study shows improved OOD performance over prevailing\nbaselines.",
          "link": "http://arxiv.org/abs/2011.01681",
          "publishedOn": "2021-06-17T01:58:44.840Z",
          "wordCount": 658,
          "title": "Learning Causal Semantic Representation for Out-of-Distribution Prediction. (arXiv:2011.01681v4 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.06148",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Ahmadi_A/0/1/0/all/0/1\">Amir Ali Ahmadi</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhang_J/0/1/0/all/0/1\">Jeffrey Zhang</a>",
          "description": "We consider the notions of (i) critical points, (ii) second-order points,\n(iii) local minima, and (iv) strict local minima for multivariate polynomials.\nFor each type of point, and as a function of the degree of the polynomial, we\nstudy the complexity of deciding (1) if a given point is of that type, and (2)\nif a polynomial has a point of that type. Our results characterize the\ncomplexity of these two questions for all degrees left open by prior\nliterature. Our main contributions reveal that many of these questions turn out\nto be tractable for cubic polynomials. In particular, we present an\nefficiently-checkable necessary and sufficient condition for local minimality\nof a point for a cubic polynomial. We also show that a local minimum of a cubic\npolynomial can be efficiently found by solving semidefinite programs of size\nlinear in the number of variables. By contrast, we show that it is strongly\nNP-hard to decide if a cubic polynomial has a critical point. We also prove\nthat the set of second-order points of any cubic polynomial is a spectrahedron,\nand conversely that any spectrahedron is the projection of the set of\nsecond-order points of a cubic polynomial. In our final section, we briefly\npresent a potential application of finding local minima of cubic polynomials to\nthe design of a third-order Newton method.",
          "link": "http://arxiv.org/abs/2008.06148",
          "publishedOn": "2021-06-17T01:58:44.823Z",
          "wordCount": 683,
          "title": "Complexity aspects of local minima and related notions. (arXiv:2008.06148v2 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2004.09764",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fang_X/0/1/0/all/0/1\">Xianghong Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_H/0/1/0/all/0/1\">Haoli Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zenglin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_M/0/1/0/all/0/1\">Michael Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+King_I/0/1/0/all/0/1\">Irwin King</a>",
          "description": "Variational autoencoders have been widely applied for natural language\ngeneration, however, there are two long-standing problems: information\nunder-representation and posterior collapse. The former arises from the fact\nthat only the last hidden state from the encoder is transformed to the latent\nspace, which is insufficient to summarize data. The latter comes as a result of\nthe imbalanced scale between the reconstruction loss and the KL divergence in\nthe objective function. To tackle these issues, in this paper we propose the\ndiscrete variational attention model with categorical distribution over the\nattention mechanism owing to the discrete nature in languages. Our approach is\ncombined with an auto-regressive prior to capture the sequential dependency\nfrom observations, which can enhance the latent space for language generation.\nMoreover, thanks to the property of discreteness, the training of our proposed\napproach does not suffer from posterior collapse. Furthermore, we carefully\nanalyze the superiority of discrete latent space over the continuous space with\nthe common Gaussian distribution. Extensive experiments on language generation\ndemonstrate superior advantages of our proposed approach in comparison with the\nstate-of-the-art counterparts.",
          "link": "http://arxiv.org/abs/2004.09764",
          "publishedOn": "2021-06-17T01:58:44.816Z",
          "wordCount": 665,
          "title": "Discrete Variational Attention Models for Language Generation. (arXiv:2004.09764v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08892",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kiyama_M/0/1/0/all/0/1\">Masato Kiyama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amagasaki_M/0/1/0/all/0/1\">Motoki Amagasaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iida_M/0/1/0/all/0/1\">Masahiro Iida</a>",
          "description": "Quantization is used to speed up execution time and save power when runnning\nDeep neural networks (DNNs) on edge devices like AI chips. To investigate the\neffect of quantization, we need performing inference after quantizing the\nweights of DNN with 32-bit floating-point precision by a some bit width, and\nthen quantizing them back to 32-bit floating-point precision. This is because\nthe DNN library can only handle floating-point numbers. However, the accuracy\nof the emulation does not provide accurate precision. We need accurate\nprecision to detect overflow in MAC operations or to verify the operation on\nedge de vices. We have developed PyParch, a DNN library that executes quantized\nDNNs (QNNs) with exactly the same be havior as hardware. In this paper, we\ndescribe a new proposal and implementation of PyParch. As a result of the\nevaluation, the accuracy of QNNs with arbitrary bit widths can be estimated for\nla rge and complex DNNs such as YOLOv5, and the overflow can be detected. We\nevaluated the overhead of the emulation time and found that it was 5.6 times\nslower for QNN and 42\n\ntimes slower for QNN with overflow detection compared to the normal DNN\nexecution time.",
          "link": "http://arxiv.org/abs/2106.08892",
          "publishedOn": "2021-06-17T01:58:44.802Z",
          "wordCount": 625,
          "title": "Development of Quantized DNN Library for Exact Hardware Emulation. (arXiv:2106.08892v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2012.03548",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_K/0/1/0/all/0/1\">Kevin Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grover_A/0/1/0/all/0/1\">Aditya Grover</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1\">Pieter Abbeel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mordatch_I/0/1/0/all/0/1\">Igor Mordatch</a>",
          "description": "The objective of lifelong reinforcement learning (RL) is to optimize agents\nwhich can continuously adapt and interact in changing environments. However,\ncurrent RL approaches fail drastically when environments are non-stationary and\ninteractions are non-episodic. We propose Lifelong Skill Planning (LiSP), an\nalgorithmic framework for non-episodic lifelong RL based on planning in an\nabstract space of higher-order skills. We learn the skills in an unsupervised\nmanner using intrinsic rewards and plan over the learned skills using a learned\ndynamics model. Moreover, our framework permits skill discovery even from\noffline data, thereby reducing the need for excessive real-world interactions.\nWe demonstrate empirically that LiSP successfully enables long-horizon planning\nand learns agents that can avoid catastrophic failures even in challenging\nnon-stationary and non-episodic environments derived from gridworld and MuJoCo\nbenchmarks.",
          "link": "http://arxiv.org/abs/2012.03548",
          "publishedOn": "2021-06-17T01:58:44.778Z",
          "wordCount": 606,
          "title": "Reset-Free Lifelong Learning with Skill-Space Planning. (arXiv:2012.03548v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08903",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Klicpera_J/0/1/0/all/0/1\">Johannes Klicpera</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Becker_F/0/1/0/all/0/1\">Florian Becker</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Gunnemann_S/0/1/0/all/0/1\">Stephan G&#xfc;nnemann</a>",
          "description": "Effectively predicting molecular interactions has the potential to accelerate\nmolecular dynamics by multiple orders of magnitude and thus revolutionize\nchemical simulations. Graph neural networks (GNNs) have recently shown great\nsuccesses for this task, overtaking classical methods based on fixed molecular\nkernels. However, they still appear very limited from a theoretical\nperspective, since regular GNNs cannot distinguish certain types of graphs. In\nthis work we close this gap between theory and practice. We show that GNNs with\ndirected edge embeddings and two-hop message passing are indeed universal\napproximators for predictions that are invariant to global rotation and\ntranslation, and equivariant to permutation. We then leverage these insights\nand multiple structural improvements to propose the geometric message passing\nneural network (GemNet). We demonstrate the benefits of the proposed changes in\nmultiple ablation studies. GemNet outperforms previous models on the COLL and\nMD17 molecular dynamics datasets by 36%, performing especially well on the most\nchallenging molecules.",
          "link": "http://arxiv.org/abs/2106.08903",
          "publishedOn": "2021-06-17T01:58:44.766Z",
          "wordCount": 587,
          "title": "GemNet: Universal Directional Graph Neural Networks for Molecules. (arXiv:2106.08903v1 [physics.comp-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2103.00430",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1\">Chengchao Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1\">Youtan Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinchao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xubin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1\">Jie Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_M/0/1/0/all/0/1\">Mingli Song</a>",
          "description": "Generative Adversarial Networks (GANs) have demonstrated unprecedented\nsuccess in various image generation tasks. The encouraging results, however,\ncome at the price of a cumbersome training process, during which the generator\nand discriminator are alternately updated in two stages. In this paper, we\ninvestigate a general training scheme that enables training GANs efficiently in\nonly one stage. Based on the adversarial losses of the generator and\ndiscriminator, we categorize GANs into two classes, Symmetric GANs and\nAsymmetric GANs, and introduce a novel gradient decomposition method to unify\nthe two, allowing us to train both classes in one stage and hence alleviate the\ntraining effort. We also computationally analyze the efficiency of the proposed\nmethod, and empirically demonstrate that, the proposed method yields a solid\n$1.5\\times$ acceleration across various datasets and network architectures.\nFurthermore, we show that the proposed method is readily applicable to other\nadversarial-training scenarios, such as data-free knowledge distillation. The\ncode is available at https://github.com/zju-vipa/OSGAN.",
          "link": "http://arxiv.org/abs/2103.00430",
          "publishedOn": "2021-06-17T01:58:44.759Z",
          "wordCount": 645,
          "title": "Training Generative Adversarial Networks in One Stage. (arXiv:2103.00430v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1806.04823",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Nekipelov_D/0/1/0/all/0/1\">Denis Nekipelov</a>, <a href=\"http://arxiv.org/find/math/1/au:+Semenova_V/0/1/0/all/0/1\">Vira Semenova</a>, <a href=\"http://arxiv.org/find/math/1/au:+Syrgkanis_V/0/1/0/all/0/1\">Vasilis Syrgkanis</a>",
          "description": "This paper proposes a Lasso-type estimator for a high-dimensional sparse\nparameter identified by a single index conditional moment restriction (CMR). In\naddition to this parameter, the moment function can also depend on a nuisance\nfunction, such as the propensity score or the conditional choice probability,\nwhich we estimate by modern machine learning tools. We first adjust the moment\nfunction so that the gradient of the future loss function is insensitive\n(formally, Neyman-orthogonal) with respect to the first-stage regularization\nbias, preserving the single index property. We then take the loss function to\nbe an indefinite integral of the adjusted moment function with respect to the\nsingle index. The proposed Lasso estimator converges at the oracle rate, where\nthe oracle knows the nuisance function and solves only the parametric problem.\nWe demonstrate our method by estimating the short-term heterogeneous impact of\nConnecticut's Jobs First welfare reform experiment on women's welfare\nparticipation decision.",
          "link": "http://arxiv.org/abs/1806.04823",
          "publishedOn": "2021-06-17T01:58:44.719Z",
          "wordCount": 649,
          "title": "Regularized Orthogonal Machine Learning for Nonlinear Semiparametric Models. (arXiv:1806.04823v7 [math.ST] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05012",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fellows_M/0/1/0/all/0/1\">Matthew Fellows</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hartikainen_K/0/1/0/all/0/1\">Kristian Hartikainen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Whiteson_S/0/1/0/all/0/1\">Shimon Whiteson</a>",
          "description": "We introduce a novel perspective on Bayesian reinforcement learning (RL);\nwhereas existing approaches infer a posterior over the transition distribution\nor Q-function, we characterise the uncertainty in the Bellman operator. Our\nBayesian Bellman operator (BBO) framework is motivated by the insight that when\nbootstrapping is introduced, model-free approaches actually infer a posterior\nover Bellman operators, not value functions. In this paper, we use BBO to\nprovide a rigorous theoretical analysis of model-free Bayesian RL to better\nunderstand its relationshipto established frequentist RL methodologies. We\nprove that Bayesian solutions are consistent with frequentist RL solutions,\neven when approximate inference isused, and derive conditions for which\nconvergence properties hold. Empirically, we demonstrate that algorithms\nderived from the BBO framework have sophisticated deep exploration properties\nthat enable them to solve continuous control tasks at which state-of-the-art\nregularised actor-critic algorithms fail catastrophically",
          "link": "http://arxiv.org/abs/2106.05012",
          "publishedOn": "2021-06-17T01:58:44.690Z",
          "wordCount": 576,
          "title": "Bayesian Bellman Operators. (arXiv:2106.05012v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1909.05350",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Stich_S/0/1/0/all/0/1\">Sebastian U. Stich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karimireddy_S/0/1/0/all/0/1\">Sai Praneeth Karimireddy</a>",
          "description": "We analyze (stochastic) gradient descent (SGD) with delayed updates on smooth\nquasi-convex and non-convex functions and derive concise, non-asymptotic,\nconvergence rates. We show that the rate of convergence in all cases consists\nof two terms: (i) a stochastic term which is not affected by the delay, and\n(ii) a higher order deterministic term which is only linearly slowed down by\nthe delay. Thus, in the presence of noise, the effects of the delay become\nnegligible after a few iterations and the algorithm converges at the same\noptimal rate as standard SGD. This result extends a line of research that\nshowed similar results in the asymptotic regime or for strongly-convex\nquadratic functions only. We further show similar results for SGD with more\nintricate form of delayed gradients---compressed gradients under error\ncompensation and for local~SGD where multiple workers perform local steps\nbefore communicating with each other. In all of these settings, we improve upon\nthe best known rates. These results show that SGD is robust to compressed\nand/or delayed stochastic gradient updates. This is in particular important for\ndistributed parallel implementations, where asynchronous and communication\nefficient methods are the key to achieve linear speedups for optimization with\nmultiple devices.",
          "link": "http://arxiv.org/abs/1909.05350",
          "publishedOn": "2021-06-17T01:58:44.681Z",
          "wordCount": 704,
          "title": "The Error-Feedback Framework: Better Rates for SGD with Delayed Gradients and Compressed Communication. (arXiv:1909.05350v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08962",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Menghani_G/0/1/0/all/0/1\">Gaurav Menghani</a>",
          "description": "Deep Learning has revolutionized the fields of computer vision, natural\nlanguage understanding, speech recognition, information retrieval and more.\nHowever, with the progressive improvements in deep learning models, their\nnumber of parameters, latency, resources required to train, etc. have all have\nincreased significantly. Consequently, it has become important to pay attention\nto these footprint metrics of a model as well, not just its quality. We present\nand motivate the problem of efficiency in deep learning, followed by a thorough\nsurvey of the five core areas of model efficiency (spanning modeling\ntechniques, infrastructure, and hardware) and the seminal work there. We also\npresent an experiment-based guide along with code, for practitioners to\noptimize their model training and deployment. We believe this is the first\ncomprehensive survey in the efficient deep learning space that covers the\nlandscape of model efficiency from modeling techniques to hardware support. Our\nhope is that this survey would provide the reader with the mental model and the\nnecessary understanding of the field to apply generic efficiency techniques to\nimmediately get significant improvements, and also equip them with ideas for\nfurther research and experimentation to achieve additional gains.",
          "link": "http://arxiv.org/abs/2106.08962",
          "publishedOn": "2021-06-17T01:58:44.674Z",
          "wordCount": 619,
          "title": "Efficient Deep Learning: A Survey on Making Deep Learning Models Smaller, Faster, and Better. (arXiv:2106.08962v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.04057",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Modas_A/0/1/0/all/0/1\">Apostolos Modas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xompero_A/0/1/0/all/0/1\">Alessio Xompero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanchez_Matilla_R/0/1/0/all/0/1\">Ricardo Sanchez-Matilla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frossard_P/0/1/0/all/0/1\">Pascal Frossard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cavallaro_A/0/1/0/all/0/1\">Andrea Cavallaro</a>",
          "description": "We investigate the problem of classifying - from a single image - the level\nof content in a cup or a drinking glass. This problem is made challenging by\nseveral ambiguities caused by transparencies, shape variations and partial\nocclusions, and by the availability of only small training datasets. In this\npaper, we tackle this problem with an appropriate strategy for transfer\nlearning. Specifically, we use adversarial training in a generic source dataset\nand then refine the training with a task-specific dataset. We also discuss and\nexperimentally evaluate several training strategies and their combination on a\nrange of container types of the CORSMAL Containers Manipulation dataset. We\nshow that transfer learning with adversarial training in the source domain\nconsistently improves the classification accuracy on the test set and limits\nthe overfitting of the classifier to specific features of the training data.",
          "link": "http://arxiv.org/abs/2102.04057",
          "publishedOn": "2021-06-17T01:58:44.599Z",
          "wordCount": 616,
          "title": "Improving filling level classification with adversarial training. (arXiv:2102.04057v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1910.04284",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1\">Colin Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1\">Tengyu Ma</a>",
          "description": "For linear classifiers, the relationship between (normalized) output margin\nand generalization is captured in a clear and simple bound -- a large output\nmargin implies good generalization. Unfortunately, for deep models, this\nrelationship is less clear: existing analyses of the output margin give\ncomplicated bounds which sometimes depend exponentially on depth. In this work,\nwe propose to instead analyze a new notion of margin, which we call the\n\"all-layer margin.\" Our analysis reveals that the all-layer margin has a clear\nand direct relationship with generalization for deep models. This enables the\nfollowing concrete applications of the all-layer margin: 1) by analyzing the\nall-layer margin, we obtain tighter generalization bounds for neural nets which\ndepend on Jacobian and hidden layer norms and remove the exponential dependency\non depth 2) our neural net results easily translate to the adversarially robust\nsetting, giving the first direct analysis of robust test error for deep\nnetworks, and 3) we present a theoretically inspired training algorithm for\nincreasing the all-layer margin. Our algorithm improves both clean and\nadversarially robust test performance over strong baselines in practice.",
          "link": "http://arxiv.org/abs/1910.04284",
          "publishedOn": "2021-06-17T01:58:44.517Z",
          "wordCount": 692,
          "title": "Improved Sample Complexities for Deep Networks and Robust Classification via an All-Layer Margin. (arXiv:1910.04284v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.04709",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lanfredi_R/0/1/0/all/0/1\">Ricardo Bigolin Lanfredi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Schroeder_J/0/1/0/all/0/1\">Joyce D. Schroeder</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tasdizen_T/0/1/0/all/0/1\">Tolga Tasdizen</a>",
          "description": "Adversarial training, especially projected gradient descent (PGD), has been a\nsuccessful approach for improving robustness against adversarial attacks. After\nadversarial training, gradients of models with respect to their inputs have a\npreferential direction. However, the direction of alignment is not\nmathematically well established, making it difficult to evaluate\nquantitatively. We propose a novel definition of this direction as the\ndirection of the vector pointing toward the closest point of the support of the\nclosest inaccurate class in decision space. To evaluate the alignment with this\ndirection after adversarial training, we apply a metric that uses generative\nadversarial networks to produce the smallest residual needed to change the\nclass present in the image. We show that PGD-trained models have a higher\nalignment than the baseline according to our definition, that our metric\npresents higher alignment values than a competing metric formulation, and that\nenforcing this alignment increases the robustness of models.",
          "link": "http://arxiv.org/abs/2009.04709",
          "publishedOn": "2021-06-17T01:58:44.507Z",
          "wordCount": 693,
          "title": "Quantifying the Preferential Direction of the Model Gradient in Adversarial Training With Projected Gradient Descent. (arXiv:2009.04709v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.06808",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moraitis_T/0/1/0/all/0/1\">Timoleon Moraitis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sebastian_A/0/1/0/all/0/1\">Abu Sebastian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eleftheriou_E/0/1/0/all/0/1\">Evangelos Eleftheriou</a> (IBM Research - Zurich)",
          "description": "Biological neurons and their in-silico emulations for neuromorphic artificial\nintelligence (AI) use extraordinarily energy-efficient mechanisms, such as\nspike-based communication and local synaptic plasticity. It remains unclear\nwhether these neuronal mechanisms only offer efficiency or also underlie the\nsuperiority of biological intelligence. Here, we prove rigorously that, indeed,\nthe Bayes-optimal prediction and inference of randomly but continuously\ntransforming environments, a common natural setting, relies on short-term\nspike-timing-dependent plasticity, a hallmark of biological synapses. Further,\nthis dynamic Bayesian inference through plasticity enables circuits of the\ncerebral cortex in simulations to recognize previously unseen, highly distorted\ndynamic stimuli. Strikingly, this also introduces a biologically-modelled AI,\nthe first to overcome multiple limitations of deep learning and outperform\nartificial neural networks in a visual task. The cortical-like network is\nspiking and event-based, trained only with unsupervised and local plasticity,\non a small, narrow, and static training dataset, but achieves recognition of\nunseen, transformed, and dynamic data better than deep neural networks with\ncontinuous activations, trained with supervised backpropagation on the\ntransforming data. These results link short-term plasticity to high-level\ncortical function, suggest optimality of natural intelligence for natural\nenvironments, and repurpose neuromorphic AI from mere efficiency to\ncomputational supremacy altogether.",
          "link": "http://arxiv.org/abs/2009.06808",
          "publishedOn": "2021-06-17T01:58:44.499Z",
          "wordCount": 687,
          "title": "Optimality of short-term synaptic plasticity in modelling certain dynamic environments. (arXiv:2009.06808v2 [cs.NE] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.04221",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1\">Shengyuan Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beirami_A/0/1/0/all/0/1\">Ahmad Beirami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_V/0/1/0/all/0/1\">Virginia Smith</a>",
          "description": "Fairness and robustness are two important concerns for federated learning\nsystems. In this work, we identify that robustness to data and model poisoning\nattacks and fairness, measured as the uniformity of performance across devices,\nare competing constraints in statistically heterogeneous networks. To address\nthese constraints, we propose employing a simple, general framework for\npersonalized federated learning, Ditto, that can inherently provide fairness\nand robustness benefits, and develop a scalable solver for it. Theoretically,\nwe analyze the ability of Ditto to achieve fairness and robustness\nsimultaneously on a class of linear problems. Empirically, across a suite of\nfederated datasets, we show that Ditto not only achieves competitive\nperformance relative to recent personalization methods, but also enables more\naccurate, robust, and fair models relative to state-of-the-art fair or robust\nbaselines.",
          "link": "http://arxiv.org/abs/2012.04221",
          "publishedOn": "2021-06-17T01:58:44.492Z",
          "wordCount": 598,
          "title": "Ditto: Fair and Robust Federated Learning Through Personalization. (arXiv:2012.04221v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.09016",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yahui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sangineto_E/0/1/0/all/0/1\">Enver Sangineto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yajing Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bao_L/0/1/0/all/0/1\">Linchao Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Haoxian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sebe_N/0/1/0/all/0/1\">Nicu Sebe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lepri_B/0/1/0/all/0/1\">Bruno Lepri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nadai_M/0/1/0/all/0/1\">Marco De Nadai</a>",
          "description": "Image-to-Image (I2I) multi-domain translation models are usually evaluated\nalso using the quality of their semantic interpolation results. However,\nstate-of-the-art models frequently show abrupt changes in the image appearance\nduring interpolation, and usually perform poorly in interpolations across\ndomains. In this paper, we propose a new training protocol based on three\nspecific losses which help a translation network to learn a smooth and\ndisentangled latent style space in which: 1) Both intra- and inter-domain\ninterpolations correspond to gradual changes in the generated images and 2) The\ncontent of the source image is better preserved during the translation.\nMoreover, we propose a novel evaluation metric to properly measure the\nsmoothness of latent style space of I2I translation models. The proposed method\ncan be plugged into existing translation approaches, and our extensive\nexperiments on different datasets show that it can significantly boost the\nquality of the generated images and the graduality of the interpolations.",
          "link": "http://arxiv.org/abs/2106.09016",
          "publishedOn": "2021-06-17T01:58:44.486Z",
          "wordCount": 606,
          "title": "Smoothing the Disentangled Latent Style Space for Unsupervised Image-to-Image Translation. (arXiv:2106.09016v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08929",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Glaser_P/0/1/0/all/0/1\">Pierre Glaser</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Arbel_M/0/1/0/all/0/1\">Michael Arbel</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gretton_A/0/1/0/all/0/1\">Arthur Gretton</a>",
          "description": "We study the gradient flow for a relaxed approximation to the\nKullback-Leibler (KL) divergence between a moving source and a fixed target\ndistribution. This approximation, termed the KALE (KL approximate lower-bound\nestimator), solves a regularized version of the Fenchel dual problem defining\nthe KL over a restricted class of functions. When using a Reproducing Kernel\nHilbert Space (RKHS) to define the function class, we show that the KALE\ncontinuously interpolates between the KL and the Maximum Mean Discrepancy\n(MMD). Like the MMD and other Integral Probability Metrics, the KALE remains\nwell defined for mutually singular distributions. Nonetheless, the KALE\ninherits from the limiting KL a greater sensitivity to mismatch in the support\nof the distributions, compared with the MMD. These two properties make the KALE\ngradient flow particularly well suited when the target distribution is\nsupported on a low-dimensional manifold. Under an assumption of sufficient\nsmoothness of the trajectories, we show the global convergence of the KALE\nflow. We propose a particle implementation of the flow given initial samples\nfrom the source and the target distribution, which we use to empirically\nconfirm the KALE's properties.",
          "link": "http://arxiv.org/abs/2106.08929",
          "publishedOn": "2021-06-17T01:58:44.471Z",
          "wordCount": 618,
          "title": "KALE Flow: A Relaxed KL Gradient Flow for Probabilities with Disjoint Support. (arXiv:2106.08929v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2004.07119",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Guo_X/0/1/0/all/0/1\">Xiaojie Guo</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Du_Y/0/1/0/all/0/1\">Yuanqi Du</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Tadepalli_S/0/1/0/all/0/1\">Sivani Tadepalli</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhao_L/0/1/0/all/0/1\">Liang Zhao</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Shehu_A/0/1/0/all/0/1\">Amarda Shehu</a>",
          "description": "Much scientific enquiry across disciplines is founded upon a mechanistic\ntreatment of dynamic systems that ties form to function. A highly visible\ninstance of this is in molecular biology, where an important goal is to\ndetermine functionally-relevant forms/structures that a protein molecule\nemploys to interact with molecular partners in the living cell. This goal is\ntypically pursued under the umbrella of stochastic optimization with algorithms\nthat optimize a scoring function. Research repeatedly shows that current\nscoring function, though steadily improving, correlate weakly with molecular\nactivity. Inspired by recent momentum in generative deep learning, this paper\nproposes and evaluates an alternative approach to generating\nfunctionally-relevant three-dimensional structures of a protein. Though\ntypically deep generative models struggle with highly-structured data, the work\npresented here circumvents this challenge via graph-generative models. A\ncomprehensive evaluation of several deep architectures shows the promise of\ngenerative models in directly revealing the latent space for sampling novel\ntertiary structures, as well as in highlighting axes/factors that carry\nstructural meaning and open the black box often associated with deep models.\nThe work presented here is a first step towards interpretative, deep generative\nmodels becoming viable and informative complementary approaches to protein\nstructure prediction.",
          "link": "http://arxiv.org/abs/2004.07119",
          "publishedOn": "2021-06-17T01:58:44.465Z",
          "wordCount": 648,
          "title": "Generating Tertiary Protein Structures via an Interpretative Variational Autoencoder. (arXiv:2004.07119v2 [q-bio.BM] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08956",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rappeport_H/0/1/0/all/0/1\">Hagai Rappeport</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reisman_I/0/1/0/all/0/1\">Irit Levin Reisman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tishby_N/0/1/0/all/0/1\">Naftali Tishby</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balaban_N/0/1/0/all/0/1\">Nathalie Q. Balaban</a>",
          "description": "Many complex phenomena, from weather systems to heartbeat rhythm patterns,\nare effectively modeled as low-dimensional dynamical systems. Such systems may\nbehave chaotically under certain conditions, and so the ability to detect chaos\nbased on empirical measurement is an important step in characterizing and\npredicting these processes. Classifying a system as chaotic usually requires\nestimating its largest Lyapunov exponent, which quantifies the average rate of\nconvergence or divergence of initially close trajectories in state space, and\nfor which a positive value is generally accepted as an operational definition\nof chaos. Estimating the largest Lyapunov exponent from observations of a\nprocess is especially challenging in systems affected by dynamical noise, which\nis the case for many models of real-world processes, in particular models of\nbiological systems. We describe a novel method for estimating the largest\nLyapunov exponent from data, based on training Deep Learning models on\nsynthetically generated trajectories, and demonstrate that this method yields\naccurate and noise-robust predictions given relatively short inputs and across\na range of different dynamical systems. Our method is unique in that it can\nanalyze tree-shaped data, a ubiquitous topology in biological settings, and\nspecifically in dynamics over lineages of cells or organisms. We also\ncharacterize the types of input information extracted by our models for their\npredictions, allowing for a deeper understanding into the different ways by\nwhich chaos can be analyzed in different topologies.",
          "link": "http://arxiv.org/abs/2106.08956",
          "publishedOn": "2021-06-17T01:58:44.458Z",
          "wordCount": 660,
          "title": "Detecting chaos in lineage-trees: A deep learning approach. (arXiv:2106.08956v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.01670",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tessera_K/0/1/0/all/0/1\">Kale-ab Tessera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hooker_S/0/1/0/all/0/1\">Sara Hooker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosman_B/0/1/0/all/0/1\">Benjamin Rosman</a>",
          "description": "Training sparse networks to converge to the same performance as dense neural\narchitectures has proven to be elusive. Recent work suggests that\ninitialization is the key. However, while this direction of research has had\nsome success, focusing on initialization alone appears to be inadequate. In\nthis paper, we take a broader view of training sparse networks and consider the\nrole of regularization, optimization, and architecture choices on sparse\nmodels. We propose a simple experimental framework, Same Capacity Sparse vs\nDense Comparison (SC-SDC), that allows for a fair comparison of sparse and\ndense networks. Furthermore, we propose a new measure of gradient flow,\nEffective Gradient Flow (EGF), that better correlates to performance in sparse\nnetworks. Using top-line metrics, SC-SDC and EGF, we show that default choices\nof optimizers, activation functions and regularizers used for dense networks\ncan disadvantage sparse networks. Based upon these findings, we show that\ngradient flow in sparse networks can be improved by reconsidering aspects of\nthe architecture design and the training regime. Our work suggests that\ninitialization is only one piece of the puzzle and taking a wider view of\ntailoring optimization to sparse networks yields promising results.",
          "link": "http://arxiv.org/abs/2102.01670",
          "publishedOn": "2021-06-17T01:58:44.439Z",
          "wordCount": 655,
          "title": "Keep the Gradients Flowing: Using Gradient Flow to Study Sparse Network Optimization. (arXiv:2102.01670v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.10885",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hutchinson_M/0/1/0/all/0/1\">Michael Hutchinson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_C/0/1/0/all/0/1\">Charline Le Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaidi_S/0/1/0/all/0/1\">Sheheryar Zaidi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dupont_E/0/1/0/all/0/1\">Emilien Dupont</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teh_Y/0/1/0/all/0/1\">Yee Whye Teh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyunjik Kim</a>",
          "description": "Group equivariant neural networks are used as building blocks of group\ninvariant neural networks, which have been shown to improve generalisation\nperformance and data efficiency through principled parameter sharing. Such\nworks have mostly focused on group equivariant convolutions, building on the\nresult that group equivariant linear maps are necessarily convolutions. In this\nwork, we extend the scope of the literature to self-attention, that is emerging\nas a prominent building block of deep learning models. We propose the\nLieTransformer, an architecture composed of LieSelfAttention layers that are\nequivariant to arbitrary Lie groups and their discrete subgroups. We\ndemonstrate the generality of our approach by showing experimental results that\nare competitive to baseline methods on a wide range of tasks: shape counting on\npoint clouds, molecular property regression and modelling particle trajectories\nunder Hamiltonian dynamics.",
          "link": "http://arxiv.org/abs/2012.10885",
          "publishedOn": "2021-06-17T01:58:44.433Z",
          "wordCount": 613,
          "title": "LieTransformer: Equivariant self-attention for Lie Groups. (arXiv:2012.10885v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08750",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wang_Z/0/1/0/all/0/1\">Ziyu Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhou_Y/0/1/0/all/0/1\">Yuhao Zhou</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ren_T/0/1/0/all/0/1\">Tongzheng Ren</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhu_J/0/1/0/all/0/1\">Jun Zhu</a>",
          "description": "Recent years have witnessed an upsurge of interest in employing flexible\nmachine learning models for instrumental variable (IV) regression, but the\ndevelopment of uncertainty quantification methodology is still lacking. In this\nwork we present a scalable quasi-Bayesian procedure for IV regression, building\nupon the recently developed kernelized IV models. Contrary to Bayesian modeling\nfor IV, our approach does not require additional assumptions on the data\ngenerating process, and leads to a scalable approximate inference algorithm\nwith time cost comparable to the corresponding point estimation methods. Our\nalgorithm can be further extended to work with neural network models. We\nanalyze the theoretical properties of the proposed quasi-posterior, and\ndemonstrate through empirical evaluation the competitive performance of our\nmethod.",
          "link": "http://arxiv.org/abs/2106.08750",
          "publishedOn": "2021-06-17T01:58:44.353Z",
          "wordCount": 548,
          "title": "Scalable Quasi-Bayesian Inference for Instrumental Variable Regression. (arXiv:2106.08750v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08943",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jiatai Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1\">Longbo Huang</a>",
          "description": "We propose Banker-OMD, a novel framework generalizing the classical Online\nMirror Descent (OMD) technique in online learning algorithm design. Banker-OMD\nallows algorithms to robustly handle delayed feedback, and offers a general\nmethodology for achieving $\\tilde{O}(\\sqrt{T} + \\sqrt{D})$-style regret bounds\nin various delayed-feedback online learning tasks, where $T$ is the time\nhorizon length and $D$ is the total feedback delay. We demonstrate the power of\nBanker-OMD with applications to three important bandit scenarios with delayed\nfeedback, including delayed adversarial Multi-armed bandits (MAB), delayed\nadversarial linear bandits, and a novel delayed best-of-both-worlds MAB\nsetting. Banker-OMD achieves nearly-optimal performance in all the three\nsettings. In particular, it leads to the first delayed adversarial linear\nbandit algorithm achieving $\\tilde{O}(\\text{poly}(n)(\\sqrt{T} + \\sqrt{D}))$\nregret.",
          "link": "http://arxiv.org/abs/2106.08943",
          "publishedOn": "2021-06-17T01:58:44.340Z",
          "wordCount": 530,
          "title": "Banker Online Mirror Descent. (arXiv:2106.08943v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2006.09858",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tabaghi_P/0/1/0/all/0/1\">Puoya Tabaghi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_J/0/1/0/all/0/1\">Jianhao Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Milenkovic_O/0/1/0/all/0/1\">Olgica Milenkovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dokmanic_I/0/1/0/all/0/1\">Ivan Dokmani&#x107;</a>",
          "description": "Many data analysis problems can be cast as distance geometry problems in\n\\emph{space forms} -- Euclidean, spherical, or hyperbolic spaces. Often,\nabsolute distance measurements are often unreliable or simply unavailable and\nonly proxies to absolute distances in the form of similarities are available.\nHence we ask the following: Given only \\emph{comparisons} of similarities\namongst a set of entities, what can be said about the geometry of the\nunderlying space form? To study this question, we introduce the notions of the\n\\textit{ordinal capacity} of a target space form and \\emph{ordinal spread} of\nthe similarity measurements. The latter is an indicator of complex patterns in\nthe measurements, while the former quantifies the capacity of a space form to\naccommodate a set of measurements with a specific ordinal spread profile. We\nprove that the ordinal capacity of a space form is related to its dimension and\nthe sign of its curvature. This leads to a lower bound on the Euclidean and\nspherical embedding dimension of what we term similarity graphs. More\nimportantly, we show that the statistical behavior of the ordinal spread random\nvariables defined on a similarity graph can be used to identify its underlying\nspace form. We support our theoretical claims with experiments on weighted\ntrees, single-cell RNA expression data and spherical cartographic measurements.",
          "link": "http://arxiv.org/abs/2006.09858",
          "publishedOn": "2021-06-17T01:58:44.335Z",
          "wordCount": 675,
          "title": "Geometry of Similarity Comparisons. (arXiv:2006.09858v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08977",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Haoming Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Danqing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_T/0/1/0/all/0/1\">Tianyu Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_B/0/1/0/all/0/1\">Bing Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tuo Zhao</a>",
          "description": "Weak supervision has shown promising results in many natural language\nprocessing tasks, such as Named Entity Recognition (NER). Existing work mainly\nfocuses on learning deep NER models only with weak supervision, i.e., without\nany human annotation, and shows that by merely using weakly labeled data, one\ncan achieve good performance, though still underperforms fully supervised NER\nwith manually/strongly labeled data. In this paper, we consider a more\npractical scenario, where we have both a small amount of strongly labeled data\nand a large amount of weakly labeled data. Unfortunately, we observe that\nweakly labeled data does not necessarily improve, or even deteriorate the model\nperformance (due to the extensive noise in the weak labels) when we train deep\nNER models over a simple or weighted combination of the strongly labeled and\nweakly labeled data. To address this issue, we propose a new multi-stage\ncomputational framework -- NEEDLE with three essential ingredients: (1) weak\nlabel completion, (2) noise-aware loss function, and (3) final fine-tuning over\nthe strongly labeled data. Through experiments on E-commerce query NER and\nBiomedical NER, we demonstrate that NEEDLE can effectively suppress the noise\nof the weak labels and outperforms existing methods. In particular, we achieve\nnew SOTA F1-scores on 3 Biomedical NER datasets: BC5CDR-chem 93.74,\nBC5CDR-disease 90.69, NCBI-disease 92.28.",
          "link": "http://arxiv.org/abs/2106.08977",
          "publishedOn": "2021-06-17T01:58:44.321Z",
          "wordCount": 669,
          "title": "Named Entity Recognition with Small Strongly Labeled and Large Weakly Labeled Data. (arXiv:2106.08977v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08812",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Han Zhao</a>",
          "description": "Real-world applications of machine learning tools in high-stakes domains are\noften regulated to be fair, in the sense that the predicted target should\nsatisfy some quantitative notion of parity with respect to a protected\nattribute. However, the exact tradeoff between fairness and accuracy with a\nreal-valued target is not clear. In this paper, we characterize the inherent\ntradeoff between statistical parity and accuracy in the regression setting by\nproviding a lower bound on the error of any fair regressor. Our lower bound is\nsharp, algorithm-independent, and admits a simple interpretation: when the\nmoments of the target differ between groups, any fair algorithm has to make a\nlarge error on at least one of the groups. We further extend this result to\ngive a lower bound on the joint error of any (approximately) fair algorithm,\nusing the Wasserstein distance to measure the quality of the approximation. On\nthe upside, we establish the first connection between individual fairness,\naccuracy parity, and the Wasserstein distance by showing that if a regressor is\nindividually fair, it also approximately verifies the accuracy parity, where\nthe gap is given by the Wasserstein distance between the two groups. Inspired\nby our theoretical results, we develop a practical algorithm for fair\nregression through the lens of representation learning, and conduct experiments\non a real-world dataset to corroborate our findings.",
          "link": "http://arxiv.org/abs/2106.08812",
          "publishedOn": "2021-06-17T01:58:44.313Z",
          "wordCount": 646,
          "title": "Costs and Benefits of Wasserstein Fair Regression. (arXiv:2106.08812v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08475",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghodsi_Z/0/1/0/all/0/1\">Zahra Ghodsi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jha_N/0/1/0/all/0/1\">Nandan Kumar Jha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reagen_B/0/1/0/all/0/1\">Brandon Reagen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garg_S/0/1/0/all/0/1\">Siddharth Garg</a>",
          "description": "The simultaneous rise of machine learning as a service and concerns over user\nprivacy have increasingly motivated the need for private inference (PI). While\nrecent work demonstrates PI is possible using cryptographic primitives, the\ncomputational overheads render it impractical. The community is largely\nunprepared to address these overheads, as the source of slowdown in PI stems\nfrom the ReLU operator whereas optimizations for plaintext inference focus on\noptimizing FLOPs. In this paper we re-think the ReLU computation and propose\noptimizations for PI tailored to properties of neural networks. Specifically,\nwe reformulate ReLU as an approximate sign test and introduce a novel\ntruncation method for the sign test that significantly reduces the cost per\nReLU. These optimizations result in a specific type of stochastic ReLU. The key\nobservation is that the stochastic fault behavior is well suited for the\nfault-tolerant properties of neural network inference. Thus, we provide\nsignificant savings without impacting accuracy. We collectively call the\noptimizations Circa and demonstrate improvements of up to 4.7x storage and 3x\nruntime over baseline implementations; we further show that Circa can be used\non top of recent PI optimizations to obtain 1.8x additional speedup.",
          "link": "http://arxiv.org/abs/2106.08475",
          "publishedOn": "2021-06-17T01:58:44.271Z",
          "wordCount": 619,
          "title": "Circa: Stochastic ReLUs for Private Deep Learning. (arXiv:2106.08475v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08756",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1\">Xiaomeng Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potter_M/0/1/0/all/0/1\">Michael Potter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_G/0/1/0/all/0/1\">Gaurav Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsai_Y/0/1/0/all/0/1\">Yun-Chan Tsai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saripalli_V/0/1/0/all/0/1\">V. Ratna Saripalli</a>",
          "description": "It is no secret amongst deep learning researchers that finding the right data\naugmentation strategy during training can mean the difference between a\nstate-of-the-art result and a run-of-the-mill ranking. To that end, the\ncommunity has seen many efforts to automate the process of finding the perfect\naugmentation procedure for any task at hand. Unfortunately, even recent\ncutting-edge methods bring massive computational overhead, requiring as many as\n100 full model trainings to settle on an ideal configuration. We show how to\nachieve even better performance in just 7: with Random Unidimensional\nAugmentation. Source code is available at https://github.com/fastestimator/RUA",
          "link": "http://arxiv.org/abs/2106.08756",
          "publishedOn": "2021-06-17T01:58:44.265Z",
          "wordCount": 521,
          "title": "Automating Augmentation Through Random Unidimensional Search. (arXiv:2106.08756v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08445",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dietrich_M/0/1/0/all/0/1\">Maximilian Dietrich</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Seidlitz_S/0/1/0/all/0/1\">Silvia Seidlitz</a> (2, 3), <a href=\"http://arxiv.org/find/cs/1/au:+Schreck_N/0/1/0/all/0/1\">Nicholas Schreck</a> (4), <a href=\"http://arxiv.org/find/cs/1/au:+Wiesenfarth_M/0/1/0/all/0/1\">Manuel Wiesenfarth</a> (4), <a href=\"http://arxiv.org/find/cs/1/au:+Godau_P/0/1/0/all/0/1\">Patrick Godau</a> (2, 3), <a href=\"http://arxiv.org/find/cs/1/au:+Tizabi_M/0/1/0/all/0/1\">Minu Tizabi</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Sellner_J/0/1/0/all/0/1\">Jan Sellner</a> (2, 3), <a href=\"http://arxiv.org/find/cs/1/au:+Marx_S/0/1/0/all/0/1\">Sebastian Marx</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Knodler_S/0/1/0/all/0/1\">Samuel Kn&#xf6;dler</a> (5), <a href=\"http://arxiv.org/find/cs/1/au:+Allers_M/0/1/0/all/0/1\">Michael M. Allers</a> (5), <a href=\"http://arxiv.org/find/cs/1/au:+Ayala_L/0/1/0/all/0/1\">Leonardo Ayala</a> (2, 7), <a href=\"http://arxiv.org/find/cs/1/au:+Schmidt_K/0/1/0/all/0/1\">Karsten Schmidt</a> (8), <a href=\"http://arxiv.org/find/cs/1/au:+Brenner_T/0/1/0/all/0/1\">Thorsten Brenner</a> (8), <a href=\"http://arxiv.org/find/cs/1/au:+Studier_Fischer_A/0/1/0/all/0/1\">Alexander Studier-Fischer</a> (5), <a href=\"http://arxiv.org/find/cs/1/au:+Nickel_F/0/1/0/all/0/1\">Felix Nickel</a> (5), <a href=\"http://arxiv.org/find/cs/1/au:+Muller_Stich_B/0/1/0/all/0/1\">Beat P. M&#xfc;ller-Stich</a> (5), <a href=\"http://arxiv.org/find/cs/1/au:+Kopp_Schneider_A/0/1/0/all/0/1\">Annette Kopp-Schneider</a> (4), <a href=\"http://arxiv.org/find/cs/1/au:+Weigand_M/0/1/0/all/0/1\">Markus A. Weigand</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Maier_Hein_L/0/1/0/all/0/1\">Lena Maier-Hein</a> (2, 6, 7) ((1) Department of Anesthesiology, Heidelberg University Hospital, Heidelberg, Germany, (2) Division of Computer Assisted Medical Interventions, German Cancer Research Center (DKFZ), Heidelberg, Germany, (3) HIDSS4Health - Helmholtz Information and Data Science School for Health, Karlsruhe/Heidelberg, Germany (4) Division of Biostatistics, German Cancer Research Center (DKFZ), Heidelberg, Germany, (5) Department of General, Visceral, and Transplantation Surgery, Heidelberg University Hospital, Heidelberg, Germany, (6) Faculty of Mathematics and Computer Science, Heidelberg University, Heidelberg, Germany, (7) Medical Faculty, Heidelberg University, Heidelberg, Germany, (8) Department of Anesthesiology and Intensive Care Medicine, University Hospital Essen, University Duisburg-Essen, Essen, Germany)",
          "description": "Sepsis is a leading cause of mortality and critical illness worldwide. While\nrobust biomarkers for early diagnosis are still missing, recent work indicates\nthat hyperspectral imaging (HSI) has the potential to overcome this bottleneck\nby monitoring microcirculatory alterations. Automated machine learning-based\ndiagnosis of sepsis based on HSI data, however, has not been explored to date.\nGiven this gap in the literature, we leveraged an existing data set to (1)\ninvestigate whether HSI-based automated diagnosis of sepsis is possible and (2)\nput forth a list of possible confounders relevant for HSI-based tissue\nclassification. While we were able to classify sepsis with an accuracy of over\n$98\\,\\%$ using the existing data, our research also revealed several subject-,\ntherapy- and imaging-related confounders that may lead to an overestimation of\nalgorithm performance when not balanced across the patient groups. We conclude\nthat further prospective studies, carefully designed with respect to these\nconfounders, are necessary to confirm the preliminary results obtained in this\nstudy.",
          "link": "http://arxiv.org/abs/2106.08445",
          "publishedOn": "2021-06-17T01:58:44.256Z",
          "wordCount": 770,
          "title": "Machine learning-based analysis of hyperspectral images for automated sepsis diagnosis. (arXiv:2106.08445v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08889",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Theerthagiri_P/0/1/0/all/0/1\">Prasannavenkatesan Theerthagiri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+J_V/0/1/0/all/0/1\">Vidya J</a>",
          "description": "Cardiovascular diseases (CVDs) are one of the most common chronic illnesses\nthat affect peoples health. Early detection of CVDs can reduce mortality rates\nby preventing or reducing the severity of the disease. Machine learning\nalgorithms are a promising method for identifying risk factors. This paper\nproposes a proposed recursive feature elimination-based gradient boosting\n(RFE-GB) algorithm in order to obtain accurate heart disease prediction. The\npatients health record with important CVD features has been analyzed for the\nevaluation of the results. Several other machine learning methods were also\nused to build the prediction model, and the results were compared with the\nproposed model. The results of this proposed model infer that the combined\nrecursive feature elimination and gradient boosting algorithm achieves the\nhighest accuracy (89.7 %). Further, with an area under the curve of 0.84, the\nproposed RFE-GB algorithm was found superior and had obtained a substantial\ngain over other techniques. Thus, the proposed RFE-GB algorithm will serve as a\nprominent model for CVD estimation and treatment.",
          "link": "http://arxiv.org/abs/2106.08889",
          "publishedOn": "2021-06-17T01:58:44.248Z",
          "wordCount": 597,
          "title": "Cardiovascular Disease Prediction using Recursive Feature Elimination and Gradient Boosting Classification Techniques. (arXiv:2106.08889v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08832",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kuznetsov_I/0/1/0/all/0/1\">Igor Kuznetsov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Filchenkov_A/0/1/0/all/0/1\">Andrey Filchenkov</a>",
          "description": "Episodic memory lets reinforcement learning algorithms remember and exploit\npromising experience from the past to improve agent performance. Previous works\non memory mechanisms show benefits of using episodic-based data structures for\ndiscrete action problems in terms of sample-efficiency. The application of\nepisodic memory for continuous control with a large action space is not\ntrivial. Our study aims to answer the question: can episodic memory be used to\nimprove agent's performance in continuous control? Our proposed algorithm\ncombines episodic memory with Actor-Critic architecture by modifying critic's\nobjective. We further improve performance by introducing episodic-based replay\nbuffer prioritization. We evaluate our algorithm on OpenAI gym domains and show\ngreater sample-efficiency compared with the state-of-the art model-free\noff-policy algorithms.",
          "link": "http://arxiv.org/abs/2106.08832",
          "publishedOn": "2021-06-17T01:58:44.243Z",
          "wordCount": 545,
          "title": "Solving Continuous Control with Episodic Memory. (arXiv:2106.08832v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08882",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Acharya_A/0/1/0/all/0/1\">Anish Acharya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hashemi_A/0/1/0/all/0/1\">Abolfazl Hashemi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_P/0/1/0/all/0/1\">Prateek Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanghavi_S/0/1/0/all/0/1\">Sujay Sanghavi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dhillon_I/0/1/0/all/0/1\">Inderjit S. Dhillon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Topcu_U/0/1/0/all/0/1\">Ufuk Topcu</a>",
          "description": "Geometric median (\\textsc{Gm}) is a classical method in statistics for\nachieving a robust estimation of the uncorrupted data; under gross corruption,\nit achieves the optimal breakdown point of 0.5. However, its computational\ncomplexity makes it infeasible for robustifying stochastic gradient descent\n(SGD) for high-dimensional optimization problems. In this paper, we show that\nby applying \\textsc{Gm} to only a judiciously chosen block of coordinates at a\ntime and using a memory mechanism, one can retain the breakdown point of 0.5\nfor smooth non-convex problems, with non-asymptotic convergence rates\ncomparable to the SGD with \\textsc{Gm}.",
          "link": "http://arxiv.org/abs/2106.08882",
          "publishedOn": "2021-06-17T01:58:44.227Z",
          "wordCount": 545,
          "title": "Robust Training in High Dimensions via Block Coordinate Geometric Median Descent. (arXiv:2106.08882v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08748",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sapkota_S/0/1/0/all/0/1\">Suman Sapkota</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhattarai_B/0/1/0/all/0/1\">Binod Bhattarai</a>",
          "description": "In this paper, we present a novel method to constrain invexity on Neural\nNetworks (NN). Invex functions ensure every stationary point is global minima.\nHence, gradient descent commenced from any point will lead to the global\nminima. Another advantage of invexity on NN is to divide data space locally\ninto two connected sets with a highly non-linear decision boundary by simply\nthresholding the output. To this end, we formulate a universal invex function\napproximator and employ it to enforce invexity in NN. We call it Input Invex\nNeural Networks (II-NN). We first fit data with a known invex function,\nfollowed by modification with a NN, compare the direction of the gradient and\npenalize the direction of gradient on NN if it contradicts with the direction\nof reference invex function. In order to penalize the direction of the gradient\nwe perform Gradient Clipped Gradient Penalty (GC-GP). We applied our method to\nthe existing NNs for both image classification and regression tasks. From the\nextensive empirical and qualitative experiments, we observe that our method\ngives the performance similar to ordinary NN yet having invexity. Our method\noutperforms linear NN and Input Convex Neural Network (ICNN) with a large\nmargin. We publish our code and implementation details at github.",
          "link": "http://arxiv.org/abs/2106.08748",
          "publishedOn": "2021-06-17T01:58:44.221Z",
          "wordCount": 621,
          "title": "Input Invex Neural Network. (arXiv:2106.08748v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08446",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Olin_Ammentorp_W/0/1/0/all/0/1\">Wilkie Olin-Ammentorp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bazhenov_M/0/1/0/all/0/1\">Maxim Bazhenov</a>",
          "description": "Despite rapid progress, current deep learning methods face a number of\ncritical challenges. These include high energy consumption, catastrophic\nforgetting, dependance on global losses, and an inability to reason\nsymbolically. By combining concepts from information bottleneck theory and\nvector-symbolic architectures, we propose and implement a novel information\nprocessing architecture, the 'Bridge network.' We show this architecture\nprovides unique advantages which can address the problem of global losses and\ncatastrophic forgetting. Furthermore, we argue that it provides a further basis\nfor increasing energy efficiency of execution and the ability to reason\nsymbolically.",
          "link": "http://arxiv.org/abs/2106.08446",
          "publishedOn": "2021-06-17T01:58:44.216Z",
          "wordCount": 503,
          "title": "Bridge Networks. (arXiv:2106.08446v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08863",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Blier_L/0/1/0/all/0/1\">L&#xe9;onard Blier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ollivier_Y/0/1/0/all/0/1\">Yann Ollivier</a>",
          "description": "In multi-goal reinforcement learning (RL) settings, the reward for each goal\nis sparse, and located in a small neighborhood of the goal. In large dimension,\nthe probability of reaching a reward vanishes and the agent receives little\nlearning signal. Methods such as Hindsight Experience Replay (HER) tackle this\nissue by also learning from realized but unplanned-for goals. But HER is known\nto introduce bias, and can converge to low-return policies by overestimating\nchancy outcomes. First, we vindicate HER by proving that it is actually\nunbiased in deterministic environments, such as many optimal control settings.\nNext, for stochastic environments in continuous spaces, we tackle sparse\nrewards by directly taking the infinitely sparse reward limit. We fully\nformalize the problem of multi-goal RL with infinitely sparse Dirac rewards at\neach goal. We introduce unbiased deep Q-learning and actor-critic algorithms\nthat can handle such infinitely sparse rewards, and test them in toy\nenvironments.",
          "link": "http://arxiv.org/abs/2106.08863",
          "publishedOn": "2021-06-17T01:58:44.210Z",
          "wordCount": 568,
          "title": "Unbiased Methods for Multi-Goal Reinforcement Learning. (arXiv:2106.08863v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08895",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mohtashami_A/0/1/0/all/0/1\">Amirkeivan Mohtashami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaggi_M/0/1/0/all/0/1\">Martin Jaggi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stich_S/0/1/0/all/0/1\">Sebastian U. Stich</a>",
          "description": "For deploying deep learning models to lower end devices, it is necessary to\ntrain less resource-demanding variants of state-of-the-art architectures. This\ndoes not eliminate the need for more expensive models as they have a higher\nperformance. In order to avoid training two separate models, we show that it is\npossible to train neural networks in such a way that a predefined 'core'\nsubnetwork can be split-off from the trained full network with remarkable good\nperformance. We extend on prior methods that focused only on core networks of\nsmaller width, while we focus on supporting arbitrary core network\narchitectures. Our proposed training scheme switches consecutively between\noptimizing only the core part of the network and the full one. The accuracy of\nthe full model remains comparable, while the core network achieves better\nperformance than when it is trained in isolation. In particular, we show that\ntraining a Transformer with a low-rank core gives a low-rank model with\nsuperior performance than when training the low-rank model alone. We analyze\nour training scheme theoretically, and show its convergence under assumptions\nthat are either standard or practically justified. Moreover, we show that the\ndeveloped theoretical framework allows analyzing many other partial training\nschemes for neural networks.",
          "link": "http://arxiv.org/abs/2106.08895",
          "publishedOn": "2021-06-17T01:58:44.205Z",
          "wordCount": 623,
          "title": "Simultaneous Training of Partially Masked Neural Networks. (arXiv:2106.08895v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08771",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gast_N/0/1/0/all/0/1\">Nicolas Gast</a> (POLARIS), <a href=\"http://arxiv.org/find/cs/1/au:+Gaujal_B/0/1/0/all/0/1\">Bruno Gaujal</a> (POLARIS), <a href=\"http://arxiv.org/find/cs/1/au:+Khun_K/0/1/0/all/0/1\">Kimang Khun</a> (POLARIS)",
          "description": "We study learning algorithms for the classical Markovian bandit problem with\ndiscount. We explain how to adapt PSRL [24] and UCRL2 [2] to exploit the\nproblem structure. These variants are called MB-PSRL and MB-UCRL2. While the\nregret bound and runtime of vanilla implementations of PSRL and UCRL2 are\nexponential in the number of bandits, we show that the episodic regret of\nMB-PSRL and MB-UCRL2 is�(S $\\sqrt$ nK) where K is the number of episodes, n is\nthe number of bandits and S is the number of states of each bandit (the exact\nbound in S, n and K is given in the paper). Up to a factor $\\sqrt$ S, this\nmatches the lower bound of $\\Omega$($\\sqrt$ SnK) that we also derive in the\npaper. MB-PSRL is also computationally efficient: its runtime is linear in the\nnumber of bandits. We further show that this linear runtime cannot be achieved\nby adapting classical non-Bayesian algorithms such as UCRL2 or UCBVI to\nMarkovian bandit problems. Finally, we perform numerical experiments that\nconfirm that MB-PSRL outperforms other existing algorithms in practice, both in\nterms of regret and of computation time.",
          "link": "http://arxiv.org/abs/2106.08771",
          "publishedOn": "2021-06-17T01:58:44.190Z",
          "wordCount": 626,
          "title": "Reinforcement Learning for Markovian Bandits: Is Posterior Sampling more Scalable than Optimism?. (arXiv:2106.08771v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08519",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Qian_K/0/1/0/all/0/1\">Kaizhi Qian</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_Y/0/1/0/all/0/1\">Yang Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chang_S/0/1/0/all/0/1\">Shiyu Chang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xiong_J/0/1/0/all/0/1\">Jinjun Xiong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gan_C/0/1/0/all/0/1\">Chuang Gan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cox_D/0/1/0/all/0/1\">David Cox</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hasegawa_Johnson_M/0/1/0/all/0/1\">Mark Hasegawa-Johnson</a>",
          "description": "Prosody plays an important role in characterizing the style of a speaker or\nan emotion, but most non-parallel voice or emotion style transfer algorithms do\nnot convert any prosody information. Two major components of prosody are pitch\nand rhythm. Disentangling the prosody information, particularly the rhythm\ncomponent, from the speech is challenging because it involves breaking the\nsynchrony between the input speech and the disentangled speech representation.\nAs a result, most existing prosody style transfer algorithms would need to rely\non some form of text transcriptions to identify the content information, which\nconfines their application to high-resource languages only. Recently,\nSpeechSplit has made sizeable progress towards unsupervised prosody style\ntransfer, but it is unable to extract high-level global prosody style in an\nunsupervised manner. In this paper, we propose AutoPST, which can disentangle\nglobal prosody style from speech without relying on any text transcriptions.\nAutoPST is an Autoencoder-based Prosody Style Transfer framework with a\nthorough rhythm removal module guided by the self-expressive representation\nlearning. Experiments on different style transfer tasks show that AutoPST can\neffectively convert prosody that correctly reflects the styles of the target\ndomains.",
          "link": "http://arxiv.org/abs/2106.08519",
          "publishedOn": "2021-06-17T01:58:44.183Z",
          "wordCount": 629,
          "title": "Global Rhythm Style Transfer Without Text Transcriptions. (arXiv:2106.08519v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2007.10817",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Foo_L/0/1/0/all/0/1\">Lin Geng Foo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jiamei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Binder_A/0/1/0/all/0/1\">Alexander Binder</a>",
          "description": "We consider the problem of segmenting cell nuclei instances from Hematoxylin\nand Eosin (H&E) stains with dot annotations only. While most recent works focus\non improving the segmentation quality, this is usually insufficient for\ninstance segmentation of cell instances clustered together or with a small\nsize. In this work, we propose a simple two-step post-processing procedure,\nSplit and Expand, that directly improves the conversion of segmentation maps to\ninstances. In the splitting step, we generate fine-grained cell instances from\nthe segmentation map with the guidance of cell-center predictions. For the\nexpansion step, we utilize Layer-wise Relevance Propagation (LRP) explanation\nresults to add small cells that are not captured in the segmentation map.\nAlthough we additionally train an output head to predict cell-centers, the\npost-processing procedure itself is not explicitly trained and is executed at\ninference-time only. A feature re-weighting loss based on LRP is proposed to\nimprove our method even further. We test our procedure on the MoNuSeg and TNBC\ndatasets and show quantitatively and qualitatively that our proposed method\nimproves object-level metrics substantially.",
          "link": "http://arxiv.org/abs/2007.10817",
          "publishedOn": "2021-06-17T01:58:44.177Z",
          "wordCount": 649,
          "title": "Split and Expand: An inference-time improvement for Weakly Supervised Cell Instance Segmentation. (arXiv:2007.10817v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08864",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yuzhou Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_L/0/1/0/all/0/1\">Lei Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shu_S/0/1/0/all/0/1\">Senlin Shu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yitian Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+An_B/0/1/0/all/0/1\">Bo An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1\">Gang Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masashi Sugiyama</a>",
          "description": "Can we learn a multi-class classifier from only data of a single class? We\nshow that without any assumptions on the loss functions, models, and\noptimizers, we can successfully learn a multi-class classifier from only data\nof a single class with a rigorous consistency guarantee when confidences (i.e.,\nthe class-posterior probabilities for all the classes) are available.\nSpecifically, we propose an empirical risk minimization framework that is\nloss-/model-/optimizer-independent. Instead of constructing a boundary between\nthe given class and other classes, our method can conduct discriminative\nclassification between all the classes even if no data from the other classes\nare provided. We further theoretically and experimentally show that our method\ncan be Bayes-consistent with a simple modification even if the provided\nconfidences are highly noisy. Then, we provide an extension of our method for\nthe case where data from a subset of all the classes are available.\nExperimental results demonstrate the effectiveness of our methods.",
          "link": "http://arxiv.org/abs/2106.08864",
          "publishedOn": "2021-06-17T01:58:44.172Z",
          "wordCount": 592,
          "title": "Multi-Class Classification from Single-Class Data with Confidences. (arXiv:2106.08864v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08927",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Boes_W/0/1/0/all/0/1\">Wim Boes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rompaey_R/0/1/0/all/0/1\">Robbe Van Rompaey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verwimp_L/0/1/0/all/0/1\">Lyan Verwimp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pelemans_J/0/1/0/all/0/1\">Joris Pelemans</a>, <a href=\"http://arxiv.org/find/cs/1/au:+hamme_H/0/1/0/all/0/1\">Hugo Van hamme</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wambacq_P/0/1/0/all/0/1\">Patrick Wambacq</a>",
          "description": "We inspect the long-term learning ability of Long Short-Term Memory language\nmodels (LSTM LMs) by evaluating a contextual extension based on the Continuous\nBag-of-Words (CBOW) model for both sentence- and discourse-level LSTM LMs and\nby analyzing its performance. We evaluate on text and speech. Sentence-level\nmodels using the long-term contextual module perform comparably to vanilla\ndiscourse-level LSTM LMs. On the other hand, the extension does not provide\ngains for discourse-level models. These findings indicate that discourse-level\nLSTM LMs already rely on contextual information to perform long-term learning.",
          "link": "http://arxiv.org/abs/2106.08927",
          "publishedOn": "2021-06-17T01:58:44.166Z",
          "wordCount": 540,
          "title": "On the long-term learning ability of LSTM LMs. (arXiv:2106.08927v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08908",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pappas_D/0/1/0/all/0/1\">Dimitris Pappas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Androutsopoulos_I/0/1/0/all/0/1\">Ion Androutsopoulos</a>",
          "description": "Question answering (QA) systems for large document collections typically use\npipelines that (i) retrieve possibly relevant documents, (ii) re-rank them,\n(iii) rank paragraphs or other snippets of the top-ranked documents, and (iv)\nselect spans of the top-ranked snippets as exact answers. Pipelines are\nconceptually simple, but errors propagate from one component to the next,\nwithout later components being able to revise earlier decisions. We present an\narchitecture for joint document and snippet ranking, the two middle stages,\nwhich leverages the intuition that relevant documents have good snippets and\ngood snippets come from relevant documents. The architecture is general and can\nbe used with any neural text relevance ranker. We experiment with two main\ninstantiations of the architecture, based on POSIT-DRMM (PDRMM) and a\nBERT-based ranker. Experiments on biomedical data from BIOASQ show that our\njoint models vastly outperform the pipelines in snippet retrieval, the main\ngoal for QA, with fewer trainable parameters, also remaining competitive in\ndocument retrieval. Furthermore, our joint PDRMM-based model is competitive\nwith BERT-based models, despite using orders of magnitude fewer parameters.\nThese claims are also supported by human evaluation on two test batches of\nBIOASQ. To test our key findings on another dataset, we modified the Natural\nQuestions dataset so that it can also be used for document and snippet\nretrieval. Our joint PDRMM-based model again outperforms the corresponding\npipeline in snippet retrieval on the modified Natural Questions dataset, even\nthough it performs worse than the pipeline in document retrieval. We make our\ncode and the modified Natural Questions dataset publicly available.",
          "link": "http://arxiv.org/abs/2106.08908",
          "publishedOn": "2021-06-17T01:58:44.150Z",
          "wordCount": 713,
          "title": "A Neural Model for Joint Document and Snippet Ranking in Question Answering for Large Document Collections. (arXiv:2106.08908v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08870",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Marinho_E/0/1/0/all/0/1\">Eraldo Pereira Marinho</a>",
          "description": "A PCA-based, machine learning version of the SPH method is proposed. In the\npresent scheme, the smoothing tensor is computed to have their eigenvalues\nproportional to the covariance's principal components, using a modified octree\ndata structure, which allows the fast estimation of the anisotropic\nself-regulating kNN. Each SPH particle is the center of such an optimal kNN\ncluster, i.e., the one whose covariance tensor allows the find of the kNN\ncluster itself according to the Mahalanobis metric. Such machine learning\nconstitutes a fixed point problem. The definitive (self-regulating) kNN cluster\ndefines the smoothing volume, or properly saying, the smoothing ellipsoid,\nrequired to perform the anisotropic interpolation. Thus, the smoothing kernel\nhas an ellipsoidal profile, which changes how the kernel gradients are\ncomputed. As an application, it was performed the simulation of collapse and\nfragmentation of a non-magnetic, rotating gaseous sphere. An interesting\noutcome was the formation of protostars in the disc fragmentation, shown to be\nmuch more persistent and much more abundant in the anisotropic simulation than\nin the isotropic case.",
          "link": "http://arxiv.org/abs/2106.08870",
          "publishedOn": "2021-06-17T01:58:44.144Z",
          "wordCount": 604,
          "title": "Covariance-based smoothed particle hydrodynamics. A machine-learning application to simulating disc fragmentation. (arXiv:2106.08870v1 [physics.comp-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08858",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Karch_T/0/1/0/all/0/1\">Tristan Karch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teodorescu_L/0/1/0/all/0/1\">Laetitia Teodorescu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hofmann_K/0/1/0/all/0/1\">Katja Hofmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moulin_Frier_C/0/1/0/all/0/1\">Cl&#xe9;ment Moulin-Frier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oudeyer_P/0/1/0/all/0/1\">Pierre-Yves Oudeyer</a>",
          "description": "Language is an interface to the outside world. In order for embodied agents\nto use it, language must be grounded in other, sensorimotor modalities. While\nthere is an extended literature studying how machines can learn grounded\nlanguage, the topic of how to learn spatio-temporal linguistic concepts is\nstill largely uncharted. To make progress in this direction, we here introduce\na novel spatio-temporal language grounding task where the goal is to learn the\nmeaning of spatio-temporal descriptions of behavioral traces of an embodied\nagent. This is achieved by training a truth function that predicts if a\ndescription matches a given history of observations. The descriptions involve\ntime-extended predicates in past and present tense as well as spatio-temporal\nreferences to objects in the scene. To study the role of architectural biases\nin this task, we train several models including multimodal Transformer\narchitectures; the latter implement different attention computations between\nwords and objects across space and time. We test models on two classes of\ngeneralization: 1) generalization to randomly held-out sentences; 2)\ngeneralization to grammar primitives. We observe that maintaining object\nidentity in the attention computation of our Transformers is instrumental to\nachieving good performance on generalization overall, and that summarizing\nobject traces in a single token has little influence on performance. We then\ndiscuss how this opens new perspectives for language-guided autonomous embodied\nagents. We also release our code under open-source license as well as\npretrained models and datasets to encourage the wider community to build upon\nand extend our work in the future.",
          "link": "http://arxiv.org/abs/2106.08858",
          "publishedOn": "2021-06-17T01:58:44.138Z",
          "wordCount": 687,
          "title": "Grounding Spatio-Temporal Language with Transformers. (arXiv:2106.08858v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08417",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ngiam_J/0/1/0/all/0/1\">Jiquan Ngiam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caine_B/0/1/0/all/0/1\">Benjamin Caine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasudevan_V/0/1/0/all/0/1\">Vijay Vasudevan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhengdong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiang_H/0/1/0/all/0/1\">Hao-Tien Lewis Chiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_J/0/1/0/all/0/1\">Jeffrey Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roelofs_R/0/1/0/all/0/1\">Rebecca Roelofs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bewley_A/0/1/0/all/0/1\">Alex Bewley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chenxi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venugopal_A/0/1/0/all/0/1\">Ashish Venugopal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weiss_D/0/1/0/all/0/1\">David Weiss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sapp_B/0/1/0/all/0/1\">Ben Sapp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhifeng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shlens_J/0/1/0/all/0/1\">Jonathon Shlens</a>",
          "description": "Predicting the future motion of multiple agents is necessary for planning in\ndynamic environments. This task is challenging for autonomous driving since\nagents (e.g., vehicles and pedestrians) and their associated behaviors may be\ndiverse and influence each other. Most prior work has focused on first\npredicting independent futures for each agent based on all past motion, and\nthen planning against these independent predictions. However, planning against\nfixed predictions can suffer from the inability to represent the future\ninteraction possibilities between different agents, leading to sub-optimal\nplanning. In this work, we formulate a model for predicting the behavior of all\nagents jointly in real-world driving environments in a unified manner. Inspired\nby recent language modeling approaches, we use a masking strategy as the query\nto our model, enabling one to invoke a single model to predict agent behavior\nin many ways, such as potentially conditioned on the goal or full future\ntrajectory of the autonomous vehicle or the behavior of other agents in the\nenvironment. Our model architecture fuses heterogeneous world state in a\nunified Transformer architecture by employing attention across road elements,\nagent interactions and time steps. We evaluate our approach on autonomous\ndriving datasets for behavior prediction, and achieve state-of-the-art\nperformance. Our work demonstrates that formulating the problem of behavior\nprediction in a unified architecture with a masking strategy may allow us to\nhave a single model that can perform multiple motion prediction and planning\nrelated tasks effectively.",
          "link": "http://arxiv.org/abs/2106.08417",
          "publishedOn": "2021-06-17T01:58:44.132Z",
          "wordCount": 703,
          "title": "Scene Transformer: A unified multi-task model for behavior prediction and planning. (arXiv:2106.08417v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08846",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_F/0/1/0/all/0/1\">Fu-Ming Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_A/0/1/0/all/0/1\">Austin Huang</a>",
          "description": "Reducing computation cost, inference latency, and memory footprint of neural\nnetworks are frequently cited as research motivations for pruning and sparsity.\nHowever, operationalizing those benefits and understanding the end-to-end\neffect of algorithm design and regularization on the runtime execution is not\noften examined in depth.\n\nHere we apply structured and unstructured pruning to attention weights of\ntransformer blocks of the BERT language model, while also expanding block\nsparse representation (BSR) operations in the TVM compiler. Integration of BSR\noperations enables the TVM runtime execution to leverage structured pattern\nsparsity induced by model regularization.\n\nThis integrated view of pruning algorithms enables us to study relationships\nbetween modeling decisions and their direct impact on sparsity-enhanced\nexecution. Our main findings are: 1) we validate that performance benefits of\nstructured sparsity block regularization must be enabled by the BSR\naugmentations to TVM, with 4x speedup relative to vanilla PyTorch and 2.2x\nspeedup relative to standard TVM compilation (without expanded BSR support). 2)\nfor BERT attention weights, the end-to-end optimal block sparsity shape in this\nCPU inference context is not a square block (as in \\cite{gray2017gpu}) but\nrather a linear 32x1 block 3) the relationship between performance and block\nsize / shape is is suggestive of how model regularization parameters interact\nwith task scheduler optimizations resulting in the observed end-to-end\nperformance.",
          "link": "http://arxiv.org/abs/2106.08846",
          "publishedOn": "2021-06-17T01:58:44.126Z",
          "wordCount": 657,
          "title": "Algorithm to Compilation Codesign: An Integrated View of Neural Network Sparsity. (arXiv:2106.08846v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08537",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Diakonikolas_I/0/1/0/all/0/1\">Ilias Diakonikolas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kane_D/0/1/0/all/0/1\">Daniel M. Kane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kongsgaard_D/0/1/0/all/0/1\">Daniel Kongsgaard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jerry Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_K/0/1/0/all/0/1\">Kevin Tian</a>",
          "description": "We study the problem of list-decodable mean estimation, where an adversary\ncan corrupt a majority of the dataset. Specifically, we are given a set $T$ of\n$n$ points in $\\mathbb{R}^d$ and a parameter $0< \\alpha <\\frac 1 2$ such that\nan $\\alpha$-fraction of the points in $T$ are i.i.d. samples from a\nwell-behaved distribution $\\mathcal{D}$ and the remaining $(1-\\alpha)$-fraction\nof the points are arbitrary. The goal is to output a small list of vectors at\nleast one of which is close to the mean of $\\mathcal{D}$. As our main\ncontribution, we develop new algorithms for list-decodable mean estimation,\nachieving nearly-optimal statistical guarantees, with running time $n^{1 +\no(1)} d$. All prior algorithms for this problem had additional polynomial\nfactors in $\\frac 1 \\alpha$. As a corollary, we obtain the first almost-linear\ntime algorithms for clustering mixtures of $k$ separated well-behaved\ndistributions, nearly-matching the statistical guarantees of spectral methods.\nPrior clustering algorithms inherently relied on an application of $k$-PCA,\nthereby incurring runtimes of $\\Omega(n d k)$. This marks the first runtime\nimprovement for this basic statistical problem in nearly two decades.\n\nThe starting point of our approach is a novel and simpler near-linear time\nrobust mean estimation algorithm in the $\\alpha \\to 1$ regime, based on a\none-shot matrix multiplicative weights-inspired potential decrease. We\ncrucially leverage this new algorithmic framework in the context of the\niterative multi-filtering technique of Diakonikolas et. al. '18, '20, providing\na method to simultaneously cluster and downsample points using one-dimensional\nprojections --- thus, bypassing the $k$-PCA subroutines required by prior\nalgorithms.",
          "link": "http://arxiv.org/abs/2106.08537",
          "publishedOn": "2021-06-17T01:58:44.118Z",
          "wordCount": 704,
          "title": "Clustering Mixture Models in Almost-Linear Time via List-Decodable Mean Estimation. (arXiv:2106.08537v1 [cs.DS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08967",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Muller_Hannemann_M/0/1/0/all/0/1\">Matthias M&#xfc;ller-Hannemann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruckert_R/0/1/0/all/0/1\">Ralf R&#xfc;ckert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schiewe_A/0/1/0/all/0/1\">Alexander Schiewe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schobel_A/0/1/0/all/0/1\">Anita Sch&#xf6;bel</a>",
          "description": "The planning of attractive and cost efficient public transport systems is a\nhighly complex optimization process involving many steps. Integrating\nrobustness from a passenger's point of view makes the task even more\nchallenging. With numerous different definitions of robustness in literature, a\nreal-world acceptable evaluation of the robustness of a public transport system\nis to simulate its performance under a large number of possible scenarios.\nUnfortunately, this is computationally very expensive. In this paper, we\ntherefore explore a new way of such a scenario-based robustness approximation\nby using methods from machine learning. We achieve a fast approach with a very\nhigh accuracy by gathering a subset of key features of a public transport\nsystem and its passenger demand and training an artificial neural network to\nlearn the outcome of a given set of robustness tests. The network is then able\nto predict the robustness of untrained instances with high accuracy using only\nits key features, allowing for a robustness oracle for transport planners that\napproximates the robustness in constant time. Such an oracle can be used as\nblack box to increase the robustness within a local search framework for\nintegrated public transportation planning. In computational experiments with\ndifferent benchmark instances we demonstrate an excellent quality of our\npredictions.",
          "link": "http://arxiv.org/abs/2106.08967",
          "publishedOn": "2021-06-17T01:58:44.102Z",
          "wordCount": 635,
          "title": "Estimating the Robustness of Public Transport Systems Using Machine Learning. (arXiv:2106.08967v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08693",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tsaregorodtsev_A/0/1/0/all/0/1\">Alexander Tsaregorodtsev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belagiannis_V/0/1/0/all/0/1\">Vasileios Belagiannis</a>",
          "description": "We present an automated data augmentation approach for image classification.\nWe formulate the problem as Monte Carlo sampling where our goal is to\napproximate the optimal augmentation policies. We propose a particle filtering\nformulation to find optimal augmentation policies and their schedules during\nmodel training. Our performance measurement procedure relies on a validation\nsubset of our training set, while the policy transition model depends on a\nGaussian prior and an optional augmentation velocity parameter. In our\nexperiments, we show that our formulation for automated augmentation reaches\npromising results on CIFAR-10, CIFAR-100, and ImageNet datasets using the\nstandard network architectures for this problem. By comparing with the related\nwork, we also show that our method reaches a balance between the computational\ncost of policy search and the model performance.",
          "link": "http://arxiv.org/abs/2106.08693",
          "publishedOn": "2021-06-17T01:58:44.096Z",
          "wordCount": 555,
          "title": "ParticleAugment: Sampling-Based Data Augmentation. (arXiv:2106.08693v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08687",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhongjie Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1\">Mingye Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trapp_M/0/1/0/all/0/1\">Martin Trapp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Skryagin_A/0/1/0/all/0/1\">Arseny Skryagin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kersting_K/0/1/0/all/0/1\">Kristian Kersting</a>",
          "description": "Inspired by recent advances in the field of expert-based approximations of\nGaussian processes (GPs), we present an expert-based approach to large-scale\nmulti-output regression using single-output GP experts. Employing a deeply\nstructured mixture of single-output GPs encoded via a probabilistic circuit\nallows us to capture correlations between multiple output dimensions\naccurately. By recursively partitioning the covariate space and the output\nspace, posterior inference in our model reduces to inference on single-output\nGP experts, which only need to be conditioned on a small subset of the\nobservations. We show that inference can be performed exactly and efficiently\nin our model, that it can capture correlations between output dimensions and,\nhence, often outperforms approaches that do not incorporate inter-output\ncorrelations, as demonstrated on several data sets in terms of the negative log\npredictive density.",
          "link": "http://arxiv.org/abs/2106.08687",
          "publishedOn": "2021-06-17T01:58:44.089Z",
          "wordCount": 567,
          "title": "Leveraging Probabilistic Circuits for Nonparametric Multi-Output Regression. (arXiv:2106.08687v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08652",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Garcia_Soriano_D/0/1/0/all/0/1\">David Garcia-Soriano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bonchi_F/0/1/0/all/0/1\">Francesco Bonchi</a>",
          "description": "We study a novel problem of fairness in ranking aimed at minimizing the\namount of individual unfairness introduced when enforcing group-fairness\nconstraints. Our proposal is rooted in the distributional maxmin fairness\ntheory, which uses randomization to maximize the expected satisfaction of the\nworst-off individuals. We devise an exact polynomial-time algorithm to find\nmaxmin-fair distributions of general search problems (including, but not\nlimited to, ranking), and show that our algorithm can produce rankings which,\nwhile satisfying the given group-fairness constraints, ensure that the maximum\npossible value is brought to individuals.",
          "link": "http://arxiv.org/abs/2106.08652",
          "publishedOn": "2021-06-17T01:58:44.072Z",
          "wordCount": 523,
          "title": "Maxmin-Fair Ranking: Individual Fairness under Group-Fairness Constraints. (arXiv:2106.08652v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08891",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Edmonds_A/0/1/0/all/0/1\">Andrew Edmonds</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Brown_D/0/1/0/all/0/1\">David Brown</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Vinas_L/0/1/0/all/0/1\">Luciano Vinas</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Pagan_S/0/1/0/all/0/1\">Samantha Pagan</a>",
          "description": "We describe the use of machine learning algorithms to select high-quality\nmeasurements for the Mu2e experiment. This technique is important for\nexperiments with backgrounds that arise due to measurement errors. The\nalgorithms use multiple pieces of ancillary information that are sensitive to\nmeasurement quality to separate high-quality and low-quality measurements.",
          "link": "http://arxiv.org/abs/2106.08891",
          "publishedOn": "2021-06-17T01:58:44.065Z",
          "wordCount": 495,
          "title": "Using Machine Learning to Select High-Quality Measurements. (arXiv:2106.08891v1 [physics.data-an])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08706",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Pandey_L/0/1/0/all/0/1\">Laxmi Pandey</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Arif_A/0/1/0/all/0/1\">Ahmed Sabbir Arif</a>",
          "description": "Speech sounds of spoken language are obtained by varying configuration of the\narticulators surrounding the vocal tract. They contain abundant information\nthat can be utilized to better understand the underlying mechanism of human\nspeech production. We propose a novel deep neural network-based learning\nframework that understands acoustic information in the variable-length sequence\nof vocal tract shaping during speech production, captured by real-time magnetic\nresonance imaging (rtMRI), and translate it into text. The proposed framework\ncomprises of spatiotemporal convolutions, a recurrent network, and the\nconnectionist temporal classification loss, trained entirely end-to-end. On the\nUSC-TIMIT corpus, the model achieved a 40.6% PER at sentence-level, much better\ncompared to the existing models. To the best of our knowledge, this is the\nfirst study that demonstrates the recognition of entire spoken sentence based\non an individual's articulatory motions captured by rtMRI video. We also\nperformed an analysis of variations in the geometry of articulation in each\nsub-regions of the vocal tract (i.e., pharyngeal, velar and dorsal, hard\npalate, labial constriction region) with respect to different emotions and\ngenders. Results suggest that each sub-regions distortion is affected by both\nemotion and gender.",
          "link": "http://arxiv.org/abs/2106.08706",
          "publishedOn": "2021-06-17T01:58:44.057Z",
          "wordCount": 656,
          "title": "Silent Speech and Emotion Recognition from Vocal Tract Shape Dynamics in Real-Time MRI. (arXiv:2106.08706v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08567",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yuqing Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1\">Jinshuo Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu-Xiang Wang</a>",
          "description": "Characterizing the privacy degradation over compositions, i.e., privacy\naccounting, is a fundamental topic in differential privacy (DP) with many\napplications to differentially private machine learning and federated learning.\n\nWe propose a unification of recent advances (Renyi DP, privacy profiles,\n$f$-DP and the PLD formalism) via the characteristic function ($\\phi$-function)\nof a certain ``worst-case'' privacy loss random variable.\n\nWe show that our approach allows natural adaptive composition like Renyi DP,\n\nprovides exactly tight privacy accounting like PLD, and can be (often\nlosslessly) converted to privacy profile and $f$-DP, thus providing\n$(\\epsilon,\\delta)$-DP guarantees and interpretable tradeoff functions.\nAlgorithmically, we propose an analytical Fourier accountant that represents\nthe complex logarithm of $\\phi$-functions symbolically and uses Gaussian\nquadrature for numerical computation. On several popular DP mechanisms and\ntheir subsampled counterparts, we demonstrate the flexibility and tightness of\nour approach in theory and experiments.",
          "link": "http://arxiv.org/abs/2106.08567",
          "publishedOn": "2021-06-17T01:58:44.035Z",
          "wordCount": 565,
          "title": "Optimal Accounting of Differential Privacy via Characteristic Function. (arXiv:2106.08567v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08710",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1\">Jacky Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lam_K/0/1/0/all/0/1\">Kit-Yung Lam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_L/0/1/0/all/0/1\">Lik-Hang Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaoli Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hui_P/0/1/0/all/0/1\">Pan Hui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_X/0/1/0/all/0/1\">Xiang Su</a>",
          "description": "Mobile Augmented Reality (MAR) integrates computer-generated virtual objects\nwith physical environments for mobile devices. MAR systems enable users to\ninteract with MAR devices, such as smartphones and head-worn wearables, and\nperforms seamless transitions from the physical world to a mixed world with\ndigital entities. These MAR systems support user experiences by using MAR\ndevices to provide universal accessibility to digital contents. Over the past\n20 years, a number of MAR systems have been developed, however, the studies and\ndesign of MAR frameworks have not yet been systematically reviewed from the\nperspective of user-centric design. This article presents the first effort of\nsurveying existing MAR frameworks (count: 37) and further discusses the latest\nstudies on MAR through a top-down approach: 1) MAR applications; 2) MAR\nvisualisation techniques adaptive to user mobility and contexts; 3) systematic\nevaluation of MAR frameworks including supported platforms and corresponding\nfeatures such as tracking, feature extraction plus sensing capabilities; and 4)\nunderlying machine learning approaches supporting intelligent operations within\nMAR systems. Finally, we summarise the development of emerging research fields,\ncurrent state-of-the-art, and discuss the important open challenges and\npossible theoretical and technical directions. This survey aims to benefit both\nresearchers and MAR system developers alike.",
          "link": "http://arxiv.org/abs/2106.08710",
          "publishedOn": "2021-06-17T01:58:44.026Z",
          "wordCount": 658,
          "title": "Mobile Augmented Reality: User Interfaces, Frameworks, and Intelligence. (arXiv:2106.08710v1 [cs.HC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08849",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Geiger_M/0/1/0/all/0/1\">Mario Geiger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eloy_C/0/1/0/all/0/1\">Christophe Eloy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wyart_M/0/1/0/all/0/1\">Matthieu Wyart</a>",
          "description": "Reinforcement learning is made much more complex when the agent's observation\nis partial or noisy. This case corresponds to a partially observable Markov\ndecision process (POMDP). One strategy to seek good performance in POMDPs is to\nendow the agent with a finite memory, whose update is governed by the policy.\nHowever, policy optimization is non-convex in that case and can lead to poor\ntraining performance for random initialization. The performance can be\nempirically improved by constraining the memory architecture, then sacrificing\noptimality to facilitate training. Here we study this trade-off in the two-arm\nbandit problem, and compare two extreme cases: (i) the random access memory\nwhere any transitions between $M$ memory states are allowed and (ii) a fixed\nmemory where the agent can access its last $m$ actions and rewards. For (i),\nthe probability $q$ to play the worst arm is known to be exponentially small in\n$M$ for the optimal policy. Our main result is to show that similar performance\ncan be reached for (ii) as well, despite the simplicity of the memory\narchitecture: using a conjecture on Gray-ordered binary necklaces, we find\npolicies for which $q$ is exponentially small in $2^m$ i.e. $q\\sim\\alpha^{2^m}$\nfor some $\\alpha < 1$. Interestingly, we observe empirically that training from\nrandom initialization leads to very poor results for (i), and significantly\nbetter results for (ii).",
          "link": "http://arxiv.org/abs/2106.08849",
          "publishedOn": "2021-06-17T01:58:44.013Z",
          "wordCount": 647,
          "title": "How memory architecture affects performance and learning in simple POMDPs. (arXiv:2106.08849v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08571",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fang_X/0/1/0/all/0/1\">Xianghong Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_H/0/1/0/all/0/1\">Haoli Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zenglin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_M/0/1/0/all/0/1\">Michael Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+King_I/0/1/0/all/0/1\">Irwin King</a>",
          "description": "Variational autoencoders (VAEs) have been widely applied for text modeling.\nIn practice, however, they are troubled by two challenges: information\nunderrepresentation and posterior collapse. The former arises as only the last\nhidden state of LSTM encoder is transformed into the latent space, which is\ngenerally insufficient to summarize the data. The latter is a long-standing\nproblem during the training of VAEs as the optimization is trapped to a\ndisastrous local optimum. In this paper, we propose Discrete Auto-regressive\nVariational Attention Model (DAVAM) to address the challenges. Specifically, we\nintroduce an auto-regressive variational attention approach to enrich the\nlatent space by effectively capturing the semantic dependency from the input.\nWe further design discrete latent space for the variational attention and\nmathematically show that our model is free from posterior collapse. Extensive\nexperiments on language modeling tasks demonstrate the superiority of DAVAM\nagainst several VAE counterparts.",
          "link": "http://arxiv.org/abs/2106.08571",
          "publishedOn": "2021-06-17T01:58:44.008Z",
          "wordCount": 579,
          "title": "Discrete Auto-regressive Variational Attention Models for Text Modeling. (arXiv:2106.08571v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08619",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Favero_A/0/1/0/all/0/1\">Alessandro Favero</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cagnetta_F/0/1/0/all/0/1\">Francesco Cagnetta</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wyart_M/0/1/0/all/0/1\">Matthieu Wyart</a>",
          "description": "Convolutional neural networks perform a local and translationally-invariant\ntreatment of the data: quantifying which of these two aspects is central to\ntheir success remains a challenge. We study this problem within a\nteacher-student framework for kernel regression, using `convolutional' kernels\ninspired by the neural tangent kernel of simple convolutional architectures of\ngiven filter size. Using heuristic methods from physics, we find in the\nridgeless case that locality is key in determining the learning curve exponent\n$\\beta$ (that relates the test error $\\epsilon_t\\sim P^{-\\beta}$ to the size of\nthe training set $P$), whereas translational invariance is not. In particular,\nif the filter size of the teacher $t$ is smaller than that of the student $s$,\n$\\beta$ is a function of $s$ only and does not depend on the input dimension.\nWe confirm our predictions on $\\beta$ empirically. Theoretically, in some cases\n(including when teacher and student are equal) it can be shown that this\nprediction is an upper bound on performance. We conclude by proving, using a\nnatural universality assumption, that performing kernel regression with a ridge\nthat decreases with the size of the training set leads to similar learning\ncurve exponents to those we obtain in the ridgeless case.",
          "link": "http://arxiv.org/abs/2106.08619",
          "publishedOn": "2021-06-17T01:58:43.990Z",
          "wordCount": 642,
          "title": "Locality defeats the curse of dimensionality in convolutional teacher-student scenarios. (arXiv:2106.08619v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2102.06806",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Carderera_A/0/1/0/all/0/1\">Alejandro Carderera</a>, <a href=\"http://arxiv.org/find/math/1/au:+Diakonikolas_J/0/1/0/all/0/1\">Jelena Diakonikolas</a>, <a href=\"http://arxiv.org/find/math/1/au:+Lin_C/0/1/0/all/0/1\">Cheuk Yin Lin</a>, <a href=\"http://arxiv.org/find/math/1/au:+Pokutta_S/0/1/0/all/0/1\">Sebastian Pokutta</a>",
          "description": "Projection-free conditional gradient (CG) methods are the algorithms of\nchoice for constrained optimization setups in which projections are often\ncomputationally prohibitive but linear optimization over the constraint set\nremains computationally feasible. Unlike in projection-based methods, globally\naccelerated convergence rates are in general unattainable for CG. However, a\nvery recent work on Locally accelerated CG (LaCG) has demonstrated that local\nacceleration for CG is possible for many settings of interest. The main\ndownside of LaCG is that it requires knowledge of the smoothness and strong\nconvexity parameters of the objective function. We remove this limitation by\nintroducing a novel, Parameter-Free Locally accelerated CG (PF-LaCG) algorithm,\nfor which we provide rigorous convergence guarantees. Our theoretical results\nare complemented by numerical experiments, which demonstrate local acceleration\nand showcase the practical improvements of PF-LaCG over non-accelerated\nalgorithms, both in terms of iteration count and wall-clock time.",
          "link": "http://arxiv.org/abs/2102.06806",
          "publishedOn": "2021-06-17T01:58:43.962Z",
          "wordCount": 589,
          "title": "Parameter-free Locally Accelerated Conditional Gradients. (arXiv:2102.06806v2 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08616",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhan_L/0/1/0/all/0/1\">Li-Ming Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_H/0/1/0/all/0/1\">Haowen Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1\">Lu Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xiao-Ming Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lam_A/0/1/0/all/0/1\">Albert Y.S. Lam</a>",
          "description": "Out-of-scope intent detection is of practical importance in task-oriented\ndialogue systems. Since the distribution of outlier utterances is arbitrary and\nunknown in the training stage, existing methods commonly rely on strong\nassumptions on data distribution such as mixture of Gaussians to make\ninference, resulting in either complex multi-step training procedures or\nhand-crafted rules such as confidence threshold selection for outlier\ndetection. In this paper, we propose a simple yet effective method to train an\nout-of-scope intent classifier in a fully end-to-end manner by simulating the\ntest scenario in training, which requires no assumption on data distribution\nand no additional post-processing or threshold setting. Specifically, we\nconstruct a set of pseudo outliers in the training stage, by generating\nsynthetic outliers using inliner features via self-supervision and sampling\nout-of-scope sentences from easily available open-domain datasets. The pseudo\noutliers are used to train a discriminative classifier that can be directly\napplied to and generalize well on the test task. We evaluate our method\nextensively on four benchmark dialogue datasets and observe significant\nimprovements over state-of-the-art approaches. Our code has been released at\nhttps://github.com/liam0949/DCLOOS.",
          "link": "http://arxiv.org/abs/2106.08616",
          "publishedOn": "2021-06-17T01:58:43.945Z",
          "wordCount": 618,
          "title": "Out-of-Scope Intent Detection with Self-Supervision and Discriminative Training. (arXiv:2106.08616v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08680",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_G/0/1/0/all/0/1\">Gauri Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramesh_K/0/1/0/all/0/1\">Krithika Ramesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Sanjay Singh</a>",
          "description": "With language models being deployed increasingly in the real world, it is\nessential to address the issue of the fairness of their outputs. The word\nembedding representations of these language models often implicitly draw\nunwanted associations that form a social bias within the model. The nature of\ngendered languages like Hindi, poses an additional problem to the\nquantification and mitigation of bias, owing to the change in the form of the\nwords in the sentence, based on the gender of the subject. Additionally, there\nis sparse work done in the realm of measuring and debiasing systems for Indic\nlanguages. In our work, we attempt to evaluate and quantify the gender bias\nwithin a Hindi-English machine translation system. We implement a modified\nversion of the existing TGBI metric based on the grammatical considerations for\nHindi. We also compare and contrast the resulting bias measurements across\nmultiple metrics for pre-trained embeddings and the ones learned by our machine\ntranslation model.",
          "link": "http://arxiv.org/abs/2106.08680",
          "publishedOn": "2021-06-17T01:58:43.939Z",
          "wordCount": 587,
          "title": "Evaluating Gender Bias in Hindi-English Machine Translation. (arXiv:2106.08680v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08444",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaoli Li</a>",
          "description": "Dropout is attracting intensive research interest in deep learning as an\nefficient approach to prevent overfitting. Recently incorporating structural\ninformation when deciding which units to drop out produced promising results\ncomparing to methods that ignore the structural information. However, a major\nissue of the existing work is that it failed to differentiate among instances\nwhen constructing the dropout architecture. This can be a significant\ndeficiency for many applications. To solve this issue, we propose\nConstructivism learning for instance-dependent Dropout Architecture (CODA),\nwhich is inspired from a philosophical theory, constructivism learning.\nSpecially, based on the theory we have designed a better drop out technique,\nUniform Process Mixture Models, using a Bayesian nonparametric method Uniform\nprocess. We have evaluated our proposed method on 5 real-world datasets and\ncompared the performance with other state-of-the-art dropout techniques. The\nexperimental results demonstrated the effectiveness of CODA.",
          "link": "http://arxiv.org/abs/2106.08444",
          "publishedOn": "2021-06-17T01:58:43.933Z",
          "wordCount": 559,
          "title": "CODA: Constructivism Learning for Instance-Dependent Dropout Architecture Construction. (arXiv:2106.08444v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08678",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sim_A/0/1/0/all/0/1\">Aaron Sim</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wiatrak_M/0/1/0/all/0/1\">Maciej Wiatrak</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Brayne_A/0/1/0/all/0/1\">Angus Brayne</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Creed_P/0/1/0/all/0/1\">P&#xe1;id&#xed; Creed</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Paliwal_S/0/1/0/all/0/1\">Saee Paliwal</a>",
          "description": "The inductive biases of graph representation learning algorithms are often\nencoded in the background geometry of their embedding space. In this paper, we\nshow that general directed graphs can be effectively represented by an\nembedding model that combines three components: a pseudo-Riemannian metric\nstructure, a non-trivial global topology, and a unique likelihood function that\nexplicitly incorporates a preferred direction in embedding space. We\ndemonstrate the representational capabilities of this method by applying it to\nthe task of link prediction on a series of synthetic and real directed graphs\nfrom natural language applications and biology. In particular, we show that\nlow-dimensional cylindrical Minkowski and anti-de Sitter spacetimes can produce\nequal or better graph representations than curved Riemannian manifolds of\nhigher dimensions.",
          "link": "http://arxiv.org/abs/2106.08678",
          "publishedOn": "2021-06-17T01:58:43.880Z",
          "wordCount": 554,
          "title": "Directed Graph Embeddings in Pseudo-Riemannian Manifolds. (arXiv:2106.08678v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08393",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moitra_A/0/1/0/all/0/1\">Ankur Moitra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mossel_E/0/1/0/all/0/1\">Elchanan Mossel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sandon_C/0/1/0/all/0/1\">Colin Sandon</a>",
          "description": "In this work, we study the computational complexity of determining whether a\nmachine learning model that perfectly fits the training data will generalizes\nto unseen data. In particular, we study the power of a malicious agent whose\ngoal is to construct a model g that fits its training data and nothing else,\nbut is indistinguishable from an accurate model f. We say that g strongly\nspoofs f if no polynomial-time algorithm can tell them apart. If instead we\nrestrict to algorithms that run in $n^c$ time for some fixed $c$, we say that g\nc-weakly spoofs f. Our main results are\n\n1. Under cryptographic assumptions, strong spoofing is possible and 2. For\nany c> 0, c-weak spoofing is possible unconditionally\n\nWhile the assumption of a malicious agent is an extreme scenario (hopefully\ncompanies training large models are not malicious), we believe that it sheds\nlight on the inherent difficulties of blindly trusting large proprietary models\nor data.",
          "link": "http://arxiv.org/abs/2106.08393",
          "publishedOn": "2021-06-17T01:58:43.865Z",
          "wordCount": 590,
          "title": "Spoofing Generalization: When Can't You Trust Proprietary Models?. (arXiv:2106.08393v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08640",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abrate_C/0/1/0/all/0/1\">Carlo Abrate</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bonchi_F/0/1/0/all/0/1\">Francesco Bonchi</a>",
          "description": "Training graph classifiers able to distinguish between healthy brains and\ndysfunctional ones, can help identifying substructures associated to specific\ncognitive phenotypes. However, the mere predictive power of the graph\nclassifier is of limited interest to the neuroscientists, which have plenty of\ntools for the diagnosis of specific mental disorders. What matters is the\ninterpretation of the model, as it can provide novel insights and new\nhypotheses.\n\nIn this paper we propose \\emph{counterfactual graphs} as a way to produce\nlocal post-hoc explanations of any black-box graph classifier. Given a graph\nand a black-box, a counterfactual is a graph which, while having high\nstructural similarity with the original graph, is classified by the black-box\nin a different class. We propose and empirically compare several strategies for\ncounterfactual graph search. Our experiments against a white-box classifier\nwith known optimal counterfactual, show that our methods, although heuristic,\ncan produce counterfactuals very close to the optimal one. Finally, we show how\nto use counterfactual graphs to build global explanations correctly capturing\nthe behaviour of different black-box classifiers and providing interesting\ninsights for the neuroscientists.",
          "link": "http://arxiv.org/abs/2106.08640",
          "publishedOn": "2021-06-17T01:58:43.845Z",
          "wordCount": 613,
          "title": "Counterfactual Graphs for Explainable Classification of Brain Networks. (arXiv:2106.08640v1 [cs.SI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08488",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuwen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xingquan Zhu</a>",
          "description": "Hospital readmission prediction is a study to learn models from historical\nmedical data to predict probability of a patient returning to hospital in a\ncertain period, 30 or 90 days, after the discharge. The motivation is to help\nhealth providers deliver better treatment and post-discharge strategies, lower\nthe hospital readmission rate, and eventually reduce the medical costs. Due to\ninherent complexity of diseases and healthcare ecosystems, modeling hospital\nreadmission is facing many challenges. By now, a variety of methods have been\ndeveloped, but existing literature fails to deliver a complete picture to\nanswer some fundamental questions, such as what are the main challenges and\nsolutions in modeling hospital readmission; what are typical features/models\nused for readmission prediction; how to achieve meaningful and transparent\npredictions for decision making; and what are possible conflicts when deploying\npredictive approaches for real-world usages. In this paper, we systematically\nreview computational models for hospital readmission prediction, and propose a\ntaxonomy of challenges featuring four main categories: (1) data variety and\ncomplexity; (2) data imbalance, locality and privacy; (3) model\ninterpretability; and (4) model implementation. The review summarizes methods\nin each category, and highlights technical solutions proposed to address the\nchallenges. In addition, a review of datasets and resources available for\nhospital readmission modeling also provides firsthand materials to support\nresearchers and practitioners to design new approaches for effective and\nefficient hospital readmission prediction.",
          "link": "http://arxiv.org/abs/2106.08488",
          "publishedOn": "2021-06-17T01:58:43.743Z",
          "wordCount": 649,
          "title": "Predictive Modeling of Hospital Readmission: Challenges and Solutions. (arXiv:2106.08488v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08598",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rando_M/0/1/0/all/0/1\">Marco Rando</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carratino_L/0/1/0/all/0/1\">Luigi Carratino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Villa_S/0/1/0/all/0/1\">Silvia Villa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosasco_L/0/1/0/all/0/1\">Lorenzo Rosasco</a>",
          "description": "Gaussian process optimization is a successful class of algorithms (e.g.\nGP-UCB) to optimize a black-box function through sequential evaluations.\nHowever, when the domain of the function is continuous, Gaussian process\noptimization has to either rely on a fixed discretization of the space, or\nsolve a non-convex optimization subproblem at each evaluation. The first\napproach can negatively affect performance, while the second one puts a heavy\ncomputational burden on the algorithm. A third option, that only recently has\nbeen theoretically studied, is to adaptively discretize the function domain.\nEven though this approach avoids the extra non-convex optimization costs, the\noverall computational complexity is still prohibitive. An algorithm such as\nGP-UCB has a runtime of $O(T^4)$, where $T$ is the number of iterations. In\nthis paper, we introduce Ada-BKB (Adaptive Budgeted Kernelized Bandit), a\nno-regret Gaussian process optimization algorithm for functions on continuous\ndomains, that provably runs in $O(T^2 d_\\text{eff}^2)$, where $d_\\text{eff}$ is\nthe effective dimension of the explored space, and which is typically much\nsmaller than $T$. We corroborate our findings with experiments on synthetic\nnon-convex functions and on the real-world problem of hyper-parameter\noptimization.",
          "link": "http://arxiv.org/abs/2106.08598",
          "publishedOn": "2021-06-17T01:58:43.738Z",
          "wordCount": 619,
          "title": "Ada-BKB: Scalable Gaussian Process Optimization on Continuous Domain by Adaptive Discretization. (arXiv:2106.08598v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08887",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dezhong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Q/0/1/0/all/0/1\">Qiujin Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zihan Huang</a>",
          "description": "Anomalous diffusion, which shows a deviation of transport dynamics from the\nframework of standard Brownian motion, is involved in the evolution of various\nphysical, chemical, biological, and economic systems. The study of such random\nprocesses is of fundamental importance in unveiling the physical properties of\nrandom walkers and complex systems. However, classical methods to characterize\nanomalous diffusion are often disqualified for individual short trajectories,\nleading to the launch of the Anomalous Diffusion (AnDi) Challenge. This\nchallenge aims at objectively assessing and comparing new approaches for single\ntrajectory characterization, with respect to three different aspects: the\ninference of the anomalous diffusion exponent; the classification of the\ndiffusion model; and the segmentation of trajectories. In this article, to\naddress the inference and classification tasks in the challenge, we develop a\nWaveNet-based deep neural network (WADNet) by combining a modified WaveNet\nencoder with long short-term memory networks, without any prior knowledge of\nanomalous diffusion. As the performance of our model has surpassed the current\n1st places in the challenge leaderboard on both two tasks for all dimensions (6\nsubtasks), WADNet could be the part of state-of-the-art techniques to decode\nthe AnDi database. Our method presents a benchmark for future research, and\ncould accelerate the development of a versatile tool for the characterization\nof anomalous diffusion.",
          "link": "http://arxiv.org/abs/2106.08887",
          "publishedOn": "2021-06-17T01:58:43.631Z",
          "wordCount": 663,
          "title": "WaveNet-Based Deep Neural Networks for the Characterization of Anomalous Diffusion (WADNet). (arXiv:2106.08887v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08569",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sarkar_D/0/1/0/all/0/1\">Dipankar Sarkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_M/0/1/0/all/0/1\">Mukur Gupta</a>",
          "description": "The training of deep learning models poses vast challenges of including\nparameter tuning and ordering of training data. Significant research has been\ndone in Curriculum learning for optimizing the sequence of training data.\nRecent works have focused on using complex reinforcement learning techniques to\nfind the optimal data ordering strategy to maximize learning for a given\nnetwork. In this paper, we present a simple and efficient technique based on\ncontinuous optimization. We call this new approach Training Sequence\nOptimization (TSO). There are three critical components in our proposed\napproach: (a) An encoder network maps/embeds training sequence into continuous\nspace. (b) A predictor network uses the continuous representation of a strategy\nas input and predicts the accuracy for fixed network architecture. (c) A\ndecoder further maps a continuous representation of a strategy to the ordered\ntraining dataset. The performance predictor and encoder enable us to perform\ngradient-based optimization in the continuous space to find the embedding of\noptimal training data ordering with potentially better accuracy. Experiments\nshow that we can gain 2AP with our generated optimal curriculum strategy over\nthe random strategy using the CIFAR-100 dataset and have better boosts than the\nstate of the art CL algorithms. We do an ablation study varying the\narchitecture, dataset and sample sizes showcasing our approach's robustness.",
          "link": "http://arxiv.org/abs/2106.08569",
          "publishedOn": "2021-06-17T01:58:43.593Z",
          "wordCount": 641,
          "title": "TSO: Curriculum Generation using continuous optimization. (arXiv:2106.08569v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08544",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1\">Zhili Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roosta_F/0/1/0/all/0/1\">Fred Roosta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1\">David P. Woodruff</a>",
          "description": "A variety of dimensionality reduction techniques have been applied for\ncomputations involving large matrices. The underlying matrix is randomly\ncompressed into a smaller one, while approximately retaining many of its\noriginal properties. As a result, much of the expensive computation can be\nperformed on the small matrix. The sketching of positive semidefinite (PSD)\nmatrices is well understood, but there are many applications where the related\nmatrices are not PSD, including Hessian matrices in non-convex optimization and\ncovariance matrices in regression applications involving complex numbers. In\nthis paper, we present novel dimensionality reduction methods for non-PSD\nmatrices, as well as their ``square-roots\", which involve matrices with complex\nentries. We show how these techniques can be used for multiple downstream\ntasks. In particular, we show how to use the proposed matrix sketching\ntechniques for both convex and non-convex optimization, $\\ell_p$-regression for\nevery $1 \\leq p \\leq \\infty$, and vector-matrix-vector queries.",
          "link": "http://arxiv.org/abs/2106.08544",
          "publishedOn": "2021-06-17T01:58:43.570Z",
          "wordCount": 578,
          "title": "Non-PSD Matrix Sketching with Applications to Regression and Optimization. (arXiv:2106.08544v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2010.12760",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alvarez_Melis_D/0/1/0/all/0/1\">David Alvarez-Melis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fusi_N/0/1/0/all/0/1\">Nicol&#xf2; Fusi</a>",
          "description": "Various machine learning tasks, from generative modeling to domain\nadaptation, revolve around the concept of dataset transformation and\nmanipulation. While various methods exist for transforming unlabeled datasets,\nprincipled methods to do so for labeled (e.g., classification) datasets are\nmissing. In this work, we propose a novel framework for dataset transformation,\nwhich we cast as optimization over data-generating joint probability\ndistributions. We approach this class of problems through Wasserstein gradient\nflows in probability space, and derive practical and efficient particle-based\nmethods for a flexible but well-behaved class of objective functions. Through\nvarious experiments, we show that this framework can be used to impose\nconstraints on classification datasets, adapt them for transfer learning, or to\nre-purpose fixed or black-box models to classify ---with high accuracy---\npreviously unseen datasets.",
          "link": "http://arxiv.org/abs/2010.12760",
          "publishedOn": "2021-06-17T01:58:43.563Z",
          "wordCount": 580,
          "title": "Dataset Dynamics via Gradient Flows in Probability Space. (arXiv:2010.12760v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08717",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Grosse_J/0/1/0/all/0/1\">Julia Grosse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Cheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hennig_P/0/1/0/all/0/1\">Philipp Hennig</a>",
          "description": "Exciting contemporary machine learning problems have recently been phrased in\nthe classic formalism of tree search -- most famously, the game of Go.\nInterestingly, the state-space underlying these sequential decision-making\nproblems often posses a more general latent structure than can be captured by a\ntree. In this work, we develop a probabilistic framework to exploit a search\nspace's latent structure and thereby share information across the search tree.\nThe method is based on a combination of approximate inference in jointly\nGaussian models for the explored part of the problem, and an abstraction for\nthe unexplored part that imposes a reduction of complexity ad hoc. We\nempirically find our algorithm to compare favorably to existing\nnon-probabilistic alternatives in Tic-Tac-Toe and a feature selection\napplication.",
          "link": "http://arxiv.org/abs/2106.08717",
          "publishedOn": "2021-06-17T01:58:43.543Z",
          "wordCount": 552,
          "title": "Probabilistic DAG Search. (arXiv:2106.08717v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08767",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1\">Xiaomeng Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_T/0/1/0/all/0/1\">Tao Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potter_M/0/1/0/all/0/1\">Michael Potter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsai_Y/0/1/0/all/0/1\">Yun-Chan Tsai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_G/0/1/0/all/0/1\">Gaurav Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saripalli_V/0/1/0/all/0/1\">V. Ratna Saripalli</a>",
          "description": "There is a parameter ubiquitous throughout the deep learning world: learning\nrate. There is likewise a ubiquitous question: what should that learning rate\nbe? The true answer to this question is often tedious and time consuming to\nobtain, and a great deal of arcane knowledge has accumulated in recent years\nover how to pick and modify learning rates to achieve optimal training\nperformance. Moreover, the long hours spent carefully crafting the perfect\nlearning rate can come to nothing the moment your network architecture,\noptimizer, dataset, or initial conditions change ever so slightly. But it need\nnot be this way. We propose a new answer to the great learning rate question:\nthe Autonomous Learning Rate Controller. Find it at\nhttps://github.com/fastestimator/ARC",
          "link": "http://arxiv.org/abs/2106.08767",
          "publishedOn": "2021-06-17T01:58:43.471Z",
          "wordCount": 555,
          "title": "To Raise or Not To Raise: The Autonomous Learning Rate Question. (arXiv:2106.08767v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08890",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuanchun Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Ziqi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bingyan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Ziyue Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yunxin Liu</a>",
          "description": "The knowledge of a deep learning model may be transferred to a student model,\nleading to intellectual property infringement or vulnerability propagation.\nDetecting such knowledge reuse is nontrivial because the suspect models may not\nbe white-box accessible and/or may serve different tasks. In this paper, we\npropose ModelDiff, a testing-based approach to deep learning model similarity\ncomparison. Instead of directly comparing the weights, activations, or outputs\nof two models, we compare their behavioral patterns on the same set of test\ninputs. Specifically, the behavioral pattern of a model is represented as a\ndecision distance vector (DDV), in which each element is the distance between\nthe model's reactions to a pair of inputs. The knowledge similarity between two\nmodels is measured with the cosine similarity between their DDVs. To evaluate\nModelDiff, we created a benchmark that contains 144 pairs of models that cover\nmost popular model reuse methods, including transfer learning, model\ncompression, and model stealing. Our method achieved 91.7% correctness on the\nbenchmark, which demonstrates the effectiveness of using ModelDiff for model\nreuse detection. A study on mobile deep learning apps has shown the feasibility\nof ModelDiff on real-world models.",
          "link": "http://arxiv.org/abs/2106.08890",
          "publishedOn": "2021-06-17T01:58:43.444Z",
          "wordCount": 631,
          "title": "ModelDiff: Testing-Based DNN Similarity Comparison for Model Reuse Detection. (arXiv:2106.08890v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08532",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cho_H/0/1/0/all/0/1\">Hyeoncheol Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_Y/0/1/0/all/0/1\">Youngrock Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeon_E/0/1/0/all/0/1\">Eunjoo Jeon</a>",
          "description": "Explaining the foundations for predictions obtained from graph neural\nnetworks (GNNs) is critical for credible use of GNN models for real-world\nproblems. Owing to the rapid growth of GNN applications, recent progress in\nexplaining predictions from GNNs, such as sensitivity analysis, perturbation\nmethods, and attribution methods, showed great opportunities and possibilities\nfor explaining GNN predictions. In this study, we propose a method to improve\nthe explanation quality of node classification tasks that can be applied in a\npost hoc manner through aggregation of auxiliary explanations from important\nneighboring nodes, named SEEN. Applying SEEN does not require modification of a\ngraph and can be used with diverse explainability techniques due to its\nindependent mechanism. Experiments on matching motif-participating nodes from a\ngiven graph show great improvement in explanation accuracy of up to 12.71% and\ndemonstrate the correlation between the auxiliary explanations and the enhanced\nexplanation accuracy through leveraging their contributions. SEEN provides a\nsimple but effective method to enhance the explanation quality of GNN model\noutputs, and this method is applicable in combination with most explainability\ntechniques.",
          "link": "http://arxiv.org/abs/2106.08532",
          "publishedOn": "2021-06-17T01:58:43.437Z",
          "wordCount": 609,
          "title": "SEEN: Sharpening Explanations for Graph Neural Networks using Explanations from Neighborhoods. (arXiv:2106.08532v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08486",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chuah_W/0/1/0/all/0/1\">WeiQin Chuah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tennakoon_R/0/1/0/all/0/1\">Ruwan Tennakoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bab_Hadiashar_A/0/1/0/all/0/1\">Alireza Bab-Hadiashar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suter_D/0/1/0/all/0/1\">David Suter</a>",
          "description": "Learning-based stereo matching and depth estimation networks currently excel\non public benchmarks with impressive results. However, state-of-the-art\nnetworks often fail to generalize from synthetic imagery to more challenging\nreal data domains. This paper is an attempt to uncover hidden secrets of\nachieving domain robustness and in particular, discovering the important\ningredients of generalization success of stereo matching networks by analyzing\nthe effect of synthetic image learning on real data performance. We provide\nevidence that demonstrates that learning of features in the synthetic domain by\na stereo matching network is heavily influenced by two \"shortcuts\" presented in\nthe synthetic data: (1) identical local statistics (RGB colour features)\nbetween matching pixels in the synthetic stereo images and (2) lack of realism\nin synthetic textures on 3D objects simulated in game engines. We will show\nthat by removing such shortcuts, we can achieve domain robustness in the\nstate-of-the-art stereo matching frameworks and produce a remarkable\nperformance on multiple realistic datasets, despite the fact that the networks\nwere trained on synthetic data, only. Our experimental results point to the\nfact that eliminating shortcuts from the synthetic data is key to achieve\ndomain-invariant generalization between synthetic and real data domains.",
          "link": "http://arxiv.org/abs/2106.08486",
          "publishedOn": "2021-06-17T01:58:43.414Z",
          "wordCount": 640,
          "title": "Achieving Domain Robustness in Stereo Matching Networks by Removing Shortcut Learning. (arXiv:2106.08486v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08704",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rabin_M/0/1/0/all/0/1\">Md Rafiqul Islam Rabin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hussain_A/0/1/0/all/0/1\">Aftab Hussain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hellendoorn_V/0/1/0/all/0/1\">Vincent J. Hellendoorn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alipour_M/0/1/0/all/0/1\">Mohammad Amin Alipour</a>",
          "description": "Deep Neural Networks (DNN) are increasingly commonly used in software\nengineering and code intelligence tasks. These are powerful tools that are\ncapable of learning highly generalizable patterns from large datasets through\nmillions of parameters. At the same time, training DNNs means walking a knife's\nedges, because their large capacity also renders them prone to memorizing data\npoints. While traditionally thought of as an aspect of over-training, recent\nwork suggests that the memorization risk manifests especially strongly when the\ntraining datasets are noisy and memorization is the only recourse.\nUnfortunately, most code intelligence tasks rely on rather noise-prone and\nrepetitive data sources, such as GitHub, which, due to their sheer size, cannot\nbe manually inspected and evaluated. We evaluate the memorization and\ngeneralization tendencies in neural code intelligence models through a case\nstudy across several benchmarks and model families by leveraging established\napproaches from other fields that use DNNs, such as introducing targeted noise\ninto the training dataset. In addition to reinforcing prior general findings\nabout the extent of memorization in DNNs, our results shed light on the impact\nof noisy dataset in training.",
          "link": "http://arxiv.org/abs/2106.08704",
          "publishedOn": "2021-06-17T01:58:43.361Z",
          "wordCount": 625,
          "title": "Memorization and Generalization in Neural Code Intelligence Models. (arXiv:2106.08704v1 [cs.SE])"
        },
        {
          "id": "http://arxiv.org/abs/2006.06863",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yiyang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Linnan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yuandong Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fonseca_R/0/1/0/all/0/1\">Rodrigo Fonseca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_T/0/1/0/all/0/1\">Tian Guo</a>",
          "description": "Efficient evaluation of a network architecture drawn from a large search\nspace remains a key challenge in Neural Architecture Search (NAS). Vanilla NAS\nevaluates each architecture by training from scratch, which gives the true\nperformance but is extremely time-consuming. Recently, one-shot NAS\nsubstantially reduces the computation cost by training only one supernetwork,\na.k.a. supernet, to approximate the performance of every architecture in the\nsearch space via weight-sharing. However, the performance estimation can be\nvery inaccurate due to the co-adaption among operations. In this paper, we\npropose few-shot NAS that uses multiple supernetworks, called sub-supernet,\neach covering different regions of the search space to alleviate the undesired\nco-adaption. Compared to one-shot NAS, few-shot NAS improves the accuracy of\narchitecture evaluation with a small increase of evaluation cost. With only up\nto 7 sub-supernets, few-shot NAS establishes new SoTAs: on ImageNet, it finds\nmodels that reach 80.5% top-1 accuracy at 600 MB FLOPS and 77.5% top-1 accuracy\nat 238 MFLOPS; on CIFAR10, it reaches 98.72% top-1 accuracy without using extra\ndata or transfer learning. In Auto-GAN, few-shot NAS outperforms the previously\npublished results by up to 20%. Extensive experiments show that few-shot NAS\nsignificantly improves various one-shot methods, including 4 gradient-based and\n6 search-based methods on 3 different tasks in NasBench-201 and\nNasBench1-shot-1.",
          "link": "http://arxiv.org/abs/2006.06863",
          "publishedOn": "2021-06-17T01:58:43.267Z",
          "wordCount": 719,
          "title": "Few-shot Neural Architecture Search. (arXiv:2006.06863v8 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.06624",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1\">Jiangchao Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Feng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_K/0/1/0/all/0/1\">KunYang Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1\">Bo Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jingren Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hongxia Yang</a>",
          "description": "With the rapid development of storage and computing power on mobile devices,\nit becomes critical and popular to deploy models on devices to save onerous\ncommunication latencies and to capture real-time features. While quite a lot of\nworks have explored to facilitate on-device learning and inference, most of\nthem focus on dealing with response delay or privacy protection. Little has\nbeen done to model the collaboration between the device and the cloud modeling\nand benefit both sides jointly. To bridge this gap, we are among the first\nattempts to study the Device-Cloud Collaborative Learning (DCCL) framework.\nSpecifically, we propose a novel MetaPatch learning approach on the device side\nto efficiently achieve \"thousands of people with thousands of models\" given a\ncentralized cloud model. Then, with billions of updated personalized device\nmodels, we propose a \"model-over-models\" distillation algorithm, namely\nMoMoDistill, to update the centralized cloud model. Our extensive experiments\nover a range of datasets with different settings demonstrate the effectiveness\nof such collaboration on both cloud and devices, especially its superiority to\nmodel long-tailed users.",
          "link": "http://arxiv.org/abs/2104.06624",
          "publishedOn": "2021-06-17T01:58:43.240Z",
          "wordCount": 668,
          "title": "Device-Cloud Collaborative Learning for Recommendation. (arXiv:2104.06624v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.04655",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenhao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramezani_R/0/1/0/all/0/1\">Ramin Ramezani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naeim_A/0/1/0/all/0/1\">Arash Naeim</a>",
          "description": "A data science task can be deemed as making sense of the data or testing a\nhypothesis about it. The conclusions inferred from data can greatly guide us to\nmake informative decisions. Big data has enabled us to carry out countless\nprediction tasks in conjunction with machine learning, such as identifying high\nrisk patients suffering from a certain disease and taking preventable measures.\nHowever, healthcare practitioners are not content with mere predictions - they\nare also interested in the cause-effect relation between input features and\nclinical outcomes. Understanding such relations will help doctors treat\npatients and reduce the risk effectively. Causality is typically identified by\nrandomized controlled trials. Often such trials are not feasible when\nscientists and researchers turn to observational studies and attempt to draw\ninferences. However, observational studies may also be affected by selection\nand/or confounding biases that can result in wrong causal conclusions. In this\nchapter, we will try to highlight some of the drawbacks that may arise in\ntraditional machine learning and statistical approaches to analyze the\nobservational data, particularly in the healthcare data analytics domain. We\nwill discuss causal inference and ways to discover the cause-effect from\nobservational studies in healthcare domain. Moreover, we will demonstrate the\napplications of causal inference in tackling some common machine learning\nissues such as missing data and model transportability. Finally, we will\ndiscuss the possibility of integrating reinforcement learning with causality as\na way to counter confounding bias.",
          "link": "http://arxiv.org/abs/2105.04655",
          "publishedOn": "2021-06-17T01:58:43.226Z",
          "wordCount": 717,
          "title": "Causal Inference in medicine and in health policy, a summary. (arXiv:2105.04655v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.07978",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nielsen_A/0/1/0/all/0/1\">A. H. Nielsen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iosifidis_A/0/1/0/all/0/1\">A. Iosifidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karstoft_H/0/1/0/all/0/1\">H. Karstoft</a>",
          "description": "Forecasting the formation and development of clouds is a central element of\nmodern weather forecasting systems. Incorrect clouds forecasts can lead to\nmajor uncertainty in the overall accuracy of weather forecasts due to their\nintrinsic role in the Earth's climate system. Few studies have tackled this\nchallenging problem from a machine learning point-of-view due to a shortage of\nhigh-resolution datasets with many historical observations globally. In this\npaper, we present a novel satellite-based dataset called ``CloudCast''. It\nconsists of 70,080 images with 10 different cloud types for multiple layers of\nthe atmosphere annotated on a pixel level. The spatial resolution of the\ndataset is 928 x 1530 pixels (3x3 km per pixel) with 15-min intervals between\nframes for the period 2017-01-01 to 2018-12-31. All frames are centered and\nprojected over Europe. To supplement the dataset, we conduct an evaluation\nstudy with current state-of-the-art video prediction methods such as\nconvolutional long short-term memory networks, generative adversarial networks,\nand optical flow-based extrapolation methods. As the evaluation of video\nprediction is difficult in practice, we aim for a thorough evaluation in the\nspatial and temporal domain. Our benchmark models show promising results but\nwith ample room for improvement. This is the first publicly available\nglobal-scale dataset with high-resolution cloud types on a high temporal\ngranularity to the authors' best knowledge.",
          "link": "http://arxiv.org/abs/2007.07978",
          "publishedOn": "2021-06-17T01:58:43.191Z",
          "wordCount": 711,
          "title": "CloudCast: A Satellite-Based Dataset and Baseline for Forecasting Clouds. (arXiv:2007.07978v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.09019",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xingyuan Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_T/0/1/0/all/0/1\">Tianju Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rusinkiewicz_S/0/1/0/all/0/1\">Szymon M. Rusinkiewicz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adams_R/0/1/0/all/0/1\">Ryan P. Adams</a>",
          "description": "In design, fabrication, and control problems, we are often faced with the\ntask of synthesis, in which we must generate an object or configuration that\nsatisfies a set of constraints while maximizing one or more objective\nfunctions. The synthesis problem is typically characterized by a physical\nprocess in which many different realizations may achieve the goal. This\nmany-to-one map presents challenges to the supervised learning of feed-forward\nsynthesis, as the set of viable designs may have a complex structure. In\naddition, the non-differentiable nature of many physical simulations prevents\ndirect optimization. We address both of these problems with a two-stage neural\nnetwork architecture that we may consider to be an autoencoder. We first learn\nthe decoder: a differentiable surrogate that approximates the many-to-one\nphysical realization process. We then learn the encoder, which maps from goal\nto design, while using the fixed decoder to evaluate the quality of the\nrealization. We evaluate the approach on two case studies: extruder path\nplanning in additive manufacturing and constrained soft robot inverse\nkinematics. We compare our approach to direct optimization of design using the\nlearned surrogate, and to supervised learning of the synthesis problem. We find\nthat our approach produces higher quality solutions than supervised learning,\nwhile being competitive in quality with direct optimization, at a greatly\nreduced computational cost.",
          "link": "http://arxiv.org/abs/2106.09019",
          "publishedOn": "2021-06-17T01:58:43.178Z",
          "wordCount": 656,
          "title": "Amortized Synthesis of Constrained Configurations Using a Differentiable Surrogate. (arXiv:2106.09019v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03096",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Du_L/0/1/0/all/0/1\">Lun Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_F/0/1/0/all/0/1\">Fei Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1\">Ran Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Junshan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Shi Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dongmei Zhang</a>",
          "description": "Tabular data are ubiquitous for the widespread applications of tables and\nhence have attracted the attention of researchers to extract underlying\ninformation. One of the critical problems in mining tabular data is how to\nunderstand their inherent semantic structures automatically. Existing studies\ntypically adopt Convolutional Neural Network (CNN) to model the spatial\ninformation of tabular structures yet ignore more diverse relational\ninformation between cells, such as the hierarchical and paratactic\nrelationships. To simultaneously extract spatial and relational information\nfrom tables, we propose a novel neural network architecture, TabularNet. The\nspatial encoder of TabularNet utilizes the row/column-level Pooling and the\nBidirectional Gated Recurrent Unit (Bi-GRU) to capture statistical information\nand local positional correlation, respectively. For relational information, we\ndesign a new graph construction method based on the WordNet tree and adopt a\nGraph Convolutional Network (GCN) based encoder that focuses on the\nhierarchical and paratactic relationships between cells. Our neural network\narchitecture can be a unified neural backbone for different understanding tasks\nand utilized in a multitask scenario. We conduct extensive experiments on three\nclassification tasks with two real-world spreadsheet data sets, and the results\ndemonstrate the effectiveness of our proposed TabularNet over state-of-the-art\nbaselines.",
          "link": "http://arxiv.org/abs/2106.03096",
          "publishedOn": "2021-06-17T01:58:43.170Z",
          "wordCount": 667,
          "title": "TabularNet: A Neural Network Architecture for Understanding Semantic Structures of Tabular Data. (arXiv:2106.03096v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08902",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ghosh_A/0/1/0/all/0/1\">Avishek Ghosh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sankararaman_A/0/1/0/all/0/1\">Abishek Sankararaman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ramchandran_K/0/1/0/all/0/1\">Kannan Ramchandran</a>",
          "description": "We consider the problem of minimizing regret in an $N$ agent heterogeneous\nstochastic linear bandits framework, where the agents (users) are similar but\nnot all identical. We model user heterogeneity using two popularly used ideas\nin practice; (i) A clustering framework where users are partitioned into groups\nwith users in the same group being identical to each other, but different\nacross groups, and (ii) a personalization framework where no two users are\nnecessarily identical, but a user's parameters are close to that of the\npopulation average. In the clustered users' setup, we propose a novel\nalgorithm, based on successive refinement of cluster identities and regret\nminimization. We show that, for any agent, the regret scales as\n$\\mathcal{O}(\\sqrt{T/N})$, if the agent is in a `well separated' cluster, or\nscales as $\\mathcal{O}(T^{\\frac{1}{2} + \\varepsilon}/(N)^{\\frac{1}{2}\n-\\varepsilon})$ if its cluster is not well separated, where $\\varepsilon$ is\npositive and arbitrarily close to $0$. Our algorithm is adaptive to the cluster\nseparation, and is parameter free -- it does not need to know the number of\nclusters, separation and cluster size, yet the regret guarantee adapts to the\ninherent complexity. In the personalization framework, we introduce a natural\nalgorithm where, the personal bandit instances are initialized with the\nestimates of the global average model. We show that, an agent $i$ whose\nparameter deviates from the population average by $\\epsilon_i$, attains a\nregret scaling of $\\widetilde{O}(\\epsilon_i\\sqrt{T})$. This demonstrates that\nif the user representations are close (small $\\epsilon_i)$, the resulting\nregret is low, and vice-versa. The results are empirically validated and we\nobserve superior performance of our adaptive algorithms over non-adaptive\nbaselines.",
          "link": "http://arxiv.org/abs/2106.08902",
          "publishedOn": "2021-06-17T01:58:43.142Z",
          "wordCount": 698,
          "title": "Collaborative Learning and Personalization in Multi-Agent Stochastic Linear Bandits. (arXiv:2106.08902v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08823",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bhojanapalli_S/0/1/0/all/0/1\">Srinadh Bhojanapalli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakrabarti_A/0/1/0/all/0/1\">Ayan Chakrabarti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_H/0/1/0/all/0/1\">Himanshu Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Sanjiv Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lukasik_M/0/1/0/all/0/1\">Michal Lukasik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Veit_A/0/1/0/all/0/1\">Andreas Veit</a>",
          "description": "State-of-the-art transformer models use pairwise dot-product based\nself-attention, which comes at a computational cost quadratic in the input\nsequence length. In this paper, we investigate the global structure of\nattention scores computed using this dot product mechanism on a typical\ndistribution of inputs, and study the principal components of their variation.\nThrough eigen analysis of full attention score matrices, as well as of their\nindividual rows, we find that most of the variation among attention scores lie\nin a low-dimensional eigenspace. Moreover, we find significant overlap between\nthese eigenspaces for different layers and even different transformer models.\nBased on this, we propose to compute scores only for a partial subset of token\npairs, and use them to estimate scores for the remaining pairs. Beyond\ninvestigating the accuracy of reconstructing attention scores themselves, we\ninvestigate training transformer models that employ these approximations, and\nanalyze the effect on overall accuracy. Our analysis and the proposed method\nprovide insights into how to balance the benefits of exact pair-wise attention\nand its significant computational expense.",
          "link": "http://arxiv.org/abs/2106.08823",
          "publishedOn": "2021-06-17T01:58:43.128Z",
          "wordCount": 606,
          "title": "Eigen Analysis of Self-Attention and its Reconstruction from Partial Computation. (arXiv:2106.08823v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2002.02077",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rangesh_A/0/1/0/all/0/1\">Akshay Rangesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Bowen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trivedi_M/0/1/0/all/0/1\">Mohan M. Trivedi</a>",
          "description": "A driver's gaze is critical for determining their attention, state,\nsituational awareness, and readiness to take over control from partially\nautomated vehicles. Estimating the gaze direction is the most obvious way to\ngauge a driver's state under ideal conditions when limited to using\nnon-intrusive imaging sensors. Unfortunately, the vehicular environment\nintroduces a variety of challenges that are usually unaccounted for - harsh\nillumination, nighttime conditions, and reflective eyeglasses. Relying on head\npose alone under such conditions can prove to be unreliable and erroneous. In\nthis study, we offer solutions to address these problems encountered in the\nreal world. To solve issues with lighting, we demonstrate that using an\ninfrared camera with suitable equalization and normalization suffices. To\nhandle eyeglasses and their corresponding artifacts, we adopt image-to-image\ntranslation using generative adversarial networks to pre-process images prior\nto gaze estimation. Our proposed Gaze Preserving CycleGAN (GPCycleGAN) is\ntrained to preserve the driver's gaze while removing potential eyeglasses from\nface images. GPCycleGAN is based on the well-known CycleGAN approach - with the\naddition of a gaze classifier and a gaze consistency loss for additional\nsupervision. Our approach exhibits improved performance, interpretability,\nrobustness and superior qualitative results on challenging real-world datasets.",
          "link": "http://arxiv.org/abs/2002.02077",
          "publishedOn": "2021-06-17T01:58:43.122Z",
          "wordCount": 699,
          "title": "Gaze Preserving CycleGANs for Eyeglass Removal & Persistent Gaze Estimation. (arXiv:2002.02077v6 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.10249",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Laage_G/0/1/0/all/0/1\">Greta Laage</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frejinger_E/0/1/0/all/0/1\">Emma Frejinger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lodi_A/0/1/0/all/0/1\">Andrea Lodi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rabusseau_G/0/1/0/all/0/1\">Guillaume Rabusseau</a>",
          "description": "Airlines and other industries have been making use of sophisticated Revenue\nManagement Systems to maximize revenue for decades. While improving the\ndifferent components of these systems has been the focus of numerous studies,\nestimating the impact of such improvements on the revenue has been overlooked\nin the literature despite its practical importance. Indeed, quantifying the\nbenefit of a change in a system serves as support for investment decisions.\nThis is a challenging problem as it corresponds to the difference between the\ngenerated value and the value that would have been generated keeping the system\nas before. The latter is not observable. Moreover, the expected impact can be\nsmall in relative value. In this paper, we cast the problem as counterfactual\nprediction of unobserved revenue. The impact on revenue is then the difference\nbetween the observed and the estimated revenue. The originality of this work\nlies in the innovative application of econometric methods proposed for\nmacroeconomic applications to a new problem setting. Broadly applicable, the\napproach benefits from only requiring revenue data observed for\norigin-destination pairs in the network of the airline at each day, before and\nafter a change in the system is applied. We report results using real\nlarge-scale data from Air Canada. We compare a deep neural network\ncounterfactual predictions model with econometric models. They achieve\nrespectively 1% and 1.1% of error on the counterfactual revenue predictions,\nand allow to accurately estimate small impacts (in the order of 2%).",
          "link": "http://arxiv.org/abs/2101.10249",
          "publishedOn": "2021-06-17T01:58:43.115Z",
          "wordCount": 718,
          "title": "Assessing the Impact: Does an Improvement to a Revenue Management System Lead to an Improved Revenue?. (arXiv:2101.10249v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08909",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brandfonbrener_D/0/1/0/all/0/1\">David Brandfonbrener</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Whitney_W/0/1/0/all/0/1\">William F. Whitney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranganath_R/0/1/0/all/0/1\">Rajesh Ranganath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bruna_J/0/1/0/all/0/1\">Joan Bruna</a>",
          "description": "Most prior approaches to offline reinforcement learning (RL) have taken an\niterative actor-critic approach involving off-policy evaluation. In this paper\nwe show that simply doing one step of constrained/regularized policy\nimprovement using an on-policy Q estimate of the behavior policy performs\nsurprisingly well. This one-step algorithm beats the previously reported\nresults of iterative algorithms on a large portion of the D4RL benchmark. The\nsimple one-step baseline achieves this strong performance without many of the\ntricks used by previously proposed iterative algorithms and is more robust to\nhyperparameters. We argue that the relatively poor performance of iterative\napproaches is a result of the high variance inherent in doing off-policy\nevaluation and magnified by the repeated optimization of policies against those\nhigh-variance estimates. In addition, we hypothesize that the strong\nperformance of the one-step algorithm is due to a combination of favorable\nstructure in the environment and behavior policy.",
          "link": "http://arxiv.org/abs/2106.08909",
          "publishedOn": "2021-06-17T01:58:43.108Z",
          "wordCount": 571,
          "title": "Offline RL Without Off-Policy Evaluation. (arXiv:2106.08909v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08963",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nencka_A/0/1/0/all/0/1\">Andrew S. Nencka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sherafati_M/0/1/0/all/0/1\">Mohammad Sherafati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goebel_T/0/1/0/all/0/1\">Timothy Goebel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tolat_P/0/1/0/all/0/1\">Parag Tolat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koch_K/0/1/0/all/0/1\">Kevin M. Koch</a>",
          "description": "Purpose: This study evaluates the effectiveness and impact of automated\norder-based protocol assignment for magnetic resonance imaging (MRI) exams\nusing natural language processing (NLP) and deep learning (DL).\n\nMethods: NLP tools were applied to retrospectively process orders from over\n116,000 MRI exams with 200 unique sub-specialized protocols (\"Local\" protocol\nclass). Separate DL models were trained on 70\\% of the processed data for\n\"Local\" protocols as well as 93 American College of Radiology (\"ACR\") protocols\nand 48 \"General\" protocols. The DL Models were assessed in an \"auto-protocoling\n(AP)\" inference mode which returns the top recommendation and in a \"clinical\ndecision support (CDS)\" inference mode which returns up to 10 protocols for\nradiologist review. The accuracy of each protocol recommendation was computed\nand analyzed based on the difference between the normalized output score of the\ncorresponding neural net for the top two recommendations.\n\nResults: The top predicted protocol in AP mode was correct for 82.8%, 73.8%,\nand 69.3% of the test cases for \"General\", \"ACR\", and \"Local\" protocol classes,\nrespectively. Higher levels of accuracy over 96% were obtained for all protocol\nclasses in CDS mode. However, at current validation performance levels, the\nproposed models offer modest, positive, financial impact on large-scale imaging\nnetworks.\n\nConclusions: DL-based protocol automation is feasible and can be tuned to\nroute substantial fractions of exams for auto-protocoling, with higher accuracy\nwith more general protocols. Economic analyses of the tested algorithms\nindicate that improved algorithm performance is required to yield a practical\nexam auto-protocoling tool for sub-specialized imaging exams.",
          "link": "http://arxiv.org/abs/2106.08963",
          "publishedOn": "2021-06-17T01:58:43.094Z",
          "wordCount": 699,
          "title": "Deep-learning based Tools for Automated Protocol Definition of Advanced Diagnostic Imaging Exams. (arXiv:2106.08963v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2103.16223",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Muller_A/0/1/0/all/0/1\">Arthur M&#xfc;ller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rangras_V/0/1/0/all/0/1\">Vishal Rangras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schnittker_G/0/1/0/all/0/1\">Georg Schnittker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Waldmann_M/0/1/0/all/0/1\">Michael Waldmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Friesen_M/0/1/0/all/0/1\">Maxim Friesen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferfers_T/0/1/0/all/0/1\">Tobias Ferfers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schreckenberg_L/0/1/0/all/0/1\">Lukas Schreckenberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hufen_F/0/1/0/all/0/1\">Florian Hufen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jasperneite_J/0/1/0/all/0/1\">J&#xfc;rgen Jasperneite</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wiering_M/0/1/0/all/0/1\">Marco Wiering</a>",
          "description": "Sub-optimal control policies in intersection traffic signal controllers (TSC)\ncontribute to congestion and lead to negative effects on human health and the\nenvironment. Reinforcement learning (RL) for traffic signal control is a\npromising approach to design better control policies and has attracted\nconsiderable research interest in recent years. However, most work done in this\narea used simplified simulation environments of traffic scenarios to train\nRL-based TSC. To deploy RL in real-world traffic systems, the gap between\nsimplified simulation environments and real-world applications has to be\nclosed. Therefore, we propose LemgoRL, a benchmark tool to train RL agents as\nTSC in a realistic simulation environment of Lemgo, a medium-sized town in\nGermany. In addition to the realistic simulation model, LemgoRL encompasses a\ntraffic signal logic unit that ensures compliance with all regulatory and\nsafety requirements. LemgoRL offers the same interface as the well-known OpenAI\ngym toolkit to enable easy deployment in existing research work. Our benchmark\ntool drives the development of RL algorithms towards real-world applications.\nWe provide LemgoRL as an open-source tool at https://github.com/rl-ina/lemgorl.",
          "link": "http://arxiv.org/abs/2103.16223",
          "publishedOn": "2021-06-17T01:58:43.086Z",
          "wordCount": 667,
          "title": "LemgoRL: An open-source Benchmark Tool to Train Reinforcement Learning Agents for Traffic Signal Control in a real-world simulation scenario. (arXiv:2103.16223v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08779",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_A/0/1/0/all/0/1\">Amulya Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_N/0/1/0/all/0/1\">Nitin Gupta</a>",
          "description": "An outlier is an observation or a data point that is far from rest of the\ndata points in a given dataset or we can be said that an outlier is away from\nthe center of mass of observations. Presence of outliers can skew statistical\nmeasures and data distributions which can lead to misleading representation of\nthe underlying data and relationships. It is seen that the removal of outliers\nfrom the training dataset before modeling can give better predictions. With the\nadvancement of machine learning, the outlier detection models are also\nadvancing at a good pace. The goal of this work is to highlight and compare\nsome of the existing outlier detection techniques for the data scientists to\nuse that information for outlier algorithm selection while building a machine\nlearning model.",
          "link": "http://arxiv.org/abs/2106.08779",
          "publishedOn": "2021-06-17T01:58:43.074Z",
          "wordCount": 555,
          "title": "Comparison of Outlier Detection Techniques for Structured Data. (arXiv:2106.08779v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08852",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaoli Li</a>",
          "description": "Dependent Dirichlet processes (DDP) have been widely applied to model data\nfrom distributions over collections of measures which are correlated in some\nway. On the other hand, in recent years, increasing research efforts in machine\nlearning and data mining have been dedicated to dealing with data involving\ninteractions from two or more factors. However, few researchers have addressed\nthe heterogeneous relationship in data brought by modulation of multiple\nfactors using techniques of DDP. In this paper, we propose a novel technique,\nMultiLinear Dirichlet Processes (MLDP), to constructing DDPs by combining DP\nwith a state-of-the-art factor analysis technique, multilinear factor analyzers\n(MLFA). We have evaluated MLDP on real-word data sets for different\napplications and have achieved state-of-the-art performance.",
          "link": "http://arxiv.org/abs/2106.08852",
          "publishedOn": "2021-06-17T01:58:43.069Z",
          "wordCount": 525,
          "title": "Multilinear Dirichlet Processes. (arXiv:2106.08852v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08957",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meyer_A/0/1/0/all/0/1\">Angela Meyer</a>",
          "description": "Wind power is seeing a strong growth around the world. At the same time,\nshrinking profit margins in the energy markets let wind farm managers explore\noptions for cost reductions in the turbine operation and maintenance.\nSensor-based condition monitoring facilitates remote diagnostics of turbine\nsubsystems, enabling faster responses when unforeseen maintenance is required.\nCondition monitoring with data from the turbines' supervisory control and data\nacquisition (SCADA) systems was proposed and SCADA-based fault detection and\ndiagnosis approaches introduced based on single-task normal operation models of\nturbine state variables. As the number of SCADA channels has grown strongly,\nthousands of independent single-target models are in place today for monitoring\na single turbine. Multi-target learning was recently proposed to limit the\nnumber of models. This study applied multi-target neural networks to the task\nof early fault detection in drive-train components. The accuracy and delay of\ndetecting gear bearing faults were compared to state-of-the-art single-target\napproaches. We found that multi-target multi-layer perceptrons (MLPs) detected\nfaults at least as early and in many cases earlier than single-target MLPs. The\nmulti-target MLPs could detect faults up to several days earlier than the\nsingle-target models. This can deliver a significant advantage in the planning\nand performance of maintenance work. At the same time, the multi-target MLPs\nachieved the same level of prediction stability.",
          "link": "http://arxiv.org/abs/2106.08957",
          "publishedOn": "2021-06-17T01:58:43.063Z",
          "wordCount": 637,
          "title": "Early fault detection with multi-target neural networks. (arXiv:2106.08957v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08990",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Matthews_S/0/1/0/all/0/1\">Spencer Matthews</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hartman_B/0/1/0/all/0/1\">Brian Hartman</a>",
          "description": "Two-part models are important to and used throughout insurance and actuarial\nscience. Since insurance is required for registering a car, obtaining a\nmortgage, and participating in certain businesses, it is especially important\nthat the models which price insurance policies are fair and non-discriminatory.\nBlack box models can make it very difficult to know which covariates are\ninfluencing the results. SHAP values enable interpretation of various black box\nmodels, but little progress has been made in two-part models. In this paper, we\npropose mSHAP (or multiplicative SHAP), a method for computing SHAP values of\ntwo-part models using the SHAP values of the individual models. This method\nwill allow for the predictions of two-part models to be explained at an\nindividual observation level. After developing mSHAP, we perform an in-depth\nsimulation study. Although the kernelSHAP algorithm is also capable of\ncomputing approximate SHAP values for a two-part model, a comparison with our\nmethod demonstrates that mSHAP is exponentially faster. Ultimately, we apply\nmSHAP to a two-part ratemaking model for personal auto property damage\ninsurance coverage. Additionally, an R package (mshap) is available to easily\nimplement the method in a wide variety of applications.",
          "link": "http://arxiv.org/abs/2106.08990",
          "publishedOn": "2021-06-17T01:58:43.043Z",
          "wordCount": 610,
          "title": "mSHAP: SHAP Values for Two-Part Models. (arXiv:2106.08990v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.09011",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cascante_Bonilla_P/0/1/0/all/0/1\">Paola Cascante-Bonilla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sekhon_A/0/1/0/all/0/1\">Arshdeep Sekhon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_Y/0/1/0/all/0/1\">Yanjun Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ordonez_V/0/1/0/all/0/1\">Vicente Ordonez</a>",
          "description": "Convolutional neural networks for visual recognition require large amounts of\ntraining samples and usually benefit from data augmentation. This paper\nproposes PatchMix, a data augmentation method that creates new samples by\ncomposing patches from pairs of images in a grid-like pattern. These new\nsamples' ground truth labels are set as proportional to the number of patches\nfrom each image. We then add a set of additional losses at the patch-level to\nregularize and to encourage good representations at both the patch and image\nlevels. A ResNet-50 model trained on ImageNet using PatchMix exhibits superior\ntransfer learning capabilities across a wide array of benchmarks. Although\nPatchMix can rely on random pairings and random grid-like patterns for mixing,\nwe explore evolutionary search as a guiding strategy to discover optimal\ngrid-like patterns and image pairing jointly. For this purpose, we conceive a\nfitness function that bypasses the need to re-train a model to evaluate each\nchoice. In this way, PatchMix outperforms a base model on CIFAR-10 (+1.91),\nCIFAR-100 (+5.31), Tiny Imagenet (+3.52), and ImageNet (+1.16) by significant\nmargins, also outperforming previous state-of-the-art pairwise augmentation\nstrategies.",
          "link": "http://arxiv.org/abs/2106.09011",
          "publishedOn": "2021-06-17T01:58:43.037Z",
          "wordCount": 619,
          "title": "Evolving Image Compositions for Feature Representation Learning. (arXiv:2106.09011v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2104.02410",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ferrari_A/0/1/0/all/0/1\">Alessio Ferrari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huichapa_T/0/1/0/all/0/1\">Thaide Huichapa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spoletini_P/0/1/0/all/0/1\">Paola Spoletini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Novielli_N/0/1/0/all/0/1\">Nicole Novielli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fucci_D/0/1/0/all/0/1\">Davide Fucci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Girardi_D/0/1/0/all/0/1\">Daniela Girardi</a>",
          "description": "Capturing users engagement is crucial for gathering feedback about the\nfeatures of a software product. In a market-driven context, current approaches\nto collect and analyze users feedback are based on techniques leveraging\ninformation extracted from product reviews and social media. These approaches\nare hardly applicable in bespoke software development, or in contexts in which\none needs to gather information from specific users. In such cases, companies\nneed to resort to face-to-face interviews to get feedback on their products. In\nthis paper, we propose to utilize biometric data, in terms of physiological and\nvoice features, to complement interviews with information about the engagement\nof the user on the discussed product-relevant topics. We evaluate our approach\nby interviewing users while gathering their physiological data (i.e.,\nbiofeedback) using an Empatica E4 wristband, and capturing their voice through\nthe default audio-recorder of a common laptop. Our results show that we can\npredict users' engagement by training supervised machine learning algorithms on\nbiometric data, and that voice features alone can be sufficiently effective.\nThe performance of the prediction algorithms is maximised when pre-processing\nthe training data with the synthetic minority oversampling technique (SMOTE).\nThe results of our work suggest that biofeedback and voice analysis can be used\nto facilitate prioritization of requirements oriented to product improvement,\nand to steer the interview based on users' engagement. Furthermore, the usage\nof voice features can be particularly helpful for emotion-aware requirements\nelicitation in remote communication, either performed by human analysts or\nvoice-based chatbots.",
          "link": "http://arxiv.org/abs/2104.02410",
          "publishedOn": "2021-06-17T01:58:43.031Z",
          "wordCount": 765,
          "title": "Using Voice and Biofeedback to Predict User Engagement during Requirements Interviews. (arXiv:2104.02410v2 [cs.SE] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08873",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mottini_A/0/1/0/all/0/1\">Alejandro Mottini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lorenzo_Trueba_J/0/1/0/all/0/1\">Jaime Lorenzo-Trueba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karlapati_S/0/1/0/all/0/1\">Sri Vishnu Kumar Karlapati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drugman_T/0/1/0/all/0/1\">Thomas Drugman</a>",
          "description": "Voice Conversion (VC) is a technique that aims to transform the\nnon-linguistic information of a source utterance to change the perceived\nidentity of the speaker. While there is a rich literature on VC, most proposed\nmethods are trained and evaluated on clean speech recordings. However, many\nacoustic environments are noisy and reverberant, severely restricting the\napplicability of popular VC methods to such scenarios. To address this\nlimitation, we propose Voicy, a new VC framework particularly tailored for\nnoisy speech. Our method, which is inspired by the de-noising auto-encoders\nframework, is comprised of four encoders (speaker, content, phonetic and\nacoustic-ASR) and one decoder. Importantly, Voicy is capable of performing\nnon-parallel zero-shot VC, an important requirement for any VC system that\nneeds to work on speakers not seen during training. We have validated our\napproach using a noisy reverberant version of the LibriSpeech dataset.\nExperimental results show that Voicy outperforms other tested VC techniques in\nterms of naturalness and target speaker similarity in noisy reverberant\nenvironments.",
          "link": "http://arxiv.org/abs/2106.08873",
          "publishedOn": "2021-06-17T01:58:43.023Z",
          "wordCount": 610,
          "title": "Voicy: Zero-Shot Non-Parallel Voice Conversion in Noisy Reverberant Environments. (arXiv:2106.08873v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08801",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qi_Z/0/1/0/all/0/1\">Zhiyuan Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Ziheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiaoyan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yefeng Zheng</a>",
          "description": "Knowledge Graph (KG) alignment aims at finding equivalent entities and\nrelations (i.e., mappings) between two KGs. The existing approaches utilize\neither reasoning-based or semantic embedding-based techniques, but few studies\nexplore their combination. In this demonstration, we present PRASEMap, an\nunsupervised KG alignment system that iteratively computes the Mappings with\nboth Probabilistic Reasoning (PR) And Semantic Embedding (SE) techniques.\nPRASEMap can support various embedding-based KG alignment approaches as the SE\nmodule, and enables easy human computer interaction that additionally provides\nan option for users to feed the mapping annotations back to the system for\nbetter results. The demonstration showcases these features via a stand-alone\nWeb application with user friendly interfaces.",
          "link": "http://arxiv.org/abs/2106.08801",
          "publishedOn": "2021-06-17T01:58:43.005Z",
          "wordCount": 552,
          "title": "PRASEMap: A Probabilistic Reasoning and Semantic Embedding based Knowledge Graph Alignment System. (arXiv:2106.08801v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08423",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sharma_K/0/1/0/all/0/1\">Karishma Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yizhou Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yan Liu</a>",
          "description": "Vaccine hesitancy and misinformation on social media has increased concerns\nabout COVID-19 vaccine uptake required to achieve herd immunity and overcome\nthe pandemic. However anti-science and political misinformation and\nconspiracies have been rampant throughout the pandemic. For COVID-19 vaccines,\nwe investigate misinformation and conspiracy campaigns and their characteristic\nbehaviours. We identify whether coordinated efforts are used to promote\nmisinformation in vaccine related discussions, and find accounts coordinately\npromoting a `Great Reset' conspiracy group promoting vaccine related\nmisinformation and strong anti-vaccine and anti-social messages such as boycott\nvaccine passports, no lock-downs and masks. We characterize other\nmisinformation communities from the information diffusion structure, and study\nthe large anti-vaccine misinformation community and smaller anti-vaccine\ncommunities, including a far-right anti-vaccine conspiracy group. In comparison\nwith the mainstream and health news, left-leaning group, which are more\npro-vaccine, the right-leaning group is influenced more by the anti-vaccine and\nfar-right misinformation/conspiracy communities. The misinformation communities\nare more vocal either specific to the vaccine discussion or political\ndiscussion, and we find other differences in the characteristic behaviours of\ndifferent communities. Lastly, we investigate misinformation narratives and\ntactics of information distortion that can increase vaccine hesitancy, using\ntopic modeling and comparison with reported vaccine side-effects (VAERS)\nfinding rarer side-effects are more frequently discussed on social media.",
          "link": "http://arxiv.org/abs/2106.08423",
          "publishedOn": "2021-06-17T01:58:42.999Z",
          "wordCount": 693,
          "title": "COVID-19 Vaccines: Characterizing Misinformation Campaigns and Vaccine Hesitancy on Twitter. (arXiv:2106.08423v1 [cs.SI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08769",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1\">Mohammad Emtiyaz Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swaroop_S/0/1/0/all/0/1\">Siddharth Swaroop</a>",
          "description": "Humans and animals have a natural ability to quickly adapt to their\nsurroundings, but machine-learning models, when subjected to changes, often\nrequire a complete retraining from scratch. We present Knowledge-adaptation\npriors (K-priors) to reduce the cost of retraining by enabling quick and\naccurate adaptation for a wide-variety of tasks and models. This is made\npossible by a combination of weight and function-space priors to reconstruct\nthe gradients of the past, which recovers and generalizes many existing, but\nseemingly-unrelated, adaptation strategies. Training with simple first-order\ngradient methods can often recover the exact retrained model to an arbitrary\naccuracy by choosing a sufficiently large memory of the past data. Empirical\nresults confirm that the adaptation can be cheap and accurate, and a promising\nalternative to retraining.",
          "link": "http://arxiv.org/abs/2106.08769",
          "publishedOn": "2021-06-17T01:58:42.993Z",
          "wordCount": 542,
          "title": "Knowledge-Adaptation Priors. (arXiv:2106.08769v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08597",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chen_W/0/1/0/all/0/1\">Wei-Ning Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kairouz_P/0/1/0/all/0/1\">Peter Kairouz</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ozgur_A/0/1/0/all/0/1\">Ayfer &#xd6;zg&#xfc;r</a>",
          "description": "We consider the problem of estimating a $d$-dimensional $s$-sparse discrete\ndistribution from its samples observed under a $b$-bit communication\nconstraint. The best-known previous result on $\\ell_2$ estimation error for\nthis problem is $O\\left( \\frac{s\\log\\left( {d}/{s}\\right)}{n2^b}\\right)$.\nSurprisingly, we show that when sample size $n$ exceeds a minimum threshold\n$n^*(s, d, b)$, we can achieve an $\\ell_2$ estimation error of $O\\left(\n\\frac{s}{n2^b}\\right)$. This implies that when $n>n^*(s, d, b)$ the convergence\nrate does not depend on the ambient dimension $d$ and is the same as knowing\nthe support of the distribution beforehand.\n\nWe next ask the question: ``what is the minimum $n^*(s, d, b)$ that allows\ndimension-free convergence?''. To upper bound $n^*(s, d, b)$, we develop novel\nlocalization schemes to accurately and efficiently localize the unknown\nsupport. For the non-interactive setting, we show that $n^*(s, d, b) = O\\left(\n\\min \\left( {d^2\\log^2 d}/{2^b}, {s^4\\log^2 d}/{2^b}\\right) \\right)$. Moreover,\nwe connect the problem with non-adaptive group testing and obtain a\npolynomial-time estimation scheme when $n = \\tilde{\\Omega}\\left({s^4\\log^4\nd}/{2^b}\\right)$. This group testing based scheme is adaptive to the sparsity\nparameter $s$, and hence can be applied without knowing it. For the interactive\nsetting, we propose a novel tree-based estimation scheme and show that the\nminimum sample-size needed to achieve dimension-free convergence can be further\nreduced to $n^*(s, d, b) = \\tilde{O}\\left( {s^2\\log^2 d}/{2^b} \\right)$.",
          "link": "http://arxiv.org/abs/2106.08597",
          "publishedOn": "2021-06-17T01:58:42.986Z",
          "wordCount": 651,
          "title": "Breaking The Dimension Dependence in Sparse Distribution Estimation under Communication Constraints. (arXiv:2106.08597v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08365",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ji_X/0/1/0/all/0/1\">Xu Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pascanu_R/0/1/0/all/0/1\">Razvan Pascanu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hjelm_D/0/1/0/all/0/1\">Devon Hjelm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vedaldi_A/0/1/0/all/0/1\">Andrea Vedaldi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lakshminarayanan_B/0/1/0/all/0/1\">Balaji Lakshminarayanan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1\">Yoshua Bengio</a>",
          "description": "Piecewise linear neural networks can be split into subfunctions, each with\nits own activation pattern, domain, and empirical error. Empirical error for\nthe full network can be written as an expectation over empirical error of\nsubfunctions. Constructing a generalization bound on subfunction empirical\nerror indicates that the more densely a subfunction is surrounded by training\nsamples in representation space, the more reliable its predictions are.\nFurther, it suggests that models with fewer activation regions generalize\nbetter, and models that abstract knowledge to a greater degree generalize\nbetter, all else equal. We propose not only a theoretical framework to reason\nabout subfunction error bounds but also a pragmatic way of approximately\nevaluating it, which we apply to predicting which samples the network will not\nsuccessfully generalize to. We test our method on detection of\nmisclassification and out-of-distribution samples, finding that it performs\ncompetitively in both cases. In short, some network activation patterns are\nassociated with higher reliability than others, and these can be identified\nusing subfunction error bounds.",
          "link": "http://arxiv.org/abs/2106.08365",
          "publishedOn": "2021-06-17T01:58:42.980Z",
          "wordCount": 604,
          "title": "Predicting Unreliable Predictions by Shattering a Neural Network. (arXiv:2106.08365v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08921",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Patel_K/0/1/0/all/0/1\">Kinjal Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hunsberger_E/0/1/0/all/0/1\">Eric Hunsberger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Batir_S/0/1/0/all/0/1\">Sean Batir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eliasmith_C/0/1/0/all/0/1\">Chris Eliasmith</a>",
          "description": "We seek to investigate the scalability of neuromorphic computing for computer\nvision, with the objective of replicating non-neuromorphic performance on\ncomputer vision tasks while reducing power consumption. We convert the deep\nArtificial Neural Network (ANN) architecture U-Net to a Spiking Neural Network\n(SNN) architecture using the Nengo framework. Both rate-based and spike-based\nmodels are trained and optimized for benchmarking performance and power, using\na modified version of the ISBI 2D EM Segmentation dataset consisting of\nmicroscope images of cells. We propose a partitioning method to optimize\ninter-chip communication to improve speed and energy efficiency when deploying\nmulti-chip networks on the Loihi neuromorphic chip. We explore the advantages\nof regularizing firing rates of Loihi neurons for converting ANN to SNN with\nminimum accuracy loss and optimized energy consumption. We propose a percentile\nbased regularization loss function to limit the spiking rate of the neuron\nbetween a desired range. The SNN is converted directly from the corresponding\nANN, and demonstrates similar semantic segmentation as the ANN using the same\nnumber of neurons and weights. However, the neuromorphic implementation on the\nIntel Loihi neuromorphic chip is over 2x more energy-efficient than\nconventional hardware (CPU, GPU) when running online (one image at a time).\nThese power improvements are achieved without sacrificing the task performance\naccuracy of the network, and when all weights (Loihi, CPU, and GPU networks)\nare quantized to 8 bits.",
          "link": "http://arxiv.org/abs/2106.08921",
          "publishedOn": "2021-06-17T01:58:42.973Z",
          "wordCount": 660,
          "title": "A Spiking Neural Network for Image Segmentation. (arXiv:2106.08921v1 [cs.NE])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08489",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Subramanian_M/0/1/0/all/0/1\">Megha Subramanian</a>, <a href=\"http://arxiv.org/find/math/1/au:+Tipireddy_R/0/1/0/all/0/1\">Ramakrishna Tipireddy</a>, <a href=\"http://arxiv.org/find/math/1/au:+Chatterjee_S/0/1/0/all/0/1\">Samrat Chatterjee</a>",
          "description": "Nonlinear dynamical systems such as Lorenz63 equations are known to be\nchaotic in nature and sensitive to initial conditions. As a result, a small\nperturbation in the initial conditions results in deviation in state trajectory\nafter a few time steps. The algorithms and computational resources needed to\naccurately identify the system states vary depending on whether the solution is\nin transition region or not. We refer to the transition and non-transition\nregions as unstable and stable regions respectively. We label a system state to\nbe stable if it's immediate past and future states reside in the same regime.\nHowever, at a given time step we don't have the prior knowledge about whether\nsystem is in stable or unstable region. In this paper, we develop and train a\nfeed forward (multi-layer perceptron) Neural Network to classify the system\nstates of a Lorenz system as stable and unstable. We pose this task as a\nsupervised learning problem where we train the neural network on Lorenz system\nwhich have states labeled as stable or unstable. We then test the ability of\nthe neural network models to identify the stable and unstable states on a\ndifferent Lorenz system that is generated using different initial conditions.\nWe also evaluate the classification performance in the mismatched case i.e.,\nwhen the initial conditions for training and validation data are sampled from\ndifferent intervals. We show that certain normalization schemes can greatly\nimprove the performance of neural networks in especially these mismatched\nscenarios. The classification framework developed in the paper can be a\npreprocessor for a larger context of sequential decision making framework where\nthe decision making is performed based on observed stable or unstable states.",
          "link": "http://arxiv.org/abs/2106.08489",
          "publishedOn": "2021-06-17T01:58:42.956Z",
          "wordCount": 707,
          "title": "Lorenz System State Stability Identification using Neural Networks. (arXiv:2106.08489v1 [math.DS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08441",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghari_P/0/1/0/all/0/1\">Pouya M Ghari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yanning Shen</a>",
          "description": "Online learning with expert advice is widely used in various machine learning\ntasks. It considers the problem where a learner chooses one from a set of\nexperts to take advice and make a decision. In many learning problems, experts\nmay be related, henceforth the learner can observe the losses associated with a\nsubset of experts that are related to the chosen one. In this context, the\nrelationship among experts can be captured by a feedback graph, which can be\nused to assist the learner's decision making. However, in practice, the nominal\nfeedback graph often entails uncertainties, which renders it impossible to\nreveal the actual relationship among experts. To cope with this challenge, the\npresent work studies various cases of potential uncertainties, and develops\nnovel online learning algorithms to deal with uncertainties while making use of\nthe uncertain feedback graph. The proposed algorithms are proved to enjoy\nsublinear regret under mild conditions. Experiments on real datasets are\npresented to demonstrate the effectiveness of the novel algorithms.",
          "link": "http://arxiv.org/abs/2106.08441",
          "publishedOn": "2021-06-17T01:58:42.942Z",
          "wordCount": 587,
          "title": "Online Learning with Uncertain Feedback Graphs. (arXiv:2106.08441v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08361",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fursov_I/0/1/0/all/0/1\">Ivan Fursov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morozov_M/0/1/0/all/0/1\">Matvey Morozov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaploukhaya_N/0/1/0/all/0/1\">Nina Kaploukhaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kovtun_E/0/1/0/all/0/1\">Elizaveta Kovtun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rivera_Castro_R/0/1/0/all/0/1\">Rodrigo Rivera-Castro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gusev_G/0/1/0/all/0/1\">Gleb Gusev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Babaev_D/0/1/0/all/0/1\">Dmitry Babaev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kireev_I/0/1/0/all/0/1\">Ivan Kireev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaytsev_A/0/1/0/all/0/1\">Alexey Zaytsev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burnaev_E/0/1/0/all/0/1\">Evgeny Burnaev</a>",
          "description": "Machine learning models using transaction records as inputs are popular among\nfinancial institutions. The most efficient models use deep-learning\narchitectures similar to those in the NLP community, posing a challenge due to\ntheir tremendous number of parameters and limited robustness. In particular,\ndeep-learning models are vulnerable to adversarial attacks: a little change in\nthe input harms the model's output.\n\nIn this work, we examine adversarial attacks on transaction records data and\ndefences from these attacks. The transaction records data have a different\nstructure than the canonical NLP or time series data, as neighbouring records\nare less connected than words in sentences, and each record consists of both\ndiscrete merchant code and continuous transaction amount. We consider a\nblack-box attack scenario, where the attack doesn't know the true decision\nmodel, and pay special attention to adding transaction tokens to the end of a\nsequence. These limitations provide more realistic scenario, previously\nunexplored in NLP world.\n\nThe proposed adversarial attacks and the respective defences demonstrate\nremarkable performance using relevant datasets from the financial industry. Our\nresults show that a couple of generated transactions are sufficient to fool a\ndeep-learning model. Further, we improve model robustness via adversarial\ntraining or separate adversarial examples detection. This work shows that\nembedding protection from adversarial attacks improves model robustness,\nallowing a wider adoption of deep models for transaction records in banking and\nfinance.",
          "link": "http://arxiv.org/abs/2106.08361",
          "publishedOn": "2021-06-17T01:58:42.936Z",
          "wordCount": 669,
          "title": "Adversarial Attacks on Deep Models for Financial Transaction Records. (arXiv:2106.08361v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08671",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Saeed_W/0/1/0/all/0/1\">Waddah Saeed</a>",
          "description": "Short Message Service (SMS) is a very popular service used for communication\nby mobile users. However, this popular service can be abused by executing\nillegal activities and influencing security risks. Nowadays, many automatic\nmachine learning (AutoML) tools exist which can help domain experts and lay\nusers to build high-quality ML models with little or no machine learning\nknowledge. In this work, a classification performance comparison was conducted\nbetween three automatic ML tools for SMS spam message filtering. These tools\nare mljar-supervised AutoML, H2O AutoML, and Tree-based Pipeline Optimization\nTool (TPOT) AutoML. Experimental results showed that ensemble models achieved\nthe best classification performance. The Stacked Ensemble model, which was\nbuilt using H2O AutoML, achieved the best performance in terms of Log Loss\n(0.8370), true positive (1088/1116), and true negative (281/287) metrics. There\nis a 19.05\\% improvement in Log Loss with respect to TPOT AutoML and 10.53\\%\nimprovement with respect to mljar-supervised AutoML. The satisfactory filtering\nperformance achieved with AutoML tools provides a potential application for\nAutoML tools to automatically determine the best ML model that can perform best\nfor SMS spam message filtering.",
          "link": "http://arxiv.org/abs/2106.08671",
          "publishedOn": "2021-06-17T01:58:42.886Z",
          "wordCount": 610,
          "title": "Comparison of Automated Machine Learning Tools for SMS Spam Message Filtering. (arXiv:2106.08671v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08492",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Velmurugan_M/0/1/0/all/0/1\">Mythreyi Velmurugan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_C/0/1/0/all/0/1\">Chun Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moreira_C/0/1/0/all/0/1\">Catarina Moreira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sindhgatta_R/0/1/0/all/0/1\">Renuka Sindhgatta</a>",
          "description": "Although modern machine learning and deep learning methods allow for complex\nand in-depth data analytics, the predictive models generated by these methods\nare often highly complex, and lack transparency. Explainable AI (XAI) methods\nare used to improve the interpretability of these complex models, and in doing\nso improve transparency. However, the inherent fitness of these explainable\nmethods can be hard to evaluate. In particular, methods to evaluate the\nfidelity of the explanation to the underlying black box require further\ndevelopment, especially for tabular data. In this paper, we (a) propose a three\nphase approach to developing an evaluation method; (b) adapt an existing\nevaluation method primarily for image and text data to evaluate models trained\non tabular data; and (c) evaluate two popular explainable methods using this\nevaluation method. Our evaluations suggest that the internal mechanism of the\nunderlying predictive model, the internal mechanism of the explainable method\nused and model and data complexity all affect explanation fidelity. Given that\nexplanation fidelity is so sensitive to context and tools and data used, we\ncould not clearly identify any specific explainable method as being superior to\nanother.",
          "link": "http://arxiv.org/abs/2106.08492",
          "publishedOn": "2021-06-17T01:58:42.871Z",
          "wordCount": 616,
          "title": "Developing a Fidelity Evaluation Approach for Interpretable Machine Learning. (arXiv:2106.08492v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08814",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Raymaekers_J/0/1/0/all/0/1\">Jakob Raymaekers</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rousseeuw_P/0/1/0/all/0/1\">Peter J. Rousseeuw</a>",
          "description": "Classification by neural nets and by tree-based methods are powerful tools of\nmachine learning. There exist interesting visualizations of the inner workings\nof these and other classifiers. Here we pursue a different goal, which is to\nvisualize the cases being classified, either in training data or in test data.\nAn important aspect is whether a case has been classified to its given class\n(label) or whether the classifier wants to assign it to different class. This\nis reflected in the (conditional and posterior) probability of the alternative\nclass (PAC). A high PAC indicates label bias, i.e. the possibility that the\ncase was mislabeled. The PAC is used to construct a silhouette plot which is\nsimilar in spirit to the silhouette plot for cluster analysis (Rousseeuw,\n1987). The average silhouette width can be used to compare different\nclassifications of the same dataset. We will also draw quasi residual plots of\nthe PAC versus a data feature, which may lead to more insight in the data. One\nof these data features is how far each case lies from its given class. The\ngraphical displays are illustrated and interpreted on benchmark data sets\ncontaining images, mixed features, and tweets.",
          "link": "http://arxiv.org/abs/2106.08814",
          "publishedOn": "2021-06-17T01:58:42.820Z",
          "wordCount": 627,
          "title": "Silhouettes and quasi residual plots for neural nets and tree-based classifiers. (arXiv:2106.08814v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08453",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Boopathy_A/0/1/0/all/0/1\">Akhilan Boopathy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fiete_I/0/1/0/all/0/1\">Ila Fiete</a>",
          "description": "Recent works have examined how deep neural networks, which can solve a\nvariety of difficult problems, incorporate the statistics of training data to\nachieve their success. However, existing results have been established only in\nlimited settings. In this work, we derive the layerwise weight dynamics of\ninfinite-width neural networks with nonlinear activations trained by gradient\ndescent. We show theoretically that weight updates are aligned with input\ncorrelations from intermediate layers weighted by error, and demonstrate\nempirically that the result also holds in finite-width wide networks. The\nalignment result allows us to formulate backpropagation-free learning rules,\nnamed Align-zero and Align-ada, that theoretically achieve the same alignment\nas backpropagation. Finally, we test these learning rules on benchmark problems\nin feedforward and recurrent neural networks and demonstrate, in wide networks,\ncomparable performance to backpropagation.",
          "link": "http://arxiv.org/abs/2106.08453",
          "publishedOn": "2021-06-17T01:58:42.765Z",
          "wordCount": 569,
          "title": "Gradient-trained Weights in Wide Neural Networks Align Layerwise to Error-scaled Input Correlations. (arXiv:2106.08453v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08188",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chanti_D/0/1/0/all/0/1\">Dawood Al Chanti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mateus_D/0/1/0/all/0/1\">Diana Mateus</a>",
          "description": "This paper addresses the domain shift problem for segmentation. As a\nsolution, we propose OLVA, a novel and lightweight unsupervised domain\nadaptation method based on a Variational Auto-Encoder (VAE) and Optimal\nTransport (OT) theory. Thanks to the VAE, our model learns a shared\ncross-domain latent space that follows a normal distribution, which reduces the\ndomain shift. To guarantee valid segmentations, our shared latent space is\ndesigned to model the shape rather than the intensity variations. We further\nrely on an OT loss to match and align the remaining discrepancy between the two\ndomains in the latent space. We demonstrate OLVA's effectiveness for the\nsegmentation of multiple cardiac structures on the public Multi-Modality Whole\nHeart Segmentation (MM-WHS) dataset, where the source domain consists of\nannotated 3D MR images and the unlabelled target domain of 3D CTs. Our results\nshow remarkable improvements with an additional margin of 12.5\\% dice score\nover concurrent generative training approaches.",
          "link": "http://arxiv.org/abs/2106.08188",
          "publishedOn": "2021-06-16T01:21:12.922Z",
          "wordCount": 600,
          "title": "Optimal Latent Vector Alignment for Unsupervised Domain Adaptation in Medical Image Segmentation. (arXiv:2106.08188v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02182",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1\">Nuo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1\">Chenyu You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1\">Yuexian Zou</a>",
          "description": "In spoken conversational question answering (SCQA), the answer to the\ncorresponding question is generated by retrieving and then analyzing a fixed\nspoken document, including multi-part conversations. Most SCQA systems have\nconsidered only retrieving information from ordered utterances. However, the\nsequential order of dialogue is important to build a robust spoken\nconversational question answering system, and the changes of utterances order\nmay severely result in low-quality and incoherent corpora. To this end, we\nintroduce a self-supervised learning approach, including incoherence\ndiscrimination, insertion detection, and question prediction, to explicitly\ncapture the coreference resolution and dialogue coherence among spoken\ndocuments. Specifically, we design a joint learning framework where the\nauxiliary self-supervised tasks can enable the pre-trained SCQA systems towards\nmore coherent and meaningful spoken dialogue learning. We also utilize the\nproposed self-supervised learning tasks to capture intra-sentence coherence.\nExperimental results demonstrate that our proposed method provides more\ncoherent, meaningful, and appropriate responses, yielding superior performance\ngains compared to the original pre-trained language models. Our method achieves\nstate-of-the-art results on the Spoken-CoQA dataset.",
          "link": "http://arxiv.org/abs/2106.02182",
          "publishedOn": "2021-06-16T01:21:12.915Z",
          "wordCount": 630,
          "title": "Self-supervised Dialogue Learning for Spoken Conversational Question Answering. (arXiv:2106.02182v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08011",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yandong Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yong Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yuanming Shi</a>",
          "description": "In this paper, we consider decentralized federated learning (FL) over\nwireless networks, where over-the-air computation (AirComp) is adopted to\nfacilitate the local model consensus in a device-to-device (D2D) communication\nmanner. However, the AirComp-based consensus phase brings the additive noise in\neach algorithm iterate and the consensus needs to be robust to wireless network\ntopology changes, which introduce a coupled and novel challenge of establishing\nthe convergence for wireless decentralized FL algorithm. To facilitate\nconsensus phase, we propose an AirComp-based DSGD with gradient tracking and\nvariance reduction (DSGT-VR) algorithm, where both precoding and decoding\nstrategies are developed for D2D communication. Furthermore, we prove that the\nproposed algorithm converges linearly and establish the optimality gap for\nstrongly convex and smooth loss functions, taking into account the channel\nfading and noise. The theoretical result shows that the additional error bound\nin the optimality gap depends on the number of devices. Extensive simulations\nverify the theoretical results and show that the proposed algorithm outperforms\nother benchmark decentralized FL algorithms over wireless networks.",
          "link": "http://arxiv.org/abs/2106.08011",
          "publishedOn": "2021-06-16T01:21:12.908Z",
          "wordCount": 597,
          "title": "Over-the-Air Decentralized Federated Learning. (arXiv:2106.08011v1 [cs.IT])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07049",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1\">Kangning Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yiqiu Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_N/0/1/0/all/0/1\">Nan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chledowski_J/0/1/0/all/0/1\">Jakub Ch&#x142;&#x119;dowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fernandez_Granda_C/0/1/0/all/0/1\">Carlos Fernandez-Granda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geras_K/0/1/0/all/0/1\">Krzysztof J. Geras</a>",
          "description": "In the last few years, deep learning classifiers have shown promising results\nin image-based medical diagnosis. However, interpreting the outputs of these\nmodels remains a challenge. In cancer diagnosis, interpretability can be\nachieved by localizing the region of the input image responsible for the\noutput, i.e. the location of a lesion. Alternatively, segmentation or detection\nmodels can be trained with pixel-wise annotations indicating the locations of\nmalignant lesions. Unfortunately, acquiring such labels is labor-intensive and\nrequires medical expertise. To overcome this difficulty, weakly-supervised\nlocalization can be utilized. These methods allow neural network classifiers to\noutput saliency maps highlighting the regions of the input most relevant to the\nclassification task (e.g. malignant lesions in mammograms) using only\nimage-level labels (e.g. whether the patient has cancer or not) during\ntraining. When applied to high-resolution images, existing methods produce\nlow-resolution saliency maps. This is problematic in applications in which\nsuspicious lesions are small in relation to the image size. In this work, we\nintroduce a novel neural network architecture to perform weakly-supervised\nsegmentation of high-resolution images. The proposed model selects regions of\ninterest via coarse-level localization, and then performs fine-grained\nsegmentation of those regions. We apply this model to breast cancer diagnosis\nwith screening mammography, and validate it on a large clinically-realistic\ndataset. Measured by Dice similarity score, our approach outperforms existing\nmethods by a large margin in terms of localization performance of benign and\nmalignant lesions, relatively improving the performance by 39.6% and 20.0%,\nrespectively. Code and the weights of some of the models are available at\nhttps://github.com/nyukat/GLAM",
          "link": "http://arxiv.org/abs/2106.07049",
          "publishedOn": "2021-06-16T01:21:12.902Z",
          "wordCount": 734,
          "title": "Weakly-supervised High-resolution Segmentation of Mammography Images for Breast Cancer Diagnosis. (arXiv:2106.07049v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08050",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alakuijala_M/0/1/0/all/0/1\">Minttu Alakuijala</a> (WILLOW, Thoth), <a href=\"http://arxiv.org/find/cs/1/au:+Dulac_Arnold_G/0/1/0/all/0/1\">Gabriel Dulac-Arnold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mairal_J/0/1/0/all/0/1\">Julien Mairal</a> (Thoth), <a href=\"http://arxiv.org/find/cs/1/au:+Ponce_J/0/1/0/all/0/1\">Jean Ponce</a> (WILLOW), <a href=\"http://arxiv.org/find/cs/1/au:+Schmid_C/0/1/0/all/0/1\">Cordelia Schmid</a>",
          "description": "Residual reinforcement learning (RL) has been proposed as a way to solve\nchallenging robotic tasks by adapting control actions from a conventional\nfeedback controller to maximize a reward signal. We extend the residual\nformulation to learn from visual inputs and sparse rewards using\ndemonstrations. Learning from images, proprioceptive inputs and a sparse\ntask-completion reward relaxes the requirement of accessing full state\nfeatures, such as object and target positions. In addition, replacing the base\ncontroller with a policy learned from demonstrations removes the dependency on\na hand-engineered controller in favour of a dataset of demonstrations, which\ncan be provided by non-experts. Our experimental evaluation on simulated\nmanipulation tasks on a 6-DoF UR5 arm and a 28-DoF dexterous hand demonstrates\nthat residual RL from demonstrations is able to generalize to unseen\nenvironment conditions more flexibly than either behavioral cloning or RL\nfine-tuning, and is capable of solving high-dimensional, sparse-reward tasks\nout of reach for RL from scratch.",
          "link": "http://arxiv.org/abs/2106.08050",
          "publishedOn": "2021-06-16T01:21:12.895Z",
          "wordCount": 582,
          "title": "Residual Reinforcement Learning from Demonstrations. (arXiv:2106.08050v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07955",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rizzo_M/0/1/0/all/0/1\">Matteo Rizzo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Conati_C/0/1/0/all/0/1\">Cristina Conati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jang_D/0/1/0/all/0/1\">Daesik Jang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Hui Hu</a>",
          "description": "Computational Colour Constancy (CCC) consists of estimating the colour of one\nor more illuminants in a scene and using them to remove unwanted chromatic\ndistortions. Much research has focused on illuminant estimation for CCC on\nsingle images, with few attempts of leveraging the temporal information\nintrinsic in sequences of correlated images (e.g., the frames in a video), a\ntask known as Temporal Colour Constancy (TCC). The state-of-the-art for TCC is\nTCCNet, a deep-learning architecture that uses a ConvLSTM for aggregating the\nencodings produced by CNN submodules for each image in a sequence. We extend\nthis architecture with different models obtained by (i) substituting the TCCNet\nsubmodules with C4, the state-of-the-art method for CCC targeting images; (ii)\nadding a cascading strategy to perform an iterative improvement of the estimate\nof the illuminant. We tested our models on the recently released TCC benchmark\nand achieved results that surpass the state-of-the-art. Analyzing the impact of\nthe number of frames involved in illuminant estimation on performance, we show\nthat it is possible to reduce inference time by training the models on few\nselected frames from the sequences while retaining comparable accuracy.",
          "link": "http://arxiv.org/abs/2106.07955",
          "publishedOn": "2021-06-16T01:21:12.878Z",
          "wordCount": 614,
          "title": "Cascading Convolutional Temporal Colour Constancy. (arXiv:2106.07955v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03594",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gianinazzi_L/0/1/0/all/0/1\">Lukas Gianinazzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fries_M/0/1/0/all/0/1\">Maximilian Fries</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dryden_N/0/1/0/all/0/1\">Nikoli Dryden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ben_Nun_T/0/1/0/all/0/1\">Tal Ben-Nun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Besta_M/0/1/0/all/0/1\">Maciej Besta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoefler_T/0/1/0/all/0/1\">Torsten Hoefler</a>",
          "description": "We present a graph neural network to learn graph coloring heuristics using\nreinforcement learning. Our learned deterministic heuristics give better\nsolutions than classical degree-based greedy heuristics and only take seconds\nto evaluate on graphs with tens of thousands of vertices. As our approach is\nbased on policy-gradients, it also learns a probabilistic policy as well. These\nprobabilistic policies outperform all greedy coloring baselines and a machine\nlearning baseline. Our approach generalizes several previous machine-learning\nframeworks, which applied to problems like minimum vertex cover. We also\ndemonstrate that our approach outperforms two greedy heuristics on minimum\nvertex cover.",
          "link": "http://arxiv.org/abs/2106.03594",
          "publishedOn": "2021-06-16T01:21:12.871Z",
          "wordCount": 540,
          "title": "Learning Combinatorial Node Labeling Algorithms. (arXiv:2106.03594v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.14937",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1\">Xiaoliang Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_J/0/1/0/all/0/1\">Jianzhong Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_C/0/1/0/all/0/1\">Chenglu Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Cheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_R/0/1/0/all/0/1\">Rongshan Yu</a>",
          "description": "Fairness has emerged as a critical problem in federated learning (FL). In\nthis work, we identify a cause of unfairness in FL -- conflicting gradients\nwith large differences in the magnitudes. To address this issue, we propose the\nfederated fair averaging (FedFV) algorithm to mitigate potential conflicts\namong clients before averaging their gradients. We first use the cosine\nsimilarity to detect gradient conflicts, and then iteratively eliminate such\nconflicts by modifying both the direction and the magnitude of the gradients.\nWe further show the theoretical foundation of FedFV to mitigate the issue\nconflicting gradients and converge to Pareto stationary solutions. Extensive\nexperiments on a suite of federated datasets confirm that FedFV compares\nfavorably against state-of-the-art methods in terms of fairness, accuracy and\nefficiency.",
          "link": "http://arxiv.org/abs/2104.14937",
          "publishedOn": "2021-06-16T01:21:12.865Z",
          "wordCount": 595,
          "title": "Federated Learning with Fair Averaging. (arXiv:2104.14937v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08060",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jourdan_T/0/1/0/all/0/1\">Th&#xe9;o Jourdan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boutet_A/0/1/0/all/0/1\">Antoine Boutet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frindel_C/0/1/0/all/0/1\">Carole Frindel</a>",
          "description": "Federated Learning (FL) is a collaborative scheme to train a learning model\nacross multiple participants without sharing data. While FL is a clear step\nforward towards enforcing users' privacy, different inference attacks have been\ndeveloped. In this paper, we quantify the utility and privacy trade-off of a FL\nscheme using private personalized layers. While this scheme has been proposed\nas local adaptation to improve the accuracy of the model through local\npersonalization, it has also the advantage to minimize the information about\nthe model exchanged with the server. However, the privacy of such a scheme has\nnever been quantified. Our evaluations using motion sensor dataset show that\npersonalized layers speed up the convergence of the model and slightly improve\nthe accuracy for all users compared to a standard FL scheme while better\npreventing both attribute and membership inferences compared to a FL scheme\nusing local differential privacy.",
          "link": "http://arxiv.org/abs/2106.08060",
          "publishedOn": "2021-06-16T01:21:12.859Z",
          "wordCount": 581,
          "title": "Privacy Assessment of Federated Learning using Private Personalized Layers. (arXiv:2106.08060v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.04554",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_T/0/1/0/all/0/1\">Tianyang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuxin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiangyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1\">Xipeng Qiu</a>",
          "description": "Transformers have achieved great success in many artificial intelligence\nfields, such as natural language processing, computer vision, and audio\nprocessing. Therefore, it is natural to attract lots of interest from academic\nand industry researchers. Up to the present, a great variety of Transformer\nvariants (a.k.a. X-formers) have been proposed, however, a systematic and\ncomprehensive literature review on these Transformer variants is still missing.\nIn this survey, we provide a comprehensive review of various X-formers. We\nfirst briefly introduce the vanilla Transformer and then propose a new taxonomy\nof X-formers. Next, we introduce the various X-formers from three perspectives:\narchitectural modification, pre-training, and applications. Finally, we outline\nsome potential directions for future research.",
          "link": "http://arxiv.org/abs/2106.04554",
          "publishedOn": "2021-06-16T01:21:12.833Z",
          "wordCount": 554,
          "title": "A Survey of Transformers. (arXiv:2106.04554v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.10306",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Pfohl_S/0/1/0/all/0/1\">Stephen R. Pfohl</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Foryciarz_A/0/1/0/all/0/1\">Agata Foryciarz</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shah_N/0/1/0/all/0/1\">Nigam H. Shah</a>",
          "description": "The use of machine learning to guide clinical decision making has the\npotential to worsen existing health disparities. Several recent works frame the\nproblem as that of algorithmic fairness, a framework that has attracted\nconsiderable attention and criticism. However, the appropriateness of this\nframework is unclear due to both ethical as well as technical considerations,\nthe latter of which include trade-offs between measures of fairness and model\nperformance that are not well-understood for predictive models of clinical\noutcomes. To inform the ongoing debate, we conduct an empirical study to\ncharacterize the impact of penalizing group fairness violations on an array of\nmeasures of model performance and group fairness. We repeat the analyses across\nmultiple observational healthcare databases, clinical outcomes, and sensitive\nattributes. We find that procedures that penalize differences between the\ndistributions of predictions across groups induce nearly-universal degradation\nof multiple performance metrics within groups. On examining the secondary\nimpact of these procedures, we observe heterogeneity of the effect of these\nprocedures on measures of fairness in calibration and ranking across\nexperimental conditions. Beyond the reported trade-offs, we emphasize that\nanalyses of algorithmic fairness in healthcare lack the contextual grounding\nand causal awareness necessary to reason about the mechanisms that lead to\nhealth disparities, as well as about the potential of algorithmic fairness\nmethods to counteract those mechanisms. In light of these limitations, we\nencourage researchers building predictive models for clinical use to step\noutside the algorithmic fairness frame and engage critically with the broader\nsociotechnical context surrounding the use of machine learning in healthcare.",
          "link": "http://arxiv.org/abs/2007.10306",
          "publishedOn": "2021-06-16T01:21:12.815Z",
          "wordCount": 754,
          "title": "An Empirical Characterization of Fair Machine Learning For Clinical Risk Prediction. (arXiv:2007.10306v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08161",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Foster_A/0/1/0/all/0/1\">Adam Foster</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vezer_A/0/1/0/all/0/1\">&#xc1;rpi Vez&#xe9;r</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Glastonbury_C/0/1/0/all/0/1\">Craig A Glastonbury</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Creed_P/0/1/0/all/0/1\">P&#xe1;id&#xed; Creed</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Abujudeh_S/0/1/0/all/0/1\">Sam Abujudeh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sim_A/0/1/0/all/0/1\">Aaron Sim</a>",
          "description": "Learning meaningful representations of data that can address challenges such\nas batch effect correction, data integration and counterfactual inference is a\ncentral problem in many domains including computational biology. Adopting a\nConditional VAE framework, we identify the mathematical principle that unites\nthese challenges: learning a representation that is marginally independent of a\ncondition variable. We therefore propose the Contrastive Mixture of Posteriors\n(CoMP) method that uses a novel misalignment penalty to enforce this\nindependence. This penalty is defined in terms of mixtures of the variational\nposteriors themselves, unlike prior work which uses external discrepancy\nmeasures such as MMD to ensure independence in latent space. We show that CoMP\nhas attractive theoretical properties compared to previous approaches,\nespecially when there is complex global structure in latent space. We further\ndemonstrate state of the art performance on a number of real-world problems,\nincluding the challenging tasks of aligning human tumour samples with cancer\ncell-lines and performing counterfactual inference on single-cell RNA\nsequencing data. Incidentally, we find parallels with the fair representation\nlearning literature, and demonstrate CoMP has competitive performance in\nlearning fair yet expressive latent representations.",
          "link": "http://arxiv.org/abs/2106.08161",
          "publishedOn": "2021-06-16T01:21:12.807Z",
          "wordCount": 627,
          "title": "Contrastive Mixture of Posteriors for Counterfactual Inference, Data Integration and Fairness. (arXiv:2106.08161v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07306",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Papay_S/0/1/0/all/0/1\">Sean Papay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klinger_R/0/1/0/all/0/1\">Roman Klinger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pado_S/0/1/0/all/0/1\">Sebastian Pad&#xf3;</a>",
          "description": "In structured prediction, a major challenge for models is to represent the\ninterdependencies within their output structures. For the common case where\noutputs are structured as a sequence, linear-chain conditional random fields\n(CRFs) are a widely used model class which can learn local dependencies in\noutput sequences. However, the CRF's Markov assumption makes it impossible for\nthese models to capture nonlocal dependencies, and standard CRFs are unable to\nrespect nonlocal constraints of the data (such as global arity constraints on\noutput labels). We present a generalization of CRFs that can enforce a broad\nclass of constraints, including nonlocal ones, by specifying the space of\npossible output structures as a regular language $\\mathcal{L}$. The resulting\nregular-constrained CRF (RegCCRF) has the same formal properties as a standard\nCRF, but assigns zero probability to all label sequences not in $\\mathcal{L}$.\nNotably, RegCCRFs can incorporate their constraints during training, while\nrelated models only enforce constraints during decoding. We prove that\nconstrained training is never worse than constrained decoding, and show using\nsynthetic data that it can be substantially better in practice. Additionally,\nwe demonstrate a practical benefit on downstream tasks by incorporating a\nRegCCRF into a deep neural model for semantic role labeling, exceeding\nstate-of-the-art results on a standard dataset.",
          "link": "http://arxiv.org/abs/2106.07306",
          "publishedOn": "2021-06-16T01:21:12.800Z",
          "wordCount": 646,
          "title": "Constraining Linear-chain CRFs to Regular Languages. (arXiv:2106.07306v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.04651",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ponnoprat_D/0/1/0/all/0/1\">Donlapark Ponnoprat</a>",
          "description": "The Wasserstein distance provides a notion of dissimilarities between\nprobability measures, which has recent applications in learning of structured\ndata with varying size such as images and text documents. In this work, we\nanalyze the $k$-nearest neighbor classifier ($k$-NN) under the Wasserstein\ndistance and establish the universal consistency on families of distributions.\nUsing previous known results on the consistency of the $k$-NN classifier on\ninfinite dimensional metric spaces, it suffices to show that the families is a\ncountable union of finite dimension sets. As a result, we show that the $k$-NN\nclassifier is universally consistent on spaces of finitely supported measures,\nthe space of Gaussian measures, and the space of measures with finite wavelet\ndensities. In addition, we give a counterexample to show that the universal\nconsistency does not hold on $\\mathcal{W}_p((0,1))$.",
          "link": "http://arxiv.org/abs/2009.04651",
          "publishedOn": "2021-06-16T01:21:12.794Z",
          "wordCount": 591,
          "title": "Universal consistency of Wasserstein $k$-NN classifier. (arXiv:2009.04651v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.07075",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Grubisic_I/0/1/0/all/0/1\">Ivan Grubi&#x161;i&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Orsic_M/0/1/0/all/0/1\">Marin Or&#x161;i&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Segvic_S/0/1/0/all/0/1\">Sini&#x161;a &#x160;egvi&#x107;</a>",
          "description": "Semi-supervised learning is especially interesting in the dense prediction\ncontext due to high cost of pixel-level ground truth. Unfortunately, most such\napproaches are evaluated on outdated architectures which hamper research due to\nvery slow training and high requirements on GPU RAM. We address this concern by\npresenting a simple and effective baseline which works very well both on\nstandard and efficient architectures. Our baseline is based on one-way\nconsistency and non-linear geometric and photometric perturbations. We show\nadvantage of perturbing only the student branch and present a plausible\nexplanation of such behaviour. Experiments on Cityscapes and CIFAR-10\ndemonstrate competitive performance with respect to prior work.",
          "link": "http://arxiv.org/abs/2106.07075",
          "publishedOn": "2021-06-16T01:21:12.771Z",
          "wordCount": 558,
          "title": "A baseline for semi-supervised learning of efficient semantic segmentation models. (arXiv:2106.07075v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08048",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Tseytlin_B/0/1/0/all/0/1\">Boris Tseytlin</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Makarov_I/0/1/0/all/0/1\">Ilya Makarov</a>",
          "description": "During a long-running pandemic a pathogen can mutate, producing new strains\nwith different epidemiological parameters. Existing approaches to epidemic\nmodelling only consider one virus strain. We have developed a modified SEIR\nmodel to simulate multiple virus strains within the same population. As a case\nstudy, we investigate the potential effects of SARS-CoV-2 strain B.1.1.7 on the\ncity of Moscow. Our analysis indicates a high risk of a new wave of infections\nin September-October 2021 with up to 35 000 daily infections at peak. We\nopen-source our code and data.",
          "link": "http://arxiv.org/abs/2106.08048",
          "publishedOn": "2021-06-16T01:21:12.744Z",
          "wordCount": 575,
          "title": "Epidemic modelling of multiple virus strains:a case study of SARS-CoV-2 B.1.1.7 in Moscow. (arXiv:2106.08048v1 [q-bio.PE])"
        },
        {
          "id": "http://arxiv.org/abs/2010.12007",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Biktairov_Y/0/1/0/all/0/1\">Yuriy Biktairov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stebelev_M/0/1/0/all/0/1\">Maxim Stebelev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rudenko_I/0/1/0/all/0/1\">Irina Rudenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shliazhko_O/0/1/0/all/0/1\">Oleh Shliazhko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yangel_B/0/1/0/all/0/1\">Boris Yangel</a>",
          "description": "Predicting the motion of agents such as pedestrians or human-driven vehicles\nis one of the most critical problems in the autonomous driving domain. The\noverall safety of driving and the comfort of a passenger directly depend on its\nsuccessful solution. The motion prediction problem also remains one of the most\nchallenging problems in autonomous driving engineering, mainly due to high\nvariance of the possible agent's future behavior given a situation. The two\nphenomena responsible for the said variance are the multimodality caused by the\nuncertainty of the agent's intent (e.g., turn right or move forward) and\nuncertainty in the realization of a given intent (e.g., which lane to turn\ninto). To be useful within a real-time autonomous driving pipeline, a motion\nprediction system must provide efficient ways to describe and quantify this\nuncertainty, such as computing posterior modes and their probabilities or\nestimating density at the point corresponding to a given trajectory. It also\nshould not put substantial density on physically impossible trajectories, as\nthey can confuse the system processing the predictions. In this paper, we\nintroduce the PRANK method, which satisfies these requirements. PRANK takes\nrasterized bird-eye images of agent's surroundings as an input and extracts\nfeatures of the scene with a convolutional neural network. It then produces the\nconditional distribution of agent's trajectories plausible in the given scene.\nThe key contribution of PRANK is a way to represent that distribution using\nnearest-neighbor methods in latent trajectory space, which allows for efficient\ninference in real time. We evaluate PRANK on the in-house and Argoverse\ndatasets, where it shows competitive results.",
          "link": "http://arxiv.org/abs/2010.12007",
          "publishedOn": "2021-06-16T01:21:12.602Z",
          "wordCount": 715,
          "title": "PRANK: motion Prediction based on RANKing. (arXiv:2010.12007v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.01604",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Joseph_V/0/1/0/all/0/1\">Vinu Joseph</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siddiqui_S/0/1/0/all/0/1\">Shoaib Ahmed Siddiqui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhaskara_A/0/1/0/all/0/1\">Aditya Bhaskara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gopalakrishnan_G/0/1/0/all/0/1\">Ganesh Gopalakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muralidharan_S/0/1/0/all/0/1\">Saurav Muralidharan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garland_M/0/1/0/all/0/1\">Michael Garland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_S/0/1/0/all/0/1\">Sheraz Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dengel_A/0/1/0/all/0/1\">Andreas Dengel</a>",
          "description": "With the rise in edge-computing devices, there has been an increasing demand\nto deploy energy and resource-efficient models. A large body of research has\nbeen devoted to developing methods that can reduce the size of the model\nconsiderably without affecting the standard metrics such as top-1 accuracy.\nHowever, these pruning approaches tend to result in a significant mismatch in\nother metrics such as fairness across classes and explainability. To combat\nsuch misalignment, we propose a novel multi-part loss function inspired by the\nknowledge-distillation literature. Through extensive experiments, we\ndemonstrate the effectiveness of our approach across different compression\nalgorithms, architectures, tasks as well as datasets. In particular, we obtain\nup to $4.1\\times$ reduction in the number of prediction mismatches between the\ncompressed and reference models, and up to $5.7\\times$ in cases where the\nreference model makes the correct prediction; all while making no changes to\nthe compression algorithm, and minor modifications to the loss function.\nFurthermore, we demonstrate how inducing simple alignment between the\npredictions of the models naturally improves the alignment on other metrics\nincluding fairness and attributions. Our framework can thus serve as a simple\nplug-and-play component for compression algorithms in the future.",
          "link": "http://arxiv.org/abs/2012.01604",
          "publishedOn": "2021-06-16T01:21:12.595Z",
          "wordCount": 673,
          "title": "Going Beyond Classification Accuracy Metrics in Model Compression. (arXiv:2012.01604v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.02298",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Du_C/0/1/0/all/0/1\">Chao Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1\">Zhifeng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_S/0/1/0/all/0/1\">Shuo Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1\">Lining Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Ziyan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1\">Yifan Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaoqiang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jian Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gai_K/0/1/0/all/0/1\">Kun Gai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Kuang-chih Lee</a>",
          "description": "Modern online advertising systems inevitably rely on personalization methods,\nsuch as click-through rate (CTR) prediction. Recent progress in CTR prediction\nenjoys the rich representation capabilities of deep learning and achieves great\nsuccess in large-scale industrial applications. However, these methods can\nsuffer from lack of exploration. Another line of prior work addresses the\nexploration-exploitation trade-off problem with contextual bandit methods,\nwhich are recently less studied in the industry due to the difficulty in\nextending their flexibility with deep models. In this paper, we propose a novel\nDeep Uncertainty-Aware Learning (DUAL) method to learn CTR models based on\nGaussian processes, which can provide predictive uncertainty estimations while\nmaintaining the flexibility of deep neural networks. DUAL can be easily\nimplemented on existing models and deployed in real-time systems with minimal\nextra computational overhead. By linking the predictive uncertainty estimation\nability of DUAL to well-known bandit algorithms, we further present DUAL-based\nAd-ranking strategies to boost up long-term utilities such as the social\nwelfare in advertising systems. Experimental results on several public datasets\ndemonstrate the effectiveness of our methods. Remarkably, an online A/B test\ndeployed in the Alibaba display advertising platform shows an 8.2% social\nwelfare improvement and an 8.0% revenue lift.",
          "link": "http://arxiv.org/abs/2012.02298",
          "publishedOn": "2021-06-16T01:21:12.587Z",
          "wordCount": 675,
          "title": "Exploration in Online Advertising Systems with Deep Uncertainty-Aware Learning. (arXiv:2012.02298v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.13511",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Yuan_B/0/1/0/all/0/1\">Bowen Yuan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_Y/0/1/0/all/0/1\">Yu-Sheng Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Quan_P/0/1/0/all/0/1\">Pengrui Quan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lin_C/0/1/0/all/0/1\">Chih-Jen Lin</a>",
          "description": "We study the problem of learning similarity by using nonlinear embedding\nmodels (e.g., neural networks) from all possible pairs. This problem is\nwell-known for its difficulty of training with the extreme number of pairs. For\nthe special case of using linear embeddings, many studies have addressed this\nissue of handling all pairs by considering certain loss functions and\ndeveloping efficient optimization algorithms. This paper aims to extend results\nfor general nonlinear embeddings. First, we finish detailed derivations and\nprovide clean formulations for efficiently calculating some building blocks of\noptimization algorithms such as function, gradient evaluation, and\nHessian-vector product. The result enables the use of many optimization methods\nfor extreme similarity learning with nonlinear embeddings. Second, we study\nsome optimization methods in detail. Due to the use of nonlinear embeddings,\nimplementation issues different from linear cases are addressed. In the end,\nsome methods are shown to be highly efficient for extreme similarity learning\nwith nonlinear embeddings.",
          "link": "http://arxiv.org/abs/2010.13511",
          "publishedOn": "2021-06-16T01:21:12.532Z",
          "wordCount": 616,
          "title": "Efficient Optimization Methods for Extreme Similarity Learning with Nonlinear Embeddings. (arXiv:2010.13511v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.07836",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sadeghi_O/0/1/0/all/0/1\">Omid Sadeghi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raut_P/0/1/0/all/0/1\">Prasanna Raut</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fazel_M/0/1/0/all/0/1\">Maryam Fazel</a>",
          "description": "In this paper, we consider an online optimization problem over $T$ rounds\nwhere at each step $t\\in[T]$, the algorithm chooses an action $x_t$ from the\nfixed convex and compact domain set $\\mathcal{K}$. A utility function\n$f_t(\\cdot)$ is then revealed and the algorithm receives the payoff $f_t(x_t)$.\nThis problem has been previously studied under the assumption that the\nutilities are adversarially chosen monotone DR-submodular functions and\n$\\mathcal{O}(\\sqrt{T})$ regret bounds have been derived. We first characterize\nthe class of strongly DR-submodular functions and then, we derive regret bounds\nfor the following new online settings: $(1)$ $\\{f_t\\}_{t=1}^T$ are monotone\nstrongly DR-submodular and chosen adversarially, $(2)$ $\\{f_t\\}_{t=1}^T$ are\nmonotone submodular (while the average $\\frac{1}{T}\\sum_{t=1}^T f_t$ is\nstrongly DR-submodular) and chosen by an adversary but they arrive in a\nuniformly random order, $(3)$ $\\{f_t\\}_{t=1}^T$ are drawn i.i.d. from some\nunknown distribution $f_t\\sim \\mathcal{D}$ where the expected function\n$f(\\cdot)=\\mathbb{E}_{f_t\\sim\\mathcal{D}}[f_t(\\cdot)]$ is monotone\nDR-submodular. For $(1)$, we obtain the first logarithmic regret bounds. In\nterms of the second framework, we show that it is possible to obtain similar\nlogarithmic bounds with high probability. Finally, for the i.i.d. model, we\nprovide algorithms with $\\tilde{\\mathcal{O}}(\\sqrt{T})$ stochastic regret\nbound, both in expectation and with high probability. Experimental results\ndemonstrate that our algorithms outperform the previous techniques in the\naforementioned three settings.",
          "link": "http://arxiv.org/abs/2106.07836",
          "publishedOn": "2021-06-16T01:21:11.497Z",
          "wordCount": 641,
          "title": "Improved Regret Bounds for Online Submodular Maximization. (arXiv:2106.07836v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2104.05441",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kaiser_M/0/1/0/all/0/1\">Marcus Kaiser</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sipos_M/0/1/0/all/0/1\">Maksim Sipos</a>",
          "description": "Causal Discovery methods aim to identify a DAG structure that represents\ncausal relationships from observational data. In this article, we stress that\nit is important to test such methods for robustness in practical settings. As\nour main example, we analyze the NOTEARS method, for which we demonstrate a\nlack of scale-invariance. We show that NOTEARS is a method that aims to\nidentify a parsimonious DAG from the data that explains the residual variance.\nWe conclude that NOTEARS is not suitable for identifying truly causal\nrelationships from the data.",
          "link": "http://arxiv.org/abs/2104.05441",
          "publishedOn": "2021-06-16T01:21:11.489Z",
          "wordCount": 537,
          "title": "Unsuitability of NOTEARS for Causal Graph Discovery. (arXiv:2104.05441v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.00995",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dutt_A/0/1/0/all/0/1\">Arkopal Dutt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lokhov_A/0/1/0/all/0/1\">Andrey Y. Lokhov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vuffray_M/0/1/0/all/0/1\">Marc Vuffray</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Misra_S/0/1/0/all/0/1\">Sidhant Misra</a>",
          "description": "The usual setting for learning the structure and parameters of a graphical\nmodel assumes the availability of independent samples produced from the\ncorresponding multivariate probability distribution. However, for many models\nthe mixing time of the respective Markov chain can be very large and i.i.d.\nsamples may not be obtained. We study the problem of reconstructing binary\ngraphical models from correlated samples produced by a dynamical process, which\nis natural in many applications. We analyze the sample complexity of two\nestimators that are based on the interaction screening objective and the\nconditional likelihood loss. We observe that for samples coming from a\ndynamical process far from equilibrium, the sample complexity reduces\nexponentially compared to a dynamical process that mixes quickly.",
          "link": "http://arxiv.org/abs/2104.00995",
          "publishedOn": "2021-06-16T01:21:11.483Z",
          "wordCount": 604,
          "title": "Exponential Reduction in Sample Complexity with Learning of Ising Model Dynamics. (arXiv:2104.00995v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2001.10119",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Chenghui Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chun-Liang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poczos_B/0/1/0/all/0/1\">Barnabas Poczos</a>",
          "description": "Program synthesis has emerged as a successful approach to the image parsing\ntask. Most prior works rely on a two-step scheme involving supervised\npretraining of a Seq2Seq model with synthetic programs followed by\nreinforcement learning (RL) for fine-tuning with real reference images. Fully\nunsupervised approaches promise to train the model directly on the target\nimages without requiring curated pretraining datasets. However, they struggle\nwith the inherent sparsity of meaningful programs in the search space. In this\npaper, we present the first unsupervised algorithm capable of parsing\nconstructive solid geometry (CSG) images into context-free grammar (CFG)\nwithout pretraining via non-differentiable renderer. To tackle the\n\\emph{non-Markovian} sparse reward problem, we combine three key ingredients --\n(i) a grammar-encoded tree LSTM ensuring program validity (ii) entropy\nregularization and (iii) sampling without replacement from the CFG syntax tree.\nEmpirically, our algorithm recovers meaningful programs in large search spaces\n(up to $3.8 \\times 10^{28}$). Further, even though our approach is fully\nunsupervised, it generalizes better than supervised methods on the synthetic 2D\nCSG dataset. On the 2D computer aided design (CAD) dataset, our approach\nsignificantly outperforms the supervised pretrained model and is competitive to\nthe refined model.",
          "link": "http://arxiv.org/abs/2001.10119",
          "publishedOn": "2021-06-16T01:21:11.476Z",
          "wordCount": 657,
          "title": "Unsupervised Program Synthesis for Images By Sampling Without Replacement. (arXiv:2001.10119v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.15588",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wulfmeier_M/0/1/0/all/0/1\">Markus Wulfmeier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rao_D/0/1/0/all/0/1\">Dushyant Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hafner_R/0/1/0/all/0/1\">Roland Hafner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lampe_T/0/1/0/all/0/1\">Thomas Lampe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdolmaleki_A/0/1/0/all/0/1\">Abbas Abdolmaleki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hertweck_T/0/1/0/all/0/1\">Tim Hertweck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neunert_M/0/1/0/all/0/1\">Michael Neunert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tirumala_D/0/1/0/all/0/1\">Dhruva Tirumala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siegel_N/0/1/0/all/0/1\">Noah Siegel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heess_N/0/1/0/all/0/1\">Nicolas Heess</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riedmiller_M/0/1/0/all/0/1\">Martin Riedmiller</a>",
          "description": "We introduce Hindsight Off-policy Options (HO2), a data-efficient option\nlearning algorithm. Given any trajectory, HO2 infers likely option choices and\nbackpropagates through the dynamic programming inference procedure to robustly\ntrain all policy components off-policy and end-to-end. The approach outperforms\nexisting option learning methods on common benchmarks. To better understand the\noption framework and disentangle benefits from both temporal and action\nabstraction, we evaluate ablations with flat policies and mixture policies with\ncomparable optimization. The results highlight the importance of both types of\nabstraction as well as off-policy training and trust-region constraints,\nparticularly in challenging, simulated 3D robot manipulation tasks from raw\npixel inputs. Finally, we intuitively adapt the inference step to investigate\nthe effect of increased temporal abstraction on training with pre-trained\noptions and from scratch.",
          "link": "http://arxiv.org/abs/2007.15588",
          "publishedOn": "2021-06-16T01:21:11.448Z",
          "wordCount": 605,
          "title": "Data-efficient Hindsight Off-policy Option Learning. (arXiv:2007.15588v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.04262",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lo_S/0/1/0/all/0/1\">Shao-Yuan Lo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valanarasu_J/0/1/0/all/0/1\">Jeya Maria Jose Valanarasu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patel_V/0/1/0/all/0/1\">Vishal M. Patel</a>",
          "description": "Adversarial robustness of deep neural networks is an extensively studied\nproblem in the literature and various methods have been proposed to defend\nagainst adversarial images. However, only a handful of defense methods have\nbeen developed for defending against attacked videos. In this paper, we propose\na novel Over-and-Under complete restoration network for Defending against\nadversarial videos (OUDefend). Most restoration networks adopt an\nencoder-decoder architecture that first shrinks spatial dimension then expands\nit back. This approach learns undercomplete representations, which have large\nreceptive fields to collect global information but overlooks local details. On\nthe other hand, overcomplete representations have opposite properties. Hence,\nOUDefend is designed to balance local and global features by learning those two\nrepresentations. We attach OUDefend to target video recognition models as a\nfeature restoration block and train the entire network end-to-end. Experimental\nresults show that the defenses focusing on images may be ineffective to videos,\nwhile OUDefend enhances robustness against different types of adversarial\nvideos, ranging from additive attacks, multiplicative attacks to physically\nrealizable attacks. Code: https://github.com/shaoyuanlo/OUDefend",
          "link": "http://arxiv.org/abs/2012.04262",
          "publishedOn": "2021-06-16T01:21:11.441Z",
          "wordCount": 647,
          "title": "Overcomplete Representations Against Adversarial Videos. (arXiv:2012.04262v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.03279",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Seidl_P/0/1/0/all/0/1\">Philipp Seidl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Renz_P/0/1/0/all/0/1\">Philipp Renz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dyubankova_N/0/1/0/all/0/1\">Natalia Dyubankova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neves_P/0/1/0/all/0/1\">Paulo Neves</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verhoeven_J/0/1/0/all/0/1\">Jonas Verhoeven</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Segler_M/0/1/0/all/0/1\">Marwin Segler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wegner_J/0/1/0/all/0/1\">J&#xf6;rg K. Wegner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hochreiter_S/0/1/0/all/0/1\">Sepp Hochreiter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klambauer_G/0/1/0/all/0/1\">G&#xfc;nter Klambauer</a>",
          "description": "Finding synthesis routes for molecules of interest is an essential step in\nthe discovery of new drugs and materials. To find such routes,\ncomputer-assisted synthesis planning (CASP) methods are employed which rely on\na model of chemical reactivity. In this study, we model single-step\nretrosynthesis in a template-based approach using modern Hopfield networks\n(MHNs). We adapt MHNs to associate different modalities, reaction templates and\nmolecules, which allows the model to leverage structural information about\nreaction templates. This approach significantly improves the performance of\ntemplate relevance prediction, especially for templates with few or zero\ntraining examples. With inference speed several times faster than that of\nbaseline methods, we improve predictive performance for top-k exact match\naccuracy for $\\mathrm{k}\\geq5$ in the retrosynthesis benchmark USPTO-50k.",
          "link": "http://arxiv.org/abs/2104.03279",
          "publishedOn": "2021-06-16T01:21:11.434Z",
          "wordCount": 620,
          "title": "Modern Hopfield Networks for Few- and Zero-Shot Reaction Template Prediction. (arXiv:2104.03279v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.01400",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kanai_S/0/1/0/all/0/1\">Sekitoshi Kanai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamada_M/0/1/0/all/0/1\">Masanori Yamada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takahashi_H/0/1/0/all/0/1\">Hiroshi Takahashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamanaka_Y/0/1/0/all/0/1\">Yuki Yamanaka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ida_Y/0/1/0/all/0/1\">Yasutoshi Ida</a>",
          "description": "Deep neural networks are vulnerable to adversarial attacks. Recent studies\nabout adversarial robustness focus on the loss landscape in the parameter space\nsince it is related to optimization and generalization performance. These\nstudies conclude that the difficulty of adversarial training is caused by the\nnon-smoothness of the loss function: i.e., its gradient is not Lipschitz\ncontinuous. However, this analysis ignores the dependence of adversarial\nattacks on model parameters. Since adversarial attacks are optimized for\nmodels, they should depend on the parameters. Considering this dependence, we\nanalyze the smoothness of the loss function of adversarial training using the\noptimal attacks for the model parameter in more detail. We reveal that the\nconstraint of adversarial attacks is one cause of the non-smoothness and that\nthe smoothness depends on the types of the constraints. Specifically, the\n$L_\\infty$ constraint can cause non-smoothness more than the $L_2$ constraint.\nMoreover, our analysis implies that if we flatten the loss function with\nrespect to input data, the Lipschitz constant of the gradient of adversarial\nloss tends to increase. To address the non-smoothness, we show that EntropySGD\nsmoothens the non-smooth loss and improves the performance of adversarial\ntraining.",
          "link": "http://arxiv.org/abs/2103.01400",
          "publishedOn": "2021-06-16T01:21:11.427Z",
          "wordCount": 674,
          "title": "Smoothness Analysis of Adversarial Training. (arXiv:2103.01400v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2002.11743",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Whang_J/0/1/0/all/0/1\">Jay Whang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lindgren_E/0/1/0/all/0/1\">Erik M. Lindgren</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dimakis_A/0/1/0/all/0/1\">Alexandros G. Dimakis</a>",
          "description": "Given an inverse problem with a normalizing flow prior, we wish to estimate\nthe distribution of the underlying signal conditioned on the observations. We\napproach this problem as a task of conditional inference on the pre-trained\nunconditional flow model. We first establish that this is computationally hard\nfor a large class of flow models. Motivated by this, we propose a framework for\napproximate inference that estimates the target conditional as a composition of\ntwo flow models. This formulation leads to a stable variational inference\ntraining procedure that avoids adversarial training. Our method is evaluated on\na variety of inverse problems and is shown to produce high-quality samples with\nuncertainty quantification. We further demonstrate that our approach can be\namortized for zero-shot inference.",
          "link": "http://arxiv.org/abs/2002.11743",
          "publishedOn": "2021-06-16T01:21:11.421Z",
          "wordCount": 578,
          "title": "Composing Normalizing Flows for Inverse Problems. (arXiv:2002.11743v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.15727",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1\">Yueqi Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lee_Y/0/1/0/all/0/1\">Yoonho Lee</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Basu_P/0/1/0/all/0/1\">Pallab Basu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lee_J/0/1/0/all/0/1\">Juho Lee</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Teh_Y/0/1/0/all/0/1\">Yee Whye Teh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Paninski_L/0/1/0/all/0/1\">Liam Paninski</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pakman_A/0/1/0/all/0/1\">Ari Pakman</a>",
          "description": "Learning community structures in graphs has broad applications across\nscientific domains. While graph neural networks (GNNs) have been successful in\nencoding graph structures, existing GNN-based methods for community detection\nare limited by requiring knowledge of the number of communities in advance, in\naddition to lacking a proper probabilistic formulation to handle uncertainty.\nWe propose a simple framework for amortized community detection, which\naddresses both of these issues by combining the expressive power of GNNs with\nrecent methods for amortized clustering. Our models consist of a graph\nrepresentation backbone that extracts structural information and an amortized\nclustering network that naturally handles variable numbers of clusters. Both\ncomponents combine into well-defined models of the posterior distribution of\ngraph communities and are jointly optimized given labeled graphs. At inference\ntime, the models yield parallel samples from the posterior of community labels,\nquantifying uncertainty in a principled way. We evaluate several models from\nour framework on synthetic and real datasets and demonstrate superior\nperformance to previous methods. As a separate contribution, we extend recent\namortized probabilistic clustering architectures by adding attention modules,\nwhich yield further improvements on community detection tasks.",
          "link": "http://arxiv.org/abs/2010.15727",
          "publishedOn": "2021-06-16T01:21:11.383Z",
          "wordCount": 645,
          "title": "Amortized Probabilistic Detection of Communities in Graphs. (arXiv:2010.15727v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.09030",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dijk_M/0/1/0/all/0/1\">Marten van Dijk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1\">Nhuong V. Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Toan N. Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_L/0/1/0/all/0/1\">Lam M. Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_P/0/1/0/all/0/1\">Phuong Ha Nguyen</a>",
          "description": "In the context of DP-SGD each round communicates a local SGD update which\nleaks some new information about the underlying local data set to the outside\nworld. In order to provide privacy, Gaussian noise is added to local SGD\nupdates. However, privacy leakage still aggregates over multiple training\nrounds. Therefore, in order to control privacy leakage over an increasing\nnumber of training rounds, we need to increase the added Gaussian noise per\nlocal SGD update. This dependence of the amount of Gaussian noise $\\sigma$ on\nthe number of training rounds $T$ may impose an impractical upper bound on $T$\n(because $\\sigma$ cannot be too large) leading to a low accuracy global model\n(because the global model receives too few local SGD updates). DP-SGD much less\ncompetitive compared to other existing privacy techniques.\n\nWe show for the first time that for $(\\epsilon,\\delta)$-differential privacy\n$\\sigma$ can be chosen equal to $\\sqrt{2(\\epsilon +\\ln(1/\\delta))/\\epsilon}$\nregardless the total number of training rounds $T$. In other words, $\\sigma$\ndoes not depend on $T$ anymore (and aggregation of privacy leakage increases to\na limit). This important discovery brings DP-SGD to practice because $\\sigma$\ncan remain small to make the trained model have high accuracy even for large\n$T$ as usually happens in practice.",
          "link": "http://arxiv.org/abs/2102.09030",
          "publishedOn": "2021-06-16T01:21:11.364Z",
          "wordCount": 706,
          "title": "Bringing Differential Private SGD to Practice: On the Independence of Gaussian Noise and the Number of Training Rounds. (arXiv:2102.09030v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2004.11231",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Mekkaoui_K/0/1/0/all/0/1\">Khaoula El Mekkaoui</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mesquita_D/0/1/0/all/0/1\">Diego Mesquita</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Blomstedt_P/0/1/0/all/0/1\">Paul Blomstedt</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kaski_S/0/1/0/all/0/1\">Samuel Kaski</a>",
          "description": "Stochastic gradient MCMC methods, such as stochastic gradient Langevin\ndynamics (SGLD), employ fast but noisy gradient estimates to enable large-scale\nposterior sampling. Although we can easily extend SGLD to distributed settings,\nit suffers from two issues when applied to federated non-IID data. First, the\nvariance of these estimates increases significantly. Second, delaying\ncommunication causes the Markov chains to diverge from the true posterior even\nfor very simple models. To alleviate both these problems, we propose conducive\ngradients, a simple mechanism that combines local likelihood approximations to\ncorrect gradient updates. Notably, conducive gradients are easy to compute, and\nsince we only calculate the approximations once, they incur negligible\noverhead. We apply conducive gradients to distributed stochastic gradient\nLangevin dynamics (DSGLD) and call the resulting method federated stochastic\ngradient Langevin dynamics (FSGLD). We demonstrate that our approach can handle\ndelayed communication rounds, converging to the target posterior in cases where\nDSGLD fails. We also show that FSGLD outperforms DSGLD for non-IID federated\ndata with experiments on metric learning and neural networks.",
          "link": "http://arxiv.org/abs/2004.11231",
          "publishedOn": "2021-06-16T01:21:11.356Z",
          "wordCount": 624,
          "title": "Federated Stochastic Gradient Langevin Dynamics. (arXiv:2004.11231v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10005",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">C.-H. Huck Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chhabra_M/0/1/0/all/0/1\">Mohit Chhabra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Y.-C. Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_Q/0/1/0/all/0/1\">Quan Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoshinaga_T/0/1/0/all/0/1\">Tomoaki Yoshinaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murakami_T/0/1/0/all/0/1\">Tomokazu Murakami</a>",
          "description": "Physical processes, camera movement, and unpredictable environmental\nconditions like the presence of dust can induce noise and artifacts in video\nfeeds. We observe that popular unsupervised MOT methods are dependent on\nnoise-free inputs. We show that the addition of a small amount of artificial\nrandom noise causes a sharp degradation in model performance on benchmark\nmetrics. We resolve this problem by introducing a robust unsupervised\nmulti-object tracking (MOT) model: AttU-Net. The proposed single-head attention\nmodel helps limit the negative impact of noise by learning visual\nrepresentations at different segment scales. AttU-Net shows better unsupervised\nMOT tracking performance over variational inference-based state-of-the-art\nbaselines. We evaluate our method in the MNIST-MOT and the Atari game video\nbenchmark. We also provide two extended video datasets: ``Kuzushiji-MNIST MOT''\nwhich consists of moving Japanese characters and ``Fashion-MNIST MOT'' to\nvalidate the effectiveness of the MOT models.",
          "link": "http://arxiv.org/abs/2105.10005",
          "publishedOn": "2021-06-16T01:21:11.349Z",
          "wordCount": 644,
          "title": "Robust Unsupervised Multi-Object Tracking in Noisy Environments. (arXiv:2105.10005v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.11436",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Robey_A/0/1/0/all/0/1\">Alexander Robey</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pappas_G/0/1/0/all/0/1\">George J. Pappas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hassani_H/0/1/0/all/0/1\">Hamed Hassani</a>",
          "description": "Despite remarkable success in a variety of applications, it is well-known\nthat deep learning can fail catastrophically when presented with\nout-of-distribution data. Toward addressing this challenge, we consider the\ndomain generalization problem, wherein predictors are trained using data drawn\nfrom a family of related training domains and then evaluated on a distinct and\nunseen test domain. We show that under a natural model of data generation and a\nconcomitant invariance condition, the domain generalization problem is\nequivalent to an infinite-dimensional constrained statistical learning problem;\nthis problem forms the basis of our approach, which we call Model-Based Domain\nGeneralization. Due to the inherent challenges in solving constrained\noptimization problems in deep learning, we exploit nonconvex duality theory to\ndevelop unconstrained relaxations of this statistical problem with tight bounds\non the duality gap. Based on this theoretical motivation, we propose a novel\ndomain generalization algorithm with convergence guarantees. In our\nexperiments, we report improvements of up to 30 percentage points over\nstate-of-the-art domain generalization baselines on several benchmarks\nincluding ColoredMNIST, Camelyon17-WILDS, FMoW-WILDS, and PACS.",
          "link": "http://arxiv.org/abs/2102.11436",
          "publishedOn": "2021-06-16T01:21:11.342Z",
          "wordCount": 610,
          "title": "Model-Based Domain Generalization. (arXiv:2102.11436v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2004.14180",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Congliang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Li Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Haozhi Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wei Liu</a>",
          "description": "In this paper, we present a distributed variant of adaptive stochastic\ngradient method for training deep neural networks in the parameter-server\nmodel. To reduce the communication cost among the workers and server, we\nincorporate two types of quantization schemes, i.e., gradient quantization and\nweight quantization, into the proposed distributed Adam. Besides, to reduce the\nbias introduced by quantization operations, we propose an error-feedback\ntechnique to compensate for the quantized gradient. Theoretically, in the\nstochastic nonconvex setting, we show that the distributed adaptive gradient\nmethod with gradient quantization and error-feedback converges to the\nfirst-order stationary point, and that the distributed adaptive gradient method\nwith weight quantization and error-feedback converges to the point related to\nthe quantized level under both the single-worker and multi-worker modes. At\nlast, we apply the proposed distributed adaptive gradient methods to train deep\nneural networks. Experimental results demonstrate the efficacy of our methods.",
          "link": "http://arxiv.org/abs/2004.14180",
          "publishedOn": "2021-06-16T01:21:11.321Z",
          "wordCount": 621,
          "title": "Quantized Adam with Error Feedback. (arXiv:2004.14180v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.11086",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ruan_Y/0/1/0/all/0/1\">Yangjun Ruan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ullrich_K/0/1/0/all/0/1\">Karen Ullrich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Severo_D/0/1/0/all/0/1\">Daniel Severo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Townsend_J/0/1/0/all/0/1\">James Townsend</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khisti_A/0/1/0/all/0/1\">Ashish Khisti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doucet_A/0/1/0/all/0/1\">Arnaud Doucet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Makhzani_A/0/1/0/all/0/1\">Alireza Makhzani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maddison_C/0/1/0/all/0/1\">Chris J. Maddison</a>",
          "description": "Latent variable models have been successfully applied in lossless compression\nwith the bits-back coding algorithm. However, bits-back suffers from an\nincrease in the bitrate equal to the KL divergence between the approximate\nposterior and the true posterior. In this paper, we show how to remove this gap\nasymptotically by deriving bits-back coding algorithms from tighter variational\nbounds. The key idea is to exploit extended space representations of Monte\nCarlo estimators of the marginal likelihood. Naively applied, our schemes would\nrequire more initial bits than the standard bits-back coder, but we show how to\ndrastically reduce this additional cost with couplings in the latent space.\nWhen parallel architectures can be exploited, our coders can achieve better\nrates than bits-back with little additional cost. We demonstrate improved\nlossless compression rates in a variety of settings, especially in\nout-of-distribution or sequential data compression.",
          "link": "http://arxiv.org/abs/2102.11086",
          "publishedOn": "2021-06-16T01:21:11.305Z",
          "wordCount": 621,
          "title": "Improving Lossless Compression Rates via Monte Carlo Bits-Back Coding. (arXiv:2102.11086v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1910.14215",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Russell_R/0/1/0/all/0/1\">Rebecca L. Russell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reale_C/0/1/0/all/0/1\">Christopher Reale</a>",
          "description": "Deep learning has the potential to dramatically impact navigation and\ntracking state estimation problems critical to autonomous vehicles and\nrobotics. Measurement uncertainties in state estimation systems based on Kalman\nand other Bayes filters are typically assumed to be a fixed covariance matrix.\nThis assumption is risky, particularly for \"black box\" deep learning models, in\nwhich uncertainty can vary dramatically and unexpectedly. Accurate\nquantification of multivariate uncertainty will allow for the full potential of\ndeep learning to be used more safely and reliably in these applications. We\nshow how to model multivariate uncertainty for regression problems with neural\nnetworks, incorporating both aleatoric and epistemic sources of heteroscedastic\nuncertainty. We train a deep uncertainty covariance matrix model in two ways:\ndirectly using a multivariate Gaussian density loss function, and indirectly\nusing end-to-end training through a Kalman filter. We experimentally show in a\nvisual tracking problem the large impact that accurate multivariate uncertainty\nquantification can have on Kalman filter performance for both in-domain and\nout-of-domain evaluation data. We additionally show in a challenging visual\nodometry problem how end-to-end filter training can allow uncertainty\npredictions to compensate for filter weaknesses.",
          "link": "http://arxiv.org/abs/1910.14215",
          "publishedOn": "2021-06-16T01:21:11.298Z",
          "wordCount": 657,
          "title": "Multivariate Uncertainty in Deep Learning. (arXiv:1910.14215v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.08244",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gillenwater_J/0/1/0/all/0/1\">Jennifer Gillenwater</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joseph_M/0/1/0/all/0/1\">Matthew Joseph</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulesza_A/0/1/0/all/0/1\">Alex Kulesza</a>",
          "description": "Quantiles are often used for summarizing and understanding data. If that data\nis sensitive, it may be necessary to compute quantiles in a way that is\ndifferentially private, providing theoretical guarantees that the result does\nnot reveal private information. However, when multiple quantiles are needed,\nexisting differentially private algorithms fare poorly: they either compute\nquantiles individually, splitting the privacy budget, or summarize the entire\ndistribution, wasting effort. In either case the result is reduced accuracy. In\nthis work we propose an instance of the exponential mechanism that\nsimultaneously estimates exactly $m$ quantiles from $n$ data points while\nguaranteeing differential privacy. The utility function is carefully structured\nto allow for an efficient implementation that returns estimates of all $m$\nquantiles in time $O(mn\\log(n) + m^2n)$. Experiments show that our method\nsignificantly outperforms the current state of the art on both real and\nsynthetic data while remaining efficient enough to be practical.",
          "link": "http://arxiv.org/abs/2102.08244",
          "publishedOn": "2021-06-16T01:21:11.291Z",
          "wordCount": 609,
          "title": "Differentially Private Quantiles. (arXiv:2102.08244v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.12661",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jafarnia_Jahromi_M/0/1/0/all/0/1\">Mehdi Jafarnia-Jahromi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_R/0/1/0/all/0/1\">Rahul Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nayyar_A/0/1/0/all/0/1\">Ashutosh Nayyar</a>",
          "description": "Solving Partially Observable Markov Decision Processes (POMDPs) is hard.\nLearning optimal controllers for POMDPs when the model is unknown is harder.\nOnline learning of optimal controllers for unknown POMDPs, which requires\nefficient learning using regret-minimizing algorithms that effectively tradeoff\nexploration and exploitation, is even harder, and no solution exists currently.\nIn this paper, we consider infinite-horizon average-cost POMDPs with unknown\ntransition model, though a known observation model. We propose a natural\nposterior sampling-based reinforcement learning algorithm (PSRL-POMDP) and show\nthat it achieves a regret bound of $O(\\log T)$, where $T$ is the time horizon,\nwhen the parameter set is finite. In the general case (continuous parameter\nset), we show that the algorithm achieves $O (T^{2/3})$ regret under two\ntechnical assumptions. To the best of our knowledge, this is the first online\nRL algorithm for POMDPs and has sub-linear regret.",
          "link": "http://arxiv.org/abs/2102.12661",
          "publishedOn": "2021-06-16T01:21:11.275Z",
          "wordCount": 587,
          "title": "Online Learning for Unknown Partially Observable MDPs. (arXiv:2102.12661v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.09931",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pande_H/0/1/0/all/0/1\">Harshit Pande</a>",
          "description": "Click-through rate (CTR) prediction models are common in many online\napplications such as digital advertising and recommender systems. Field-Aware\nFactorization Machine (FFM) and Field-weighted Factorization Machine (FwFM) are\nstate-of-the-art among the shallow models for CTR prediction. Recently, many\ndeep learning-based models have also been proposed. Among deeper models,\nDeepFM, xDeepFM, AutoInt+, and FiBiNet are state-of-the-art models. The deeper\nmodels combine a core architectural component, which learns explicit feature\ninteractions, with a deep neural network (DNN) component. We propose a novel\nshallow Field-Embedded Factorization Machine (FEFM) and its deep counterpart\nDeep Field-Embedded Factorization Machine (DeepFEFM). FEFM learns symmetric\nmatrix embeddings for each field pair along with the usual single vector\nembeddings for each feature. FEFM has significantly lower model complexity than\nFFM and roughly the same complexity as FwFM. FEFM also has insightful\nmathematical properties about important fields and field interactions. DeepFEFM\ncombines the FEFM interaction vectors learned by the FEFM component with a DNN\nand is thus able to learn higher order interactions. We conducted comprehensive\nexperiments over a wide range of hyperparameters on two large publicly\navailable real-world datasets. When comparing test AUC and log loss, the\nresults show that FEFM and DeepFEFM outperform the existing state-of-the-art\nshallow and deep models for CTR prediction tasks. We have made the code of FEFM\nand DeepFEFM available in the DeepCTR library\n(https://github.com/shenweichen/DeepCTR).",
          "link": "http://arxiv.org/abs/2009.09931",
          "publishedOn": "2021-06-16T01:21:11.264Z",
          "wordCount": 675,
          "title": "Field-Embedded Factorization Machines for Click-through rate prediction. (arXiv:2009.09931v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.08898",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tong_T/0/1/0/all/0/1\">Tian Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1\">Cong Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chi_Y/0/1/0/all/0/1\">Yuejie Chi</a>",
          "description": "Low-rank matrix estimation is a canonical problem that finds numerous\napplications in signal processing, machine learning and imaging science. A\npopular approach in practice is to factorize the matrix into two compact\nlow-rank factors, and then optimize these factors directly via simple iterative\nmethods such as gradient descent and alternating minimization. Despite\nnonconvexity, recent literatures have shown that these simple heuristics in\nfact achieve linear convergence when initialized properly for a growing number\nof problems of interest. However, upon closer examination, existing approaches\ncan still be computationally expensive especially for ill-conditioned matrices:\nthe convergence rate of gradient descent depends linearly on the condition\nnumber of the low-rank matrix, while the per-iteration cost of alternating\nminimization is often prohibitive for large matrices. The goal of this paper is\nto set forth a competitive algorithmic approach dubbed Scaled Gradient Descent\n(ScaledGD) which can be viewed as pre-conditioned or diagonally-scaled gradient\ndescent, where the pre-conditioners are adaptive and iteration-varying with a\nminimal computational overhead. With tailored variants for low-rank matrix\nsensing, robust principal component analysis and matrix completion, we\ntheoretically show that ScaledGD achieves the best of both worlds: it converges\nlinearly at a rate independent of the condition number of the low-rank matrix\nsimilar as alternating minimization, while maintaining the low per-iteration\ncost of gradient descent. Our analysis is also applicable to general loss\nfunctions that are restricted strongly convex and smooth over low-rank\nmatrices. To the best of our knowledge, ScaledGD is the first algorithm that\nprovably has such properties over a wide range of low-rank matrix estimation\ntasks.",
          "link": "http://arxiv.org/abs/2005.08898",
          "publishedOn": "2021-06-16T01:21:11.246Z",
          "wordCount": 758,
          "title": "Accelerating Ill-Conditioned Low-Rank Matrix Estimation via Scaled Gradient Descent. (arXiv:2005.08898v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.06837",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_N/0/1/0/all/0/1\">Nan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_X/0/1/0/all/0/1\">Xiaochun Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Duo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_D/0/1/0/all/0/1\">Dongrui Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1\">Zhimin Tang</a>",
          "description": "Many meta-learning methods are proposed for few-shot detection. However,\nprevious most methods have two main problems, poor detection APs, and strong\nbias because of imbalance and insufficient datasets. Previous works mainly\nalleviate these issues by additional datasets, multi-relation attention\nmechanisms and sub-modules. However, they require more cost. In this work, for\nmeta-learning, we find that the main challenges focus on related or irrelevant\nsemantic features between categories. Therefore, based on semantic features, we\npropose a Top-C classification loss (i.e., TCL-C) for classification task and a\ncategory-based grouping mechanism for category-based meta-features obtained by\nthe meta-model. The TCL-C exploits the true-label prediction and the most\nlikely C-1 false classification predictions to improve detection performance on\nfew-shot classes. According to similar appearance (i.e., visual appearance,\nshape, and limbs etc.) and environment in which objects often appear, the\ncategory-based grouping mechanism splits categories into disjoint groups to\nmake similar semantic features more compact between categories within a group\nand obtain more significant difference between groups, alleviating the strong\nbias problem and further improving detection APs. The whole training consists\nof the base model and the fine-tuning phases. According to grouping mechanism,\nwe group the meta-features vectors obtained by meta-model, so that the\ndistribution difference between groups is obvious, and the one within each\ngroup is less. Extensive experiments on Pascal VOC dataset demonstrate that\nours which combines the TCL-C with category-based grouping significantly\noutperforms previous state-of-the-art methods for few-shot detection. Compared\nwith previous competitive baseline, ours improves detection APs by almost 4%\nfor few-shot detection.",
          "link": "http://arxiv.org/abs/2007.06837",
          "publishedOn": "2021-06-16T01:21:11.214Z",
          "wordCount": 762,
          "title": "Top-Related Meta-Learning Method for Few-Shot Object Detection. (arXiv:2007.06837v6 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.05246",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yi Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1\">Aiguo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hui_B/0/1/0/all/0/1\">Bei Hui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_K/0/1/0/all/0/1\">Ke Yan</a>",
          "description": "Conventional Supervised Learning approaches focus on the mapping from input\nfeatures to output labels. After training, the learnt models alone are adapted\nonto testing features to predict testing labels in isolation, with training\ndata wasted and their associations ignored. To take full advantage of the vast\nnumber of training data and their associations, we propose a novel learning\nparadigm called Memory-Associated Differential (MAD) Learning. We first\nintroduce an additional component called Memory to memorize all the training\ndata. Then we learn the differences of labels as well as the associations of\nfeatures in the combination of a differential equation and some sampling\nmethods. Finally, in the evaluating phase, we predict unknown labels by\ninferencing from the memorized facts plus the learnt differences and\nassociations in a geometrically meaningful manner. We gently build this theory\nin unary situations and apply it on Image Recognition, then extend it into Link\nPrediction as a binary situation, in which our method outperforms strong\nstate-of-the-art baselines on ogbl-ddi dataset.",
          "link": "http://arxiv.org/abs/2102.05246",
          "publishedOn": "2021-06-16T01:21:11.201Z",
          "wordCount": 617,
          "title": "Memory-Associated Differential Learning. (arXiv:2102.05246v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.10246",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alemohammad_S/0/1/0/all/0/1\">Sina Alemohammad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zichao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balestriero_R/0/1/0/all/0/1\">Randall Balestriero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baraniuk_R/0/1/0/all/0/1\">Richard Baraniuk</a>",
          "description": "The study of deep neural networks (DNNs) in the infinite-width limit, via the\nso-called neural tangent kernel (NTK) approach, has provided new insights into\nthe dynamics of learning, generalization, and the impact of initialization. One\nkey DNN architecture remains to be kernelized, namely, the recurrent neural\nnetwork (RNN). In this paper we introduce and study the Recurrent Neural\nTangent Kernel (RNTK), which provides new insights into the behavior of\noverparametrized RNNs. A key property of the RNTK should greatly benefit\npractitioners is its ability to compare inputs of different length. To this\nend, we characterize how the RNTK weights different time steps to form its\noutput under different initialization parameters and nonlinearity choices. A\nsynthetic and 56 real-world data experiments demonstrate that the RNTK offers\nsignificant performance gains over other kernels, including standard NTKs,\nacross a wide array of data sets.",
          "link": "http://arxiv.org/abs/2006.10246",
          "publishedOn": "2021-06-16T01:21:11.176Z",
          "wordCount": 609,
          "title": "The Recurrent Neural Tangent Kernel. (arXiv:2006.10246v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.09704",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Barik_A/0/1/0/all/0/1\">Adarsh Barik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Honorio_J/0/1/0/all/0/1\">Jean Honorio</a>",
          "description": "In this paper, we study the problem of fair sparse regression on a biased\ndataset where bias depends upon a hidden binary attribute. The presence of a\nhidden attribute adds an extra layer of complexity to the problem by combining\nsparse regression and clustering with unknown binary labels. The corresponding\noptimization problem is combinatorial, but we propose a novel relaxation of it\nas an \\emph{invex} optimization problem. To the best of our knowledge, this is\nthe first invex relaxation for a combinatorial problem. We show that the\ninclusion of the debiasing/fairness constraint in our model has no adverse\neffect on the performance. Rather, it enables the recovery of the hidden\nattribute. The support of our recovered regression parameter vector matches\nexactly with the true parameter vector. Moreover, we simultaneously solve the\nclustering problem by recovering the exact value of the hidden attribute for\neach sample. Our method uses carefully constructed primal dual witnesses to\nprovide theoretical guarantees for the combinatorial problem. To that end, we\nshow that the sample complexity of our method is logarithmic in terms of the\ndimension of the regression parameter vector.",
          "link": "http://arxiv.org/abs/2102.09704",
          "publishedOn": "2021-06-16T01:21:11.157Z",
          "wordCount": 640,
          "title": "Fair Sparse Regression with Clustering: An Invex Relaxation for a Combinatorial Problem. (arXiv:2102.09704v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.07043",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Haitian Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verga_P/0/1/0/all/0/1\">Pat Verga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dhingra_B/0/1/0/all/0/1\">Bhuwan Dhingra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1\">Ruslan Salakhutdinov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_W/0/1/0/all/0/1\">William W. Cohen</a>",
          "description": "We present the Open Predicate Query Language (OPQL); a method for\nconstructing a virtual KB (VKB) trained entirely from text. Large Knowledge\nBases (KBs) are indispensable for a wide-range of industry applications such as\nquestion answering and recommendation. Typically, KBs encode world knowledge in\na structured, readily accessible form derived from laborious human annotation\nefforts. Unfortunately, while they are extremely high precision, KBs are\ninevitably highly incomplete and automated methods for enriching them are far\ntoo inaccurate. Instead, OPQL constructs a VKB by encoding and indexing a set\nof relation mentions in a way that naturally enables reasoning and can be\ntrained without any structured supervision. We demonstrate that OPQL\noutperforms prior VKB methods on two different KB reasoning tasks and,\nadditionally, can be used as an external memory integrated into a language\nmodel (OPQL-LM) leading to improvements on two open-domain question answering\ntasks.",
          "link": "http://arxiv.org/abs/2102.07043",
          "publishedOn": "2021-06-16T01:21:11.151Z",
          "wordCount": 625,
          "title": "Reasoning Over Virtual Knowledge Bases With Open Predicate Relations. (arXiv:2102.07043v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.12589",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singh_J/0/1/0/all/0/1\">Jaskirat Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1\">Liang Zheng</a>",
          "description": "Generation of stroke-based non-photorealistic imagery, is an important\nproblem in the computer vision community. As an endeavor in this direction,\nsubstantial recent research efforts have been focused on teaching machines \"how\nto paint\", in a manner similar to a human painter. However, the applicability\nof previous methods has been limited to datasets with little variation in\nposition, scale and saliency of the foreground object. As a consequence, we\nfind that these methods struggle to cover the granularity and diversity\npossessed by real world images. To this end, we propose a Semantic Guidance\npipeline with 1) a bi-level painting procedure for learning the distinction\nbetween foreground and background brush strokes at training time. 2) We also\nintroduce invariance to the position and scale of the foreground object through\na neural alignment model, which combines object localization and spatial\ntransformer networks in an end to end manner, to zoom into a particular\nsemantic instance. 3) The distinguishing features of the in-focus object are\nthen amplified by maximizing a novel guided backpropagation based focus reward.\nThe proposed agent does not require any supervision on human stroke-data and\nsuccessfully handles variations in foreground object attributes, thus,\nproducing much higher quality canvases for the CUB-200 Birds and Stanford\nCars-196 datasets. Finally, we demonstrate the further efficacy of our method\non complex datasets with multiple foreground object instances by evaluating an\nextension of our method on the challenging Virtual-KITTI dataset. Source code\nand models are available at https://github.com/1jsingh/semantic-guidance.",
          "link": "http://arxiv.org/abs/2011.12589",
          "publishedOn": "2021-06-16T01:21:11.144Z",
          "wordCount": 728,
          "title": "Combining Semantic Guidance and Deep Reinforcement Learning For Generating Human Level Paintings. (arXiv:2011.12589v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08314",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vorbach_C/0/1/0/all/0/1\">Charles Vorbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasani_R/0/1/0/all/0/1\">Ramin Hasani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amini_A/0/1/0/all/0/1\">Alexander Amini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lechner_M/0/1/0/all/0/1\">Mathias Lechner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rus_D/0/1/0/all/0/1\">Daniela Rus</a>",
          "description": "Imitation learning enables high-fidelity, vision-based learning of policies\nwithin rich, photorealistic environments. However, such techniques often rely\non traditional discrete-time neural models and face difficulties in\ngeneralizing to domain shifts by failing to account for the causal\nrelationships between the agent and the environment. In this paper, we propose\na theoretical and experimental framework for learning causal representations\nusing continuous-time neural networks, specifically over their discrete-time\ncounterparts. We evaluate our method in the context of visual-control learning\nof drones over a series of complex tasks, ranging from short- and long-term\nnavigation, to chasing static and dynamic objects through photorealistic\nenvironments. Our results demonstrate that causal continuous-time deep models\ncan perform robust navigation tasks, where advanced recurrent models fail.\nThese models learn complex causal control representations directly from raw\nvisual inputs and scale to solve a variety of tasks using imitation learning.",
          "link": "http://arxiv.org/abs/2106.08314",
          "publishedOn": "2021-06-16T01:21:11.123Z",
          "wordCount": 578,
          "title": "Causal Navigation by Continuous-time Neural Networks. (arXiv:2106.08314v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2104.13970",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Rikhye_R/0/1/0/all/0/1\">Rajeev Rikhye</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_Q/0/1/0/all/0/1\">Quan Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liang_Q/0/1/0/all/0/1\">Qiao Liang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+He_Y/0/1/0/all/0/1\">Yanzhang He</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhao_D/0/1/0/all/0/1\">Ding Zhao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yiteng/0/1/0/all/0/1\">Yiteng</a> (Arden) <a href=\"http://arxiv.org/find/eess/1/au:+Huang/0/1/0/all/0/1\">Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Narayanan_A/0/1/0/all/0/1\">Arun Narayanan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+McGraw_I/0/1/0/all/0/1\">Ian McGraw</a>",
          "description": "In this paper, we introduce a streaming keyphrase detection system that can\nbe easily customized to accurately detect any phrase composed of words from a\nlarge vocabulary. The system is implemented with an end-to-end trained\nautomatic speech recognition (ASR) model and a text-independent speaker\nverification model. To address the challenge of detecting these keyphrases\nunder various noisy conditions, a speaker separation model is added to the\nfeature frontend of the speaker verification model, and an adaptive noise\ncancellation (ANC) algorithm is included to exploit cross-microphone noise\ncoherence. Our experiments show that the text-independent speaker verification\nmodel largely reduces the false triggering rate of the keyphrase detection,\nwhile the speaker separation model and adaptive noise cancellation largely\nreduce false rejections.",
          "link": "http://arxiv.org/abs/2104.13970",
          "publishedOn": "2021-06-16T01:21:11.104Z",
          "wordCount": 583,
          "title": "Personalized Keyphrase Detection using Speaker and Environment Information. (arXiv:2104.13970v2 [eess.AS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.02095",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Beknazaryan_A/0/1/0/all/0/1\">Aleksandr Beknazaryan</a>",
          "description": "We provide an entropy bound for the spaces of path norm regularized neural\nnetworks with piecewise linear activation functions, such as the ReLU and the\nabsolute value functions. This bound generalizes the known entropy bound for\nthe spaces of linear functions on $\\mathbb{R}^d$. Keeping the path norm\ntogether with the depth, width and the weights of networks to have logarithmic\ndependence on $1/\\varepsilon$, we $\\varepsilon$-approximate functions that are\nanalytic on certain regions of $\\mathbb{C}^d$.",
          "link": "http://arxiv.org/abs/2104.02095",
          "publishedOn": "2021-06-16T01:21:11.045Z",
          "wordCount": 524,
          "title": "Analytic function approximation by path norm regularized deep networks. (arXiv:2104.02095v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1912.04177",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bakshi_A/0/1/0/all/0/1\">Ainesh Bakshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chepurko_N/0/1/0/all/0/1\">Nadiia Chepurko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1\">David P. Woodruff</a>",
          "description": "Recently, Musco and Woodruff (FOCS, 2017) showed that given an $n \\times n$\npositive semidefinite (PSD) matrix $A$, it is possible to compute a\n$(1+\\epsilon)$-approximate relative-error low-rank approximation to $A$ by\nquerying $O(nk/\\epsilon^{2.5})$ entries of $A$ in time $O(nk/\\epsilon^{2.5} +n\nk^{\\omega-1}/\\epsilon^{2(\\omega-1)})$. They also showed that any relative-error\nlow-rank approximation algorithm must query $\\Omega(nk/\\epsilon)$ entries of\n$A$, this gap has since remained open. Our main result is to resolve this\nquestion by obtaining an optimal algorithm that queries $O(nk/\\epsilon)$\nentries of $A$ and outputs a relative-error low-rank approximation in\n$O(n(k/\\epsilon)^{\\omega-1})$ time. Note, our running time improves that of\nMusco and Woodruff, and matches the information-theoretic lower bound if the\nmatrix-multiplication exponent $\\omega$ is $2$.\n\nWe then extend our techniques to negative-type distance matrices. Bakshi and\nWoodruff (NeurIPS, 2018) showed a bi-criteria, relative-error low-rank\napproximation which queries $O(nk/\\epsilon^{2.5})$ entries and outputs a\nrank-$(k+4)$ matrix. We show that the bi-criteria guarantee is not necessary\nand obtain an $O(nk/\\epsilon)$ query algorithm, which is optimal. Our algorithm\napplies to all distance matrices that arise from metrics satisfying\nnegative-type inequalities, including $\\ell_1, \\ell_2,$ spherical metrics and\nhypermetrics.\n\nNext, we introduce a new robust low-rank approximation model which captures\nPSD matrices that have been corrupted with noise. While a sample complexity\nlower bound precludes sublinear algorithms for arbitrary PSD matrices, we\nprovide the first sublinear time and query algorithms when the corruption on\nthe diagonal entries is bounded. As a special case, we show sample-optimal\nsublinear time algorithms for low-rank approximation of correlation matrices\ncorrupted by noise.",
          "link": "http://arxiv.org/abs/1912.04177",
          "publishedOn": "2021-06-16T01:21:11.035Z",
          "wordCount": 745,
          "title": "Robust and Sample Optimal Algorithms for PSD Low-Rank Approximation. (arXiv:1912.04177v5 [cs.DS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2002.07687",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1\">Zhichuang Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1\">Ruimin Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_L/0/1/0/all/0/1\">Long Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mislove_A/0/1/0/all/0/1\">Alan Mislove</a>",
          "description": "On-device machine learning (ML) is quickly gaining popularity among mobile\napps. It allows offline model inference while preserving user privacy. However,\nML models, considered as core intellectual properties of model owners, are now\nstored on billions of untrusted devices and subject to potential thefts. Leaked\nmodels can cause both severe financial loss and security consequences. This\npaper presents the first empirical study of ML model protection on mobile\ndevices. Our study aims to answer three open questions with quantitative\nevidence: How widely is model protection used in apps? How robust are existing\nmodel protection techniques? What impacts can (stolen) models incur? To that\nend, we built a simple app analysis pipeline and analyzed 46,753 popular apps\ncollected from the US and Chinese app markets. We identified 1,468 ML apps\nspanning all popular app categories. We found that, alarmingly, 41% of ML apps\ndo not protect their models at all, which can be trivially stolen from app\npackages. Even for those apps that use model protection or encryption, we were\nable to extract the models from 66% of them via unsophisticated dynamic\nanalysis techniques. The extracted models are mostly commercial products and\nused for face recognition, liveness detection, ID/bank card recognition, and\nmalware detection. We quantitatively estimated the potential financial and\nsecurity impact of a leaked model, which can amount to millions of dollars for\ndifferent stakeholders. Our study reveals that on-device models are currently\nat high risk of being leaked; attackers are highly motivated to steal such\nmodels. Drawn from our large-scale study, we report our insights into this\nemerging security problem and discuss the technical challenges, hoping to\ninspire future research on robust and practical model protection for mobile\ndevices.",
          "link": "http://arxiv.org/abs/2002.07687",
          "publishedOn": "2021-06-16T01:21:11.018Z",
          "wordCount": 758,
          "title": "Mind Your Weight(s): A Large-scale Study on Insufficient Machine Learning Model Protection in Mobile Apps. (arXiv:2002.07687v2 [cs.CR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.11066",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1\">Chenyu You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1\">Nuo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1\">Yuexian Zou</a>",
          "description": "Spoken conversational question answering (SCQA) requires machines to model\ncomplex dialogue flow given the speech utterances and text corpora. Different\nfrom traditional text question answering (QA) tasks, SCQA involves audio signal\nprocessing, passage comprehension, and contextual understanding. However, ASR\nsystems introduce unexpected noisy signals to the transcriptions, which result\nin performance degradation on SCQA. To overcome the problem, we propose CADNet,\na novel contextualized attention-based distillation approach, which applies\nboth cross-attention and self-attention to obtain ASR-robust contextualized\nembedding representations of the passage and dialogue history for performance\nimprovements. We also introduce the spoken conventional knowledge distillation\nframework to distill the ASR-robust knowledge from the estimated probabilities\nof the teacher model to the student. We conduct extensive experiments on the\nSpoken-CoQA dataset and demonstrate that our approach achieves remarkable\nperformance in this task.",
          "link": "http://arxiv.org/abs/2010.11066",
          "publishedOn": "2021-06-16T01:21:11.011Z",
          "wordCount": 616,
          "title": "Contextualized Attention-based Knowledge Transfer for Spoken Conversational Question Answering. (arXiv:2010.11066v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1903.05631",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1\">Bing Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1\">Haoteng Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1\">Zhanxing Zhu</a>",
          "description": "The spatio-temporal graph learning is becoming an increasingly important\nobject of graph study. Many application domains involve highly dynamic graphs\nwhere temporal information is crucial, e.g. traffic networks and financial\ntransaction graphs. Despite the constant progress made on learning structured\ndata, there is still a lack of effective means to extract dynamic complex\nfeatures from spatio-temporal structures. Particularly, conventional models\nsuch as convolutional networks or recurrent neural networks are incapable of\nrevealing the temporal patterns in short or long terms and exploring the\nspatial properties in local or global scope from spatio-temporal graphs\nsimultaneously. To tackle this problem, we design a novel multi-scale\narchitecture, Spatio-Temporal U-Net (ST-UNet), for graph-structured time series\nmodeling. In this U-shaped network, a paired sampling operation is proposed in\nspacetime domain accordingly: the pooling (ST-Pool) coarsens the input graph in\nspatial from its deterministic partition while abstracts multi-resolution\ntemporal dependencies through dilated recurrent skip connections; based on\nprevious settings in the downsampling, the unpooling (ST-Unpool) restores the\noriginal structure of spatio-temporal graphs and resumes regular intervals\nwithin graph sequences. Experiments on spatio-temporal prediction tasks\ndemonstrate that our model effectively captures comprehensive features in\nmultiple scales and achieves substantial improvements over mainstream methods\non several real-world datasets.",
          "link": "http://arxiv.org/abs/1903.05631",
          "publishedOn": "2021-06-16T01:21:11.004Z",
          "wordCount": 657,
          "title": "ST-UNet: A Spatio-Temporal U-Network for Graph-structured Time Series Modeling. (arXiv:1903.05631v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.01271",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chao-Han Huck Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siniscalchi_S/0/1/0/all/0/1\">Sabato Marco Siniscalchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1\">Chin-Hui Lee</a>",
          "description": "We propose using an adversarial autoencoder (AAE) to replace generative\nadversarial network (GAN) in the private aggregation of teacher ensembles\n(PATE), a solution for ensuring differential privacy in speech applications.\nThe AAE architecture allows us to obtain good synthetic speech leveraging upon\na discriminative training of latent vectors. Such synthetic speech is used to\nbuild a privacy-preserving classifier when non-sensitive data is not\nsufficiently available in the public domain. This classifier follows the PATE\nscheme that uses an ensemble of noisy outputs to label the synthetic samples\nand guarantee $\\varepsilon$-differential privacy (DP) on its derived\nclassifiers. Our proposed framework thus consists of an AAE-based generator and\na PATE-based classifier (PATE-AAE). Evaluated on the Google Speech Commands\nDataset Version II, the proposed PATE-AAE improves the average classification\naccuracy by +$2.11\\%$ and +$6.60\\%$, respectively, when compared with\nalternative privacy-preserving solutions, namely PATE-GAN and DP-GAN, while\nmaintaining a strong level of privacy target at $\\varepsilon$=0.01 with a fixed\n$\\delta$=10$^{-5}$.",
          "link": "http://arxiv.org/abs/2104.01271",
          "publishedOn": "2021-06-16T01:21:10.997Z",
          "wordCount": 646,
          "title": "PATE-AAE: Incorporating Adversarial Autoencoder into Private Aggregation of Teacher Ensembles for Spoken Command Classification. (arXiv:2104.01271v2 [cs.SD] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.07002",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dar_Y/0/1/0/all/0/1\">Yehuda Dar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baraniuk_R/0/1/0/all/0/1\">Richard G. Baraniuk</a>",
          "description": "We study the transfer learning process between two linear regression\nproblems. An important and timely special case is when the regressors are\noverparameterized and perfectly interpolate their training data. We examine a\nparameter transfer mechanism whereby a subset of the parameters of the target\ntask solution are constrained to the values learned for a related source task.\nWe analytically characterize the generalization error of the target task in\nterms of the salient factors in the transfer learning architecture, i.e., the\nnumber of examples available, the number of (free) parameters in each of the\ntasks, the number of parameters transferred from the source to target task, and\nthe correlation between the two tasks. Our non-asymptotic analysis shows that\nthe generalization error of the target task follows a two-dimensional double\ndescent trend (with respect to the number of free parameters in each of the\ntasks) that is controlled by the transfer learning factors. Our analysis points\nto specific cases where the transfer of parameters is beneficial. Specifically,\nwe show that transferring a specific set of parameters that generalizes well on\nthe respective part of the source task can soften the demand on the task\ncorrelation level that is required for successful transfer learning. Moreover,\nwe show that the usefulness of a transfer learning setting is fragile and\ndepends on a delicate interplay among the set of transferred parameters, the\nrelation between the tasks, and the true solution.",
          "link": "http://arxiv.org/abs/2006.07002",
          "publishedOn": "2021-06-16T01:21:10.971Z",
          "wordCount": 727,
          "title": "Double Double Descent: On Generalization Errors in Transfer Learning between Linear Regression Tasks. (arXiv:2006.07002v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.04975",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Immer_A/0/1/0/all/0/1\">Alexander Immer</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bauer_M/0/1/0/all/0/1\">Matthias Bauer</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fortuin_V/0/1/0/all/0/1\">Vincent Fortuin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ratsch_G/0/1/0/all/0/1\">Gunnar R&#xe4;tsch</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Khan_M/0/1/0/all/0/1\">Mohammad Emtiyaz Khan</a>",
          "description": "Marginal-likelihood based model-selection, even though promising, is rarely\nused in deep learning due to estimation difficulties. Instead, most approaches\nrely on validation data, which may not be readily available. In this work, we\npresent a scalable marginal-likelihood estimation method to select both\nhyperparameters and network architectures, based on the training data alone.\nSome hyperparameters can be estimated online during training, simplifying the\nprocedure. Our marginal-likelihood estimate is based on Laplace's method and\nGauss-Newton approximations to the Hessian, and it outperforms cross-validation\nand manual-tuning on standard regression and image classification datasets,\nespecially in terms of calibration and out-of-distribution detection. Our work\nshows that marginal likelihoods can improve generalization and be useful when\nvalidation data is unavailable (e.g., in nonstationary settings).",
          "link": "http://arxiv.org/abs/2104.04975",
          "publishedOn": "2021-06-16T01:21:10.956Z",
          "wordCount": 583,
          "title": "Scalable Marginal Likelihood Estimation for Model Selection in Deep Learning. (arXiv:2104.04975v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.12321",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shu_T/0/1/0/all/0/1\">Tianmin Shu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhandwaldar_A/0/1/0/all/0/1\">Abhishek Bhandwaldar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_C/0/1/0/all/0/1\">Chuang Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_K/0/1/0/all/0/1\">Kevin A. Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shari Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gutfreund_D/0/1/0/all/0/1\">Dan Gutfreund</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spelke_E/0/1/0/all/0/1\">Elizabeth Spelke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1\">Joshua B. Tenenbaum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ullman_T/0/1/0/all/0/1\">Tomer D. Ullman</a>",
          "description": "For machine agents to successfully interact with humans in real-world\nsettings, they will need to develop an understanding of human mental life.\nIntuitive psychology, the ability to reason about hidden mental variables that\ndrive observable actions, comes naturally to people: even pre-verbal infants\ncan tell agents from objects, expecting agents to act efficiently to achieve\ngoals given constraints. Despite recent interest in machine agents that reason\nabout other agents, it is not clear if such agents learn or hold the core\npsychology principles that drive human reasoning. Inspired by cognitive\ndevelopment studies on intuitive psychology, we present a benchmark consisting\nof a large dataset of procedurally generated 3D animations, AGENT (Action,\nGoal, Efficiency, coNstraint, uTility), structured around four scenarios (goal\npreferences, action efficiency, unobserved constraints, and cost-reward\ntrade-offs) that probe key concepts of core intuitive psychology. We validate\nAGENT with human-ratings, propose an evaluation protocol emphasizing\ngeneralization, and compare two strong baselines built on Bayesian inverse\nplanning and a Theory of Mind neural network. Our results suggest that to pass\nthe designed tests of core intuitive psychology at human levels, a model must\nacquire or have built-in representations of how agents plan, combining utility\ncomputations and core knowledge of objects and physics.",
          "link": "http://arxiv.org/abs/2102.12321",
          "publishedOn": "2021-06-16T01:21:10.940Z",
          "wordCount": 697,
          "title": "AGENT: A Benchmark for Core Psychological Reasoning. (arXiv:2102.12321v3 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.05541",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Thornton_C/0/1/0/all/0/1\">Charles E. Thornton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buehrer_R/0/1/0/all/0/1\">R. Michael Buehrer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martone_A/0/1/0/all/0/1\">Anthony F. Martone</a>",
          "description": "A sequential decision process in which an adaptive radar system repeatedly\ninteracts with a finite-state target channel is studied. The radar is capable\nof passively sensing the spectrum at regular intervals, which provides side\ninformation for the waveform selection process. The radar transmitter uses the\nsequence of spectrum observations as well as feedback from a collocated\nreceiver to select waveforms which accurately estimate target parameters. It is\nshown that the waveform selection problem can be effectively addressed using a\nlinear contextual bandit formulation in a manner that is both computationally\nfeasible and sample efficient. Stochastic and adversarial linear contextual\nbandit models are introduced, allowing the radar to achieve effective\nperformance in broad classes of physical environments. Simulations in a\nradar-communication coexistence scenario, as well as in an adversarial\nradar-jammer scenario, demonstrate that the proposed formulation provides a\nsubstantial improvement in target detection performance when Thompson Sampling\nand EXP3 algorithms are used to drive the waveform selection process. Further,\nit is shown that the harmful impacts of pulse-agile behavior on coherently\nprocessed radar data can be mitigated by adopting a time-varying constraint on\nthe radar's waveform catalog.",
          "link": "http://arxiv.org/abs/2103.05541",
          "publishedOn": "2021-06-16T01:21:10.922Z",
          "wordCount": 665,
          "title": "Constrained Contextual Bandit Learning for Adaptive Radar Waveform Selection. (arXiv:2103.05541v2 [cs.IT] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.00774",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Alvarez_Melis_D/0/1/0/all/0/1\">David Alvarez-Melis</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Schiff_Y/0/1/0/all/0/1\">Yair Schiff</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mroueh_Y/0/1/0/all/0/1\">Youssef Mroueh</a>",
          "description": "Gradient flows are a powerful tool for optimizing functionals in general\nmetric spaces, including the space of probabilities endowed with the\nWasserstein metric. A typical approach to solving this optimization problem\nrelies on its connection to the dynamic formulation of optimal transport and\nthe celebrated Jordan-Kinderlehrer-Otto (JKO) scheme. However, this formulation\ninvolves optimization over convex functions, which is challenging, especially\nin high dimensions. In this work, we propose an approach that relies on the\nrecently introduced input-convex neural networks (ICNN) to parameterize the\nspace of convex functions in order to approximate the JKO scheme, as well as in\ndesigning functionals over measures that enjoy convergence guarantees. We\nderive a computationally efficient implementation of this JKO-ICNN framework\nand use various experiments to demonstrate its feasibility and validity in\napproximating solutions of low-dimensional partial differential equations with\nknown solutions. We also explore the use of our JKO-ICNN approach in high\ndimensions with an experiment in controlled generation for molecular discovery.",
          "link": "http://arxiv.org/abs/2106.00774",
          "publishedOn": "2021-06-16T01:21:10.876Z",
          "wordCount": 615,
          "title": "Optimizing Functionals on the Space of Probabilities with Input Convex Neural Networks. (arXiv:2106.00774v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.06064",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yongyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yangkun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jinjing Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_Q/0/1/0/all/0/1\">Quan Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1\">Zhewei Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zengfeng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wipf_D/0/1/0/all/0/1\">David Wipf</a>",
          "description": "Despite the recent success of graph neural networks (GNN), common\narchitectures often exhibit significant limitations, including sensitivity to\noversmoothing, long-range dependencies, and spurious edges, e.g., as can occur\nas a result of graph heterophily or adversarial attacks. To at least partially\naddress these issues within a simple transparent framework, we consider a new\nfamily of GNN layers designed to mimic and integrate the update rules of two\nclassical iterative algorithms, namely, proximal gradient descent and iterative\nreweighted least squares (IRLS). The former defines an extensible base GNN\narchitecture that is immune to oversmoothing while nonetheless capturing\nlong-range dependencies by allowing arbitrary propagation steps. In contrast,\nthe latter produces a novel attention mechanism that is explicitly anchored to\nan underlying end-to-end energy function, contributing stability with respect\nto edge uncertainty. When combined we obtain an extremely simple yet robust\nmodel that we evaluate across disparate scenarios including standardized\nbenchmarks, adversarially-perturbated graphs, graphs with heterophily, and\ngraphs involving long-range dependencies. In doing so, we compare against SOTA\nGNN approaches that have been explicitly designed for the respective task,\nachieving competitive or superior node classification accuracy. Our code is\navailable at https://github.com/FFTYYY/TWIRLS.",
          "link": "http://arxiv.org/abs/2103.06064",
          "publishedOn": "2021-06-16T01:21:10.870Z",
          "wordCount": 664,
          "title": "Graph Neural Networks Inspired by Classical Iterative Algorithms. (arXiv:2103.06064v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1909.06723",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaosen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_H/0/1/0/all/0/1\">Hao Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yichen Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_K/0/1/0/all/0/1\">Kun He</a>",
          "description": "In the area of natural language processing, deep learning models are recently\nknown to be vulnerable to various types of adversarial perturbations, but\nrelatively few works are done on the defense side. Especially, there exists few\neffective defense method against the successful synonym substitution based\nattacks that preserve the syntactic structure and semantic information of the\noriginal text while fooling the deep learning models. We contribute in this\ndirection and propose a novel adversarial defense method called Synonym\nEncoding Method (SEM). Specifically, SEM inserts an encoder before the input\nlayer of the target model to map each cluster of synonyms to a unique encoding\nand trains the model to eliminate possible adversarial perturbations without\nmodifying the network architecture or adding extra data. Extensive experiments\ndemonstrate that SEM can effectively defend the current synonym substitution\nbased attacks and block the transferability of adversarial examples. SEM is\nalso easy and efficient to scale to large models and big datasets.",
          "link": "http://arxiv.org/abs/1909.06723",
          "publishedOn": "2021-06-16T01:21:10.863Z",
          "wordCount": 643,
          "title": "Natural Language Adversarial Defense through Synonym Encoding. (arXiv:1909.06723v4 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.07367",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Khanduri_P/0/1/0/all/0/1\">Prashant Khanduri</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zeng_S/0/1/0/all/0/1\">Siliang Zeng</a>, <a href=\"http://arxiv.org/find/math/1/au:+Hong_M/0/1/0/all/0/1\">Mingyi Hong</a>, <a href=\"http://arxiv.org/find/math/1/au:+Wai_H/0/1/0/all/0/1\">Hoi-To Wai</a>, <a href=\"http://arxiv.org/find/math/1/au:+Wang_Z/0/1/0/all/0/1\">Zhaoran Wang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Yang_Z/0/1/0/all/0/1\">Zhuoran Yang</a>",
          "description": "This paper proposes a new algorithm -- the \\underline{S}ingle-timescale\nDo\\underline{u}ble-momentum \\underline{St}ochastic\n\\underline{A}pprox\\underline{i}matio\\underline{n} (SUSTAIN) -- for tackling\nstochastic unconstrained bilevel optimization problems. We focus on bilevel\nproblems where the lower level subproblem is strongly-convex and the upper\nlevel objective function is smooth. Unlike prior works which rely on\n\\emph{two-timescale} or \\emph{double loop} techniques, we design a stochastic\nmomentum-assisted gradient estimator for both the upper and lower level\nupdates. The latter allows us to control the error in the stochastic gradient\nupdates due to inaccurate solution to both subproblems. If the upper objective\nfunction is smooth but possibly non-convex, we show that {\\aname}~requires\n$\\mathcal{O}(\\epsilon^{-3/2})$ iterations (each using ${\\cal O}(1)$ samples) to\nfind an $\\epsilon$-stationary solution. The $\\epsilon$-stationary solution is\ndefined as the point whose squared norm of the gradient of the outer function\nis less than or equal to $\\epsilon$. The total number of stochastic gradient\nsamples required for the upper and lower level objective functions matches the\nbest-known complexity for single-level stochastic gradient algorithms. We also\nanalyze the case when the upper level objective function is strongly-convex.",
          "link": "http://arxiv.org/abs/2102.07367",
          "publishedOn": "2021-06-16T01:21:10.857Z",
          "wordCount": 648,
          "title": "A Near-Optimal Algorithm for Stochastic Bilevel Optimization via Double-Momentum. (arXiv:2102.07367v3 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08318",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Malinowski_M/0/1/0/all/0/1\">Mateusz Malinowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vytiniotis_D/0/1/0/all/0/1\">Dimitrios Vytiniotis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swirszcz_G/0/1/0/all/0/1\">Grzegorz Swirszcz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patraucean_V/0/1/0/all/0/1\">Viorica Patraucean</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carreira_J/0/1/0/all/0/1\">Joao Carreira</a>",
          "description": "How can neural networks be trained on large-volume temporal data efficiently?\nTo compute the gradients required to update parameters, backpropagation blocks\ncomputations until the forward and backward passes are completed. For temporal\nsignals, this introduces high latency and hinders real-time learning. It also\ncreates a coupling between consecutive layers, which limits model parallelism\nand increases memory consumption. In this paper, we build upon Sideways, which\navoids blocking by propagating approximate gradients forward in time, and we\npropose mechanisms for temporal integration of information based on different\nvariants of skip connections. We also show how to decouple computation and\ndelegate individual neural modules to different devices, allowing distributed\nand parallel training. The proposed Skip-Sideways achieves low latency\ntraining, model parallelism, and, importantly, is capable of extracting\ntemporal features, leading to more stable training and improved performance on\nreal-world action recognition video datasets such as HMDB51, UCF101, and the\nlarge-scale Kinetics-600. Finally, we also show that models trained with\nSkip-Sideways generate better future frames than Sideways models, and hence\nthey can better utilize motion cues.",
          "link": "http://arxiv.org/abs/2106.08318",
          "publishedOn": "2021-06-16T01:21:10.797Z",
          "wordCount": 632,
          "title": "Gradient Forward-Propagation for Large-Scale Temporal Video Modelling. (arXiv:2106.08318v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07916",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Duboudin_T/0/1/0/all/0/1\">Thomas Duboudin</a> (imagine), <a href=\"http://arxiv.org/find/cs/1/au:+Dellandrea_E/0/1/0/all/0/1\">Emmanuel Dellandr&#xe9;a</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abgrall_C/0/1/0/all/0/1\">Corentin Abgrall</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henaff_G/0/1/0/all/0/1\">Gilles H&#xe9;naff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Liming Chen</a>",
          "description": "Traditional deep learning algorithms often fail to generalize when they are\ntested outside of the domain of training data. Because data distributions can\nchange dynamically in real-life applications once a learned model is deployed,\nin this paper we are interested in single-source domain generalization (SDG)\nwhich aims to develop deep learning algorithms able to generalize from a single\ntraining domain where no information about the test domain is available at\ntraining time. Firstly, we design two simple MNISTbased SDG benchmarks, namely\nMNIST Color SDG-MP and MNIST Color SDG-UP, which highlight the two different\nfundamental SDG issues of increasing difficulties: 1) a class-correlated\npattern in the training domain is missing (SDG-MP), or 2) uncorrelated with the\nclass (SDG-UP), in the testing data domain. This is in sharp contrast with the\ncurrent domain generalization (DG) benchmarks which mix up different\ncorrelation and variation factors and thereby make hard to disentangle success\nor failure factors when benchmarking DG algorithms. We further evaluate several\nstate-of-the-art SDG algorithms through our simple benchmark, namely MNIST\nColor SDG-MP, and show that the issue SDG-MP is largely unsolved despite of a\ndecade of efforts in developing DG algorithms. Finally, we also propose a\npartially reversed contrastive loss to encourage intra-class diversity and find\nless strongly correlated patterns, to deal with SDG-MP and show that the\nproposed approach is very effective on our MNIST Color SDG-MP benchmark.",
          "link": "http://arxiv.org/abs/2106.07916",
          "publishedOn": "2021-06-16T01:21:10.753Z",
          "wordCount": 678,
          "title": "Encouraging Intra-Class Diversity Through a Reverse Contrastive Loss for Better Single-Source Domain Generalization. (arXiv:2106.07916v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2104.02397",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Gerazov_B/0/1/0/all/0/1\">Branislav Gerazov</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wagner_M/0/1/0/all/0/1\">Michael Wagner</a>",
          "description": "The labelling of speech corpora is a laborious and time-consuming process.\nThe ProsoBeast Annotation Tool seeks to ease and accelerate this process by\nproviding an interactive 2D representation of the prosodic landscape of the\ndata, in which contours are distributed based on their similarity. This\ninteractive map allows the user to inspect and label the utterances. The tool\nintegrates several state-of-the-art methods for dimensionality reduction and\nfeature embedding, including variational autoencoders. The user can use these\nto find a good representation for their data. In addition, as most of these\nmethods are stochastic, each can be used to generate an unlimited number of\ndifferent prosodic maps. The web app then allows the user to seamlessly switch\nbetween these alternative representations in the annotation process.\nExperiments with a sample prosodically rich dataset have shown that the tool\nmanages to find good representations of varied data and is helpful both for\nannotation and label correction. The tool is released as free software for use\nby the community.",
          "link": "http://arxiv.org/abs/2104.02397",
          "publishedOn": "2021-06-16T01:21:10.731Z",
          "wordCount": 610,
          "title": "ProsoBeast Prosody Annotation Tool. (arXiv:2104.02397v2 [eess.AS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.02469",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Karra_K/0/1/0/all/0/1\">Kiran Karra</a>, <a href=\"http://arxiv.org/find/eess/1/au:+McCree_A/0/1/0/all/0/1\">Alan McCree</a>",
          "description": "Many modern systems for speaker diarization, such as the recently-developed\nVBx approach, rely on clustering of DNN speaker embeddings followed by\nresegmentation. Two problems with this approach are that the DNN is not\ndirectly optimized for this task, and the parameters need significant retuning\nfor different applications. We have recently presented progress in this\ndirection with a Leave-One-Out Gaussian PLDA (LGP) clustering algorithm and an\napproach to training the DNN such that embeddings directly optimize performance\nof this scoring method. This paper presents a new two-pass version of this\nsystem, where the second pass uses finer time resolution to significantly\nimprove overall performance. For the Callhome corpus, we achieve the first\npublished error rate below 4% without any task-dependent parameter tuning. We\nalso show significant progress towards a robust single solution for multiple\ndiarization tasks.",
          "link": "http://arxiv.org/abs/2104.02469",
          "publishedOn": "2021-06-16T01:21:10.709Z",
          "wordCount": 612,
          "title": "Speaker Diarization using Two-pass Leave-One-Out Gaussian PLDA Clustering of DNN Embeddings. (arXiv:2104.02469v3 [eess.AS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.12535",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Usman_M/0/1/0/all/0/1\">Muhammad Usman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gopinath_D/0/1/0/all/0/1\">Divya Gopinath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Youcheng Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noller_Y/0/1/0/all/0/1\">Yannic Noller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pasareanu_C/0/1/0/all/0/1\">Corina Pasareanu</a>",
          "description": "We present NNrepair, a constraint-based technique for repairing neural\nnetwork classifiers. The technique aims to fix the logic of the network at an\nintermediate layer or at the last layer. NNrepair first uses fault localization\nto find potentially faulty network parameters (such as the weights) and then\nperforms repair using constraint solving to apply small modifications to the\nparameters to remedy the defects. We present novel strategies to enable precise\nyet efficient repair such as inferring correctness specifications to act as\noracles for intermediate layer repair, and generation of experts for each\nclass. We demonstrate the technique in the context of three different\nscenarios: (1) Improving the overall accuracy of a model, (2) Fixing security\nvulnerabilities caused by poisoning of training data and (3) Improving the\nrobustness of the network against adversarial attacks. Our evaluation on MNIST\nand CIFAR-10 models shows that NNrepair can improve the accuracy by 45.56\npercentage points on poisoned data and 10.40 percentage points on adversarial\ndata. NNrepair also provides small improvement in the overall accuracy of\nmodels, without requiring new data or re-training.",
          "link": "http://arxiv.org/abs/2103.12535",
          "publishedOn": "2021-06-16T01:21:10.700Z",
          "wordCount": 637,
          "title": "NNrepair: Constraint-based Repair of Neural Network Classifiers. (arXiv:2103.12535v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.08677",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yue_S/0/1/0/all/0/1\">Sheng Yue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1\">Ju Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xin_J/0/1/0/all/0/1\">Jiang Xin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1\">Sen Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Junshan Zhang</a>",
          "description": "In order to meet the requirements for performance, safety, and latency in\nmany IoT applications, intelligent decisions must be made right here right now\nat the network edge. However, the constrained resources and limited local data\namount pose significant challenges to the development of edge AI. To overcome\nthese challenges, we explore continual edge learning capable of leveraging the\nknowledge transfer from previous tasks. Aiming to achieve fast and continual\nedge learning, we propose a platform-aided federated meta-learning architecture\nwhere edge nodes collaboratively learn a meta-model, aided by the knowledge\ntransfer from prior tasks. The edge learning problem is cast as a regularized\noptimization problem, where the valuable knowledge learned from previous tasks\nis extracted as regularization. Then, we devise an ADMM based federated\nmeta-learning algorithm, namely ADMM-FedMeta, where ADMM offers a natural\nmechanism to decompose the original problem into many subproblems which can be\nsolved in parallel across edge nodes and the platform. Further, a variant of\ninexact-ADMM method is employed where the subproblems are `solved' via linear\napproximation as well as Hessian estimation to reduce the computational cost\nper round to $\\mathcal{O}(n)$. We provide a comprehensive analysis of\nADMM-FedMeta, in terms of the convergence properties, the rapid adaptation\nperformance, and the forgetting effect of prior knowledge transfer, for the\ngeneral non-convex case. Extensive experimental studies demonstrate the\neffectiveness and efficiency of ADMM-FedMeta, and showcase that it\nsubstantially outperforms the existing baselines.",
          "link": "http://arxiv.org/abs/2012.08677",
          "publishedOn": "2021-06-16T01:21:10.617Z",
          "wordCount": null,
          "title": "Inexact-ADMM Based Federated Meta-Learning for Fast and Continual Edge Learning. (arXiv:2012.08677v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.10330",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Raileanu_R/0/1/0/all/0/1\">Roberta Raileanu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fergus_R/0/1/0/all/0/1\">Rob Fergus</a>",
          "description": "Standard deep reinforcement learning algorithms use a shared representation\nfor the policy and value function, especially when training directly from\nimages. However, we argue that more information is needed to accurately\nestimate the value function than to learn the optimal policy. Consequently, the\nuse of a shared representation for the policy and value function can lead to\noverfitting. To alleviate this problem, we propose two approaches which are\ncombined to create IDAAC: Invariant Decoupled Advantage Actor-Critic. First,\nIDAAC decouples the optimization of the policy and value function, using\nseparate networks to model them. Second, it introduces an auxiliary loss which\nencourages the representation to be invariant to task-irrelevant properties of\nthe environment. IDAAC shows good generalization to unseen environments,\nachieving a new state-of-the-art on the Procgen benchmark and outperforming\npopular methods on DeepMind Control tasks with distractors. Our implementation\nis available at https://github.com/rraileanu/idaac.",
          "link": "http://arxiv.org/abs/2102.10330",
          "publishedOn": "2021-06-16T01:21:10.616Z",
          "wordCount": 598,
          "title": "Decoupling Value and Policy for Generalization in Reinforcement Learning. (arXiv:2102.10330v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.00671",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Blum_A/0/1/0/all/0/1\">Avrim Blum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hanneke_S/0/1/0/all/0/1\">Steve Hanneke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_J/0/1/0/all/0/1\">Jian Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_H/0/1/0/all/0/1\">Han Shao</a>",
          "description": "We study the problem of robust learning under clean-label data-poisoning\nattacks, where the attacker injects (an arbitrary set of) correctly-labeled\nexamples to the training set to fool the algorithm into making mistakes on\nspecific test instances at test time. The learning goal is to minimize the\nattackable rate (the probability mass of attackable test instances), which is\nmore difficult than optimal PAC learning. As we show, any robust algorithm with\ndiminishing attackable rate can achieve the optimal dependence on $\\epsilon$ in\nits PAC sample complexity, i.e., $O(1/\\epsilon)$. On the other hand, the\nattackable rate might be large even for some optimal PAC learners, e.g., SVM\nfor linear classifiers. Furthermore, we show that the class of linear\nhypotheses is not robustly learnable when the data distribution has zero margin\nand is robustly learnable in the case of positive margin but requires sample\ncomplexity exponential in the dimension. For a general hypothesis class with\nbounded VC dimension, if the attacker is limited to add at most $t>0$ poison\nexamples, the optimal robust learning sample complexity grows almost linearly\nwith $t$.",
          "link": "http://arxiv.org/abs/2103.00671",
          "publishedOn": "2021-06-16T01:21:10.608Z",
          "wordCount": null,
          "title": "Robust learning under clean-label attack. (arXiv:2103.00671v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.00769",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Berg_A/0/1/0/all/0/1\">Axel Berg</a>, <a href=\"http://arxiv.org/find/eess/1/au:+OConnor_M/0/1/0/all/0/1\">Mark O&#x27;Connor</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cruz_M/0/1/0/all/0/1\">Miguel Tairum Cruz</a>",
          "description": "The Transformer architecture has been successful across many domains,\nincluding natural language processing, computer vision and speech recognition.\nIn keyword spotting, self-attention has primarily been used on top of\nconvolutional or recurrent encoders. We investigate a range of ways to adapt\nthe Transformer architecture to keyword spotting and introduce the Keyword\nTransformer (KWT), a fully self-attentional architecture that exceeds\nstate-of-the-art performance across multiple tasks without any pre-training or\nadditional data. Surprisingly, this simple architecture outperforms more\ncomplex models that mix convolutional, recurrent and attentive layers. KWT can\nbe used as a drop-in replacement for these models, setting two new benchmark\nrecords on the Google Speech Commands dataset with 98.6% and 97.7% accuracy on\nthe 12 and 35-command tasks respectively.",
          "link": "http://arxiv.org/abs/2104.00769",
          "publishedOn": "2021-06-16T01:21:10.607Z",
          "wordCount": null,
          "title": "Keyword Transformer: A Self-Attention Model for Keyword Spotting. (arXiv:2104.00769v3 [eess.AS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1901.10002",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Suresh_H/0/1/0/all/0/1\">Harini Suresh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guttag_J/0/1/0/all/0/1\">John V. Guttag</a>",
          "description": "As machine learning (ML) increasingly affects people and society, awareness\nof its potential unwanted consequences has also grown. To anticipate, prevent,\nand mitigate undesirable downstream consequences, it is critical that we\nunderstand when and how harm might be introduced throughout the ML life cycle.\nIn this paper, we provide a framework that identifies seven distinct potential\nsources of downstream harm in machine learning, spanning data collection,\ndevelopment, and deployment. In doing so, we aim to facilitate more productive\nand precise communication around these issues, as well as more direct,\napplication-grounded ways to mitigate them.",
          "link": "http://arxiv.org/abs/1901.10002",
          "publishedOn": "2021-06-16T01:21:10.491Z",
          "wordCount": 597,
          "title": "A Framework for Understanding Sources of Harm throughout the Machine Learning Life Cycle. (arXiv:1901.10002v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.02203",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cooper_A/0/1/0/all/0/1\">A. Feder Cooper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levy_K/0/1/0/all/0/1\">Karen Levy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sa_C/0/1/0/all/0/1\">Christopher De Sa</a>",
          "description": "Trade-offs between accuracy and efficiency are found in multiple\nnon-computing domains, such as law and public health, which have developed\nrules and heuristics to guide how to balance the two in conditions of\nuncertainty. While accuracy-efficiency trade-offs are also commonly\nacknowledged in some areas of computer science, their policy implications\nremain poorly examined. Drawing on risk assessment practices in the US, we\nargue that, since examining accuracy-efficiency trade-offs has been useful for\nguiding governance in other domains, explicitly framing such trade-offs in\ncomputing is similarly useful for the governance of computer systems. Our\ndiscussion focuses on real-time distributed ML systems; understanding the\npolicy implications in this area is particularly urgent because such systems,\nwhich include autonomous vehicles, tend to be high-stakes and safety-critical.\nWe describe how the trade-off takes shape for these systems, highlight gaps\nbetween existing US risk assessment standards and what these systems require in\norder to be properly assessed, and make specific calls to action to facilitate\naccountability when hypothetical risks become realized as accidents in the real\nworld. We close by discussing how such accountability mechanisms encourage more\njust, transparent governance aligned with public values.",
          "link": "http://arxiv.org/abs/2007.02203",
          "publishedOn": "2021-06-16T01:21:10.464Z",
          "wordCount": 682,
          "title": "Understanding Accuracy-Efficiency Trade-Offs as a Means for Holding Distributed ML Systems Accountable. (arXiv:2007.02203v5 [cs.CY] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08207",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Long Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ravichandran_V/0/1/0/all/0/1\">Venkatesh Ravichandran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stolcke_A/0/1/0/all/0/1\">Andreas Stolcke</a>",
          "description": "Speaker identification in the household scenario (e.g., for smart speakers)\nis typically based on only a few enrollment utterances but a much larger set of\nunlabeled data, suggesting semisupervised learning to improve speaker profiles.\nWe propose a graph-based semi-supervised learning approach for speaker\nidentification in the household scenario, to leverage the unlabeled speech\nsamples. In contrast to most of the works in speaker recognition that focus on\nspeaker-discriminative embeddings, this work focuses on speaker label inference\n(scoring). Given a pre-trained embedding extractor, graph-based learning allows\nus to integrate information about both labeled and unlabeled utterances.\nConsidering each utterance as a graph node, we represent pairwise utterance\nsimilarity scores as edge weights. Graphs are constructed per household, and\nspeaker identities are propagated to unlabeled nodes to optimize a global\nconsistency criterion. We show in experiments on the VoxCeleb dataset that this\napproach makes effective use of unlabeled data and improves speaker\nidentification accuracy compared to two state-of-the-art scoring methods as\nwell as their semi-supervised variants based on pseudo-labels.",
          "link": "http://arxiv.org/abs/2106.08207",
          "publishedOn": "2021-06-16T01:21:10.431Z",
          "wordCount": 599,
          "title": "Graph-based Label Propagation for Semi-Supervised Speaker Identification. (arXiv:2106.08207v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08170",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+DAmario_V/0/1/0/all/0/1\">Vanessa D&#x27;Amario</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sasaki_T/0/1/0/all/0/1\">Tomotake Sasaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boix_X/0/1/0/all/0/1\">Xavier Boix</a>",
          "description": "Neural Module Networks (NMNs) aim at Visual Question Answering (VQA) via\ncomposition of modules that tackle a sub-task. NMNs are a promising strategy to\nachieve systematic generalization, i.e. overcoming biasing factors in the\ntraining distribution. However, the aspects of NMNs that facilitate systematic\ngeneralization are not fully understood. In this paper, we demonstrate that the\nstage and the degree at which modularity is defined has large influence on\nsystematic generalization. In a series of experiments on three VQA datasets\n(MNIST with multiple attributes, SQOOP, and CLEVR-CoGenT), our results reveal\nthat tuning the degree of modularity in the network, especially at the image\nencoder stage, reaches substantially higher systematic generalization. These\nfindings lead to new NMN architectures that outperform previous ones in terms\nof systematic generalization.",
          "link": "http://arxiv.org/abs/2106.08170",
          "publishedOn": "2021-06-16T01:21:10.424Z",
          "wordCount": 557,
          "title": "How Modular Should Neural Module Networks Be for Systematic Generalization?. (arXiv:2106.08170v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08185",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Simpson_F/0/1/0/all/0/1\">Fergus Simpson</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Davies_I/0/1/0/all/0/1\">Ian Davies</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lalchand_V/0/1/0/all/0/1\">Vidhi Lalchand</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vullo_A/0/1/0/all/0/1\">Alessandro Vullo</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Durrande_N/0/1/0/all/0/1\">Nicolas Durrande</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rasmussen_C/0/1/0/all/0/1\">Carl Rasmussen</a>",
          "description": "Kernel selection plays a central role in determining the performance of\nGaussian Process (GP) models, as the chosen kernel determines both the\ninductive biases and prior support of functions under the GP prior. This work\naddresses the challenge of constructing custom kernel functions for\nhigh-dimensional GP regression models. Drawing inspiration from recent progress\nin deep learning, we introduce a novel approach named KITT: Kernel\nIdentification Through Transformers. KITT exploits a transformer-based\narchitecture to generate kernel recommendations in under 0.1 seconds, which is\nseveral orders of magnitude faster than conventional kernel search algorithms.\nWe train our model using synthetic data generated from priors over a vocabulary\nof known kernels. By exploiting the nature of the self-attention mechanism,\nKITT is able to process datasets with inputs of arbitrary dimension. We\ndemonstrate that kernels chosen by KITT yield strong performance over a diverse\ncollection of regression benchmarks.",
          "link": "http://arxiv.org/abs/2106.08185",
          "publishedOn": "2021-06-16T01:21:10.417Z",
          "wordCount": 573,
          "title": "Kernel Identification Through Transformers. (arXiv:2106.08185v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08320",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Li_Y/0/1/0/all/0/1\">Yazhe Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pogodin_R/0/1/0/all/0/1\">Roman Pogodin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sutherland_D/0/1/0/all/0/1\">Danica J. Sutherland</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gretton_A/0/1/0/all/0/1\">Arthur Gretton</a>",
          "description": "We approach self-supervised learning of image representations from a\nstatistical dependence perspective, proposing Self-Supervised Learning with the\nHilbert-Schmidt Independence Criterion (SSL-HSIC). SSL-HSIC maximizes\ndependence between representations of transformed versions of an image and the\nimage identity, while minimizing the kernelized variance of those features.\nThis self-supervised learning framework yields a new understanding of InfoNCE,\na variational lower bound on the mutual information (MI) between different\ntransformations. While the MI itself is known to have pathologies which can\nresult in meaningless representations being learned, its bound is much better\nbehaved: we show that it implicitly approximates SSL-HSIC (with a slightly\ndifferent regularizer). Our approach also gives us insight into BYOL, since\nSSL-HSIC similarly learns local neighborhoods of samples. SSL-HSIC allows us to\ndirectly optimize statistical dependence in time linear in the batch size,\nwithout restrictive data assumptions or indirect mutual information estimators.\nTrained with or without a target network, SSL-HSIC matches the current\nstate-of-the-art for standard linear evaluation on ImageNet, semi-supervised\nlearning and transfer to other classification and vision tasks such as semantic\nsegmentation, depth estimation and object recognition.",
          "link": "http://arxiv.org/abs/2106.08320",
          "publishedOn": "2021-06-16T01:21:10.380Z",
          "wordCount": 615,
          "title": "Self-Supervised Learning with Kernel Dependence Maximization. (arXiv:2106.08320v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07860",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Boutsikas_J/0/1/0/all/0/1\">John Boutsikas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eren_M/0/1/0/all/0/1\">Maksim E. Eren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Varga_C/0/1/0/all/0/1\">Charles Varga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raff_E/0/1/0/all/0/1\">Edward Raff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matuszek_C/0/1/0/all/0/1\">Cynthia Matuszek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nicholas_C/0/1/0/all/0/1\">Charles Nicholas</a>",
          "description": "The use of Machine Learning has become a significant part of malware\ndetection efforts due to the influx of new malware, an ever changing threat\nlandscape, and the ability of Machine Learning methods to discover meaningful\ndistinctions between malicious and benign software. Antivirus vendors have also\nbegun to widely utilize malware classifiers based on dynamic and static malware\nanalysis features. Therefore, a malware author might make evasive binary\nmodifications against Machine Learning models as part of the malware\ndevelopment life cycle to execute an attack successfully. This makes the\nstudying of possible classifier evasion strategies an essential part of cyber\ndefense against malice. To this extent, we stage a grey box setup to analyze a\nscenario where the malware author does not know the target classifier\nalgorithm, and does not have access to decisions made by the classifier, but\nknows the features used in training. In this experiment, a malicious actor\ntrains a surrogate model using the EMBER-2018 dataset to discover binary\nmutations that cause an instance to be misclassified via a Monte Carlo tree\nsearch. Then, mutated malware is sent to the victim model that takes the place\nof an antivirus API to test whether it can evade detection.",
          "link": "http://arxiv.org/abs/2106.07860",
          "publishedOn": "2021-06-16T01:21:10.347Z",
          "wordCount": 651,
          "title": "Evading Malware Classifiers via Monte Carlo Mutant Feature Discovery. (arXiv:2106.07860v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2006.01017",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kahale_N/0/1/0/all/0/1\">Nabil Kahale</a>",
          "description": "We analyse an iterative algorithm to minimize quadratic functions whose\nHessian matrix $H$ is the expectation of a random symmetric $d\\times d$ matrix.\nThe algorithm is a variant of the stochastic variance reduced gradient (SVRG).\nIn several applications, including least-squares regressions, ridge\nregressions, linear discriminant analysis and regularized linear discriminant\nanalysis, the running time of each iteration is proportional to $d$. Under\nsmoothness and convexity conditions, the algorithm has linear convergence. When\napplied to quadratic functions, our analysis improves the state-of-the-art\nperformance of SVRG up to a logarithmic factor. Furthermore, for\nwell-conditioned quadratic problems, our analysis improves the state-of-the-art\nrunning times of accelerated SVRG, and is better than the known matching lower\nbound, by a logarithmic factor. Our theoretical results are backed with\nnumerical experiments.",
          "link": "http://arxiv.org/abs/2006.01017",
          "publishedOn": "2021-06-16T01:21:10.341Z",
          "wordCount": 580,
          "title": "Improved SVRG for quadratic functions. (arXiv:2006.01017v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08199",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abdolmaleki_A/0/1/0/all/0/1\">Abbas Abdolmaleki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Sandy H. Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vezzani_G/0/1/0/all/0/1\">Giulia Vezzani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shahriari_B/0/1/0/all/0/1\">Bobak Shahriari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Springenberg_J/0/1/0/all/0/1\">Jost Tobias Springenberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1\">Shruti Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+TB_D/0/1/0/all/0/1\">Dhruva TB</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Byravan_A/0/1/0/all/0/1\">Arunkumar Byravan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bousmalis_K/0/1/0/all/0/1\">Konstantinos Bousmalis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gyorgy_A/0/1/0/all/0/1\">Andras Gyorgy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szepesvari_C/0/1/0/all/0/1\">Csaba Szepesvari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hadsell_R/0/1/0/all/0/1\">Raia Hadsell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heess_N/0/1/0/all/0/1\">Nicolas Heess</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riedmiller_M/0/1/0/all/0/1\">Martin Riedmiller</a>",
          "description": "Many advances that have improved the robustness and efficiency of deep\nreinforcement learning (RL) algorithms can, in one way or another, be\nunderstood as introducing additional objectives, or constraints, in the policy\noptimization step. This includes ideas as far ranging as exploration bonuses,\nentropy regularization, and regularization toward teachers or data priors when\nlearning from experts or in offline RL. Often, task reward and auxiliary\nobjectives are in conflict with each other and it is therefore natural to treat\nthese examples as instances of multi-objective (MO) optimization problems. We\nstudy the principles underlying MORL and introduce a new algorithm,\nDistillation of a Mixture of Experts (DiME), that is intuitive and\nscale-invariant under some conditions. We highlight its strengths on standard\nMO benchmark problems and consider case studies in which we recast offline RL\nand learning from experts as MO problems. This leads to a natural algorithmic\nformulation that sheds light on the connection between existing approaches. For\noffline RL, we use the MO perspective to derive a simple algorithm, that\noptimizes for the standard RL objective plus a behavioral cloning term. This\noutperforms state-of-the-art on two established offline RL benchmarks.",
          "link": "http://arxiv.org/abs/2106.08199",
          "publishedOn": "2021-06-16T01:21:10.334Z",
          "wordCount": 643,
          "title": "On Multi-objective Policy Optimization as a Tool for Reinforcement Learning. (arXiv:2106.08199v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07849",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Blakeney_C/0/1/0/all/0/1\">Cody Blakeney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huish_N/0/1/0/all/0/1\">Nathaniel Huish</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1\">Yan Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zong_Z/0/1/0/all/0/1\">Ziliang Zong</a>",
          "description": "In recent years the ubiquitous deployment of AI has posed great concerns in\nregards to algorithmic bias, discrimination, and fairness. Compared to\ntraditional forms of bias or discrimination caused by humans, algorithmic bias\ngenerated by AI is more abstract and unintuitive therefore more difficult to\nexplain and mitigate. A clear gap exists in the current literature on\nevaluating and mitigating bias in pruned neural networks. In this work, we\nstrive to tackle the challenging issues of evaluating, mitigating, and\nexplaining induced bias in pruned neural networks. Our paper makes three\ncontributions. First, we propose two simple yet effective metrics, Combined\nError Variance (CEV) and Symmetric Distance Error (SDE), to quantitatively\nevaluate the induced bias prevention quality of pruned models. Second, we\ndemonstrate that knowledge distillation can mitigate induced bias in pruned\nneural networks, even with unbalanced datasets. Third, we reveal that model\nsimilarity has strong correlations with pruning induced bias, which provides a\npowerful method to explain why bias occurs in pruned neural networks. Our code\nis available at https://github.com/codestar12/pruning-distilation-bias",
          "link": "http://arxiv.org/abs/2106.07849",
          "publishedOn": "2021-06-16T01:21:10.326Z",
          "wordCount": 616,
          "title": "Simon Says: Evaluating and Mitigating Bias in Pruned Neural Networks with Knowledge Distillation. (arXiv:2106.07849v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08317",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Chen_X/0/1/0/all/0/1\">Xiaoqiao Chen</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Chen_S/0/1/0/all/0/1\">Sisi Chen</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Thomson_M/0/1/0/all/0/1\">Matt Thomson</a>",
          "description": "Sequencing costs currently prohibit the application of single cell mRNA-seq\nfor many biological and clinical tasks of interest. Here, we introduce an\nactive learning framework that constructs compressed gene sets that enable high\naccuracy classification of cell-types and physiological states while analyzing\na minimal number of gene transcripts. Our active feature selection procedure\nconstructs gene sets through an iterative cell-type classification task where\nmisclassified cells are examined at each round to identify maximally\ninformative genes through an `active' support vector machine (SVM) classifier.\nOur active SVM procedure automatically identifies gene sets that enables\n$>90\\%$ cell-type classification accuracy in the Tabula Muris mouse tissue\nsurvey as well as a $\\sim 40$ gene set that enables classification of multiple\nmyeloma patient samples with $>95\\%$ accuracy. Broadly, the discovery of\ncompact but highly informative gene sets might enable drastic reductions in\nsequencing requirements for applications of single-cell mRNA-seq.",
          "link": "http://arxiv.org/abs/2106.08317",
          "publishedOn": "2021-06-16T01:21:10.312Z",
          "wordCount": 591,
          "title": "Active feature selection discovers minimal gene-sets for classifying cell-types and disease states in single-cell mRNA-seq data. (arXiv:2106.08317v1 [q-bio.GN])"
        },
        {
          "id": "http://arxiv.org/abs/2007.00674",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dai_B/0/1/0/all/0/1\">Biwei Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seljak_U/0/1/0/all/0/1\">Uros Seljak</a>",
          "description": "We develop an iterative (greedy) deep learning (DL) algorithm which is able\nto transform an arbitrary probability distribution function (PDF) into the\ntarget PDF. The model is based on iterative Optimal Transport of a series of 1D\nslices, matching on each slice the marginal PDF to the target. The axes of the\northogonal slices are chosen to maximize the PDF difference using Wasserstein\ndistance at each iteration, which enables the algorithm to scale well to high\ndimensions. As special cases of this algorithm, we introduce two sliced\niterative Normalizing Flow (SINF) models, which map from the data to the latent\nspace (GIS) and vice versa (SIG). We show that SIG is able to generate high\nquality samples of image datasets, which match the GAN benchmarks, while GIS\nobtains competitive results on density estimation tasks compared to the density\ntrained NFs, and is more stable, faster, and achieves higher $p(x)$ when\ntrained on small training sets. SINF approach deviates significantly from the\ncurrent DL paradigm, as it is greedy and does not use concepts such as\nmini-batching, stochastic gradient descent and gradient back-propagation\nthrough deep layers.",
          "link": "http://arxiv.org/abs/2007.00674",
          "publishedOn": "2021-06-16T01:21:10.292Z",
          "wordCount": null,
          "title": "Sliced Iterative Normalizing Flows. (arXiv:2007.00674v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08043",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maiya_A/0/1/0/all/0/1\">Arun S. Maiya</a>",
          "description": "The vast majority of existing methods and systems for causal inference assume\nthat all variables under consideration are categorical or numerical (e.g.,\ngender, price, blood pressure, enrollment). In this paper, we present\nCausalNLP, a toolkit for inferring causality from observational data that\nincludes text in addition to traditional numerical and categorical variables.\nCausalNLP employs the use of meta-learners for treatment effect estimation and\nsupports using raw text and its linguistic properties as both a treatment and a\n\"controlled-for\" variable (e.g., confounder). The library is open-source and\navailable at: https://github.com/amaiya/causalnlp.",
          "link": "http://arxiv.org/abs/2106.08043",
          "publishedOn": "2021-06-16T01:21:10.274Z",
          "wordCount": 521,
          "title": "CausalNLP: A Practical Toolkit for Causal Inference with Text. (arXiv:2106.08043v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/1911.01529",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Blumenkamp_J/0/1/0/all/0/1\">Jan Blumenkamp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baude_A/0/1/0/all/0/1\">Andreas Baude</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laue_T/0/1/0/all/0/1\">Tim Laue</a>",
          "description": "Deep learning approaches have become the standard solution to many problems\nin computer vision and robotics, but obtaining sufficient training data in high\nenough quality is challenging, as human labor is error prone, time consuming,\nand expensive. Solutions based on simulation have become more popular in recent\nyears, but the gap between simulation and reality is still a major issue. In\nthis paper, we introduce a novel method for augmenting synthetic image data\nthrough unsupervised image-to-image translation by applying the style of real\nworld images to simulated images with open source frameworks. The generated\ndataset is combined with conventional augmentation methods and is then applied\nto a neural network model running in real-time on autonomous soccer robots. Our\nevaluation shows a significant improvement compared to models trained on images\ngenerated entirely in simulation.",
          "link": "http://arxiv.org/abs/1911.01529",
          "publishedOn": "2021-06-16T01:21:10.268Z",
          "wordCount": 599,
          "title": "Closing the Reality Gap with Unsupervised Sim-to-Real Image Translation. (arXiv:1911.01529v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08235",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zhaozhuo Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_M/0/1/0/all/0/1\">Minghao Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Junyan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shrivastava_A/0/1/0/all/0/1\">Anshumali Shrivastava</a>",
          "description": "Transformer models have demonstrated superior performance in natural language\nprocessing. The dot product self-attention in Transformer allows us to model\ninteractions between words. However, this modeling comes with significant\ncomputational overhead. In this work, we revisit the memory-compute trade-off\nassociated with Transformer, particularly multi-head attention, and show a\nmemory-heavy but significantly more compute-efficient alternative to\nTransformer. Our proposal, denoted as PairConnect, a multilayer perceptron\n(MLP), models the pairwise interaction between words by explicit pairwise word\nembeddings. As a result, PairConnect substitutes self dot product with a simple\nembedding lookup. We show mathematically that despite being an MLP, our\ncompute-efficient PairConnect is strictly more expressive than Transformer. Our\nexperiment on language modeling tasks suggests that PairConnect could achieve\ncomparable results with Transformer while reducing the computational cost\nassociated with inference significantly.",
          "link": "http://arxiv.org/abs/2106.08235",
          "publishedOn": "2021-06-16T01:21:10.262Z",
          "wordCount": 557,
          "title": "PairConnect: A Compute-Efficient MLP Alternative to Attention. (arXiv:2106.08235v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08217",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Alakus_C/0/1/0/all/0/1\">Cansu Alakus</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Larocque_D/0/1/0/all/0/1\">Denis Larocque</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Labbe_A/0/1/0/all/0/1\">Aurelie Labbe</a>",
          "description": "Like many predictive models, random forests provide a point prediction for a\nnew observation. Besides the point prediction, it is important to quantify the\nuncertainty in the prediction. Prediction intervals provide information about\nthe reliability of the point predictions. We have developed a comprehensive R\npackage, RFpredInterval, that integrates 16 methods to build prediction\nintervals with random forests and boosted forests. The methods implemented in\nthe package are a new method to build prediction intervals with boosted forests\n(PIBF) and 15 different variants to produce prediction intervals with random\nforests proposed by Roy and Larocque (2020). We perform an extensive simulation\nstudy and apply real data analyses to compare the performance of the proposed\nmethod to ten existing methods to build prediction intervals with random\nforests. The results show that the proposed method is very competitive and,\nglobally, it outperforms the competing methods.",
          "link": "http://arxiv.org/abs/2106.08217",
          "publishedOn": "2021-06-16T01:21:10.255Z",
          "wordCount": 586,
          "title": "RFpredInterval: An R Package for Prediction Intervals with Random Forests and Boosted Forests. (arXiv:2106.08217v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08283",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1\">Chulin Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Minghao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1\">Pin-Yu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>",
          "description": "Federated Learning (FL) as a distributed learning paradigm that aggregates\ninformation from diverse clients to train a shared global model, has\ndemonstrated great success. However, malicious clients can perform poisoning\nattacks and model replacement to introduce backdoors into the trained global\nmodel. Although there have been intensive studies designing robust aggregation\nmethods and empirical robust federated training protocols against backdoors,\nexisting approaches lack robustness certification. This paper provides the\nfirst general framework, Certifiably Robust Federated Learning (CRFL), to train\ncertifiably robust FL models against backdoors. Our method exploits clipping\nand smoothing on model parameters to control the global model smoothness, which\nyields a sample-wise robustness certification on backdoors with limited\nmagnitude. Our certification also specifies the relation to federated learning\nparameters, such as poisoning ratio on instance level, number of attackers, and\ntraining iterations. Practically, we conduct comprehensive experiments across a\nrange of federated datasets, and provide the first benchmark for certified\nrobustness against backdoor attacks in federated learning. Our code is\navailable at https://github.com/AI-secure/CRFL.",
          "link": "http://arxiv.org/abs/2106.08283",
          "publishedOn": "2021-06-16T01:21:10.205Z",
          "wordCount": 594,
          "title": "CRFL: Certifiably Robust Federated Learning against Backdoor Attacks. (arXiv:2106.08283v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07801",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Bi_H/0/1/0/all/0/1\">Hangrui Bi</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Wang_H/0/1/0/all/0/1\">Hengyi Wang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Shi_C/0/1/0/all/0/1\">Chence Shi</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Coley_C/0/1/0/all/0/1\">Connor Coley</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Tang_J/0/1/0/all/0/1\">Jian Tang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Guo_H/0/1/0/all/0/1\">Hongyu Guo</a>",
          "description": "Reliably predicting the products of chemical reactions presents a fundamental\nchallenge in synthetic chemistry. Existing machine learning approaches\ntypically produce a reaction product by sequentially forming its subparts or\nintermediate molecules. Such autoregressive methods, however, not only require\na pre-defined order for the incremental construction but preclude the use of\nparallel decoding for efficient computation. To address these issues, we devise\na non-autoregressive learning paradigm that predicts reaction in one shot.\nLeveraging the fact that chemical reactions can be described as a\nredistribution of electrons in molecules, we formulate a reaction as an\narbitrary electron flow and predict it with a novel multi-pointer decoding\nnetwork. Experiments on the USPTO-MIT dataset show that our approach has\nestablished a new state-of-the-art top-1 accuracy and achieves at least 27\ntimes inference speedup over the state-of-the-art methods. Also, our\npredictions are easier for chemists to interpret owing to predicting the\nelectron flows.",
          "link": "http://arxiv.org/abs/2106.07801",
          "publishedOn": "2021-06-16T01:21:10.185Z",
          "wordCount": 584,
          "title": "Non-Autoregressive Electron Redistribution Modeling for Reaction Prediction. (arXiv:2106.07801v1 [physics.chem-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07704",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1\">Han Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_B/0/1/0/all/0/1\">Bowen Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhengzhong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1\">Eric P. Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Zhiting Hu</a>",
          "description": "Maximum likelihood estimation (MLE) is the predominant algorithm for training\ntext generation models. This paradigm relies on direct supervision examples,\nwhich is not applicable to many applications, such as generating adversarial\nattacks or generating prompts to control language models. Reinforcement\nlearning (RL) on the other hand offers a more flexible solution by allowing\nusers to plug in arbitrary task metrics as reward. Yet previous RL algorithms\nfor text generation, such as policy gradient (on-policy RL) and Q-learning\n(off-policy RL), are often notoriously inefficient or unstable to train due to\nthe large sequence space and the sparse reward received only at the end of\nsequences. In this paper, we introduce a new RL formulation for text generation\nfrom the soft Q-learning perspective. It further enables us to draw from the\nlatest RL advances, such as path consistency learning, to combine the best of\non-/off-policy updates, and learn effectively from sparse reward. We apply the\napproach to a wide range of tasks, including learning from noisy/negative\nexamples, adversarial attacks, and prompt generation. Experiments show our\napproach consistently outperforms both task-specialized algorithms and the\nprevious RL methods. On standard supervised tasks where MLE prevails, our\napproach also achieves competitive performance and stability by training text\ngeneration from scratch.",
          "link": "http://arxiv.org/abs/2106.07704",
          "publishedOn": "2021-06-16T01:21:10.177Z",
          "wordCount": 641,
          "title": "Text Generation with Efficient (Soft) Q-Learning. (arXiv:2106.07704v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/1912.08421",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shuang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_L/0/1/0/all/0/1\">Liyao Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Congcong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yixuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Quanshi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>",
          "description": "Powered by machine learning services in the cloud, numerous learning-driven\nmobile applications are gaining popularity in the market. As deep learning\ntasks are mostly computation-intensive, it has become a trend to process raw\ndata on devices and send the deep neural network (DNN) features to the cloud,\nwhere the features are further processed to return final results. However,\nthere is always unexpected leakage with the release of features, with which an\nadversary could infer a significant amount of information about the original\ndata. We propose a privacy-preserving reinforcement learning framework on top\nof the mobile cloud infrastructure from the perspective of DNN structures. The\nframework aims to learn a policy to modify the base DNNs to prevent information\nleakage while maintaining high inference accuracy. The policy can also be\nreadily transferred to large-size DNNs to speed up learning. Extensive\nevaluations on a variety of DNNs have shown that our framework can successfully\nfind privacy-preserving DNN structures to defend different privacy attacks.",
          "link": "http://arxiv.org/abs/1912.08421",
          "publishedOn": "2021-06-16T01:21:10.170Z",
          "wordCount": 636,
          "title": "Learning to Prevent Leakage: Privacy-Preserving Inference in the Mobile Cloud. (arXiv:1912.08421v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.07830",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bu_Z/0/1/0/all/0/1\">Zhiqi Bu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hua Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_Q/0/1/0/all/0/1\">Qi Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_W/0/1/0/all/0/1\">Weijie J. Su</a>",
          "description": "In deep learning with differential privacy (DP), the neural network achieves\nthe privacy usually at the cost of slower convergence (and thus lower\nperformance) than its non-private counterpart. This work gives the first\nconvergence analysis of the DP deep learning, through the lens of training\ndynamics and the neural tangent kernel (NTK). Our convergence theory\nsuccessfully characterizes the effects of two key components in the DP\ntraining: the per-sample clipping (flat or layerwise) and the noise addition.\nOur analysis not only initiates a general principled framework to understand\nthe DP deep learning with any network architecture and loss function, but also\nmotivates a new clipping method -- the global clipping, that significantly\nimproves the convergence while preserving the same privacy guarantee as the\nexisting local clipping.\n\nIn terms of theoretical results, we establish the precise connection between\nthe per-sample clipping and NTK matrix. We show that in the gradient flow,\ni.e., with infinitesimal learning rate, the noise level of DP optimizers does\nnot affect the convergence. We prove that DP gradient descent (GD) with global\nclipping guarantees the monotone convergence to zero loss, which can be\nviolated by the existing DP-GD with local clipping. Notably, our analysis\nframework easily extends to other optimizers, e.g., DP-Adam. Empirically\nspeaking, DP optimizers equipped with global clipping perform strongly on a\nwide range of classification and regression tasks. In particular, our global\nclipping is surprisingly effective at learning calibrated classifiers, in\ncontrast to the existing DP classifiers which are oftentimes over-confident and\nunreliable. Implementation-wise, the new clipping can be realized by adding one\nline of code into the Opacus library.",
          "link": "http://arxiv.org/abs/2106.07830",
          "publishedOn": "2021-06-16T01:21:10.161Z",
          "wordCount": 698,
          "title": "On the Convergence of Deep Learning with Differential Privacy. (arXiv:2106.07830v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07895",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Levy_E/0/1/0/all/0/1\">Efrat Levy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shabtai_A/0/1/0/all/0/1\">Asaf Shabtai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Groza_B/0/1/0/all/0/1\">Bogdan Groza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murvay_P/0/1/0/all/0/1\">Pal-Stefan Murvay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elovici_Y/0/1/0/all/0/1\">Yuval Elovici</a>",
          "description": "The Controller Area Network (CAN) is used for communication between\nin-vehicle devices. The CAN bus has been shown to be vulnerable to remote\nattacks. To harden vehicles against such attacks, vehicle manufacturers have\ndivided in-vehicle networks into sub-networks, logically isolating critical\ndevices. However, attackers may still have physical access to various\nsub-networks where they can connect a malicious device. This threat has not\nbeen adequately addressed, as methods proposed to determine physical intrusion\npoints have shown weak results, emphasizing the need to develop more advanced\ntechniques. To address this type of threat, we propose a security hardening\nsystem for in-vehicle networks. The proposed system includes two mechanisms\nthat process deep features extracted from voltage signals measured on the CAN\nbus. The first mechanism uses data augmentation and deep learning to detect and\nlocate physical intrusions when the vehicle starts; this mechanism can detect\nand locate intrusions, even when the connected malicious devices are silent.\nThis mechanism's effectiveness (100% accuracy) is demonstrated in a wide\nvariety of insertion scenarios on a CAN bus prototype. The second mechanism is\na continuous device authentication mechanism, which is also based on deep\nlearning; this mechanism's robustness (99.8% accuracy) is demonstrated on a\nreal moving vehicle.",
          "link": "http://arxiv.org/abs/2106.07895",
          "publishedOn": "2021-06-16T01:21:10.152Z",
          "wordCount": 655,
          "title": "CAN-LOC: Spoofing Detection and Physical Intrusion Localization on an In-Vehicle CAN Bus Based on Deep Features of Voltage Signals. (arXiv:2106.07895v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07767",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jiong Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_J/0/1/0/all/0/1\">Junchen Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schaub_M/0/1/0/all/0/1\">Michael T. Schaub</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koutra_D/0/1/0/all/0/1\">Danai Koutra</a>",
          "description": "Recent studies have exposed that many graph neural networks (GNNs) are\nsensitive to adversarial attacks, and can suffer from performance loss if the\ngraph structure is intentionally perturbed. A different line of research has\nshown that many GNN architectures implicitly assume that the underlying graph\ndisplays homophily, i.e., connected nodes are more likely to have similar\nfeatures and class labels, and perform poorly if this assumption is not\nfulfilled. In this work, we formalize the relation between these two seemingly\ndifferent issues. We theoretically show that in the standard scenario in which\nnode features exhibit homophily, impactful structural attacks always lead to\nincreased levels of heterophily. Then, inspired by GNN architectures that\ntarget heterophily, we present two designs -- (i) separate aggregators for ego-\nand neighbor-embeddings, and (ii) a reduced scope of aggregation -- that can\nsignificantly improve the robustness of GNNs. Our extensive empirical\nevaluations show that GNNs featuring merely these two designs can achieve\nsignificantly improved robustness compared to the best-performing unvaccinated\nmodel with 24.99% gain in average performance under targeted attacks, while\nhaving smaller computational overhead than existing defense mechanisms.\nFurthermore, these designs can be readily combined with explicit defense\nmechanisms to yield state-of-the-art robustness with up to 18.33% increase in\nperformance under attacks compared to the best-performing vaccinated model.",
          "link": "http://arxiv.org/abs/2106.07767",
          "publishedOn": "2021-06-16T01:21:10.112Z",
          "wordCount": 653,
          "title": "Improving Robustness of Graph Neural Networks with Heterophily-Inspired Designs. (arXiv:2106.07767v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08021",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Akundi_P/0/1/0/all/0/1\">Prathyusha Akundi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gun_S/0/1/0/all/0/1\">Soumyasis Gun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sivaswamy_J/0/1/0/all/0/1\">Jayanthi Sivaswamy</a>",
          "description": "Melanoma is a leading cause of deaths due to skin cancer deaths and hence,\nearly and effective diagnosis of melanoma is of interest. Current approaches\nfor automated diagnosis of melanoma either use pattern recognition or\nanalytical recognition like ABCDE (asymmetry, border, color, diameter and\nevolving) criterion. In practice however, a differential approach wherein\noutliers (ugly duckling) are detected and used to evaluate nevi/lesions.\nIncorporation of differential recognition in Computer Aided Diagnosis (CAD)\nsystems has not been explored but can be beneficial as it can provide a\nclinical justification for the derived decision. We present a method for\nidentifying and quantifying ugly ducklings by performing Intra-Patient\nComparative Analysis (IPCA) of neighboring nevi. This is then incorporated in a\nCAD system design for melanoma detection. This design ensures flexibility to\nhandle cases where IPCA is not possible. Our experiments on a public dataset\nshow that the outlier information helps boost the sensitivity of detection by\nat least 4.1 % and specificity by 4.0 % to 8.9 %, depending on the use of a\nstrong (EfficientNet) or moderately strong (VGG or ResNet) classifier.",
          "link": "http://arxiv.org/abs/2106.08021",
          "publishedOn": "2021-06-16T01:21:10.098Z",
          "wordCount": 620,
          "title": "A Clinically Inspired Approach for Melanoma classification. (arXiv:2106.08021v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07780",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1\">A. Tuan Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1\">Toan Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gal_Y/0/1/0/all/0/1\">Yarin Gal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1\">Philip H. S. Torr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baydin_A/0/1/0/all/0/1\">At&#x131;l&#x131;m G&#xfc;ne&#x15f; Baydin</a>",
          "description": "Domain adaptation is an important problem and often needed for real-world\napplications. In this problem, instead of i.i.d. datapoints, we assume that the\nsource (training) data and the target (testing) data have different\ndistributions. With that setting, the empirical risk minimization training\nprocedure often does not perform well, since it does not account for the change\nin the distribution. A common approach in the domain adaptation literature is\nto learn a representation of the input that has the same distributions over the\nsource and the target domain. However, these approaches often require\nadditional networks and/or optimizing an adversarial (minimax) objective, which\ncan be very expensive or unstable in practice. To tackle this problem, we first\nderive a generalization bound for the target loss based on the training loss\nand the reverse Kullback-Leibler (KL) divergence between the source and the\ntarget representation distributions. Based on this bound, we derive an\nalgorithm that minimizes the KL term to obtain a better generalization to the\ntarget domain. We show that with a probabilistic representation network, the KL\nterm can be estimated efficiently via minibatch samples without any additional\nnetwork or a minimax objective. This leads to a theoretically sound alignment\nmethod which is also very efficient and stable in practice. Experimental\nresults also suggest that our method outperforms other representation-alignment\napproaches.",
          "link": "http://arxiv.org/abs/2106.07780",
          "publishedOn": "2021-06-16T01:21:10.092Z",
          "wordCount": 641,
          "title": "KL Guided Domain Adaptation. (arXiv:2106.07780v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08208",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Huang_F/0/1/0/all/0/1\">Feihu Huang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Li_J/0/1/0/all/0/1\">Junyi Li</a>, <a href=\"http://arxiv.org/find/math/1/au:+Huang_H/0/1/0/all/0/1\">Heng Huang</a>",
          "description": "Adaptive gradient methods have shown excellent performance for solving many\nmachine learning problems. Although multiple adaptive methods were recently\nstudied, they mainly focus on either empirical or theoretical aspects and also\nonly work for specific problems by using specific adaptive learning rates. It\nis desired to design a universal framework for practical algorithms of adaptive\ngradients with theoretical guarantee to solve general problems. To fill this\ngap, we propose a faster and universal framework of adaptive gradients (i.e.,\nSUPER-ADAM) by introducing a universal adaptive matrix that includes most\nexisting adaptive gradient forms. Moreover, our framework can flexibly\nintegrates the momentum and variance reduced techniques. In particular, our\nnovel framework provides the convergence analysis support for adaptive gradient\nmethods under the nonconvex setting. In theoretical analysis, we prove that our\nnew algorithm can achieve the best known complexity of\n$\\tilde{O}(\\epsilon^{-3})$ for finding an $\\epsilon$-stationary point of\nnonconvex optimization, which matches the lower bound for stochastic smooth\nnonconvex optimization. In numerical experiments, we employ various deep\nlearning tasks to validate that our algorithm consistently outperforms the\nexisting adaptive algorithms.",
          "link": "http://arxiv.org/abs/2106.08208",
          "publishedOn": "2021-06-16T01:21:10.083Z",
          "wordCount": 616,
          "title": "SUPER-ADAM: Faster and Universal Framework of Adaptive Gradients. (arXiv:2106.08208v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07820",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Charles_Z/0/1/0/all/0/1\">Zachary Charles</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garrett_Z/0/1/0/all/0/1\">Zachary Garrett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huo_Z/0/1/0/all/0/1\">Zhouyuan Huo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shmulyian_S/0/1/0/all/0/1\">Sergei Shmulyian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_V/0/1/0/all/0/1\">Virginia Smith</a>",
          "description": "Federated learning methods typically learn a model by iteratively sampling\nupdates from a population of clients. In this work, we explore how the number\nof clients sampled at each round (the cohort size) impacts the quality of the\nlearned model and the training dynamics of federated learning algorithms. Our\nwork poses three fundamental questions. First, what challenges arise when\ntrying to scale federated learning to larger cohorts? Second, what parallels\nexist between cohort sizes in federated learning and batch sizes in centralized\nlearning? Last, how can we design federated learning methods that effectively\nutilize larger cohort sizes? We give partial answers to these questions based\non extensive empirical evaluation. Our work highlights a number of challenges\nstemming from the use of larger cohorts. While some of these (such as\ngeneralization issues and diminishing returns) are analogs of large-batch\ntraining challenges, others (including training failures and fairness concerns)\nare unique to federated learning.",
          "link": "http://arxiv.org/abs/2106.07820",
          "publishedOn": "2021-06-16T01:21:10.074Z",
          "wordCount": 581,
          "title": "On Large-Cohort Training for Federated Learning. (arXiv:2106.07820v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07903",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1\">Jaemoo Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_C/0/1/0/all/0/1\">Changyeon Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bae_J/0/1/0/all/0/1\">Jeongwoo Bae</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_M/0/1/0/all/0/1\">Myungjoo Kang</a>",
          "description": "Out-of-distribution (OOD) detection is an important task in machine learning\nsystems for ensuring their reliability and safety. Deep probabilistic\ngenerative models facilitate OOD detection by estimating the likelihood of a\ndata sample. However, such models frequently assign a suspiciously high\nlikelihood to a specific outlier. Several recent works have addressed this\nissue by training a neural network with auxiliary outliers, which are generated\nby perturbing the input data. In this paper, we discover that these approaches\nfail for certain OOD datasets. Thus, we suggest a new detection metric that\noperates without outlier exposure. We observe that our metric is robust to\ndiverse variations of an image compared to the previous outlier-exposing\nmethods. Furthermore, our proposed score requires neither auxiliary models nor\nadditional training. Instead, this paper utilizes the likelihood ratio\nstatistic in a new perspective to extract genuine properties from the given\nsingle deep probabilistic generative model. We also apply a novel numerical\napproximation to enable fast implementation. Finally, we demonstrate\ncomprehensive experiments on various probabilistic generative models and show\nthat our method achieves state-of-the-art performance.",
          "link": "http://arxiv.org/abs/2106.07903",
          "publishedOn": "2021-06-16T01:21:10.049Z",
          "wordCount": 612,
          "title": "Robust Out-of-Distribution Detection on Deep Probabilistic Generative Models. (arXiv:2106.07903v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08301",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1\">Sheng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1\">Wei Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1\">Kaidi Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanzhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Songnan Li</a>",
          "description": "Compressing Deep Neural Network (DNN) models to alleviate the storage and\ncomputation requirements is essential for practical applications, especially\nfor resource limited devices. Although capable of reducing a reasonable amount\nof model parameters, previous unstructured or structured weight pruning methods\ncan hardly truly accelerate inference, either due to the poor hardware\ncompatibility of the unstructured sparsity or due to the low sparse rate of the\nstructurally pruned network. Aiming at reducing both storage and computation,\nas well as preserving the original task performance, we propose a generalized\nweight unification framework at a hardware compatible micro-structured level to\nachieve high amount of compression and acceleration. Weight coefficients of a\nselected micro-structured block are unified to reduce the storage and\ncomputation of the block without changing the neuron connections, which turns\nto a micro-structured pruning special case when all unified coefficients are\nset to zero, where neuron connections (hence storage and computation) are\ncompletely removed. In addition, we developed an effective training framework\nbased on the alternating direction method of multipliers (ADMM), which converts\nour complex constrained optimization into separately solvable subproblems.\nThrough iteratively optimizing the subproblems, the desired micro-structure can\nbe ensured with high compression ratio and low performance degradation. We\nextensively evaluated our method using a variety of benchmark models and\ndatasets for different applications. Experimental results demonstrate\nstate-of-the-art performance.",
          "link": "http://arxiv.org/abs/2106.08301",
          "publishedOn": "2021-06-16T01:21:10.042Z",
          "wordCount": 669,
          "title": "Efficient Micro-Structured Weight Unification for Neural Network Compression. (arXiv:2106.08301v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08038",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ashukha_A/0/1/0/all/0/1\">Arsenii Ashukha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Atanov_A/0/1/0/all/0/1\">Andrei Atanov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vetrov_D/0/1/0/all/0/1\">Dmitry Vetrov</a>",
          "description": "Averaging predictions over a set of models -- an ensemble -- is widely used\nto improve predictive performance and uncertainty estimation of deep learning\nmodels. At the same time, many machine learning systems, such as search,\nmatching, and recommendation systems, heavily rely on embeddings.\nUnfortunately, due to misalignment of features of independently trained models,\nembeddings, cannot be improved with a naive deep ensemble like approach. In\nthis work, we look at the ensembling of representations and propose mean\nembeddings with test-time augmentation (MeTTA) simple yet well-performing\nrecipe for ensembling representations. Empirically we demonstrate that MeTTA\nsignificantly boosts the quality of linear evaluation on ImageNet for both\nsupervised and self-supervised models. Even more exciting, we draw connections\nbetween MeTTA, image retrieval, and transformation invariant models. We believe\nthat spreading the success of ensembles to inference higher-quality\nrepresentations is the important step that will open many new applications of\nensembling.",
          "link": "http://arxiv.org/abs/2106.08038",
          "publishedOn": "2021-06-16T01:21:10.030Z",
          "wordCount": 580,
          "title": "Mean Embeddings with Test-Time Data Augmentation for Ensembling of Representations. (arXiv:2106.08038v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07688",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gauthier_D/0/1/0/all/0/1\">Daniel J. Gauthier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bollt_E/0/1/0/all/0/1\">Erik Bollt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Griffith_A/0/1/0/all/0/1\">Aaron Griffith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barbosa_W/0/1/0/all/0/1\">Wendson A.S. Barbosa</a>",
          "description": "Reservoir computing is a best-in-class machine learning algorithm for\nprocessing information generated by dynamical systems using observed\ntime-series data. Importantly, it requires very small training data sets, uses\nlinear optimization, and thus requires minimal computing resources. However,\nthe algorithm uses randomly sampled matrices to define the underlying recurrent\nneural network and has a multitude of metaparameters that must be optimized.\nRecent results demonstrate the equivalence of reservoir computing to nonlinear\nvector autoregression, which requires no random matrices, fewer metaparameters,\nand provides interpretable results. Here, we demonstrate that nonlinear vector\nautoregression excels at reservoir computing benchmark tasks and requires even\nshorter training data sets and training time, heralding the next generation of\nreservoir computing.",
          "link": "http://arxiv.org/abs/2106.07688",
          "publishedOn": "2021-06-16T01:21:10.023Z",
          "wordCount": 537,
          "title": "Next Generation Reservoir Computing. (arXiv:2106.07688v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07905",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Rui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_Z/0/1/0/all/0/1\">Ziheng Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongyuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xuelong Li</a>",
          "description": "Deep neural network (DNN) generally takes thousands of iterations to optimize\nvia gradient descent and thus has a slow convergence. In addition, softmax, as\na decision layer, may ignore the distribution information of the data during\nclassification. Aiming to tackle the referred problems, we propose a novel\nmanifold neural network based on non-gradient optimization, i.e., the\nclosed-form solutions. Considering that the activation function is generally\ninvertible, we reconstruct the network via forward ridge regression and low\nrank backward approximation, which achieve the rapid convergence. Moreover, by\nunifying the flexible Stiefel manifold and adaptive support vector machine, we\ndevise the novel decision layer which efficiently fits the manifold structure\nof the data and label information. Consequently, a jointly non-gradient\noptimization method is designed to generate the network with closed-form\nresults. Eventually, extensive experiments validate the superior performance of\nthe model.",
          "link": "http://arxiv.org/abs/2106.07905",
          "publishedOn": "2021-06-16T01:21:10.014Z",
          "wordCount": 566,
          "title": "Non-Gradient Manifold Neural Network. (arXiv:2106.07905v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07868",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Haibin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhiyong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Dong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hung-yi Lee</a>",
          "description": "Automatic speaker verification (ASV) is a well developed technology for\nbiometric identification, and has been ubiquitous implemented in\nsecurity-critic applications, such as banking and access control. However,\nprevious works have shown that ASV is under the radar of adversarial attacks,\nwhich are very similar to their original counterparts from human's perception,\nyet will manipulate the ASV render wrong prediction. Due to the very late\nemergence of adversarial attacks for ASV, effective countermeasures against\nthem are limited. Given that the security of ASV is of high priority, in this\nwork, we propose the idea of \"voting for the right answer\" to prevent risky\ndecisions of ASV in blind spot areas, by employing random sampling and voting.\nExperimental results show that our proposed method improves the robustness\nagainst both the limited-knowledge attackers by pulling the adversarial samples\nout of the blind spots, and the perfect-knowledge attackers by introducing\nrandomness and increasing the attackers' budgets. The code for reproducing main\nresults is available at https://github.com/thuhcsi/adsv_voting.",
          "link": "http://arxiv.org/abs/2106.07868",
          "publishedOn": "2021-06-16T01:21:10.001Z",
          "wordCount": 620,
          "title": "Voting for the right answer: Adversarial defense for speaker verification. (arXiv:2106.07868v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07804",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Seo_S/0/1/0/all/0/1\">Sungyong Seo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arik_S/0/1/0/all/0/1\">Sercan O. Arik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_J/0/1/0/all/0/1\">Jinsung Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sohn_K/0/1/0/all/0/1\">Kihyuk Sohn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfister_T/0/1/0/all/0/1\">Tomas Pfister</a>",
          "description": "We propose a novel training method to integrate rules into deep learning, in\na way their strengths are controllable at inference. Deep Neural Networks with\nControllable Rule Representations (DeepCTRL) incorporates a rule encoder into\nthe model coupled with a rule-based objective, enabling a shared representation\nfor decision making. DeepCTRL is agnostic to data type and model architecture.\nIt can be applied to any kind of rule defined for inputs and outputs. The key\naspect of DeepCTRL is that it does not require retraining to adapt the rule\nstrength -- at inference, the user can adjust it based on the desired operation\npoint on accuracy vs. rule verification ratio. In real-world domains where\nincorporating rules is critical -- such as Physics, Retail and Healthcare -- we\nshow the effectiveness of DeepCTRL in teaching rules for deep learning.\nDeepCTRL improves the trust and reliability of the trained models by\nsignificantly increasing their rule verification ratio, while also providing\naccuracy gains at downstream tasks. Additionally, DeepCTRL enables novel use\ncases such as hypothesis testing of the rules on data samples, and unsupervised\nadaptation based on shared rules between datasets.",
          "link": "http://arxiv.org/abs/2106.07804",
          "publishedOn": "2021-06-16T01:21:09.977Z",
          "wordCount": 615,
          "title": "Controlling Neural Networks with Rule Representations. (arXiv:2106.07804v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07724",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rajput_S/0/1/0/all/0/1\">Shashank Rajput</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sreenivasan_K/0/1/0/all/0/1\">Kartik Sreenivasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papailiopoulos_D/0/1/0/all/0/1\">Dimitris Papailiopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karbasi_A/0/1/0/all/0/1\">Amin Karbasi</a>",
          "description": "It is well known that modern deep neural networks are powerful enough to\nmemorize datasets even when the labels have been randomized. Recently,\nVershynin (2020) settled a long standing question by Baum (1988), proving that\n\\emph{deep threshold} networks can memorize $n$ points in $d$ dimensions using\n$\\widetilde{\\mathcal{O}}(e^{1/\\delta^2}+\\sqrt{n})$ neurons and\n$\\widetilde{\\mathcal{O}}(e^{1/\\delta^2}(d+\\sqrt{n})+n)$ weights, where $\\delta$\nis the minimum distance between the points. In this work, we improve the\ndependence on $\\delta$ from exponential to almost linear, proving that\n$\\widetilde{\\mathcal{O}}(\\frac{1}{\\delta}+\\sqrt{n})$ neurons and\n$\\widetilde{\\mathcal{O}}(\\frac{d}{\\delta}+n)$ weights are sufficient. Our\nconstruction uses Gaussian random weights only in the first layer, while all\nthe subsequent layers use binary or integer weights. We also prove new lower\nbounds by connecting memorization in neural networks to the purely geometric\nproblem of separating $n$ points on a sphere using hyperplanes.",
          "link": "http://arxiv.org/abs/2106.07724",
          "publishedOn": "2021-06-16T01:21:09.963Z",
          "wordCount": 571,
          "title": "An Exponential Improvement on the Memorization Capacity of Deep Threshold Networks. (arXiv:2106.07724v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08254",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bao_H/0/1/0/all/0/1\">Hangbo Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_L/0/1/0/all/0/1\">Li Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>",
          "description": "We introduce a self-supervised vision representation model BEiT, which stands\nfor Bidirectional Encoder representation from Image Transformers. Following\nBERT developed in the natural language processing area, we propose a masked\nimage modeling task to pretrain vision Transformers. Specifically, each image\nhas two views in our pre-training, i.e, image patches (such as 16x16 pixels),\nand visual tokens (i.e., discrete tokens). We first \"tokenize\" the original\nimage into visual tokens. Then we randomly mask some image patches and fed them\ninto the backbone Transformer. The pre-training objective is to recover the\noriginal visual tokens based on the corrupted image patches. After pre-training\nBEiT, we directly fine-tune the model parameters on downstream tasks by\nappending task layers upon the pretrained encoder. Experimental results on\nimage classification and semantic segmentation show that our model achieves\ncompetitive results with previous pre-training methods. For example, base-size\nBEiT achieves 83.2% top-1 accuracy on ImageNet-1K, significantly outperforming\nfrom-scratch DeiT training (81.8%) with the same setup. Moreover, large-size\nBEiT obtains 86.3% only using ImageNet-1K, even outperforming ViT-L with\nsupervised pre-training on ImageNet-22K (85.2%). The code and pretrained models\nare available at https://aka.ms/beit.",
          "link": "http://arxiv.org/abs/2106.08254",
          "publishedOn": "2021-06-16T01:21:09.955Z",
          "wordCount": 625,
          "title": "BEiT: BERT Pre-Training of Image Transformers. (arXiv:2106.08254v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08247",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_S/0/1/0/all/0/1\">Sikai Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_T/0/1/0/all/0/1\">Tingna Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Worden_K/0/1/0/all/0/1\">Keith Worden</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cross_E/0/1/0/all/0/1\">Elizabeth J. Cross</a>",
          "description": "This paper proposes a canonical-correlation-based filter method for feature\nselection. The sum of squared canonical correlation coefficients is adopted as\nthe feature ranking criterion. The proposed method boosts the computational\nspeed of the ranking criterion in greedy search. The supporting theorems\ndeveloped for the feature selection method are fundamental to the understanding\nof the canonical correlation analysis. In empirical studies, a synthetic\ndataset is used to demonstrate the speed advantage of the proposed method, and\neight real datasets are applied to show the effectiveness of the proposed\nfeature ranking criterion in both classification and regression. The results\nshow that the proposed method is considerably faster than the definition-based\nmethod, and the proposed ranking criterion is competitive compared with the\nseven mutual-information-based criteria.",
          "link": "http://arxiv.org/abs/2106.08247",
          "publishedOn": "2021-06-16T01:21:09.944Z",
          "wordCount": 543,
          "title": "Canonical-Correlation-Based Fast Feature Selection. (arXiv:2106.08247v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07814",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Malik_D/0/1/0/all/0/1\">Dhruv Malik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pacchiano_A/0/1/0/all/0/1\">Aldo Pacchiano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivasan_V/0/1/0/all/0/1\">Vishwak Srinivasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuanzhi Li</a>",
          "description": "Reinforcement learning (RL) is empirically successful in complex nonlinear\nMarkov decision processes (MDPs) with continuous state spaces. By contrast, the\nmajority of theoretical RL literature requires the MDP to satisfy some form of\nlinear structure, in order to guarantee sample efficient RL. Such efforts\ntypically assume the transition dynamics or value function of the MDP are\ndescribed by linear functions of the state features. To resolve this\ndiscrepancy between theory and practice, we introduce the Effective Planning\nWindow (EPW) condition, a structural condition on MDPs that makes no linearity\nassumptions. We demonstrate that the EPW condition permits sample efficient RL,\nby providing an algorithm which provably solves MDPs satisfying this condition.\nOur algorithm requires minimal assumptions on the policy class, which can\ninclude multi-layer neural networks with nonlinear activation functions.\nNotably, the EPW condition is directly motivated by popular gaming benchmarks,\nand we show that many classic Atari games satisfy this condition. We\nadditionally show the necessity of conditions like EPW, by demonstrating that\nsimple MDPs with slight nonlinearities cannot be solved sample efficiently.",
          "link": "http://arxiv.org/abs/2106.07814",
          "publishedOn": "2021-06-16T01:21:09.938Z",
          "wordCount": 618,
          "title": "Sample Efficient Reinforcement Learning In Continuous State Spaces: A Perspective Beyond Linearity. (arXiv:2106.07814v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07875",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhou_Z/0/1/0/all/0/1\">Zhengze Zhou</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hooker_G/0/1/0/all/0/1\">Giles Hooker</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_F/0/1/0/all/0/1\">Fei Wang</a>",
          "description": "An increasing number of machine learning models have been deployed in domains\nwith high stakes such as finance and healthcare. Despite their superior\nperformances, many models are black boxes in nature which are hard to explain.\nThere are growing efforts for researchers to develop methods to interpret these\nblack-box models. Post hoc explanations based on perturbations, such as LIME,\nare widely used approaches to interpret a machine learning model after it has\nbeen built. This class of methods has been shown to exhibit large instability,\nposing serious challenges to the effectiveness of the method itself and harming\nuser trust. In this paper, we propose S-LIME, which utilizes a hypothesis\ntesting framework based on central limit theorem for determining the number of\nperturbation points needed to guarantee stability of the resulting explanation.\nExperiments on both simulated and real world data sets are provided to\ndemonstrate the effectiveness of our method.",
          "link": "http://arxiv.org/abs/2106.07875",
          "publishedOn": "2021-06-16T01:21:09.919Z",
          "wordCount": 593,
          "title": "S-LIME: Stabilized-LIME for Model Explanation. (arXiv:2106.07875v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07787",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chowdhury_S/0/1/0/all/0/1\">Shreyan Chowdhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Praher_V/0/1/0/all/0/1\">Verena Praher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Widmer_G/0/1/0/all/0/1\">Gerhard Widmer</a>",
          "description": "Music emotion recognition is an important task in MIR (Music Information\nRetrieval) research. Owing to factors like the subjective nature of the task\nand the variation of emotional cues between musical genres, there are still\nsignificant challenges in developing reliable and generalizable models. One\nimportant step towards better models would be to understand what a model is\nactually learning from the data and how the prediction for a particular input\nis made. In previous work, we have shown how to derive explanations of model\npredictions in terms of spectrogram image segments that connect to the\nhigh-level emotion prediction via a layer of easily interpretable perceptual\nfeatures. However, that scheme lacks intuitive musical comprehensibility at the\nspectrogram level. In the present work, we bridge this gap by merging audioLIME\n-- a source-separation based explainer -- with mid-level perceptual features,\nthus forming an intuitive connection chain between the input audio and the\noutput emotion predictions. We demonstrate the usefulness of this method by\napplying it to debug a biased emotion prediction model.",
          "link": "http://arxiv.org/abs/2106.07787",
          "publishedOn": "2021-06-16T01:21:09.912Z",
          "wordCount": 615,
          "title": "Tracing Back Music Emotion Predictions to Sound Sources and Intuitive Perceptual Qualities. (arXiv:2106.07787v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07644",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Even_M/0/1/0/all/0/1\">Mathieu Even</a>, <a href=\"http://arxiv.org/find/math/1/au:+Berthier_R/0/1/0/all/0/1\">Rapha&#xeb;l Berthier</a>, <a href=\"http://arxiv.org/find/math/1/au:+Bach_F/0/1/0/all/0/1\">Francis Bach</a>, <a href=\"http://arxiv.org/find/math/1/au:+Flammarion_N/0/1/0/all/0/1\">Nicolas Flammarion</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gaillard_P/0/1/0/all/0/1\">Pierre Gaillard</a>, <a href=\"http://arxiv.org/find/math/1/au:+Hendrikx_H/0/1/0/all/0/1\">Hadrien Hendrikx</a>, <a href=\"http://arxiv.org/find/math/1/au:+Massoulie_L/0/1/0/all/0/1\">Laurent Massouli&#xe9;</a>, <a href=\"http://arxiv.org/find/math/1/au:+Taylor_A/0/1/0/all/0/1\">Adrien Taylor</a>",
          "description": "We introduce the continuized Nesterov acceleration, a close variant of\nNesterov acceleration whose variables are indexed by a continuous time\nparameter. The two variables continuously mix following a linear ordinary\ndifferential equation and take gradient steps at random times. This continuized\nvariant benefits from the best of the continuous and the discrete frameworks:\nas a continuous process, one can use differential calculus to analyze\nconvergence and obtain analytical expressions for the parameters; and a\ndiscretization of the continuized process can be computed exactly with\nconvergence rates similar to those of Nesterov original acceleration. We show\nthat the discretization has the same structure as Nesterov acceleration, but\nwith random parameters. We provide continuized Nesterov acceleration under\ndeterministic as well as stochastic gradients, with either additive or\nmultiplicative noise. Finally, using our continuized framework and expressing\nthe gossip averaging problem as the stochastic minimization of a certain energy\nfunction, we provide the first rigorous acceleration of asynchronous gossip\nalgorithms.",
          "link": "http://arxiv.org/abs/2106.07644",
          "publishedOn": "2021-06-16T01:21:09.905Z",
          "wordCount": 625,
          "title": "A Continuized View on Nesterov Acceleration for Stochastic Gradient Descent and Randomized Gossip. (arXiv:2106.07644v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07900",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Yang_C/0/1/0/all/0/1\">Chaoqi Yang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Qian_C/0/1/0/all/0/1\">Cheng Qian</a>, <a href=\"http://arxiv.org/find/math/1/au:+Singh_N/0/1/0/all/0/1\">Navjot Singh</a>, <a href=\"http://arxiv.org/find/math/1/au:+Xiao_C/0/1/0/all/0/1\">Cao Xiao</a>, <a href=\"http://arxiv.org/find/math/1/au:+Westover_M/0/1/0/all/0/1\">M Brandon Westover</a>, <a href=\"http://arxiv.org/find/math/1/au:+Solomonik_E/0/1/0/all/0/1\">Edgar Solomonik</a>, <a href=\"http://arxiv.org/find/math/1/au:+Sun_J/0/1/0/all/0/1\">Jimeng Sun</a>",
          "description": "Tensor decompositions are powerful tools for dimensionality reduction and\nfeature interpretation of multidimensional data such as signals. Existing\ntensor decomposition objectives (e.g., Frobenius norm) are designed for fitting\nraw data under statistical assumptions, which may not align with downstream\nclassification tasks. Also, real-world tensor data are usually high-ordered and\nhave large dimensions with millions or billions of entries. Thus, it is\nexpensive to decompose the whole tensor with traditional algorithms. In\npractice, raw tensor data also contains redundant information while data\naugmentation techniques may be used to smooth out noise in samples. This paper\naddresses the above challenges by proposing augmented tensor decomposition\n(ATD), which effectively incorporates data augmentations to boost downstream\nclassification. To reduce the memory footprint of the decomposition, we propose\na stochastic algorithm that updates the factor matrices in a batch fashion. We\nevaluate ATD on multiple signal datasets. It shows comparable or better\nperformance (e.g., up to 15% in accuracy) over self-supervised and autoencoder\nbaselines with less than 5% of model parameters, achieves 0.6% ~ 1.3% accuracy\ngain over other tensor-based baselines, and reduces the memory footprint by 9X\nwhen compared to standard tensor decomposition algorithms.",
          "link": "http://arxiv.org/abs/2106.07900",
          "publishedOn": "2021-06-16T01:21:09.888Z",
          "wordCount": 635,
          "title": "Augmented Tensor Decomposition with Stochastic Optimization. (arXiv:2106.07900v1 [math.NA])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07873",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Asnani_V/0/1/0/all/0/1\">Vishal Asnani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_X/0/1/0/all/0/1\">Xi Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hassner_T/0/1/0/all/0/1\">Tal Hassner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaoming Liu</a>",
          "description": "State-of-the-art (SOTA) Generative Models (GMs) can synthesize\nphoto-realistic images that are hard for humans to distinguish from genuine\nphotos. We propose to perform reverse engineering of GMs to infer the model\nhyperparameters from the images generated by these models. We define a novel\nproblem, \"model parsing\", as estimating GM network architectures and training\nloss functions by examining their generated images -- a task seemingly\nimpossible for human beings. To tackle this problem, we propose a framework\nwith two components: a Fingerprint Estimation Network (FEN), which estimates a\nGM fingerprint from a generated image by training with four constraints to\nencourage the fingerprint to have desired properties, and a Parsing Network\n(PN), which predicts network architecture and loss functions from the estimated\nfingerprints. To evaluate our approach, we collect a fake image dataset with\n$100$K images generated by $100$ GMs. Extensive experiments show encouraging\nresults in parsing the hyperparameters of the unseen models. Finally, our\nfingerprint estimation can be leveraged for deepfake detection and image\nattribution, as we show by reporting SOTA results on both the recent Celeb-DF\nand image attribution benchmarks.",
          "link": "http://arxiv.org/abs/2106.07873",
          "publishedOn": "2021-06-16T01:21:09.877Z",
          "wordCount": 624,
          "title": "Reverse Engineering of Generative Models: Inferring Model Hyperparameters from Generated Images. (arXiv:2106.07873v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07734",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Swaminathan_R/0/1/0/all/0/1\">Rupak Vignesh Swaminathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+King_B/0/1/0/all/0/1\">Brian King</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Strimel_G/0/1/0/all/0/1\">Grant P. Strimel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Droppo_J/0/1/0/all/0/1\">Jasha Droppo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mouchtaris_A/0/1/0/all/0/1\">Athanasios Mouchtaris</a>",
          "description": "We propose a simple yet effective method to compress an RNN-Transducer\n(RNN-T) through the well-known knowledge distillation paradigm. We show that\nthe transducer's encoder outputs naturally have a high entropy and contain rich\ninformation about acoustically similar word-piece confusions. This rich\ninformation is suppressed when combined with the lower entropy decoder outputs\nto produce the joint network logits. Consequently, we introduce an auxiliary\nloss to distill the encoder logits from a teacher transducer's encoder, and\nexplore training strategies where this encoder distillation works effectively.\nWe find that tandem training of teacher and student encoders with an inplace\nencoder distillation outperforms the use of a pre-trained and static teacher\ntransducer. We also report an interesting phenomenon we refer to as implicit\ndistillation, that occurs when the teacher and student encoders share the same\ndecoder. Our experiments show 5.37-8.4% relative word error rate reductions\n(WERR) on in-house test sets, and 5.05-6.18% relative WERRs on LibriSpeech test\nsets.",
          "link": "http://arxiv.org/abs/2106.07734",
          "publishedOn": "2021-06-16T01:21:09.858Z",
          "wordCount": 606,
          "title": "CoDERT: Distilling Encoder Representations with Co-learning for Transducer-based Speech Recognition. (arXiv:2106.07734v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07877",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Curry_M/0/1/0/all/0/1\">Michael J. Curry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyi_U/0/1/0/all/0/1\">Uro Lyi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1\">Tom Goldstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dickerson_J/0/1/0/all/0/1\">John Dickerson</a>",
          "description": "We propose a new architecture to approximately learn incentive compatible,\nrevenue-maximizing auctions from sampled valuations. Our architecture uses the\nSinkhorn algorithm to perform a differentiable bipartite matching which allows\nthe network to learn strategyproof revenue-maximizing mechanisms in settings\nnot learnable by the previous RegretNet architecture. In particular, our\narchitecture is able to learn mechanisms in settings without free disposal\nwhere each bidder must be allocated exactly some number of items. In\nexperiments, we show our approach successfully recovers multiple known optimal\nmechanisms and high-revenue, low-regret mechanisms in larger settings where the\noptimal mechanism is unknown.",
          "link": "http://arxiv.org/abs/2106.07877",
          "publishedOn": "2021-06-16T01:21:09.842Z",
          "wordCount": 526,
          "title": "Learning Revenue-Maximizing Auctions With Differentiable Matching. (arXiv:2106.07877v1 [cs.GT])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07708",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Avram_R/0/1/0/all/0/1\">Robert Avram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Olgin_J/0/1/0/all/0/1\">Jeffrey E. Olgin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_A/0/1/0/all/0/1\">Alvin Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_Z/0/1/0/all/0/1\">Zeeshan Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verreault_Julien_L/0/1/0/all/0/1\">Louis Verreault-Julien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abreau_S/0/1/0/all/0/1\">Sean Abreau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_D/0/1/0/all/0/1\">Derek Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1\">Joseph E. Gonzalez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+So_D/0/1/0/all/0/1\">Derek Y. So</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soni_K/0/1/0/all/0/1\">Krishan Soni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tison_G/0/1/0/all/0/1\">Geoffrey H. Tison</a>",
          "description": "Coronary heart disease (CHD) is the leading cause of adult death in the\nUnited States and worldwide, and for which the coronary angiography procedure\nis the primary gateway for diagnosis and clinical management decisions. The\nstandard-of-care for interpretation of coronary angiograms depends upon ad-hoc\nvisual assessment by the physician operator. However, ad-hoc visual\ninterpretation of angiograms is poorly reproducible, highly variable and bias\nprone. Here we show for the first time that fully-automated angiogram\ninterpretation to estimate coronary artery stenosis is possible using a\nsequence of deep neural network algorithms. The algorithmic pipeline we\ndeveloped--called CathAI--achieves state-of-the art performance across the\nsequence of tasks required to accomplish automated interpretation of\nunselected, real-world angiograms. CathAI (Algorithms 1-2) demonstrated\npositive predictive value, sensitivity and F1 score of >=90% to identify the\nprojection angle overall and >=93% for left or right coronary artery angiogram\ndetection, the primary anatomic structures of interest. To predict obstructive\ncoronary artery stenosis (>=70% stenosis), CathAI (Algorithm 4) exhibited an\narea under the receiver operating characteristic curve (AUC) of 0.862 (95% CI:\n0.843-0.880). When externally validated in a healthcare system in another\ncountry, CathAI AUC was 0.869 (95% CI: 0.830-0.907) to predict obstructive\ncoronary artery stenosis. Our results demonstrate that multiple purpose-built\nneural networks can function in sequence to accomplish the complex series of\ntasks required for automated analysis of real-world angiograms. Deployment of\nCathAI may serve to increase standardization and reproducibility in coronary\nstenosis assessment, while providing a robust foundation to accomplish future\ntasks for algorithmic angiographic interpretation.",
          "link": "http://arxiv.org/abs/2106.07708",
          "publishedOn": "2021-06-16T01:21:09.834Z",
          "wordCount": 727,
          "title": "CathAI: Fully Automated Interpretation of Coronary Angiograms Using Neural Networks. (arXiv:2106.07708v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07802",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Ganea_O/0/1/0/all/0/1\">Octavian-Eugen Ganea</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Pattanaik_L/0/1/0/all/0/1\">Lagnajit Pattanaik</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Coley_C/0/1/0/all/0/1\">Connor W. Coley</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Barzilay_R/0/1/0/all/0/1\">Regina Barzilay</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Jensen_K/0/1/0/all/0/1\">Klavs F. Jensen</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Green_W/0/1/0/all/0/1\">William H. Green</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Jaakkola_T/0/1/0/all/0/1\">Tommi S. Jaakkola</a>",
          "description": "Prediction of a molecule's 3D conformer ensemble from the molecular graph\nholds a key role in areas of cheminformatics and drug discovery. Existing\ngenerative models have several drawbacks including lack of modeling important\nmolecular geometry elements (e.g. torsion angles), separate optimization stages\nprone to error accumulation, and the need for structure fine-tuning based on\napproximate classical force-fields or computationally expensive methods such as\nmetadynamics with approximate quantum mechanics calculations at each geometry.\nWe propose GeoMol--an end-to-end, non-autoregressive and SE(3)-invariant\nmachine learning approach to generate distributions of low-energy molecular 3D\nconformers. Leveraging the power of message passing neural networks (MPNNs) to\ncapture local and global graph information, we predict local atomic 3D\nstructures and torsion angles, avoiding unnecessary over-parameterization of\nthe geometric degrees of freedom (e.g. one angle per non-terminal bond). Such\nlocal predictions suffice both for the training loss computation, as well as\nfor the full deterministic conformer assembly (at test time). We devise a\nnon-adversarial optimal transport based loss function to promote diverse\nconformer generation. GeoMol predominantly outperforms popular open-source,\ncommercial, or state-of-the-art machine learning (ML) models, while achieving\nsignificant speed-ups. We expect such differentiable 3D structure generators to\nsignificantly impact molecular modeling and related applications.",
          "link": "http://arxiv.org/abs/2106.07802",
          "publishedOn": "2021-06-16T01:21:09.826Z",
          "wordCount": 637,
          "title": "GeoMol: Torsional Geometric Generation of Molecular 3D Conformer Ensembles. (arXiv:2106.07802v1 [physics.chem-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07887",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meulemans_A/0/1/0/all/0/1\">Alexander Meulemans</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farinha_M/0/1/0/all/0/1\">Matilde Tristany Farinha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ordonez_J/0/1/0/all/0/1\">Javier Garc&#xed;a Ord&#xf3;&#xf1;ez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aceituno_P/0/1/0/all/0/1\">Pau Vilimelis Aceituno</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sacramento_J/0/1/0/all/0/1\">Jo&#xe3;o Sacramento</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grewe_B/0/1/0/all/0/1\">Benjamin F. Grewe</a>",
          "description": "The success of deep learning sparked interest in whether the brain learns by\nusing similar techniques for assigning credit to each synaptic weight for its\ncontribution to the network output. However, the majority of current attempts\nat biologically-plausible learning methods are either non-local in time,\nrequire highly specific connectivity motives, or have no clear link to any\nknown mathematical optimization method. Here, we introduce Deep Feedback\nControl (DFC), a new learning method that uses a feedback controller to drive a\ndeep neural network to match a desired output target and whose control signal\ncan be used for credit assignment. The resulting learning rule is fully local\nin space and time and approximates Gauss-Newton optimization for a wide range\nof feedback connectivity patterns. To further underline its biological\nplausibility, we relate DFC to a multi-compartment model of cortical pyramidal\nneurons with a local voltage-dependent synaptic plasticity rule, consistent\nwith recent theories of dendritic processing. By combining dynamical system\ntheory with mathematical optimization theory, we provide a strong theoretical\nfoundation for DFC that we corroborate with detailed results on toy experiments\nand standard computer-vision benchmarks.",
          "link": "http://arxiv.org/abs/2106.07887",
          "publishedOn": "2021-06-16T01:21:09.818Z",
          "wordCount": 642,
          "title": "Credit Assignment in Neural Networks through Deep Feedback Control. (arXiv:2106.07887v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07798",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ashcraft_C/0/1/0/all/0/1\">Chace Ashcraft</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karra_K/0/1/0/all/0/1\">Kiran Karra</a>",
          "description": "In this paper, we propose a new data poisoning attack and apply it to deep\nreinforcement learning agents. Our attack centers on what we call\nin-distribution triggers, which are triggers native to the data distributions\nthe model will be trained on and deployed in. We outline a simple procedure for\nembedding these, and other, triggers in deep reinforcement learning agents\nfollowing a multi-task learning paradigm, and demonstrate in three common\nreinforcement learning environments. We believe that this work has important\nimplications for the security of deep learning models.",
          "link": "http://arxiv.org/abs/2106.07798",
          "publishedOn": "2021-06-16T01:21:09.796Z",
          "wordCount": 531,
          "title": "Poisoning Deep Reinforcement Learning Agents with In-Distribution Triggers. (arXiv:2106.07798v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07841",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ishfaq_H/0/1/0/all/0/1\">Haque Ishfaq</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_Q/0/1/0/all/0/1\">Qiwen Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_V/0/1/0/all/0/1\">Viet Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ayoub_A/0/1/0/all/0/1\">Alex Ayoub</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhuoran Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhaoran Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Precup_D/0/1/0/all/0/1\">Doina Precup</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Lin F. Yang</a>",
          "description": "We propose a model-free reinforcement learning algorithm inspired by the\npopular randomized least squares value iteration (RLSVI) algorithm as well as\nthe optimism principle. Unlike existing upper-confidence-bound (UCB) based\napproaches, which are often computationally intractable, our algorithm drives\nexploration by simply perturbing the training data with judiciously chosen\ni.i.d. scalar noises. To attain optimistic value function estimation without\nresorting to a UCB-style bonus, we introduce an optimistic reward sampling\nprocedure. When the value functions can be represented by a function class\n$\\mathcal{F}$, our algorithm achieves a worst-case regret bound of\n$\\widetilde{O}(\\mathrm{poly}(d_EH)\\sqrt{T})$ where $T$ is the time elapsed, $H$\nis the planning horizon and $d_E$ is the $\\textit{eluder dimension}$ of\n$\\mathcal{F}$. In the linear setting, our algorithm reduces to LSVI-PHE, a\nvariant of RLSVI, that enjoys an $\\widetilde{\\mathcal{O}}(\\sqrt{d^3H^3T})$\nregret. We complement the theory with an empirical evaluation across known\ndifficult exploration tasks.",
          "link": "http://arxiv.org/abs/2106.07841",
          "publishedOn": "2021-06-16T01:21:09.777Z",
          "wordCount": 600,
          "title": "Randomized Exploration for Reinforcement Learning with General Value Function Approximation. (arXiv:2106.07841v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07760",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Killamsetty_K/0/1/0/all/0/1\">Krishnateja Killamsetty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xujiang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1\">Feng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iyer_R/0/1/0/all/0/1\">Rishabh Iyer</a>",
          "description": "Semi-supervised learning (SSL) algorithms have had great success in recent\nyears in limited labeled data regimes. However, the current state-of-the-art\nSSL algorithms are computationally expensive and entail significant compute\ntime and energy requirements. This can prove to be a huge limitation for many\nsmaller companies and academic groups. Our main insight is that training on a\nsubset of unlabeled data instead of entire unlabeled data enables the current\nSSL algorithms to converge faster, thereby reducing the computational costs\nsignificantly. In this work, we propose RETRIEVE, a coreset selection framework\nfor efficient and robust semi-supervised learning. RETRIEVE selects the coreset\nby solving a mixed discrete-continuous bi-level optimization problem such that\nthe selected coreset minimizes the labeled set loss. We use a one-step gradient\napproximation and show that the discrete optimization problem is approximately\nsubmodular, thereby enabling simple greedy algorithms to obtain the coreset. We\nempirically demonstrate on several real-world datasets that existing SSL\nalgorithms like VAT, Mean-Teacher, FixMatch, when used with RETRIEVE, achieve\na) faster training times, b) better performance when unlabeled data consists of\nOut-of-Distribution(OOD) data and imbalance. More specifically, we show that\nwith minimal accuracy degradation, RETRIEVE achieves a speedup of around 3X in\nthe traditional SSL setting and achieves a speedup of 5X compared to\nstate-of-the-art (SOTA) robust SSL algorithms in the case of imbalance and OOD\ndata.",
          "link": "http://arxiv.org/abs/2106.07760",
          "publishedOn": "2021-06-16T01:21:09.767Z",
          "wordCount": 649,
          "title": "RETRIEVE: Coreset Selection for Efficient and Robust Semi-Supervised Learning. (arXiv:2106.07760v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/1903.04556",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mesquita_D/0/1/0/all/0/1\">Diego Mesquita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blomstedt_P/0/1/0/all/0/1\">Paul Blomstedt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaski_S/0/1/0/all/0/1\">Samuel Kaski</a>",
          "description": "While MCMC methods have become a main work-horse for Bayesian inference,\nscaling them to large distributed datasets is still a challenge. Embarrassingly\nparallel MCMC strategies take a divide-and-conquer stance to achieve this by\nwriting the target posterior as a product of subposteriors, running MCMC for\neach of them in parallel and subsequently combining the results. The challenge\nthen lies in devising efficient aggregation strategies. Current strategies\ntrade-off between approximation quality, and costs of communication and\ncomputation. In this work, we introduce a novel method that addresses these\nissues simultaneously. Our key insight is to introduce a deep invertible\ntransformation to approximate each of the subposteriors. These approximations\ncan be made accurate even for complex distributions and serve as intermediate\nrepresentations, keeping the total communication cost limited. Moreover, they\nenable us to sample from the product of the subposteriors using an efficient\nand stable importance sampling scheme. We demonstrate the approach outperforms\navailable state-of-the-art methods in a range of challenging scenarios,\nincluding high-dimensional and heterogeneous subposteriors.",
          "link": "http://arxiv.org/abs/1903.04556",
          "publishedOn": "2021-06-16T01:21:09.684Z",
          "wordCount": 632,
          "title": "Embarrassingly parallel MCMC using deep invertible transformations. (arXiv:1903.04556v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.07769",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+LeJeune_D/0/1/0/all/0/1\">Daniel LeJeune</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Javadi_H/0/1/0/all/0/1\">Hamid Javadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baraniuk_R/0/1/0/all/0/1\">Richard G. Baraniuk</a>",
          "description": "Among the most successful methods for sparsifying deep (neural) networks are\nthose that adaptively mask the network weights throughout training. By\nexamining this masking, or dropout, in the linear case, we uncover a duality\nbetween such adaptive methods and regularization through the so-called\n\"$\\eta$-trick\" that casts both as iteratively reweighted optimizations. We show\nthat any dropout strategy that adapts to the weights in a monotonic way\ncorresponds to an effective subquadratic regularization penalty, and therefore\nleads to sparse solutions. We obtain the effective penalties for several\npopular sparsification strategies, which are remarkably similar to classical\npenalties commonly used in sparse optimization. Considering variational dropout\nas a case study, we demonstrate similar empirical behavior between the adaptive\ndropout method and classical methods on the task of deep network\nsparsification, validating our theory.",
          "link": "http://arxiv.org/abs/2106.07769",
          "publishedOn": "2021-06-16T01:21:09.666Z",
          "wordCount": 577,
          "title": "The Flip Side of the Reweighted Coin: Duality of Adaptive Dropout and Regularization. (arXiv:2106.07769v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/1910.12016",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kong_H/0/1/0/all/0/1\">Hao Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1\">Canyi Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhouchen Lin</a>",
          "description": "Recently, the \\textit{Tensor Nuclear Norm~(TNN)} regularization based on\nt-SVD has been widely used in various low tubal-rank tensor recovery tasks.\nHowever, these models usually require smooth change of data along the third\ndimension to ensure their low rank structures. In this paper, we propose a new\ndefinition of data dependent tensor rank named \\textit{tensor Q-rank} by a\nlearnable orthogonal matrix $\\mathbf{Q}$, and further introduce a unified data\ndependent low rank tensor recovery model. According to the low rank hypothesis,\nwe introduce two explainable selection method of $\\mathbf{Q}$, under which the\ndata tensor may have a more significant low tensor Q-rank structure than that\nof low tubal-rank structure. Specifically, maximizing the variance of singular\nvalue distribution leads to Variance Maximization Tensor Q-Nuclear\nnorm~(VMTQN), while minimizing the value of nuclear norm through manifold\noptimization leads to Manifold Optimization Tensor Q-Nuclear norm~(MOTQN).\nMoreover, we apply these two models to the low rank tensor completion problem,\nand then give an effective algorithm and briefly analyze why our method works\nbetter than TNN based methods in the case of complex data with low sampling\nrate. Finally, experimental results on real-world datasets demonstrate the\nsuperiority of our proposed model in the tensor completion problem with respect\nto other tensor rank regularization models.",
          "link": "http://arxiv.org/abs/1910.12016",
          "publishedOn": "2021-06-16T01:21:09.654Z",
          "wordCount": 679,
          "title": "Tensor Q-Rank: New Data Dependent Definition of Tensor Rank. (arXiv:1910.12016v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.07898",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Liu_L/0/1/0/all/0/1\">Lang Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pillutla_K/0/1/0/all/0/1\">Krishna Pillutla</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Welleck_S/0/1/0/all/0/1\">Sean Welleck</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Oh_S/0/1/0/all/0/1\">Sewoong Oh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Harchaoui_Z/0/1/0/all/0/1\">Zaid Harchaoui</a>",
          "description": "The spectacular success of deep generative models calls for quantitative\ntools to measure their statistical performance. Divergence frontiers have\nrecently been proposed as an evaluation framework for generative models, due to\ntheir ability to measure the quality-diversity trade-off inherent to deep\ngenerative modeling. However, the statistical behavior of divergence frontiers\nestimated from data remains unknown to this day. In this paper, we establish\nnon-asymptotic bounds on the sample complexity of the plug-in estimator of\ndivergence frontiers. Along the way, we introduce a novel integral summary of\ndivergence frontiers. We derive the corresponding non-asymptotic bounds and\ndiscuss the choice of the quantization level by balancing the two types of\napproximation errors arisen from its computation. We also augment the\ndivergence frontier framework by investigating the statistical performance of\nsmoothed distribution estimators such as the Good-Turing estimator. We\nillustrate the theoretical results with numerical examples from natural\nlanguage processing and computer vision.",
          "link": "http://arxiv.org/abs/2106.07898",
          "publishedOn": "2021-06-16T01:21:09.647Z",
          "wordCount": 590,
          "title": "Divergence Frontiers for Generative Models: Sample Complexity, Quantization Level, and Frontier Integral. (arXiv:2106.07898v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/1910.10897",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1\">Tianhe Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quillen_D/0/1/0/all/0/1\">Deirdre Quillen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1\">Zhanpeng He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Julian_R/0/1/0/all/0/1\">Ryan Julian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narayan_A/0/1/0/all/0/1\">Avnish Narayan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shively_H/0/1/0/all/0/1\">Hayden Shively</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bellathur_A/0/1/0/all/0/1\">Adithya Bellathur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hausman_K/0/1/0/all/0/1\">Karol Hausman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1\">Chelsea Finn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1\">Sergey Levine</a>",
          "description": "Meta-reinforcement learning algorithms can enable robots to acquire new\nskills much more quickly, by leveraging prior experience to learn how to learn.\nHowever, much of the current research on meta-reinforcement learning focuses on\ntask distributions that are very narrow. For example, a commonly used\nmeta-reinforcement learning benchmark uses different running velocities for a\nsimulated robot as different tasks. When policies are meta-trained on such\nnarrow task distributions, they cannot possibly generalize to more quickly\nacquire entirely new tasks. Therefore, if the aim of these methods is to enable\nfaster acquisition of entirely new behaviors, we must evaluate them on task\ndistributions that are sufficiently broad to enable generalization to new\nbehaviors. In this paper, we propose an open-source simulated benchmark for\nmeta-reinforcement learning and multi-task learning consisting of 50 distinct\nrobotic manipulation tasks. Our aim is to make it possible to develop\nalgorithms that generalize to accelerate the acquisition of entirely new,\nheld-out tasks. We evaluate 7 state-of-the-art meta-reinforcement learning and\nmulti-task learning algorithms on these tasks. Surprisingly, while each task\nand its variations (e.g., with different object positions) can be learned with\nreasonable success, these algorithms struggle to learn with multiple tasks at\nthe same time, even with as few as ten distinct training tasks. Our analysis\nand open-source environments pave the way for future research in multi-task\nlearning and meta-learning that can enable meaningful generalization, thereby\nunlocking the full potential of these methods.",
          "link": "http://arxiv.org/abs/1910.10897",
          "publishedOn": "2021-06-16T01:21:09.640Z",
          "wordCount": 759,
          "title": "Meta-World: A Benchmark and Evaluation for Multi-Task and Meta Reinforcement Learning. (arXiv:1910.10897v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.07714",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yufei Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belkhir_N/0/1/0/all/0/1\">Nacim Belkhir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Angulo_J/0/1/0/all/0/1\">Jesus Angulo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_A/0/1/0/all/0/1\">Angela Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Franchi_G/0/1/0/all/0/1\">Gianni Franchi</a>",
          "description": "Deep Neural Networks (DNNs) are generated by sequentially performing linear\nand non-linear processes. Using a combination of linear and non-linear\nprocedures is critical for generating a sufficiently deep feature space. The\nmajority of non-linear operators are derivations of activation functions or\npooling functions. Mathematical morphology is a branch of mathematics that\nprovides non-linear operators for a variety of image processing problems. We\ninvestigate the utility of integrating these operations in an end-to-end deep\nlearning framework in this paper. DNNs are designed to acquire a realistic\nrepresentation for a particular job. Morphological operators give topological\ndescriptors that convey salient information about the shapes of objects\ndepicted in images. We propose a method based on meta-learning to incorporate\nmorphological operators into DNNs. The learned architecture demonstrates how\nour novel morphological operations significantly increase DNN performance on\nvarious tasks, including picture classification and edge detection.",
          "link": "http://arxiv.org/abs/2106.07714",
          "publishedOn": "2021-06-16T01:21:09.633Z",
          "wordCount": 584,
          "title": "Learning Deep Morphological Networks with Neural Architecture Search. (arXiv:2106.07714v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07832",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jaini_P/0/1/0/all/0/1\">Priyank Jaini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holdijk_L/0/1/0/all/0/1\">Lars Holdijk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1\">Max Welling</a>",
          "description": "We focus on the problem of efficient sampling and learning of probability\ndensities by incorporating symmetries in probabilistic models. We first\nintroduce Equivariant Stein Variational Gradient Descent algorithm -- an\nequivariant sampling method based on Stein's identity for sampling from\ndensities with symmetries. Equivariant SVGD explicitly incorporates symmetry\ninformation in a density through equivariant kernels which makes the resultant\nsampler efficient both in terms of sample complexity and the quality of\ngenerated samples. Subsequently, we define equivariant energy based models to\nmodel invariant densities that are learned using contrastive divergence. By\nutilizing our equivariant SVGD for training equivariant EBMs, we propose new\nways of improving and scaling up training of energy based models. We apply\nthese equivariant energy models for modelling joint densities in regression and\nclassification tasks for image datasets, many-body particle systems and\nmolecular structure generation.",
          "link": "http://arxiv.org/abs/2106.07832",
          "publishedOn": "2021-06-16T01:21:09.623Z",
          "wordCount": 574,
          "title": "Learning Equivariant Energy Based Models with Equivariant Stein Variational Gradient Descent. (arXiv:2106.07832v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08295",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nagel_M/0/1/0/all/0/1\">Markus Nagel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fournarakis_M/0/1/0/all/0/1\">Marios Fournarakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amjad_R/0/1/0/all/0/1\">Rana Ali Amjad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bondarenko_Y/0/1/0/all/0/1\">Yelysei Bondarenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baalen_M/0/1/0/all/0/1\">Mart van Baalen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blankevoort_T/0/1/0/all/0/1\">Tijmen Blankevoort</a>",
          "description": "While neural networks have advanced the frontiers in many applications, they\noften come at a high computational cost. Reducing the power and latency of\nneural network inference is key if we want to integrate modern networks into\nedge devices with strict power and compute requirements. Neural network\nquantization is one of the most effective ways of achieving these savings but\nthe additional noise it induces can lead to accuracy degradation. In this white\npaper, we introduce state-of-the-art algorithms for mitigating the impact of\nquantization noise on the network's performance while maintaining low-bit\nweights and activations. We start with a hardware motivated introduction to\nquantization and then consider two main classes of algorithms: Post-Training\nQuantization (PTQ) and Quantization-Aware-Training (QAT). PTQ requires no\nre-training or labelled data and is thus a lightweight push-button approach to\nquantization. In most cases, PTQ is sufficient for achieving 8-bit quantization\nwith close to floating-point accuracy. QAT requires fine-tuning and access to\nlabeled training data but enables lower bit quantization with competitive\nresults. For both solutions, we provide tested pipelines based on existing\nliterature and extensive experimentation that lead to state-of-the-art\nperformance for common deep learning models and tasks.",
          "link": "http://arxiv.org/abs/2106.08295",
          "publishedOn": "2021-06-16T01:21:09.583Z",
          "wordCount": 630,
          "title": "A White Paper on Neural Network Quantization. (arXiv:2106.08295v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07806",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Bridge_C/0/1/0/all/0/1\">Christopher P. Bridge</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gorman_C/0/1/0/all/0/1\">Chris Gorman</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pieper_S/0/1/0/all/0/1\">Steven Pieper</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Doyle_S/0/1/0/all/0/1\">Sean W. Doyle</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lennerz_J/0/1/0/all/0/1\">Jochen K. Lennerz</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kalpathy_Cramer_J/0/1/0/all/0/1\">Jayashree Kalpathy-Cramer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Clunie_D/0/1/0/all/0/1\">David A. Clunie</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fedorov_A/0/1/0/all/0/1\">Andriy Y. Fedorov</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Herrmann_M/0/1/0/all/0/1\">Markus D. Herrmann</a>",
          "description": "Machine learning is revolutionizing image-based diagnostics in pathology and\nradiology. ML models have shown promising results in research settings, but\ntheir lack of interoperability has been a major barrier for clinical\nintegration and evaluation. The DICOM a standard specifies Information Object\nDefinitions and Services for the representation and communication of digital\nimages and related information, including image-derived annotations and\nanalysis results. However, the complexity of the standard represents an\nobstacle for its adoption in the ML community and creates a need for software\nlibraries and tools that simplify working with data sets in DICOM format. Here\nwe present the highdicom library, which provides a high-level application\nprogramming interface for the Python programming language that abstracts\nlow-level details of the standard and enables encoding and decoding of\nimage-derived information in DICOM format in a few lines of Python code. The\nhighdicom library ties into the extensive Python ecosystem for image processing\nand machine learning. Simultaneously, by simplifying creation and parsing of\nDICOM-compliant files, highdicom achieves interoperability with the medical\nimaging systems that hold the data used to train and run ML models, and\nultimately communicate and store model outputs for clinical use. We demonstrate\nthrough experiments with slide microscopy and computed tomography imaging,\nthat, by bridging these two ecosystems, highdicom enables developers to train\nand evaluate state-of-the-art ML models in pathology and radiology while\nremaining compliant with the DICOM standard and interoperable with clinical\nsystems at all stages. To promote standardization of ML research and streamline\nthe ML model development and deployment process, we made the library available\nfree and open-source.",
          "link": "http://arxiv.org/abs/2106.07806",
          "publishedOn": "2021-06-16T01:21:09.475Z",
          "wordCount": 740,
          "title": "Highdicom: A Python library for standardized encoding of image annotations and machine learning model outputs in pathology and radiology. (arXiv:2106.07806v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07825",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mashayekhi_M/0/1/0/all/0/1\">Maryam Mashayekhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tapia_I/0/1/0/all/0/1\">Itzel Ramirez Tapia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balagopal_A/0/1/0/all/0/1\">Anjali Balagopal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_X/0/1/0/all/0/1\">Xinran Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barkousaraie_A/0/1/0/all/0/1\">Azar Sadeghnejad Barkousaraie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McBeth_R/0/1/0/all/0/1\">Rafe McBeth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_M/0/1/0/all/0/1\">Mu-Han Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1\">Steve Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1\">Dan Nguyen</a>",
          "description": "Typically, the current dose prediction models are limited to small amounts of\ndata and require re-training for a specific site, often leading to suboptimal\nperformance. We propose a site-agnostic, 3D dose distribution prediction model\nusing deep learning that can leverage data from any treatment site, thus\nincreasing the total data available to train the model. Applying our proposed\nmodel to a new target treatment site requires only a brief fine-tuning of the\nmodel to the new data and involves no modifications to the model input channels\nor its parameters. Thus, it can be efficiently adapted to a different treatment\nsite, even with a small training dataset.",
          "link": "http://arxiv.org/abs/2106.07825",
          "publishedOn": "2021-06-16T01:21:09.468Z",
          "wordCount": 554,
          "title": "Site-Agnostic 3D Dose Distribution Prediction with Deep Learning Neural Networks. (arXiv:2106.07825v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07718",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+E%2E_W/0/1/0/all/0/1\">Wilson E. Marc&#xed;lio-Jr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eler_D/0/1/0/all/0/1\">Danilo M. Eler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paulovich_F/0/1/0/all/0/1\">Fernando V. Paulovich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martins_R/0/1/0/all/0/1\">Rafael M. Martins</a>",
          "description": "Dimensionality reduction (DR) techniques help analysts to understand patterns\nin high-dimensional spaces. These techniques, often represented by scatter\nplots, are employed in diverse science domains and facilitate similarity\nanalysis among clusters and data samples. For datasets containing many\ngranularities or when analysis follows the information visualization mantra,\nhierarchical DR techniques are the most suitable approach since they present\nmajor structures beforehand and details on demand. However, current\nhierarchical DR techniques are not fully capable of addressing literature\nproblems because they do not preserve the projection mental map across\nhierarchical levels or are not suitable for most data types. This work presents\nHUMAP, a novel hierarchical dimensionality reduction technique designed to be\nflexible on preserving local and global structures and preserve the mental map\nthroughout hierarchical exploration. We provide empirical evidence of our\ntechnique's superiority compared with current hierarchical approaches and show\ntwo case studies to demonstrate its strengths.",
          "link": "http://arxiv.org/abs/2106.07718",
          "publishedOn": "2021-06-16T01:21:09.401Z",
          "wordCount": 579,
          "title": "HUMAP: Hierarchical Uniform Manifold Approximation and Projection. (arXiv:2106.07718v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2004.11468",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Benko_Z/0/1/0/all/0/1\">Zsigmond Benk&#x151;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Babel_T/0/1/0/all/0/1\">Tam&#xe1;s B&#xe1;bel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Somogyvari_Z/0/1/0/all/0/1\">Zolt&#xe1;n Somogyv&#xe1;ri</a>",
          "description": "Recognition of anomalous events is a challenging but critical task in many\nscientific and industrial fields, especially when the properties of anomalies\nare unknown. In this paper, we introduce a new anomaly concept called \"unicorn\"\nor unique event and present a new, model-free, unsupervised detection algorithm\nto detect unicorns. The key component of the new algorithm is the Temporal\nOutlier Factor (TOF) to measure the uniqueness of events in continuous data\nsets from dynamic systems. The concept of unique events differs significantly\nfrom traditional outliers in many aspects: while repetitive outliers are no\nlonger unique events, a unique event is not necessarily an outlier; it does not\nnecessarily fall out from the distribution of normal activity. The performance\nof our algorithm was examined in recognizing unique events on different types\nof simulated data sets with anomalies and it was compared with the Local\nOutlier Factor (LOF) and discord discovery algorithms. TOF had superior\nperformance compared to LOF and discord algorithms even in recognizing\ntraditional outliers and it also recognized unique events that those did not.\nThe benefits of the unicorn concept and the new detection method were\nillustrated by example data sets from very different scientific fields. Our\nalgorithm successfully recognized unique events in those cases where they were\nalready known such as the gravitational waves of a binary black hole merger on\nLIGO detector data and the signs of respiratory failure on ECG data series.\nFurthermore, unique events were found on the LIBOR data set of the last 30\nyears.",
          "link": "http://arxiv.org/abs/2004.11468",
          "publishedOn": "2021-06-16T01:21:09.222Z",
          "wordCount": 742,
          "title": "How to find a unicorn: a novel model-free, unsupervised anomaly detection method for time series. (arXiv:2004.11468v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08233",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Czolbe_S/0/1/0/all/0/1\">Steffen Czolbe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feragen_A/0/1/0/all/0/1\">Aasa Feragen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krause_O/0/1/0/all/0/1\">Oswin Krause</a>",
          "description": "Geometric alignment appears in a variety of applications, ranging from domain\nadaptation, optimal transport, and normalizing flows in machine learning;\noptical flow and learned augmentation in computer vision and deformable\nregistration within biomedical imaging. A recurring challenge is the alignment\nof domains whose topology is not the same; a problem that is routinely ignored,\npotentially introducing bias in downstream analysis. As a first step towards\nsolving such alignment problems, we propose an unsupervised topological\ndifference detection algorithm. The model is based on a conditional variational\nauto-encoder and detects topological anomalies with regards to a reference\nalongside the registration step. We consider both a) topological changes in the\nimage under spatial variation and b) unexpected transformations. Our approach\nis validated on a proxy task of unsupervised anomaly detection in images.",
          "link": "http://arxiv.org/abs/2106.08233",
          "publishedOn": "2021-06-16T01:21:09.202Z",
          "wordCount": 573,
          "title": "Spot the Difference: Topological Anomaly Detection via Geometric Alignment. (arXiv:2106.08233v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08285",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Prangemeier_T/0/1/0/all/0/1\">Tim Prangemeier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reich_C/0/1/0/all/0/1\">Christoph Reich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wildner_C/0/1/0/all/0/1\">Christian Wildner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koeppl_H/0/1/0/all/0/1\">Heinz Koeppl</a>",
          "description": "Time-lapse fluorescent microscopy (TLFM) combined with predictive\nmathematical modelling is a powerful tool to study the inherently dynamic\nprocesses of life on the single-cell level. Such experiments are costly,\ncomplex and labour intensive. A complimentary approach and a step towards\ncompletely in silico experiments, is to synthesise the imagery itself. Here, we\npropose Multi-StyleGAN as a descriptive approach to simulate time-lapse\nfluorescence microscopy imagery of living cells, based on a past experiment.\nThis novel generative adversarial network synthesises a multi-domain sequence\nof consecutive timesteps. We showcase Multi-StyleGAN on imagery of multiple\nlive yeast cells in microstructured environments and train on a dataset\nrecorded in our laboratory. The simulation captures underlying biophysical\nfactors and time dependencies, such as cell morphology, growth, physical\ninteractions, as well as the intensity of a fluorescent reporter protein. An\nimmediate application is to generate additional training and validation data\nfor feature extraction algorithms or to aid and expedite development of\nadvanced experimental techniques such as online monitoring or control of cells.\n\nCode and dataset is available at\nhttps://git.rwth-aachen.de/bcs/projects/tp/multi-stylegan.",
          "link": "http://arxiv.org/abs/2106.08285",
          "publishedOn": "2021-06-16T01:21:09.193Z",
          "wordCount": 640,
          "title": "Multi-StyleGAN: Towards Image-Based Simulation of Time-Lapse Live-Cell Microscopy. (arXiv:2106.08285v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08269",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Henriques_L/0/1/0/all/0/1\">Luis Felipe Henriques</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Colcher_S/0/1/0/all/0/1\">S&#xe9;rgio Colcher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Milidiu_R/0/1/0/all/0/1\">Ruy Luiz Milidi&#xfa;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bulcao_A/0/1/0/all/0/1\">Andr&#xe9; Bulc&#xe3;o</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barros_P/0/1/0/all/0/1\">Pablo Barros</a>",
          "description": "Nowadays, subsurface salt body localization and delineation, also called\nsemantic segmentation of salt bodies, are among the most challenging\ngeophysicist tasks. Thus, identifying large salt bodies is notoriously tricky\nand is crucial for identifying hydrocarbon reservoirs and drill path planning.\nThis work proposes a Data Augmentation method based on training two generative\nmodels to augment the number of samples in a seismic image dataset for the\nsemantic segmentation of salt bodies. Our method uses deep learning models to\ngenerate pairs of seismic image patches and their respective salt masks for the\nData Augmentation. The first model is a Variational Autoencoder and is\nresponsible for generating patches of salt body masks. The second is a\nConditional Normalizing Flow model, which receives the generated masks as\ninputs and generates the associated seismic image patches. We evaluate the\nproposed method by comparing the performance of ten distinct state-of-the-art\nmodels for semantic segmentation, trained with and without the generated\naugmentations, in a dataset from two synthetic seismic images. The proposed\nmethodology yields an average improvement of 8.57% in the IoU metric across all\ncompared models. The best result is achieved by a DeeplabV3+ model variant,\nwhich presents an IoU score of 95.17% when trained with our augmentations.\nAdditionally, our proposal outperformed six selected data augmentation methods,\nand the most significant improvement in the comparison, of 9.77%, is achieved\nby composing our DA with augmentations from an elastic transformation. At last,\nwe show that the proposed method is adaptable for a larger context size by\nachieving results comparable to the obtained on the smaller context size.",
          "link": "http://arxiv.org/abs/2106.08269",
          "publishedOn": "2021-06-16T01:21:09.187Z",
          "wordCount": 719,
          "title": "Generating Data Augmentation samples for Semantic Segmentation of Salt Bodies in a Synthetic Seismic Image Dataset. (arXiv:2106.08269v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08027",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pfeiffer_P/0/1/0/all/0/1\">Peter Pfeiffer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lahann_J/0/1/0/all/0/1\">Johannes Lahann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fettke_P/0/1/0/all/0/1\">Peter Fettke</a>",
          "description": "Learning meaningful representations of data is an important aspect of machine\nlearning and has recently been successfully applied to many domains like\nlanguage understanding or computer vision. Instead of training a model for one\nspecific task, representation learning is about training a model to capture all\nuseful information in the underlying data and make it accessible for a\npredictor. For predictive process analytics, it is essential to have all\nexplanatory characteristics of a process instance available when making\npredictions about the future, as well as for clustering and anomaly detection.\nDue to the large variety of perspectives and types within business process\ndata, generating a good representation is a challenging task. In this paper, we\npropose a novel approach for representation learning of business process\ninstances which can process and combine most perspectives in an event log. In\nconjunction with a self-supervised pre-training method, we show the\ncapabilities of the approach through a visualization of the representation\nspace and case retrieval. Furthermore, the pre-trained model is fine-tuned to\nmultiple process prediction tasks and demonstrates its effectiveness in\ncomparison with existing approaches.",
          "link": "http://arxiv.org/abs/2106.08027",
          "publishedOn": "2021-06-16T01:21:09.180Z",
          "wordCount": 630,
          "title": "Multivariate Business Process Representation Learning utilizing Gramian Angular Fields and Convolutional Neural Networks. (arXiv:2106.08027v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08206",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Surana_A/0/1/0/all/0/1\">Amit Surana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Can Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajapakse_I/0/1/0/all/0/1\">Indika Rajapakse</a>",
          "description": "In this paper, we propose two novel approaches for hypergraph comparison. The\nfirst approach transforms the hypergraph into a graph representation for use of\nstandard graph dissimilarity measures. The second approach exploits the\nmathematics of tensors to intrinsically capture multi-way relations. For each\napproach, we present measures that assess hypergraph dissimilarity at a\nspecific scale or provide a more holistic multi-scale comparison. We test these\nmeasures on synthetic hypergraphs and apply them to biological datasets.",
          "link": "http://arxiv.org/abs/2106.08206",
          "publishedOn": "2021-06-16T01:21:09.173Z",
          "wordCount": 487,
          "title": "Hypergraph Dissimilarity Measures. (arXiv:2106.08206v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08151",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Schneider_M/0/1/0/all/0/1\">Maja Schneider</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Broszeit_A/0/1/0/all/0/1\">Amelie Broszeit</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Korner_M/0/1/0/all/0/1\">Marco K&#xf6;rner</a>",
          "description": "We present EuroCrops, a dataset based on self-declared field annotations for\ntraining and evaluating methods for crop type classification and mapping,\ntogether with its process of acquisition and harmonisation. By this, we aim to\nenrich the research efforts and discussion for data-driven land cover\nclassification via Earth observation and remote sensing. Additionally, through\ninclusion of self-declarations gathered in the scope of subsidy control from\nall countries of the European Union (EU), this dataset highlights the\ndifficulties and pitfalls one comes across when operating on a transnational\nlevel. We, therefore, also introduce a new taxonomy scheme, HCAT-ID, that\naspires to capture all the aspects of reference data originating from\nadministrative and agency databases. To address researchers from both the\nremote sensing and the computer vision and machine learning communities, we\npublish the dataset in different formats and processing levels.",
          "link": "http://arxiv.org/abs/2106.08151",
          "publishedOn": "2021-06-16T01:21:09.149Z",
          "wordCount": 607,
          "title": "EuroCrops: A Pan-European Dataset for Time Series Crop Type Classification. (arXiv:2106.08151v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08146",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_P/0/1/0/all/0/1\">Peiyuan Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiu Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1\">Yu-Hang Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_M/0/1/0/all/0/1\">Muqing Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anderson_A/0/1/0/all/0/1\">Amity Anderson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murugesan_V/0/1/0/all/0/1\">Vijayakumar Murugesan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hollas_A/0/1/0/all/0/1\">Aaron Hollas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>",
          "description": "The solvation free energy of organic molecules is a critical parameter in\ndetermining emergent properties such as solubility, liquid-phase equilibrium\nconstants, and pKa and redox potentials in an organic redox flow battery. In\nthis work, we present a machine learning (ML) model that can learn and predict\nthe aqueous solvation free energy of an organic molecule using Gaussian process\nregression method based on a new molecular graph kernel. To investigate the\nperformance of the ML model on electrostatic interaction, the nonpolar\ninteraction contribution of solvent and the conformational entropy of solute in\nsolvation free energy, three data sets with implicit or explicit water solvent\nmodels, and contribution of conformational entropy of solute are tested. We\ndemonstrate that our ML model can predict the solvation free energy of\nmolecules at chemical accuracy with a mean absolute error of less than 1\nkcal/mol for subsets of the QM9 dataset and the Freesolv database. To solve the\ngeneral data scarcity problem for a graph-based ML model, we propose a\ndimension reduction algorithm based on the distance between molecular graphs,\nwhich can be used to examine the diversity of the molecular data set. It\nprovides a promising way to build a minimum training set to improve prediction\nfor certain test sets where the space of molecular structures is predetermined.",
          "link": "http://arxiv.org/abs/2106.08146",
          "publishedOn": "2021-06-16T01:21:09.140Z",
          "wordCount": 683,
          "title": "Graphical Gaussian Process Regression Model for Aqueous Solvation Free Energy Prediction of Organic Molecules in Redox Flow Battery. (arXiv:2106.08146v1 [cs.CE])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08153",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Foote_A/0/1/0/all/0/1\">Alex Foote</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Asif_A/0/1/0/all/0/1\">Amina Asif</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Azam_A/0/1/0/all/0/1\">Ayesha Azam</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rajpoot_N/0/1/0/all/0/1\">Nasir Rajpoot</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Minhas_F/0/1/0/all/0/1\">Fayyaz Minhas</a>",
          "description": "Deep learning models are routinely employed in computational pathology\n(CPath) for solving problems of diagnostic and prognostic significance.\nTypically, the generalization performance of CPath models is analyzed using\nevaluation protocols such as cross-validation and testing on multi-centric\ncohorts. However, to ensure that such CPath solutions are robust and safe for\nuse in a clinical setting, a critical analysis of their predictive performance\nand vulnerability to adversarial attacks is required, which is the focus of\nthis paper. Specifically, we show that a highly accurate model for\nclassification of tumour patches in pathology images (AUC > 0.95) can easily be\nattacked with minimal perturbations which are imperceptible to lay humans and\ntrained pathologists alike. Our analytical results show that it is possible to\ngenerate single-instance white-box attacks on specific input images with high\nsuccess rate and low perturbation energy. Furthermore, we have also generated a\nsingle universal perturbation matrix using the training dataset only which,\nwhen added to unseen test images, results in forcing the trained neural network\nto flip its prediction labels with high confidence at a success rate of > 84%.\nWe systematically analyze the relationship between perturbation energy of an\nadversarial attack, its impact on morphological constructs of clinical\nsignificance, their perceptibility by a trained pathologist and saliency maps\nobtained using deep learning models. Based on our analysis, we strongly\nrecommend that computational pathology models be critically analyzed using the\nproposed adversarial validation strategy prior to clinical adoption.",
          "link": "http://arxiv.org/abs/2106.08153",
          "publishedOn": "2021-06-16T01:21:09.112Z",
          "wordCount": 686,
          "title": "Now You See It, Now You Dont: Adversarial Vulnerabilities in Computational Pathology. (arXiv:2106.08153v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08008",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ingolfsson_T/0/1/0/all/0/1\">Thorir Mar Ingolfsson</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cossettini_A/0/1/0/all/0/1\">Andrea Cossettini</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_X/0/1/0/all/0/1\">Xiaying Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tabanelli_E/0/1/0/all/0/1\">Enrico Tabanelli</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tagliavini_G/0/1/0/all/0/1\">Guiseppe Tagliavini</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ryvlin_P/0/1/0/all/0/1\">Philippe Ryvlin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Benini_L/0/1/0/all/0/1\">Luca Benini</a>",
          "description": "We present the implementation of seizure detection algorithms based on a\nminimal number of EEG channels on a parallel ultra-low-power embedded platform.\nThe analyses are based on the CHB-MIT dataset, and include explorations of\ndifferent classification approaches (Support Vector Machines, Random Forest,\nExtra Trees, AdaBoost) and different pre/post-processing techniques to maximize\nsensitivity while guaranteeing no false alarms. We analyze global and\nsubject-specific approaches, considering all 23-electrodes or only 4 temporal\nchannels. For 8s window size and subject-specific approach, we report zero\nfalse positives and 100% sensitivity. These algorithms are parallelized and\noptimized for a parallel ultra-low power (PULP) platform, enabling 300h of\ncontinuous monitoring on a 300 mAh battery, in a wearable form factor and power\nbudget. These results pave the way for the implementation of affordable,\nwearable, long-term epilepsy monitoring solutions with low false-positive rates\nand high sensitivity, meeting both patient and caregiver requirements.",
          "link": "http://arxiv.org/abs/2106.08008",
          "publishedOn": "2021-06-16T01:21:09.103Z",
          "wordCount": 601,
          "title": "Towards Long-term Non-invasive Monitoring for Epilepsy via Wearable EEG Devices. (arXiv:2106.08008v1 [eess.SP])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08229",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Castro_P/0/1/0/all/0/1\">Pablo Samuel Castro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kastner_T/0/1/0/all/0/1\">Tyler Kastner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panangaden_P/0/1/0/all/0/1\">Prakash Panangaden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rowland_M/0/1/0/all/0/1\">Mark Rowland</a>",
          "description": "We present a new behavioural distance over the state space of a Markov\ndecision process, and demonstrate the use of this distance as an effective\nmeans of shaping the learnt representations of deep reinforcement learning\nagents. While existing notions of state similarity are typically difficult to\nlearn at scale due to high computational cost and lack of sample-based\nalgorithms, our newly-proposed distance addresses both of these issues. In\naddition to providing detailed theoretical analysis, we provide empirical\nevidence that learning this distance alongside the value function yields\nstructured and informative representations, including strong results on the\nArcade Learning Environment benchmark.",
          "link": "http://arxiv.org/abs/2106.08229",
          "publishedOn": "2021-06-16T01:21:09.083Z",
          "wordCount": 538,
          "title": "MICo: Learning improved representations via sampling-based state similarity for Markov decision processes. (arXiv:2106.08229v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08138",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Corzo_H/0/1/0/all/0/1\">Hector H. Corzo</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Sehanobish_A/0/1/0/all/0/1\">Arijit Sehanobish</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Kara_O/0/1/0/all/0/1\">Onur Kara</a>",
          "description": "In this report, the application of the Quantum Potential Neural Network\n(QPNN) framework to many electron atomic systems is presented. For this study,\nfull configuration interaction (FCI) one--electron density functions within\npredefined limits of accuracy were used to train the QPNN. The obtained results\nsuggest that this new neural network is capable of learning the effective\npotential functions of many electron atoms in a completely unsupervised manner,\nand using only limited information from the probability density. Using the\neffective potential functions learned for each of the studied systems the QPNN\nwas able to estimate the total energies of each of the systems (with a maximum\nof 10 trials) with a remarkable accuracy when compared to the FCI energies.",
          "link": "http://arxiv.org/abs/2106.08138",
          "publishedOn": "2021-06-16T01:21:09.067Z",
          "wordCount": 559,
          "title": "Application of the Quantum Potential Neural Network to multi-electronic atoms. (arXiv:2106.08138v1 [quant-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08112",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1\">Han-Jia Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1\">Da-Wei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_L/0/1/0/all/0/1\">Lanqing Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhenguo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1\">Xiu-Shen Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_D/0/1/0/all/0/1\">De-Chuan Zhan</a>",
          "description": "One single instance could possess multiple portraits and reveal diverse\nrelationships with others according to different contexts. Those ambiguities\nincrease the difficulty of learning a generalizable model when there exists one\nconcept or mixed concepts in a task. We propose a general approach Learning to\nDecompose Network (LeadNet) for both two cases, which contextualizes a model\nthrough meta-learning multiple maps for concepts discovery -- the\nrepresentations of instances are decomposed and adapted conditioned on the\ncontexts. Through taking a holistic view over multiple latent components over\ninstances in a sampled pseudo task, LeadNet learns to automatically select the\nright concept via incorporating those rich semantics inside and between\nobjects. LeadNet demonstrates its superiority in various applications,\nincluding exploring multiple views of confusing tasks, out-of-distribution\nrecognition, and few-shot image classification.",
          "link": "http://arxiv.org/abs/2106.08112",
          "publishedOn": "2021-06-16T01:21:09.050Z",
          "wordCount": 562,
          "title": "Contextualizing Multiple Tasks via Learning to Decompose. (arXiv:2106.08112v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08279",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ying_C/0/1/0/all/0/1\">Chengxuan Ying</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Mingqi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1\">Shuxin Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ke_G/0/1/0/all/0/1\">Guolin Ke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1\">Shengjie Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_T/0/1/0/all/0/1\">Tianle Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chenglin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuxin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yanming Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1\">Di He</a>",
          "description": "In this technical report, we present our solution of KDD Cup 2021 OGB\nLarge-Scale Challenge - PCQM4M-LSC Track. We adopt Graphormer and ExpC as our\nbasic models. We train each model by 8-fold cross-validation, and additionally\ntrain two Graphormer models on the union of training and validation sets with\ndifferent random seeds. For final submission, we use a naive ensemble for these\n18 models by taking average of their outputs. Using our method, our team\nMachineLearning achieved 0.1200 MAE on test set.",
          "link": "http://arxiv.org/abs/2106.08279",
          "publishedOn": "2021-06-16T01:21:09.031Z",
          "wordCount": 524,
          "title": "Awardee Solution of KDD Cup 2021 OGB Large-Scale Challenge Graph-Level Track. (arXiv:2106.08279v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07964",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiangyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_M/0/1/0/all/0/1\">Min Ye</a>",
          "description": "The cyclically equivariant neural decoder was recently proposed in [Chen-Ye,\nInternational Conference on Machine Learning, 2021] to decode cyclic codes. In\nthe same paper, a list decoding procedure was also introduced for two widely\nused classes of cyclic codes -- BCH codes and punctured Reed-Muller (RM) codes.\nWhile the list decoding procedure significantly improves the Frame Error Rate\n(FER) of the cyclically equivariant neural decoder, the Bit Error Rate (BER) of\nthe list decoding procedure is even worse than the unique decoding algorithm\nwhen the list size is small. In this paper, we propose an improved version of\nthe list decoding algorithm for BCH codes and punctured RM codes. Our new\nproposal significantly reduces the BER while maintaining the same (in some\ncases even smaller) FER. More specifically, our new decoder provides up to\n$2$dB gain over the previous list decoder when measured by BER, and the running\ntime of our new decoder is $15\\%$ smaller. Code available at\nhttps://github.com/improvedlistdecoder/code",
          "link": "http://arxiv.org/abs/2106.07964",
          "publishedOn": "2021-06-16T01:21:09.025Z",
          "wordCount": 601,
          "title": "Improving the List Decoding Version of the Cyclically Equivariant Neural Decoder. (arXiv:2106.07964v1 [cs.IT])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08272",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lapeyrolerie_M/0/1/0/all/0/1\">Marcus Lapeyrolerie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chapman_M/0/1/0/all/0/1\">Melissa S. Chapman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Norman_K/0/1/0/all/0/1\">Kari E. A. Norman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boettiger_C/0/1/0/all/0/1\">Carl Boettiger</a>",
          "description": "Can machine learning help us make better decisions about a changing planet?\nIn this paper, we illustrate and discuss the potential of a promising corner of\nmachine learning known as _reinforcement learning_ (RL) to help tackle the most\nchallenging conservation decision problems. RL is uniquely well suited to\nconservation and global change challenges for three reasons: (1) RL explicitly\nfocuses on designing an agent who _interacts_ with an environment which is\ndynamic and uncertain, (2) RL approaches do not require massive amounts of\ndata, (3) RL approaches would utilize rather than replace existing models,\nsimulations, and the knowledge they contain. We provide a conceptual and\ntechnical introduction to RL and its relevance to ecological and conservation\nchallenges, including examples of a problem in setting fisheries quotas and in\nmanaging ecological tipping points. Four appendices with annotated code provide\na tangible introduction to researchers looking to adopt, evaluate, or extend\nthese approaches.",
          "link": "http://arxiv.org/abs/2106.08272",
          "publishedOn": "2021-06-16T01:21:09.019Z",
          "wordCount": 581,
          "title": "Deep Reinforcement Learning for Conservation Decisions. (arXiv:2106.08272v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08117",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Dongsheng Wang</a>",
          "description": "Semantic representation and inference is essential for Natural Language\nProcessing (NLP). The state of the art for semantic representation and\ninference is deep learning, and particularly Recurrent Neural Networks (RNNs),\nConvolutional Neural Networks (CNNs), and transformer Self-Attention models.\nThis thesis investigates the use of deep learning for novel semantic\nrepresentation and inference, and makes contributions in the following three\nareas: creating training data, improving semantic representations and extending\ninference learning. In terms of creating training data, we contribute the\nlargest publicly available dataset of real-life factual claims for the purpose\nof automatic claim verification (MultiFC), and we present a novel inference\nmodel composed of multi-scale CNNs with different kernel sizes that learn from\nexternal sources to infer fact checking labels. In terms of improving semantic\nrepresentations, we contribute a novel model that captures non-compositional\nsemantic indicators. By definition, the meaning of a non-compositional phrase\ncannot be inferred from the individual meanings of its composing words (e.g.,\nhot dog). Motivated by this, we operationalize the compositionality of a phrase\ncontextually by enriching the phrase representation with external word\nembeddings and knowledge graphs. Finally, in terms of inference learning, we\npropose a series of novel deep learning architectures that improve inference by\nusing syntactic dependencies, by ensembling role guided attention heads,\nincorporating gating layers, and concatenating multiple heads in novel and\neffective ways. This thesis consists of seven publications (five published and\ntwo under review).",
          "link": "http://arxiv.org/abs/2106.08117",
          "publishedOn": "2021-06-16T01:21:09.012Z",
          "wordCount": 663,
          "title": "Semantic Representation and Inference for NLP. (arXiv:2106.08117v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08259",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khan_F/0/1/0/all/0/1\">Falaah Arif Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manis_E/0/1/0/all/0/1\">Eleni Manis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stoyanovich_J/0/1/0/all/0/1\">Julia Stoyanovich</a>",
          "description": "Recent interest in codifying fairness in Automated Decision Systems (ADS) has\nresulted in a wide range of formulations of what it means for an algorithmic\nsystem to be fair. Most of these propositions are inspired by, but inadequately\ngrounded in, political philosophy scholarship. This paper aims to correct that\ndeficit. We introduce a taxonomy of fairness ideals using doctrines of Equality\nof Opportunity (EOP) from political philosophy, clarifying their conceptions in\nphilosophy and the proposed codification in fair machine learning. We arrange\nthese fairness ideals onto an EOP spectrum, which serves as a useful frame to\nguide the design of a fair ADS in a given context.\n\nWe use our fairness-as-EOP framework to re-interpret the impossibility\nresults from a philosophical perspective, as the in-compatibility between\ndifferent value systems, and demonstrate the utility of the framework with\nseveral real-world and hypothetical examples. Through our EOP-framework we hope\nto answer what it means for an ADS to be fair from a moral and political\nphilosophy standpoint, and to pave the way for similar scholarship from ethics\nand legal experts.",
          "link": "http://arxiv.org/abs/2106.08259",
          "publishedOn": "2021-06-16T01:21:09.006Z",
          "wordCount": 614,
          "title": "Fairness as Equality of Opportunity: Normative Guidance from Political Philosophy. (arXiv:2106.08259v1 [cs.CY])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08126",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Arabskyy_Y/0/1/0/all/0/1\">Yuriy Arabskyy</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Agarwal_A/0/1/0/all/0/1\">Aashish Agarwal</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dey_S/0/1/0/all/0/1\">Subhadeep Dey</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Koller_O/0/1/0/all/0/1\">Oscar Koller</a>",
          "description": "This paper describes the winning approach in the public SwissText 2021\ncompetition on dialect recognition and translation of Swiss German speech to\nstandard German text. Swiss German refers to the multitude of Alemannic\ndialects spoken in the German-speaking parts of Switzerland. Swiss German\ndiffers significantly from standard German in pronunciation, word inventory and\ngrammar. It is mostly incomprehensible to native German speakers. Moreover, it\nlacks a standardized written script. To solve the challenging task, we propose\na hybrid automatic speech recognition system with a lexicon that incorporates\ntranslations, a 1st pass language model that deals with Swiss German\nparticularities, a transfer-learned acoustic model and a strong neural language\nmodel for 2nd pass rescoring. Our submission reaches 46.04% BLEU on a blind\nconversational test set and outperforms the second best competitor by a 12%\nrelative margin.",
          "link": "http://arxiv.org/abs/2106.08126",
          "publishedOn": "2021-06-16T01:21:08.999Z",
          "wordCount": 598,
          "title": "Dialectal Speech Recognition and Translation of Swiss German Speech to Standard German Text: Microsoft's Submission to SwissText 2021. (arXiv:2106.08126v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08307",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vazirizade_S/0/1/0/all/0/1\">Sayyed Mohsen Vazirizade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mukhopadhyay_A/0/1/0/all/0/1\">Ayan Mukhopadhyay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pettet_G/0/1/0/all/0/1\">Geoffrey Pettet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Said_S/0/1/0/all/0/1\">Said El Said</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baroud_H/0/1/0/all/0/1\">Hiba Baroud</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dubey_A/0/1/0/all/0/1\">Abhishek Dubey</a>",
          "description": "Principled decision making in emergency response management necessitates the\nuse of statistical models that predict the spatial-temporal likelihood of\nincident occurrence. These statistical models are then used for proactive\nstationing which allocates first responders across the spatial area in order to\nreduce overall response time. Traditional methods that simply aggregate past\nincidents over space and time fail to make useful short-term predictions when\nthe spatial region is large and focused on fine-grained spatial entities like\ninterstate highway networks. This is partially due to the sparsity of incidents\nwith respect to the area in consideration. Further, accidents are affected by\nseveral covariates, and collecting, cleaning, and managing multiple streams of\ndata from various sources is challenging for large spatial areas. In this\npaper, we highlight how this problem is being solved for the state of\nTennessee, a state in the USA with a total area of over 100,000 sq. km. Our\npipeline, based on a combination of synthetic resampling, non-spatial\nclustering, and learning from data can efficiently forecast the spatial and\ntemporal dynamics of accident occurrence, even under sparse conditions. In the\npaper, we describe our pipeline that uses data related to roadway geometry,\nweather, historical accidents, and real-time traffic congestion to aid accident\nforecasting. To understand how our forecasting model can affect allocation and\ndispatch, we improve upon a classical resource allocation approach.\nExperimental results show that our approach can significantly reduce response\ntimes in the field in comparison with current approaches followed by first\nresponders.",
          "link": "http://arxiv.org/abs/2106.08307",
          "publishedOn": "2021-06-16T01:21:08.980Z",
          "wordCount": 684,
          "title": "Learning Incident Prediction Models Over Large Geographical Areas for Emergency Response Systems. (arXiv:2106.08307v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08104",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haoqi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_M/0/1/0/all/0/1\">Mingfu Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1\">Shichang Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yushu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jian Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Weiqiang Liu</a>",
          "description": "Deep neural networks (DNN) have achieved remarkable performance in various\nfields. However, training a DNN model from scratch requires a lot of computing\nresources and training data. It is difficult for most individual users to\nobtain such computing resources and training data. Model copyright infringement\nis an emerging problem in recent years. For instance, pre-trained models may be\nstolen or abuse by illegal users without the authorization of the model owner.\nRecently, many works on protecting the intellectual property of DNN models have\nbeen proposed. In these works, embedding watermarks into DNN based on backdoor\nis one of the widely used methods. However, when the DNN model is stolen, the\nbackdoor-based watermark may face the risk of being detected and removed by an\nadversary. In this paper, we propose a scheme to detect and remove watermark in\ndeep neural networks via generative adversarial networks (GAN). We demonstrate\nthat the backdoor-based DNN watermarks are vulnerable to the proposed GAN-based\nwatermark removal attack. The proposed attack method includes two phases. In\nthe first phase, we use the GAN and few clean images to detect and reverse the\nwatermark in the DNN model. In the second phase, we fine-tune the watermarked\nDNN based on the reversed backdoor images. Experimental evaluations on the\nMNIST and CIFAR10 datasets demonstrate that, the proposed method can\neffectively remove about 98% of the watermark in DNN models, as the watermark\nretention rate reduces from 100% to less than 2% after applying the proposed\nattack. In the meantime, the proposed attack hardly affects the model's\nperformance. The test accuracy of the watermarked DNN on the MNIST and the\nCIFAR10 datasets drops by less than 1% and 3%, respectively.",
          "link": "http://arxiv.org/abs/2106.08104",
          "publishedOn": "2021-06-16T01:21:08.973Z",
          "wordCount": 724,
          "title": "Detect and remove watermark in deep neural networks via generative adversarial networks. (arXiv:2106.08104v1 [cs.MM])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08105",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bommert_A/0/1/0/all/0/1\">Andrea Bommert</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rahnenfuhrer_J/0/1/0/all/0/1\">J&#xf6;rg Rahnenf&#xfc;hrer</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lang_M/0/1/0/all/0/1\">Michel Lang</a>",
          "description": "Fitting models with high predictive accuracy that include all relevant but no\nirrelevant or redundant features is a challenging task on data sets with\nsimilar (e.g. highly correlated) features. We propose the approach of tuning\nthe hyperparameters of a predictive model in a multi-criteria fashion with\nrespect to predictive accuracy and feature selection stability. We evaluate\nthis approach based on both simulated and real data sets and we compare it to\nthe standard approach of single-criteria tuning of the hyperparameters as well\nas to the state-of-the-art technique \"stability selection\". We conclude that\nour approach achieves the same or better predictive performance compared to the\ntwo established approaches. Considering the stability during tuning does not\ndecrease the predictive accuracy of the resulting models. Our approach succeeds\nat selecting the relevant features while avoiding irrelevant or redundant\nfeatures. The single-criteria approach fails at avoiding irrelevant or\nredundant features and the stability selection approach fails at selecting\nenough relevant features for achieving acceptable predictive accuracy. For our\napproach, for data sets with many similar features, the feature selection\nstability must be evaluated with an adjusted stability measure, that is, a\nmeasure that considers similarities between features. For data sets with only\nfew similar features, an unadjusted stability measure suffices and is faster to\ncompute.",
          "link": "http://arxiv.org/abs/2106.08105",
          "publishedOn": "2021-06-16T01:21:08.964Z",
          "wordCount": 651,
          "title": "Employing an Adjusted Stability Measure for Multi-Criteria Model Fitting on Data Sets with Similar Features. (arXiv:2106.08105v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08299",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tommy Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Merkel_C/0/1/0/all/0/1\">Cory Merkel</a>",
          "description": "Artificial neural networks (ANNs) have gained significant popularity in the\nlast decade for solving narrow AI problems in domains such as healthcare,\ntransportation, and defense. As ANNs become more ubiquitous, it is imperative\nto understand their associated safety, security, and privacy vulnerabilities.\nRecently, it has been shown that ANNs are susceptible to a number of\nadversarial evasion attacks--inputs that cause the ANN to make high-confidence\nmisclassifications despite being almost indistinguishable from the data used to\ntrain and test the network. This work explores to what degree finding these\nexamples maybe aided by using side-channel information, specifically switching\npower consumption, of hardware implementations of ANNs. A black-box threat\nscenario is assumed, where an attacker has access to the ANN hardware's input,\noutputs, and topology, but the trained model parameters are unknown. Then, a\nsurrogate model is trained to have similar functional (i.e. input-output\nmapping) and switching power characteristics as the oracle (black-box) model.\nOur results indicate that the inclusion of power consumption data increases the\nfidelity of the model extraction by up to 30 percent based on a mean square\nerror comparison of the oracle and surrogate weights. However, transferability\nof adversarial examples from the surrogate to the oracle model was not\nsignificantly affected.",
          "link": "http://arxiv.org/abs/2106.08299",
          "publishedOn": "2021-06-16T01:21:08.957Z",
          "wordCount": 631,
          "title": "Model Extraction and Adversarial Attacks on Neural Networks using Switching Power Information. (arXiv:2106.08299v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07989",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gronlund_A/0/1/0/all/0/1\">Allan Gr&#xf8;nlund</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hogsgaard_M/0/1/0/all/0/1\">Mikael H&#xf8;gsgaard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamma_L/0/1/0/all/0/1\">Lior Kamma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Larsen_K/0/1/0/all/0/1\">Kasper Green Larsen</a>",
          "description": "Explaining the surprising generalization performance of deep neural networks\nis an active and important line of research in theoretical machine learning.\nInfluential work by Arora et al. (ICML'18) showed that, noise stability\nproperties of deep nets occurring in practice can be used to provably compress\nmodel representations. They then argued that the small representations of\ncompressed networks imply good generalization performance albeit only of the\ncompressed nets. Extending their compression framework to yield generalization\nbounds for the original uncompressed networks remains elusive.\n\nOur main contribution is the establishment of a compression-based framework\nfor proving generalization bounds. The framework is simple and powerful enough\nto extend the generalization bounds by Arora et al. to also hold for the\noriginal network. To demonstrate the flexibility of the framework, we also show\nthat it allows us to give simple proofs of the strongest known generalization\nbounds for other popular machine learning models, namely Support Vector\nMachines and Boosting.",
          "link": "http://arxiv.org/abs/2106.07989",
          "publishedOn": "2021-06-16T01:21:08.950Z",
          "wordCount": 571,
          "title": "Compression Implies Generalization. (arXiv:2106.07989v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08062",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1\">Soyoung Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1\">Gyuwan Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_K/0/1/0/all/0/1\">Kyumin Park</a>",
          "description": "Data augmentation with mixup has shown to be effective on various computer\nvision tasks. Despite its great success, there has been a hurdle to apply mixup\nto NLP tasks since text consists of discrete tokens with variable length. In\nthis work, we propose SSMix, a novel mixup method where the operation is\nperformed on input text rather than on hidden vectors like previous approaches.\nSSMix synthesizes a sentence while preserving the locality of two original\ntexts by span-based mixing and keeping more tokens related to the prediction\nrelying on saliency information. With extensive experiments, we empirically\nvalidate that our method outperforms hidden-level mixup methods on a wide range\nof text classification benchmarks, including textual entailment, sentiment\nclassification, and question-type classification. Our code is available at\nhttps://github.com/clovaai/ssmix.",
          "link": "http://arxiv.org/abs/2106.08062",
          "publishedOn": "2021-06-16T01:21:08.928Z",
          "wordCount": 563,
          "title": "SSMix: Saliency-Based Span Mixup for Text Classification. (arXiv:2106.08062v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07971",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Godwin_J/0/1/0/all/0/1\">Jonathan Godwin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schaarschmidt_M/0/1/0/all/0/1\">Michael Schaarschmidt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaunt_A/0/1/0/all/0/1\">Alexander Gaunt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanchez_Gonzalez_A/0/1/0/all/0/1\">Alvaro Sanchez-Gonzalez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubanova_Y/0/1/0/all/0/1\">Yulia Rubanova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Velickovic_P/0/1/0/all/0/1\">Petar Veli&#x10d;kovi&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kirkpatrick_J/0/1/0/all/0/1\">James Kirkpatrick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Battaglia_P/0/1/0/all/0/1\">Peter Battaglia</a>",
          "description": "Graph Neural Networks (GNNs) perform learned message passing over an input\ngraph, but conventional wisdom says performing more than handful of steps makes\ntraining difficult and does not yield improved performance. Here we show the\ncontrary. We train a deep GNN with up to 100 message passing steps and achieve\nseveral state-of-the-art results on two challenging molecular property\nprediction benchmarks, Open Catalyst 2020 IS2RE and QM9. Our approach depends\ncrucially on a novel but simple regularisation method, which we call ``Noisy\nNodes'', in which we corrupt the input graph with noise and add an auxiliary\nnode autoencoder loss if the task is graph property prediction. Our results\nshow this regularisation method allows the model to monotonically improve in\nperformance with increased message passing steps. Our work opens new\nopportunities for reaping the benefits of deep neural networks in the space of\ngraph and other structured prediction problems.",
          "link": "http://arxiv.org/abs/2106.07971",
          "publishedOn": "2021-06-16T01:21:08.921Z",
          "wordCount": 578,
          "title": "Very Deep Graph Neural Networks Via Noise Regularisation. (arXiv:2106.07971v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08085",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kao_T/0/1/0/all/0/1\">Ta-Chu Kao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jensen_K/0/1/0/all/0/1\">Kristopher T. Jensen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bernacchia_A/0/1/0/all/0/1\">Alberto Bernacchia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hennequin_G/0/1/0/all/0/1\">Guillaume Hennequin</a>",
          "description": "Biological agents are known to learn many different tasks over the course of\ntheir lives, and to be able to revisit previous tasks and behaviors with little\nto no loss in performance. In contrast, artificial agents are prone to\n'catastrophic forgetting' whereby performance on previous tasks deteriorates\nrapidly as new ones are acquired. This shortcoming has recently been addressed\nusing methods that encourage parameters to stay close to those used for\nprevious tasks. This can be done by (i) using specific parameter regularizers\nthat map out suitable destinations in parameter space, or (ii) guiding the\noptimization journey by projecting gradients into subspaces that do not\ninterfere with previous tasks. However, parameter regularization has been shown\nto be relatively ineffective in recurrent neural networks (RNNs), a setting\nrelevant to the study of neural dynamics supporting biological continual\nlearning. Similarly, projection based methods can reach capacity and fail to\nlearn any further as the number of tasks increases. To address these\nlimitations, we propose Natural Continual Learning (NCL), a new method that\nunifies weight regularization and projected gradient descent. NCL uses Bayesian\nweight regularization to encourage good performance on all tasks at convergence\nand combines this with gradient projections designed to prevent catastrophic\nforgetting during optimization. NCL formalizes gradient projection as a trust\nregion algorithm based on the Fisher information metric, and achieves\nscalability via a novel Kronecker-factored approximation strategy. Our method\noutperforms both standard weight regularization techniques and projection based\napproaches when applied to continual learning problems in RNNs. The trained\nnetworks evolve task-specific dynamics that are strongly preserved as new tasks\nare learned, similar to experimental findings in biological circuits.",
          "link": "http://arxiv.org/abs/2106.08085",
          "publishedOn": "2021-06-16T01:21:08.915Z",
          "wordCount": 706,
          "title": "Natural continual learning: success is a journey, not (just) a destination. (arXiv:2106.08085v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07894",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jianlei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_W/0/1/0/all/0/1\">Wenzhi Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1\">Xingzhou Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_X/0/1/0/all/0/1\">Xucheng Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_P/0/1/0/all/0/1\">Pengcheng Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Weisheng Zhao</a>",
          "description": "Convolutional neural networks (CNNs) have achieved great success in\nperforming cognitive tasks. However, execution of CNNs requires a large amount\nof computing resources and generates heavy memory traffic, which imposes a\nsevere challenge on computing system design. Through optimizing parallel\nexecutions and data reuse in convolution, systolic architecture demonstrates\ngreat advantages in accelerating CNN computations. However, regular internal\ndata transmission path in traditional systolic architecture prevents the\nsystolic architecture from completely leveraging the benefits introduced by\nneural network sparsity. Deployment of fine-grained sparsity on the existing\nsystolic architectures is greatly hindered by the incurred computational\noverheads. In this work, we propose S2Engine $-$ a novel systolic architecture\nthat can fully exploit the sparsity in CNNs with maximized data reuse. S2Engine\ntransmits compressed data internally and allows each processing element to\ndynamically select an aligned data from the compressed dataflow in convolution.\nCompared to the naive systolic array, S2Engine achieves about $3.2\\times$ and\nabout $3.0\\times$ improvements on speed and energy efficiency, respectively.",
          "link": "http://arxiv.org/abs/2106.07894",
          "publishedOn": "2021-06-16T01:21:08.908Z",
          "wordCount": 618,
          "title": "S2Engine: A Novel Systolic Architecture for Sparse Convolutional Neural Networks. (arXiv:2106.07894v1 [cs.AR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08042",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tseytlin_B/0/1/0/all/0/1\">Boris Tseytlin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Makarov_I/0/1/0/all/0/1\">Ilya Makarov</a>",
          "description": "We approach the problem of hotel recognition with deep metric learning. We\noverview the existing approaches and propose a modification to Contrastive loss\ncalled Contrastive-Triplet loss. We construct a robust pipeline for\nbenchmarking metric learning models and perform experiments on Hotels-50K and\nCUB200 datasets. Contrastive-Triplet loss is shown to achieve better retrieval\non Hotels-50k. We open-source our code.",
          "link": "http://arxiv.org/abs/2106.08042",
          "publishedOn": "2021-06-16T01:21:08.901Z",
          "wordCount": 491,
          "title": "Hotel Recognition via Latent Image Embedding. (arXiv:2106.08042v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07995",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Boney_R/0/1/0/all/0/1\">Rinu Boney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ilin_A/0/1/0/all/0/1\">Alexander Ilin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kannala_J/0/1/0/all/0/1\">Juho Kannala</a>",
          "description": "In many control problems that include vision, optimal controls can be\ninferred from the location of the objects in the scene. This information can be\nrepresented using keypoints, which is a list of spatial locations in the input\nimage. Previous works show that keypoint representations learned during\nunsupervised pre-training using encoder-decoder architectures can provide good\nfeatures for control tasks. In this paper, we show that it is possible to learn\nefficient keypoint representations end-to-end, without the need for\nunsupervised pre-training, decoders, or additional losses. Our proposed\narchitecture consists of a differentiable keypoint extractor that feeds the\ncoordinates of the estimated keypoints directly to a soft actor-critic agent.\nThe proposed algorithm yields performance competitive to the state-of-the art\non DeepMind Control Suite tasks.",
          "link": "http://arxiv.org/abs/2106.07995",
          "publishedOn": "2021-06-16T01:21:08.881Z",
          "wordCount": 558,
          "title": "End-to-End Learning of Keypoint Representations for Continuous Control from Images. (arXiv:2106.07995v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08064",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rabold_J/0/1/0/all/0/1\">Johannes Rabold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siebers_M/0/1/0/all/0/1\">Michael Siebers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmid_U/0/1/0/all/0/1\">Ute Schmid</a>",
          "description": "In recent research, human-understandable explanations of machine learning\nmodels have received a lot of attention. Often explanations are given in form\nof model simplifications or visualizations. However, as shown in cognitive\nscience as well as in early AI research, concept understanding can also be\nimproved by the alignment of a given instance for a concept with a similar\ncounterexample. Contrasting a given instance with a structurally similar\nexample which does not belong to the concept highlights what characteristics\nare necessary for concept membership. Such near misses have been proposed by\nWinston (1970) as efficient guidance for learning in relational domains. We\nintroduce an explanation generation algorithm for relational concepts learned\nwith Inductive Logic Programming (\\textsc{GeNME}). The algorithm identifies\nnear miss examples from a given set of instances and ranks these examples by\ntheir degree of closeness to a specific positive instance. A modified rule\nwhich covers the near miss but not the original instance is given as an\nexplanation. We illustrate \\textsc{GeNME} with the well known family domain\nconsisting of kinship relations, the visual relational Winston arches domain\nand a real-world domain dealing with file management. We also present a\npsychological experiment comparing human preferences of rule-based,\nexample-based, and near miss explanations in the family and the arches domains.",
          "link": "http://arxiv.org/abs/2106.08064",
          "publishedOn": "2021-06-16T01:21:08.874Z",
          "wordCount": 645,
          "title": "Generating Contrastive Explanations for Inductive Logic Programming Based on a Near Miss Approach. (arXiv:2106.08064v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07925",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Joe_B/0/1/0/all/0/1\">Byunggill Joe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehra_A/0/1/0/all/0/1\">Akshay Mehra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_I/0/1/0/all/0/1\">Insik Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamm_J/0/1/0/all/0/1\">Jihun Hamm</a>",
          "description": "Electronic Health Records (EHRs) provide a wealth of information for machine\nlearning algorithms to predict the patient outcome from the data including\ndiagnostic information, vital signals, lab tests, drug administration, and\ndemographic information. Machine learning models can be built, for example, to\nevaluate patients based on their predicted mortality or morbidity and to\npredict required resources for efficient resource management in hospitals. In\nthis paper, we demonstrate that an attacker can manipulate the machine learning\npredictions with EHRs easily and selectively at test time by backdoor attacks\nwith the poisoned training data. Furthermore, the poison we create has\nstatistically similar features to the original data making it hard to detect,\nand can also attack multiple machine learning models without any knowledge of\nthe models. With less than 5% of the raw EHR data poisoned, we achieve average\nattack success rates of 97% on mortality prediction tasks with MIMIC-III\ndatabase against Logistic Regression, Multilayer Perceptron, and Long\nShort-term Memory models simultaneously.",
          "link": "http://arxiv.org/abs/2106.07925",
          "publishedOn": "2021-06-16T01:21:08.868Z",
          "wordCount": 606,
          "title": "Machine Learning with Electronic Health Records is vulnerable to Backdoor Trigger Attacks. (arXiv:2106.07925v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07953",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Chen_P/0/1/0/all/0/1\">Po-Yu Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_H/0/1/0/all/0/1\">Hao Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tsai_Y/0/1/0/all/0/1\">Yi-Min Tsai</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kuo_H/0/1/0/all/0/1\">Hsien-Kai Kuo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huang_H/0/1/0/all/0/1\">Hantao Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_H/0/1/0/all/0/1\">Hsin-Hung Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yan_S/0/1/0/all/0/1\">Sheng-Hong Yan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ou_W/0/1/0/all/0/1\">Wei-Lun Ou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cheng_C/0/1/0/all/0/1\">Chia-Ming Cheng</a>",
          "description": "Owing to the complicated characteristics of 5G communication system,\ndesigning RF components through mathematical modeling becomes a challenging\nobstacle. Moreover, such mathematical models need numerous manual adjustments\nfor various specification requirements. In this paper, we present a\nlearning-based framework to model and compensate Power Amplifiers (PAs) in 5G\ncommunication. In the proposed framework, Deep Neural Networks (DNNs) are used\nto learn the characteristics of the PAs, while, correspondent Digital\nPre-Distortions (DPDs) are also learned to compensate for the nonlinear and\nmemory effects of PAs. On top of the framework, we further propose two\nfrequency domain losses to guide the learning process to better optimize the\ntarget, compared to naive time domain Mean Square Error (MSE). The proposed\nframework serves as a drop-in replacement for the conventional approach. The\nproposed approach achieves an average of 56.7% reduction of nonlinear and\nmemory effects, which converts to an average of 16.3% improvement over a\ncarefully-designed mathematical model, and even reaches 34% enhancement in\nsevere distortion scenarios.",
          "link": "http://arxiv.org/abs/2106.07953",
          "publishedOn": "2021-06-16T01:21:08.861Z",
          "wordCount": 622,
          "title": "Learning to Compensate: A Deep Neural Network Framework for 5G Power Amplifier Compensation. (arXiv:2106.07953v1 [eess.SP])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07976",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tuo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_C/0/1/0/all/0/1\">Chaoyang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1\">Tianhao Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1\">Mark Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Avestimehr_S/0/1/0/all/0/1\">Salman Avestimehr</a>",
          "description": "Federated learning can be a promising solution for enabling IoT cybersecurity\n(i.e., anomaly detection in the IoT environment) while preserving data privacy\nand mitigating the high communication/storage overhead (e.g., high-frequency\ndata from time-series sensors) of centralized over-the-cloud approaches. In\nthis paper, to further push forward this direction with a comprehensive study\nin both algorithm and system design, we build FedIoT platform that contains a\nsynthesized dataset using N-BaIoT, FedDetect algorithm, and a system design for\nIoT devices. Furthermore, the proposed FedDetect learning framework improves\nthe performance by utilizing an adaptive optimizer (e.g., Adam) and a\ncross-round learning rate scheduler. In a network of realistic IoT devices\n(Raspberry PI), we evaluate FedIoT platform and FedDetect algorithm in both\nmodel and system performance. Our results demonstrate the efficacy of federated\nlearning in detecting a large range of attack types. The system efficiency\nanalysis indicates that both end-to-end training time and memory cost are\naffordable and promising for resource-constrained IoT devices. The source code\nis publicly available.",
          "link": "http://arxiv.org/abs/2106.07976",
          "publishedOn": "2021-06-16T01:21:08.854Z",
          "wordCount": 610,
          "title": "Federated Learning for Internet of Things: A Federated Learning Framework for On-device Anomaly Data Detection. (arXiv:2106.07976v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08122",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shao_C/0/1/0/all/0/1\">Chenze Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yang Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jinchao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_F/0/1/0/all/0/1\">Fandong Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>",
          "description": "In recent years, Neural Machine Translation (NMT) has achieved notable\nresults in various translation tasks. However, the word-by-word generation\nmanner determined by the autoregressive mechanism leads to high translation\nlatency of the NMT and restricts its low-latency applications.\nNon-Autoregressive Neural Machine Translation (NAT) removes the autoregressive\nmechanism and achieves significant decoding speedup through generating target\nwords independently and simultaneously. Nevertheless, NAT still takes the\nword-level cross-entropy loss as the training objective, which is not optimal\nbecause the output of NAT cannot be properly evaluated due to the multimodality\nproblem. In this paper, we propose using sequence-level training objectives to\ntrain NAT models, which evaluate the NAT outputs as a whole and correlates well\nwith the real translation quality. Firstly, we propose training NAT models to\noptimize sequence-level evaluation metrics (e.g., BLEU) based on several novel\nreinforcement algorithms customized for NAT, which outperforms the conventional\nmethod by reducing the variance of gradient estimation. Secondly, we introduce\na novel training objective for NAT models, which aims to minimize the\nBag-of-Ngrams (BoN) difference between the model output and the reference\nsentence. The BoN training objective is differentiable and can be calculated\nefficiently without doing any approximations. Finally, we apply a three-stage\ntraining strategy to combine these two methods to train the NAT model. We\nvalidate our approach on four translation tasks (WMT14 En$\\leftrightarrow$De,\nWMT16 En$\\leftrightarrow$Ro), which shows that our approach largely outperforms\nNAT baselines and achieves remarkable performance on all translation tasks.",
          "link": "http://arxiv.org/abs/2106.08122",
          "publishedOn": "2021-06-16T01:21:08.846Z",
          "wordCount": 669,
          "title": "Sequence-Level Training for Non-Autoregressive Neural Machine Translation. (arXiv:2106.08122v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08147",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ma_D/0/1/0/all/0/1\">Di Ma</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Afonso_M/0/1/0/all/0/1\">Mariana Afonso</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_F/0/1/0/all/0/1\">Fan Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bull_D/0/1/0/all/0/1\">David R. Bull</a>",
          "description": "Spatial resolution adaptation is a technique which has often been employed in\nvideo compression to enhance coding efficiency. This approach encodes a lower\nresolution version of the input video and reconstructs the original resolution\nduring decoding. Instead of using conventional up-sampling filters, recent work\nhas employed advanced super-resolution methods based on convolutional neural\nnetworks (CNNs) to further improve reconstruction quality. These approaches are\nusually trained to minimise pixel-based losses such as Mean-Squared Error\n(MSE), despite the fact that this type of loss metric does not correlate well\nwith subjective opinions. In this paper, a perceptually-inspired\nsuper-resolution approach (M-SRGAN) is proposed for spatial up-sampling of\ncompressed video using a modified CNN model, which has been trained using a\ngenerative adversarial network (GAN) on compressed content with perceptual loss\nfunctions. The proposed method was integrated with HEVC HM 16.20, and has been\nevaluated on the JVET Common Test Conditions (UHD test sequences) using the\nRandom Access configuration. The results show evident perceptual quality\nimprovement over the original HM 16.20, with an average bitrate saving of 35.6%\n(Bj{\\o}ntegaard Delta measurement) based on a perceptual quality metric, VMAF.",
          "link": "http://arxiv.org/abs/2106.08147",
          "publishedOn": "2021-06-16T01:21:08.826Z",
          "wordCount": 624,
          "title": "Perceptually-inspired super-resolution of compressed videos. (arXiv:2106.08147v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08007",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Isonuma_M/0/1/0/all/0/1\">Masaru Isonuma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mori_J/0/1/0/all/0/1\">Junichiro Mori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bollegala_D/0/1/0/all/0/1\">Danushka Bollegala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sakata_I/0/1/0/all/0/1\">Ichiro Sakata</a>",
          "description": "This paper presents a novel unsupervised abstractive summarization method for\nopinionated texts. While the basic variational autoencoder-based models assume\na unimodal Gaussian prior for the latent code of sentences, we alternate it\nwith a recursive Gaussian mixture, where each mixture component corresponds to\nthe latent code of a topic sentence and is mixed by a tree-structured topic\ndistribution. By decoding each Gaussian component, we generate sentences with\ntree-structured topic guidance, where the root sentence conveys generic\ncontent, and the leaf sentences describe specific topics. Experimental results\ndemonstrate that the generated topic sentences are appropriate as a summary of\nopinionated texts, which are more informative and cover more input contents\nthan those generated by the recent unsupervised summarization model\n(Bra\\v{z}inskas et al., 2020). Furthermore, we demonstrate that the variance of\nlatent Gaussians represents the granularity of sentences, analogous to Gaussian\nword embedding (Vilnis and McCallum, 2015).",
          "link": "http://arxiv.org/abs/2106.08007",
          "publishedOn": "2021-06-16T01:21:08.819Z",
          "wordCount": 592,
          "title": "Unsupervised Abstractive Opinion Summarization by Generating Sentences with Tree-Structured Topic Guidance. (arXiv:2106.08007v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08056",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dong_Z/0/1/0/all/0/1\">Zhe Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mnih_A/0/1/0/all/0/1\">Andriy Mnih</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tucker_G/0/1/0/all/0/1\">George Tucker</a>",
          "description": "Training models with discrete latent variables is challenging due to the high\nvariance of unbiased gradient estimators. While low-variance reparameterization\ngradients of a continuous relaxation can provide an effective solution, a\ncontinuous relaxation is not always available or tractable. Dong et al. (2020)\nand Yin et al. (2020) introduced a performant estimator that does not rely on\ncontinuous relaxations; however, it is limited to binary random variables. We\nintroduce a novel derivation of their estimator based on importance sampling\nand statistical couplings, which we extend to the categorical setting.\nMotivated by the construction of a stick-breaking coupling, we introduce\ngradient estimators based on reparameterizing categorical variables as\nsequences of binary variables and Rao-Blackwellization. In systematic\nexperiments, we show that our proposed categorical gradient estimators provide\nstate-of-the-art performance, whereas even with additional\nRao-Blackwellization, previous estimators (Yin et al., 2019) underperform a\nsimpler REINFORCE with a leave-one-out-baseline estimator (Kool et al., 2019).",
          "link": "http://arxiv.org/abs/2106.08056",
          "publishedOn": "2021-06-16T01:21:08.813Z",
          "wordCount": 577,
          "title": "Coupled Gradient Estimators for Discrete Latent Variables. (arXiv:2106.08056v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07991",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Liu_R/0/1/0/all/0/1\">Risheng Liu</a>, <a href=\"http://arxiv.org/find/math/1/au:+Liu_X/0/1/0/all/0/1\">Xuan Liu</a>, <a href=\"http://arxiv.org/find/math/1/au:+Yuan_X/0/1/0/all/0/1\">Xiaoming Yuan</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zeng_S/0/1/0/all/0/1\">Shangzhi Zeng</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhang_J/0/1/0/all/0/1\">Jin Zhang</a>",
          "description": "Bi-level optimization model is able to capture a wide range of complex\nlearning tasks with practical interest. Due to the witnessed efficiency in\nsolving bi-level programs, gradient-based methods have gained popularity in the\nmachine learning community. In this work, we propose a new gradient-based\nsolution scheme, namely, the Bi-level Value-Function-based Interior-point\nMethod (BVFIM). Following the main idea of the log-barrier interior-point\nscheme, we penalize the regularized value function of the lower level problem\ninto the upper level objective. By further solving a sequence of differentiable\nunconstrained approximation problems, we consequently derive a sequential\nprogramming scheme. The numerical advantage of our scheme relies on the fact\nthat, when gradient methods are applied to solve the approximation problem, we\nsuccessfully avoid computing any expensive Hessian-vector or Jacobian-vector\nproduct. We prove the convergence without requiring any convexity assumption on\neither the upper level or the lower level objective. Experiments demonstrate\nthe efficiency of the proposed BVFIM on non-convex bi-level problems.",
          "link": "http://arxiv.org/abs/2106.07991",
          "publishedOn": "2021-06-16T01:21:08.806Z",
          "wordCount": 600,
          "title": "A Value-Function-based Interior-point Method for Non-convex Bi-level Optimization. (arXiv:2106.07991v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07961",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Corsini_A/0/1/0/all/0/1\">Andrea Corsini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shanchieh Jay Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Apruzzese_G/0/1/0/all/0/1\">Giovanni Apruzzese</a>",
          "description": "Recent advances in deep learning renewed the research interests in machine\nlearning for Network Intrusion Detection Systems (NIDS). Specifically,\nattention has been given to sequential learning models, due to their ability to\nextract the temporal characteristics of Network traffic Flows (NetFlows), and\nuse them for NIDS tasks. However, the applications of these sequential models\noften consist of transferring and adapting methodologies directly from other\nfields, without an in-depth investigation on how to leverage the specific\ncircumstances of cybersecurity scenarios; moreover, there is a lack of\ncomprehensive studies on sequential models that rely on NetFlow data, which\npresents significant advantages over traditional full packet captures. We\ntackle this problem in this paper. We propose a detailed methodology to extract\ntemporal sequences of NetFlows that denote patterns of malicious activities.\nThen, we apply this methodology to compare the efficacy of sequential learning\nmodels against traditional static learning models. In particular, we perform a\nfair comparison of a `sequential' Long Short-Term Memory (LSTM) against a\n`static' Feedforward Neural Networks (FNN) in distinct environments represented\nby two well-known datasets for NIDS: the CICIDS2017 and the CTU13. Our results\nhighlight that LSTM achieves comparable performance to FNN in the CICIDS2017\nwith over 99.5\\% F1-score; while obtaining superior performance in the CTU13,\nwith 95.7\\% F1-score against 91.5\\%. This paper thus paves the way to future\napplications of sequential learning models for NIDS.",
          "link": "http://arxiv.org/abs/2106.07961",
          "publishedOn": "2021-06-16T01:21:08.800Z",
          "wordCount": 662,
          "title": "On the Evaluation of Sequential Machine Learning for Network Intrusion Detection. (arXiv:2106.07961v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07998",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Minderer_M/0/1/0/all/0/1\">Matthias Minderer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Djolonga_J/0/1/0/all/0/1\">Josip Djolonga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Romijnders_R/0/1/0/all/0/1\">Rob Romijnders</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hubis_F/0/1/0/all/0/1\">Frances Hubis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_X/0/1/0/all/0/1\">Xiaohua Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Houlsby_N/0/1/0/all/0/1\">Neil Houlsby</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_D/0/1/0/all/0/1\">Dustin Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lucic_M/0/1/0/all/0/1\">Mario Lucic</a>",
          "description": "Accurate estimation of predictive uncertainty (model calibration) is\nessential for the safe application of neural networks. Many instances of\nmiscalibration in modern neural networks have been reported, suggesting a trend\nthat newer, more accurate models produce poorly calibrated predictions. Here,\nwe revisit this question for recent state-of-the-art image classification\nmodels. We systematically relate model calibration and accuracy, and find that\nthe most recent models, notably those not using convolutions, are among the\nbest calibrated. Trends observed in prior model generations, such as decay of\ncalibration with distribution shift or model size, are less pronounced in\nrecent architectures. We also show that model size and amount of pretraining do\nnot fully explain these differences, suggesting that architecture is a major\ndeterminant of calibration properties.",
          "link": "http://arxiv.org/abs/2106.07998",
          "publishedOn": "2021-06-16T01:21:08.781Z",
          "wordCount": 560,
          "title": "Revisiting the Calibration of Modern Neural Networks. (arXiv:2106.07998v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08166",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alivanistos_D/0/1/0/all/0/1\">Dimitrios Alivanistos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berrendorf_M/0/1/0/all/0/1\">Max Berrendorf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cochez_M/0/1/0/all/0/1\">Michael Cochez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galkin_M/0/1/0/all/0/1\">Mikhail Galkin</a>",
          "description": "Multi-hop logical reasoning is an established problem in the field of\nrepresentation learning on knowledge graphs (KGs). It subsumes both one-hop\nlink prediction as well as other more complex types of logical queries.\nExisting algorithms operate only on classical, triple-based graphs, whereas\nmodern KGs often employ a hyper-relational modeling paradigm. In this paradigm,\ntyped edges may have several key-value pairs known as qualifiers that provide\nfine-grained context for facts. In queries, this context modifies the meaning\nof relations, and usually reduces the answer set. Hyper-relational queries are\noften observed in real-world KG applications, and existing approaches for\napproximate query answering cannot make use of qualifier pairs. In this work,\nwe bridge this gap and extend the multi-hop reasoning problem to\nhyper-relational KGs allowing to tackle this new type of complex queries.\nBuilding upon recent advancements in Graph Neural Networks and query embedding\ntechniques, we study how to embed and answer hyper-relational conjunctive\nqueries. Besides that, we propose a method to answer such queries and\ndemonstrate in our experiments that qualifiers improve query answering on a\ndiverse set of query patterns.",
          "link": "http://arxiv.org/abs/2106.08166",
          "publishedOn": "2021-06-16T01:21:08.775Z",
          "wordCount": 611,
          "title": "Query Embedding on Hyper-relational Knowledge Graphs. (arXiv:2106.08166v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08187",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Long Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Zehong Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruan_S/0/1/0/all/0/1\">Shasha Ruan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shijian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_G/0/1/0/all/0/1\">Gang Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hongyang Chen</a>",
          "description": "In this paper, we propose a Thompson Sampling algorithm for \\emph{unimodal}\nbandits, where the expected reward is unimodal over the partially ordered arms.\nTo exploit the unimodal structure better, at each step, instead of exploration\nfrom the entire decision space, our algorithm makes decision according to\nposterior distribution only in the neighborhood of the arm that has the highest\nempirical mean estimate. We theoretically prove that, for Bernoulli rewards,\nthe regret of our algorithm reaches the lower bound of unimodal bandits, thus\nit is asymptotically optimal. For Gaussian rewards, the regret of our algorithm\nis $\\mathcal{O}(\\log T)$, which is far better than standard Thompson Sampling\nalgorithms. Extensive experiments demonstrate the effectiveness of the proposed\nalgorithm on both synthetic data sets and the real-world applications.",
          "link": "http://arxiv.org/abs/2106.08187",
          "publishedOn": "2021-06-16T01:21:08.768Z",
          "wordCount": 553,
          "title": "Thompson Sampling for Unimodal Bandits. (arXiv:2106.08187v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07984",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hoon Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sang Hyun Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quek_T/0/1/0/all/0/1\">Tony Q. S. Quek</a>",
          "description": "This paper presents a machine learning strategy that tackles a distributed\noptimization task in a wireless network with an arbitrary number of randomly\ninterconnected nodes. Individual nodes decide their optimal states with\ndistributed coordination among other nodes through randomly varying backhaul\nlinks. This poses a technical challenge in distributed universal optimization\npolicy robust to a random topology of the wireless network, which has not been\nproperly addressed by conventional deep neural networks (DNNs) with rigid\nstructural configurations. We develop a flexible DNN formalism termed\ndistributed message-passing neural network (DMPNN) with forward and backward\ncomputations independent of the network topology. A key enabler of this\napproach is an iterative message-sharing strategy through arbitrarily connected\nbackhaul links. The DMPNN provides a convergent solution for iterative\ncoordination by learning numerous random backhaul interactions. The DMPNN is\ninvestigated for various configurations of the power control in wireless\nnetworks, and intensive numerical results prove its universality and viability\nover conventional optimization and DNN approaches.",
          "link": "http://arxiv.org/abs/2106.07984",
          "publishedOn": "2021-06-16T01:21:08.762Z",
          "wordCount": 597,
          "title": "Learning Autonomy in Management of Wireless Random Networks. (arXiv:2106.07984v1 [cs.IT])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08086",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Konig_G/0/1/0/all/0/1\">Gunnar K&#xf6;nig</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Freiesleben_T/0/1/0/all/0/1\">Timo Freiesleben</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bischl_B/0/1/0/all/0/1\">Bernd Bischl</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Casalicchio_G/0/1/0/all/0/1\">Giuseppe Casalicchio</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Grosse_Wentrup_M/0/1/0/all/0/1\">Moritz Grosse-Wentrup</a>",
          "description": "Global model-agnostic feature importance measures either quantify whether\nfeatures are directly used for a model's predictions (direct importance) or\nwhether they contain prediction-relevant information (associative importance).\nDirect importance provides causal insight into the model's mechanism, yet it\nfails to expose the leakage of information from associated but not directly\nused variables. In contrast, associative importance exposes information leakage\nbut does not provide causal insight into the model's mechanism. We introduce\nDEDACT - a framework to decompose well-established direct and associative\nimportance measures into their respective associative and direct components.\nDEDACT provides insight into both the sources of prediction-relevant\ninformation in the data and the direct and indirect feature pathways by which\nthe information enters the model. We demonstrate the method's usefulness on\nsimulated examples.",
          "link": "http://arxiv.org/abs/2106.08086",
          "publishedOn": "2021-06-16T01:21:08.731Z",
          "wordCount": 559,
          "title": "Decomposition of Global Feature Importance into Direct and Associative Components (DEDACT). (arXiv:2106.08086v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07963",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Yokoo_K/0/1/0/all/0/1\">Kazuki Yokoo</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Ishida_K/0/1/0/all/0/1\">Kei Ishida</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Ercan_A/0/1/0/all/0/1\">Ali Ercan</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Tu_T/0/1/0/all/0/1\">Tongbi Tu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Nagasato_T/0/1/0/all/0/1\">Takeyoshi Nagasato</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Kiyama_M/0/1/0/all/0/1\">Masato Kiyama</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Amagasaki_M/0/1/0/all/0/1\">Motoki Amagasaki</a>",
          "description": "This study investigates the relationships which deep learning methods can\nidentify between the input and output data. As a case study, rainfall-runoff\nmodeling in a snow-dominated watershed by means of a long- and short-term\nmemory (LSTM) network is selected. Daily precipitation and mean air temperature\nwere used as model input to estimate daily flow discharge. After model training\nand verification, two experimental simulations were conducted with hypothetical\ninputs instead of observed meteorological data to clarify the response of the\ntrained model to the inputs. The first numerical experiment showed that even\nwithout input precipitation, the trained model generated flow discharge,\nparticularly winter low flow and high flow during the snow-melting period. The\neffects of warmer and colder conditions on the flow discharge were also\nreplicated by the trained model without precipitation. Additionally, the model\nreflected only 17-39% of the total precipitation mass during the snow\naccumulation period in the total annual flow discharge, revealing a strong lack\nof water mass conservation. The results of this study indicated that a deep\nlearning method may not properly learn the explicit physical relationships\nbetween input and target variables, although they are still capable of\nmaintaining strong goodness-of-fit results.",
          "link": "http://arxiv.org/abs/2106.07963",
          "publishedOn": "2021-06-16T01:21:08.651Z",
          "wordCount": 651,
          "title": "Capabilities of Deep Learning Models on Learning Physical Relationships: Case of Rainfall-Runoff Modeling with LSTM. (arXiv:2106.07963v1 [physics.ao-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07752",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Braverman_M/0/1/0/all/0/1\">Mark Braverman</a>",
          "description": "The goal of this paper is to develop a generic framework for converting\nmodern optimization algorithms into mechanisms where inputs come from\nself-interested agents. We focus on aggregating preferences from $n$ players in\na context without money. Special cases of this setting include voting,\nallocation of items by lottery, and matching. Our key technical contribution is\na new meta-algorithm we call \\apex (Adaptive Pricing Equalizing Externalities).\nThe framework is sufficiently general to be combined with any optimization\nalgorithm that is based on local search. We outline an agenda for studying the\nalgorithm's properties and its applications. As a special case of applying the\nframework to the problem of one-sided assignment with lotteries, we obtain a\nstrengthening of the 1979 result by Hylland and Zeckhauser on allocation via a\ncompetitive equilibrium from equal incomes (CEEI). The [HZ79] result posits\nthat there is a (fractional) allocation and a set of item prices such that the\nallocation is a competitive equilibrium given prices. We further show that\nthere is always a reweighing of the players' utility values such that running\nunit-demand VCG with reweighed utilities leads to a HZ-equilibrium prices.\nInterestingly, not all HZ competitive equilibria come from VCG prices. As part\nof our proof, we re-prove the [HZ79] result using only Brouwer's fixed point\ntheorem (and not the more general Kakutani's theorem). This may be of\nindependent interest.",
          "link": "http://arxiv.org/abs/2106.07752",
          "publishedOn": "2021-06-16T01:21:08.578Z",
          "wordCount": 667,
          "title": "Optimization-friendly generic mechanisms without money. (arXiv:2106.07752v1 [cs.GT])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07992",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Feng_C/0/1/0/all/0/1\">Cheng Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_P/0/1/0/all/0/1\">Pengwei Tian</a>",
          "description": "Recent advances in AIoT technologies have led to an increasing popularity of\nutilizing machine learning algorithms to detect operational failures for\ncyber-physical systems (CPS). In its basic form, an anomaly detection module\nmonitors the sensor measurements and actuator states from the physical plant,\nand detects anomalies in these measurements to identify abnormal operation\nstatus. Nevertheless, building effective anomaly detection models for CPS is\nrather challenging as the model has to accurately detect anomalies in presence\nof highly complicated system dynamics and unknown amount of sensor noise. In\nthis work, we propose a novel time series anomaly detection method called\nNeural System Identification and Bayesian Filtering (NSIBF) in which a\nspecially crafted neural network architecture is posed for system\nidentification, i.e., capturing the dynamics of CPS in a dynamical state-space\nmodel; then a Bayesian filtering algorithm is naturally applied on top of the\n\"identified\" state-space model for robust anomaly detection by tracking the\nuncertainty of the hidden state of the system recursively over time. We provide\nqualitative as well as quantitative experiments with the proposed method on a\nsynthetic and three real-world CPS datasets, showing that NSIBF compares\nfavorably to the state-of-the-art methods with considerable improvements on\nanomaly detection in CPS.",
          "link": "http://arxiv.org/abs/2106.07992",
          "publishedOn": "2021-06-16T01:21:08.560Z",
          "wordCount": 650,
          "title": "Time Series Anomaly Detection for Cyber-physical Systems via Neural System Identification and Bayesian Filtering. (arXiv:2106.07992v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07823",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_V/0/1/0/all/0/1\">Vivek Srivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_M/0/1/0/all/0/1\">Mayank Singh</a>",
          "description": "Multilingualism refers to the high degree of proficiency in two or more\nlanguages in the written and oral communication modes. It often results in\nlanguage mixing, a.k.a. code-mixing, when a multilingual speaker switches\nbetween multiple languages in a single utterance of a text or speech. This\npaper discusses the current state of the NLP research, limitations, and\nforeseeable pitfalls in addressing five real-world applications for social good\ncrisis management, healthcare, political campaigning, fake news, and hate\nspeech for multilingual societies. We also propose futuristic datasets, models,\nand tools that can significantly advance the current research in multilingual\nNLP applications for the societal good. As a representative example, we\nconsider English-Hindi code-mixing but draw similar inferences for other\nlanguage pairs",
          "link": "http://arxiv.org/abs/2106.07823",
          "publishedOn": "2021-06-16T01:21:08.554Z",
          "wordCount": 547,
          "title": "Challenges and Considerations with Code-Mixed NLP for Multilingual Societies. (arXiv:2106.07823v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07827",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Valente_F/0/1/0/all/0/1\">Francisco Valente</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paredes_S/0/1/0/all/0/1\">Simao Paredes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henriques_J/0/1/0/all/0/1\">Jorge Henriques</a>",
          "description": "One of the key challenges when developing a predictive model is the\ncapability to describe the domain knowledge and the cause-effect relationships\nin a simple way. Decision rules are a useful and important methodology in this\ncontext, justifying their application in several areas, in particular in\nclinical practice. Several machine-learning classifiers have exploited the\nadvantageous properties of decision rules to build intelligent prediction\nmodels, namely decision trees and ensembles of trees (ETs). However, such\nmethodologies usually suffer from a trade-off between interpretability and\npredictive performance. Some procedures consider a simplification of ETs, using\nheuristic approaches to select an optimal reduced set of decision rules. In\nthis paper, we introduce a novel step to those methodologies. We create a new\ncomponent to predict if a given rule will be correct or not for a particular\npatient, which introduces personalization into the procedure. Furthermore, the\nvalidation results using three public clinical datasets show that it also\nallows to increase the predictive performance of the selected set of rules,\nimproving the mentioned trade-off.",
          "link": "http://arxiv.org/abs/2106.07827",
          "publishedOn": "2021-06-16T01:21:08.548Z",
          "wordCount": 606,
          "title": "Improving the compromise between accuracy, interpretability and personalization of rule-based machine learning in medical problems. (arXiv:2106.07827v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07851",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuqi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poskitt_C/0/1/0/all/0/1\">Christopher M. Poskitt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jun Sun</a>",
          "description": "Cyber-physical systems (CPSs) are widespread in critical domains, and\nsignificant damage can be caused if an attacker is able to modify the code of\ntheir programmable logic controllers (PLCs). Unfortunately, traditional\ntechniques for attesting code integrity (i.e. verifying that it has not been\nmodified) rely on firmware access or roots-of-trust, neither of which\nproprietary or legacy PLCs are likely to provide. In this paper, we propose a\npractical code integrity checking solution based on privacy-preserving black\nbox models that instead attest the input/output behaviour of PLC programs.\nUsing faithful offline copies of the PLC programs, we identify their most\nimportant inputs through an information flow analysis, execute them on multiple\ncombinations to collect data, then train neural networks able to predict PLC\noutputs (i.e. actuator commands) from their inputs. By exploiting the black box\nnature of the model, our solution maintains the privacy of the original PLC\ncode and does not assume that attackers are unaware of its presence. The trust\ninstead comes from the fact that it is extremely hard to attack the PLC code\nand neural networks at the same time and with consistent outcomes. We evaluated\nour approach on a modern six-stage water treatment plant testbed, finding that\nit could predict actuator states from PLC inputs with near-100% accuracy, and\nthus could detect all 120 effective code mutations that we subjected the PLCs\nto. Finally, we found that it is not practically possible to simultaneously\nmodify the PLC code and apply discreet adversarial noise to our attesters in a\nway that leads to consistent (mis-)predictions.",
          "link": "http://arxiv.org/abs/2106.07851",
          "publishedOn": "2021-06-16T01:21:08.498Z",
          "wordCount": 715,
          "title": "Code Integrity Attestation for PLCs using Black Box Neural Network Predictions. (arXiv:2106.07851v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2102.10769",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kidambi_R/0/1/0/all/0/1\">Rahul Kidambi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_J/0/1/0/all/0/1\">Jonathan Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1\">Wen Sun</a>",
          "description": "This paper studies Imitation Learning from Observations alone (ILFO) where\nthe learner is presented with expert demonstrations that consist only of states\nvisited by an expert (without access to actions taken by the expert). We\npresent a provably efficient model-based framework MobILE to solve the ILFO\nproblem. MobILE involves carefully trading off strategic exploration against\nimitation - this is achieved by integrating the idea of optimism in the face of\nuncertainty into the distribution matching imitation learning (IL) framework.\nWe provide a unified analysis for MobILE, and demonstrate that MobILE enjoys\nstrong performance guarantees for classes of MDP dynamics that satisfy certain\nwell studied notions of structural complexity. We also show that the ILFO\nproblem is strictly harder than the standard IL problem by presenting an\nexponential sample complexity separation between IL and ILFO. We complement\nthese theoretical results with experimental simulations on benchmark OpenAI Gym\ntasks that indicate the efficacy of MobILE.",
          "link": "http://arxiv.org/abs/2102.10769",
          "publishedOn": "2021-06-16T01:21:08.466Z",
          "wordCount": 614,
          "title": "MobILE: Model-Based Imitation Learning From Observation Alone. (arXiv:2102.10769v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.07954",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_L/0/1/0/all/0/1\">Liexing Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haoxue Wang</a>",
          "description": "Loan risk for small business has long been a complex problem worthy of\nexploring. Predicting the loan risk approximately can benefit entrepreneurship\nby developing more jobs for the society. CatBoost (Categorical Boosting) is a\npowerful machine learning algorithm that is suitable for dataset with many\ncategorical variables like the dataset for forecasting loan risk. In this\npaper, we identify the important risk factors that contribute to loan status\nclassification problem. Then we compare the the performance between\nboosting-type algorithms(especially CatBoost) with other traditional yet\npopular ones. The dataset we adopt in the research comes from the U.S. Small\nBusiness Administration (SBA) and holds a very large sample size (899,164\nobservations and 27 features). We obtain a high accuracy of 95.74% and\nwell-performed AUC of 98.59% compared with the existent literature of related\nresearch. In order to make best use of the important features in the dataset,\nwe propose a technique named \"synthetic generation\" to develop more combined\nfeatures based on arithmetic operation, which ends up improving the accuracy\nand AUC of original CatBoost model.",
          "link": "http://arxiv.org/abs/2106.07954",
          "publishedOn": "2021-06-16T01:21:08.426Z",
          "wordCount": 616,
          "title": "CatBoost model with synthetic features in application to loan risk assessment of small businesses. (arXiv:2106.07954v1 [cs.CE])"
        },
        {
          "id": "http://arxiv.org/abs/2104.01894",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sanabria_R/0/1/0/all/0/1\">Ramon Sanabria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Waters_A/0/1/0/all/0/1\">Austin Waters</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baldridge_J/0/1/0/all/0/1\">Jason Baldridge</a>",
          "description": "Speech-based image retrieval has been studied as a proxy for joint\nrepresentation learning, usually without emphasis on retrieval itself. As such,\nit is unclear how well speech-based retrieval can work in practice -- both in\nan absolute sense and versus alternative strategies that combine automatic\nspeech recognition (ASR) with strong text encoders. In this work, we\nextensively study and expand choices of encoder architectures, training\nmethodology (including unimodal and multimodal pretraining), and other factors.\nOur experiments cover different types of speech in three datasets: Flickr\nAudio, Places Audio, and Localized Narratives. Our best model configuration\nachieves large gains over state of the art, e.g., pushing recall-at-one from\n21.8% to 33.2% for Flickr Audio and 27.6% to 53.4% for Places Audio. We also\nshow our best speech-based models can match or exceed cascaded ASR-to-text\nencoding when speech is spontaneous, accented, or otherwise hard to\nautomatically transcribe.",
          "link": "http://arxiv.org/abs/2104.01894",
          "publishedOn": "2021-06-16T01:21:08.419Z",
          "wordCount": 631,
          "title": "Talk, Don't Write: A Study of Direct Speech-Based Image Retrieval. (arXiv:2104.01894v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.07847",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bao_Y/0/1/0/all/0/1\">Yujia Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1\">Shiyu Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barzilay_R/0/1/0/all/0/1\">Regina Barzilay</a>",
          "description": "We study transfer learning in the presence of spurious correlations. We\nexperimentally demonstrate that directly transferring the stable feature\nextractor learned on the source task may not eliminate these biases for the\ntarget task. However, we hypothesize that the unstable features in the source\ntask and those in the target task are directly related. By explicitly informing\nthe target classifier of the source task's unstable features, we can regularize\nthe biases in the target task. Specifically, we derive a representation that\nencodes the unstable features by contrasting different data environments in the\nsource task. On the target task, we cluster data from this representation, and\nachieve robustness by minimizing the worst-case risk across all clusters. We\nevaluate our method on both text and image classifications. Empirical results\ndemonstrate that our algorithm is able to maintain robustness on the target\ntask, outperforming the best baseline by 22.9% in absolute accuracy across 12\ntransfer settings. Our code is available at https://github.com/YujiaBao/Tofu.",
          "link": "http://arxiv.org/abs/2106.07847",
          "publishedOn": "2021-06-16T01:21:08.412Z",
          "wordCount": 601,
          "title": "Learning Stable Classifiers by Transferring Unstable Features. (arXiv:2106.07847v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2011.12690",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Heijden_B/0/1/0/all/0/1\">Bas van der Heijden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferranti_L/0/1/0/all/0/1\">Laura Ferranti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kober_J/0/1/0/all/0/1\">Jens Kober</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Babuska_R/0/1/0/all/0/1\">Robert Babuska</a>",
          "description": "This paper presents DeepKoCo, a novel model-based agent that learns a latent\nKoopman representation from images. This representation allows DeepKoCo to plan\nefficiently using linear control methods, such as linear model predictive\ncontrol. Compared to traditional agents, DeepKoCo is robust to task-irrelevant\ndynamics, thanks to the use of a tailored lossy autoencoder network that allows\nDeepKoCo to learn latent dynamics that reconstruct and predict only observed\ncosts, rather than all observed dynamics. As our results show, DeepKoCo\nachieves a similar final performance as traditional model-free methods on\ncomplex control tasks, while being considerably more robust to distractor\ndynamics, making the proposed agent more amenable for real-life applications.",
          "link": "http://arxiv.org/abs/2011.12690",
          "publishedOn": "2021-06-16T01:21:08.391Z",
          "wordCount": 581,
          "title": "DeepKoCo: Efficient latent planning with a robust Koopman representation. (arXiv:2011.12690v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.09757",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Feng_H/0/1/0/all/0/1\">Hao-Zhe Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_Z/0/1/0/all/0/1\">Zhaoyang You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Minghao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tianye Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1\">Minfeng Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wei Chen</a>",
          "description": "Conventional unsupervised multi-source domain adaptation (UMDA) methods\nassume all source domains can be accessed directly. This neglects the\nprivacy-preserving policy, that is, all the data and computations must be kept\ndecentralized. There exists three problems in this scenario: (1) Minimizing the\ndomain distance requires the pairwise calculation of the data from source and\ntarget domains, which is not accessible. (2) The communication cost and privacy\nsecurity limit the application of UMDA methods (e.g., the domain adversarial\ntraining). (3) Since users have no authority to check the data quality, the\nirrelevant or malicious source domains are more likely to appear, which causes\nnegative transfer. In this study, we propose a privacy-preserving UMDA paradigm\nnamed Knowledge Distillation based Decentralized Domain Adaptation (KD3A),\nwhich performs domain adaptation through the knowledge distillation on models\nfrom different source domains. KD3A solves the above problems with three\ncomponents: (1) A multi-source knowledge distillation method named Knowledge\nVote to learn high-quality domain consensus knowledge. (2) A dynamic weighting\nstrategy named Consensus Focus to identify both the malicious and irrelevant\ndomains. (3) A decentralized optimization strategy for domain distance named\nBatchNorm MMD. The extensive experiments on DomainNet demonstrate that KD3A is\nrobust to the negative transfer and brings a 100x reduction of communication\ncost compared with other decentralized UMDA methods. Moreover, our KD3A\nsignificantly outperforms state-of-the-art UMDA approaches.",
          "link": "http://arxiv.org/abs/2011.09757",
          "publishedOn": "2021-06-16T01:21:08.385Z",
          "wordCount": 740,
          "title": "KD3A: Unsupervised Multi-Source Decentralized Domain Adaptation via Knowledge Distillation. (arXiv:2011.09757v7 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.07914",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vlassis_N/0/1/0/all/0/1\">Nikos Vlassis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandrashekar_A/0/1/0/all/0/1\">Ashok Chandrashekar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gil_F/0/1/0/all/0/1\">Fernando Amat Gil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kallus_N/0/1/0/all/0/1\">Nathan Kallus</a>",
          "description": "We study the problem of off-policy evaluation from batched contextual bandit\ndata with multidimensional actions, often termed slates. The problem is common\nto recommender systems and user-interface optimization, and it is particularly\nchallenging because of the combinatorially-sized action space. Swaminathan et\nal. (2017) have proposed the pseudoinverse (PI) estimator under the assumption\nthat the conditional mean rewards are additive in actions. Using control\nvariates, we consider a large class of unbiased estimators that includes as\nspecific cases the PI estimator and (asymptotically) its self-normalized\nvariant. By optimizing over this class, we obtain new estimators with risk\nimprovement guarantees over both the PI and self-normalized PI estimators.\nExperiments with real-world recommender data as well as synthetic data validate\nthese improvements in practice.",
          "link": "http://arxiv.org/abs/2106.07914",
          "publishedOn": "2021-06-16T01:21:08.377Z",
          "wordCount": 546,
          "title": "Control Variates for Slate Off-Policy Evaluation. (arXiv:2106.07914v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2011.05905",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1\">Zhichuang Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1\">Ruimin Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Changming Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chowdhury_A/0/1/0/all/0/1\">Amrita Roy Chowdhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jha_S/0/1/0/all/0/1\">Somesh Jha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_L/0/1/0/all/0/1\">Long Lu</a>",
          "description": "With the increased usage of AI accelerators on mobile and edge devices,\non-device machine learning (ML) is gaining popularity. Consequently, thousands\nof proprietary ML models are being deployed on billions of untrusted devices.\nThis raises serious security concerns about model privacy. However, protecting\nthe model privacy without losing access to the AI accelerators is a challenging\nproblem. In this paper, we present a novel on-device model inference system,\nShadowNet. ShadowNet protects the model privacy with Trusted Execution\nEnvironment (TEE) while securely outsourcing the heavy linear layers of the\nmodel to the untrusted hardware accelerators. ShadowNet achieves this by\ntransforming the weights of the linear layers before outsourcing them and\nrestoring the results inside the TEE. The nonlinear layers are also kept secure\ninside the TEE. The transformation of the weights and the restoration of the\nresults are designed in a way that can be implemented efficiently. We have\nbuilt a ShadowNet prototype based on TensorFlow Lite and applied it on four\npopular CNNs, namely, MobileNets, ResNet-44, AlexNet and MiniVGG. Our\nevaluation shows that ShadowNet achieves strong security guarantees with\nreasonable performance, offering a practical solution for secure on-device\nmodel inference.",
          "link": "http://arxiv.org/abs/2011.05905",
          "publishedOn": "2021-06-16T01:21:08.371Z",
          "wordCount": 669,
          "title": "ShadowNet: A Secure and Efficient System for On-device Model Inference. (arXiv:2011.05905v2 [cs.CR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.07754",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Crupi_R/0/1/0/all/0/1\">Riccardo Crupi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Castelnovo_A/0/1/0/all/0/1\">Alessandro Castelnovo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Regoli_D/0/1/0/all/0/1\">Daniele Regoli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_B/0/1/0/all/0/1\">Beatriz San Miguel Gonzalez</a>",
          "description": "Explainable Artificial Intelligence (XAI) is a set of techniques that allows\nthe understanding of both technical and non-technical aspects of Artificial\nIntelligence (AI) systems. XAI is crucial to help satisfying the increasingly\nimportant demand of \\emph{trustworthy} Artificial Intelligence, characterized\nby fundamental characteristics such as respect of human autonomy, prevention of\nharm, transparency, accountability, etc. Within XAI techniques, counterfactual\nexplanations aim to provide to end users a set of features (and their\ncorresponding values) that need to be changed in order to achieve a desired\noutcome. Current approaches rarely take into account the feasibility of actions\nneeded to achieve the proposed explanations, and in particular they fall short\nof considering the causal impact of such actions. In this paper, we present\nCounterfactual Explanations as Interventions in Latent Space (CEILS), a\nmethodology to generate counterfactual explanations capturing by design the\nunderlying causal relations from the data, and at the same time to provide\nfeasible recommendations to reach the proposed profile. Moreover, our\nmethodology has the advantage that it can be set on top of existing\ncounterfactuals generator algorithms, thus minimising the complexity of\nimposing additional causal constrains. We demonstrate the effectiveness of our\napproach with a set of different experiments using synthetic and real datasets\n(including a proprietary dataset of the financial domain).",
          "link": "http://arxiv.org/abs/2106.07754",
          "publishedOn": "2021-06-16T01:21:08.364Z",
          "wordCount": 655,
          "title": "Counterfactual Explanations as Interventions in Latent Space. (arXiv:2106.07754v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07719",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hajiaghayi_M/0/1/0/all/0/1\">Mahdi Hajiaghayi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hajiaghayi_M/0/1/0/all/0/1\">Monir Hajiaghayi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bolin_M/0/1/0/all/0/1\">Mark Bolin</a>",
          "description": "In this paper, we present a multi-lingual sentence encoder that can be used\nin search engines as a query and document encoder. This embedding enables a\nsemantic similarity score between queries and documents that can be an\nimportant feature in document ranking and relevancy. To train such a customized\nsentence encoder, it is beneficial to leverage users search data in the form of\nquery-document clicked pairs however, we must avoid relying too much on search\nclick data as it is biased and does not cover many unseen cases. The search\ndata is heavily skewed towards short queries and for long queries is small and\noften noisy. The goal is to design a universal multi-lingual encoder that works\nfor all cases and covers both short and long queries. We select a number of\npublic NLI datasets in different languages and translation data and together\nwith user search data we train a language model using a multi-task approach. A\nchallenge is that these datasets are not homogeneous in terms of content, size\nand the balance ratio. While the public NLI datasets are usually two-sentence\nbased with the same portion of positive and negative pairs, the user search\ndata can contain multi-sentence documents and only positive pairs. We show how\nmulti-task training enables us to leverage all these datasets and exploit\nknowledge sharing across these tasks.",
          "link": "http://arxiv.org/abs/2106.07719",
          "publishedOn": "2021-06-16T01:21:08.343Z",
          "wordCount": 651,
          "title": "Unbiased Sentence Encoder For Large-Scale Multi-lingual Search Engines. (arXiv:2106.07719v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08315",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Beznosikov_A/0/1/0/all/0/1\">Aleksandr Beznosikov</a>, <a href=\"http://arxiv.org/find/math/1/au:+Dvurechensky_P/0/1/0/all/0/1\">Pavel Dvurechensky</a>, <a href=\"http://arxiv.org/find/math/1/au:+Koloskova_A/0/1/0/all/0/1\">Anastasia Koloskova</a>, <a href=\"http://arxiv.org/find/math/1/au:+Samokhin_V/0/1/0/all/0/1\">Valentin Samokhin</a>, <a href=\"http://arxiv.org/find/math/1/au:+Stich_S/0/1/0/all/0/1\">Sebastian U Stich</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gasnikov_A/0/1/0/all/0/1\">Alexander Gasnikov</a>",
          "description": "We consider decentralized stochastic variational inequalities where the\nproblem data is distributed across many participating devices (heterogeneous,\nor non-IID data setting). We propose a novel method - based on stochastic\nextra-gradient - where participating devices can communicate over arbitrary,\npossibly time-varying network topologies. This covers both the fully\ndecentralized optimization setting and the centralized topologies commonly used\nin Federated Learning. Our method further supports multiple local updates on\nthe workers for reducing the communication frequency between workers. We\ntheoretically analyze the proposed scheme in the strongly monotone, monotone\nand non-monotone setting. As a special case, our method and analysis apply in\nparticular to decentralized stochastic min-max problems which are being studied\nwith increased interest in Deep Learning. For example, the training objective\nof Generative Adversarial Networks (GANs) are typically saddle point problems\nand the decentralized training of GANs has been reported to be extremely\nchallenging. While SOTA techniques rely on either repeated gossip rounds or\nproximal updates, we alleviate both of these requirements. Experimental results\nfor decentralized GAN demonstrate the effectiveness of our proposed algorithm.",
          "link": "http://arxiv.org/abs/2106.08315",
          "publishedOn": "2021-06-16T01:21:08.337Z",
          "wordCount": 615,
          "title": "Decentralized Local Stochastic Extra-Gradient for Variational Inequalities. (arXiv:2106.08315v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/1909.00453",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Sachin Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wintner_S/0/1/0/all/0/1\">Shuly Wintner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1\">Noah A. Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsvetkov_Y/0/1/0/all/0/1\">Yulia Tsvetkov</a>",
          "description": "Despite impressive performance on many text classification tasks, deep neural\nnetworks tend to learn frequent superficial patterns that are specific to the\ntraining data and do not always generalize well. In this work, we observe this\nlimitation with respect to the task of native language identification. We find\nthat standard text classifiers which perform well on the test set end up\nlearning topical features which are confounds of the prediction task (e.g., if\nthe input text mentions Sweden, the classifier predicts that the author's\nnative language is Swedish). We propose a method that represents the latent\ntopical confounds and a model which \"unlearns\" confounding features by\npredicting both the label of the input text and the confound; but we train the\ntwo predictors adversarially in an alternating fashion to learn a text\nrepresentation that predicts the correct label but is less prone to using\ninformation about the confound. We show that this model generalizes better and\nlearns features that are indicative of the writing style rather than the\ncontent.",
          "link": "http://arxiv.org/abs/1909.00453",
          "publishedOn": "2021-06-16T01:21:08.330Z",
          "wordCount": 648,
          "title": "Topics to Avoid: Demoting Latent Confounds in Text Classification. (arXiv:1909.00453v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.04051",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shui_C/0/1/0/all/0/1\">Changjian Shui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zijian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiaqi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gagne_C/0/1/0/all/0/1\">Christian Gagn&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_C/0/1/0/all/0/1\">Charles Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Boyu Wang</a>",
          "description": "Multi-source domain adaptation aims at leveraging the knowledge from multiple\ntasks for predicting a related target domain. Hence, a crucial aspect is to\nproperly combine different sources based on their relations. In this paper, we\nanalyzed the problem for aggregating source domains with different label\ndistributions, where most recent source selection approaches fail. Our proposed\nalgorithm differs from previous approaches in two key ways: the model\naggregates multiple sources mainly through the similarity of semantic\nconditional distribution rather than marginal distribution; the model proposes\na \\emph{unified} framework to select relevant sources for three popular\nscenarios, i.e., domain adaptation with limited label on target domain,\nunsupervised domain adaptation and label partial unsupervised domain adaption.\nWe evaluate the proposed method through extensive experiments. The empirical\nresults significantly outperform the baselines.",
          "link": "http://arxiv.org/abs/2105.04051",
          "publishedOn": "2021-06-16T01:21:08.323Z",
          "wordCount": 587,
          "title": "Aggregating From Multiple Target-Shifted Sources. (arXiv:2105.04051v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.12230",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jingzhao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Menon_A/0/1/0/all/0/1\">Aditya Menon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Veit_A/0/1/0/all/0/1\">Andreas Veit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhojanapalli_S/0/1/0/all/0/1\">Srinadh Bhojanapalli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Sanjiv Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sra_S/0/1/0/all/0/1\">Suvrit Sra</a>",
          "description": "The label shift problem refers to the supervised learning setting where the\ntrain and test label distributions do not match. Existing work addressing label\nshift usually assumes access to an \\emph{unlabelled} test sample. This sample\nmay be used to estimate the test label distribution, and to then train a\nsuitably re-weighted classifier. While approaches using this idea have proven\neffective, their scope is limited as it is not always feasible to access the\ntarget domain; further, they require repeated retraining if the model is to be\ndeployed in \\emph{multiple} test environments. Can one instead learn a\n\\emph{single} classifier that is robust to arbitrary label shifts from a broad\nfamily? In this paper, we answer this question by proposing a model that\nminimises an objective based on distributionally robust optimisation (DRO). We\nthen design and analyse a gradient descent-proximal mirror ascent algorithm\ntailored for large-scale problems to optimise the proposed objective. %, and\nestablish its convergence. Finally, through experiments on CIFAR-100 and\nImageNet, we show that our technique can significantly improve performance over\na number of baselines in settings where label shift is present.",
          "link": "http://arxiv.org/abs/2010.12230",
          "publishedOn": "2021-06-16T01:21:08.316Z",
          "wordCount": 656,
          "title": "Coping with Label Shift via Distributionally Robust Optimisation. (arXiv:2010.12230v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.11872",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_S/0/1/0/all/0/1\">Shivin Srivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhatia_S/0/1/0/all/0/1\">Siddharth Bhatia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1\">Lingxiao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heng_L/0/1/0/all/0/1\">Lim Jun Heng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kawaguchi_K/0/1/0/all/0/1\">Kenji Kawaguchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajan_V/0/1/0/all/0/1\">Vaibhav Rajan</a>",
          "description": "In data containing heterogeneous subpopulations, classification performance\nbenefits from incorporating the knowledge of cluster structure in the\nclassifier. Previous methods for such combined clustering and classification\nare either 1) classifier-specific and not generic, or 2) independently perform\nclustering and classifier training, which may not form clusters that can\npotentially benefit classifier performance. The question of how to perform\nclustering to improve the performance of classifiers trained on the clusters\nhas received scant attention in previous literature, despite its importance in\nseveral real-world applications. In this paper, we design a simple and\nefficient classification algorithm called Clustering Aware Classification\n(CAC), to find clusters that are well suited for being used as training\ndatasets by classifiers for each underlying subpopulation. Our experiments on\nsynthetic and real benchmark datasets demonstrate the efficacy of CAC over\nprevious methods for combined clustering and classification.",
          "link": "http://arxiv.org/abs/2102.11872",
          "publishedOn": "2021-06-16T01:21:08.297Z",
          "wordCount": 600,
          "title": "Dont Just Divide; Polarize and Conquer!. (arXiv:2102.11872v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.07779",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Diakonikolas_I/0/1/0/all/0/1\">Ilias Diakonikolas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Impagliazzo_R/0/1/0/all/0/1\">Russell Impagliazzo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kane_D/0/1/0/all/0/1\">Daniel Kane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_R/0/1/0/all/0/1\">Rex Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sorrell_J/0/1/0/all/0/1\">Jessica Sorrell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tzamos_C/0/1/0/all/0/1\">Christos Tzamos</a>",
          "description": "We study the problem of boosting the accuracy of a weak learner in the\n(distribution-independent) PAC model with Massart noise. In the Massart noise\nmodel, the label of each example $x$ is independently misclassified with\nprobability $\\eta(x) \\leq \\eta$, where $\\eta<1/2$. The Massart model lies\nbetween the random classification noise model and the agnostic model. Our main\npositive result is the first computationally efficient boosting algorithm in\nthe presence of Massart noise that achieves misclassification error arbitrarily\nclose to $\\eta$. Prior to our work, no non-trivial booster was known in this\nsetting. Moreover, we show that this error upper bound is best possible for\npolynomial-time black-box boosters, under standard cryptographic assumptions.\nOur upper and lower bounds characterize the complexity of boosting in the\ndistribution-independent PAC model with Massart noise. As a simple application\nof our positive result, we give the first efficient Massart learner for unions\nof high-dimensional rectangles.",
          "link": "http://arxiv.org/abs/2106.07779",
          "publishedOn": "2021-06-16T01:21:08.291Z",
          "wordCount": 581,
          "title": "Boosting in the Presence of Massart Noise. (arXiv:2106.07779v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2012.02409",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chatterji_N/0/1/0/all/0/1\">Niladri S. Chatterji</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Long_P/0/1/0/all/0/1\">Philip M. Long</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bartlett_P/0/1/0/all/0/1\">Peter L. Bartlett</a>",
          "description": "We study the training of finite-width two-layer smoothed ReLU networks for\nbinary classification using the logistic loss. We show that gradient descent\ndrives the training loss to zero if the initial loss is small enough. When the\ndata satisfies certain cluster and separation conditions and the network is\nwide enough, we show that one step of gradient descent reduces the loss\nsufficiently that the first result applies.",
          "link": "http://arxiv.org/abs/2012.02409",
          "publishedOn": "2021-06-16T01:21:08.285Z",
          "wordCount": 539,
          "title": "When does gradient descent with logistic loss find interpolating two-layer networks?. (arXiv:2012.02409v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.03639",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lang_H/0/1/0/all/0/1\">Hunter Lang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sontag_D/0/1/0/all/0/1\">David Sontag</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vijayaraghavan_A/0/1/0/all/0/1\">Aravindan Vijayaraghavan</a>",
          "description": "We prove that the $\\alpha$-expansion algorithm for MAP inference always\nreturns a globally optimal assignment for Markov Random Fields with Potts\npairwise potentials, with a catch: the returned assignment is only guaranteed\nto be optimal for an instance within a small perturbation of the original\nproblem instance. In other words, all local minima with respect to expansion\nmoves are global minima to slightly perturbed versions of the problem. On\n\"real-world\" instances, MAP assignments of small perturbations of the problem\nshould be very similar to the MAP assignment(s) of the original problem\ninstance. We design an algorithm that can certify whether this is the case in\npractice. On several MAP inference problem instances from computer vision, this\nalgorithm certifies that MAP solutions to all of these perturbations are very\nclose to solutions of the original instance. These results taken together give\na cohesive explanation for the good performance of \"graph cuts\" algorithms in\npractice. Every local expansion minimum is a global minimum in a small\nperturbation of the problem, and all of these global minima are close to the\noriginal solution.",
          "link": "http://arxiv.org/abs/2011.03639",
          "publishedOn": "2021-06-16T01:21:08.278Z",
          "wordCount": 652,
          "title": "Graph cuts always find a global optimum for Potts models (with a catch). (arXiv:2011.03639v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1910.12019",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_H/0/1/0/all/0/1\">Huanhou Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1\">Jinglun Shi</a>",
          "description": "Automatically describing video content with text description is challenging\nbut important task, which has been attracting a lot of attention in computer\nvision community. Previous works mainly strive for the accuracy of the\ngenerated sentences, while ignoring the sentences diversity, which is\ninconsistent with human behavior. In this paper, we aim to caption each video\nwith multiple descriptions and propose a novel framework. Concretely, for a\ngiven video, the intermediate latent variables of conventional encode-decode\nprocess are utilized as input to the conditional generative adversarial network\n(CGAN) with the purpose of generating diverse sentences. We adopt different\nConvolutional Neural Networks (CNNs) as our generator that produces\ndescriptions conditioned on latent variables and discriminator that assesses\nthe quality of generated sentences. Simultaneously, a novel DCE metric is\ndesigned to assess the diverse captions. We evaluate our method on the\nbenchmark datasets, where it demonstrates its ability to generate diverse\ndescriptions and achieves superior results against other state-of-the-art\nmethods.",
          "link": "http://arxiv.org/abs/1910.12019",
          "publishedOn": "2021-06-16T01:21:08.269Z",
          "wordCount": 645,
          "title": "Diverse Video Captioning Through Latent Variable Expansion. (arXiv:1910.12019v6 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.07908",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hoang_T/0/1/0/all/0/1\">Truong-Vinh Hoang</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Krumscheid_S/0/1/0/all/0/1\">Sebastian Krumscheid</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Matthies_H/0/1/0/all/0/1\">Hermann G. Matthies</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Tempone_R/0/1/0/all/0/1\">Ra&#xfa;l Tempone</a> (1 and 3) ((1) Chair of Mathematics for Uncertainty Quantification, RWTH Aachen University, (2) Technische Universit&#xe4;t Braunschweig (3) Computer, Electrical and Mathematical Sciences and Engineering, KAUST, and Alexander von Humboldt professor in Mathematics of Uncertainty Quantification, RWTH Aachen University)",
          "description": "Filtering is a data assimilation technique that performs the sequential\ninference of dynamical systems states from noisy observations. Herein, we\npropose a machine learning-based ensemble conditional mean filter (ML-EnCMF)\nfor tracking possibly high-dimensional non-Gaussian state models with nonlinear\ndynamics based on sparse observations. The proposed filtering method is\ndeveloped based on the conditional expectation and numerically implemented\nusing machine learning (ML) techniques combined with the ensemble method. The\ncontribution of this work is twofold. First, we demonstrate that the ensembles\nassimilated using the ensemble conditional mean filter (EnCMF) provide an\nunbiased estimator of the Bayesian posterior mean, and their variance matches\nthe expected conditional variance. Second, we implement the EnCMF using\nartificial neural networks, which have a significant advantage in representing\nnonlinear functions over high-dimensional domains such as the conditional mean.\nFinally, we demonstrate the effectiveness of the ML-EnCMF for tracking the\nstates of Lorenz-63 and Lorenz-96 systems under the chaotic regime. Numerical\nresults show that the ML-EnCMF outperforms the ensemble Kalman filter.",
          "link": "http://arxiv.org/abs/2106.07908",
          "publishedOn": "2021-06-16T01:21:08.252Z",
          "wordCount": 660,
          "title": "Machine learning-based conditional mean filter: a generalization of the ensemble Kalman filter for nonlinear data assimilation. (arXiv:2106.07908v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07880",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zandieh_A/0/1/0/all/0/1\">Amir Zandieh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_I/0/1/0/all/0/1\">Insu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Avron_H/0/1/0/all/0/1\">Haim Avron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shoham_N/0/1/0/all/0/1\">Neta Shoham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_C/0/1/0/all/0/1\">Chaewon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1\">Jinwoo Shin</a>",
          "description": "The Neural Tangent Kernel (NTK) characterizes the behavior of infinitely-wide\nneural networks trained under least squares loss by gradient descent. Recent\nworks also report that NTK regression can outperform finitely-wide neural\nnetworks trained on small-scale datasets. However, the computational complexity\nof kernel methods has limited its use in large-scale learning tasks. To\naccelerate learning with NTK, we design a near input-sparsity time\napproximation algorithm for NTK, by sketching the polynomial expansions of\narc-cosine kernels: our sketch for the convolutional counterpart of NTK (CNTK)\ncan transform any image using a linear runtime in the number of pixels.\nFurthermore, we prove a spectral approximation guarantee for the NTK matrix, by\ncombining random features (based on leverage score sampling) of the arc-cosine\nkernels with a sketching algorithm. We benchmark our methods on various\nlarge-scale regression and classification tasks and show that a linear\nregressor trained on our CNTK features matches the accuracy of exact CNTK on\nCIFAR-10 dataset while achieving 150x speedup.",
          "link": "http://arxiv.org/abs/2106.07880",
          "publishedOn": "2021-06-16T01:21:08.245Z",
          "wordCount": 609,
          "title": "Scaling Neural Tangent Kernels via Sketching and Random Features. (arXiv:2106.07880v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07720",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Peito_J/0/1/0/all/0/1\">Joel Peito</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_Q/0/1/0/all/0/1\">Qiwei Han</a>",
          "description": "In contrast to many other domains, recommender systems in health services may\nbenefit particularly from the incorporation of health domain knowledge, as it\nhelps to provide meaningful and personalised recommendations catering to the\nindividual's health needs. With recent advances in representation learning\nenabling the hierarchical embedding of health knowledge into the hyperbolic\nPoincare space, this work proposes a content-based recommender system for\npatient-doctor matchmaking in primary care based on patients' health profiles,\nenriched by pre-trained Poincare embeddings of the ICD-9 codes through transfer\nlearning. The proposed model outperforms its conventional counterpart in terms\nof recommendation accuracy and has several important business implications for\nimproving the patient-doctor relationship.",
          "link": "http://arxiv.org/abs/2106.07720",
          "publishedOn": "2021-06-16T01:21:08.228Z",
          "wordCount": 552,
          "title": "Incorporating Domain Knowledge into Health Recommender Systems using Hyperbolic Embeddings. (arXiv:2106.07720v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08068",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Saglietti_L/0/1/0/all/0/1\">Luca Saglietti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mannelli_S/0/1/0/all/0/1\">Stefano Sarao Mannelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saxe_A/0/1/0/all/0/1\">Andrew Saxe</a>",
          "description": "In humans and animals, curriculum learning -- presenting data in a curated\norder - is critical to rapid learning and effective pedagogy. Yet in machine\nlearning, curricula are not widely used and empirically often yield only\nmoderate benefits. This stark difference in the importance of curriculum raises\na fundamental theoretical question: when and why does curriculum learning help?\n\nIn this work, we analyse a prototypical neural network model of curriculum\nlearning in the high-dimensional limit, employing statistical physics methods.\nCurricula could in principle change both the learning speed and asymptotic\nperformance of a model. To study the former, we provide an exact description of\nthe online learning setting, confirming the long-standing experimental\nobservation that curricula can modestly speed up learning. To study the latter,\nwe derive performance in a batch learning setting, in which a network trains to\nconvergence in successive phases of learning on dataset slices of varying\ndifficulty. With standard training losses, curriculum does not provide\ngeneralisation benefit, in line with empirical observations. However, we show\nthat by connecting different learning phases through simple Gaussian priors,\ncurriculum can yield a large improvement in test performance. Taken together,\nour reduced analytical descriptions help reconcile apparently conflicting\nempirical results and trace regimes where curriculum learning yields the\nlargest gains. More broadly, our results suggest that fully exploiting a\ncurriculum may require explicit changes to the loss function at curriculum\nboundaries.",
          "link": "http://arxiv.org/abs/2106.08068",
          "publishedOn": "2021-06-16T01:21:08.207Z",
          "wordCount": 674,
          "title": "An Analytical Theory of Curriculum Learning in Teacher-Student Networks. (arXiv:2106.08068v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07736",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Jin_D/0/1/0/all/0/1\">Dian Jin</a>, <a href=\"http://arxiv.org/find/math/1/au:+Bing_X/0/1/0/all/0/1\">Xin Bing</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuqian Zhang</a>",
          "description": "The problem of finding the unique low dimensional decomposition of a given\nmatrix has been a fundamental and recurrent problem in many areas. In this\npaper, we study the problem of seeking a unique decomposition of a low rank\nmatrix $Y\\in \\mathbb{R}^{p\\times n}$ that admits a sparse representation.\nSpecifically, we consider $Y = A X\\in \\mathbb{R}^{p\\times n}$ where the matrix\n$A\\in \\mathbb{R}^{p\\times r}$ has full column rank, with $r < \\min\\{n,p\\}$, and\nthe matrix $X\\in \\mathbb{R}^{r\\times n}$ is element-wise sparse. We prove that\nthis sparse decomposition of $Y$ can be uniquely identified, up to some\nintrinsic signed permutation. Our approach relies on solving a nonconvex\noptimization problem constrained over the unit sphere. Our geometric analysis\nfor the nonconvex optimization landscape shows that any {\\em strict} local\nsolution is close to the ground truth solution, and can be recovered by a\nsimple data-driven initialization followed with any second order descent\nalgorithm. At last, we corroborate these theoretical results with numerical\nexperiments.",
          "link": "http://arxiv.org/abs/2106.07736",
          "publishedOn": "2021-06-16T01:21:08.196Z",
          "wordCount": 597,
          "title": "Unique sparse decomposition of low rank matrices. (arXiv:2106.07736v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07904",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qizhou Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Feng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1\">Bo Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tongliang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_C/0/1/0/all/0/1\">Chen Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1\">Gang Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1\">Mingyuan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masashi Sugiyama</a>",
          "description": "Reweighting adversarial data during training has been recently shown to\nimprove adversarial robustness, where data closer to the current decision\nboundaries are regarded as more critical and given larger weights. However,\nexisting methods measuring the closeness are not very reliable: they are\ndiscrete and can take only a few values, and they are path-dependent, i.e.,\nthey may change given the same start and end points with different attack\npaths. In this paper, we propose three types of probabilistic margin (PM),\nwhich are continuous and path-independent, for measuring the aforementioned\ncloseness and reweighting adversarial data. Specifically, a PM is defined as\nthe difference between two estimated class-posterior probabilities, e.g., such\nthe probability of the true label minus the probability of the most confusing\nlabel given some natural data. Though different PMs capture different geometric\nproperties, all three PMs share a negative correlation with the vulnerability\nof data: data with larger/smaller PMs are safer/riskier and should have\nsmaller/larger weights. Experiments demonstrate that PMs are reliable\nmeasurements and PM-based reweighting methods outperform state-of-the-art\nmethods.",
          "link": "http://arxiv.org/abs/2106.07904",
          "publishedOn": "2021-06-16T01:21:08.190Z",
          "wordCount": 608,
          "title": "Probabilistic Margins for Instance Reweighting in Adversarial Training. (arXiv:2106.07904v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07758",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Verma_S/0/1/0/all/0/1\">Sahil Verma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lahiri_A/0/1/0/all/0/1\">Aditya Lahiri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dickerson_J/0/1/0/all/0/1\">John P. Dickerson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Su-In Lee</a>",
          "description": "As machine learning (ML) systems take a more prominent and central role in\ncontributing to life-impacting decisions, ensuring their trustworthiness and\naccountability is of utmost importance. Explanations sit at the core of these\ndesirable attributes of a ML system. The emerging field is frequently called\n``Explainable AI (XAI)'' or ``Explainable ML.'' The goal of explainable ML is\nto intuitively explain the predictions of a ML system, while adhering to the\nneeds to various stakeholders. Many explanation techniques were developed with\ncontributions from both academia and industry. However, there are several\nexisting challenges that have not garnered enough interest and serve as\nroadblocks to widespread adoption of explainable ML. In this short paper, we\nenumerate challenges in explainable ML from an industry perspective. We hope\nthese challenges will serve as promising future research directions, and would\ncontribute to democratizing explainable ML.",
          "link": "http://arxiv.org/abs/2106.07758",
          "publishedOn": "2021-06-16T01:21:08.116Z",
          "wordCount": 579,
          "title": "Pitfalls of Explainable ML: An Industry Perspective. (arXiv:2106.07758v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07677",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Herlihy_C/0/1/0/all/0/1\">Christine Herlihy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prins_A/0/1/0/all/0/1\">Aviva Prins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivasan_A/0/1/0/all/0/1\">Aravind Srinivasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dickerson_J/0/1/0/all/0/1\">John Dickerson</a>",
          "description": "Restless and collapsing bandits are commonly used to model constrained\nresource allocation in settings featuring arms with action-dependent transition\nprobabilities, such as allocating health interventions among patients [Whittle,\n1988; Mate et al., 2020]. However, state-of-the-art Whittle-index-based\napproaches to this planning problem either do not consider fairness among arms,\nor incentivize fairness without guaranteeing it [Mate et al., 2021].\nAdditionally, their optimality guarantees only apply when arms are indexable\nand threshold-optimal. We demonstrate that the incorporation of hard fairness\nconstraints necessitates the coupling of arms, which undermines the\ntractability, and by extension, indexability of the problem. We then introduce\nProbFair, a probabilistically fair stationary policy that maximizes total\nexpected reward and satisfies the budget constraint, while ensuring a strictly\npositive lower bound on the probability of being pulled at each timestep. We\nevaluate our algorithm on a real-world application, where interventions support\ncontinuous positive airway pressure (CPAP) therapy adherence among obstructive\nsleep apnea (OSA) patients, as well as simulations on a broader class of\nsynthetic transition matrices.",
          "link": "http://arxiv.org/abs/2106.07677",
          "publishedOn": "2021-06-16T01:21:08.108Z",
          "wordCount": 610,
          "title": "Planning to Fairly Allocate: Probabilistic Fairness in the Restless Bandit Setting. (arXiv:2106.07677v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2002.03206",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1\">Ziheng Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chiyuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Talwar_K/0/1/0/all/0/1\">Kunal Talwar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mozer_M/0/1/0/all/0/1\">Michael C. Mozer</a>",
          "description": "Humans are accustomed to environments that contain both regularities and\nexceptions. For example, at most gas stations, one pays prior to pumping, but\nthe occasional rural station does not accept payment in advance. Likewise, deep\nneural networks can generalize across instances that share common patterns or\nstructures, yet have the capacity to memorize rare or irregular forms. We\nanalyze how individual instances are treated by a model via a consistency\nscore. The score characterizes the expected accuracy for a held-out instance\ngiven training sets of varying size sampled from the data distribution. We\nobtain empirical estimates of this score for individual instances in multiple\ndata sets, and we show that the score identifies out-of-distribution and\nmislabeled examples at one end of the continuum and strongly regular examples\nat the other end. We identify computationally inexpensive proxies to the\nconsistency score using statistics collected during training. We show examples\nof potential applications to the analysis of deep-learning systems.",
          "link": "http://arxiv.org/abs/2002.03206",
          "publishedOn": "2021-06-16T01:21:08.101Z",
          "wordCount": 635,
          "title": "Characterizing Structural Regularities of Labeled Data in Overparameterized Models. (arXiv:2002.03206v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.07761",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kramer_N/0/1/0/all/0/1\">Nicholas Kr&#xe4;mer</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hennig_P/0/1/0/all/0/1\">Philipp Hennig</a>",
          "description": "We propose a fast algorithm for the probabilistic solution of boundary value\nproblems (BVPs), which are ordinary differential equations subject to boundary\nconditions. In contrast to previous work, we introduce a Gauss--Markov prior\nand tailor it specifically to BVPs, which allows computing a posterior\ndistribution over the solution in linear time, at a quality and cost comparable\nto that of well-established, non-probabilistic methods. Our model further\ndelivers uncertainty quantification, mesh refinement, and hyperparameter\nadaptation. We demonstrate how these practical considerations positively impact\nthe efficiency of the scheme. Altogether, this results in a practically usable\nprobabilistic BVP solver that is (in contrast to non-probabilistic algorithms)\nnatively compatible with other parts of the statistical modelling tool-chain.",
          "link": "http://arxiv.org/abs/2106.07761",
          "publishedOn": "2021-06-16T01:21:08.028Z",
          "wordCount": 541,
          "title": "Linear-Time Probabilistic Solutions of Boundary Value Problems. (arXiv:2106.07761v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07803",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fazel_A/0/1/0/all/0/1\">Amin Fazel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1\">Wei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yulan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barra_Chicote_R/0/1/0/all/0/1\">Roberto Barra-Chicote</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Y/0/1/0/all/0/1\">Yixiong Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maas_R/0/1/0/all/0/1\">Roland Maas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Droppo_J/0/1/0/all/0/1\">Jasha Droppo</a>",
          "description": "End-to-end (E2E) automatic speech recognition (ASR) models have recently\ndemonstrated superior performance over the traditional hybrid ASR models.\nTraining an E2E ASR model requires a large amount of data which is not only\nexpensive but may also raise dependency on production data. At the same time,\nsynthetic speech generated by the state-of-the-art text-to-speech (TTS) engines\nhas advanced to near-human naturalness. In this work, we propose to utilize\nsynthetic speech for ASR training (SynthASR) in applications where data is\nsparse or hard to get for ASR model training. In addition, we apply continual\nlearning with a novel multi-stage training strategy to address catastrophic\nforgetting, achieved by a mix of weighted multi-style training, data\naugmentation, encoder freezing, and parameter regularization. In our\nexperiments conducted on in-house datasets for a new application of recognizing\nmedication names, training ASR RNN-T models with synthetic audio via the\nproposed multi-stage training improved the recognition performance on new\napplication by more than 65% relative, without degradation on existing general\napplications. Our observations show that SynthASR holds great promise in\ntraining the state-of-the-art large-scale E2E ASR models for new applications\nwhile reducing the costs and dependency on production data.",
          "link": "http://arxiv.org/abs/2106.07803",
          "publishedOn": "2021-06-16T01:21:08.001Z",
          "wordCount": 634,
          "title": "SynthASR: Unlocking Synthetic Data for Speech Recognition. (arXiv:2106.07803v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07756",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Verma_S/0/1/0/all/0/1\">Sahil Verma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dickerson_J/0/1/0/all/0/1\">John Dickerson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hines_K/0/1/0/all/0/1\">Keegan Hines</a>",
          "description": "Counterfactual explanations (CFEs) are an emerging technique under the\numbrella of interpretability of machine learning (ML) models. They provide\n``what if'' feedback of the form ``if an input datapoint were $x'$ instead of\n$x$, then an ML model's output would be $y'$ instead of $y$.'' Counterfactual\nexplainability for ML models has yet to see widespread adoption in industry. In\nthis short paper, we posit reasons for this slow uptake. Leveraging recent work\noutlining desirable properties of CFEs and our experience running the ML wing\nof a model monitoring startup, we identify outstanding obstacles hindering CFE\ndeployment in industry.",
          "link": "http://arxiv.org/abs/2106.07756",
          "publishedOn": "2021-06-16T01:21:07.904Z",
          "wordCount": 529,
          "title": "Counterfactual Explanations for Machine Learning: Challenges Revisited. (arXiv:2106.07756v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.07333",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brima_Y/0/1/0/all/0/1\">Yusuf Brima</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tushar_M/0/1/0/all/0/1\">Mossadek Hossain Kamal Tushar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kabir_U/0/1/0/all/0/1\">Upama Kabir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Islam_T/0/1/0/all/0/1\">Tariqul Islam</a>",
          "description": "Magnetic Resonance Imaging (MRI) is a principal diagnostic approach used in\nthe field of radiology to create images of the anatomical and physiological\nstructure of patients. MRI is the prevalent medical imaging practice to find\nabnormalities in soft tissues. Traditionally they are analyzed by a radiologist\nto detect abnormalities in soft tissues, especially the brain. The process of\ninterpreting a massive volume of patient's MRI is laborious. Hence, the use of\nMachine Learning methodologies can aid in detecting abnormalities in soft\ntissues with considerable accuracy. In this research, we have curated a novel\ndataset and developed a framework that uses Deep Transfer Learning to perform a\nmulti-classification of tumors in the brain MRI images. In this paper, we\nadopted the Deep Residual Convolutional Neural Network (ResNet50) architecture\nfor the experiments along with discriminative learning techniques to train the\nmodel. Using the novel dataset and two publicly available MRI brain datasets,\nthis proposed approach attained a classification accuracy of 86.40% on the\ncurated dataset, 93.80% on the Harvard Whole Brain Atlas dataset, and 97.05%\naccuracy on the School of Biomedical Engineering dataset. Results of our\nexperiments significantly demonstrate our proposed framework for transfer\nlearning is a potential and effective method for brain tumor\nmulti-classification tasks.",
          "link": "http://arxiv.org/abs/2106.07333",
          "publishedOn": "2021-06-16T01:21:07.891Z",
          "wordCount": 701,
          "title": "Deep Transfer Learning for Brain Magnetic Resonance Image Multi-class Classification. (arXiv:2106.07333v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.07751",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_G/0/1/0/all/0/1\">Guoming Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1\">Qianyi Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xudong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lou_J/0/1/0/all/0/1\">Jiadong Lou</a>",
          "description": "Non-intrusive load monitoring (NILM) helps disaggregate the household's main\nelectricity consumption to energy usages of individual appliances, thus greatly\ncutting down the cost in fine-grained household load monitoring. To address the\narisen privacy concern in NILM applications, federated learning (FL) could be\nleveraged for NILM model training and sharing. When applying the FL paradigm in\nreal-world NILM applications, however, we are faced with the challenges of edge\nresource restriction, edge model personalization and edge training data\nscarcity.\n\nIn this paper we present FedNILM, a practical FL paradigm for NILM\napplications at the edge client. Specifically, FedNILM is designed to deliver\nprivacy-preserving and personalized NILM services to large-scale edge clients,\nby leveraging i) secure data aggregation through federated learning, ii)\nefficient cloud model compression via filter pruning and multi-task learning,\nand iii) personalized edge model building with unsupervised transfer learning.\nOur experiments on real-world energy data show that, FedNILM is able to achieve\npersonalized energy disaggregation with the state-of-the-art accuracy, while\nensuring privacy preserving at the edge client.",
          "link": "http://arxiv.org/abs/2106.07751",
          "publishedOn": "2021-06-16T01:21:07.847Z",
          "wordCount": 605,
          "title": "FedNILM: Applying Federated Learning to NILM Applications at the Edge. (arXiv:2106.07751v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2101.09451",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lo_S/0/1/0/all/0/1\">Shao-Yuan Lo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patel_V/0/1/0/all/0/1\">Vishal M. Patel</a>",
          "description": "Adversarial examples contain carefully crafted perturbations that can fool\ndeep neural networks (DNNs) into making wrong predictions. Enhancing the\nadversarial robustness of DNNs has gained considerable interest in recent\nyears. Although image transformation-based defenses were widely considered at\nan earlier time, most of them have been defeated by adaptive attacks. In this\npaper, we propose a new image transformation defense based on error diffusion\nhalftoning, and combine it with adversarial training to defend against\nadversarial examples. Error diffusion halftoning projects an image into a 1-bit\nspace and diffuses quantization error to neighboring pixels. This process can\nremove adversarial perturbations from a given image while maintaining\nacceptable image quality in the meantime in favor of recognition. Experimental\nresults demonstrate that the proposed method is able to improve adversarial\nrobustness even under advanced adaptive attacks, while most of the other image\ntransformation-based defenses do not. We show that a proper image\ntransformation can still be an effective defense approach. Code:\nhttps://github.com/shaoyuanlo/Halftoning-Defense",
          "link": "http://arxiv.org/abs/2101.09451",
          "publishedOn": "2021-06-16T01:21:07.729Z",
          "wordCount": 639,
          "title": "Error Diffusion Halftoning Against Adversarial Examples. (arXiv:2101.09451v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.13566",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jiong Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rossi_R/0/1/0/all/0/1\">Ryan A. Rossi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rao_A/0/1/0/all/0/1\">Anup Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mai_T/0/1/0/all/0/1\">Tung Mai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lipka_N/0/1/0/all/0/1\">Nedim Lipka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_N/0/1/0/all/0/1\">Nesreen K. Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koutra_D/0/1/0/all/0/1\">Danai Koutra</a>",
          "description": "Graph Neural Networks (GNNs) have proven to be useful for many different\npractical applications. However, many existing GNN models have implicitly\nassumed homophily among the nodes connected in the graph, and therefore have\nlargely overlooked the important setting of heterophily, where most connected\nnodes are from different classes. In this work, we propose a novel framework\ncalled CPGNN that generalizes GNNs for graphs with either homophily or\nheterophily. The proposed framework incorporates an interpretable compatibility\nmatrix for modeling the heterophily or homophily level in the graph, which can\nbe learned in an end-to-end fashion, enabling it to go beyond the assumption of\nstrong homophily. Theoretically, we show that replacing the compatibility\nmatrix in our framework with the identity (which represents pure homophily)\nreduces to GCN. Our extensive experiments demonstrate the effectiveness of our\napproach in more realistic and challenging experimental settings with\nsignificantly less training data compared to previous works: CPGNN variants\nachieve state-of-the-art results in heterophily settings with or without\ncontextual node features, while maintaining comparable performance in homophily\nsettings.",
          "link": "http://arxiv.org/abs/2009.13566",
          "publishedOn": "2021-06-16T01:21:07.710Z",
          "wordCount": 682,
          "title": "Graph Neural Networks with Heterophily. (arXiv:2009.13566v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.13493",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kidger_P/0/1/0/all/0/1\">Patrick Kidger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Foster_J/0/1/0/all/0/1\">James Foster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xuechen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyons_T/0/1/0/all/0/1\">Terry Lyons</a>",
          "description": "Neural SDEs combine many of the best qualities of both RNNs and SDEs: memory\nefficient training, high-capacity function approximation, and strong priors on\nmodel space. This makes them a natural choice for modelling many types of\ntemporal dynamics. Training a Neural SDE (either as a VAE or as a GAN) requires\nbackpropagating through an SDE solve. This may be done by solving a\nbackwards-in-time SDE whose solution is the desired parameter gradients.\nHowever, this has previously suffered from severe speed and accuracy issues,\ndue to high computational cost and numerical truncation errors. Here, we\novercome these issues through several technical innovations. First, we\nintroduce the \\textit{reversible Heun method}. This is a new SDE solver that is\n\\textit{algebraically reversible}: eliminating numerical gradient errors, and\nthe first such solver of which we are aware. Moreover it requires half as many\nfunction evaluations as comparable solvers, giving up to a $1.98\\times$\nspeedup. Second, we introduce the \\textit{Brownian Interval}: a new, fast,\nmemory efficient, and exact way of sampling \\textit{and reconstructing}\nBrownian motion. With this we obtain up to a $10.6\\times$ speed improvement\nover previous techniques, which in contrast are both approximate and relatively\nslow. Third, when specifically training Neural SDEs as GANs (Kidger et al.\n2021), we demonstrate how SDE-GANs may be trained through careful weight\nclipping and choice of activation function. This reduces computational cost\n(giving up to a $1.87\\times$ speedup) and removes the numerical truncation\nerrors associated with gradient penalty. Altogether, we outperform the\nstate-of-the-art by substantial margins, with respect to training speed, and\nwith respect to classification, prediction, and MMD test metrics. We have\ncontributed implementations of all of our techniques to the torchsde library to\nhelp facilitate their adoption.",
          "link": "http://arxiv.org/abs/2105.13493",
          "publishedOn": "2021-06-16T01:21:07.703Z",
          "wordCount": 748,
          "title": "Efficient and Accurate Gradients for Neural SDEs. (arXiv:2105.13493v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.09048",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shiwei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mocanu_D/0/1/0/all/0/1\">Decebal Constantin Mocanu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pei_Y/0/1/0/all/0/1\">Yulong Pei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pechenizkiy_M/0/1/0/all/0/1\">Mykola Pechenizkiy</a>",
          "description": "Sparse neural networks have been widely applied to reduce the computational\ndemands of training and deploying over-parameterized deep neural networks. For\ninference acceleration, methods that discover a sparse network from a\npre-trained dense network (dense-to-sparse training) work effectively.\nRecently, dynamic sparse training (DST) has been proposed to train sparse\nneural networks without pre-training a dense model (sparse-to-sparse training),\nso that the training process can also be accelerated. However, previous\nsparse-to-sparse methods mainly focus on Multilayer Perceptron Networks (MLPs)\nand Convolutional Neural Networks (CNNs), failing to match the performance of\ndense-to-sparse methods in the Recurrent Neural Networks (RNNs) setting. In\nthis paper, we propose an approach to train intrinsically sparse RNNs with a\nfixed parameter count in one single run, without compromising performance.\nDuring training, we allow RNN layers to have a non-uniform redistribution\nacross cell gates for better regularization. Further, we propose SNT-ASGD, a\nnovel variant of the averaged stochastic gradient optimizer, which\nsignificantly improves the performance of all sparse training methods for RNNs.\nUsing these strategies, we achieve state-of-the-art sparse training results,\nbetter than the dense-to-sparse methods, with various types of RNNs on Penn\nTreeBank and Wikitext-2 datasets. Our codes are available at\nhttps://github.com/Shiweiliuiiiiiii/Selfish-RNN.",
          "link": "http://arxiv.org/abs/2101.09048",
          "publishedOn": "2021-06-16T01:21:07.696Z",
          "wordCount": 689,
          "title": "Selfish Sparse RNN Training. (arXiv:2101.09048v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.07101",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fujita_K/0/1/0/all/0/1\">Kazuhisa Fujita</a>",
          "description": "Spectral clustering (SC) is one of the most popular clustering methods and\noften outperforms traditional clustering methods. SC uses the eigenvectors of a\nLaplacian matrix calculated from a similarity matrix of a dataset. SC has the\nserious drawbacks that are the significant increases in the time complexity\nderived from the computation of eigenvectors and the memory space complexity to\nstore the similarity matrix. To address the issues, I develop a new approximate\nspectral clustering using the network generated by growing neural gas (GNG),\ncalled ASC with GNG in this study. ASC with GNG uses not only reference vectors\nfor vector quantization but also the topology of the network for extraction of\nthe topological relationship between data points in a dataset. ASC with GNG\nmakes the similarity matrix from both the reference vectors and the topology of\nthe network generated by GNG. Using the network generated from a dataset by\nGNG, ASC with GNG achieves to reduce the computational and space complexities\nand improve clustering quality. In this study, I demonstrate that ASC with GNG\neffectively reduces computational time. Moreover, this study shows that ASC\nwith GNG displays equal to or better clustering performance than SC.",
          "link": "http://arxiv.org/abs/2009.07101",
          "publishedOn": "2021-06-16T01:21:07.690Z",
          "wordCount": 670,
          "title": "Approximate spectral clustering using both reference vectors and topology of the network generated by growing neural gas. (arXiv:2009.07101v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.15721",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aldaghri_N/0/1/0/all/0/1\">Nasser Aldaghri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahdavifar_H/0/1/0/all/0/1\">Hessam Mahdavifar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beirami_A/0/1/0/all/0/1\">Ahmad Beirami</a>",
          "description": "There are applications that may require removing the trace of a sample from\nthe system, e.g., a user requests their data to be deleted, or corrupted data\nis discovered. Simply removing a sample from storage units does not necessarily\nremove its entire trace since downstream machine learning models may store some\ninformation about the samples used to train them. A sample can be perfectly\nunlearned if we retrain all models that used it from scratch with that sample\nremoved from their training dataset. When multiple such unlearning requests are\nexpected to be served, unlearning by retraining becomes prohibitively\nexpensive. Ensemble learning enables the training data to be split into smaller\ndisjoint shards that are assigned to non-communicating weak learners. Each\nshard is used to produce a weak model. These models are then aggregated to\nproduce the final central model. This setup introduces an inherent trade-off\nbetween performance and unlearning cost, as reducing the shard size reduces the\nunlearning cost but may cause degradation in performance. In this paper, we\npropose a coded learning protocol where we utilize linear encoders to encode\nthe training data into shards prior to the learning phase. We also present the\ncorresponding unlearning protocol and show that it satisfies the perfect\nunlearning criterion. Our experimental results show that the proposed coded\nmachine unlearning provides a better performance versus unlearning cost\ntrade-off compared to the uncoded baseline.",
          "link": "http://arxiv.org/abs/2012.15721",
          "publishedOn": "2021-06-16T01:21:07.683Z",
          "wordCount": 677,
          "title": "Coded Machine Unlearning. (arXiv:2012.15721v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08171",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cui_G/0/1/0/all/0/1\">Ganqu Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1\">Yufeng Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Cheng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1\">Liang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lifeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>",
          "description": "The recent emergence of contrastive learning approaches facilitates the\nresearch on graph representation learning (GRL), introducing graph contrastive\nlearning (GCL) into the literature. These methods contrast semantically similar\nand dissimilar sample pairs to encode the semantics into node or graph\nembeddings. However, most existing works only performed model-level evaluation,\nand did not explore the combination space of modules for more comprehensive and\nsystematic studies. For effective module-level evaluation, we propose a\nframework that decomposes GCL models into four modules: (1) a sampler to\ngenerate anchor, positive and negative data samples (nodes or graphs); (2) an\nencoder and a readout function to get sample embeddings; (3) a discriminator to\nscore each sample pair (anchor-positive and anchor-negative); and (4) an\nestimator to define the loss function. Based on this framework, we conduct\ncontrolled experiments over a wide range of architectural designs and\nhyperparameter settings on node and graph classification tasks. Specifically,\nwe manage to quantify the impact of a single module, investigate the\ninteraction between modules, and compare the overall performance with current\nmodel architectures. Our key findings include a set of module-level guidelines\nfor GCL, e.g., simple samplers from LINE and DeepWalk are strong and robust; an\nMLP encoder associated with Sum readout could achieve competitive performance\non graph classification. Finally, we release our implementations and results as\nOpenGCL, a modularized toolkit that allows convenient reproduction, standard\nmodel and module evaluation, and easy extension.",
          "link": "http://arxiv.org/abs/2106.08171",
          "publishedOn": "2021-06-16T01:21:07.652Z",
          "wordCount": 663,
          "title": "Evaluating Modules in Graph Contrastive Learning. (arXiv:2106.08171v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.02887",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shiwei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_L/0/1/0/all/0/1\">Lu Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mocanu_D/0/1/0/all/0/1\">Decebal Constantin Mocanu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pechenizkiy_M/0/1/0/all/0/1\">Mykola Pechenizkiy</a>",
          "description": "In this paper, we introduce a new perspective on training deep neural\nnetworks capable of state-of-the-art performance without the need for the\nexpensive over-parameterization by proposing the concept of In-Time\nOver-Parameterization (ITOP) in sparse training. By starting from a random\nsparse network and continuously exploring sparse connectivities during\ntraining, we can perform an Over-Parameterization in the space-time manifold,\nclosing the gap in the expressibility between sparse training and dense\ntraining. We further use ITOP to understand the underlying mechanism of Dynamic\nSparse Training (DST) and indicate that the benefits of DST come from its\nability to consider across time all possible parameters when searching for the\noptimal sparse connectivity. As long as there are sufficient parameters that\nhave been reliably explored during training, DST can outperform the dense\nneural network by a large margin. We present a series of experiments to support\nour conjecture and achieve the state-of-the-art sparse training performance\nwith ResNet-50 on ImageNet. More impressively, our method achieves dominant\nperformance over the overparameterization-based sparse methods at extreme\nsparsity levels. When trained on CIFAR-100, our method can match the\nperformance of the dense model even at an extreme sparsity (98%). Code can be\nfound https://github.com/Shiweiliuiiiiiii/In-Time-Over-Parameterization.",
          "link": "http://arxiv.org/abs/2102.02887",
          "publishedOn": "2021-06-16T01:21:07.644Z",
          "wordCount": 713,
          "title": "Do We Actually Need Dense Over-Parameterization? In-Time Over-Parameterization in Sparse Training. (arXiv:2102.02887v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08267",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gondere_M/0/1/0/all/0/1\">Mesay Samuel Gondere</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidt_Thieme_L/0/1/0/all/0/1\">Lars Schmidt-Thieme</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_D/0/1/0/all/0/1\">Durga Prasad Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scholz_R/0/1/0/all/0/1\">Randolf Scholz</a>",
          "description": "Handwritten digit recognition is one of the extensively studied area in\nmachine learning. Apart from the wider research on handwritten digit\nrecognition on MNIST dataset, there are many other research works on various\nscript recognition. However, it is not very common for multi-script digit\nrecognition which encourage the development of robust and multipurpose systems.\nAdditionally working on multi-script digit recognition enables multi-task\nlearning, considering the script classification as a related task for instance.\nIt is evident that multi-task learning improves model performance through\ninductive transfer using the information contained in related tasks. Therefore,\nin this study multi-script handwritten digit recognition using multi-task\nlearning will be investigated. As a specific case of demonstrating the solution\nto the problem, Amharic handwritten character recognition will also be\nexperimented. The handwritten digits of three scripts including Latin, Arabic\nand Kannada are studied to show that multi-task models with reformulation of\nthe individual tasks have shown promising results. In this study a novel way of\nusing the individual tasks predictions was proposed to help classification\nperformance and regularize the different loss for the purpose of the main task.\nThis finding has outperformed the baseline and the conventional multi-task\nlearning models. More importantly, it avoided the need for weighting the\ndifferent losses of the tasks, which is one of the challenges in multi-task\nlearning.",
          "link": "http://arxiv.org/abs/2106.08267",
          "publishedOn": "2021-06-16T01:21:07.638Z",
          "wordCount": 651,
          "title": "Multi-script Handwritten Digit Recognition Using Multi-task Learning. (arXiv:2106.08267v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2101.00420",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ye_Q/0/1/0/all/0/1\">Qinyuan Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>",
          "description": "Pre-trained text-to-text transformers such as BART have achieved impressive\nperformance across a range of NLP tasks. Recent study further shows that they\ncan learn to generalize to novel tasks, by including task descriptions as part\nof the source sequence and training the model with (source, target) examples.\nAt test time, these fine-tuned models can make inferences on new tasks using\nthe new task descriptions as part of the input. However, this approach has\npotential limitations, as the model learns to solve individual (source, target)\nexamples (i.e., at the instance level), instead of learning to solve tasks by\ntaking all examples within a task as a whole (i.e., at the task level). To this\nend, we introduce Hypter, a framework that improves text-to-text transformer's\ngeneralization ability to unseen tasks by training a hypernetwork to generate\ntask-specific, light-weight adapters from task descriptions. Experiments on\nZEST dataset and a synthetic SQuAD dataset demonstrate that Hypter improves\nupon fine-tuning baselines. Notably, when using BART-Large as the main network,\nHypter brings 11.3% comparative improvement on ZEST dataset.",
          "link": "http://arxiv.org/abs/2101.00420",
          "publishedOn": "2021-06-16T01:21:07.630Z",
          "wordCount": 636,
          "title": "Learning to Generate Task-Specific Adapters from Task Description. (arXiv:2101.00420v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.01620",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Caucheteux_C/0/1/0/all/0/1\">Charlotte Caucheteux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gramfort_A/0/1/0/all/0/1\">Alexandre Gramfort</a>, <a href=\"http://arxiv.org/find/cs/1/au:+King_J/0/1/0/all/0/1\">Jean-Remi King</a>",
          "description": "The activations of language transformers like GPT-2 have been shown to\nlinearly map onto brain activity during speech comprehension. However, the\nnature of these activations remains largely unknown and presumably conflate\ndistinct linguistic classes. Here, we propose a taxonomy to factorize the\nhigh-dimensional activations of language models into four combinatorial\nclasses: lexical, compositional, syntactic, and semantic representations. We\nthen introduce a statistical method to decompose, through the lens of GPT-2's\nactivations, the brain activity of 345 subjects recorded with functional\nmagnetic resonance imaging (fMRI) during the listening of ~4.6 hours of\nnarrated text. The results highlight two findings. First, compositional\nrepresentations recruit a more widespread cortical network than lexical ones,\nand encompass the bilateral temporal, parietal and prefrontal cortices. Second,\ncontrary to previous claims, syntax and semantics are not associated with\nseparated modules, but, instead, appear to share a common and distributed\nneural substrate. Overall, this study introduces a versatile framework to\nisolate, in the brain activity, the distributed representations of linguistic\nconstructs.",
          "link": "http://arxiv.org/abs/2103.01620",
          "publishedOn": "2021-06-16T01:21:07.603Z",
          "wordCount": 631,
          "title": "Disentangling Syntax and Semantics in the Brain with Deep Networks. (arXiv:2103.01620v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08053",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_R/0/1/0/all/0/1\">Rui Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1\">Gao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_S/0/1/0/all/0/1\">Simon S. Du</a>",
          "description": "While multitask representation learning has become a popular approach in\nreinforcement learning (RL), theoretical understanding of why and when it works\nremains limited. This paper presents analyses for the statistical benefit of\nmultitask representation learning in linear Markov Decision Process (MDP) under\na generative model. In this paper, we consider an agent to learn a\nrepresentation function $\\phi$ out of a function class $\\Phi$ from $T$ source\ntasks with $N$ data per task, and then use the learned $\\hat{\\phi}$ to reduce\nthe required number of sample for a new task. We first discover a\n\\emph{Least-Activated-Feature-Abundance} (LAFA) criterion, denoted as $\\kappa$,\nwith which we prove that a straightforward least-square algorithm learns a\npolicy which is $\\tilde{O}(H^2\\sqrt{\\frac{\\mathcal{C}(\\Phi)^2 \\kappa\nd}{NT}+\\frac{\\kappa d}{n}})$ sub-optimal. Here $H$ is the planning horizon,\n$\\mathcal{C}(\\Phi)$ is $\\Phi$'s complexity measure, $d$ is the dimension of the\nrepresentation (usually $d\\ll \\mathcal{C}(\\Phi)$) and $n$ is the number of\nsamples for the new task. Thus the required $n$ is $O(\\kappa d H^4)$ for the\nsub-optimality to be close to zero, which is much smaller than\n$O(\\mathcal{C}(\\Phi)^2\\kappa d H^4)$ in the setting without multitask\nrepresentation learning, whose sub-optimality gap is\n$\\tilde{O}(H^2\\sqrt{\\frac{\\kappa \\mathcal{C}(\\Phi)^2d}{n}})$. This\ntheoretically explains the power of multitask representation learning in\nreducing sample complexity. Further, we note that to ensure high sample\nefficiency, the LAFA criterion $\\kappa$ should be small. In fact, $\\kappa$\nvaries widely in magnitude depending on the different sampling distribution for\nnew task. This indicates adaptive sampling technique is important to make\n$\\kappa$ solely depend on $d$. Finally, we provide empirical results of a noisy\ngrid-world environment to corroborate our theoretical findings.",
          "link": "http://arxiv.org/abs/2106.08053",
          "publishedOn": "2021-06-16T01:21:07.596Z",
          "wordCount": 693,
          "title": "On the Power of Multitask Representation Learning in Linear MDP. (arXiv:2106.08053v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2012.07805",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Carlini_N/0/1/0/all/0/1\">Nicholas Carlini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tramer_F/0/1/0/all/0/1\">Florian Tramer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wallace_E/0/1/0/all/0/1\">Eric Wallace</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jagielski_M/0/1/0/all/0/1\">Matthew Jagielski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Herbert_Voss_A/0/1/0/all/0/1\">Ariel Herbert-Voss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Katherine Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roberts_A/0/1/0/all/0/1\">Adam Roberts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brown_T/0/1/0/all/0/1\">Tom Brown</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1\">Dawn Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erlingsson_U/0/1/0/all/0/1\">Ulfar Erlingsson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oprea_A/0/1/0/all/0/1\">Alina Oprea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raffel_C/0/1/0/all/0/1\">Colin Raffel</a>",
          "description": "It has become common to publish large (billion parameter) language models\nthat have been trained on private datasets. This paper demonstrates that in\nsuch settings, an adversary can perform a training data extraction attack to\nrecover individual training examples by querying the language model.\n\nWe demonstrate our attack on GPT-2, a language model trained on scrapes of\nthe public Internet, and are able to extract hundreds of verbatim text\nsequences from the model's training data. These extracted examples include\n(public) personally identifiable information (names, phone numbers, and email\naddresses), IRC conversations, code, and 128-bit UUIDs. Our attack is possible\neven though each of the above sequences are included in just one document in\nthe training data.\n\nWe comprehensively evaluate our extraction attack to understand the factors\nthat contribute to its success. Worryingly, we find that larger models are more\nvulnerable than smaller models. We conclude by drawing lessons and discussing\npossible safeguards for training large language models.",
          "link": "http://arxiv.org/abs/2012.07805",
          "publishedOn": "2021-06-16T01:21:07.588Z",
          "wordCount": 643,
          "title": "Extracting Training Data from Large Language Models. (arXiv:2012.07805v2 [cs.CR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.07682",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bansal_Y/0/1/0/all/0/1\">Yamini Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakkiran_P/0/1/0/all/0/1\">Preetum Nakkiran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barak_B/0/1/0/all/0/1\">Boaz Barak</a>",
          "description": "We revisit and extend model stitching (Lenc & Vedaldi 2015) as a methodology\nto study the internal representations of neural networks. Given two trained and\nfrozen models $A$ and $B$, we consider a \"stitched model'' formed by connecting\nthe bottom-layers of $A$ to the top-layers of $B$, with a simple trainable\nlayer between them. We argue that model stitching is a powerful and perhaps\nunder-appreciated tool, which reveals aspects of representations that measures\nsuch as centered kernel alignment (CKA) cannot. Through extensive experiments,\nwe use model stitching to obtain quantitative verifications for intuitive\nstatements such as \"good networks learn similar representations'', by\ndemonstrating that good networks of the same architecture, but trained in very\ndifferent ways (e.g.: supervised vs. self-supervised learning), can be stitched\nto each other without drop in performance. We also give evidence for the\nintuition that \"more is better'' by showing that representations learnt with\n(1) more data, (2) bigger width, or (3) more training time can be \"plugged in''\nto weaker models to improve performance. Finally, our experiments reveal a new\nstructural property of SGD which we call \"stitching connectivity'', akin to\nmode-connectivity: typical minima reached by SGD can all be stitched to each\nother with minimal change in accuracy.",
          "link": "http://arxiv.org/abs/2106.07682",
          "publishedOn": "2021-06-16T01:21:07.579Z",
          "wordCount": 629,
          "title": "Revisiting Model Stitching to Compare Neural Representations. (arXiv:2106.07682v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.07024",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1\">Khanh Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Misra_D/0/1/0/all/0/1\">Dipendra Misra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schapire_R/0/1/0/all/0/1\">Robert Schapire</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dudik_M/0/1/0/all/0/1\">Miro Dud&#xed;k</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shafto_P/0/1/0/all/0/1\">Patrick Shafto</a>",
          "description": "We present a novel interactive learning protocol that enables training\nrequest-fulfilling agents by verbally describing their activities. Unlike\nimitation learning (IL), our protocol allows the teaching agent to provide\nfeedback in a language that is most appropriate for them. Compared with reward\nin reinforcement learning (RL), the description feedback is richer and allows\nfor improved sample complexity. We develop a probabilistic framework and an\nalgorithm that practically implements our protocol. Empirical results in two\nchallenging request-fulfilling problems demonstrate the strengths of our\napproach: compared with RL baselines, it is more sample-efficient; compared\nwith IL baselines, it achieves competitive success rates without requiring the\nteaching agent to be able to demonstrate the desired behavior using the\nlearning agent's actions. Apart from empirical evaluation, we also provide\ntheoretical guarantees for our algorithm under certain assumptions about the\nteacher and the environment.",
          "link": "http://arxiv.org/abs/2102.07024",
          "publishedOn": "2021-06-16T01:21:07.559Z",
          "wordCount": 606,
          "title": "Interactive Learning from Activity Description. (arXiv:2102.07024v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.07683",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Eslami_M/0/1/0/all/0/1\">Mohammed Eslami</a>, <a href=\"http://arxiv.org/find/math/1/au:+Eramian_H/0/1/0/all/0/1\">Hamed Eramian</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gameiro_M/0/1/0/all/0/1\">Marcio Gameiro</a>, <a href=\"http://arxiv.org/find/math/1/au:+Kalies_W/0/1/0/all/0/1\">William Kalies</a>, <a href=\"http://arxiv.org/find/math/1/au:+Mischaikow_K/0/1/0/all/0/1\">Konstantin Mischaikow</a>",
          "description": "Deep learning models evolve through training to learn the manifold in which\nthe data exists to satisfy an objective. It is well known that evolution leads\nto different final states which produce inconsistent predictions of the same\ntest data points. This calls for techniques to be able to empirically quantify\nthe difference in the trajectories and highlight problematic regions. While\nmuch focus is placed on discovering what models learn, the question of how a\nmodel learns is less studied beyond theoretical landscape characterizations and\nlocal geometric approximations near optimal conditions. Here, we present a\ntoolkit for the Dynamical Organization Of Deep Learning Loss Landscapes, or\nDOODL3. DOODL3 formulates the training of neural networks as a dynamical\nsystem, analyzes the learning process, and presents an interpretable global\nview of trajectories in the loss landscape. Our approach uses the coarseness of\ntopology to capture the granularity of geometry to mitigate against states of\ninstability or elongated training. Overall, our analysis presents an empirical\nframework to extract the global dynamics of a model and to use that information\nto guide the training of neural networks.",
          "link": "http://arxiv.org/abs/2106.07683",
          "publishedOn": "2021-06-16T01:21:07.551Z",
          "wordCount": 621,
          "title": "Extracting Global Dynamics of Loss Landscape in Deep Learning Models. (arXiv:2106.07683v1 [math.DS])"
        },
        {
          "id": "http://arxiv.org/abs/2007.05426",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Caterini_A/0/1/0/all/0/1\">Anthony Caterini</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cornish_R/0/1/0/all/0/1\">Rob Cornish</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sejdinovic_D/0/1/0/all/0/1\">Dino Sejdinovic</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Doucet_A/0/1/0/all/0/1\">Arnaud Doucet</a>",
          "description": "Continuously-indexed flows (CIFs) have recently achieved improvements over\nbaseline normalizing flows on a variety of density estimation tasks. CIFs do\nnot possess a closed-form marginal density, and so, unlike standard flows,\ncannot be plugged in directly to a variational inference (VI) scheme in order\nto produce a more expressive family of approximate posteriors. However, we show\nhere how CIFs can be used as part of an auxiliary VI scheme to formulate and\ntrain expressive posterior approximations in a natural way. We exploit the\nconditional independence structure of multi-layer CIFs to build the required\nauxiliary inference models, which we show empirically yield low-variance\nestimators of the model evidence. We then demonstrate the advantages of CIFs\nover baseline flows in VI problems when the posterior distribution of interest\npossesses a complicated topology, obtaining improved results in both the\nBayesian inference and surrogate maximum likelihood settings.",
          "link": "http://arxiv.org/abs/2007.05426",
          "publishedOn": "2021-06-16T01:21:07.543Z",
          "wordCount": 591,
          "title": "Variational Inference with Continuously-Indexed Normalizing Flows. (arXiv:2007.05426v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.03837",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Laskin_M/0/1/0/all/0/1\">Michael Laskin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Metz_L/0/1/0/all/0/1\">Luke Metz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nabarro_S/0/1/0/all/0/1\">Seth Nabarro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saroufim_M/0/1/0/all/0/1\">Mark Saroufim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noune_B/0/1/0/all/0/1\">Badreddine Noune</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luschi_C/0/1/0/all/0/1\">Carlo Luschi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sohl_Dickstein_J/0/1/0/all/0/1\">Jascha Sohl-Dickstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1\">Pieter Abbeel</a>",
          "description": "Deep learning models trained on large data sets have been widely successful\nin both vision and language domains. As state-of-the-art deep learning\narchitectures have continued to grow in parameter count so have the compute\nbudgets and times required to train them, increasing the need for\ncompute-efficient methods that parallelize training. Two common approaches to\nparallelize the training of deep networks have been data and model parallelism.\nWhile useful, data and model parallelism suffer from diminishing returns in\nterms of compute efficiency for large batch sizes. In this paper, we\ninvestigate how to continue scaling compute efficiently beyond the point of\ndiminishing returns for large batches through local parallelism, a framework\nwhich parallelizes training of individual layers in deep networks by replacing\nglobal backpropagation with truncated layer-wise backpropagation. Local\nparallelism enables fully asynchronous layer-wise parallelism with a low memory\nfootprint, and requires little communication overhead compared with model\nparallelism. We show results in both vision and language domains across a\ndiverse set of architectures, and find that local parallelism is particularly\neffective in the high-compute regime.",
          "link": "http://arxiv.org/abs/2012.03837",
          "publishedOn": "2021-06-16T01:21:07.536Z",
          "wordCount": 666,
          "title": "Parallel Training of Deep Networks with Local Updates. (arXiv:2012.03837v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.08372",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Karkar_S/0/1/0/all/0/1\">Skander Karkar</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ayed_I/0/1/0/all/0/1\">Ibrahim Ayed</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bezenac_E/0/1/0/all/0/1\">Emmanuel de B&#xe9;zenac</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gallinari_P/0/1/0/all/0/1\">Patrick Gallinari</a>",
          "description": "Neural networks have been achieving high generalization performance on many\ntasks despite being highly over-parameterized. Since classical statistical\nlearning theory struggles to explain this behavior, much effort has recently\nbeen focused on uncovering the mechanisms behind it, in the hope of developing\na more adequate theoretical framework and having a better control over the\ntrained models. In this work, we adopt an alternate perspective, viewing the\nneural network as a dynamical system displacing input particles over time. We\nconduct a series of experiments and, by analyzing the network's behavior\nthrough its displacements, we show the presence of a low kinetic energy\ndisplacement bias in the transport map of the network, and link this bias with\ngeneralization performance. From this observation, we reformulate the learning\nproblem as follows: finding neural networks which solve the task while\ntransporting the data as efficiently as possible. This offers a novel\nformulation of the learning problem which allows us to provide regularity\nresults for the solution network, based on Optimal Transport theory. From a\npractical viewpoint, this allows us to propose a new learning algorithm, which\nautomatically adapts to the complexity of the given task, and leads to networks\nwith a high generalization ability even in low data regimes.",
          "link": "http://arxiv.org/abs/2009.08372",
          "publishedOn": "2021-06-16T01:21:07.521Z",
          "wordCount": 679,
          "title": "A Principle of Least Action for the Training of Neural Networks. (arXiv:2009.08372v4 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.07689",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lipman_Y/0/1/0/all/0/1\">Yaron Lipman</a>",
          "description": "Representing surfaces as zero level sets of neural networks recently emerged\nas a powerful modeling paradigm, named Implicit Neural Representations (INRs),\nserving numerous downstream applications in geometric deep learning and 3D\nvision. Training INRs previously required choosing between occupancy and\ndistance function representation and different losses with unknown limit\nbehavior and/or bias. In this paper we draw inspiration from the theory of\nphase transitions of fluids and suggest a loss for training INRs that learns a\ndensity function that converges to a proper occupancy function, while its log\ntransform converges to a distance function. Furthermore, we analyze the limit\nminimizer of this loss showing it satisfies the reconstruction constraints and\nhas minimal surface perimeter, a desirable inductive bias for surface\nreconstruction. Training INRs with this new loss leads to state-of-the-art\nreconstructions on a standard benchmark.",
          "link": "http://arxiv.org/abs/2106.07689",
          "publishedOn": "2021-06-16T01:21:07.502Z",
          "wordCount": 557,
          "title": "Phase Transitions, Distance Functions, and Implicit Neural Representations. (arXiv:2106.07689v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2008.07428",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Xin_R/0/1/0/all/0/1\">Ran Xin</a>, <a href=\"http://arxiv.org/find/math/1/au:+Khan_U/0/1/0/all/0/1\">Usman A. Khan</a>, <a href=\"http://arxiv.org/find/math/1/au:+Kar_S/0/1/0/all/0/1\">Soummya Kar</a>",
          "description": "This paper considers decentralized minimization of $N:=nm$ smooth non-convex\ncost functions equally divided over a directed network of $n$ nodes.\nSpecifically, we describe a stochastic first-order gradient method, called\nGT-SARAH, that employs a SARAH-type variance reduction technique and gradient\ntracking (GT) to address the stochastic and decentralized nature of the\nproblem. We show that GT-SARAH, with appropriate algorithmic parameters, finds\nan $\\epsilon$-accurate first-order stationary point with\n$O\\big(\\max\\big\\{N^{\\frac{1}{2}},n(1-\\lambda)^{-2},n^{\\frac{2}{3}}m^{\\frac{1}{3}}(1-\\lambda)^{-1}\\big\\}L\\epsilon^{-2}\\big)$\ngradient complexity, where ${(1-\\lambda)\\in(0,1]}$ is the spectral gap of the\nnetwork weight matrix and $L$ is the smoothness parameter of the cost\nfunctions. This gradient complexity outperforms that of the existing\ndecentralized stochastic gradient methods. In particular, in a big-data regime\nsuch that ${n = O(N^{\\frac{1}{2}}(1-\\lambda)^{3})}$, this gradient complexity\nfurthers reduces to ${O(N^{\\frac{1}{2}}L\\epsilon^{-2})}$, independent of the\nnetwork topology, and matches that of the centralized near-optimal\nvariance-reduced methods. Moreover, in this regime GT-SARAH achieves a\nnon-asymptotic linear speedup, in that, the total number of gradient\ncomputations at each node is reduced by a factor of $1/n$ compared to the\ncentralized near-optimal algorithms that perform all gradient computations at a\nsingle node. To the best of our knowledge, GT-SARAH is the first algorithm that\nachieves this property. In addition, we show that appropriate choices of local\nminibatch size balance the trade-offs between the gradient and communication\ncomplexity of GT-SARAH. Over infinite time horizon, we establish that all nodes\nin GT-SARAH asymptotically achieve consensus and converge to a first-order\nstationary point in the almost sure and mean-squared sense.",
          "link": "http://arxiv.org/abs/2008.07428",
          "publishedOn": "2021-06-16T01:21:07.488Z",
          "wordCount": 733,
          "title": "Fast decentralized non-convex finite-sum optimization with recursive variance reduction. (arXiv:2008.07428v5 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.07770",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Butte_S/0/1/0/all/0/1\">Sujata Butte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vakanski_A/0/1/0/all/0/1\">Aleksandar Vakanski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duellman_K/0/1/0/all/0/1\">Kasia Duellman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haotian Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mirkouei_A/0/1/0/all/0/1\">Amin Mirkouei</a>",
          "description": "Recent research on the application of remote sensing and deep learning-based\nanalysis in precision agriculture demonstrated a potential for improved crop\nmanagement and reduced environmental impacts of agricultural production.\nDespite the promising results, the practical relevance of these technologies\nfor actual field deployment requires novel algorithms that are customized for\nanalysis of agricultural images and robust to implementation on natural field\nimagery. The paper presents an approach for analyzing aerial images of a potato\ncrop using deep neural networks. The main objective is to demonstrate automated\nspatial recognition of a healthy versus stressed crop at a plant level.\nSpecifically, we examine premature plant senescence resulting in drought stress\non Russet Burbank potato plants. The proposed deep learning model, named\nRetina-UNet-Ag, is a variant of Retina-UNet (Jaeger et al., 2018) and includes\nconnections from low-level semantic dense representation maps to the feature\npyramid network. The paper also introduces a dataset of field images acquired\nwith a Parrot Sequoia camera carried by a Solo unmanned aerial vehicle.\nExperimental validation demonstrated the ability for distinguishing healthy and\nstressed plants in field images, achieving an average Dice score coefficient of\n0.74. A comparison to related state-of-the-art deep learning models for object\ndetection revealed that the presented approach is effective for the task at\nhand. The method applied here is conducive toward the assessment and\nrecognition of potato crop stress (early plant senescence resulting from\ndrought stress in this case) in natural aerial field images collected under\nreal conditions.",
          "link": "http://arxiv.org/abs/2106.07770",
          "publishedOn": "2021-06-16T01:21:07.474Z",
          "wordCount": 692,
          "title": "Potato Crop Stress Identification in Aerial Images using Deep Learning-based Object Detection. (arXiv:2106.07770v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2011.13511",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Niaki_S/0/1/0/all/0/1\">Sina Amini Niaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haghighat_E/0/1/0/all/0/1\">Ehsan Haghighat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Campbell_T/0/1/0/all/0/1\">Trevor Campbell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poursartip_A/0/1/0/all/0/1\">Anoush Poursartip</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vaziri_R/0/1/0/all/0/1\">Reza Vaziri</a>",
          "description": "We present a Physics-Informed Neural Network (PINN) to simulate the\nthermochemical evolution of a composite material on a tool undergoing cure in\nan autoclave. In particular, we solve the governing coupled system of\ndifferential equations -- including conductive heat transfer and resin cure\nkinetics -- by optimizing the parameters of a deep neural network (DNN) using a\nphysics-based loss function. To account for the vastly different behaviour of\nthermal conduction and resin cure, we design a PINN consisting of two\ndisconnected subnetworks, and develop a sequential training algorithm that\nmitigates instability present in traditional training methods. Further, we\nincorporate explicit discontinuities into the DNN at the composite-tool\ninterface and enforce known physical behaviour directly in the loss function to\nimprove the solution near the interface. We train the PINN with a technique\nthat automatically adapts the weights on the loss terms corresponding to PDE,\nboundary, interface, and initial conditions. Finally, we demonstrate that one\ncan include problem parameters as an input to the model -- resulting in a\nsurrogate that provides real-time simulation for a range of problem settings --\nand that one can use transfer learning to significantly reduce the training\ntime for problem settings similar to that of an initial trained model. The\nperformance of the proposed PINN is demonstrated in multiple scenarios with\ndifferent material thicknesses and thermal boundary conditions.",
          "link": "http://arxiv.org/abs/2011.13511",
          "publishedOn": "2021-06-16T01:21:07.467Z",
          "wordCount": 707,
          "title": "Physics-Informed Neural Network for Modelling the Thermochemical Curing Process of Composite-Tool Systems During Manufacture. (arXiv:2011.13511v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.07732",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Changan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1\">Wei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harwath_D/0/1/0/all/0/1\">David Harwath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grauman_K/0/1/0/all/0/1\">Kristen Grauman</a>",
          "description": "Reverberation from audio reflecting off surfaces and objects in the\nenvironment not only degrades the quality of speech for human perception, but\nalso severely impacts the accuracy of automatic speech recognition. Prior work\nattempts to remove reverberation based on the audio modality only. Our idea is\nto learn to dereverberate speech from audio-visual observations. The visual\nenvironment surrounding a human speaker reveals important cues about the room\ngeometry, materials, and speaker location, all of which influence the precise\nreverberation effects in the audio stream. We introduce Visually-Informed\nDereverberation of Audio (VIDA), an end-to-end approach that learns to remove\nreverberation based on both the observed sounds and visual scene. In support of\nthis new task, we develop a large-scale dataset that uses realistic acoustic\nrenderings of speech in real-world 3D scans of homes offering a variety of room\nacoustics. Demonstrating our approach on both simulated and real imagery for\nspeech enhancement, speech recognition, and speaker identification, we show it\nachieves state-of-the-art performance and substantially improves over\ntraditional audio-only methods. Project page:\nthis http URL",
          "link": "http://arxiv.org/abs/2106.07732",
          "publishedOn": "2021-06-16T01:21:07.443Z",
          "wordCount": 602,
          "title": "Learning Audio-Visual Dereverberation. (arXiv:2106.07732v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2012.07919",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Giray_G/0/1/0/all/0/1\">G&#xf6;rkem Giray</a>",
          "description": "Context: Advancements in machine learning (ML) lead to a shift from the\ntraditional view of software development, where algorithms are hard-coded by\nhumans, to ML systems materialized through learning from data. Therefore, we\nneed to revisit our ways of developing software systems and consider the\nparticularities required by these new types of systems. Objective: The purpose\nof this study is to systematically identify, analyze, summarize, and synthesize\nthe current state of software engineering (SE) research for engineering ML\nsystems. Method: I performed a systematic literature review (SLR). I\nsystematically selected a pool of 141 studies from SE venues and then conducted\na quantitative and qualitative analysis using the data extracted from these\nstudies. Results: The non-deterministic nature of ML systems complicates all SE\naspects of engineering ML systems. Despite increasing interest from 2018\nonwards, the results reveal that none of the SE aspects have a mature set of\ntools and techniques. Testing is by far the most popular area among\nresearchers. Even for testing ML systems, engineers have only some tool\nprototypes and solution proposals with weak experimental proof. Many of the\nchallenges of ML systems engineering were identified through surveys and\ninterviews. Researchers should conduct experiments and case studies, ideally in\nindustrial environments, to further understand these challenges and propose\nsolutions. Conclusion: The results may benefit (1) practitioners in foreseeing\nthe challenges of ML systems engineering; (2) researchers and academicians in\nidentifying potential research questions; and (3) educators in designing or\nupdating SE courses to cover ML systems engineering.",
          "link": "http://arxiv.org/abs/2012.07919",
          "publishedOn": "2021-06-16T01:21:07.427Z",
          "wordCount": 735,
          "title": "A Software Engineering Perspective on Engineering Machine Learning Systems: State of the Art and Challenges. (arXiv:2012.07919v3 [cs.SE] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03954",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pereira_G/0/1/0/all/0/1\">Geand Trindade Pereira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santos_M/0/1/0/all/0/1\">Moises Rocha dos Santos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carvalho_A/0/1/0/all/0/1\">Andre Carlos Ponce de Leon Ferreira de Carvalho</a>",
          "description": "With the popularity of Machine Learning (ML) solutions, algorithms and data\nhave been released faster than the capacity of processing them. In this\ncontext, the problem of Algorithm Recommendation (AR) is receiving a\nsignificant deal of attention recently. This problem has been addressed in the\nliterature as a learning task, often as a Meta-Learning problem where the aim\nis to recommend the best alternative for a specific dataset. For such, datasets\nencoded by meta-features are explored by ML algorithms that try to learn the\nmapping between meta-representations and the best technique to be used. One of\nthe challenges for the successful use of ML is to define which features are the\nmost valuable for a specific dataset since several meta-features can be used,\nwhich increases the meta-feature dimension. This paper presents an empirical\nanalysis of Feature Selection and Feature Extraction in the meta-level for the\nAR problem. The present study was focused on three criteria: predictive\nperformance, dimensionality reduction, and pipeline runtime. As we verified,\napplying Dimensionality Reduction (DR) methods did not improve predictive\nperformances in general. However, DR solutions reduced about 80% of the\nmeta-features, obtaining pretty much the same performance as the original setup\nbut with lower runtimes. The only exception was PCA, which presented about the\nsame runtime as the original meta-features. Experimental results also showed\nthat various datasets have many non-informative meta-features and that it is\npossible to obtain high predictive performance using around 20% of the original\nmeta-features. Therefore, due to their natural trend for high dimensionality,\nDR methods should be used for Meta-Feature Selection and Meta-Feature\nExtraction.",
          "link": "http://arxiv.org/abs/2106.03954",
          "publishedOn": "2021-06-15T22:41:25.615Z",
          "wordCount": 718,
          "title": "Evaluating Meta-Feature Selection for the Algorithm Recommendation Problem. (arXiv:2106.03954v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14710",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Patil_A/0/1/0/all/0/1\">Ameya D. Patil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuttle_M/0/1/0/all/0/1\">Michael Tuttle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schwing_A/0/1/0/all/0/1\">Alexander G. Schwing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shanbhag_N/0/1/0/all/0/1\">Naresh R. Shanbhag</a>",
          "description": "Classical adversarial training (AT) frameworks are designed to achieve high\nadversarial accuracy against a single attack type, typically $\\ell_\\infty$\nnorm-bounded perturbations. Recent extensions in AT have focused on defending\nagainst the union of multiple perturbations but this benefit is obtained at the\nexpense of a significant (up to $10\\times$) increase in training complexity\nover single-attack $\\ell_\\infty$ AT. In this work, we expand the capabilities\nof widely popular single-attack $\\ell_\\infty$ AT frameworks to provide\nrobustness to the union of ($\\ell_\\infty, \\ell_2, \\ell_1$) perturbations while\npreserving their training efficiency. Our technique, referred to as Shaped\nNoise Augmented Processing (SNAP), exploits a well-established byproduct of\nsingle-attack AT frameworks -- the reduction in the curvature of the decision\nboundary of networks. SNAP prepends a given deep net with a shaped noise\naugmentation layer whose distribution is learned along with network parameters\nusing any standard single-attack AT. As a result, SNAP enhances adversarial\naccuracy of ResNet-18 on CIFAR-10 against the union of ($\\ell_\\infty, \\ell_2,\n\\ell_1$) perturbations by 14%-to-20% for four state-of-the-art (SOTA)\nsingle-attack $\\ell_\\infty$ AT frameworks, and, for the first time, establishes\na benchmark for ResNet-50 and ResNet-101 on ImageNet.",
          "link": "http://arxiv.org/abs/2105.14710",
          "publishedOn": "2021-06-15T22:41:25.605Z",
          "wordCount": 646,
          "title": "Robustifying $\\ell_\\infty$ Adversarial Training to the Union of Perturbation Models. (arXiv:2105.14710v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04392",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1\">Yihong Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1\">Ying Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Muqiao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1\">Songtao Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Q/0/1/0/all/0/1\">Qingjiang Shi</a>",
          "description": "Deep neural networks have been shown as a class of useful tools for\naddressing signal recognition issues in recent years, especially for\nidentifying the nonlinear feature structures of signals. However, this power of\nmost deep learning techniques heavily relies on an abundant amount of training\ndata, so the performance of classic neural nets decreases sharply when the\nnumber of training data samples is small or unseen data are presented in the\ntesting phase. This calls for an advanced strategy, i.e., model-agnostic\nmeta-learning (MAML), which is able to capture the invariant representation of\nthe data samples or signals. In this paper, inspired by the special structure\nof the signal, i.e., real and imaginary parts consisted in practical\ntime-series signals, we propose a Complex-valued Attentional MEta Learner\n(CAMEL) for the problem of few-shot signal recognition by leveraging attention\nand meta-learning in the complex domain. To the best of our knowledge, this is\nalso the first complex-valued MAML that can find the first-order stationary\npoints of general nonconvex problems with theoretical convergence guarantees.\nExtensive experiments results showcase the superiority of the proposed CAMEL\ncompared with the state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2106.04392",
          "publishedOn": "2021-06-15T22:41:25.595Z",
          "wordCount": 639,
          "title": "Signal Transformer: Complex-valued Attention and Meta-Learning for Signal Recognition. (arXiv:2106.04392v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04527",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sellars_P/0/1/0/all/0/1\">Philip Sellars</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aviles_Rivero_A/0/1/0/all/0/1\">Angelica I. Aviles-Rivero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schonlieb_C/0/1/0/all/0/1\">Carola-Bibiane Sch&#xf6;nlieb</a>",
          "description": "Semi-supervised learning has received a lot of recent attention as it\nalleviates the need for large amounts of labelled data which can often be\nexpensive, requires expert knowledge and be time consuming to collect. Recent\ndevelopments in deep semi-supervised classification have reached unprecedented\nperformance and the gap between supervised and semi-supervised learning is\never-decreasing. This improvement in performance has been based on the\ninclusion of numerous technical tricks, strong augmentation techniques and\ncostly optimisation schemes with multi-term loss functions. We propose a new\nframework, LaplaceNet, for deep semi-supervised classification that has a\ngreatly reduced model complexity. We utilise a hybrid energy-neural network\nwhere graph based pseudo-labels, generated by minimising the graphical\nLaplacian, are used to iteratively improve a neural-network backbone. Our model\noutperforms state-of-the-art methods for deep semi-supervised classification,\nover several benchmark datasets. Furthermore, we consider the application of\nstrong-augmentations to neural networks theoretically and justify the use of a\nmulti-sampling approach for semi-supervised learning. We demonstrate, through\nrigorous experimentation, that a multi-sampling augmentation approach improves\ngeneralisation and reduces the sensitivity of the network to augmentation.",
          "link": "http://arxiv.org/abs/2106.04527",
          "publishedOn": "2021-06-15T22:41:25.576Z",
          "wordCount": 617,
          "title": "LaplaceNet: A Hybrid Energy-Neural Model for Deep Semi-Supervised Classification. (arXiv:2106.04527v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04563",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_S/0/1/0/all/0/1\">Subhabrata Mukherjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awadallah_A/0/1/0/all/0/1\">Ahmed Hassan Awadallah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>",
          "description": "While deep and large pre-trained models are the state-of-the-art for various\nnatural language processing tasks, their huge size poses significant challenges\nfor practical uses in resource constrained settings. Recent works in knowledge\ndistillation propose task-agnostic as well as task-specific methods to compress\nthese models, with task-specific ones often yielding higher compression rate.\nIn this work, we develop a new task-agnostic distillation framework\nXtremeDistilTransformers that leverages the advantage of task-specific methods\nfor learning a small universal model that can be applied to arbitrary tasks and\nlanguages. To this end, we study the transferability of several source tasks,\naugmentation resources and model architecture for distillation. We evaluate our\nmodel performance on multiple tasks, including the General Language\nUnderstanding Evaluation (GLUE) benchmark, SQuAD question answering dataset and\na massive multi-lingual NER dataset with 41 languages. We release three\ndistilled task-agnostic checkpoints with 13MM, 22MM and 33MM parameters\nobtaining SOTA performance in several tasks.",
          "link": "http://arxiv.org/abs/2106.04563",
          "publishedOn": "2021-06-15T22:41:25.566Z",
          "wordCount": 604,
          "title": "XtremeDistilTransformers: Task Transfer for Task-agnostic Distillation. (arXiv:2106.04563v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04496",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1\">Haotian Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1\">Chuanlong Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_T/0/1/0/all/0/1\">Tianle Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Ruichen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhenguo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Liwei Wang</a>",
          "description": "Generalization to out-of-distribution (OOD) data, or domain generalization,\nis one of the central problems in modern machine learning. Recently, there is a\nsurge of attempts to propose algorithms for OOD that mainly build upon the idea\nof extracting invariant features. Although intuitively reasonable, theoretical\nunderstanding of what kind of invariance can guarantee OOD generalization is\nstill limited, and generalization to arbitrary out-of-distribution is clearly\nimpossible. In this work, we take the first step towards rigorous and\nquantitative definitions of 1) what is OOD; and 2) what does it mean by saying\nan OOD problem is learnable. We also introduce a new concept of expansion\nfunction, which characterizes to what extent the variance is amplified in the\ntest domains over the training domains, and therefore give a quantitative\nmeaning of invariant features. Based on these, we prove OOD generalization\nerror bounds. It turns out that OOD generalization largely depends on the\nexpansion function. As recently pointed out by Gulrajani and Lopez-Paz (2020),\nany OOD learning algorithm without a model selection module is incomplete. Our\ntheory naturally induces a model selection criterion. Extensive experiments on\nbenchmark OOD datasets demonstrate that our model selection criterion has a\nsignificant advantage over baselines.",
          "link": "http://arxiv.org/abs/2106.04496",
          "publishedOn": "2021-06-15T22:41:25.555Z",
          "wordCount": 641,
          "title": "Towards a Theoretical Framework of Out-of-Distribution Generalization. (arXiv:2106.04496v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04292",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wan_C/0/1/0/all/0/1\">Changlin Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Muhan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_W/0/1/0/all/0/1\">Wei Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_S/0/1/0/all/0/1\">Sha Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Pan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chi Zhang</a>",
          "description": "Hypergraph offers a framework to depict the multilateral relationships in\nreal-world complex data. Predicting higher-order relationships, i.e hyperedge,\nbecomes a fundamental problem for the full understanding of complicated\ninteractions. The development of graph neural network (GNN) has greatly\nadvanced the analysis of ordinary graphs with pair-wise relations. However,\nthese methods could not be easily extended to the case of hypergraph. In this\npaper, we generalize the challenges of GNN in representing higher-order data in\nprinciple, which are edge- and node-level ambiguities. To overcome the\nchallenges, we present SNALS that utilizes bipartite graph neural network with\nstructural features to collectively tackle the two ambiguity issues. SNALS\ncaptures the joint interactions of a hyperedge by its local environment, which\nis retrieved by collecting the spectrum information of their connections. As a\nresult, SNALS achieves nearly 30% performance increase compared with most\nrecent GNN-based models. In addition, we applied SNALS to predict genetic\nhigher-order interactions on 3D genome organization data. SNALS showed\nconsistently high prediction accuracy across different chromosomes, and\ngenerated novel findings on 4-way gene interaction, which is further validated\nby existing literature.",
          "link": "http://arxiv.org/abs/2106.04292",
          "publishedOn": "2021-06-15T22:41:25.543Z",
          "wordCount": 656,
          "title": "Principled Hyperedge Prediction with Structural Spectral Features and Neural Networks. (arXiv:2106.04292v4 [cs.SI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.04740",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Gurbuzbalaban_M/0/1/0/all/0/1\">Mert Gurbuzbalaban</a>, <a href=\"http://arxiv.org/find/math/1/au:+Simsekli_U/0/1/0/all/0/1\">Umut &#x15e;im&#x15f;ekli</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhu_L/0/1/0/all/0/1\">Lingjiong Zhu</a>",
          "description": "In recent years, various notions of capacity and complexity have been\nproposed for characterizing the generalization properties of stochastic\ngradient descent (SGD) in deep learning. Some of the popular notions that\ncorrelate well with the performance on unseen data are (i) the `flatness' of\nthe local minimum found by SGD, which is related to the eigenvalues of the\nHessian, (ii) the ratio of the stepsize $\\eta$ to the batch-size $b$, which\nessentially controls the magnitude of the stochastic gradient noise, and (iii)\nthe `tail-index', which measures the heaviness of the tails of the network\nweights at convergence. In this paper, we argue that these three seemingly\nunrelated perspectives for generalization are deeply linked to each other. We\nclaim that depending on the structure of the Hessian of the loss at the\nminimum, and the choices of the algorithm parameters $\\eta$ and $b$, the SGD\niterates will converge to a \\emph{heavy-tailed} stationary distribution. We\nrigorously prove this claim in the setting of quadratic optimization: we show\nthat even in a simple linear regression problem with independent and\nidentically distributed data whose distribution has finite moments of all\norder, the iterates can be heavy-tailed with infinite variance. We further\ncharacterize the behavior of the tails with respect to algorithm parameters,\nthe dimension, and the curvature. We then translate our results into insights\nabout the behavior of SGD in deep learning. We support our theory with\nexperiments conducted on synthetic data, fully connected, and convolutional\nneural networks.",
          "link": "http://arxiv.org/abs/2006.04740",
          "publishedOn": "2021-06-15T22:41:25.530Z",
          "wordCount": 731,
          "title": "The Heavy-Tail Phenomenon in SGD. (arXiv:2006.04740v5 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14188",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_L/0/1/0/all/0/1\">Liyi Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_J/0/1/0/all/0/1\">Junqi Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Haoqi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zhenzhe Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhiye Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_Z/0/1/0/all/0/1\">Zhizhuang Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_F/0/1/0/all/0/1\">Fei Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_L/0/1/0/all/0/1\">Lvyin Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haiyang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1\">Chuan Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yuning Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaoqiang Zhu</a>",
          "description": "Advertising expenditures have become the major source of revenue for\ne-commerce platforms. Providing good advertising experiences for advertisers by\nreducing their costs of trial and error in discovering the optimal advertising\nstrategies is crucial for the long-term prosperity of online advertising. To\nachieve this goal, the advertising platform needs to identify the advertiser's\noptimization objectives, and then recommend the corresponding strategies to\nfulfill the objectives. In this work, we first deploy a prototype of strategy\nrecommender system on Taobao display advertising platform, which indeed\nincreases the advertisers' performance and the platform's revenue, indicating\nthe effectiveness of strategy recommendation for online advertising. We further\naugment this prototype system by explicitly learning the advertisers'\npreferences over various advertising performance indicators and then\noptimization objectives through their adoptions of different recommending\nadvertising strategies. We use contextual bandit algorithms to efficiently\nlearn the advertisers' preferences and maximize the recommendation adoption,\nsimultaneously. Simulation experiments based on Taobao online bidding data show\nthat the designed algorithms can effectively optimize the strategy adoption\nrate of advertisers.",
          "link": "http://arxiv.org/abs/2105.14188",
          "publishedOn": "2021-06-15T22:41:25.502Z",
          "wordCount": 675,
          "title": "We Know What You Want: An Advertising Strategy Recommender System for Online Advertising. (arXiv:2105.14188v3 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06916",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lixu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shichao Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">Ruiqi Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1\">Qi Zhu</a>",
          "description": "As Artificial Intelligence as a Service gains popularity, protecting\nwell-trained models as intellectual property is becoming increasingly\nimportant. Generally speaking, there are two common protection methods:\nownership verification and usage authorization. In this paper, we propose\nNon-Transferable Learning (NTL), a novel approach that captures the exclusive\ndata representation in the learned model and restricts the model generalization\nability to certain domains. This approach provides effective solutions to both\nmodel verification and authorization. For ownership verification, watermarking\ntechniques are commonly used but are often vulnerable to sophisticated\nwatermark removal methods. Our NTL-based model verification approach instead\nprovides robust resistance to state-of-the-art watermark removal methods, as\nshown in extensive experiments for four of such methods over the digits,\nCIFAR10 & STL10, and VisDA datasets. For usage authorization, prior solutions\nfocus on authorizing specific users to use the model, but authorized users can\nstill apply the model to any data without restriction. Our NTL-based\nauthorization approach instead provides data-centric usage protection by\nsignificantly degrading the performance of usage on unauthorized data. Its\neffectiveness is also shown through experiments on a variety of datasets.",
          "link": "http://arxiv.org/abs/2106.06916",
          "publishedOn": "2021-06-15T22:07:49.359Z",
          "wordCount": 617,
          "title": "Non-Transferable Learning: A New Approach for Model Verification and Authorization. (arXiv:2106.06916v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06733",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Lin_Y/0/1/0/all/0/1\">Yi Lin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_Y/0/1/0/all/0/1\">Yanfei Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_J/0/1/0/all/0/1\">Jingguang Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_G/0/1/0/all/0/1\">Guocai Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ma_K/0/1/0/all/0/1\">Kai Ma</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zheng_Y/0/1/0/all/0/1\">Yefeng Zheng</a>",
          "description": "Radiation therapy treatment planning is a complex process, as the target dose\nprescription and normal tissue sparing are conflicting objectives. Automated\nand accurate dose prediction for radiation therapy planning is in high demand.\nIn this study, we propose a novel learning-based ensemble approach, named\nLE-NAS, which integrates neural architecture search (NAS) with knowledge\ndistillation for 3D radiotherapy dose prediction. Specifically, the prediction\nnetwork first exhaustively searches each block from enormous architecture\nspace. Then, multiple architectures are selected with promising performance and\ndiversity. To reduce the inference time, we adopt the teacher-student paradigm\nby treating the combination of diverse outputs from multiple searched networks\nas supervisions to guide the student network training. In addition, we apply\nadversarial learning to optimize the student network to recover the knowledge\nin teacher networks. To the best of our knowledge, we are the first to\ninvestigate the combination of NAS and knowledge distillation. The proposed\nmethod has been evaluated on the public OpenKBP dataset, and experimental\nresults demonstrate the effectiveness of our method and its superior\nperformance to the state-of-the-art method.",
          "link": "http://arxiv.org/abs/2106.06733",
          "publishedOn": "2021-06-15T22:07:49.342Z",
          "wordCount": 622,
          "title": "LE-NAS: Learning-based Ensenble with NAS for Dose Prediction. (arXiv:2106.06733v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06769",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Junfu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bi Wang</a>",
          "description": "Working memory (WM) is a basic part of human cognition, which plays an\nimportant role in the study of human cognitive load. Among various brain\nimaging techniques, electroencephalography has shown its advantage on easy\naccess and reliability. However, one of the critical challenges is that\nindividual difference may cause the ineffective results, especially when the\nestablished model meets an unfamiliar subject. In this work, we propose a\ncross-subject deep adaptation model with spatial attention (CS-DASA) to\ngeneralize the workload classifications across subjects. First, we transform\ntime-series EEG data into multi-frame EEG images incorporating more\nspatio-temporal information. First, the subject-shared module in CS-DASA\nreceives multi-frame EEG image data from both source and target subjects and\nlearns the common feature representations. Then, in subject-specific module,\nthe maximum mean discrepancy is implemented to measure the domain distribution\ndivergence in a reproducing kernel Hilbert space, which can add an effective\npenalty loss for domain adaptation. Additionally, the subject-to-subject\nspatial attention mechanism is employed to focus on the most discriminative\nspatial feature in EEG image data. Experiments conducted on a public WM EEG\ndataset containing 13 subjects show that the proposed model is capable of\nachieve better performance than existing state-of-the art methods.",
          "link": "http://arxiv.org/abs/2106.06769",
          "publishedOn": "2021-06-15T22:07:49.270Z",
          "wordCount": 632,
          "title": "Cross-Subject Domain Adaptation for Multi-Frame EEG Images. (arXiv:2106.06769v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.01391",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Grimstad_B/0/1/0/all/0/1\">Bjarne Grimstad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hotvedt_M/0/1/0/all/0/1\">Mathilde Hotvedt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sandnes_A/0/1/0/all/0/1\">Anders T. Sandnes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolbjornsen_O/0/1/0/all/0/1\">Odd Kolbj&#xf8;rnsen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Imsland_L/0/1/0/all/0/1\">Lars S. Imsland</a>",
          "description": "Recent works have presented promising results from the application of machine\nlearning (ML) to the modeling of flow rates in oil and gas wells. Encouraging\nresults and advantageous properties of ML models, such as computationally cheap\nevaluation and ease of calibration to new data, have sparked optimism for the\ndevelopment of data-driven virtual flow meters (VFMs). Data-driven VFMs are\ndeveloped in the small data regime, where it is important to question the\nuncertainty and robustness of models. The modeling of uncertainty may help to\nbuild trust in models, which is a prerequisite for industrial applications. The\ncontribution of this paper is the introduction of a probabilistic VFM based on\nBayesian neural networks. Uncertainty in the model and measurements is\ndescribed, and the paper shows how to perform approximate Bayesian inference\nusing variational inference. The method is studied by modeling on a large and\nheterogeneous dataset, consisting of 60 wells across five different oil and gas\nassets. The predictive performance is analyzed on historical and future test\ndata, where an average error of 4-6% and 8-13% is achieved for the 50% best\nperforming models, respectively. Variational inference appears to provide more\nrobust predictions than the reference approach on future data. Prediction\nperformance and uncertainty calibration is explored in detail and discussed in\nlight of four data challenges. The findings motivate the development of\nalternative strategies to improve the robustness of data-driven VFMs.",
          "link": "http://arxiv.org/abs/2102.01391",
          "publishedOn": "2021-06-15T01:45:21.535Z",
          "wordCount": 708,
          "title": "Bayesian Neural Networks for Virtual Flow Metering: An Empirical Study. (arXiv:2102.01391v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.16205",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1\">Sang Michael Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1\">Tengyu Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1\">Percy Liang</a>",
          "description": "We focus on prediction problems with structured outputs that are subject to\noutput validity constraints, e.g. pseudocode-to-code translation where the code\nmust compile. While labeled input-output pairs are expensive to obtain,\n\"unlabeled\" outputs, i.e. outputs without corresponding inputs, are freely\navailable (e.g. code on GitHub) and provide information about output validity.\nPre-training captures this structure by training a denoiser to denoise\ncorrupted versions of unlabeled outputs. We first show that standard\nfine-tuning after pre-training destroys some of this structure. We then propose\ncomposed fine-tuning, which trains a predictor composed with the pre-trained\ndenoiser. Importantly, the denoiser is fixed to preserve output structure. Like\nstandard fine-tuning, the predictor is also initialized with the pre-trained\ndenoiser. We prove for two-layer ReLU networks that composed fine-tuning\nsignificantly reduces the complexity of the predictor, thus improving\ngeneralization. Empirically, we show that composed fine-tuning improves over\nstandard fine-tuning on two pseudocode-to-code translation datasets (3% and 6%\nrelative). The improvement is magnified on out-of-distribution (OOD) examples\n(4% and 25% relative), suggesting that reducing predictor complexity improves\nOOD extrapolation.",
          "link": "http://arxiv.org/abs/2006.16205",
          "publishedOn": "2021-06-15T01:45:21.468Z",
          "wordCount": 644,
          "title": "Composed Fine-Tuning: Freezing Pre-Trained Denoising Autoencoders for Improved Generalization. (arXiv:2006.16205v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02639",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Rosenfeld_J/0/1/0/all/0/1\">Joel A. Rosenfeld</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kamalapurkar_R/0/1/0/all/0/1\">Rushikesh Kamalapurkar</a>",
          "description": "This manuscript is aimed at addressing several long standing limitations of\ndynamic mode decompositions in the application of Koopman analysis. Principle\namong these limitations are the convergence of associated Dynamic Mode\nDecomposition algorithms and the existence of Koopman modes. To address these\nlimitations, two major modifications are made, where Koopman operators are\nremoved from the analysis in light of Liouville operators (known as Koopman\ngenerators in special cases), and these operators are shown to be compact for\ncertain pairs of Hilbert spaces selected separately as the domain and range of\nthe operator. While eigenfunctions are discarded in the general analysis, a\nviable reconstruction algorithm is still demonstrated, and the sacrifice of\neigenfunctions realizes the theoretical goals of DMD analysis that have yet to\nbe achieved in other contexts. However, in the case where the domain is\nembedded in the range, an eigenfunction approach is still achievable, where a\nmore typical DMD routine is established, but that leverages a finite rank\nrepresentation that converges in norm. The manuscript concludes with the\ndescription of two Dynamic Mode Decomposition algorithms that converges when a\ndense collection of occupation kernels, arising from the data, are leveraged in\nthe analysis.",
          "link": "http://arxiv.org/abs/2106.02639",
          "publishedOn": "2021-06-15T01:45:21.438Z",
          "wordCount": 666,
          "title": "Singular Dynamic Mode Decompositions. (arXiv:2106.02639v2 [eess.SY] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06932",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Junfeng Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Saurabh Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gummadi_R/0/1/0/all/0/1\">Ramki Gummadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schuurmans_D/0/1/0/all/0/1\">Dale Schuurmans</a>",
          "description": "Actor-critic (AC) methods are ubiquitous in reinforcement learning. Although\nit is understood that AC methods are closely related to policy gradient (PG),\ntheir precise connection has not been fully characterized previously. In this\npaper, we explain the gap between AC and PG methods by identifying the exact\nadjustment to the AC objective/gradient that recovers the true policy gradient\nof the cumulative reward objective (PG). Furthermore, by viewing the AC method\nas a two-player Stackelberg game between the actor and critic, we show that the\nStackelberg policy gradient can be recovered as a special case of our more\ngeneral analysis. Based on these results, we develop practical algorithms,\nResidual Actor-Critic and Stackelberg Actor-Critic, for estimating the\ncorrection between AC and PG and use these to modify the standard AC algorithm.\nExperiments on popular tabular and continuous environments show the proposed\ncorrections can improve both the sample efficiency and final performance of\nexisting AC methods.",
          "link": "http://arxiv.org/abs/2106.06932",
          "publishedOn": "2021-06-15T01:45:21.389Z",
          "wordCount": 584,
          "title": "Characterizing the Gap Between Actor-Critic and Policy Gradient. (arXiv:2106.06932v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2102.06752",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Xin_R/0/1/0/all/0/1\">Ran Xin</a>, <a href=\"http://arxiv.org/find/math/1/au:+Khan_U/0/1/0/all/0/1\">Usman A. Khan</a>, <a href=\"http://arxiv.org/find/math/1/au:+Kar_S/0/1/0/all/0/1\">Soummya Kar</a>",
          "description": "This paper considers decentralized stochastic optimization over a network of\n$n$ nodes, where each node possesses a smooth non-convex local cost function\nand the goal of the networked nodes is to find an $\\epsilon$-accurate\nfirst-order stationary point of the sum of the local costs. We focus on an\nonline setting, where each node accesses its local cost only by means of a\nstochastic first-order oracle that returns a noisy version of the exact\ngradient. In this context, we propose a novel single-loop decentralized hybrid\nvariance-reduced stochastic gradient method, called GT-HSGD, that outperforms\nthe existing approaches in terms of both the oracle complexity and practical\nimplementation. The GT-HSGD algorithm implements specialized local hybrid\nstochastic gradient estimators that are fused over the network to track the\nglobal gradient. Remarkably, GT-HSGD achieves a network topology-independent\noracle complexity of $O(n^{-1}\\epsilon^{-3})$ when the required error tolerance\n$\\epsilon$ is small enough, leading to a linear speedup with respect to the\ncentralized optimal online variance-reduced approaches that operate on a single\nnode. Numerical experiments are provided to illustrate our main technical\nresults.",
          "link": "http://arxiv.org/abs/2102.06752",
          "publishedOn": "2021-06-15T01:45:21.382Z",
          "wordCount": 644,
          "title": "A Hybrid Variance-Reduced Method for Decentralized Stochastic Non-Convex Optimization. (arXiv:2102.06752v2 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.09261",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1\">Xu Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Boyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Han Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miao_C/0/1/0/all/0/1\">Chunyan Miao</a>",
          "description": "The existence of multiple datasets for sarcasm detection prompts us to apply\ntransfer learning to exploit their commonality. The adversarial neural transfer\n(ANT) framework utilizes multiple loss terms that encourage the source-domain\nand the target-domain feature distributions to be similar while optimizing for\ndomain-specific performance. However, these objectives may be in conflict,\nwhich can lead to optimization difficulties and sometimes diminished transfer.\nWe propose a generalized latent optimization strategy that allows different\nlosses to accommodate each other and improves training dynamics. The proposed\nmethod outperforms transfer learning and meta-learning baselines. In\nparticular, we achieve 10.02% absolute performance gain over the previous state\nof the art on the iSarcasm dataset.",
          "link": "http://arxiv.org/abs/2104.09261",
          "publishedOn": "2021-06-15T01:45:21.376Z",
          "wordCount": 579,
          "title": "Latent-Optimized Adversarial Neural Transfer for Sarcasm Detection. (arXiv:2104.09261v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.03230",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zbontar_J/0/1/0/all/0/1\">Jure Zbontar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jing_L/0/1/0/all/0/1\">Li Jing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Misra_I/0/1/0/all/0/1\">Ishan Misra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+LeCun_Y/0/1/0/all/0/1\">Yann LeCun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deny_S/0/1/0/all/0/1\">St&#xe9;phane Deny</a>",
          "description": "Self-supervised learning (SSL) is rapidly closing the gap with supervised\nmethods on large computer vision benchmarks. A successful approach to SSL is to\nlearn embeddings which are invariant to distortions of the input sample.\nHowever, a recurring issue with this approach is the existence of trivial\nconstant solutions. Most current methods avoid such solutions by careful\nimplementation details. We propose an objective function that naturally avoids\ncollapse by measuring the cross-correlation matrix between the outputs of two\nidentical networks fed with distorted versions of a sample, and making it as\nclose to the identity matrix as possible. This causes the embedding vectors of\ndistorted versions of a sample to be similar, while minimizing the redundancy\nbetween the components of these vectors. The method is called Barlow Twins,\nowing to neuroscientist H. Barlow's redundancy-reduction principle applied to a\npair of identical networks. Barlow Twins does not require large batches nor\nasymmetry between the network twins such as a predictor network, gradient\nstopping, or a moving average on the weight updates. Intriguingly it benefits\nfrom very high-dimensional output vectors. Barlow Twins outperforms previous\nmethods on ImageNet for semi-supervised classification in the low-data regime,\nand is on par with current state of the art for ImageNet classification with a\nlinear classifier head, and for transfer tasks of classification and object\ndetection.",
          "link": "http://arxiv.org/abs/2103.03230",
          "publishedOn": "2021-06-15T01:45:21.369Z",
          "wordCount": 717,
          "title": "Barlow Twins: Self-Supervised Learning via Redundancy Reduction. (arXiv:2103.03230v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.11005",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+You_K/0/1/0/all/0/1\">Kaichao You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_M/0/1/0/all/0/1\">Mingsheng Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianmin Wang</a>",
          "description": "This paper studies task adaptive pre-trained model selection, an\nunderexplored problem of assessing pre-trained models for the target task and\nselect best ones from the model zoo \\emph{without fine-tuning}. A few pilot\nworks addressed the problem in transferring supervised pre-trained models to\nclassification tasks, but they cannot handle emerging unsupervised pre-trained\nmodels or regression tasks. In pursuit of a practical assessment method, we\npropose to estimate the maximum value of label evidence given features\nextracted by pre-trained models. Unlike the maximum likelihood, the maximum\nevidence is \\emph{immune to over-fitting}, while its expensive computation can\nbe dramatically reduced by our carefully designed algorithm. The Logarithm of\nMaximum Evidence (LogME) can be used to assess pre-trained models for transfer\nlearning: a pre-trained model with a high LogME value is likely to have good\ntransfer performance. LogME is \\emph{fast, accurate, and general},\ncharacterizing itself as the first practical method for assessing pre-trained\nmodels. Compared with brute-force fine-tuning, LogME brings at most\n$3000\\times$ speedup in wall-clock time and requires only $1\\%$ memory\nfootprint. It outperforms prior methods by a large margin in their setting and\nis applicable to new settings. It is general enough for diverse pre-trained\nmodels (supervised pre-trained and unsupervised pre-trained), downstream tasks\n(classification and regression), and modalities (vision and language). Code is\navailable at this repository:\n\\href{https://github.com/thuml/LogME}{https://github.com/thuml/LogME}.",
          "link": "http://arxiv.org/abs/2102.11005",
          "publishedOn": "2021-06-15T01:45:21.320Z",
          "wordCount": 686,
          "title": "LogME: Practical Assessment of Pre-trained Models for Transfer Learning. (arXiv:2102.11005v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.01956",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Karan_A/0/1/0/all/0/1\">Alperen Karan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kaygun_A/0/1/0/all/0/1\">Atabey Kaygun</a>",
          "description": "In this paper, we develop topological data analysis methods for\nclassification tasks on univariate time series. As an application, we perform\nbinary and ternary classification tasks on two public datasets that consist of\nphysiological signals collected under stress and non-stress conditions. We\naccomplish our goal by using persistent homology to engineer stable topological\nfeatures after we use a time delay embedding of the signals and perform a\nsubwindowing instead of using windows of fixed length. The combination of\nmethods we use can be applied to any univariate time series and in this\napplication allows us to reduce noise and use long window sizes without\nincurring an extra computational cost. We then use machine learning models on\nthe features we algorithmically engineered to obtain higher accuracies with\nfewer features.",
          "link": "http://arxiv.org/abs/2102.01956",
          "publishedOn": "2021-06-15T01:45:21.302Z",
          "wordCount": 578,
          "title": "Time Series Classification via Topological Data Analysis. (arXiv:2102.01956v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.09670",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Croce_F/0/1/0/all/0/1\">Francesco Croce</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andriushchenko_M/0/1/0/all/0/1\">Maksym Andriushchenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sehwag_V/0/1/0/all/0/1\">Vikash Sehwag</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Debenedetti_E/0/1/0/all/0/1\">Edoardo Debenedetti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Flammarion_N/0/1/0/all/0/1\">Nicolas Flammarion</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiang_M/0/1/0/all/0/1\">Mung Chiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mittal_P/0/1/0/all/0/1\">Prateek Mittal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hein_M/0/1/0/all/0/1\">Matthias Hein</a>",
          "description": "As a research community, we are still lacking a systematic understanding of\nthe progress on adversarial robustness, which often makes it hard to identify\nthe most promising ideas in training robust models. A key challenge in\nbenchmarking robustness is that its evaluation is often error-prone, leading to\noverestimation of the true robustness of models. While adaptive attacks\ndesigned for a particular defense are a potential solution, they have to be\nhighly customized for particular models, which makes it difficult to compare\ndifferent methods. Our goal is to instead establish a standardized benchmark of\nadversarial robustness, which as accurately as possible reflects the robustness\nof the considered models within a reasonable computational budget. To evaluate\nthe robustness of models for our benchmark, we consider AutoAttack, an ensemble\nof white- and black-box attacks which was recently shown in a large-scale study\nto improve almost all robustness evaluations compared to the original\npublications. We also impose some restrictions on the admitted models to rule\nout defenses that only make gradient-based attacks ineffective without\nimproving actual robustness. Our leaderboard, hosted at\nhttps://robustbench.github.io/, contains evaluations of 90+ models and aims at\nreflecting the current state of the art on a set of well-defined tasks in\n$\\ell_\\infty$- and $\\ell_2$-threat models and on common corruptions, with\npossible extensions in the future. Additionally, we open-source the library\nhttps://github.com/RobustBench/robustbench that provides unified access to 60+\nrobust models to facilitate their downstream applications. Finally, based on\nthe collected models, we analyze the impact of robustness on the performance on\ndistribution shifts, calibration, out-of-distribution detection, fairness,\nprivacy leakage, smoothness, and transferability.",
          "link": "http://arxiv.org/abs/2010.09670",
          "publishedOn": "2021-06-15T01:45:21.289Z",
          "wordCount": 763,
          "title": "RobustBench: a standardized adversarial robustness benchmark. (arXiv:2010.09670v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06989",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alcorn_M/0/1/0/all/0/1\">Michael A. Alcorn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1\">Anh Nguyen</a>",
          "description": "Order-agnostic autoregressive distribution estimation (OADE), i.e.,\nautoregressive distribution estimation where the features can occur in an\narbitrary order, is a challenging problem in generative machine learning. Prior\nwork on OADE has encoded feature identity (e.g., pixel location) by assigning\neach feature to a distinct fixed position in an input vector. As a result,\narchitectures built for these inputs must strategically mask either the input\nor model weights to learn the various conditional distributions necessary for\ninferring the full joint distribution of the dataset in an order-agnostic way.\nIn this paper, we propose an alternative approach for encoding feature\nidentities, where each feature's identity is included alongside its value in\nthe input. This feature identity encoding strategy allows neural architectures\ndesigned for sequential data to be applied to the OADE task without\nmodification. As a proof of concept, we show that a Transformer trained on this\ninput (which we refer to as \"the DEformer\", i.e., the distribution estimating\nTransformer) can effectively model binarized-MNIST, approaching the average\nnegative log-likelihood of fixed order autoregressive distribution estimating\nalgorithms while still being entirely order-agnostic.",
          "link": "http://arxiv.org/abs/2106.06989",
          "publishedOn": "2021-06-15T01:45:21.277Z",
          "wordCount": 598,
          "title": "The DEformer: An Order-Agnostic Distribution Estimating Transformer. (arXiv:2106.06989v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06613",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Treutlein_J/0/1/0/all/0/1\">Johannes Treutlein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dennis_M/0/1/0/all/0/1\">Michael Dennis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oesterheld_C/0/1/0/all/0/1\">Caspar Oesterheld</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Foerster_J/0/1/0/all/0/1\">Jakob Foerster</a>",
          "description": "In many coordination problems, independently reasoning humans are able to\ndiscover mutually compatible policies. In contrast, independently trained\nself-play policies are often mutually incompatible. Zero-shot coordination\n(ZSC) has recently been proposed as a new frontier in multi-agent reinforcement\nlearning to address this fundamental issue. Prior work approaches the ZSC\nproblem by assuming players can agree on a shared learning algorithm but not on\nlabels for actions and observations, and proposes other-play as an optimal\nsolution. However, until now, this \"label-free\" problem has only been\ninformally defined. We formalize this setting as the label-free coordination\n(LFC) problem by defining the label-free coordination game. We show that\nother-play is not an optimal solution to the LFC problem as it fails to\nconsistently break ties between incompatible maximizers of the other-play\nobjective. We introduce an extension of the algorithm, other-play with\ntie-breaking, and prove that it is optimal in the LFC problem and an\nequilibrium in the LFC game. Since arbitrary tie-breaking is precisely what the\nZSC setting aims to prevent, we conclude that the LFC problem does not reflect\nthe aims of ZSC. To address this, we introduce an alternative informal\noperationalization of ZSC as a starting point for future work.",
          "link": "http://arxiv.org/abs/2106.06613",
          "publishedOn": "2021-06-15T01:45:21.260Z",
          "wordCount": 630,
          "title": "A New Formalism, Method and Open Issues for Zero-Shot Coordination. (arXiv:2106.06613v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2103.13740",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ingolfsson_T/0/1/0/all/0/1\">Thorir Mar Ingolfsson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaying Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hersche_M/0/1/0/all/0/1\">Michael Hersche</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burrello_A/0/1/0/all/0/1\">Alessio Burrello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cavigelli_L/0/1/0/all/0/1\">Lukas Cavigelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benini_L/0/1/0/all/0/1\">Luca Benini</a>",
          "description": "Personalized ubiquitous healthcare solutions require energy-efficient\nwearable platforms that provide an accurate classification of bio-signals while\nconsuming low average power for long-term battery-operated use. Single lead\nelectrocardiogram (ECG) signals provide the ability to detect, classify, and\neven predict cardiac arrhythmia. In this paper, we propose a novel temporal\nconvolutional network (TCN) that achieves high accuracy while still being\nfeasible for wearable platform use. Experimental results on the ECG5000 dataset\nshow that the TCN has a similar accuracy (94.2%) score as the state-of-the-art\n(SoA) network while achieving an improvement of 16.5% in the balanced accuracy\nscore. This accurate classification is done with 27 times fewer parameters and\n37 times less multiply-accumulate operations. We test our implementation on two\npublicly available platforms, the STM32L475, which is based on ARM Cortex M4F,\nand the GreenWaves Technologies GAP8 on the GAPuino board, based on 1+8 RISC-V\nCV32E40P cores. Measurements show that the GAP8 implementation respects the\nreal-time constraints while consuming 0.10 mJ per inference. With 9.91\nGMAC/s/W, it is 23.0 times more energy-efficient and 46.85 times faster than an\nimplementation on the ARM Cortex M4F (0.43 GMAC/s/W). Overall, we obtain 8.1%\nhigher accuracy while consuming 19.6 times less energy and being 35.1 times\nfaster compared to a previous SoA embedded implementation.",
          "link": "http://arxiv.org/abs/2103.13740",
          "publishedOn": "2021-06-15T01:45:21.253Z",
          "wordCount": 681,
          "title": "ECG-TCN: Wearable Cardiac Arrhythmia Detection with a Temporal Convolutional Network. (arXiv:2103.13740v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.09887",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maheshwari_A/0/1/0/all/0/1\">Ayush Maheshwari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chatterjee_O/0/1/0/all/0/1\">Oishik Chatterjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Killamsetty_K/0/1/0/all/0/1\">KrishnaTeja Killamsetty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramakrishnan_G/0/1/0/all/0/1\">Ganesh Ramakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iyer_R/0/1/0/all/0/1\">Rishabh Iyer</a>",
          "description": "The paradigm of data programming, which uses weak supervision in the form of\nrules/labelling functions, and semi-supervised learning, which augments small\namounts of labelled data with a large unlabelled dataset, have shown great\npromise in several text classification scenarios. In this work, we argue that\nby not using any labelled data, data programming based approaches can yield\nsub-optimal performances, particularly when the labelling functions are noisy.\nThe first contribution of this work is an introduction of a framework, \\model\nwhich is a semi-supervised data programming paradigm that learns a \\emph{joint\nmodel} that effectively uses the rules/labelling functions along with\nsemi-supervised loss functions on the feature space. Next, we also study\n\\modelss which additionally does subset selection on top of the joint\nsemi-supervised data programming objective and \\emph{selects} a set of examples\nthat can be used as the labelled set by \\model. The goal of \\modelss is to\nensure that the labelled data can \\emph{complement} the labelling functions,\nthereby benefiting from both data-programming as well as appropriately selected\ndata for human labelling. We demonstrate that by effectively combining\nsemi-supervision, data-programming, and subset selection paradigms, we\nsignificantly outperform the current state-of-the-art on seven publicly\navailable datasets. \\footnote{The source code is available at\n\\url{https://github.com/ayushbits/Semi-Supervised-LFs-Subset-Selection}}",
          "link": "http://arxiv.org/abs/2008.09887",
          "publishedOn": "2021-06-15T01:45:21.247Z",
          "wordCount": 672,
          "title": "Semi-Supervised Data Programming with Subset Selection. (arXiv:2008.09887v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.10683",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Koeppe_A/0/1/0/all/0/1\">Arnd Koeppe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bamer_F/0/1/0/all/0/1\">Franz Bamer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Selzer_M/0/1/0/all/0/1\">Michael Selzer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nestler_B/0/1/0/all/0/1\">Britta Nestler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Markert_B/0/1/0/all/0/1\">Bernd Markert</a>",
          "description": "(Artificial) neural networks have become increasingly popular in mechanics as\nmeans to accelerate computations with model order reduction techniques and as\nuniversal models for a wide variety of materials. However, the major\ndisadvantage of neural networks remains: their numerous parameters are\nchallenging to interpret and explain. Thus, neural networks are often labeled\nas black boxes, and their results often elude human interpretation. In\nmechanics, the new and active field of physics-informed neural networks\nattempts to mitigate this disadvantage by designing deep neural networks on the\nbasis of mechanical knowledge. By using this a priori knowledge, deeper and\nmore complex neural networks became feasible, since the mechanical assumptions\ncould be explained. However, the internal reasoning and explanation of neural\nnetwork parameters remain mysterious.\n\nComplementary to the physics-informed approach, we propose a first step\ntowards a physics-informing approach, which explains neural networks trained on\nmechanical data a posteriori. This novel explainable artificial intelligence\napproach aims at elucidating the black box of neural networks and their\nhigh-dimensional representations. Therein, the principal component analysis\ndecorrelates the distributed representations in cell states of RNNs and allows\nthe comparison to known and fundamental functions. The novel approach is\nsupported by a systematic hyperparameter search strategy that identifies the\nbest neural network architectures and training parameters. The findings of\nthree case studies on fundamental constitutive models (hyperelasticity,\nelastoplasticity, and viscoelasticity) imply that the proposed strategy can\nhelp identify numerical and analytical closed-form solutions to characterize\nnew materials.",
          "link": "http://arxiv.org/abs/2104.10683",
          "publishedOn": "2021-06-15T01:45:21.241Z",
          "wordCount": 723,
          "title": "Explainable artificial intelligence for mechanics: physics-informing neural networks for constitutive models. (arXiv:2104.10683v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.07238",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Harzli_O/0/1/0/all/0/1\">Ouns El Harzli</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Valle_Perez_G/0/1/0/all/0/1\">Guillermo Valle-P&#xe9;rez</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Louis_A/0/1/0/all/0/1\">Ard A. Louis</a>",
          "description": "Double-descent curves in neural networks describe the phenomenon that the\ngeneralisation error initially descends with increasing parameters, then grows\nafter reaching an optimal number of parameters which is less than the number of\ndata points, but then descends again in the overparameterised regime. Here we\nuse a neural network Gaussian process (NNGP) which maps exactly to a fully\nconnected network (FCN) in the infinite width limit, combined with techniques\nfrom random matrix theory, to calculate this generalisation behaviour, with a\nparticular focus on the overparameterised regime. An advantage of our NNGP\napproach is that the analytical calculations are easier to interpret. We argue\nthat neural network generalization performance improves in the\noverparameterised regime precisely because that is where they converge to their\nequivalent Gaussian process.",
          "link": "http://arxiv.org/abs/2102.07238",
          "publishedOn": "2021-06-15T01:45:21.235Z",
          "wordCount": 585,
          "title": "Double-descent curves in neural networks: a new perspective using Gaussian processes. (arXiv:2102.07238v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.00467",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Castelnovo_A/0/1/0/all/0/1\">Alessandro Castelnovo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crupi_R/0/1/0/all/0/1\">Riccardo Crupi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Greco_G/0/1/0/all/0/1\">Greta Greco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Regoli_D/0/1/0/all/0/1\">Daniele Regoli</a>",
          "description": "In recent years, the problem of addressing fairness in Machine Learning (ML)\nand automatic decision-making has attracted a lot of attention in the\nscientific communities dealing with Artificial Intelligence. A plethora of\ndifferent definitions of fairness in ML have been proposed, that consider\ndifferent notions of what is a \"fair decision\" in situations impacting\nindividuals in the population. The precise differences, implications and\n\"orthogonality\" between these notions have not yet been fully analyzed in the\nliterature. In this work, we try to make some order out of this zoo of\ndefinitions.",
          "link": "http://arxiv.org/abs/2106.00467",
          "publishedOn": "2021-06-15T01:45:21.218Z",
          "wordCount": 546,
          "title": "The zoo of Fairness metrics in Machine Learning. (arXiv:2106.00467v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02556",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Farris_N/0/1/0/all/0/1\">Nicholas Farris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Model_B/0/1/0/all/0/1\">Brian Model</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Savery_R/0/1/0/all/0/1\">Richard Savery</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weinberg_G/0/1/0/all/0/1\">Gil Weinberg</a>",
          "description": "The task of classifying emotions within a musical track has received\nwidespread attention within the Music Information Retrieval (MIR) community.\nMusic emotion recognition has traditionally relied on the use of acoustic\nfeatures, verbal features, and metadata-based filtering. The role of musical\nprosody remains under-explored despite several studies demonstrating a strong\nconnection between prosody and emotion. In this study, we restrict the input of\ntraditional machine learning algorithms to the features of musical prosody.\nFurthermore, our proposed approach builds upon the prior by classifying\nemotions under an expanded emotional taxonomy, using the Geneva Wheel of\nEmotion. We utilize a methodology for individual data collection from\nvocalists, and personal ground truth labeling by the artist themselves. We\nfound that traditional machine learning algorithms when limited to the features\nof musical prosody (1) achieve high accuracies for a single singer, (2)\nmaintain high accuracy when the dataset is expanded to multiple singers, and\n(3) achieve high accuracies when trained on a reduced subset of the total\nfeatures.",
          "link": "http://arxiv.org/abs/2106.02556",
          "publishedOn": "2021-06-15T01:45:21.211Z",
          "wordCount": 622,
          "title": "Musical Prosody-Driven Emotion Classification: Interpreting Vocalists Portrayal of Emotions Through Machine Learning. (arXiv:2106.02556v2 [cs.SD] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.03767",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ozdayi_M/0/1/0/all/0/1\">Mustafa Safa Ozdayi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kantarcioglu_M/0/1/0/all/0/1\">Murat Kantarcioglu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gel_Y/0/1/0/all/0/1\">Yulia R. Gel</a>",
          "description": "Federated learning (FL) allows a set of agents to collaboratively train a\nmodel without sharing their potentially sensitive data. This makes FL suitable\nfor privacy-preserving applications. At the same time, FL is susceptible to\nadversarial attacks due to decentralized and unvetted data. One important line\nof attacks against FL is the backdoor attacks. In a backdoor attack, an\nadversary tries to embed a backdoor functionality to the model during training\nthat can later be activated to cause a desired misclassification. To prevent\nbackdoor attacks, we propose a lightweight defense that requires minimal change\nto the FL protocol. At a high level, our defense is based on carefully\nadjusting the aggregation server's learning rate, per dimension and per round,\nbased on the sign information of agents' updates. We first conjecture the\nnecessary steps to carry a successful backdoor attack in FL setting, and then,\nexplicitly formulate the defense based on our conjecture. Through experiments,\nwe provide empirical evidence that supports our conjecture, and we test our\ndefense against backdoor attacks under different settings. We observe that\neither backdoor is completely eliminated, or its accuracy is significantly\nreduced. Overall, our experiments suggest that our defense significantly\noutperforms some of the recently proposed defenses in the literature. We\nachieve this by having minimal influence over the accuracy of the trained\nmodels. In addition, we also provide convergence rate analysis for our proposed\nscheme.",
          "link": "http://arxiv.org/abs/2007.03767",
          "publishedOn": "2021-06-15T01:45:21.202Z",
          "wordCount": 710,
          "title": "Defending against Backdoors in Federated Learning with Robust Learning Rate. (arXiv:2007.03767v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06608",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ho_N/0/1/0/all/0/1\">Nhat Ho</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Walker_S/0/1/0/all/0/1\">Stephen G. Walker</a>",
          "description": "Taking the Fourier integral theorem as our starting point, in this paper we\nfocus on natural Monte Carlo and fully nonparametric estimators of multivariate\ndistributions and conditional distribution functions. We do this without the\nneed for any estimated covariance matrix or dependence structure between\nvariables. These aspects arise immediately from the integral theorem. Being\nable to model multivariate data sets using conditional distribution functions\nwe can study a number of problems, such as prediction for Markov processes,\nestimation of mixing distribution functions which depend on covariates, and\ngeneral multivariate data. Estimators are explicit Monte Carlo based and\nrequire no recursive or iterative algorithms.",
          "link": "http://arxiv.org/abs/2106.06608",
          "publishedOn": "2021-06-15T01:45:21.191Z",
          "wordCount": 536,
          "title": "Statistical Analysis from the Fourier Integral Theorem. (arXiv:2106.06608v1 [stat.ME])"
        },
        {
          "id": "http://arxiv.org/abs/2102.05140",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bahri_D/0/1/0/all/0/1\">Dara Bahri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Heinrich Jiang</a>",
          "description": "Training modern neural networks is an inherently noisy process that can lead\nto high \\emph{prediction churn} -- disagreements between re-trainings of the\nsame model due to factors such as randomization in the parameter initialization\nand mini-batches -- even when the trained models all attain similar accuracies.\nSuch prediction churn can be very undesirable in practice. In this paper, we\npresent several baselines for reducing churn and show that training on soft\nlabels obtained by adaptively smoothing each example's label based on the\nexample's neighboring labels often outperforms the baselines on churn while\nimproving accuracy on a variety of benchmark classification tasks and model\narchitectures.",
          "link": "http://arxiv.org/abs/2102.05140",
          "publishedOn": "2021-06-15T01:45:21.185Z",
          "wordCount": 554,
          "title": "Locally Adaptive Label Smoothing for Predictive Churn. (arXiv:2102.05140v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.04507",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Guo_X/0/1/0/all/0/1\">Xin Guo</a>, <a href=\"http://arxiv.org/find/math/1/au:+Han_J/0/1/0/all/0/1\">Jiequn Han</a>, <a href=\"http://arxiv.org/find/math/1/au:+Tajrobehkar_M/0/1/0/all/0/1\">Mahan Tajrobehkar</a>, <a href=\"http://arxiv.org/find/math/1/au:+Tang_W/0/1/0/all/0/1\">Wenpin Tang</a>",
          "description": "This paper develops further the idea of perturbed gradient descent (PGD), by\nadapting perturbation with the history of states via the notion of occupation\ntime. The proposed algorithm, perturbed gradient descent adapted with\noccupation time (PGDOT), is shown to converge at least as fast as the PGD\nalgorithm and is guaranteed to avoid getting stuck at saddle points. The\nanalysis is corroborated by empirical studies, in which a mini-batch version of\nPGDOT is shown to outperform alternatives such as mini-batch gradient descent,\nAdam, AMSGrad, and RMSProp in training multilayer perceptrons (MLPs). In\nparticular, the mini-batch PGDOT manages to escape saddle points whereas these\nalternatives fail.",
          "link": "http://arxiv.org/abs/2005.04507",
          "publishedOn": "2021-06-15T01:45:21.166Z",
          "wordCount": 561,
          "title": "PGDOT -- Perturbed Gradient Descent Adapted with Occupation Time. (arXiv:2005.04507v2 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.10685",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zou_X/0/1/0/all/0/1\">Xu Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_D/0/1/0/all/0/1\">Da Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_Q/0/1/0/all/0/1\">Qingyang Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1\">Ming Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhilin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jie Tang</a>",
          "description": "Large-scale pre-trained language models have demonstrated strong capabilities\nof generating realistic text. However, it remains challenging to control the\ngeneration results. Previous approaches such as prompting are far from\nsufficient, which limits the usage of language models. To tackle this\nchallenge, we propose an innovative method, inverse prompting, to better\ncontrol text generation. The core idea of inverse prompting is to use generated\ntext to inversely predict the prompt during beam search, which enhances the\nrelevance between the prompt and the generated text and provides better\ncontrollability. Empirically, we pre-train a large-scale Chinese language model\nto perform a systematic study using human evaluation on the tasks of\nopen-domain poem generation and open-domain long-form question answering. Our\nresults show that our proposed method substantially outperforms the baselines\nand that our generation quality is close to human performance on some of the\ntasks.\n\nNarrators can try our poem generation demo at\nhttps://pretrain.aminer.cn/apps/poetry.html, while our QA demo can be found at\nhttps://pretrain.aminer.cn/app/qa. For researchers, the code is provided in\nhttps://github.com/THUDM/InversePrompting.",
          "link": "http://arxiv.org/abs/2103.10685",
          "publishedOn": "2021-06-15T01:45:21.159Z",
          "wordCount": 641,
          "title": "Controllable Generation from Pre-trained Language Models via Inverse Prompting. (arXiv:2103.10685v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.10271",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walters_R/0/1/0/all/0/1\">Robin Walters</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_R/0/1/0/all/0/1\">Rose Yu</a>",
          "description": "Current deep learning models for dynamics forecasting struggle with\ngeneralization. They can only forecast in a specific domain and fail when\napplied to systems with different parameters, external forces, or boundary\nconditions. We propose a model-based meta-learning method called DyAd which can\ngeneralize across heterogeneous domains by partitioning them into different\ntasks. DyAd has two parts: an encoder which infers the time-invariant hidden\nfeatures of the task with weak supervision, and a forecaster which learns the\nshared dynamics of the entire domain. The encoder adapts and controls the\nforecaster during inference using adaptive instance normalization and adaptive\npadding. Theoretically, we prove that the generalization error of such\nprocedure is related to the task relatedness in the source domain, as well as\nthe domain differences between source and target. Experimentally, we\ndemonstrate that our model outperforms state-of-the-art approaches on both\nturbulent flow and real-world ocean data forecasting tasks.",
          "link": "http://arxiv.org/abs/2102.10271",
          "publishedOn": "2021-06-15T01:45:21.141Z",
          "wordCount": 592,
          "title": "Meta-Learning Dynamics Forecasting Using Task Inference. (arXiv:2102.10271v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03279",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Kai Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_S/0/1/0/all/0/1\">Sanket Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Haipeng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perrault_A/0/1/0/all/0/1\">Andrew Perrault</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doshi_Velez_F/0/1/0/all/0/1\">Finale Doshi-Velez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tambe_M/0/1/0/all/0/1\">Milind Tambe</a>",
          "description": "In the predict-then-optimize framework, the objective is to train a\npredictive model, mapping from environment features to parameters of an\noptimization problem, which maximizes decision quality when the optimization is\nsubsequently solved. Recent work on decision-focused learning shows that\nembedding the optimization problem in the training pipeline can improve\ndecision quality and help generalize better to unseen tasks compared to relying\non an intermediate loss function for evaluating prediction quality. We study\nthe predict-then-optimize framework in the context of sequential decision\nproblems (formulated as MDPs) that are solved via reinforcement learning. In\nparticular, we are given environment features and a set of trajectories from\ntraining MDPs, which we use to train a predictive model that generalizes to\nunseen test MDPs without trajectories. Two significant computational challenges\narise in applying decision-focused learning to MDPs: (i) large state and action\nspaces make it infeasible for existing techniques to differentiate through MDP\nproblems, and (ii) the high-dimensional policy space, as parameterized by a\nneural network, makes differentiating through a policy expensive. We resolve\nthe first challenge by sampling provably unbiased derivatives to approximate\nand differentiate through optimality conditions, and the second challenge by\nusing a low-rank approximation to the high-dimensional sample-based\nderivatives. We implement both Bellman--based and policy gradient--based\ndecision-focused learning on three different MDP problems with missing\nparameters, and show that decision-focused learning performs better in\ngeneralization to unseen tasks.",
          "link": "http://arxiv.org/abs/2106.03279",
          "publishedOn": "2021-06-15T01:45:21.135Z",
          "wordCount": 680,
          "title": "Learning MDPs from Features: Predict-Then-Optimize for Sequential Decision Problems by Reinforcement Learning. (arXiv:2106.03279v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.04850",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jesson_A/0/1/0/all/0/1\">Andrew Jesson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mindermann_S/0/1/0/all/0/1\">S&#xf6;ren Mindermann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gal_Y/0/1/0/all/0/1\">Yarin Gal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shalit_U/0/1/0/all/0/1\">Uri Shalit</a>",
          "description": "We study the problem of learning conditional average treatment effects (CATE)\nfrom high-dimensional, observational data with unobserved confounders.\nUnobserved confounders introduce ignorance -- a level of unidentifiability --\nabout an individual's response to treatment by inducing bias in CATE estimates.\nWe present a new parametric interval estimator suited for high-dimensional\ndata, that estimates a range of possible CATE values when given a predefined\nbound on the level of hidden confounding. Further, previous interval estimators\ndo not account for ignorance about the CATE associated with samples that may be\nunderrepresented in the original study, or samples that violate the overlap\nassumption. Our interval estimator also incorporates model uncertainty so that\npractitioners can be made aware of out-of-distribution data. We prove that our\nestimator converges to tight bounds on CATE when there may be unobserved\nconfounding, and assess it using semi-synthetic, high-dimensional datasets.",
          "link": "http://arxiv.org/abs/2103.04850",
          "publishedOn": "2021-06-15T01:45:21.129Z",
          "wordCount": 627,
          "title": "Quantifying Ignorance in Individual-Level Causal-Effect Estimates under Hidden Confounding. (arXiv:2103.04850v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.08633",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sirignano_J/0/1/0/all/0/1\">Justin Sirignano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+MacArt_J/0/1/0/all/0/1\">Jonathan MacArt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spiliopoulos_K/0/1/0/all/0/1\">Konstantinos Spiliopoulos</a>",
          "description": "Recent research has used deep learning to develop partial differential\nequation (PDE) models in science and engineering. The functional form of the\nPDE is determined by a neural network, and the neural network parameters are\ncalibrated to available data. Calibration of the embedded neural network can be\nperformed by optimizing over the PDE. Motivated by these applications, we\nrigorously study the optimization of a class of linear elliptic PDEs with\nneural network terms. The neural network parameters in the PDE are optimized\nusing gradient descent, where the gradient is evaluated using an adjoint PDE.\nAs the number of parameters become large, the PDE and adjoint PDE converge to a\nnon-local PDE system. Using this limit PDE system, we are able to prove\nconvergence of the neural network-PDE to a global minimum during the\noptimization. The limit PDE system contains a non-local linear operator whose\neigenvalues are positive but become arbitrarily small. The lack of a spectral\ngap for the eigenvalues poses the main challenge for the global convergence\nproof. Careful analysis of the spectral decomposition of the coupled PDE and\nadjoint PDE system is required. Finally, we use this adjoint method to train a\nneural network model for an application in fluid mechanics, in which the neural\nnetwork functions as a closure model for the Reynolds-averaged Navier-Stokes\n(RANS) equations. The RANS neural network model is trained on several datasets\nfor turbulent channel flow and is evaluated out-of-sample at different Reynolds\nnumbers.",
          "link": "http://arxiv.org/abs/2105.08633",
          "publishedOn": "2021-06-15T01:45:21.065Z",
          "wordCount": 695,
          "title": "PDE-constrained Models with Neural Network Terms: Optimization and Global Convergence. (arXiv:2105.08633v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.03129",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1\">Rui Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dash_S/0/1/0/all/0/1\">Sanjeeb Dash</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_T/0/1/0/all/0/1\">Tian Gao</a>",
          "description": "The problem of finding an ancestral acyclic directed mixed graph (ADMG) that\nrepresents the causal relationships between a set of variables is an important\narea of research on causal inference. Most existing score-based structure\nlearning methods focus on learning directed acyclic graph (DAG) models without\nlatent variables. A number of score-based methods have recently been proposed\nfor the ADMG learning, yet they are heuristic in nature and do not guarantee an\noptimal solution. We propose a novel exact score-based method that solves an\ninteger programming (IP) formulation and returns a score-maximizing ancestral\nADMG for a set of continuous variables that follow a multivariate Gaussian\ndistribution. We generalize the state-of-the-art IP model for DAG learning\nproblems and derive new classes of valid inequalities to formulate an IP model\nfor ADMG learning. Empirically, our model can be solved efficiently for\nmedium-sized problems and achieves better accuracy than state-of-the-art\nscore-based methods as well as benchmark constraint-based methods.",
          "link": "http://arxiv.org/abs/2102.03129",
          "publishedOn": "2021-06-15T01:45:20.460Z",
          "wordCount": 618,
          "title": "Integer Programming for Causal Structure Learning in the Presence of Latent Variables. (arXiv:2102.03129v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.02266",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Guo_Z/0/1/0/all/0/1\">Zhishuai Guo</a>, <a href=\"http://arxiv.org/find/math/1/au:+Hu_Q/0/1/0/all/0/1\">Quanqi Hu</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhang_L/0/1/0/all/0/1\">Lijun Zhang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Yang_T/0/1/0/all/0/1\">Tianbao Yang</a>",
          "description": "In this paper, we consider non-convex stochastic bilevel optimization (SBO)\nproblems that have many applications in machine learning. Although numerous\nstudies have proposed stochastic algorithms for solving these problems, they\nare limited in two perspectives: (i) their sample complexities are high, which\ndo not match the state-of-the-art result for non-convex stochastic\noptimization; (ii) their algorithms are tailored to problems with only one\nlower-level problem. When there are many lower-level problems, it could be\nprohibitive to process all these lower-level problems at each iteration. To\naddress these limitations, this paper proposes fast randomized stochastic\nalgorithms for non-convex SBO problems. First, we present a stochastic method\nfor non-convex SBO with only one lower problem and establish its sample\ncomplexity of $O(1/\\epsilon^3)$ for finding an $\\epsilon$-stationary point\nunder Lipschitz continuous conditions of stochastic oracles, matching the lower\nbound for stochastic smooth non-convex optimization. Second, we present a\nrandomized stochastic method for non-convex SBO with $m>1$ lower level problems\n(multi-task SBO) by processing a constant number of lower problems at each\niteration, and establish its sample complexity no worse than $O(m/\\epsilon^3)$,\nwhich could be a better complexity than that of simply processing all $m$ lower\nproblems at each iteration. Lastly, we establish even faster convergence\nresults for gradient-dominant functions. To the best of our knowledge, this is\nthe first work considering multi-task SBO and developing state-of-the-art\nsample complexity results.",
          "link": "http://arxiv.org/abs/2105.02266",
          "publishedOn": "2021-06-15T01:45:20.453Z",
          "wordCount": 674,
          "title": "Randomized Stochastic Variance-Reduced Methods for Multi-Task Stochastic Bilevel Optimization. (arXiv:2105.02266v2 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.15082",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_A/0/1/0/all/0/1\">An Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Junyang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Men_R/0/1/0/all/0/1\">Rui Men</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Chang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1\">Le Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_X/0/1/0/all/0/1\">Xianyan Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_A/0/1/0/all/0/1\">Ang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jie Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiamang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Di Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1\">Wei Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_L/0/1/0/all/0/1\">Lin Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jingren Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hongxia Yang</a>",
          "description": "Mixture-of-Experts (MoE) models can achieve promising results with outrageous\nlarge amount of parameters but constant computation cost, and thus it has\nbecome a trend in model scaling. Still it is a mystery how MoE layers bring\nquality gains by leveraging the parameters with sparse activation. In this\nwork, we investigate several key factors in sparse expert models. We observe\nthat load imbalance may not be a significant problem affecting model quality,\ncontrary to the perspectives of recent studies, while the number of sparsely\nactivated experts $k$ and expert capacity $C$ in top-$k$ routing can\nsignificantly make a difference in this context. Furthermore, we take a step\nforward to propose a simple method called expert prototyping that splits\nexperts into different prototypes and applies $k$ top-$1$ routing. This\nstrategy improves the model quality but maintains constant computational costs,\nand our further exploration on extremely large-scale models reflects that it is\nmore effective in training larger models. We push the model scale to over $1$\ntrillion parameters and implement it on solely $480$ NVIDIA V100-32GB GPUs, in\ncomparison with the recent SOTAs on $2048$ TPU cores. The proposed giant model\nachieves substantial speedup in convergence over the same-size baseline.",
          "link": "http://arxiv.org/abs/2105.15082",
          "publishedOn": "2021-06-15T01:45:20.439Z",
          "wordCount": 674,
          "title": "Exploring Sparse Expert Models and Beyond. (arXiv:2105.15082v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.11982",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1\">Dongxia Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1\">Liyao Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_X/0/1/0/all/0/1\">Xinyue Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chinazzi_M/0/1/0/all/0/1\">Matteo Chinazzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vespignani_A/0/1/0/all/0/1\">Alessandro Vespignani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yi-An Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_R/0/1/0/all/0/1\">Rose Yu</a>",
          "description": "Deep learning is gaining increasing popularity for spatiotemporal\nforecasting. However, prior works have mostly focused on point estimates\nwithout quantifying the uncertainty of the predictions. In high stakes domains,\nbeing able to generate probabilistic forecasts with confidence intervals is\ncritical to risk assessment and decision making. Hence, a systematic study of\nuncertainty quantification (UQ) methods for spatiotemporal forecasting is\nmissing in the community. In this paper, we describe two types of\nspatiotemporal forecasting problems: regular grid-based and graph-based. Then\nwe analyze UQ methods from both the Bayesian and the frequentist point of view,\ncasting in a unified framework via statistical decision theory. Through\nextensive experiments on real-world road network traffic, epidemics, and air\nquality forecasting tasks, we reveal the statistical and computational\ntrade-offs for different UQ methods: Bayesian methods are typically more robust\nin mean prediction, while confidence levels obtained from frequentist methods\nprovide more extensive coverage over data variations. Computationally, quantile\nregression type methods are cheaper for a single confidence interval but\nrequire re-training for different intervals. Sampling based methods generate\nsamples that can form multiple confidence intervals, albeit at a higher\ncomputational cost.",
          "link": "http://arxiv.org/abs/2105.11982",
          "publishedOn": "2021-06-15T01:45:20.433Z",
          "wordCount": 661,
          "title": "Quantifying Uncertainty in Deep Spatiotemporal Forecasting. (arXiv:2105.11982v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.08452",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Leino_K/0/1/0/all/0/1\">Klas Leino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zifan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fredrikson_M/0/1/0/all/0/1\">Matt Fredrikson</a>",
          "description": "The threat of adversarial examples has motivated work on training certifiably\nrobust neural networks to facilitate efficient verification of local robustness\nat inference time. We formalize a notion of global robustness, which captures\nthe operational properties of on-line local robustness certification while\nyielding a natural learning objective for robust training. We show that\nwidely-used architectures can be easily adapted to this objective by\nincorporating efficient global Lipschitz bounds into the network, yielding\ncertifiably-robust models by construction that achieve state-of-the-art\nverifiable accuracy. Notably, this approach requires significantly less time\nand memory than recent certifiable training methods, and leads to negligible\ncosts when certifying points on-line; for example, our evaluation shows that it\nis possible to train a large robust Tiny-Imagenet model in a matter of hours.\nOur models effectively leverage inexpensive global Lipschitz bounds for\nreal-time certification, despite prior suggestions that tighter local bounds\nare needed for good performance; we posit this is possible because our models\nare specifically trained to achieve tighter global bounds. Namely, we prove\nthat the maximum achievable verifiable accuracy for a given dataset is not\nimproved by using a local bound.",
          "link": "http://arxiv.org/abs/2102.08452",
          "publishedOn": "2021-06-15T01:45:20.416Z",
          "wordCount": 639,
          "title": "Globally-Robust Neural Networks. (arXiv:2102.08452v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.07496",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Skarding_J/0/1/0/all/0/1\">Joakim Skarding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gabrys_B/0/1/0/all/0/1\">Bogdan Gabrys</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Musial_K/0/1/0/all/0/1\">Katarzyna Musial</a>",
          "description": "Dynamic networks are used in a wide range of fields, including social network\nanalysis, recommender systems, and epidemiology. Representing complex networks\nas structures changing over time allow network models to leverage not only\nstructural but also temporal patterns. However, as dynamic network literature\nstems from diverse fields and makes use of inconsistent terminology, it is\nchallenging to navigate. Meanwhile, graph neural networks (GNNs) have gained a\nlot of attention in recent years for their ability to perform well on a range\nof network science tasks, such as link prediction and node classification.\nDespite the popularity of graph neural networks and the proven benefits of\ndynamic network models, there has been little focus on graph neural networks\nfor dynamic networks. To address the challenges resulting from the fact that\nthis research crosses diverse fields as well as to survey dynamic graph neural\nnetworks, this work is split into two main parts. First, to address the\nambiguity of the dynamic network terminology we establish a foundation of\ndynamic networks with consistent, detailed terminology and notation. Second, we\npresent a comprehensive survey of dynamic graph neural network models using the\nproposed terminology",
          "link": "http://arxiv.org/abs/2005.07496",
          "publishedOn": "2021-06-15T01:45:20.410Z",
          "wordCount": 680,
          "title": "Foundations and modelling of dynamic networks using Dynamic Graph Neural Networks: A survey. (arXiv:2005.07496v2 [cs.SI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.13010",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jian Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_Y/0/1/0/all/0/1\">Yuling Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yunfei Yang</a>",
          "description": "This paper studies how well generative adversarial networks (GANs) learn\nprobability distributions from finite samples. Our main results establish the\nconvergence rates of GANs under a collection of integral probability metrics\ndefined through H\\\"older classes, including the Wasserstein distance as a\nspecial case. We also show that GANs are able to adaptively learn data\ndistributions with low-dimensional structures or have H\\\"older densities, when\nthe network architectures are chosen properly. In particular, for distributions\nconcentrated around a low-dimensional set, we show that the learning rates of\nGANs do not depend on the high ambient dimension, but on the lower intrinsic\ndimension. Our analysis is based on a new oracle inequality decomposing the\nestimation error into the generator and discriminator approximation error and\nthe statistical error, which may be of independent interest.",
          "link": "http://arxiv.org/abs/2105.13010",
          "publishedOn": "2021-06-15T01:45:20.404Z",
          "wordCount": 613,
          "title": "An error analysis of generative adversarial networks for learning distributions. (arXiv:2105.13010v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.00123",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Killamsetty_K/0/1/0/all/0/1\">Krishnateja Killamsetty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sivasubramanian_D/0/1/0/all/0/1\">Durga Sivasubramanian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramakrishnan_G/0/1/0/all/0/1\">Ganesh Ramakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+De_A/0/1/0/all/0/1\">Abir De</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iyer_R/0/1/0/all/0/1\">Rishabh Iyer</a>",
          "description": "The great success of modern machine learning models on large datasets is\ncontingent on extensive computational resources with high financial and\nenvironmental costs. One way to address this is by extracting subsets that\ngeneralize on par with the full data. In this work, we propose a general\nframework, GRAD-MATCH, which finds subsets that closely match the gradient of\nthe training or validation set. We find such subsets effectively using an\northogonal matching pursuit algorithm. We show rigorous theoretical and\nconvergence guarantees of the proposed algorithm and, through our extensive\nexperiments on real-world datasets, show the effectiveness of our proposed\nframework. We show that GRAD-MATCH significantly and consistently outperforms\nseveral recent data-selection algorithms and achieves the best\naccuracy-efficiency trade-off. GRAD-MATCH is available as a part of the CORDS\ntoolkit: \\url{https://github.com/decile-team/cords}.",
          "link": "http://arxiv.org/abs/2103.00123",
          "publishedOn": "2021-06-15T01:45:20.397Z",
          "wordCount": 611,
          "title": "GRAD-MATCH: Gradient Matching based Data Subset Selection for Efficient Deep Model Training. (arXiv:2103.00123v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.03821",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yuheng Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jinpeng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1\">ChuXiong Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1\">Jie Hu</a>",
          "description": "Learning node representations that incorporate information from graph\nstructure benefits wide range of tasks on graph. The majority of existing graph\nneural networks (GNNs) have limited power in capturing position information for\na given node. The idea of positioning nodes with selected anchors has been\nexploited, yet mainly relying on explicit labeling of distance information.\nHere we propose Graph Inference Representation (GIR), an anchor based GNN model\nencoding path information related to pre-selected anchors for each node.\nAbilities to get position-aware embeddings are theoretically and experimentally\ninvestigated on GIR and its core variants. Further, the complementarity between\nGIRs and typical GNNs is demonstrated. We show that GIRs get outperformed\nresults in position-aware scenarios, and performances on typical GNNs could be\nimproved by fusing GIR embeddings.",
          "link": "http://arxiv.org/abs/2105.03821",
          "publishedOn": "2021-06-15T01:45:20.374Z",
          "wordCount": 590,
          "title": "Graph Inference Representation: Learning Graph Positional Embeddings with Anchor Path Encoding. (arXiv:2105.03821v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.11417",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singla_S/0/1/0/all/0/1\">Sahil Singla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feizi_S/0/1/0/all/0/1\">Soheil Feizi</a>",
          "description": "Training convolutional neural networks with a Lipschitz constraint under the\n$l_{2}$ norm is useful for provable adversarial robustness, interpretable\ngradients, stable training, etc. While 1-Lipschitz networks can be designed by\nimposing a 1-Lipschitz constraint on each layer, training such networks\nrequires each layer to be gradient norm preserving (GNP) to prevent gradients\nfrom vanishing. However, existing GNP convolutions suffer from slow training,\nlead to significant reduction in accuracy and provide no guarantees on their\napproximations. In this work, we propose a GNP convolution layer called Skew\nOrthogonal Convolution (SOC) that uses the following mathematical property:\nwhen a matrix is {\\it Skew-Symmetric}, its exponential function is an {\\it\northogonal} matrix. To use this property, we first construct a convolution\nfilter whose Jacobian is Skew-Symmetric. Then, we use the Taylor series\nexpansion of the Jacobian exponential to construct the SOC layer that is\northogonal. To efficiently implement SOC, we keep a finite number of terms from\nthe Taylor series and provide a provable guarantee on the approximation error.\nOur experiments on CIFAR-10 and CIFAR-100 show that SOC allows us to train\nprovably Lipschitz, large convolutional neural networks significantly faster\nthan prior works while achieving significant improvements for both standard and\ncertified robust accuracies.",
          "link": "http://arxiv.org/abs/2105.11417",
          "publishedOn": "2021-06-15T01:45:20.367Z",
          "wordCount": 642,
          "title": "Skew Orthogonal Convolutions. (arXiv:2105.11417v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1911.10258",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singla_S/0/1/0/all/0/1\">Sahil Singla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feizi_S/0/1/0/all/0/1\">Soheil Feizi</a>",
          "description": "In deep neural networks, the spectral norm of the Jacobian of a layer bounds\nthe factor by which the norm of a signal changes during forward/backward\npropagation. Spectral norm regularizations have been shown to improve\ngeneralization, robustness and optimization of deep learning methods. Existing\nmethods to compute the spectral norm of convolution layers either rely on\nheuristics that are efficient in computation but lack guarantees or are\ntheoretically-sound but computationally expensive. In this work, we obtain the\nbest of both worlds by deriving {\\it four} provable upper bounds on the\nspectral norm of a standard 2D multi-channel convolution layer. These bounds\nare differentiable and can be computed efficiently during training with\nnegligible overhead. One of these bounds is in fact the popular heuristic\nmethod of Miyato et al. (multiplied by a constant factor depending on filter\nsizes). Each of these four bounds can achieve the tightest gap depending on\nconvolution filters. Thus, we propose to use the minimum of these four bounds\nas a tight, differentiable and efficient upper bound on the spectral norm of\nconvolution layers. We show that our spectral bound is an effective regularizer\nand can be used to bound either the lipschitz constant or curvature values\n(eigenvalues of the Hessian) of neural networks. Through experiments on MNIST\nand CIFAR-10, we demonstrate the effectiveness of our spectral bound in\nimproving generalization and provable robustness of deep networks.",
          "link": "http://arxiv.org/abs/1911.10258",
          "publishedOn": "2021-06-15T01:45:20.361Z",
          "wordCount": 700,
          "title": "Fantastic Four: Differentiable Bounds on Singular Values of Convolution Layers. (arXiv:1911.10258v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.12013",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chi_J/0/1/0/all/0/1\">Jianfeng Chi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yuan Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gordon_G/0/1/0/all/0/1\">Geoffrey J. Gordon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Han Zhao</a>",
          "description": "With the widespread deployment of large-scale prediction systems in\nhigh-stakes domains, e.g., face recognition, criminal justice, etc., disparity\nin prediction accuracy between different demographic subgroups has called for\nfundamental understanding on the source of such disparity and algorithmic\nintervention to mitigate it. In this paper, we study the accuracy disparity\nproblem in regression. To begin with, we first propose an error decomposition\ntheorem, which decomposes the accuracy disparity into the distance between\nmarginal label distributions and the distance between conditional\nrepresentations, to help explain why such accuracy disparity appears in\npractice. Motivated by this error decomposition and the general idea of\ndistribution alignment with statistical distances, we then propose an algorithm\nto reduce this disparity, and analyze its game-theoretic optima of the proposed\nobjective functions. To corroborate our theoretical findings, we also conduct\nexperiments on five benchmark datasets. The experimental results suggest that\nour proposed algorithms can effectively mitigate accuracy disparity while\nmaintaining the predictive power of the regression models.",
          "link": "http://arxiv.org/abs/2102.12013",
          "publishedOn": "2021-06-15T01:45:20.354Z",
          "wordCount": 626,
          "title": "Understanding and Mitigating Accuracy Disparity in Regression. (arXiv:2102.12013v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.08622",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tai_K/0/1/0/all/0/1\">Kai Sheng Tai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bailis_P/0/1/0/all/0/1\">Peter Bailis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valiant_G/0/1/0/all/0/1\">Gregory Valiant</a>",
          "description": "Self-training is a standard approach to semi-supervised learning where the\nlearner's own predictions on unlabeled data are used as supervision during\ntraining. In this paper, we reinterpret this label assignment process as an\noptimal transportation problem between examples and classes, wherein the cost\nof assigning an example to a class is mediated by the current predictions of\nthe classifier. This formulation facilitates a practical annealing strategy for\nlabel assignment and allows for the inclusion of prior knowledge on class\nproportions via flexible upper bound constraints. The solutions to these\nassignment problems can be efficiently approximated using Sinkhorn iteration,\nthus enabling their use in the inner loop of standard stochastic optimization\nalgorithms. We demonstrate the effectiveness of our algorithm on the CIFAR-10,\nCIFAR-100, and SVHN datasets in comparison with FixMatch, a state-of-the-art\nself-training algorithm. Our code is available at\nhttps://github.com/stanford-futuredata/sinkhorn-label-allocation.",
          "link": "http://arxiv.org/abs/2102.08622",
          "publishedOn": "2021-06-15T01:45:20.347Z",
          "wordCount": 604,
          "title": "Sinkhorn Label Allocation: Semi-Supervised Classification via Annealed Self-Training. (arXiv:2102.08622v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.01714",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Polar_A/0/1/0/all/0/1\">Andrew Polar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poluektov_M/0/1/0/all/0/1\">Michael Poluektov</a>",
          "description": "The terms tree and forest are normally associated with an ensemble of\nclassifiers. In this article Urysohn tree is a regression model representing\nmultiple discrete Urysohn operators connected as a tree, where the inputs of\none operator are outputs of the others. This structure, referred as Urysohn\ntree, is not completely new. One example of such tree is known for more than\nhalf a century. It is Kolmogorov-Arnold representation. The authors of this\npaper in their recently published research offered the new computational\ntechnique for generating of Kolmogorov-Arnold representation as a deep machine\nlearning process. This article is two steps further into this research. First\nis a Urysohn tree with multiple hidden layers which is generalization of\nKolmogorov-Arnold model and second is a boosting algorithm for building of the\nforest of such trees for modeling of aleatoric uncertainty of the data.",
          "link": "http://arxiv.org/abs/2104.01714",
          "publishedOn": "2021-06-15T01:45:20.331Z",
          "wordCount": 584,
          "title": "Urysohn Forest for Aleatoric Uncertainty Quantification. (arXiv:2104.01714v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.01338",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_N/0/1/0/all/0/1\">Naman Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goel_S/0/1/0/all/0/1\">Surbhi Goel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Cyril Zhang</a>",
          "description": "In practical applications of iterative first-order optimization, the learning\nrate schedule remains notoriously difficult to understand and expensive to\ntune. We demonstrate the presence of these subtleties even in the innocuous\ncase when the objective is a convex quadratic. We reinterpret an iterative\nalgorithm from the numerical analysis literature as what we call the Chebyshev\nlearning rate schedule for accelerating vanilla gradient descent, and show that\nthe problem of mitigating instability leads to a fractal ordering of step\nsizes. We provide some experiments to challenge conventional beliefs about\nstable learning rates in deep learning: the fractal schedule enables training\nto converge with locally unstable updates which make negative progress on the\nobjective.",
          "link": "http://arxiv.org/abs/2103.01338",
          "publishedOn": "2021-06-15T01:45:20.322Z",
          "wordCount": 575,
          "title": "Acceleration via Fractal Learning Rate Schedules. (arXiv:2103.01338v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02549",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Frank_T/0/1/0/all/0/1\">Thorben Frank</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chmiela_S/0/1/0/all/0/1\">Stefan Chmiela</a>",
          "description": "Attention mechanisms are developing into a viable alternative to\nconvolutional layers as elementary building block of NNs. Their main advantage\nis that they are not restricted to capture local dependencies in the input, but\ncan draw arbitrary connections. This unprecedented capability coincides with\nthe long-standing problem of modeling global atomic interactions in molecular\nforce fields and other many-body problems. In its original formulation,\nhowever, attention is not applicable to the continuous domains in which the\natoms live. For this purpose we propose a variant to describe geometric\nrelations for arbitrary atomic configurations in Euclidean space that also\nrespects all relevant physical symmetries. We furthermore demonstrate, how the\nsuccessive application of our learned attention matrices effectively translates\nthe molecular geometry into a set of individual atomic contributions\non-the-fly.",
          "link": "http://arxiv.org/abs/2106.02549",
          "publishedOn": "2021-06-15T01:45:20.317Z",
          "wordCount": 578,
          "title": "Detect the Interactions that Matter in Matter: Geometric Attention for Many-Body Systems. (arXiv:2106.02549v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.00455",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Strobl_E/0/1/0/all/0/1\">Eric V. Strobl</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lasko_T/0/1/0/all/0/1\">Thomas A. Lasko</a>",
          "description": "We consider estimating the conditional average treatment effect for everyone\nby eliminating confounding and selection bias. Unfortunately, randomized\nclinical trials (RCTs) eliminate confounding but impose strict exclusion\ncriteria that prevent sampling of the entire clinical population. Observational\ndatasets are more inclusive but suffer from confounding. We therefore analyze\nRCT and observational data simultaneously in order to extract the strengths of\neach. Our solution builds upon Difference in Differences (DD), an algorithm\nthat eliminates confounding from observational data by comparing outcomes\nbefore and after treatment administration. DD requires a parallel slopes\nassumption that may not apply in practice when confounding shifts across time.\nWe instead propose Synthesized Difference in Differences (SDD) that infers the\ncorrect (possibly non-parallel) slopes by linearly adjusting a conditional\nversion of DD using additional RCT data. The algorithm achieves state of the\nart performance across multiple synthetic and real datasets even when the RCT\nexcludes the majority of patients.",
          "link": "http://arxiv.org/abs/2105.00455",
          "publishedOn": "2021-06-15T01:45:20.310Z",
          "wordCount": 596,
          "title": "Synthesized Difference in Differences. (arXiv:2105.00455v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.12672",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lo_S/0/1/0/all/0/1\">Shaw-Hwa Lo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1\">Yiqiao Yin</a>",
          "description": "In the field of eXplainable AI (XAI), robust ``blackbox'' algorithms such as\nConvolutional Neural Networks (CNNs) are known for making high prediction\nperformance. However, the ability to explain and interpret these algorithms\nstill require innovation in the understanding of influential and, more\nimportantly, explainable features that directly or indirectly impact the\nperformance of predictivity. A number of methods existing in literature focus\non visualization techniques but the concepts of explainability and\ninterpretability still require rigorous definition. In view of the above needs,\nthis paper proposes an interaction-based methodology -- Influence Score\n(I-score) -- to screen out the noisy and non-informative variables in the\nimages hence it nourishes an environment with explainable and interpretable\nfeatures that are directly associated to feature predictivity. We apply the\nproposed method on a real world application in Pneumonia Chest X-ray Image data\nset and produced state-of-the-art results. We demonstrate how to apply the\nproposed approach for more general big data problems by improving the\nexplainability and interpretability without sacrificing the prediction\nperformance. The contribution of this paper opens a novel angle that moves the\ncommunity closer to the future pipelines of XAI problems.",
          "link": "http://arxiv.org/abs/2104.12672",
          "publishedOn": "2021-06-15T01:45:20.304Z",
          "wordCount": 656,
          "title": "A Novel Interaction-based Methodology Towards Explainable AI with Better Understanding of Pneumonia Chest X-ray Images. (arXiv:2104.12672v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.03212",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bodnar_C/0/1/0/all/0/1\">Cristian Bodnar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frasca_F/0/1/0/all/0/1\">Fabrizio Frasca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu Guang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Otter_N/0/1/0/all/0/1\">Nina Otter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Montufar_G/0/1/0/all/0/1\">Guido Mont&#xfa;far</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lio_P/0/1/0/all/0/1\">Pietro Li&#xf2;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bronstein_M/0/1/0/all/0/1\">Michael Bronstein</a>",
          "description": "The pairwise interaction paradigm of graph machine learning has predominantly\ngoverned the modelling of relational systems. However, graphs alone cannot\ncapture the multi-level interactions present in many complex systems and the\nexpressive power of such schemes was proven to be limited. To overcome these\nlimitations, we propose Message Passing Simplicial Networks (MPSNs), a class of\nmodels that perform message passing on simplicial complexes (SCs). To\ntheoretically analyse the expressivity of our model we introduce a Simplicial\nWeisfeiler-Lehman (SWL) colouring procedure for distinguishing non-isomorphic\nSCs. We relate the power of SWL to the problem of distinguishing non-isomorphic\ngraphs and show that SWL and MPSNs are strictly more powerful than the WL test\nand not less powerful than the 3-WL test. We deepen the analysis by comparing\nour model with traditional graph neural networks (GNNs) with ReLU activations\nin terms of the number of linear regions of the functions they can represent.\nWe empirically support our theoretical claims by showing that MPSNs can\ndistinguish challenging strongly regular graphs for which GNNs fail and, when\nequipped with orientation equivariant layers, they can improve classification\naccuracy in oriented SCs compared to a GNN baseline.",
          "link": "http://arxiv.org/abs/2103.03212",
          "publishedOn": "2021-06-15T01:45:20.280Z",
          "wordCount": 669,
          "title": "Weisfeiler and Lehman Go Topological: Message Passing Simplicial Networks. (arXiv:2103.03212v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06991",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_N/0/1/0/all/0/1\">Nianhui Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bethge_J/0/1/0/all/0/1\">Joseph Bethge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Haojin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_K/0/1/0/all/0/1\">Kai Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ning_X/0/1/0/all/0/1\">Xuefei Ning</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meinel_C/0/1/0/all/0/1\">Christoph Meinel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu Wang</a>",
          "description": "Recent works on Binary Neural Networks (BNNs) have made promising progress in\nnarrowing the accuracy gap of BNNs to their 32-bit counterparts. However, the\naccuracy gains are often based on specialized model designs using additional\n32-bit components. Furthermore, almost all previous BNNs use 32-bit for feature\nmaps and the shortcuts enclosing the corresponding binary convolution blocks,\nwhich helps to effectively maintain the accuracy, but is not friendly to\nhardware accelerators with limited memory, energy, and computing resources.\nThus, we raise the following question: How can accuracy and energy consumption\nbe balanced in a BNN network design? We extensively study this fundamental\nproblem in this work and propose a novel BNN architecture without most commonly\nused 32-bit components: \\textit{BoolNet}. Experimental results on ImageNet\ndemonstrate that BoolNet can achieve 4.6x energy reduction coupled with 1.2\\%\nhigher accuracy than the commonly used BNN architecture Bi-RealNet. Code and\ntrained models are available at: https://github.com/hpi-xnor/BoolNet.",
          "link": "http://arxiv.org/abs/2106.06991",
          "publishedOn": "2021-06-15T01:45:20.268Z",
          "wordCount": 588,
          "title": "BoolNet: Minimizing The Energy Consumption of Binary Neural Networks. (arXiv:2106.06991v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2012.01926",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pahar_M/0/1/0/all/0/1\">Madhurananda Pahar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klopper_M/0/1/0/all/0/1\">Marisa Klopper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Warren_R/0/1/0/all/0/1\">Robin Warren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niesler_T/0/1/0/all/0/1\">Thomas Niesler</a>",
          "description": "We present a machine learning based COVID-19 cough classifier which can\ndiscriminate COVID-19 positive coughs from both COVID-19 negative and healthy\ncoughs recorded on a smartphone. This type of screening is non-contact, easy to\napply, and can reduce the workload in testing centres as well as limit\ntransmission by recommending early self-isolation to those who have a cough\nsuggestive of COVID-19. The datasets used in this study include subjects from\nall six continents and contain both forced and natural coughs, indicating that\nthe approach is widely applicable. The publicly available Coswara dataset\ncontains 92 COVID-19 positive and 1079 healthy subjects, while the second\nsmaller dataset was collected mostly in South Africa and contains 18 COVID-19\npositive and 26 COVID-19 negative subjects who have undergone a SARS-CoV\nlaboratory test. Both datasets indicate that COVID-19 positive coughs are\n15\\%-20\\% shorter than non-COVID coughs. Dataset skew was addressed by applying\nthe synthetic minority oversampling technique (SMOTE). A leave-$p$-out\ncross-validation scheme was used to train and evaluate seven machine learning\nclassifiers: LR, KNN, SVM, MLP, CNN, LSTM and Resnet50. Our results show that\nalthough all classifiers were able to identify COVID-19 coughs, the best\nperformance was exhibited by the Resnet50 classifier, which was best able to\ndiscriminate between the COVID-19 positive and the healthy coughs with an area\nunder the ROC curve (AUC) of 0.98. An LSTM classifier was best able to\ndiscriminate between the COVID-19 positive and COVID-19 negative coughs, with\nan AUC of 0.94 after selecting the best 13 features from a sequential forward\nselection (SFS). Since this type of cough audio classification is\ncost-effective and easy to deploy, it is potentially a useful and viable means\nof non-contact COVID-19 screening.",
          "link": "http://arxiv.org/abs/2012.01926",
          "publishedOn": "2021-06-15T01:45:20.262Z",
          "wordCount": 802,
          "title": "COVID-19 Cough Classification using Machine Learning and Global Smartphone Recordings. (arXiv:2012.01926v2 [cs.SD] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2004.00202",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Choi_C/0/1/0/all/0/1\">Chiho Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1\">Joon Hee Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malla_S/0/1/0/all/0/1\">Srikanth Malla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiachen Li</a>",
          "description": "Predicting future trajectories of traffic agents in highly interactive\nenvironments is an essential and challenging problem for the safe operation of\nautonomous driving systems. On the basis of the fact that self-driving vehicles\nare equipped with various types of sensors (e.g., LiDAR scanner, RGB camera,\nradar, etc.), we propose a Cross-Modal Embedding framework that aims to benefit\nfrom the use of multiple input modalities. At training time, our model learns\nto embed a set of complementary features in a shared latent space by jointly\noptimizing the objective functions across different types of input data. At\ntest time, a single input modality (e.g., LiDAR data) is required to generate\npredictions from the input perspective (i.e., in the LiDAR space), while taking\nadvantages from the model trained with multiple sensor modalities. An extensive\nevaluation is conducted to show the efficacy of the proposed framework using\ntwo benchmark driving datasets.",
          "link": "http://arxiv.org/abs/2004.00202",
          "publishedOn": "2021-06-15T01:45:20.237Z",
          "wordCount": 629,
          "title": "Shared Cross-Modal Trajectory Prediction for Autonomous Driving. (arXiv:2004.00202v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2003.03196",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yoon_J/0/1/0/all/0/1\">Jaehong Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeong_W/0/1/0/all/0/1\">Wonyong Jeong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_G/0/1/0/all/0/1\">Giwoong Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_E/0/1/0/all/0/1\">Eunho Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1\">Sung Ju Hwang</a>",
          "description": "There has been a surge of interest in continual learning and federated\nlearning, both of which are important in deep neural networks in real-world\nscenarios. Yet little research has been done regarding the scenario where each\nclient learns on a sequence of tasks from a private local data stream. This\nproblem of federated continual learning poses new challenges to continual\nlearning, such as utilizing knowledge from other clients, while preventing\ninterference from irrelevant knowledge. To resolve these issues, we propose a\nnovel federated continual learning framework, Federated Weighted Inter-client\nTransfer (FedWeIT), which decomposes the network weights into global federated\nparameters and sparse task-specific parameters, and each client receives\nselective knowledge from other clients by taking a weighted combination of\ntheir task-specific parameters. FedWeIT minimizes interference between\nincompatible tasks, and also allows positive knowledge transfer across clients\nduring learning. We validate our FedWeIT against existing federated learning\nand continual learning methods under varying degrees of task similarity across\nclients, and our model significantly outperforms them with a large reduction in\nthe communication cost. Code is available at https://github.com/wyjeong/FedWeIT",
          "link": "http://arxiv.org/abs/2003.03196",
          "publishedOn": "2021-06-15T01:45:20.231Z",
          "wordCount": 668,
          "title": "Federated Continual Learning with Weighted Inter-client Transfer. (arXiv:2003.03196v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06718",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Vago_N/0/1/0/all/0/1\">Nicol&#xf2; Oreste Pinciroli Vago</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Hameed_I/0/1/0/all/0/1\">Ibrahim A. Hameed</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Kachelriess_M/0/1/0/all/0/1\">Michael Kachelriess</a>",
          "description": "The presence of non-zero helicity in intergalactic magnetic fields is a\nsmoking gun for their primordial origin since they have to be generated by\nprocesses that break CP invariance. As an experimental signature for the\npresence of helical magnetic fields, an estimator $Q$ based on the triple\nscalar product of the wave-vectors of photons generated in electromagnetic\ncascades from, e.g., TeV blazars, has been suggested previously. We propose to\napply deep learning to helicity classification employing Convolutional Neural\nNetworks and show that this method outperforms the $Q$ estimator.",
          "link": "http://arxiv.org/abs/2106.06718",
          "publishedOn": "2021-06-15T01:45:20.224Z",
          "wordCount": 567,
          "title": "Using Convolutional Neural Networks for the Helicity Classification of Magnetic Fields. (arXiv:2106.06718v1 [astro-ph.HE])"
        },
        {
          "id": "http://arxiv.org/abs/2103.05331",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kossen_J/0/1/0/all/0/1\">Jannik Kossen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Farquhar_S/0/1/0/all/0/1\">Sebastian Farquhar</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gal_Y/0/1/0/all/0/1\">Yarin Gal</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rainforth_T/0/1/0/all/0/1\">Tom Rainforth</a>",
          "description": "We introduce a new framework for sample-efficient model evaluation that we\ncall active testing. While approaches like active learning reduce the number of\nlabels needed for model training, existing literature largely ignores the cost\nof labeling test data, typically unrealistically assuming large test sets for\nmodel evaluation. This creates a disconnect to real applications, where test\nlabels are important and just as expensive, e.g. for optimizing\nhyperparameters. Active testing addresses this by carefully selecting the test\npoints to label, ensuring model evaluation is sample-efficient. To this end, we\nderive theoretically-grounded and intuitive acquisition strategies that are\nspecifically tailored to the goals of active testing, noting these are distinct\nto those of active learning. As actively selecting labels introduces a bias; we\nfurther show how to remove this bias while reducing the variance of the\nestimator at the same time. Active testing is easy to implement and can be\napplied to any supervised machine learning method. We demonstrate its\neffectiveness on models including WideResNets and Gaussian processes on\ndatasets including Fashion-MNIST and CIFAR-100.",
          "link": "http://arxiv.org/abs/2103.05331",
          "publishedOn": "2021-06-15T01:45:20.216Z",
          "wordCount": 623,
          "title": "Active Testing: Sample-Efficient Model Evaluation. (arXiv:2103.05331v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.08554",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Katiyar_A/0/1/0/all/0/1\">Ashish Katiyar</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Basu_S/0/1/0/all/0/1\">Soumya Basu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shah_V/0/1/0/all/0/1\">Vatsal Shah</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Caramanis_C/0/1/0/all/0/1\">Constantine Caramanis</a>",
          "description": "We study the problem of learning tree-structured Markov random fields (MRF)\non discrete random variables with common support when the observations are\ncorrupted by a $k$-ary symmetric noise channel with unknown probability of\nerror. For Ising models (support size = 2), past work has shown that graph\nstructure can only be recovered up to the leaf clusters (a leaf node, its\nparent, and its siblings form a leaf cluster) and exact recovery is impossible.\nNo prior work has addressed the setting of support size of 3 or more, and\nindeed this setting is far richer. As we show, when the support size is 3 or\nmore, the structure of the leaf clusters may be partially or fully\nidentifiable. We provide a precise characterization of this phenomenon and show\nthat the extent of recoverability is dictated by the joint PMF of the random\nvariables. In particular, we provide necessary and sufficient conditions for\nexact recoverability. Furthermore, we present a polynomial time, sample\nefficient algorithm that recovers the exact tree when this is possible, or up\nto the unidentifiability as promised by our characterization, when full\nrecoverability is impossible. Finally, we demonstrate the efficacy of our\nalgorithm experimentally.",
          "link": "http://arxiv.org/abs/2102.08554",
          "publishedOn": "2021-06-15T01:45:20.198Z",
          "wordCount": 655,
          "title": "Recoverability Landscape of Tree Structured Markov Random Fields under Symmetric Noise. (arXiv:2102.08554v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03207",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chang_J/0/1/0/all/0/1\">Jonathan D. Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uehara_M/0/1/0/all/0/1\">Masatoshi Uehara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sreenivas_D/0/1/0/all/0/1\">Dhruv Sreenivas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kidambi_R/0/1/0/all/0/1\">Rahul Kidambi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1\">Wen Sun</a>",
          "description": "This paper studies offline Imitation Learning (IL) where an agent learns to\nimitate an expert demonstrator without additional online environment\ninteractions. Instead, the learner is presented with a static offline dataset\nof state-action-next state transition triples from a potentially less\nproficient behavior policy. We introduce Model-based IL from Offline data\n(MILO): an algorithmic framework that utilizes the static dataset to solve the\noffline IL problem efficiently both in theory and in practice. In theory, even\nif the behavior policy is highly sub-optimal compared to the expert, we show\nthat as long as the data from the behavior policy provides sufficient coverage\non the expert state-action traces (and with no necessity for a global coverage\nover the entire state-action space), MILO can provably combat the covariate\nshift issue in IL. Complementing our theory results, we also demonstrate that a\npractical implementation of our approach mitigates covariate shift on benchmark\nMuJoCo continuous control tasks. We demonstrate that with behavior policies\nwhose performances are less than half of that of the expert, MILO still\nsuccessfully imitates with an extremely low number of expert state-action pairs\nwhile traditional offline IL method such as behavior cloning (BC) fails\ncompletely. Source code is provided at https://github.com/jdchang1/milo.",
          "link": "http://arxiv.org/abs/2106.03207",
          "publishedOn": "2021-06-15T01:45:20.186Z",
          "wordCount": 666,
          "title": "Mitigating Covariate Shift in Imitation Learning via Offline Data Without Great Coverage. (arXiv:2106.03207v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.04097",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Garriga_Alonso_A/0/1/0/all/0/1\">Adri&#xe0; Garriga-Alonso</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wilk_M/0/1/0/all/0/1\">Mark van der Wilk</a>",
          "description": "Infinite width limits of deep neural networks often have tractable forms.\nThey have been used to analyse the behaviour of finite networks, as well as\nbeing useful methods in their own right. When investigating infinitely wide\nconvolutional neural networks (CNNs), it was observed that the correlations\narising from spatial weight sharing disappear in the infinite limit. This is\nundesirable, as spatial correlation is the main motivation behind CNNs. We show\nthat the loss of this property is not a consequence of the infinite limit, but\nrather of choosing an independent weight prior. Correlating the weights\nmaintains the correlations in the activations. Varying the amount of\ncorrelation interpolates between independent-weight limits and mean-pooling.\nEmpirical evaluation of the infinitely wide network shows that optimal\nperformance is achieved between the extremes, indicating that correlations can\nbe useful.",
          "link": "http://arxiv.org/abs/2101.04097",
          "publishedOn": "2021-06-15T01:45:20.179Z",
          "wordCount": 593,
          "title": "Correlated Weights in Infinite Limits of Deep Convolutional Neural Networks. (arXiv:2101.04097v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.07850",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Corenflos_A/0/1/0/all/0/1\">Adrien Corenflos</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Thornton_J/0/1/0/all/0/1\">James Thornton</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Doucet_A/0/1/0/all/0/1\">Arnaud Doucet</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Deligiannidis_G/0/1/0/all/0/1\">George Deligiannidis</a>",
          "description": "Particle Filtering (PF) methods are an established class of procedures for\nperforming inference in non-linear state-space models. Resampling is a key\ningredient of PF, necessary to obtain low variance likelihood and states\nestimates. However, traditional resampling methods result in PF-based loss\nfunctions being non-differentiable with respect to model and PF parameters. In\na variational inference context, resampling also yields high variance gradient\nestimates of the PF-based evidence lower bound. By leveraging optimal transport\nideas, we introduce a principled differentiable particle filter and provide\nconvergence results. We demonstrate this novel method on a variety of\napplications.",
          "link": "http://arxiv.org/abs/2102.07850",
          "publishedOn": "2021-06-15T01:45:20.173Z",
          "wordCount": 555,
          "title": "Differentiable Particle Filtering via Entropy-Regularized Optimal Transport. (arXiv:2102.07850v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.05632",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ball_P/0/1/0/all/0/1\">Philip J. Ball</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1\">Cong Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parker_Holder_J/0/1/0/all/0/1\">Jack Parker-Holder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roberts_S/0/1/0/all/0/1\">Stephen Roberts</a>",
          "description": "Reinforcement learning from large-scale offline datasets provides us with the\nability to learn policies without potentially unsafe or impractical\nexploration. Significant progress has been made in the past few years in\ndealing with the challenge of correcting for differing behavior between the\ndata collection and learned policies. However, little attention has been paid\nto potentially changing dynamics when transferring a policy to the online\nsetting, where performance can be up to 90% reduced for existing methods. In\nthis paper we address this problem with Augmented World Models (AugWM). We\naugment a learned dynamics model with simple transformations that seek to\ncapture potential changes in physical properties of the robot, leading to more\nrobust policies. We not only train our policy in this new setting, but also\nprovide it with the sampled augmentation as a context, allowing it to adapt to\nchanges in the environment. At test time we learn the context in a\nself-supervised fashion by approximating the augmentation which corresponds to\nthe new environment. We rigorously evaluate our approach on over 100 different\nchanged dynamics settings, and show that this simple approach can significantly\nimprove the zero-shot generalization of a recent state-of-the-art baseline,\noften achieving successful policies where the baseline fails.",
          "link": "http://arxiv.org/abs/2104.05632",
          "publishedOn": "2021-06-15T01:45:20.166Z",
          "wordCount": 682,
          "title": "Augmented World Models Facilitate Zero-Shot Dynamics Generalization From a Single Offline Environment. (arXiv:2104.05632v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06981",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weiss_G/0/1/0/all/0/1\">Gail Weiss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldberg_Y/0/1/0/all/0/1\">Yoav Goldberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yahav_E/0/1/0/all/0/1\">Eran Yahav</a>",
          "description": "What is the computational model behind a Transformer? Where recurrent neural\nnetworks have direct parallels in finite state machines, allowing clear\ndiscussion and thought around architecture variants or trained models,\nTransformers have no such familiar parallel. In this paper we aim to change\nthat, proposing a computational model for the transformer-encoder in the form\nof a programming language. We map the basic components of a transformer-encoder\n-- attention and feed-forward computation -- into simple primitives, around\nwhich we form a programming language: the Restricted Access Sequence Processing\nLanguage (RASP). We show how RASP can be used to program solutions to tasks\nthat could conceivably be learned by a Transformer, and how a Transformer can\nbe trained to mimic a RASP solution. In particular, we provide RASP programs\nfor histograms, sorting, and Dyck-languages. We further use our model to relate\ntheir difficulty in terms of the number of required layers and attention heads:\nanalyzing a RASP program implies a maximum number of heads and layers necessary\nto encode a task in a transformer. Finally, we see how insights gained from our\nabstraction might be used to explain phenomena seen in recent works.",
          "link": "http://arxiv.org/abs/2106.06981",
          "publishedOn": "2021-06-15T01:45:20.150Z",
          "wordCount": 611,
          "title": "Thinking Like Transformers. (arXiv:2106.06981v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.05912",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Nguyen_K/0/1/0/all/0/1\">Khai Nguyen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nguyen_Q/0/1/0/all/0/1\">Quoc Nguyen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ho_N/0/1/0/all/0/1\">Nhat Ho</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pham_T/0/1/0/all/0/1\">Tung Pham</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bui_H/0/1/0/all/0/1\">Hung Bui</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Phung_D/0/1/0/all/0/1\">Dinh Phung</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Le_T/0/1/0/all/0/1\">Trung Le</a>",
          "description": "Mini-batch optimal transport (m-OT) has been successfully used in practical\napplications that involve probability measures with intractable density, or\nprobability measures with a very high number of supports. The m-OT solves\nseveral sparser optimal transport problems and then returns the average of\ntheir costs and transportation plans. Despite its scalability advantage, the\nm-OT does not consider the relationship between mini-batches which leads to\nundesirable estimation. Moreover, the m-OT does not approximate a proper metric\nbetween probability measures since the identity property is not satisfied. To\naddress these problems, we propose a novel mini-batching scheme for optimal\ntransport, named Batch of Mini-batches Optimal Transport (BoMb-OT), that finds\nthe optimal coupling between mini-batches and it can be seen as an\napproximation to a well-defined distance on the space of probability measures.\nFurthermore, we show that the m-OT is a limit of the entropic regularized\nversion of the BoMb-OT when the regularized parameter goes to infinity.\nFinally, we carry out extensive experiments to show that the BoMb-OT can\nestimate a better transportation plan between two original measures than the\nm-OT. It leads to a favorable performance of the BoMb-OT in the matching and\ncolor transfer tasks. Furthermore, we observe that the BoMb-OT also provides a\nbetter objective loss than the m-OT for doing approximate Bayesian computation,\nestimating parameters of interest in parametric generative models, and learning\nnon-parametric generative models with gradient flow.",
          "link": "http://arxiv.org/abs/2102.05912",
          "publishedOn": "2021-06-15T01:45:20.143Z",
          "wordCount": 683,
          "title": "BoMb-OT: On Batch of Mini-batches Optimal Transport. (arXiv:2102.05912v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.01454",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dai_E/0/1/0/all/0/1\">Enyan Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Suhang Wang</a>",
          "description": "Graph neural networks (GNNs) have achieved state-of-the-art performance in\nmodeling graphs. Despite its great success, as with many other models, GNNs\nhave the risk to inherit the bias from the training data. In addition, the bias\nof GNN can be magnified by the graph structures and message-passing mechanism\nof GNNs. The risk of discrimination limits the adoption of GNNs in sensitive\ndomains such as credit score estimation. Though extensive studies of fair\nclassification have been conducted on i.i.d data, methods to address the\nproblem of discrimination on non-i.i.d data are rather limited. Furthermore,\nthe practical scenario of sparse annotations in sensitive attributes is rarely\nconsidered in existing works. Therefore, we study the novel and important\nproblem of learning fair GNNs with limited sensitive information. We propose a\nnovel framework called FairGNN, which is able to reduce the bias of GNNs and\nmaintain high node classification accuracy by leveraging graph structured data\nand sensitive information. Theoretical analysis is conducted to show that\nFairGNN can ensure fairness under mild conditions given limited nodes with\nknown sensitive attributes. Experiments on real-world datasets demonstrated the\neffectiveness of the proposed framework in eliminating discrimination while\nmaintaining high node classification accuracy.",
          "link": "http://arxiv.org/abs/2009.01454",
          "publishedOn": "2021-06-15T01:45:20.100Z",
          "wordCount": 664,
          "title": "Say No to the Discrimination: Learning Fair Graph Neural Networks with Limited Sensitive Attribute Information. (arXiv:2009.01454v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06815",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hanika_T/0/1/0/all/0/1\">Tom Hanika</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hirth_J/0/1/0/all/0/1\">Johannes Hirth</a>",
          "description": "Dimension reduction of data sets is a standard problem in the realm of\nmachine learning and knowledge reasoning. They affect patterns in and\ndependencies on data dimensions and ultimately influence any decision-making\nprocesses. Therefore, a wide variety of reduction procedures are in use, each\npursuing different objectives. A so far not considered criterion is the\nconceptual continuity of the reduction mapping, i.e., the preservation of the\nconceptual structure with respect to the original data set. Based on the notion\nscale-measure from formal concept analysis we present in this work a) the\ntheoretical foundations to detect and quantify conceptual errors in data\nscalings; b) an experimental investigation of our approach on eleven data sets\nthat were respectively treated with a variant of non-negative matrix\nfactorization.",
          "link": "http://arxiv.org/abs/2106.06815",
          "publishedOn": "2021-06-15T01:45:20.083Z",
          "wordCount": 564,
          "title": "Quantifying the Conceptual Error in Dimensionality Reduction. (arXiv:2106.06815v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06860",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fujimoto_S/0/1/0/all/0/1\">Scott Fujimoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_S/0/1/0/all/0/1\">Shixiang Shane Gu</a>",
          "description": "Offline reinforcement learning (RL) defines the task of learning from a fixed\nbatch of data. Due to errors in value estimation from out-of-distribution\nactions, most offline RL algorithms take the approach of constraining or\nregularizing the policy with the actions contained in the dataset. Built on\npre-existing RL algorithms, modifications to make an RL algorithm work offline\ncomes at the cost of additional complexity. Offline RL algorithms introduce new\nhyperparameters and often leverage secondary components such as generative\nmodels, while adjusting the underlying RL algorithm. In this paper we aim to\nmake a deep RL algorithm work while making minimal changes. We find that we can\nmatch the performance of state-of-the-art offline RL algorithms by simply\nadding a behavior cloning term to the policy update of an online RL algorithm\nand normalizing the data. The resulting algorithm is a simple to implement and\ntune baseline, while more than halving the overall run time by removing the\nadditional computational overheads of previous methods.",
          "link": "http://arxiv.org/abs/2106.06860",
          "publishedOn": "2021-06-15T01:45:19.652Z",
          "wordCount": null,
          "title": "A Minimalist Approach to Offline Reinforcement Learning. (arXiv:2106.06860v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.06828",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1\">Xiaoyong Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_Y/0/1/0/all/0/1\">Youngsuk Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maddix_D/0/1/0/all/0/1\">Danielle C. Maddix</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1\">Xifeng Yan</a>",
          "description": "Recent years have witnessed deep neural networks gaining increasing\npopularity in the field of time series forecasting. A primary reason of their\nsuccess is their ability to effectively capture complex temporal dynamics\nacross multiple related time series. However, the advantages of these deep\nforecasters only start to emerge in the presence of a sufficient amount of\ndata. This poses a challenge for typical forecasting problems in practice,\nwhere one either has a small number of time series, or limited observations per\ntime series, or both. To cope with the issue of data scarcity, we propose a\nnovel domain adaptation framework, Domain Adaptation Forecaster (DAF), that\nleverages the statistical strengths from another relevant domain with abundant\ndata samples (source) to improve the performance on the domain of interest with\nlimited data (target). In particular, we propose an attention-based shared\nmodule with a domain discriminator across domains as well as private modules\nfor individual domains. This allows us to jointly train the source and target\ndomains by generating domain-invariant latent features while retraining\ndomain-specific features. Extensive experiments on various domains demonstrate\nthat our proposed method outperforms state-of-the-art baselines on synthetic\nand real-world datasets.",
          "link": "http://arxiv.org/abs/2102.06828",
          "publishedOn": "2021-06-15T01:45:19.649Z",
          "wordCount": null,
          "title": "Domain Adaptation for Time Series Forecasting via Attention Sharing. (arXiv:2102.06828v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.00922",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghiassian_S/0/1/0/all/0/1\">Sina Ghiassian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sutton_R/0/1/0/all/0/1\">Richard S. Sutton</a>",
          "description": "Off-policy prediction -- learning the value function for one policy from data\ngenerated while following another policy -- is one of the most challenging\nsubproblems in reinforcement learning. This paper presents empirical results\nwith eleven prominent off-policy learning algorithms that use linear function\napproximation: five Gradient-TD methods, two Emphatic-TD methods, Off-policy\nTD($\\lambda$), Vtrace, and versions of Tree Backup and ABQ modified to apply to\na prediction setting. Our experiments used the Collision task, a small\nidealized off-policy problem analogous to that of an autonomous car trying to\npredict whether it will collide with an obstacle. We assessed the performance\nof the algorithms according to their learning rate, asymptotic error level, and\nsensitivity to step-size and bootstrapping parameters. By these measures, the\neleven algorithms can be partially ordered on the Collision task. In the top\ntier, the two Emphatic-TD algorithms learned the fastest, reached the lowest\nerrors, and were robust to parameter settings. In the middle tier, the five\nGradient-TD algorithms and Off-policy TD($\\lambda$) were more sensitive to the\nbootstrapping parameter. The bottom tier comprised Vtrace, Tree Backup, and\nABQ; these algorithms were no faster and had higher asymptotic error than the\nothers. Our results are definitive for this task, though of course experiments\nwith more tasks are needed before an overall assessment of the algorithms'\nmerits can be made.",
          "link": "http://arxiv.org/abs/2106.00922",
          "publishedOn": "2021-06-15T01:45:19.632Z",
          "wordCount": null,
          "title": "An Empirical Comparison of Off-policy Prediction Learning Algorithms on the Collision Task. (arXiv:2106.00922v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06969",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yuhang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trigoni_N/0/1/0/all/0/1\">Niki Trigoni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Markham_A/0/1/0/all/0/1\">Andrew Markham</a>",
          "description": "We present a new framework SoundDet, which is an end-to-end trainable and\nlight-weight framework, for polyphonic moving sound event detection and\nlocalization. Prior methods typically approach this problem by preprocessing\nraw waveform into time-frequency representations, which is more amenable to\nprocess with well-established image processing pipelines. Prior methods also\ndetect in segment-wise manner, leading to incomplete and partial detections.\nSoundDet takes a novel approach and directly consumes the raw, multichannel\nwaveform and treats the spatio-temporal sound event as a complete\n``sound-object\" to be detected. Specifically, SoundDet consists of a backbone\nneural network and two parallel heads for temporal detection and spatial\nlocalization, respectively. Given the large sampling rate of raw waveform, the\nbackbone network first learns a set of phase-sensitive and frequency-selective\nbank of filters to explicitly retain direction-of-arrival information, whilst\nbeing highly computationally and parametrically efficient than standard 1D/2D\nconvolution. A dense sound event proposal map is then constructed to handle the\nchallenges of predicting events with large varying temporal duration.\nAccompanying the dense proposal map are a temporal overlapness map and a motion\nsmoothness map that measure a proposal's confidence to be an event from\ntemporal detection accuracy and movement consistency perspective. Involving the\ntwo maps guarantees SoundDet to be trained in a spatio-temporally unified\nmanner. Experimental results on the public DCASE dataset show the advantage of\nSoundDet on both segment-based and our newly proposed event-based evaluation\nsystem.",
          "link": "http://arxiv.org/abs/2106.06969",
          "publishedOn": "2021-06-15T01:45:19.631Z",
          "wordCount": null,
          "title": "SoundDet: Polyphonic Sound Event Detection and Localization from Raw Waveform. (arXiv:2106.06969v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2004.08891",
          "author": "<a href=\"http://arxiv.org/find/q-fin/1/au:+Ruf_J/0/1/0/all/0/1\">Johannes Ruf</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Wang_W/0/1/0/all/0/1\">Weiguan Wang</a>",
          "description": "We study neural networks as nonparametric estimation tools for the hedging of\noptions. To this end, we design a network, named HedgeNet, that directly\noutputs a hedging strategy. This network is trained to minimise the hedging\nerror instead of the pricing error. Applied to end-of-day and tick prices of\nS&P 500 and Euro Stoxx 50 options, the network is able to reduce the mean\nsquared hedging error of the Black-Scholes benchmark significantly. However, a\nsimilar benefit arises by simple linear regressions that incorporate the\nleverage effect.",
          "link": "http://arxiv.org/abs/2004.08891",
          "publishedOn": "2021-06-15T01:45:19.625Z",
          "wordCount": null,
          "title": "Hedging with Linear Regressions and Neural Networks. (arXiv:2004.08891v3 [q-fin.RM] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06805",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Mbuvha_R/0/1/0/all/0/1\">Rendani Mbuvha</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zondo_P/0/1/0/all/0/1\">Patience Zondo</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mauda_A/0/1/0/all/0/1\">Aluwani Mauda</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Marwala_T/0/1/0/all/0/1\">Tshilidzi Marwala</a>",
          "description": "We use gradient boosting machines and logistic regression to predict academic\nthroughput at a South African university. The results highlight the significant\ninfluence of socio-economic factors and field of study as predictors of\nthroughput. We further find that socio-economic factors become less of a\npredictor relative to the field of study as the time to completion increases.\nWe provide recommendations on interventions to counteract the identified\neffects, which include academic, psychosocial and financial support.",
          "link": "http://arxiv.org/abs/2106.06805",
          "publishedOn": "2021-06-15T01:45:19.624Z",
          "wordCount": null,
          "title": "Predicting Higher Education Throughput in South Africa Using a Tree-Based Ensemble Technique. (arXiv:2106.06805v1 [stat.AP])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06830",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1\">Anthony Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gudipati_P/0/1/0/all/0/1\">Pallavi Gudipati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Longpre_S/0/1/0/all/0/1\">Shayne Longpre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_X/0/1/0/all/0/1\">Xiao Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Sameer Singh</a>",
          "description": "Retrieval is a core component for open-domain NLP tasks. In open-domain\ntasks, multiple entities can share a name, making disambiguation an inherent\nyet under-explored problem. We propose an evaluation benchmark for assessing\nthe entity disambiguation capabilities of these retrievers, which we call\nAmbiguous Entity Retrieval (AmbER) sets. We define an AmbER set as a collection\nof entities that share a name along with queries about those entities. By\ncovering the set of entities for polysemous names, AmbER sets act as a\nchallenging test of entity disambiguation. We create AmbER sets for three\npopular open-domain tasks: fact checking, slot filling, and question answering,\nand evaluate a diverse set of retrievers. We find that the retrievers exhibit\npopularity bias, significantly under-performing on rarer entities that share a\nname, e.g., they are twice as likely to retrieve erroneous documents on queries\nfor the less popular entity under the same name. These experiments on AmbER\nsets show their utility as an evaluation tool and highlight the weaknesses of\npopular retrieval systems.",
          "link": "http://arxiv.org/abs/2106.06830",
          "publishedOn": "2021-06-15T01:45:19.623Z",
          "wordCount": null,
          "title": "Evaluating Entity Disambiguation and the Role of Popularity in Retrieval-Based NLP. (arXiv:2106.06830v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2102.03895",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhu_J/0/1/0/all/0/1\">Jiacheng Zhu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Guha_A/0/1/0/all/0/1\">Aritra Guha</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Do_D/0/1/0/all/0/1\">Dat Do</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Xu_M/0/1/0/all/0/1\">Mengdi Xu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nguyen_X/0/1/0/all/0/1\">XuanLong Nguyen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhao_D/0/1/0/all/0/1\">Ding Zhao</a>",
          "description": "We introduce a formulation of optimal transport problem for distributions on\nfunction spaces, where the stochastic map between functional domains can be\npartially represented in terms of an (infinite-dimensional) Hilbert-Schmidt\noperator mapping a Hilbert space of functions to another. For numerous machine\nlearning tasks, data can be naturally viewed as samples drawn from spaces of\nfunctions, such as curves and surfaces, in high dimensions. Optimal transport\nfor functional data analysis provides a useful framework of treatment for such\ndomains. In this work, we develop an efficient algorithm for finding the\nstochastic transport map between functional domains and provide theoretical\nguarantees on the existence, uniqueness, and consistency of our estimate for\nthe Hilbert-Schmidt operator. We validate our method on synthetic datasets and\nstudy the geometric properties of the transport map. Experiments on real-world\ndatasets of robot arm trajectories further demonstrate the effectiveness of our\nmethod on applications in domain adaptation.",
          "link": "http://arxiv.org/abs/2102.03895",
          "publishedOn": "2021-06-15T01:45:19.623Z",
          "wordCount": null,
          "title": "Functional optimal transport: map estimation and domain adaptation for functional data. (arXiv:2102.03895v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1812.03664",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1\">Han-Jia Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Hexiang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_D/0/1/0/all/0/1\">De-Chuan Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sha_F/0/1/0/all/0/1\">Fei Sha</a>",
          "description": "Learning with limited data is a key challenge for visual recognition. Many\nfew-shot learning methods address this challenge by learning an instance\nembedding function from seen classes and apply the function to instances from\nunseen classes with limited labels. This style of transfer learning is\ntask-agnostic: the embedding function is not learned optimally discriminative\nwith respect to the unseen classes, where discerning among them leads to the\ntarget task. In this paper, we propose a novel approach to adapt the instance\nembeddings to the target classification task with a set-to-set function,\nyielding embeddings that are task-specific and are discriminative. We\nempirically investigated various instantiations of such set-to-set functions\nand observed the Transformer is most effective -- as it naturally satisfies key\nproperties of our desired model. We denote this model as FEAT (few-shot\nembedding adaptation w/ Transformer) and validate it on both the standard\nfew-shot classification benchmark and four extended few-shot learning settings\nwith essential use cases, i.e., cross-domain, transductive, generalized\nfew-shot learning, and low-shot learning. It archived consistent improvements\nover baseline models as well as previous methods and established the new\nstate-of-the-art results on two benchmarks.",
          "link": "http://arxiv.org/abs/1812.03664",
          "publishedOn": "2021-06-15T01:45:19.621Z",
          "wordCount": null,
          "title": "Few-Shot Learning via Embedding Adaptation with Set-to-Set Functions. (arXiv:1812.03664v6 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06799",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiang_L/0/1/0/all/0/1\">Lichuan Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dudziak_L/0/1/0/all/0/1\">&#x141;ukasz Dudziak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdelfattah_M/0/1/0/all/0/1\">Mohamed S. Abdelfattah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chau_T/0/1/0/all/0/1\">Thomas Chau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lane_N/0/1/0/all/0/1\">Nicholas D. Lane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_H/0/1/0/all/0/1\">Hongkai Wen</a>",
          "description": "Differentiable neural architecture search (NAS) has attracted significant\nattention in recent years due to its ability to quickly discover promising\narchitectures of deep neural networks even in very large search spaces. Despite\nits success, DARTS lacks robustness in certain cases, e.g. it may degenerate to\ntrivial architectures with excessive parametric-free operations such as skip\nconnection or random noise, leading to inferior performance. In particular,\noperation selection based on the magnitude of architectural parameters was\nrecently proven to be fundamentally wrong showcasing the need to rethink this\naspect. On the other hand, zero-cost proxies have been recently studied in the\ncontext of sample-based NAS showing promising results -- speeding up the search\nprocess drastically in some cases but also failing on some of the large search\nspaces typical for differentiable NAS. In this work we propose a novel\noperation selection paradigm in the context of differentiable NAS which\nutilises zero-cost proxies. Our perturbation-based zero-cost operation\nselection (Zero-Cost-PT) improves searching time and, in many cases, accuracy\ncompared to the best available differentiable architecture search, regardless\nof the search space size. Specifically, we are able to find comparable\narchitectures to DARTS-PT on the DARTS CNN search space while being over 40x\nfaster (total searching time 25 minutes on a single GPU).",
          "link": "http://arxiv.org/abs/2106.06799",
          "publishedOn": "2021-06-15T01:45:19.620Z",
          "wordCount": null,
          "title": "Zero-Cost Proxies Meet Differentiable Architecture Search. (arXiv:2106.06799v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06630",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xuezhou Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yiding Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jerry Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1\">Wen Sun</a>",
          "description": "We study the adversarial robustness in offline reinforcement learning. Given\na batch dataset consisting of tuples $(s, a, r, s')$, an adversary is allowed\nto arbitrarily modify $\\epsilon$ fraction of the tuples. From the corrupted\ndataset the learner aims to robustly identify a near-optimal policy. We first\nshow that a worst-case $\\Omega(d\\epsilon)$ optimality gap is unavoidable in\nlinear MDP of dimension $d$, even if the adversary only corrupts the reward\nelement in a tuple. This contrasts with dimension-free results in robust\nsupervised learning and best-known lower-bound in the online RL setting with\ncorruption. Next, we propose robust variants of the Least-Square Value\nIteration (LSVI) algorithm utilizing robust supervised learning oracles, which\nachieve near-matching performances in cases both with and without full data\ncoverage. The algorithm requires the knowledge of $\\epsilon$ to design the\npessimism bonus in the no-coverage case. Surprisingly, in this case, the\nknowledge of $\\epsilon$ is necessary, as we show that being adaptive to unknown\n$\\epsilon$ is impossible.This again contrasts with recent results on\ncorruption-robust online RL and implies that robust offline RL is a strictly\nharder problem.",
          "link": "http://arxiv.org/abs/2106.06630",
          "publishedOn": "2021-06-15T01:45:19.619Z",
          "wordCount": null,
          "title": "Corruption-Robust Offline Reinforcement Learning. (arXiv:2106.06630v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00305",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ruis_F/0/1/0/all/0/1\">Frank Ruis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burghouts_G/0/1/0/all/0/1\">Gertjan Burghouts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bucur_D/0/1/0/all/0/1\">Doina Bucur</a>",
          "description": "Humans are good at compositional zero-shot reasoning; someone who has never\nseen a zebra before could nevertheless recognize one when we tell them it looks\nlike a horse with black and white stripes. Machine learning systems, on the\nother hand, usually leverage spurious correlations in the training data, and\nwhile such correlations can help recognize objects in context, they hurt\ngeneralization. To be able to deal with underspecified datasets while still\nleveraging contextual clues during classification, we propose ProtoProp, a\nnovel prototype propagation graph method. First we learn prototypical\nrepresentations of objects (e.g., zebra) that are conditionally independent\nw.r.t. their attribute labels (e.g., stripes) and vice versa. Next we propagate\nthe independent prototypes through a compositional graph, to learn\ncompositional prototypes of novel attribute-object combinations that reflect\nthe dependencies of the target distribution. The method does not rely on any\nexternal data, such as class hierarchy graphs or pretrained word embeddings. We\nevaluate our approach on AO-Clever, a synthetic and strongly visual dataset\nwith clean labels, and UT-Zappos, a noisy real-world dataset of fine-grained\nshoe types. We show that in the generalized compositional zero-shot setting we\noutperform state-of-the-art results, and through ablations we show the\nimportance of each part of the method and their contribution to the final\nresults.",
          "link": "http://arxiv.org/abs/2106.00305",
          "publishedOn": "2021-06-15T01:45:19.618Z",
          "wordCount": null,
          "title": "Independent Prototype Propagation for Zero-Shot Compositionality. (arXiv:2106.00305v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06666",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiying Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuzhao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1\">Xi Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_R/0/1/0/all/0/1\">Runiu Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_S/0/1/0/all/0/1\">Shu-Tao Xia</a>",
          "description": "HyperGraph Convolutional Neural Networks (HGCNNs) have demonstrated their\npotential in modeling high-order relations preserved in graph structured data.\nHowever, most existing convolution filters are localized and determined by the\npre-defined initial hypergraph topology, neglecting to explore implicit and\nlong-ange relations in real-world data. In this paper, we propose the first\nlearning-based method tailored for constructing adaptive hypergraph structure,\ntermed HypERgrAph Laplacian aDaptor (HERALD), which serves as a generic\nplug-in-play module for improving the representational power of HGCNNs.\nSpecifically, HERALD adaptively optimizes the adjacency relationship between\nhypernodes and hyperedges in an end-to-end manner and thus the task-aware\nhypergraph is learned. Furthermore, HERALD employs the self-attention mechanism\nto capture the non-local paired-nodes relation. Extensive experiments on\nvarious popular hypergraph datasets for node classification and graph\nclassification tasks demonstrate that our approach obtains consistent and\nconsiderable performance enhancement, proving its effectiveness and\ngeneralization ability.",
          "link": "http://arxiv.org/abs/2106.06666",
          "publishedOn": "2021-06-15T01:45:19.614Z",
          "wordCount": null,
          "title": "Learnable Hypergraph Laplacian for Hypergraph Learning. (arXiv:2106.06666v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06854",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fujimoto_S/0/1/0/all/0/1\">Scott Fujimoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meger_D/0/1/0/all/0/1\">David Meger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Precup_D/0/1/0/all/0/1\">Doina Precup</a>",
          "description": "Marginalized importance sampling (MIS), which measures the density ratio\nbetween the state-action occupancy of a target policy and that of a sampling\ndistribution, is a promising approach for off-policy evaluation. However,\ncurrent state-of-the-art MIS methods rely on complex optimization tricks and\nsucceed mostly on simple toy problems. We bridge the gap between MIS and deep\nreinforcement learning by observing that the density ratio can be computed from\nthe successor representation of the target policy. The successor representation\ncan be trained through deep reinforcement learning methodology and decouples\nthe reward optimization from the dynamics of the environment, making the\nresulting algorithm stable and applicable to high-dimensional domains. We\nevaluate the empirical performance of our approach on a variety of challenging\nAtari and MuJoCo environments.",
          "link": "http://arxiv.org/abs/2106.06854",
          "publishedOn": "2021-06-15T01:45:19.610Z",
          "wordCount": null,
          "title": "A Deep Reinforcement Learning Approach to Marginalized Importance Sampling with the Successor Representation. (arXiv:2106.06854v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.09768",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Honghua Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Juba_B/0/1/0/all/0/1\">Brendan Juba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Broeck_G/0/1/0/all/0/1\">Guy Van den Broeck</a>",
          "description": "Generating functions, which are widely used in combinatorics and probability\ntheory, encode function values into the coefficients of a polynomial. In this\npaper, we explore their use as a tractable probabilistic model, and propose\nprobabilistic generating circuits (PGCs) for their efficient representation.\nPGCs are strictly more expressive efficient than many existing tractable\nprobabilistic models, including determinantal point processes (DPPs),\nprobabilistic circuits (PCs) such as sum-product networks, and tractable\ngraphical models. We contend that PGCs are not just a theoretical framework\nthat unifies vastly different existing models, but also show great potential in\nmodeling realistic data. We exhibit a simple class of PGCs that are not\ntrivially subsumed by simple combinations of PCs and DPPs, and obtain\ncompetitive performance on a suite of density estimation benchmarks. We also\nhighlight PGCs' connection to the theory of strongly Rayleigh distributions.",
          "link": "http://arxiv.org/abs/2102.09768",
          "publishedOn": "2021-06-15T01:45:19.607Z",
          "wordCount": null,
          "title": "Probabilistic Generating Circuits. (arXiv:2102.09768v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.10255",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1\">Zuoyu Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1\">Tengfei Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1\">Liangcai Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1\">Zhi Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chao Chen</a>",
          "description": "Link prediction is an important learning task for graph-structured data. In\nthis paper, we propose a novel topological approach to characterize\ninteractions between two nodes. Our topological feature, based on the extended\npersistent homology, encodes rich structural information regarding the\nmulti-hop paths connecting nodes. Based on this feature, we propose a graph\nneural network method that outperforms state-of-the-arts on different\nbenchmarks. As another contribution, we propose a novel algorithm to more\nefficiently compute the extended persistence diagrams for graphs. This\nalgorithm can be generally applied to accelerate many other topological methods\nfor graph learning tasks.",
          "link": "http://arxiv.org/abs/2102.10255",
          "publishedOn": "2021-06-15T01:45:19.601Z",
          "wordCount": null,
          "title": "Link Prediction with Persistent Homology: An Interactive View. (arXiv:2102.10255v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06882",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vedder_K/0/1/0/all/0/1\">Kyle Vedder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eaton_E/0/1/0/all/0/1\">Eric Eaton</a>",
          "description": "Bird's Eye View (BEV) is a popular representation for processing 3D point\nclouds, and by its nature is fundamentally sparse. Motivated by the\ncomputational limitations of mobile robot platforms, we take a fast\nhigh-performance BEV 3D object detector - PointPillars - and modify its\nbackbone to exploit this sparsity, leading to decreased runtimes. We present\npreliminary results demonstrating decreased runtimes with either the same\nperformance or a modest decrease in performance, which we anticipate will be\nremedied by model specific hyperparameter tuning. Our work is a first step\ntowards a new class of 3D object detectors that exploit sparsity throughout\ntheir entire pipeline in order to reduce runtime and resource usage while\nmaintaining good detection performance.",
          "link": "http://arxiv.org/abs/2106.06882",
          "publishedOn": "2021-06-15T01:45:19.600Z",
          "wordCount": null,
          "title": "Sparse PointPillars: Exploiting Sparsity in Birds-Eye-View Object Detection. (arXiv:2106.06882v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06712",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haike Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jian Li</a>",
          "description": "We consider the stochastic combinatorial semi-bandit problem with adversarial\ncorruptions. We provide a simple combinatorial algorithm that can achieve a\nregret of $\\tilde{O}\\left(C+d^2K/\\Delta_{min}\\right)$ where $C$ is the total\namount of corruptions, $d$ is the maximal number of arms one can play in each\nround, $K$ is the number of arms. If one selects only one arm in each round, we\nachieves a regret of $\\tilde{O}\\left(C+\\sum_{\\Delta_i>0}(1/\\Delta_i)\\right)$.\nOur algorithm is combinatorial and improves on the previous combinatorial\nalgorithm by [Gupta et al., COLT2019] (their bound is\n$\\tilde{O}\\left(KC+\\sum_{\\Delta_i>0}(1/\\Delta_i)\\right)$), and almost matches\nthe best known bounds obtained by [Zimmert et al., ICML2019] and [Zimmert and\nSeldin, AISTATS2019] (up to logarithmic factor). Note that the algorithms in\n[Zimmert et al., ICML2019] and [Zimmert and Seldin, AISTATS2019] require one to\nsolve complex convex programs while our algorithm is combinatorial, very easy\nto implement, requires weaker assumptions and has very low oracle complexity\nand running time. We also study the setting where we only get access to an\napproximation oracle for the stochastic combinatorial semi-bandit problem. Our\nalgorithm achieves an (approximation) regret bound of\n$\\tilde{O}\\left(d\\sqrt{KT}\\right)$. Our algorithm is very simple, only worse\nthan the best known regret bound by $\\sqrt{d}$, and has much lower oracle\ncomplexity than previous work.",
          "link": "http://arxiv.org/abs/2106.06712",
          "publishedOn": "2021-06-15T01:45:19.599Z",
          "wordCount": null,
          "title": "Simple Combinatorial Algorithms for Combinatorial Bandits: Corruptions and Approximations. (arXiv:2106.06712v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06577",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1\">Yonggan Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chaojian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhongzhi Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yingyan Lin</a>",
          "description": "Driven by the explosive interest in applying deep reinforcement learning\n(DRL) agents to numerous real-time control and decision-making applications,\nthere has been a growing demand to deploy DRL agents to empower daily-life\nintelligent devices, while the prohibitive complexity of DRL stands at odds\nwith limited on-device resources. In this work, we propose an Automated Agent\nAccelerator Co-Search (A3C-S) framework, which to our best knowledge is the\nfirst to automatically co-search the optimally matched DRL agents and\naccelerators that maximize both test scores and hardware efficiency. Extensive\nexperiments consistently validate the superiority of our A3C-S over\nstate-of-the-art techniques.",
          "link": "http://arxiv.org/abs/2106.06577",
          "publishedOn": "2021-06-15T01:45:19.597Z",
          "wordCount": null,
          "title": "A3C-S: Automated Agent Accelerator Co-Search towards Efficient Deep Reinforcement Learning. (arXiv:2106.06577v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06620",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Taghanaki_S/0/1/0/all/0/1\">Saeid Asgari Taghanaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_K/0/1/0/all/0/1\">Kristy Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khasahmadi_A/0/1/0/all/0/1\">Amir Khasahmadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_A/0/1/0/all/0/1\">Anirudh Goyal</a>",
          "description": "A fundamental challenge in artificial intelligence is learning useful\nrepresentations of data that yield good performance on a downstream task,\nwithout overfitting to spurious input features. Extracting such task-relevant\npredictive information is particularly difficult for real-world datasets. In\nthis work, we propose Contrastive Input Morphing (CIM), a representation\nlearning framework that learns input-space transformations of the data to\nmitigate the effect of irrelevant input features on downstream performance. Our\nmethod leverages a perceptual similarity metric via a triplet loss to ensure\nthat the transformation preserves task-relevant information.Empirically, we\ndemonstrate the efficacy of our approach on tasks which typically suffer from\nthe presence of spurious correlations: classification with nuisance\ninformation, out-of-distribution generalization, and preservation of subgroup\naccuracies. We additionally show that CIM is complementary to other mutual\ninformation-based representation learning techniques, and demonstrate that it\nimproves the performance of variational information bottleneck (VIB) when used\ntogether.",
          "link": "http://arxiv.org/abs/2106.06620",
          "publishedOn": "2021-06-15T01:45:19.595Z",
          "wordCount": null,
          "title": "Robust Representation Learning via Perceptual Similarity Metrics. (arXiv:2106.06620v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.06961",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_A/0/1/0/all/0/1\">Anish Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alomar_A/0/1/0/all/0/1\">Abdullah Alomar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alumootil_V/0/1/0/all/0/1\">Varkey Alumootil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_D/0/1/0/all/0/1\">Devavrat Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_D/0/1/0/all/0/1\">Dennis Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zhi Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Cindy Yang</a>",
          "description": "We consider offline reinforcement learning (RL) with heterogeneous agents\nunder severe data scarcity, i.e., we only observe a single historical\ntrajectory for every agent under an unknown, potentially sub-optimal policy. We\nfind that the performance of state-of-the-art offline and model-based RL\nmethods degrade significantly given such limited data availability, even for\ncommonly perceived \"solved\" benchmark settings such as \"MountainCar\" and\n\"CartPole\". To address this challenge, we propose PerSim, a model-based offline\nRL approach which first learns a personalized simulator for each agent by\ncollectively using the historical trajectories across all agents, prior to\nlearning a policy. We do so by positing that the transition dynamics across\nagents can be represented as a latent function of latent factors associated\nwith agents, states, and actions; subsequently, we theoretically establish that\nthis function is well-approximated by a \"low-rank\" decomposition of separable\nagent, state, and action latent functions. This representation suggests a\nsimple, regularized neural network architecture to effectively learn the\ntransition dynamics per agent, even with scarce, offline data. We perform\nextensive experiments across several benchmark environments and RL methods. The\nconsistent improvement of our approach, measured in terms of both state\ndynamics prediction and eventual reward, confirms the efficacy of our framework\nin leveraging limited historical data to simultaneously learn personalized\npolicies across agents.",
          "link": "http://arxiv.org/abs/2102.06961",
          "publishedOn": "2021-06-15T01:45:19.590Z",
          "wordCount": null,
          "title": "PerSim: Data-Efficient Offline Reinforcement Learning with Heterogeneous Agents via Personalized Simulators. (arXiv:2102.06961v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06935",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1\">Zhaocheng Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zuobai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xhonneux_L/0/1/0/all/0/1\">Louis-Pascal Xhonneux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jian Tang</a>",
          "description": "Link prediction is a very fundamental task on graphs. Inspired by traditional\npath-based methods, in this paper we propose a general and flexible\nrepresentation learning framework based on paths for link prediction.\nSpecifically, we define the representation of a pair of nodes as the\ngeneralized sum of all path representations, with each path representation as\nthe generalized product of the edge representations in the path. Motivated by\nthe Bellman-Ford algorithm for solving the shortest path problem, we show that\nthe proposed path formulation can be efficiently solved by the generalized\nBellman-Ford algorithm. To further improve the capacity of the path\nformulation, we propose the Neural Bellman-Ford Network (NBFNet), a general\ngraph neural network framework that solves the path formulation with learned\noperators in the generalized Bellman-Ford algorithm. The NBFNet parameterizes\nthe generalized Bellman-Ford algorithm with 3 neural components, namely\nINDICATOR, MESSAGE and AGGREGATE functions, which corresponds to the boundary\ncondition, multiplication operator, and summation operator respectively. The\nNBFNet is very general, covers many traditional path-based methods, and can be\napplied to both homogeneous graphs and multi-relational graphs (e.g., knowledge\ngraphs) in both transductive and inductive settings. Experiments on both\nhomogeneous graphs and knowledge graphs show that the proposed NBFNet\noutperforms existing methods by a large margin in both transductive and\ninductive settings, achieving new state-of-the-art results.",
          "link": "http://arxiv.org/abs/2106.06935",
          "publishedOn": "2021-06-15T01:45:19.585Z",
          "wordCount": null,
          "title": "Neural Bellman-Ford Networks: A General Graph Neural Network Framework for Link Prediction. (arXiv:2106.06935v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2002.00526",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yang Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_W/0/1/0/all/0/1\">Wenbo Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_X/0/1/0/all/0/1\">Xinyu Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noble_W/0/1/0/all/0/1\">William Stafford Noble</a>",
          "description": "Saliency methods can make deep neural network predictions more interpretable\nby identifying a set of critical features in an input sample, such as pixels\nthat contribute most strongly to a prediction made by an image classifier.\nUnfortunately, recent evidence suggests that many saliency methods poorly\nperform, especially in situations where gradients are saturated, inputs contain\nadversarial perturbations, or predictions rely upon inter-feature dependence.\nTo address these issues, we propose a framework that improves the robustness of\nsaliency methods by following a two-step procedure. First, we introduce a\nperturbation mechanism that subtly varies the input sample without changing its\nintermediate representations. Using this approach, we can gather a corpus of\nperturbed data samples while ensuring that the perturbed and original input\nsamples follow the same distribution. Second, we compute saliency maps for the\nperturbed samples and propose a new method to aggregate saliency maps. With\nthis design, we offset the gradient saturation influence upon interpretation.\nFrom a theoretical perspective, we show the aggregated saliency map could not\nonly capture inter-feature dependence but, more importantly, robustify\ninterpretation against previously described adversarial perturbation methods.\nFollowing our theoretical analysis, we present experimental results suggesting\nthat, both qualitatively and quantitatively, our saliency method outperforms\nexisting methods.",
          "link": "http://arxiv.org/abs/2002.00526",
          "publishedOn": "2021-06-15T01:45:19.581Z",
          "wordCount": 666,
          "title": "DANCE: Enhancing saliency maps using decoys. (arXiv:2002.00526v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06765",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abaimov_S/0/1/0/all/0/1\">Stanislav Abaimov</a>",
          "description": "Data Distribution Service (DDS) is an innovative approach towards\ncommunication in ICS/IoT infrastructure and robotics. Being based on the\ncross-platform and cross-language API to be applicable in any computerised\ndevice, it offers the benefits of modern programming languages and the\nopportunities to develop more complex and advanced systems. However, the DDS\ncomplexity equally increases its vulnerability, while the existing security\nmeasures are limited to plug-ins and static rules, with the rest of the\nsecurity provided by third-party applications and operating system.\nSpecifically, traditional intrusion detection systems (IDS) do not detect any\nanomalies in the publish/subscribe method. With the exponentially growing\nglobal communication exchange, securing DDS is of the utmost importance to\nfutureproofing industrial, public, and even personal devices and systems. This\nreport presents an experimental work on the simulation of several specific\nattacks against DDS, and the application of Deep Learning for their detection.\nThe findings show that even though Deep Learning allows to detect all simulated\nattacks using only metadata analysis, their detection level varies, with some\nof the advanced attacks being harder to detect. The limitations imposed by the\nattempts to preserve privacy significantly decrease the detection rate. The\nreport also reviews the drawbacks and limitations of the Deep Learning approach\nand proposes a set of selected solutions and configurations, that can further\nimprove the DDS security.",
          "link": "http://arxiv.org/abs/2106.06765",
          "publishedOn": "2021-06-15T01:45:19.564Z",
          "wordCount": 648,
          "title": "Towards a Privacy-preserving Deep Learning-based Network Intrusion Detection in Data Distribution Services. (arXiv:2106.06765v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.05858",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1\">Chung-Wei Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1\">Haipeng Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1\">Chen-Yu Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mengxiao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaojin Zhang</a>",
          "description": "In this work, we develop linear bandit algorithms that automatically adapt to\ndifferent environments. By plugging a novel loss estimator into the\noptimization problem that characterizes the instance-optimal strategy, our\nfirst algorithm not only achieves nearly instance-optimal regret in stochastic\nenvironments, but also works in corrupted environments with additional regret\nbeing the amount of corruption, while the state-of-the-art (Li et al., 2019)\nachieves neither instance-optimality nor the optimal dependence on the\ncorruption amount. Moreover, by equipping this algorithm with an adversarial\ncomponent and carefully-designed testings, our second algorithm additionally\nenjoys minimax-optimal regret in completely adversarial environments, which is\nthe first of this kind to our knowledge. Finally, all our guarantees hold with\nhigh probability, while existing instance-optimal guarantees only hold in\nexpectation.",
          "link": "http://arxiv.org/abs/2102.05858",
          "publishedOn": "2021-06-15T01:45:19.554Z",
          "wordCount": 595,
          "title": "Achieving Near Instance-Optimality and Minimax-Optimality in Stochastic and Adversarial Linear Bandits Simultaneously. (arXiv:2102.05858v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.08266",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aggarwal_A/0/1/0/all/0/1\">Abhinav Aggarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kasiviswanathan_S/0/1/0/all/0/1\">Shiva Prasad Kasiviswanathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zekun Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feyisetan_O/0/1/0/all/0/1\">Oluwaseyi Feyisetan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teissier_N/0/1/0/all/0/1\">Nathanael Teissier</a>",
          "description": "Log-loss (also known as cross-entropy loss) metric is ubiquitously used\nacross machine learning applications to assess the performance of\nclassification algorithms. In this paper, we investigate the problem of\ninferring the labels of a dataset from single (or multiple) log-loss score(s),\nwithout any other access to the dataset. Surprisingly, we show that for any\nfinite number of label classes, it is possible to accurately infer the labels\nof the dataset from the reported log-loss score of a single carefully\nconstructed prediction vector if we allow arbitrary precision arithmetic.\nAdditionally, we present label inference algorithms (attacks) that succeed even\nunder addition of noise to the log-loss scores and under limited precision\narithmetic. All our algorithms rely on ideas from number theory and\ncombinatorics and require no model training. We run experimental simulations on\nsome real datasets to demonstrate the ease of running these attacks in\npractice.",
          "link": "http://arxiv.org/abs/2105.08266",
          "publishedOn": "2021-06-15T01:45:19.545Z",
          "wordCount": 602,
          "title": "Label Inference Attacks from Log-loss Scores. (arXiv:2105.08266v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2003.06601",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Takahashi_T/0/1/0/all/0/1\">Tomoei Takahashi</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Chikenji_G/0/1/0/all/0/1\">George Chikenji</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Tokita_K/0/1/0/all/0/1\">Kei Tokita</a>",
          "description": "Protein design is the inverse approach of the three-dimensional (3D)\nstructure prediction for elucidating the relationship between the 3D structures\nand amino acid sequences. In general, the computation of the protein design\ninvolves a double loop: a loop for amino acid sequence changes and a loop for\nan exhaustive conformational search for each amino acid sequence. Herein, we\npropose a novel statistical mechanical design method using Bayesian learning,\nwhich can design lattice proteins without the exhaustive conformational search.\nWe consider a thermodynamic hypothesis of the evolution of proteins and apply\nit to the prior distribution of amino acid sequences. Furthermore, we take the\nwater effect into account in view of the grand canonical picture. As a result,\non applying the 2D lattice hydrophobic-polar (HP) model, our design method\nsuccessfully finds an amino acid sequence for which the target conformation has\na unique ground state. However, the performance was not as good for the 3D\nlattice HP models compared to the 2D models. The performance of the 3D model\nimproves on using a 20-letter lattice proteins. Furthermore, we find a strong\nlinearity between the chemical potential of water and the number of surface\nresidues, thereby revealing the relationship between protein structure and the\neffect of water molecules. The advantage of our method is that it greatly\nreduces computation time, because it does not require long calculations for the\npartition function corresponding to an exhaustive conformational search. As our\nmethod uses a general form of Bayesian learning and statistical mechanics and\nis not limited to lattice proteins, the results presented here elucidate some\nheuristics used successfully in previous protein design methods.",
          "link": "http://arxiv.org/abs/2003.06601",
          "publishedOn": "2021-06-15T01:45:19.534Z",
          "wordCount": 748,
          "title": "Lattice protein design using Bayesian learning. (arXiv:2003.06601v5 [physics.bio-ph] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06868",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hoyos_Gomez_L/0/1/0/all/0/1\">Laura S. Hoyos-G&#xf3;mez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruiz_Munoz_J/0/1/0/all/0/1\">Jose F. Ruiz-Mu&#xf1;oz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruiz_Mendoza_B/0/1/0/all/0/1\">Belizza J. Ruiz-Mendoza</a>",
          "description": "Accurate mechanisms for forecasting solar irradiance and insolation provide\nimportant information for the planning of renewable energy and agriculture\nprojects as well as for environmental and socio-economical studies. This\nresearch introduces a pipeline for the one-day ahead forecasting of solar\nirradiance and insolation that only requires solar irradiance historical data\nfor training. Furthermore, our approach is able to deal with missing data since\nit includes a data imputation state. In the prediction stage, we consider four\ndata-driven approaches: Autoregressive Integrated Moving Average (ARIMA),\nSingle Layer Feed Forward Network (SL-FNN), Multiple Layer Feed Forward Network\n(FL-FNN), and Long Short-Term Memory (LSTM). The experiments are performed in a\nreal-world dataset collected with 12 Automatic Weather Stations (AWS) located\nin the Nari\\~no - Colombia. The results show that the neural network-based\nmodels outperform ARIMA in most cases. Furthermore, LSTM exhibits better\nperformance in cloudy environments (where more randomness is expected).",
          "link": "http://arxiv.org/abs/2106.06868",
          "publishedOn": "2021-06-15T01:45:19.498Z",
          "wordCount": 578,
          "title": "Short-term forecasting of global solar irradiance with incomplete data. (arXiv:2106.06868v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2008.05221",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_M/0/1/0/all/0/1\">Manish Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_P/0/1/0/all/0/1\">Puneet Agrawal</a>",
          "description": "In recent years, the fields of natural language processing (NLP) and\ninformation retrieval (IR) have made tremendous progress thanksto deep learning\nmodels like Recurrent Neural Networks (RNNs), Gated Recurrent Units (GRUs) and\nLong Short-Term Memory (LSTMs)networks, and Transformer [120] based models like\nBidirectional Encoder Representations from Transformers (BERT) [24],\nGenerativePre-training Transformer (GPT-2) [94], Multi-task Deep Neural Network\n(MT-DNN) [73], Extra-Long Network (XLNet) [134], Text-to-text transfer\ntransformer (T5) [95], T-NLG [98] and GShard [63]. But these models are\nhumongous in size. On the other hand,real world applications demand small model\nsize, low response times and low computational power wattage. In this survey,\nwediscuss six different types of methods (Pruning, Quantization, Knowledge\nDistillation, Parameter Sharing, Tensor Decomposition, andSub-quadratic\nTransformer based methods) for compression of such models to enable their\ndeployment in real industry NLP projects.Given the critical need of building\napplications with efficient and small models, and the large amount of recently\npublished work inthis area, we believe that this survey organizes the plethora\nof work done by the 'deep learning for NLP' community in the past fewyears and\npresents it as a coherent story.",
          "link": "http://arxiv.org/abs/2008.05221",
          "publishedOn": "2021-06-15T01:45:19.480Z",
          "wordCount": 675,
          "title": "Compression of Deep Learning Models for Text: A Survey. (arXiv:2008.05221v4 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.05185",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ross_A/0/1/0/all/0/1\">Andrew Slavin Ross</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doshi_Velez_F/0/1/0/all/0/1\">Finale Doshi-Velez</a>",
          "description": "In representation learning, there has been recent interest in developing\nalgorithms to disentangle the ground-truth generative factors behind a dataset,\nand metrics to quantify how fully this occurs. However, these algorithms and\nmetrics often assume that both representations and ground-truth factors are\nflat, continuous, and factorized, whereas many real-world generative processes\ninvolve rich hierarchical structure, mixtures of discrete and continuous\nvariables with dependence between them, and even varying intrinsic\ndimensionality. In this work, we develop benchmarks, algorithms, and metrics\nfor learning such hierarchical representations.",
          "link": "http://arxiv.org/abs/2102.05185",
          "publishedOn": "2021-06-15T01:45:19.464Z",
          "wordCount": null,
          "title": "Benchmarks, Algorithms, and Metrics for Hierarchical Disentanglement. (arXiv:2102.05185v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06586",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Suresh_S/0/1/0/all/0/1\">Susheel Suresh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Budde_V/0/1/0/all/0/1\">Vinith Budde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neville_J/0/1/0/all/0/1\">Jennifer Neville</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Pan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jianzhu Ma</a>",
          "description": "Graph neural networks (GNNs) have achieved tremendous success on multiple\ngraph-based learning tasks by fusing network structure and node features.\nModern GNN models are built upon iterative aggregation of neighbor's/proximity\nfeatures by message passing. Its prediction performance has been shown to be\nstrongly bounded by assortative mixing in the graph, a key property wherein\nnodes with similar attributes mix/connect with each other. We observe that real\nworld networks exhibit heterogeneous or diverse mixing patterns and the\nconventional global measurement of assortativity, such as global assortativity\ncoefficient, may not be a representative statistic in quantifying this mixing.\nWe adopt a generalized concept, node-level assortativity, one that is based at\nthe node level to better represent the diverse patterns and accurately quantify\nthe learnability of GNNs. We find that the prediction performance of a wide\nrange of GNN models is highly correlated with the node level assortativity. To\nbreak this limit, in this work, we focus on transforming the input graph into a\ncomputation graph which contains both proximity and structural information as\ndistinct type of edges. The resulted multi-relational graph has an enhanced\nlevel of assortativity and, more importantly, preserves rich information from\nthe original graph. We then propose to run GNNs on this computation graph and\nshow that adaptively choosing between structure and proximity leads to improved\nperformance under diverse mixing. Empirically, we show the benefits of adopting\nour transformation framework for semi-supervised node classification task on a\nvariety of real world graph learning benchmarks.",
          "link": "http://arxiv.org/abs/2106.06586",
          "publishedOn": "2021-06-15T01:45:19.461Z",
          "wordCount": null,
          "title": "Breaking the Limit of Graph Neural Networks by Improving the Assortativity of Graphs with Local Mixing Patterns. (arXiv:2106.06586v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.11367",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lai_F/0/1/0/all/0/1\">Fan Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_Y/0/1/0/all/0/1\">Yinwei Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiangfeng Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chowdhury_M/0/1/0/all/0/1\">Mosharaf Chowdhury</a>",
          "description": "We present FedScale, a diverse set of challenging and realistic benchmark\ndatasets to facilitate scalable, comprehensive, and reproducible federated\nlearning (FL) research. FedScale datasets are large-scale, encompassing a\ndiverse range of important FL tasks, such as image classification, object\ndetection, language modeling, speech recognition, and reinforcement learning.\nFor each dataset, we provide a unified evaluation protocol using realistic data\nsplits and evaluation metrics. To meet the pressing need for reproducing\nrealistic FL at scale, we have also built an efficient evaluation platform to\nsimplify and standardize the process of FL experimental setup and model\nevaluation. Our evaluation platform provides flexible APIs to implement new FL\nalgorithms and includes new execution backends with minimal developer efforts.\nFinally, we perform indepth benchmark experiments on these datasets. Our\nexperiments suggest fruitful opportunities in heterogeneity-aware\nco-optimizations of the system and statistical efficiency under realistic FL\ncharacteristics. FedScale is open-source with permissive licenses and actively\nmaintained,1 and we welcome feedback and contributions from the community.",
          "link": "http://arxiv.org/abs/2105.11367",
          "publishedOn": "2021-06-15T01:45:19.459Z",
          "wordCount": null,
          "title": "FedScale: Benchmarking Model and System Performance of Federated Learning. (arXiv:2105.11367v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.07003",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1\">Gyuwan Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1\">Kyunghyun Cho</a>",
          "description": "Despite transformers' impressive accuracy, their computational cost is often\nprohibitive to use with limited computational resources. Most previous\napproaches to improve inference efficiency require a separate model for each\npossible computational budget. In this paper, we extend PoWER-BERT (Goyal et\nal., 2020) and propose Length-Adaptive Transformer that can be used for various\ninference scenarios after one-shot training. We train a transformer with\nLengthDrop, a structural variant of dropout, which stochastically determines a\nsequence length at each layer. We then conduct a multi-objective evolutionary\nsearch to find a length configuration that maximizes the accuracy and minimizes\nthe efficiency metric under any given computational budget. Additionally, we\nsignificantly extend the applicability of PoWER-BERT beyond sequence-level\nclassification into token-level classification with Drop-and-Restore process\nthat drops word-vectors temporarily in intermediate layers and restores at the\nlast layer if necessary. We empirically verify the utility of the proposed\napproach by demonstrating the superior accuracy-efficiency trade-off under\nvarious setups, including span-based question answering and text\nclassification. Code is available at\nhttps://github.com/clovaai/length-adaptive-transformer.",
          "link": "http://arxiv.org/abs/2010.07003",
          "publishedOn": "2021-06-15T01:45:19.445Z",
          "wordCount": 633,
          "title": "Length-Adaptive Transformer: Train Once with Length Drop, Use Anytime with Search. (arXiv:2010.07003v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.10025",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liao_W/0/1/0/all/0/1\">Wenlong Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bak_Jensen_B/0/1/0/all/0/1\">Birgitte Bak-Jensen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pillai_J/0/1/0/all/0/1\">Jayakrishnan Radhakrishna Pillai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuelong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yusen Wang</a>",
          "description": "Deep neural networks have revolutionized many machine learning tasks in power\nsystems, ranging from pattern recognition to signal processing. The data in\nthese tasks is typically represented in Euclidean domains. Nevertheless, there\nis an increasing number of applications in power systems, where data are\ncollected from non-Euclidean domains and represented as graph-structured data\nwith high dimensional features and interdependency among nodes. The complexity\nof graph-structured data has brought significant challenges to the existing\ndeep neural networks defined in Euclidean domains. Recently, many publications\ngeneralizing deep neural networks for graph-structured data in power systems\nhave emerged. In this paper, a comprehensive overview of graph neural networks\n(GNNs) in power systems is proposed. Specifically, several classical paradigms\nof GNNs structures (e.g., graph convolutional networks) are summarized, and key\napplications in power systems, such as fault scenario application, time series\nprediction, power flow calculation, and data generation are reviewed in detail.\nFurthermore, main issues and some research trends about the applications of\nGNNs in power systems are discussed.",
          "link": "http://arxiv.org/abs/2101.10025",
          "publishedOn": "2021-06-15T01:45:19.437Z",
          "wordCount": 633,
          "title": "A Review of Graph Neural Networks and Their Applications in Power Systems. (arXiv:2101.10025v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.03216",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nekoei_H/0/1/0/all/0/1\">Hadi Nekoei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Badrinaaraayanan_A/0/1/0/all/0/1\">Akilesh Badrinaaraayanan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Courville_A/0/1/0/all/0/1\">Aaron Courville</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandar_S/0/1/0/all/0/1\">Sarath Chandar</a>",
          "description": "Current deep reinforcement learning (RL) algorithms are still highly\ntask-specific and lack the ability to generalize to new environments. Lifelong\nlearning (LLL), however, aims at solving multiple tasks sequentially by\nefficiently transferring and using knowledge between tasks. Despite a surge of\ninterest in lifelong RL in recent years, the lack of a realistic testbed makes\nrobust evaluation of LLL algorithms difficult. Multi-agent RL (MARL), on the\nother hand, can be seen as a natural scenario for lifelong RL due to its\ninherent non-stationarity, since the agents' policies change over time. In this\nwork, we introduce a multi-agent lifelong learning testbed that supports both\nzero-shot and few-shot settings. Our setup is based on Hanabi -- a\npartially-observable, fully cooperative multi-agent game that has been shown to\nbe challenging for zero-shot coordination. Its large strategy space makes it a\ndesirable environment for lifelong RL tasks. We evaluate several recent MARL\nmethods, and benchmark state-of-the-art LLL algorithms in limited memory and\ncomputation regimes to shed light on their strengths and weaknesses. This\ncontinual learning paradigm also provides us with a pragmatic way of going\nbeyond centralized training which is the most commonly used training protocol\nin MARL. We empirically show that the agents trained in our setup are able to\ncoordinate well with unseen agents, without any additional assumptions made by\nprevious works. The code and all pre-trained models are available at\nhttps://github.com/chandar-lab/Lifelong-Hanabi.",
          "link": "http://arxiv.org/abs/2103.03216",
          "publishedOn": "2021-06-15T01:45:19.414Z",
          "wordCount": 713,
          "title": "Continuous Coordination As a Realistic Scenario for Lifelong Learning. (arXiv:2103.03216v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.06701",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sato_T/0/1/0/all/0/1\">Takami Sato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1\">Junjie Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_N/0/1/0/all/0/1\">Ningfei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1\">Yunhan Jack Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1\">Xue Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qi Alfred Chen</a>",
          "description": "Automated Lane Centering (ALC) systems are convenient and widely deployed\ntoday, but also highly security and safety critical. In this work, we are the\nfirst to systematically study the security of state-of-the-art deep learning\nbased ALC systems in their designed operational domains under physical-world\nadversarial attacks. We formulate the problem with a safety-critical attack\ngoal, and a novel and domain-specific attack vector: dirty road patches. To\nsystematically generate the attack, we adopt an optimization-based approach and\novercome domain-specific design challenges such as camera frame\ninter-dependencies due to attack-influenced vehicle control, and the lack of\nobjective function design for lane detection models.\n\nWe evaluate our attack on a production ALC using 80 scenarios from real-world\ndriving traces. The results show that our attack is highly effective with over\n97.5% success rates and less than 0.903 sec average success time, which is\nsubstantially lower than the average driver reaction time. This attack is also\nfound (1) robust to various real-world factors such as lighting conditions and\nview angles, (2) general to different model designs, and (3) stealthy from the\ndriver's view. To understand the safety impacts, we conduct experiments using\nsoftware-in-the-loop simulation and attack trace injection in a real vehicle.\nThe results show that our attack can cause a 100% collision rate in different\nscenarios, including when tested with common safety features such as automatic\nemergency braking. We also evaluate and discuss defenses.",
          "link": "http://arxiv.org/abs/2009.06701",
          "publishedOn": "2021-06-15T01:45:19.398Z",
          "wordCount": null,
          "title": "Dirty Road Can Attack: Security of Deep Learning based Automated Lane Centering under Physical-World Attack. (arXiv:2009.06701v2 [cs.CR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.14824",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yoo_S/0/1/0/all/0/1\">Soyoung Yoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_N/0/1/0/all/0/1\">Namwoo Kang</a>",
          "description": "Studies on manufacturing cost prediction based on deep learning have begun in\nrecent years, but the cost prediction rationale cannot be explained because the\nmodels are still used as a black box. This study aims to propose a\nmanufacturing cost prediction process for 3D computer-aided design (CAD) models\nusing explainable artificial intelligence. The proposed process can visualize\nthe machining features of the 3D CAD model that are influencing the increase in\nmanufacturing costs. The proposed process consists of (1) data collection and\npre-processing, (2) 3D deep learning architecture exploration, and (3)\nvisualization to explain the prediction results. The proposed deep learning\nmodel shows high predictability of manufacturing cost for the computer\nnumerical control (CNC) machined parts. In particular, using 3D\ngradient-weighted class activation mapping proves that the proposed model not\nonly can detect the CNC machining features but also can differentiate the\nmachining difficulty for the same feature. Using the proposed process, we can\nprovide a design guidance to engineering designers in reducing manufacturing\ncosts during the conceptual design phase. We can also provide real-time\nquotations and redesign proposals to online manufacturing platform customers.",
          "link": "http://arxiv.org/abs/2010.14824",
          "publishedOn": "2021-06-15T01:45:19.390Z",
          "wordCount": 639,
          "title": "Explainable Artificial Intelligence for Manufacturing Cost Estimation and Machining Feature Visualization. (arXiv:2010.14824v2 [cs.CG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.15190",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Nakagawa_A/0/1/0/all/0/1\">Akira Nakagawa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kato_K/0/1/0/all/0/1\">Keizo Kato</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Suzuki_T/0/1/0/all/0/1\">Taiji Suzuki</a>",
          "description": "Variational autoencoder (VAE) estimates the posterior parameters (mean and\nvariance) of latent variables corresponding to each input data. While it is\nused for many tasks, the transparency of the model is still an underlying\nissue. This paper provides a quantitative understanding of VAE property through\nthe differential geometric and information-theoretic interpretations of VAE.\nAccording to the Rate-distortion theory, the optimal transform coding is\nachieved by using an orthonormal transform with PCA basis where the transform\nspace is isometric to the input. Considering the analogy of transform coding to\nVAE, we clarify theoretically and experimentally that VAE can be mapped to an\nimplicit isometric embedding with a scale factor derived from the posterior\nparameter. As a result, we can estimate the data probabilities in the input\nspace from the prior, loss metrics, and corresponding posterior parameters, and\nfurther, the quantitative importance of each latent variable can be evaluated\nlike the eigenvalue of PCA.",
          "link": "http://arxiv.org/abs/2007.15190",
          "publishedOn": "2021-06-15T01:45:19.378Z",
          "wordCount": 622,
          "title": "Quantitative Understanding of VAE as a Non-linearly Scaled Isometric Embedding. (arXiv:2007.15190v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06555",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lovelace_J/0/1/0/all/0/1\">Justin Lovelace</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Newman_Griffis_D/0/1/0/all/0/1\">Denis Newman-Griffis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vashishth_S/0/1/0/all/0/1\">Shikhar Vashishth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lehman_J/0/1/0/all/0/1\">Jill Fain Lehman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rose_C/0/1/0/all/0/1\">Carolyn Penstein Ros&#xe9;</a>",
          "description": "Knowledge Graph (KG) completion research usually focuses on densely connected\nbenchmark datasets that are not representative of real KGs. We curate two KG\ndatasets that include biomedical and encyclopedic knowledge and use an existing\ncommonsense KG dataset to explore KG completion in the more realistic setting\nwhere dense connectivity is not guaranteed. We develop a deep convolutional\nnetwork that utilizes textual entity representations and demonstrate that our\nmodel outperforms recent KG completion methods in this challenging setting. We\nfind that our model's performance improvements stem primarily from its\nrobustness to sparsity. We then distill the knowledge from the convolutional\nnetwork into a student network that re-ranks promising candidate entities. This\nre-ranking stage leads to further improvements in performance and demonstrates\nthe effectiveness of entity re-ranking for KG completion.",
          "link": "http://arxiv.org/abs/2106.06555",
          "publishedOn": "2021-06-15T01:45:19.372Z",
          "wordCount": 591,
          "title": "Robust Knowledge Graph Completion with Stacked Convolutions and a Student Re-Ranking Network. (arXiv:2106.06555v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06749",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_K/0/1/0/all/0/1\">Kun Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jinlan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1\">Zhixia Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1\">Dongpo Xu</a>",
          "description": "Currently, researchers have proposed the adaptive gradient descent algorithm\nand its variants, such as AdaGrad, RMSProp, Adam, AmsGrad, etc. Although these\nalgorithms have a faster speed in the early stage, the generalization ability\nin the later stage of training is often not as good as the stochastic gradient\ndescent. Recently, some researchers have combined the adaptive gradient descent\nand stochastic gradient descent to obtain the advantages of both and achieved\ngood results. Based on this research, we propose a decreasing scaling\ntransition from adaptive gradient descent to stochastic gradient descent\nmethod(DSTAda). For the training stage of the stochastic gradient descent, we\nuse a learning rate that decreases linearly with the number of iterations\ninstead of a constant learning rate. We achieve a smooth and stable transition\nfrom adaptive gradient descent to stochastic gradient descent through scaling.\nAt the same time, we give a theoretical proof of the convergence of DSTAda\nunder the framework of online learning. Our experimental results show that the\nDSTAda algorithm has a faster convergence speed, higher accuracy, and better\nstability and robustness. Our implementation is available at:\nhttps://github.com/kunzeng/DSTAdam.",
          "link": "http://arxiv.org/abs/2106.06749",
          "publishedOn": "2021-06-15T01:45:19.354Z",
          "wordCount": 616,
          "title": "Decreasing scaling transition from adaptive gradient descent to stochastic gradient descent. (arXiv:2106.06749v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2104.13352",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_A/0/1/0/all/0/1\">Ajay Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_B/0/1/0/all/0/1\">Basant Agarwal</a>",
          "description": "On 26 January 2021, India witnessed a national embarrassment from the\ndemographic least expected from - farmers. People across the nation watched in\nhorror as a pseudo-patriotic mob of farmers stormed capital Delhi and\nvandalized the national pride- Red Fort. Investigations that followed the event\nrevealed the existence of a social media trail that led to the likes of such an\nevent. Consequently, it became essential and necessary to archive this trail\nfor social media analysis - not only to understand the bread-crumbs that are\ndispersed across the trail but also to visualize the role played by\nmisinformation and fake news in this event. In this paper, we propose the\ntractor2twitter dataset which contains around 0.05 million tweets that were\nposted before, during, and after this event. Also, we benchmark our dataset\nwith an Explainable AI ML model for classification of each tweet into either of\nthe three categories - disinformation, misinformation, and opinion.",
          "link": "http://arxiv.org/abs/2104.13352",
          "publishedOn": "2021-06-15T01:45:19.340Z",
          "wordCount": null,
          "title": "Tracking Peaceful Tractors on Social Media -- XAI-enabled analysis of Red Fort Riots 2021. (arXiv:2104.13352v2 [cs.SI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06753",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_K/0/1/0/all/0/1\">Kun Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jinlan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1\">Zhixia Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1\">Dongpo Xu</a>",
          "description": "The plain stochastic gradient descent and momentum stochastic gradient\ndescent have extremely wide applications in deep learning due to their simple\nsettings and low computational complexity. The momentum stochastic gradient\ndescent uses the accumulated gradient as the updated direction of the current\nparameters, which has a faster training speed. Because the direction of the\nplain stochastic gradient descent has not been corrected by the accumulated\ngradient. For the parameters that currently need to be updated, it is the\noptimal direction, and its update is more accurate. We combine the advantages\nof the momentum stochastic gradient descent with fast training speed and the\nplain stochastic gradient descent with high accuracy, and propose a scaling\ntransition from momentum stochastic gradient descent to plain stochastic\ngradient descent(TSGD) method. At the same time, a learning rate that decreases\nlinearly with the iterations is used instead of a constant learning rate. The\nTSGD algorithm has a larger step size in the early stage to speed up the\ntraining, and training with a smaller step size in the later stage can steadily\nconverge. Our experimental results show that the TSGD algorithm has faster\ntraining speed, higher accuracy and better stability. Our implementation is\navailable at: https://github.com/kunzeng/TSGD.",
          "link": "http://arxiv.org/abs/2106.06753",
          "publishedOn": "2021-06-15T01:45:19.338Z",
          "wordCount": 638,
          "title": "Scaling transition from momentum stochastic gradient descent to plain stochastic gradient descent. (arXiv:2106.06753v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2004.12908",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vogelstein_J/0/1/0/all/0/1\">Joshua T. Vogelstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dey_J/0/1/0/all/0/1\">Jayanta Dey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Helm_H/0/1/0/all/0/1\">Hayden S. Helm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+LeVine_W/0/1/0/all/0/1\">Will LeVine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehta_R/0/1/0/all/0/1\">Ronak D. Mehta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geisa_A/0/1/0/all/0/1\">Ali Geisa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ven_G/0/1/0/all/0/1\">Gido M. van de Ven</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_E/0/1/0/all/0/1\">Emily Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1\">Chenyu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1\">Weiwei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tower_B/0/1/0/all/0/1\">Bryan Tower</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Larson_J/0/1/0/all/0/1\">Jonathan Larson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+White_C/0/1/0/all/0/1\">Christopher M. White</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Priebe_C/0/1/0/all/0/1\">Carey E. Priebe</a>",
          "description": "In biological learning, data are used to improve performance not only on the\ncurrent task, but also on previously encountered and as yet unencountered\ntasks. In contrast, classical machine learning starts from a blank slate, or\ntabula rasa, using data only for the single task at hand. While typical\ntransfer learning algorithms can improve performance on future tasks, their\nperformance on prior tasks degrades upon learning new tasks (called\ncatastrophic forgetting). Many recent approaches for continual or lifelong\nlearning have attempted to maintain performance given new tasks. But striving\nto avoid forgetting sets the goal unnecessarily low: the goal of lifelong\nlearning, whether biological or artificial, should be to improve performance on\nall tasks (including past and future) with any new data. We propose\nomnidirectional transfer learning algorithms, which includes two special cases\nof interest: decision forests and deep networks. Our key insight is the\ndevelopment of the omni-voter layer, which ensembles representations learned\nindependently on all tasks to jointly decide how to proceed on any given new\ndata point, thereby improving performance on both past and future tasks. Our\nalgorithms demonstrate omnidirectional transfer in a variety of simulated and\nreal data scenarios, including tabular data, image data, spoken data, and\nadversarial tasks. Moreover, they do so with quasilinear space and time\ncomplexity.",
          "link": "http://arxiv.org/abs/2004.12908",
          "publishedOn": "2021-06-15T01:45:19.332Z",
          "wordCount": null,
          "title": "Omnidirectional Transfer for Quasilinear Lifelong Learning. (arXiv:2004.12908v7 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06858",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Deshmukh_S/0/1/0/all/0/1\">Soham Deshmukh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Raj_B/0/1/0/all/0/1\">Bhiksha Raj</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Singh_R/0/1/0/all/0/1\">Rita Singh</a>",
          "description": "While multitask and transfer learning has shown to improve the performance of\nneural networks in limited data settings, they require pretraining of the model\non large datasets beforehand. In this paper, we focus on improving the\nperformance of weakly supervised sound event detection in low data and noisy\nsettings simultaneously without requiring any pretraining task. To that extent,\nwe propose a shared encoder architecture with sound event detection as a\nprimary task and an additional secondary decoder for a self-supervised\nauxiliary task. We empirically evaluate the proposed framework for weakly\nsupervised sound event detection on a remix dataset of the DCASE 2019 task 1\nacoustic scene data with DCASE 2018 Task 2 sounds event data under 0, 10 and 20\ndB SNR. To ensure we retain the localisation information of multiple sound\nevents, we propose a two-step attention pooling mechanism that provides a\ntime-frequency localisation of multiple audio events in the clip. The proposed\nframework with two-step attention outperforms existing benchmark models by\n22.3%, 12.8%, 5.9% on 0, 10 and 20 dB SNR respectively. We carry out an\nablation study to determine the contribution of the auxiliary task and two-step\nattention pooling to the SED performance improvement.",
          "link": "http://arxiv.org/abs/2106.06858",
          "publishedOn": "2021-06-15T01:45:19.330Z",
          "wordCount": 639,
          "title": "Improving weakly supervised sound event detection with self-supervised auxiliary tasks. (arXiv:2106.06858v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2010.09317",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qingqing Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jie Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1\">Yong Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ng_D/0/1/0/all/0/1\">Derrick Wing Kwan Ng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Al_Dhahir_N/0/1/0/all/0/1\">Naofal Al-Dhahir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schober_R/0/1/0/all/0/1\">Robert Schober</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swindlehurst_A/0/1/0/all/0/1\">A. Lee Swindlehurst</a>",
          "description": "Due to the advancements in cellular technologies and the dense deployment of\ncellular infrastructure, integrating unmanned aerial vehicles (UAVs) into the\nfifth-generation (5G) and beyond cellular networks is a promising solution to\nachieve safe UAV operation as well as enabling diversified applications with\nmission-specific payload data delivery. In particular, 5G networks need to\nsupport three typical usage scenarios, namely, enhanced mobile broadband\n(eMBB), ultra-reliable low-latency communications (URLLC), and massive\nmachine-type communications (mMTC). On the one hand, UAVs can be leveraged as\ncost-effective aerial platforms to provide ground users with enhanced\ncommunication services by exploiting their high cruising altitude and\ncontrollable maneuverability in three-dimensional (3D) space. On the other\nhand, providing such communication services simultaneously for both UAV and\nground users poses new challenges due to the need for ubiquitous 3D signal\ncoverage as well as the strong air-ground network interference. Besides the\nrequirement of high-performance wireless communications, the ability to support\neffective and efficient sensing as well as network intelligence is also\nessential for 5G-and-beyond 3D heterogeneous wireless networks with coexisting\naerial and ground users. In this paper, we provide a comprehensive overview of\nthe latest research efforts on integrating UAVs into cellular networks, with an\nemphasis on how to exploit advanced techniques (e.g., intelligent reflecting\nsurface, short packet transmission, energy harvesting, joint communication and\nradar sensing, and edge intelligence) to meet the diversified service\nrequirements of next-generation wireless systems. Moreover, we highlight\nimportant directions for further investigation in future work.",
          "link": "http://arxiv.org/abs/2010.09317",
          "publishedOn": "2021-06-15T01:45:19.304Z",
          "wordCount": 740,
          "title": "A Comprehensive Overview on 5G-and-Beyond Networks with UAVs: From Communications to Sensing and Intelligence. (arXiv:2010.09317v2 [cs.IT] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06926",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1\">Tengyang Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1\">Ching-An Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_N/0/1/0/all/0/1\">Nan Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mineiro_P/0/1/0/all/0/1\">Paul Mineiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_A/0/1/0/all/0/1\">Alekh Agarwal</a>",
          "description": "The use of pessimism, when reasoning about datasets lacking exhaustive\nexploration has recently gained prominence in offline reinforcement learning.\nDespite the robustness it adds to the algorithm, overly pessimistic reasoning\ncan be equally damaging in precluding the discovery of good policies, which is\nan issue for the popular bonus-based pessimism. In this paper, we introduce the\nnotion of Bellman-consistent pessimism for general function approximation:\ninstead of calculating a point-wise lower bound for the value function, we\nimplement pessimism at the initial state over the set of functions consistent\nwith the Bellman equations. Our theoretical guarantees only require Bellman\nclosedness as standard in the exploratory setting, in which case bonus-based\npessimism fails to provide guarantees. Even in the special case of linear MDPs\nwhere stronger function-approximation assumptions hold, our result improves\nupon a recent bonus-based approach by $\\mathcal{O}(d)$ in its sample complexity\nwhen the action space is finite. Remarkably, our algorithms automatically adapt\nto the best bias-variance tradeoff in the hindsight, whereas most prior\napproaches require tuning extra hyperparameters a priori.",
          "link": "http://arxiv.org/abs/2106.06926",
          "publishedOn": "2021-06-15T01:45:19.298Z",
          "wordCount": 601,
          "title": "Bellman-consistent Pessimism for Offline Reinforcement Learning. (arXiv:2106.06926v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06927",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rojas_Gomez_R/0/1/0/all/0/1\">Renan A. Rojas-Gomez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeh_R/0/1/0/all/0/1\">Raymond A. Yeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Do_M/0/1/0/all/0/1\">Minh N. Do</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1\">Anh Nguyen</a>",
          "description": "Recent research in adversarially robust classifiers suggests their\nrepresentations tend to be aligned with human perception, which makes them\nattractive for image synthesis and restoration applications. Despite favorable\nempirical results on a few downstream tasks, their advantages are limited to\nslow and sensitive optimization-based techniques. Moreover, their use on\ngenerative models remains unexplored. This work proposes the use of robust\nrepresentations as a perceptual primitive for feature inversion models, and\nshow its benefits with respect to standard non-robust image features. We\nempirically show that adopting robust representations as an image prior\nsignificantly improves the reconstruction accuracy of CNN-based feature\ninversion models. Furthermore, it allows reconstructing images at multiple\nscales out-of-the-box. Following these findings, we propose an\nencoding-decoding network based on robust representations and show its\nadvantages for applications such as anomaly detection, style transfer and image\ndenoising.",
          "link": "http://arxiv.org/abs/2106.06927",
          "publishedOn": "2021-06-15T01:45:19.290Z",
          "wordCount": 577,
          "title": "Inverting Adversarially Robust Networks for Image Synthesis. (arXiv:2106.06927v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/1905.13298",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Elhoushi_M/0/1/0/all/0/1\">Mostafa Elhoushi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zihao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shafiq_F/0/1/0/all/0/1\">Farhan Shafiq</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Ye Henry Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Joey Yiwei Li</a>",
          "description": "The high computation, memory, and power budgets of inferring convolutional\nneural networks (CNNs) are major bottlenecks of model deployment to edge\ncomputing platforms, e.g., mobile devices and IoT. Moreover, training CNNs is\ntime and energy-intensive even on high-grade servers. Convolution layers and\nfully connected layers, because of their intense use of multiplications, are\nthe dominant contributor to this computation budget.\n\nWe propose to alleviate this problem by introducing two new operations:\nconvolutional shifts and fully-connected shifts which replace multiplications\nwith bitwise shift and sign flipping during both training and inference. During\ninference, both approaches require only 5 bits (or less) to represent the\nweights. This family of neural network architectures (that use convolutional\nshifts and fully connected shifts) is referred to as DeepShift models. We\npropose two methods to train DeepShift models: DeepShift-Q which trains regular\nweights constrained to powers of 2, and DeepShift-PS that trains the values of\nthe shifts and sign flips directly.\n\nVery close accuracy, and in some cases higher accuracy, to baselines are\nachieved. Converting pre-trained 32-bit floating-point baseline models of\nResNet18, ResNet50, VGG16, and GoogleNet to DeepShift and training them for 15\nto 30 epochs, resulted in Top-1/Top-5 accuracies higher than that of the\noriginal model.\n\nLast but not least, we implemented the convolutional shifts and fully\nconnected shift GPU kernels and showed a reduction in latency time of 25% when\ninferring ResNet18 compared to unoptimized multiplication-based GPU kernels.\nThe code can be found at https://github.com/mostafaelhoushi/DeepShift.",
          "link": "http://arxiv.org/abs/1905.13298",
          "publishedOn": "2021-06-15T01:45:19.259Z",
          "wordCount": 786,
          "title": "DeepShift: Towards Multiplication-Less Neural Networks. (arXiv:1905.13298v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06885",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Flaspohler_G/0/1/0/all/0/1\">Genevieve Flaspohler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Orabona_F/0/1/0/all/0/1\">Francesco Orabona</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_J/0/1/0/all/0/1\">Judah Cohen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mouatadid_S/0/1/0/all/0/1\">Soukayna Mouatadid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oprescu_M/0/1/0/all/0/1\">Miruna Oprescu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Orenstein_P/0/1/0/all/0/1\">Paulo Orenstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mackey_L/0/1/0/all/0/1\">Lester Mackey</a>",
          "description": "Inspired by the demands of real-time climate and weather forecasting, we\ndevelop optimistic online learning algorithms that require no parameter tuning\nand have optimal regret guarantees under delayed feedback. Our algorithms --\nDORM, DORMP, and AdaHedgeD -- arise from a novel reduction of delayed online\nlearning to optimistic online learning that reveals how optimistic hints can\nmitigate the regret penalty caused by delay. We pair this delay-as-optimism\nperspective with a new analysis of optimistic learning that exposes its\nrobustness to hinting errors and a new meta-algorithm for learning effective\nhinting strategies in the presence of delay. We conclude by benchmarking our\nalgorithms on four subseasonal climate forecasting tasks, demonstrating low\nregret relative to state-of-the-art forecasting models.",
          "link": "http://arxiv.org/abs/2106.06885",
          "publishedOn": "2021-06-15T01:45:19.232Z",
          "wordCount": 560,
          "title": "Online Learning with Optimism and Delay. (arXiv:2106.06885v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2006.04648",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_G/0/1/0/all/0/1\">Guihua Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chapman_A/0/1/0/all/0/1\">Adriane Chapman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_P/0/1/0/all/0/1\">Pei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_M/0/1/0/all/0/1\">Mingnan Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yingxue Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_D/0/1/0/all/0/1\">Dan Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hall_W/0/1/0/all/0/1\">Wendy Hall</a>",
          "description": "Zero-shot learning uses semantic attributes to connect the search space of\nunseen objects. In recent years, although the deep convolutional network brings\npowerful visual modeling capabilities to the ZSL task, its visual features have\nsevere pattern inertia and lack of representation of semantic relationships,\nwhich leads to severe bias and ambiguity. In response to this, we propose the\nGraph-based Visual-Semantic Entanglement Network to conduct graph modeling of\nvisual features, which is mapped to semantic attributes by using a knowledge\ngraph, it contains several novel designs: 1. it establishes a multi-path\nentangled network with the convolutional neural network (CNN) and the graph\nconvolutional network (GCN), which input the visual features from CNN to GCN to\nmodel the implicit semantic relations, then GCN feedback the graph modeled\ninformation to CNN features; 2. it uses attribute word vectors as the target\nfor the graph semantic modeling of GCN, which forms a self-consistent\nregression for graph modeling and supervise GCN to learn more personalized\nattribute relations; 3. it fuses and supplements the hierarchical\nvisual-semantic features refined by graph modeling into visual embedding. Our\nmethod outperforms state-of-the-art approaches on multiple representative ZSL\ndatasets: AwA2, CUB, and SUN by promoting the semantic linkage modelling of\nvisual features.",
          "link": "http://arxiv.org/abs/2006.04648",
          "publishedOn": "2021-06-15T01:45:19.224Z",
          "wordCount": 699,
          "title": "Graph-based Visual-Semantic Entanglement Network for Zero-shot Image Recognition. (arXiv:2006.04648v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.02194",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Le_D/0/1/0/all/0/1\">Duc Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_M/0/1/0/all/0/1\">Mahaveer Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keren_G/0/1/0/all/0/1\">Gil Keren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Suyoun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yangyang Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahadeokar_J/0/1/0/all/0/1\">Jay Mahadeokar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_J/0/1/0/all/0/1\">Julian Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shangguan_Y/0/1/0/all/0/1\">Yuan Shangguan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fuegen_C/0/1/0/all/0/1\">Christian Fuegen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalinli_O/0/1/0/all/0/1\">Ozlem Kalinli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saraf_Y/0/1/0/all/0/1\">Yatharth Saraf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seltzer_M/0/1/0/all/0/1\">Michael L. Seltzer</a>",
          "description": "How to leverage dynamic contextual information in end-to-end speech\nrecognition has remained an active research area. Previous solutions to this\nproblem were either designed for specialized use cases that did not generalize\nwell to open-domain scenarios, did not scale to large biasing lists, or\nunderperformed on rare long-tail words. We address these limitations by\nproposing a novel solution that combines shallow fusion, trie-based deep\nbiasing, and neural network language model contextualization. These techniques\nresult in significant 19.5% relative Word Error Rate improvement over existing\ncontextual biasing approaches and 5.4%-9.3% improvement compared to a strong\nhybrid baseline on both open-domain and constrained contextualization tasks,\nwhere the targets consist of mostly rare long-tail words. Our final system\nremains lightweight and modular, allowing for quick modification without model\nre-training.",
          "link": "http://arxiv.org/abs/2104.02194",
          "publishedOn": "2021-06-15T01:45:19.216Z",
          "wordCount": 626,
          "title": "Contextualized Streaming End-to-End Speech Recognition with Trie-Based Deep Biasing and Shallow Fusion. (arXiv:2104.02194v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06845",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rongguang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhari_P/0/1/0/all/0/1\">Pratik Chaudhari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Davatzikos_C/0/1/0/all/0/1\">Christos Davatzikos</a>",
          "description": "Heterogeneity in medical data, e.g., from data collected at different sites\nand with different protocols in a clinical study, is a fundamental hurdle for\naccurate prediction using machine learning models, as such models often fail to\ngeneralize well. This paper presents a normalizing-flow-based method to perform\ncounterfactual inference upon a structural causal model (SCM) to harmonize such\ndata. We formulate a causal model for observed effects (brain magnetic\nresonance imaging data) that result from known confounders (site, gender and\nage) and exogenous noise variables. Our method exploits the bijection induced\nby flow for harmonization. We can infer the posterior of exogenous variables,\nintervene on observations, and draw samples from the resultant SCM to obtain\ncounterfactuals. We evaluate on multiple, large, real-world medical datasets to\nobserve that this method leads to better cross-domain generalization compared\nto state-of-the-art algorithms. Further experiments that evaluate the quality\nof confounder-independent data generated by our model using regression and\nclassification tasks are provided.",
          "link": "http://arxiv.org/abs/2106.06845",
          "publishedOn": "2021-06-15T01:45:19.205Z",
          "wordCount": 579,
          "title": "Harmonization with Flow-based Causal Inference. (arXiv:2106.06845v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2003.01926",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Singh_C/0/1/0/all/0/1\">Chandan Singh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ha_W/0/1/0/all/0/1\">Wooseok Ha</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lanusse_F/0/1/0/all/0/1\">Francois Lanusse</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Boehm_V/0/1/0/all/0/1\">Vanessa Boehm</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liu_J/0/1/0/all/0/1\">Jia Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yu_B/0/1/0/all/0/1\">Bin Yu</a>",
          "description": "Machine learning lies at the heart of new possibilities for scientific\ndiscovery, knowledge generation, and artificial intelligence. Its potential\nbenefits to these fields requires going beyond predictive accuracy and focusing\non interpretability. In particular, many scientific problems require\ninterpretations in a domain-specific interpretable feature space (e.g. the\nfrequency domain) whereas attributions to the raw features (e.g. the pixel\nspace) may be unintelligible or even misleading. To address this challenge, we\npropose TRIM (TRansformation IMportance), a novel approach which attributes\nimportances to features in a transformed space and can be applied post-hoc to a\nfully trained model. TRIM is motivated by a cosmological parameter estimation\nproblem using deep neural networks (DNNs) on simulated data, but it is\ngenerally applicable across domains/models and can be combined with any local\ninterpretation method. In our cosmology example, combining TRIM with contextual\ndecomposition shows promising results for identifying which frequencies a DNN\nuses, helping cosmologists to understand and validate that the model learns\nappropriate physical features rather than simulation artifacts.",
          "link": "http://arxiv.org/abs/2003.01926",
          "publishedOn": "2021-06-15T01:45:19.188Z",
          "wordCount": 632,
          "title": "Transformation Importance with Applications to Cosmology. (arXiv:2003.01926v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06713",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xiangyu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Haochen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_W/0/1/0/all/0/1\">Wenqi Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jiliang Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chong Wang</a>",
          "description": "Designing an effective loss function plays a crucial role in training deep\nrecommender systems. Most existing works often leverage a predefined and fixed\nloss function that could lead to suboptimal recommendation quality and training\nefficiency. Some recent efforts rely on exhaustively or manually searched\nweights to fuse a group of candidate loss functions, which is exceptionally\ncostly in computation and time. They also neglect the various convergence\nbehaviors of different data examples. In this work, we propose an AutoLoss\nframework that can automatically and adaptively search for the appropriate loss\nfunction from a set of candidates. To be specific, we develop a novel\ncontroller network, which can dynamically adjust the loss probabilities in a\ndifferentiable manner. Unlike existing algorithms, the proposed controller can\nadaptively generate the loss probabilities for different data examples\naccording to their varied convergence behaviors. Such design improves the\nmodel's generalizability and transferability between deep recommender systems\nand datasets. We evaluate the proposed framework on two benchmark datasets. The\nresults show that AutoLoss outperforms representative baselines. Further\nexperiments have been conducted to deepen our understandings of AutoLoss,\nincluding its transferability, components and training efficiency.",
          "link": "http://arxiv.org/abs/2106.06713",
          "publishedOn": "2021-06-15T01:45:19.177Z",
          "wordCount": 634,
          "title": "AutoLoss: Automated Loss Function Search in Recommendations. (arXiv:2106.06713v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06676",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Devvrit_F/0/1/0/all/0/1\">Fnu Devvrit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajaraman_N/0/1/0/all/0/1\">Nived Rajaraman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awasthi_P/0/1/0/all/0/1\">Pranjal Awasthi</a>",
          "description": "Labelled data often comes at a high cost as it may require recruiting human\nlabelers or running costly experiments. At the same time, in many practical\nscenarios, one already has access to a partially labelled, potentially biased\ndataset that can help with the learning task at hand. Motivated by such\nsettings, we formally initiate a study of $semi-supervised$ $active$ $learning$\nthrough the frame of linear regression. In this setting, the learner has access\nto a dataset $X \\in \\mathbb{R}^{(n_1+n_2) \\times d}$ which is composed of $n_1$\nunlabelled examples that an algorithm can actively query, and $n_2$ examples\nlabelled a-priori. Concretely, denoting the true labels by $Y \\in\n\\mathbb{R}^{n_1 + n_2}$, the learner's objective is to find $\\widehat{\\beta}\n\\in \\mathbb{R}^d$ such that, \\begin{equation}\n\n\\| X \\widehat{\\beta} - Y \\|_2^2 \\le (1 + \\epsilon) \\min_{\\beta \\in\n\\mathbb{R}^d} \\| X \\beta - Y \\|_2^2 \\end{equation} while making as few\nadditional label queries as possible. In order to bound the label queries, we\nintroduce an instance dependent parameter called the reduced rank, denoted by\n$R_X$, and propose an efficient algorithm with query complexity\n$O(R_X/\\epsilon)$. This result directly implies improved upper bounds for two\nimportant special cases: (i) active ridge regression, and (ii) active kernel\nridge regression, where the reduced-rank equates to the statistical dimension,\n$sd_\\lambda$ and effective dimension, $d_\\lambda$ of the problem respectively,\nwhere $\\lambda \\ge 0$ denotes the regularization parameter. For active ridge\nregression we also prove a matching lower bound of $O(sd_\\lambda / \\epsilon)$\non the query complexity of any algorithm. This subsumes prior work that only\nconsidered the unregularized case, i.e., $\\lambda = 0$.",
          "link": "http://arxiv.org/abs/2106.06676",
          "publishedOn": "2021-06-15T01:45:19.150Z",
          "wordCount": 675,
          "title": "Semi-supervised Active Regression. (arXiv:2106.06676v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.02959",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+DAnniballe_V/0/1/0/all/0/1\">Vincent M. D&#x27;Anniballe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tushar_F/0/1/0/all/0/1\">Fakrul I. Tushar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faryna_K/0/1/0/all/0/1\">Khrystyna Faryna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Songyue Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mazurowski_M/0/1/0/all/0/1\">Maciej A. Mazurowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubin_G/0/1/0/all/0/1\">Geoffrey D. Rubin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lo_J/0/1/0/all/0/1\">Joseph Y. Lo</a>",
          "description": "Purpose: To develop high throughput multi-label annotators for body (chest,\nabdomen, and pelvis) Computed Tomography (CT) reports that can be applied\nacross a variety of abnormalities, organs, and disease states.\n\nApproach: We used a dictionary approach to develop rule-based algorithms\n(RBA) for extraction of disease labels from radiology text reports. We targeted\nthree organ systems (lungs/pleura, liver/gallbladder, kidneys/ureters) with\nfour diseases per system based on their prevalence in our dataset. To expand\nthe algorithms beyond pre-defined keywords, attention-guided recurrent neural\nnetworks (RNN) were trained using the RBA-extracted labels to classify reports\nas being positive for one or more diseases or normal for each organ system.\nConfounding effects on model performance were evaluated using random\ninitialization or pre-trained embedding as well as different sizes of training\ndatasets. Performance was evaluated using the receiver operating characteristic\n(ROC) area under the curve (AUC) against 2,158 manually obtained labels.\n\nResults: Our models extracted disease labels from 261,229 radiology reports\nof 112,501 unique subjects. Pre-trained models outperformed random\ninitialization across all diseases. As the training dataset size was reduced,\nperformance was robust except for a few diseases with relatively small number\nof cases. Pre-trained classification AUCs achieved > 0.95 for all five disease\noutcomes across all three organ systems.\n\nConclusions: Our label-extracting pipeline was able to encompass a variety of\ncases and diseases by generalizing beyond strict rules with exceptional\naccuracy. This method can be easily adapted to enable automated labeling of\nhospital-scale medical data sets for training image-based disease classifiers.",
          "link": "http://arxiv.org/abs/2102.02959",
          "publishedOn": "2021-06-15T01:45:19.142Z",
          "wordCount": 748,
          "title": "Multi-Label Annotation of Chest Abdomen Pelvis Computed Tomography Text Reports Using Deep Learning. (arXiv:2102.02959v4 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06561",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chong_M/0/1/0/all/0/1\">Min Jin Chong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Forsyth_D/0/1/0/all/0/1\">David Forsyth</a>",
          "description": "We show how to learn a map that takes a content code, derived from a face\nimage, and a randomly chosen style code to an anime image. We derive an\nadversarial loss from our simple and effective definitions of style and\ncontent. This adversarial loss guarantees the map is diverse -- a very wide\nrange of anime can be produced from a single content code. Under plausible\nassumptions, the map is not just diverse, but also correctly represents the\nprobability of an anime, conditioned on an input face. In contrast, current\nmultimodal generation procedures cannot capture the complex styles that appear\nin anime. Extensive quantitative experiments support the idea the map is\ncorrect. Extensive qualitative results show that the method can generate a much\nmore diverse range of styles than SOTA comparisons. Finally, we show that our\nformalization of content and style allows us to perform video to video\ntranslation without ever training on videos.",
          "link": "http://arxiv.org/abs/2106.06561",
          "publishedOn": "2021-06-15T01:45:19.128Z",
          "wordCount": 609,
          "title": "GANs N' Roses: Stable, Controllable, Diverse Image to Image Translation (works for videos too!). (arXiv:2106.06561v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2006.09179",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Buzzicotti_M/0/1/0/all/0/1\">M. Buzzicotti</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Bonaccorso_F/0/1/0/all/0/1\">F. Bonaccorso</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Leoni_P/0/1/0/all/0/1\">P. Clark Di Leoni</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Biferale_L/0/1/0/all/0/1\">L. Biferale</a>",
          "description": "We study the applicability of tools developed by the computer vision\ncommunity for features learning and semantic image inpainting to perform data\nreconstruction of fluid turbulence configurations. The aim is twofold. First,\nwe explore on a quantitative basis, the capability of Convolutional Neural\nNetworks embedded in a Deep Generative Adversarial Model (Deep-GAN) to generate\nmissing data in turbulence, a paradigmatic high dimensional chaotic system. In\nparticular, we investigate their use in reconstructing two-dimensional damaged\nsnapshots extracted from a large database of numerical configurations of 3d\nturbulence in the presence of rotation, a case with multi-scale random features\nwhere both large-scale organised structures and small-scale highly intermittent\nand non-Gaussian fluctuations are present. Second, following a reverse\nengineering approach, we aim to rank the input flow properties (features) in\nterms of their qualitative and quantitative importance to obtain a better set\nof reconstructed fields. We present two approaches both based on Context\nEncoders. The first one infers the missing data via a minimization of the L2\npixel-wise reconstruction loss, plus a small adversarial penalisation. The\nsecond searches for the closest encoding of the corrupted flow configuration\nfrom a previously trained generator. Finally, we present a comparison with a\ndifferent data assimilation tool, based on Nudging, an equation-informed\nunbiased protocol, well known in the numerical weather prediction community.\nThe TURB-Rot database, this http URL, of roughly 300K 2d\nturbulent images is released and details on how to download it are given.",
          "link": "http://arxiv.org/abs/2006.09179",
          "publishedOn": "2021-06-15T01:45:19.109Z",
          "wordCount": 723,
          "title": "Reconstruction of turbulent data with deep generative models for semantic inpainting from TURB-Rot database. (arXiv:2006.09179v2 [physics.flu-dyn] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.10911",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Liu_K/0/1/0/all/0/1\">Kai-Chun Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Can_M/0/1/0/all/0/1\">Michael Can</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kuo_H/0/1/0/all/0/1\">Heng-Cheng Kuo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hsieh_C/0/1/0/all/0/1\">Chia-Yeh Hsieh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huang_H/0/1/0/all/0/1\">Hsiang-Yun Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chan_C/0/1/0/all/0/1\">Chia-Tai Chan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tsao_Y/0/1/0/all/0/1\">Yu Tsao</a>",
          "description": "Fall detection (FD) systems are important assistive technologies for\nhealthcare that can detect emergency fall events and alert caregivers. However,\nit is not easy to obtain large-scale annotated fall events with various\nspecifications of sensors or sensor positions during the implementation of\naccurate FD systems. Moreover, the knowledge obtained through machine learning\nhas been restricted to tasks in the same domain. The mismatch between different\ndomains might hinder the performance of FD systems. Cross-domain knowledge\ntransfer is very beneficial for machine-learning-based FD systems to train a\nreliable FD model with well-labeled data in new environments. In this study, we\npropose domain-adaptive fall detection (DAFD) using deep adversarial training\n(DAT) to tackle cross-domain problems, such as cross-position and\ncross-configuration. The proposed DAFD can transfer knowledge from the source\ndomain to the target domain by minimizing the domain discrepancy to avoid\nmismatch problems. The experimental results show that the average F1-score\nimprovement when using DAFD ranges from 1.5% to 7% in the cross-position\nscenario, and from 3.5% to 12% in the cross-configuration scenario, compared to\nusing the conventional FD model without domain adaptation training. The results\ndemonstrate that the proposed DAFD successfully helps to deal with cross-domain\nproblems and to achieve better detection performance.",
          "link": "http://arxiv.org/abs/2012.10911",
          "publishedOn": "2021-06-15T01:45:19.094Z",
          "wordCount": 671,
          "title": "Domain-adaptive Fall Detection Using Deep Adversarial Training. (arXiv:2012.10911v2 [eess.SP] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06786",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lamb_A/0/1/0/all/0/1\">Alex Lamb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clanuwat_T/0/1/0/all/0/1\">Tarin Clanuwat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Siyu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bober_Irizar_M/0/1/0/all/0/1\">Mikel Bober-Irizar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kitamoto_A/0/1/0/all/0/1\">Asanobu Kitamoto</a>",
          "description": "Japan is a unique country with a distinct cultural heritage, which is\nreflected in billions of historical documents that have been preserved.\nHowever, the change in Japanese writing system in 1900 made these documents\ninaccessible for the general public. A major research project has been to make\nthese historical documents accessible and understandable. An increasing amount\nof research has focused on the character recognition task and the location of\ncharacters on image, yet less research has focused on how to predict the\nsequential ordering of the characters. This is because sequence in classical\nJapanese is very different from modern Japanese. Ordering characters into a\nsequence is important for making the document text easily readable and\nsearchable. Additionally, it is a necessary step for any kind of natural\nlanguage processing on the data (e.g. machine translation, language modeling,\nand word embeddings). We explore a few approaches to the task of predicting the\nsequential ordering of the characters: one using simple hand-crafted rules,\nanother using hand-crafted rules with adaptive thresholds, and another using a\ndeep recurrent sequence model trained with teacher forcing. We provide a\nquantitative and qualitative comparison of these techniques as well as their\ndistinct trade-offs. Our best-performing system has an accuracy of 98.65\\% and\nhas a perfect accuracy on 49\\% of the books in our dataset, suggesting that the\ntechnique is able to predict the order of the characters well enough for many\ntasks.",
          "link": "http://arxiv.org/abs/2106.06786",
          "publishedOn": "2021-06-15T01:45:19.088Z",
          "wordCount": 673,
          "title": "Predicting the Ordering of Characters in Japanese Historical Documents. (arXiv:2106.06786v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2009.12480",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kurka_D/0/1/0/all/0/1\">David Burth Kurka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gunduz_D/0/1/0/all/0/1\">Deniz G&#xfc;nd&#xfc;z</a>",
          "description": "We propose deep learning based communication methods for adaptive-bandwidth\ntransmission of images over wireless channels. We consider the scenario in\nwhich images are transmitted progressively in layers over time or frequency,\nand such layers can be aggregated by receivers in order to increase the quality\nof their reconstructions. We investigate two scenarios, one in which the layers\nare sent sequentially, and incrementally contribute to the refinement of a\nreconstruction, and another in which the layers are independent and can be\nretrieved in any order. Those scenarios correspond to the well known problems\nof \\textit{successive refinement} and \\textit{multiple descriptions},\nrespectively, in the context of joint source-channel coding (JSCC). We propose\nDeepJSCC-$l$, an innovative solution that uses convolutional autoencoders, and\npresent three architectures with different complexity trade-offs. To the best\nof our knowledge, this is the first practical multiple-description JSCC scheme\ndeveloped and tested for practical information sources and channels. Numerical\nresults show that DeepJSCC-$l$ can learn to transmit the source progressively\nwith negligible losses in the end-to-end performance compared with a single\ntransmission. Moreover, DeepJSCC-$l$ has comparable performance with state of\nthe art digital progressive transmission schemes in the challenging low\nsignal-to-noise ratio (SNR) and small bandwidth regimes, with the additional\nadvantage of graceful degradation with channel SNR.",
          "link": "http://arxiv.org/abs/2009.12480",
          "publishedOn": "2021-06-15T01:45:19.066Z",
          "wordCount": 674,
          "title": "Bandwidth-Agile Image Transmission with Deep Joint Source-Channel Coding. (arXiv:2009.12480v2 [cs.IT] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06607",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ahuja_K/0/1/0/all/0/1\">Kartik Ahuja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caballero_E/0/1/0/all/0/1\">Ethan Caballero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dinghuai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1\">Yoshua Bengio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitliagkas_I/0/1/0/all/0/1\">Ioannis Mitliagkas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rish_I/0/1/0/all/0/1\">Irina Rish</a>",
          "description": "The invariance principle from causality is at the heart of notable approaches\nsuch as invariant risk minimization (IRM) that seek to address\nout-of-distribution (OOD) generalization failures. Despite the promising\ntheory, invariance principle-based approaches fail in common classification\ntasks, where invariant (causal) features capture all the information about the\nlabel. Are these failures due to the methods failing to capture the invariance?\nOr is the invariance principle itself insufficient? To answer these questions,\nwe revisit the fundamental assumptions in linear regression tasks, where\ninvariance-based approaches were shown to provably generalize OOD. In contrast\nto the linear regression tasks, we show that for linear classification tasks we\nneed much stronger restrictions on the distribution shifts, or otherwise OOD\ngeneralization is impossible. Furthermore, even with appropriate restrictions\non distribution shifts in place, we show that the invariance principle alone is\ninsufficient. We prove that a form of the information bottleneck constraint\nalong with invariance helps address key failures when invariant features\ncapture all the information about the label and also retains the existing\nsuccess when they do not. We propose an approach that incorporates both of\nthese principles and demonstrate its effectiveness in several experiments.",
          "link": "http://arxiv.org/abs/2106.06607",
          "publishedOn": "2021-06-15T01:45:19.021Z",
          "wordCount": 625,
          "title": "Invariance Principle Meets Information Bottleneck for Out-of-Distribution Generalization. (arXiv:2106.06607v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2101.06983",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1\">Luyu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yunyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Callan_J/0/1/0/all/0/1\">Jamie Callan</a>",
          "description": "Contrastive learning has been applied successfully to learn vector\nrepresentations of text. Previous research demonstrated that learning\nhigh-quality representations benefits from batch-wise contrastive loss with a\nlarge number of negatives. In practice, the technique of in-batch negative is\nused, where for each example in a batch, other batch examples' positives will\nbe taken as its negatives, avoiding encoding extra negatives. This, however,\nstill conditions each example's loss on all batch examples and requires fitting\nthe entire large batch into GPU memory. This paper introduces a gradient\ncaching technique that decouples backpropagation between contrastive loss and\nthe encoder, removing encoder backward pass data dependency along the batch\ndimension. As a result, gradients can be computed for one subset of the batch\nat a time, leading to almost constant memory usage.",
          "link": "http://arxiv.org/abs/2101.06983",
          "publishedOn": "2021-06-15T01:45:19.013Z",
          "wordCount": 584,
          "title": "Scaling Deep Contrastive Learning Batch Size under Memory Limited Setup. (arXiv:2101.06983v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06848",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Azizi_M/0/1/0/all/0/1\">MohammadJavad Azizi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ross_S/0/1/0/all/0/1\">Sheldon M Ross</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhengyu Zhang</a>",
          "description": "We consider the problem of finding, through adaptive sampling, which of n\npopulations (arms) has the largest mean. Our objective is to determine a rule\nwhich identifies the best population with a fixed minimum confidence using as\nfew observations as possible, i.e. fixed-confidence (FC) best arm\nidentification (BAI) in multi-armed bandits. We study such problems under the\nBayesian setting with both Bernoulli and Gaussian populations. We propose to\nuse the classical vector at a time (VT) rule, which samples each alive\npopulation once in each round. We show how VT can be implemented and analyzed\nin our Bayesian setting and be improved by early elimination. We also propose\nand analyze a variant of the classical play the winner (PW) algorithm.\nNumerical results show that these rules compare favorably with state-of-art\nalgorithms.",
          "link": "http://arxiv.org/abs/2106.06848",
          "publishedOn": "2021-06-15T01:45:19.004Z",
          "wordCount": 555,
          "title": "Guaranteed Fixed-Confidence Best Arm Identification in Multi-Armed Bandit. (arXiv:2106.06848v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00671",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khazatsky_A/0/1/0/all/0/1\">Alexander Khazatsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nair_A/0/1/0/all/0/1\">Ashvin Nair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jing_D/0/1/0/all/0/1\">Daniel Jing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1\">Sergey Levine</a>",
          "description": "A generalist robot equipped with learned skills must be able to perform many\ntasks in many different environments. However, zero-shot generalization to new\nsettings is not always possible. When the robot encounters a new environment or\nobject, it may need to finetune some of its previously learned skills to\naccommodate this change. But crucially, previously learned behaviors and models\nshould still be suitable to accelerate this relearning. In this paper, we aim\nto study how generative models of possible outcomes can allow a robot to learn\nvisual representations of affordances, so that the robot can sample potentially\npossible outcomes in new situations, and then further train its policy to\nachieve those outcomes. In effect, prior data is used to learn what kinds of\noutcomes may be possible, such that when the robot encounters an unfamiliar\nsetting, it can sample potential outcomes from its model, attempt to reach\nthem, and thereby update both its skills and its outcome model. This approach,\nvisuomotor affordance learning (VAL), can be used to train goal-conditioned\npolicies that operate on raw image inputs, and can rapidly learn to manipulate\nnew objects via our proposed affordance-directed exploration scheme. We show\nthat VAL can utilize prior data to solve real-world tasks such drawer opening,\ngrasping, and placing objects in new scenes with only five minutes of online\nexperience in the new scene.",
          "link": "http://arxiv.org/abs/2106.00671",
          "publishedOn": "2021-06-15T01:45:18.979Z",
          "wordCount": 696,
          "title": "What Can I Do Here? Learning New Skills by Imagining Visual Affordances. (arXiv:2106.00671v2 [cs.RO] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.13112",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Beznosikov_A/0/1/0/all/0/1\">Aleksandr Beznosikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samokhin_V/0/1/0/all/0/1\">Valentin Samokhin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gasnikov_A/0/1/0/all/0/1\">Alexander Gasnikov</a>",
          "description": "This paper focuses on the distributed optimization of smooth stochastic\nsaddle-point problems. The first part of the paper is devoted to lower bounds\nfor the cenralized and decentralized distributed methods for smooth\n(strongly-)convex-(strongly-)concave saddle-point problems as well as the\noptimal algorithms by which these bounds are achieved. Next, we present a new\nfederated algorithm for saddle-point problems - Extra Step Local SGD.\nTheoretical analysis of the new method is carried out for\n(strongly-)convex-(strongly-)concave and non-convex-non-concave problems. In\nthe experimental part of the paper, we show the effectiveness of our method in\npractice. In particular, we train GANs in a distributed manner.",
          "link": "http://arxiv.org/abs/2010.13112",
          "publishedOn": "2021-06-15T01:45:18.972Z",
          "wordCount": 598,
          "title": "Distributed Saddle-Point Problems: Lower Bounds, Optimal and Robust Algorithms. (arXiv:2010.13112v6 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2002.07285",
          "author": "<a href=\"http://arxiv.org/find/econ/1/au:+Lewis_G/0/1/0/all/0/1\">Greg Lewis</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Syrgkanis_V/0/1/0/all/0/1\">Vasilis Syrgkanis</a>",
          "description": "We consider the estimation of treatment effects in settings when multiple\ntreatments are assigned over time and treatments can have a causal effect on\nfuture outcomes or the state of the treated unit. We propose an extension of\nthe double/debiased machine learning framework to estimate the dynamic effects\nof treatments, which can be viewed as a Neyman orthogonal (locally robust)\ncross-fitted version of $g$-estimation in the dynamic treatment regime. Our\nmethod applies to a general class of non-linear dynamic treatment models known\nas Structural Nested Mean Models and allows the use of machine learning methods\nto control for potentially high dimensional state variables, subject to a mean\nsquare error guarantee, while still allowing parametric estimation and\nconstruction of confidence intervals for the structural parameters of interest.\nThese structural parameters can be used for off-policy evaluation of any target\ndynamic policy at parametric rates, subject to semi-parametric restrictions on\nthe data generating process. Our work is based on a recursive peeling process,\ntypical in $g$-estimation, and formulates a strongly convex objective at each\nstage, which allows us to extend the $g$-estimation framework in multiple\ndirections: i) to provide finite sample guarantees, ii) to estimate non-linear\neffect heterogeneity with respect to fixed unit characteristics, within\narbitrary function spaces, enabling a dynamic analogue of the RLearner\nalgorithm for heterogeneous effects, iii) to allow for high-dimensional sparse\nparameterizations of the target structural functions, enabling automated model\nselection via a recursive lasso algorithm. We also provide guarantees for data\nstemming from a single treated unit over a long horizon and under stationarity\nconditions.",
          "link": "http://arxiv.org/abs/2002.07285",
          "publishedOn": "2021-06-15T01:45:18.958Z",
          "wordCount": 722,
          "title": "Double/Debiased Machine Learning for Dynamic Treatment Effects via g-Estimation. (arXiv:2002.07285v4 [econ.EM] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.03419",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Duan_S/0/1/0/all/0/1\">Shiyu Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Principe_J/0/1/0/all/0/1\">Jose C. Principe</a>",
          "description": "This tutorial paper surveys training alternatives to end-to-end\nbackpropagation (E2EBP) -- the de facto standard for training deep\narchitectures. Modular training refers to strictly local training without both\nthe forward and the backward pass, i.e., dividing a deep architecture into\nseveral nonoverlapping modules and training them separately without any\nend-to-end operation. Between the fully global E2EBP and the strictly local\nmodular training, there are \"weakly modular\" hybrids performing training\nwithout the backward pass only. These alternatives can match or surpass the\nperformance of E2EBP on challenging datasets such as ImageNet, and are gaining\nincreased attention primarily because they offer practical advantages over\nE2EBP, which will be enumerated herein. In particular, they allow for greater\nmodularity and transparency in deep learning workflows, aligning deep learning\nwith the mainstream computer science engineering that heavily exploits\nmodularization for scalability. Modular training has also revealed novel\ninsights about learning and has further implications on other important\nresearch domains. Specifically, it induces natural and effective solutions to\nsome important practical problems such as data efficiency and transferability\nestimation.",
          "link": "http://arxiv.org/abs/2101.03419",
          "publishedOn": "2021-06-15T01:45:18.946Z",
          "wordCount": 635,
          "title": "Training Deep Architectures Without End-to-End Backpropagation: A Brief Survey. (arXiv:2101.03419v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.09947",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yaodong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zitong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dobriban_E/0/1/0/all/0/1\">Edgar Dobriban</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steinhardt_J/0/1/0/all/0/1\">Jacob Steinhardt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yi Ma</a>",
          "description": "Adversarially trained models exhibit a large generalization gap: they can\ninterpolate the training set even for large perturbation radii, but at the cost\nof large test error on clean samples. To investigate this gap, we decompose the\ntest risk into its bias and variance components and study their behavior as a\nfunction of adversarial training perturbation radii ($\\varepsilon$). We find\nthat the bias increases monotonically with $\\varepsilon$ and is the dominant\nterm in the risk. Meanwhile, the variance is unimodal as a function of\n$\\varepsilon$, peaking near the interpolation threshold for the training set.\nThis characteristic behavior occurs robustly across different datasets and also\nfor other robust training procedures such as randomized smoothing. It thus\nprovides a test for proposed explanations of the generalization gap. We find\nthat some existing explanations fail this test--for instance, by predicting a\nmonotonically increasing variance curve. This underscores the power of\nbias-variance decompositions in modern settings-by providing two measurements\ninstead of one, they can rule out more explanations than test accuracy alone.\nWe also show that bias and variance can provide useful guidance for scalably\nreducing the generalization gap, highlighting pre-training and unlabeled data\nas promising routes.",
          "link": "http://arxiv.org/abs/2103.09947",
          "publishedOn": "2021-06-15T01:45:18.919Z",
          "wordCount": 666,
          "title": "Understanding Generalization in Adversarial Training via the Bias-Variance Decomposition. (arXiv:2103.09947v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.01755",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Haliem_M/0/1/0/all/0/1\">Marina Haliem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mani_G/0/1/0/all/0/1\">Ganapathy Mani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aggarwal_V/0/1/0/all/0/1\">Vaneet Aggarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhargava_B/0/1/0/all/0/1\">Bharat Bhargava</a>",
          "description": "Significant development of ride-sharing services presents a plethora of\nopportunities to transform urban mobility by providing personalized and\nconvenient transportation while ensuring efficiency of large-scale ride\npooling. However, a core problem for such services is route planning for each\ndriver to fulfill the dynamically arriving requests while satisfying given\nconstraints. Current models are mostly limited to static routes with only two\nrides per vehicle (optimally) or three (with heuristics). In this paper, we\npresent a dynamic, demand aware, and pricing-based vehicle-passenger matching\nand route planning framework that (1) dynamically generates optimal routes for\neach vehicle based on online demand, pricing associated with each ride, vehicle\ncapacities and locations. This matching algorithm starts greedily and optimizes\nover time using an insertion operation, (2) involves drivers in the\ndecision-making process by allowing them to propose a different price based on\nthe expected reward for a particular ride as well as the destination locations\nfor future rides, which is influenced by supply-and demand computed by the Deep\nQ-network, (3) allows customers to accept or reject rides based on their set of\npreferences with respect to pricing and delay windows, vehicle type and\ncarpooling preferences, and (4) based on demand prediction, our approach\nre-balances idle vehicles by dispatching them to the areas of anticipated high\ndemand using deep Reinforcement Learning (RL). Our framework is validated using\nthe New York City Taxi public dataset; however, we consider different vehicle\ntypes and designed customer utility functions to validate the setup and study\ndifferent settings. Experimental results show the effectiveness of our approach\nin real-time and large scale settings.",
          "link": "http://arxiv.org/abs/2010.01755",
          "publishedOn": "2021-06-15T01:45:18.897Z",
          "wordCount": 736,
          "title": "A Distributed Model-Free Ride-Sharing Approach for Joint Matching, Pricing, and Dispatching using Deep Reinforcement Learning. (arXiv:2010.01755v2 [cs.MA] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06707",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Barcelo_P/0/1/0/all/0/1\">Pablo Barcel&#xf3;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geerts_F/0/1/0/all/0/1\">Floris Geerts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reutter_J/0/1/0/all/0/1\">Juan Reutter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ryschkov_M/0/1/0/all/0/1\">Maksimilian Ryschkov</a>",
          "description": "Various recent proposals increase the distinguishing power of Graph Neural\nNetworks GNNs by propagating features between $k$-tuples of vertices. The\ndistinguishing power of these \"higher-order'' GNNs is known to be bounded by\nthe $k$-dimensional Weisfeiler-Leman (WL) test, yet their $\\mathcal O(n^k)$\nmemory requirements limit their applicability. Other proposals infuse GNNs with\nlocal higher-order graph structural information from the start, hereby\ninheriting the desirable $\\mathcal O(n)$ memory requirement from GNNs at the\ncost of a one-time, possibly non-linear, preprocessing step. We propose local\ngraph parameter enabled GNNs as a framework for studying the latter kind of\napproaches and precisely characterize their distinguishing power, in terms of a\nvariant of the WL test, and in terms of the graph structural properties that\nthey can take into account. Local graph parameters can be added to any GNN\narchitecture, and are cheap to compute. In terms of expressive power, our\nproposal lies in the middle of GNNs and their higher-order counterparts.\nFurther, we propose several techniques to aide in choosing the right local\ngraph parameters. Our results connect GNNs with deep results in finite model\ntheory and finite variable logics. Our experimental evaluation shows that\nadding local graph parameters often has a positive effect for a variety of\nGNNs, datasets and graph learning tasks.",
          "link": "http://arxiv.org/abs/2106.06707",
          "publishedOn": "2021-06-15T01:45:18.817Z",
          "wordCount": 631,
          "title": "Graph Neural Networks with Local Graph Parameters. (arXiv:2106.06707v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06770",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ortiz_Jimenez_G/0/1/0/all/0/1\">Guillermo Ortiz-Jim&#xe9;nez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moosavi_Dezfooli_S/0/1/0/all/0/1\">Seyed-Mohsen Moosavi-Dezfooli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frossard_P/0/1/0/all/0/1\">Pascal Frossard</a>",
          "description": "For certain infinitely-wide neural networks, the neural tangent kernel (NTK)\ntheory fully characterizes generalization. However, for the networks used in\npractice, the empirical NTK represents only a rough first-order approximation\nof these architectures. Still, a growing body of work keeps leveraging this\napproximation to successfully analyze important deep learning phenomena and\nderive algorithms for new applications. In our work, we provide strong\nempirical evidence to determine the practical validity of such approximation by\nconducting a systematic comparison of the behaviour of different neural\nnetworks and their linear approximations on different tasks. We show that the\nlinear approximations can indeed rank the learning complexity of certain tasks\nfor neural networks, albeit with important nuances. Specifically, we discover\nthat, in contrast to what was previously observed, neural networks do not\nalways perform better than their kernel approximations, and reveal that their\nperformance gap heavily depends on architecture, number of samples and training\ntask. In fact, we show that during training, deep networks increase the\nalignment of their empirical NTK with the target task, which explains why\nlinear approximations at the end of training can better explain the dynamics of\ndeep networks. Overall, our work provides concrete examples of novel deep\nlearning phenomena which can inspire future theoretical research, as well as\nprovides a new perspective on the use of the NTK approximation in deep\nlearning.",
          "link": "http://arxiv.org/abs/2106.06770",
          "publishedOn": "2021-06-15T01:45:18.785Z",
          "wordCount": 655,
          "title": "What can linearized neural networks actually say about generalization?. (arXiv:2106.06770v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06575",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1\">Yonggan Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cox_D/0/1/0/all/0/1\">David Cox</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yingyan Lin</a>",
          "description": "While maximizing deep neural networks' (DNNs') acceleration efficiency\nrequires a joint search/design of three different yet highly coupled aspects,\nincluding the networks, bitwidths, and accelerators, the challenges associated\nwith such a joint search have not yet been fully understood and addressed. The\nkey challenges include (1) the dilemma of whether to explode the memory\nconsumption due to the huge joint space or achieve sub-optimal designs, (2) the\ndiscrete nature of the accelerator design space that is coupled yet different\nfrom that of the networks and bitwidths, and (3) the chicken and egg problem\nassociated with network-accelerator co-search, i.e., co-search requires\noperation-wise hardware cost, which is lacking during search as the optimal\naccelerator depending on the whole network is still unknown during search. To\ntackle these daunting challenges towards optimal and fast development of DNN\naccelerators, we propose a framework dubbed Auto-NBA to enable jointly\nsearching for the Networks, Bitwidths, and Accelerators, by efficiently\nlocalizing the optimal design within the huge joint design space for each\ntarget dataset and acceleration specification. Our Auto-NBA integrates a\nheterogeneous sampling strategy to achieve unbiased search with constant memory\nconsumption, and a novel joint-search pipeline equipped with a generic\ndifferentiable accelerator search engine. Extensive experiments and ablation\nstudies validate that both Auto-NBA generated networks and accelerators\nconsistently outperform state-of-the-art designs (including\nco-search/exploration techniques, hardware-aware NAS methods, and DNN\naccelerators), in terms of search time, task accuracy, and accelerator\nefficiency. Our codes are available at: https://github.com/RICE-EIC/Auto-NBA.",
          "link": "http://arxiv.org/abs/2106.06575",
          "publishedOn": "2021-06-15T01:45:18.779Z",
          "wordCount": 685,
          "title": "Auto-NBA: Efficient and Effective Search Over the Joint Space of Networks, Bitwidths, and Accelerators. (arXiv:2106.06575v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06624",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Leino_K/0/1/0/all/0/1\">Klas Leino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fredrikson_M/0/1/0/all/0/1\">Matt Fredrikson</a>",
          "description": "Certifiable local robustness, which rigorously precludes small-norm\nadversarial examples, has received significant attention as a means of\naddressing security concerns in deep learning. However, for some classification\nproblems, local robustness is not a natural objective, even in the presence of\nadversaries; for example, if an image contains two classes of subjects, the\ncorrect label for the image may be considered arbitrary between the two, and\nthus enforcing strict separation between them is unnecessary. In this work, we\nintroduce two relaxed safety properties for classifiers that address this\nobservation: (1) relaxed top-k robustness, which serves as the analogue of\ntop-k accuracy; and (2) affinity robustness, which specifies which sets of\nlabels must be separated by a robustness margin, and which can be\n$\\epsilon$-close in $\\ell_p$ space. We show how to construct models that can be\nefficiently certified against each relaxed robustness property, and trained\nwith very little overhead relative to standard gradient descent. Finally, we\ndemonstrate experimentally that these relaxed variants of robustness are\nwell-suited to several significant classification problems, leading to lower\nrejection rates and higher certified accuracies than can be obtained when\ncertifying \"standard\" local robustness.",
          "link": "http://arxiv.org/abs/2106.06624",
          "publishedOn": "2021-06-15T01:45:18.764Z",
          "wordCount": 597,
          "title": "Relaxing Local Robustness. (arXiv:2106.06624v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02968",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mahmood_R/0/1/0/all/0/1\">Rafid Mahmood</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fidler_S/0/1/0/all/0/1\">Sanja Fidler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Law_M/0/1/0/all/0/1\">Marc T. Law</a>",
          "description": "Given restrictions on the availability of data, active learning is the\nprocess of training a model with limited labeled data by selecting a core\nsubset of an unlabeled data pool to label. Although selecting the most useful\npoints for training is an optimization problem, the scale of deep learning data\nsets forces most selection strategies to employ efficient heuristics. Instead,\nwe propose a new integer optimization problem for selecting a core set that\nminimizes the discrete Wasserstein distance from the unlabeled pool. We\ndemonstrate that this problem can be tractably solved with a Generalized\nBenders Decomposition algorithm. Our strategy requires high-quality latent\nfeatures which we obtain by unsupervised learning on the unlabeled pool.\nNumerical results on several data sets show that our optimization approach is\ncompetitive with baselines and particularly outperforms them in the low budget\nregime where less than one percent of the data set is labeled.",
          "link": "http://arxiv.org/abs/2106.02968",
          "publishedOn": "2021-06-15T01:45:18.727Z",
          "wordCount": 599,
          "title": "Low Budget Active Learning via Wasserstein Distance: An Integer Programming Approach. (arXiv:2106.02968v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03153",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Min_D/0/1/0/all/0/1\">Dongchan Min</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_D/0/1/0/all/0/1\">Dong Bok Lee</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_E/0/1/0/all/0/1\">Eunho Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hwang_S/0/1/0/all/0/1\">Sung Ju Hwang</a>",
          "description": "With rapid progress in neural text-to-speech (TTS) models, personalized\nspeech generation is now in high demand for many applications. For practical\napplicability, a TTS model should generate high-quality speech with only a few\naudio samples from the given speaker, that are also short in length. However,\nexisting methods either require to fine-tune the model or achieve low\nadaptation quality without fine-tuning. In this work, we propose StyleSpeech, a\nnew TTS model which not only synthesizes high-quality speech but also\neffectively adapts to new speakers. Specifically, we propose Style-Adaptive\nLayer Normalization (SALN) which aligns gain and bias of the text input\naccording to the style extracted from a reference speech audio. With SALN, our\nmodel effectively synthesizes speech in the style of the target speaker even\nfrom single speech audio. Furthermore, to enhance StyleSpeech's adaptation to\nspeech from new speakers, we extend it to Meta-StyleSpeech by introducing two\ndiscriminators trained with style prototypes, and performing episodic training.\nThe experimental results show that our models generate high-quality speech\nwhich accurately follows the speaker's voice with single short-duration (1-3\nsec) speech audio, significantly outperforming baselines.",
          "link": "http://arxiv.org/abs/2106.03153",
          "publishedOn": "2021-06-15T01:45:18.700Z",
          "wordCount": 645,
          "title": "Meta-StyleSpeech : Multi-Speaker Adaptive Text-to-Speech Generation. (arXiv:2106.03153v2 [eess.AS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.05390",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yoo_J/0/1/0/all/0/1\">Jason Yoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joseph_T/0/1/0/all/0/1\">Tony Joseph</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yung_D/0/1/0/all/0/1\">Dylan Yung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nasseri_S/0/1/0/all/0/1\">S. Ali Nasseri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wood_F/0/1/0/all/0/1\">Frank Wood</a>",
          "description": "There are currently many barriers that prevent non-experts from exploiting\nmachine learning solutions ranging from the lack of intuition on statistical\nlearning techniques to the trickiness of hyperparameter tuning. Such barriers\nhave led to an explosion of interest in automated machine learning (AutoML),\nwhereby an off-the-shelf system can take care of many of the steps for\nend-users without the need for expertise in machine learning. This paper\npresents Ensemble Squared (Ensemble$^2$), an AutoML system that ensembles the\nresults of state-of-the-art open-source AutoML systems. Ensemble$^2$ exploits\nthe diversity of existing AutoML systems by leveraging the differences in their\nmodel search space and heuristics. Empirically, we show that diversity of each\nAutoML system is sufficient to justify ensembling at the AutoML system level.\nIn demonstrating this, we also establish new state-of-the-art AutoML results on\nthe OpenML tabular classification benchmark.",
          "link": "http://arxiv.org/abs/2012.05390",
          "publishedOn": "2021-06-15T01:45:18.406Z",
          "wordCount": 591,
          "title": "Ensemble Squared: A Meta AutoML System. (arXiv:2012.05390v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.04222",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Iqbal_S/0/1/0/all/0/1\">Shariq Iqbal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Witt_C/0/1/0/all/0/1\">Christian A. Schroeder de Witt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1\">Bei Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bohmer_W/0/1/0/all/0/1\">Wendelin B&#xf6;hmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Whiteson_S/0/1/0/all/0/1\">Shimon Whiteson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sha_F/0/1/0/all/0/1\">Fei Sha</a>",
          "description": "Multi-agent settings in the real world often involve tasks with varying types\nand quantities of agents and non-agent entities; however, common patterns of\nbehavior often emerge among these agents/entities. Our method aims to leverage\nthese commonalities by asking the question: ``What is the expected utility of\neach agent when only considering a randomly selected sub-group of its observed\nentities?'' By posing this counterfactual question, we can recognize\nstate-action trajectories within sub-groups of entities that we may have\nencountered in another task and use what we learned in that task to inform our\nprediction in the current one. We then reconstruct a prediction of the full\nreturns as a combination of factors considering these disjoint groups of\nentities and train this ``randomly factorized\" value function as an auxiliary\nobjective for value-based multi-agent reinforcement learning. By doing so, our\nmodel can recognize and leverage similarities across tasks to improve learning\nefficiency in a multi-task setting. Our approach, Randomized Entity-wise\nFactorization for Imagined Learning (REFIL), outperforms all strong baselines\nby a significant margin in challenging multi-task StarCraft micromanagement\nsettings.",
          "link": "http://arxiv.org/abs/2006.04222",
          "publishedOn": "2021-06-15T01:45:18.397Z",
          "wordCount": 666,
          "title": "Randomized Entity-wise Factorization for Multi-Agent Reinforcement Learning. (arXiv:2006.04222v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06957",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_F/0/1/0/all/0/1\">Feng Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ning_Y/0/1/0/all/0/1\">Yilin Ning</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1\">Han Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldstein_B/0/1/0/all/0/1\">Benjamin Alan Goldstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ong_M/0/1/0/all/0/1\">Marcus Eng Hock Ong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1\">Nan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_B/0/1/0/all/0/1\">Bibhas Chakraborty</a>",
          "description": "Scoring systems are highly interpretable and widely used to evaluate\ntime-to-event outcomes in healthcare research. However, existing time-to-event\nscores are predominantly created ad-hoc using a few manually selected variables\nbased on clinician's knowledge, suggesting an unmet need for a robust and\nefficient generic score-generating method.\n\nAutoScore was previously developed as an interpretable machine learning score\ngenerator, integrated both machine learning and point-based scores in the\nstrong discriminability and accessibility. We have further extended it to\ntime-to-event data and developed AutoScore-Survival, for automatically\ngenerating time-to-event scores with right-censored survival data. Random\nsurvival forest provides an efficient solution for selecting variables, and Cox\nregression was used for score weighting. We illustrated our method in a\nreal-life study of 90-day mortality of patients in intensive care units and\ncompared its performance with survival models (i.e., Cox) and the random\nsurvival forest.\n\nThe AutoScore-Survival-derived scoring model was more parsimonious than\nsurvival models built using traditional variable selection methods (e.g.,\npenalized likelihood approach and stepwise variable selection), and its\nperformance was comparable to survival models using the same set of variables.\nAlthough AutoScore-Survival achieved a comparable integrated area under the\ncurve of 0.782 (95% CI: 0.767-0.794), the integer-valued time-to-event scores\ngenerated are favorable in clinical applications because they are easier to\ncompute and interpret.\n\nOur proposed AutoScore-Survival provides an automated, robust and easy-to-use\nmachine learning-based clinical score generator to studies of time-to-event\noutcomes. It provides a systematic guideline to facilitate the future\ndevelopment of time-to-event scores for clinical applications.",
          "link": "http://arxiv.org/abs/2106.06957",
          "publishedOn": "2021-06-15T01:45:18.378Z",
          "wordCount": 681,
          "title": "AutoScore-Survival: Developing interpretable machine learning-based time-to-event scores with right-censored survival data. (arXiv:2106.06957v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09369",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wainakh_A/0/1/0/all/0/1\">Aidmar Wainakh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ventola_F/0/1/0/all/0/1\">Fabrizio Ventola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mussig_T/0/1/0/all/0/1\">Till M&#xfc;&#xdf;ig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keim_J/0/1/0/all/0/1\">Jens Keim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cordero_C/0/1/0/all/0/1\">Carlos Garcia Cordero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zimmer_E/0/1/0/all/0/1\">Ephraim Zimmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grube_T/0/1/0/all/0/1\">Tim Grube</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kersting_K/0/1/0/all/0/1\">Kristian Kersting</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muhlhauser_M/0/1/0/all/0/1\">Max M&#xfc;hlh&#xe4;user</a>",
          "description": "Federated learning enables multiple users to build a joint model by sharing\ntheir model updates (gradients), while their raw data remains local on their\ndevices. In contrast to the common belief that this provides privacy benefits,\nwe here add to the very recent results on privacy risks when sharing gradients.\nSpecifically, we propose Label Leakage from Gradients (LLG), a novel attack to\nextract the labels of the users' training data from their shared gradients. The\nattack exploits the direction and magnitude of gradients to determine the\npresence or absence of any label. LLG is simple yet effective, capable of\nleaking potential sensitive information represented by labels, and scales well\nto arbitrary batch sizes and multiple classes. We empirically and\nmathematically demonstrate the validity of our attack under different settings.\nMoreover, empirical results show that LLG successfully extracts labels with\nhigh accuracy at the early stages of model training. We also discuss different\ndefense mechanisms against such leakage. Our findings suggest that gradient\ncompression is a practical technique to prevent our attack.",
          "link": "http://arxiv.org/abs/2105.09369",
          "publishedOn": "2021-06-15T01:45:18.371Z",
          "wordCount": 650,
          "title": "User Label Leakage from Gradients in Federated Learning. (arXiv:2105.09369v3 [cs.CR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06964",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tikhonov_A/0/1/0/all/0/1\">Alexey Tikhonov</a>",
          "description": "Pre-trained word representations became a key component in many NLP tasks.\nHowever, the global geometry of the word embeddings remains poorly understood.\nIn this paper, we demonstrate that a typical word embeddings cloud is shaped as\na high-dimensional simplex with interpretable vertices and propose a simple yet\neffective method for enumeration of these vertices. We show that the proposed\nmethod can detect and describe vertices of the simplex for GloVe and fasttext\nspaces.",
          "link": "http://arxiv.org/abs/2106.06964",
          "publishedOn": "2021-06-15T01:45:18.360Z",
          "wordCount": 514,
          "title": "Shape of Elephant: Study of Macro Properties of Word Embeddings Spaces. (arXiv:2106.06964v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2011.11057",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhao-Zhou Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_Z/0/1/0/all/0/1\">Zhengyi Shao</a>",
          "description": "The Gaussian process (GP) regression can be severely biased when the data are\ncontaminated by outliers. This paper presents a new robust GP regression\nalgorithm that iteratively trims the most extreme data points. While the new\nalgorithm retains the attractive properties of the standard GP as a\nnonparametric and flexible regression method, it can greatly improve the model\naccuracy for contaminated data even in the presence of extreme or abundant\noutliers. It is also easier to implement compared with previous robust GP\nvariants that rely on approximate inference. Applied to a wide range of\nexperiments with different contamination levels, the proposed method\nsignificantly outperforms the standard GP and the popular robust GP variant\nwith the Student-t likelihood in most test cases. In addition, as a practical\nexample in the astrophysical study, we show that this method can precisely\ndetermine the main-sequence ridge line in the color-magnitude diagram of star\nclusters.",
          "link": "http://arxiv.org/abs/2011.11057",
          "publishedOn": "2021-06-15T01:45:18.336Z",
          "wordCount": 633,
          "title": "Robust Gaussian Process Regression Based on Iterative Trimming. (arXiv:2011.11057v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06662",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shakerinava_M/0/1/0/all/0/1\">Mehran Shakerinava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ravanbakhsh_S/0/1/0/all/0/1\">Siamak Ravanbakhsh</a>",
          "description": "Pixelizations of Platonic solids such as the cube and icosahedron have been\nwidely used to represent spherical data, from climate records to Cosmic\nMicrowave Background maps. Platonic solids have well-known global symmetries.\nOnce we pixelize each face of the solid, each face also possesses its own local\nsymmetries in the form of Euclidean isometries. One way to combine these\nsymmetries is through a hierarchy. However, this approach does not adequately\nmodel the interplay between the two levels of symmetry transformations. We show\nhow to model this interplay using ideas from group theory, identify the\nequivariant linear maps, and introduce equivariant padding that respects these\nsymmetries. Deep networks that use these maps as their building blocks\ngeneralize gauge equivariant CNNs on pixelized spheres. These deep networks\nachieve state-of-the-art results on semantic segmentation for climate data and\nomnidirectional image processing. Code is available at https://git.io/JGiZA.",
          "link": "http://arxiv.org/abs/2106.06662",
          "publishedOn": "2021-06-15T01:45:18.324Z",
          "wordCount": 564,
          "title": "Equivariant Networks for Pixelized Spheres. (arXiv:2106.06662v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06777",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hahn_E/0/1/0/all/0/1\">Ernst Moritz Hahn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perez_M/0/1/0/all/0/1\">Mateo Perez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schewe_S/0/1/0/all/0/1\">Sven Schewe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Somenzi_F/0/1/0/all/0/1\">Fabio Somenzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trivedi_A/0/1/0/all/0/1\">Ashutosh Trivedi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wojtczak_D/0/1/0/all/0/1\">Dominik Wojtczak</a>",
          "description": "We study reinforcement learning for the optimal control of Branching Markov\nDecision Processes (BMDPs), a natural extension of (multitype) Branching Markov\nChains (BMCs). The state of a (discrete-time) BMCs is a collection of entities\nof various types that, while spawning other entities, generate a payoff. In\ncomparison with BMCs, where the evolution of a each entity of the same type\nfollows the same probabilistic pattern, BMDPs allow an external controller to\npick from a range of options. This permits us to study the best/worst behaviour\nof the system. We generalise model-free reinforcement learning techniques to\ncompute an optimal control strategy of an unknown BMDP in the limit. We present\nresults of an implementation that demonstrate the practicality of the approach.",
          "link": "http://arxiv.org/abs/2106.06777",
          "publishedOn": "2021-06-15T01:45:18.273Z",
          "wordCount": 568,
          "title": "Model-free Reinforcement Learning for Branching Markov Decision Processes. (arXiv:2106.06777v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2012.12854",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Wu_Z/0/1/0/all/0/1\">Zhaolong Wu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhang_S/0/1/0/all/0/1\">Shuwen Zhang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Wang_W/0/1/0/all/0/1\">Wei Li Wang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ma_Y/0/1/0/all/0/1\">Yinping Ma</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Dong_Y/0/1/0/all/0/1\">Yuanchen Dong</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Mao_Y/0/1/0/all/0/1\">Youdong Mao</a>",
          "description": "The 2.5-MDa 26S proteasome maintains proteostasis and regulates myriad\ncellular processes. How polyubiquitylated substrate interactions regulate\nproteasome activity is not understood. Here we introduce a deep manifold\nlearning framework, named AlphaCryo4D, which enables atomic-level cryogenic\nelectron microscopy (cryo-EM) reconstructions of nonequilibrium conformational\ncontinuum and reconstitutes hidden dynamics of proteasome autoregulation in the\nact of substrate degradation. AlphaCryo4D integrates 3D deep residual learning\nwith manifold embedding of free-energy landscapes, which directs 3D clustering\nvia an energy-based particle-voting algorithm. In blind assessments using\nsimulated heterogeneous cryo-EM datasets, AlphaCryo4D achieved 3D\nclassification accuracy three times that of conventional method and\nreconstructed continuous conformational changes of a 130-kDa protein at\nsub-3-angstrom resolution. By using AlphaCryo4D to analyze a single\nexperimental cryo-EM dataset, we identified 64 conformers of the\nsubstrate-bound human 26S proteasome, revealing conformational entanglement of\ntwo regulatory particles in the doubly capped holoenzymes and their energetic\ndifferences with singly capped ones. Novel ubiquitin-binding sites are\ndiscovered on the RPN2, RPN10 and Alpha5 subunits to remodel polyubiquitin\nchains for deubiquitylation and recycle. Importantly, AlphaCryo4D choreographs\nsingle-nucleotide-exchange dynamics of proteasomal AAA-ATPase motor during\ntranslocation initiation, which upregulates proteolytic activity by\nallosterically promoting nucleophilic attack. Our systemic analysis illuminates\na grand hierarchical allostery for proteasome autoregulation.",
          "link": "http://arxiv.org/abs/2012.12854",
          "publishedOn": "2021-06-15T01:45:18.267Z",
          "wordCount": 671,
          "title": "Deep manifold learning reveals hidden dynamics of proteasome autoregulation. (arXiv:2012.12854v2 [q-bio.QM] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.13658",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Amin_S/0/1/0/all/0/1\">Susan Amin</a> (1 and 2), <a href=\"http://arxiv.org/find/cs/1/au:+Gomrokchi_M/0/1/0/all/0/1\">Maziar Gomrokchi</a> (1 and 2), <a href=\"http://arxiv.org/find/cs/1/au:+Aboutalebi_H/0/1/0/all/0/1\">Hossein Aboutalebi</a> (3), <a href=\"http://arxiv.org/find/cs/1/au:+Satija_H/0/1/0/all/0/1\">Harsh Satija</a> (1 and 2), <a href=\"http://arxiv.org/find/cs/1/au:+Precup_D/0/1/0/all/0/1\">Doina Precup</a> (1 and 2) ((1) McGill University, (2) Mila- Quebec Artificial Intelligence Institute, (3) University of Waterloo)",
          "description": "A major challenge in reinforcement learning is the design of exploration\nstrategies, especially for environments with sparse reward structures and\ncontinuous state and action spaces. Intuitively, if the reinforcement signal is\nvery scarce, the agent should rely on some form of short-term memory in order\nto cover its environment efficiently. We propose a new exploration method,\nbased on two intuitions: (1) the choice of the next exploratory action should\ndepend not only on the (Markovian) state of the environment, but also on the\nagent's trajectory so far, and (2) the agent should utilize a measure of spread\nin the state space to avoid getting stuck in a small region. Our method\nleverages concepts often used in statistical physics to provide explanations\nfor the behavior of simplified (polymer) chains in order to generate persistent\n(locally self-avoiding) trajectories in state space. We discuss the theoretical\nproperties of locally self-avoiding walks and their ability to provide a kind\nof short-term memory through a decaying temporal correlation within the\ntrajectory. We provide empirical evaluations of our approach in a simulated 2D\nnavigation task, as well as higher-dimensional MuJoCo continuous control\nlocomotion tasks with sparse rewards.",
          "link": "http://arxiv.org/abs/2012.13658",
          "publishedOn": "2021-06-15T01:45:18.261Z",
          "wordCount": 683,
          "title": "Locally Persistent Exploration in Continuous Control Tasks with Sparse Rewards. (arXiv:2012.13658v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.05145",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+ODonoghue_B/0/1/0/all/0/1\">Brendan O&#x27;Donoghue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lattimore_T/0/1/0/all/0/1\">Tor Lattimore</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Osband_I/0/1/0/all/0/1\">Ian Osband</a>",
          "description": "We study a version of the classical zero-sum matrix game with unknown payoff\nmatrix and bandit feedback, where the players only observe each others actions\nand a noisy payoff. This generalizes the usual matrix game, where the payoff\nmatrix is known to the players. Despite numerous applications, this problem has\nreceived relatively little attention. Although adversarial bandit algorithms\nachieve low regret, they do not exploit the matrix structure and perform poorly\nrelative to the new algorithms. The main contributions are regret analyses of\nvariants of UCB and K-learning that hold for any opponent, e.g., even when the\nopponent adversarially plays the best-response to the learner's mixed strategy.\nAlong the way, we show that Thompson fails catastrophically in this setting and\nprovide empirical comparison to existing algorithms.",
          "link": "http://arxiv.org/abs/2006.05145",
          "publishedOn": "2021-06-15T01:45:18.255Z",
          "wordCount": 578,
          "title": "Matrix games with bandit feedback. (arXiv:2006.05145v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06895",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Odetola_T/0/1/0/all/0/1\">Tolulope Odetola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khalid_F/0/1/0/all/0/1\">Faiq Khalid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sandefur_T/0/1/0/all/0/1\">Travis Sandefur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohammed_H/0/1/0/all/0/1\">Hawzhin Mohammed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasan_S/0/1/0/all/0/1\">Syed Rafay Hasan</a>",
          "description": "Convolutional Neural Networks (CNN) have shown impressive performance in\ncomputer vision, natural language processing, and many other applications, but\nthey exhibit high computations and substantial memory requirements. To address\nthese limitations, especially in resource-constrained devices, the use of cloud\ncomputing for CNNs is becoming more popular. This comes with privacy and\nlatency concerns that have motivated the designers to develop embedded hardware\naccelerators for CNNs. However, designing a specialized accelerator increases\nthe time-to-market and cost of production. Therefore, to reduce the\ntime-to-market and access to state-of-the-art techniques, CNN hardware mapping\nand deployment on embedded accelerators are often outsourced to untrusted third\nparties, which is going to be more prevalent in futuristic artificial\nintelligence of things (AIoT) systems. These AIoT systems anticipate horizontal\ncollaboration among different resource-constrained AIoT node devices, where CNN\nlayers are partitioned and these devices collaboratively compute complex CNN\ntasks Therefore, there is a dire need to explore this attack surface for\ndesigning secure embedded hardware accelerators for CNNs. Towards this goal, in\nthis paper, we exploited this attack surface to propose an HT-based attack\ncalled FeSHI. This attack exploits the statistical distribution i.e., Gaussian\ndistribution, of the layer-by-layer feature maps of the CNN to design two\ntriggers for stealthy HT with a very low probability of triggering. To\nillustrate the effectiveness of the proposed attack, we deployed the LeNet and\nLeNet-3D on PYNQ to classify the MNIST and CIFAR-10 datasets, respectively, and\ntested FeSHI. The experimental results show that FeSHI utilizes up to 2% extra\nLUTs, and the overall resource overhead is less than 1% compared to the\noriginal designs",
          "link": "http://arxiv.org/abs/2106.06895",
          "publishedOn": "2021-06-15T01:45:18.236Z",
          "wordCount": 700,
          "title": "FeSHI: Feature Map Based Stealthy Hardware Intrinsic Attack. (arXiv:2106.06895v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06596",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Noci_L/0/1/0/all/0/1\">Lorenzo Noci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_K/0/1/0/all/0/1\">Kevin Roth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bachmann_G/0/1/0/all/0/1\">Gregor Bachmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nowozin_S/0/1/0/all/0/1\">Sebastian Nowozin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hofmann_T/0/1/0/all/0/1\">Thomas Hofmann</a>",
          "description": "The \"cold posterior effect\" (CPE) in Bayesian deep learning describes the\nuncomforting observation that the predictive performance of Bayesian neural\nnetworks can be significantly improved if the Bayes posterior is artificially\nsharpened using a temperature parameter T<1. The CPE is problematic in theory\nand practice and since the effect was identified many researchers have proposed\nhypotheses to explain the phenomenon. However, despite this intensive research\neffort the effect remains poorly understood. In this work we provide novel and\nnuanced evidence relevant to existing explanations for the cold posterior\neffect, disentangling three hypotheses: 1. The dataset curation hypothesis of\nAitchison (2020): we show empirically that the CPE does not arise in a real\ncurated data set but can be produced in a controlled experiment with varying\ncuration strength. 2. The data augmentation hypothesis of Izmailov et al.\n(2021) and Fortuin et al. (2021): we show empirically that data augmentation is\nsufficient but not necessary for the CPE to be present. 3. The bad prior\nhypothesis of Wenzel et al. (2020): we use a simple experiment evaluating the\nrelative importance of the prior and the likelihood, strongly linking the CPE\nto the prior. Our results demonstrate how the CPE can arise in isolation from\nsynthetic curation, data augmentation, and bad priors. Cold posteriors observed\n\"in the wild\" are therefore unlikely to arise from a single simple cause; as a\nresult, we do not expect a simple \"fix\" for cold posteriors.",
          "link": "http://arxiv.org/abs/2106.06596",
          "publishedOn": "2021-06-15T01:45:18.194Z",
          "wordCount": 680,
          "title": "Disentangling the Roles of Curation, Data-Augmentation and the Prior in the Cold Posterior Effect. (arXiv:2106.06596v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2008.00483",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fu_Z/0/1/0/all/0/1\">Zuyue Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhuoran Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhaoran Wang</a>",
          "description": "We study the global convergence and global optimality of actor-critic, one of\nthe most popular families of reinforcement learning algorithms. While most\nexisting works on actor-critic employ bi-level or two-timescale updates, we\nfocus on the more practical single-timescale setting, where the actor and\ncritic are updated simultaneously. Specifically, in each iteration, the critic\nupdate is obtained by applying the Bellman evaluation operator only once while\nthe actor is updated in the policy gradient direction computed using the\ncritic. Moreover, we consider two function approximation settings where both\nthe actor and critic are represented by linear or deep neural networks. For\nboth cases, we prove that the actor sequence converges to a globally optimal\npolicy at a sublinear $O(K^{-1/2})$ rate, where $K$ is the number of\niterations. To the best of our knowledge, we establish the rate of convergence\nand global optimality of single-timescale actor-critic with linear function\napproximation for the first time. Moreover, under the broader scope of policy\noptimization with nonlinear function approximation, we prove that actor-critic\nwith deep neural network finds the globally optimal policy at a sublinear rate\nfor the first time.",
          "link": "http://arxiv.org/abs/2008.00483",
          "publishedOn": "2021-06-15T01:45:18.183Z",
          "wordCount": 644,
          "title": "Single-Timescale Actor-Critic Provably Finds Globally Optimal Policy. (arXiv:2008.00483v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.07639",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_H/0/1/0/all/0/1\">Hongyu Gong</a>",
          "description": "Multilingual models are parameter-efficient with the prospect improving\nlow-resource languages by leveraging crosslingual transfer. Despite recent\nadvance in massive multilingual translation with ever-growing model and data,\nhow to effectively train multilingual models has not been well understood. In\nthis paper, we show that a common situation in multilingual training, data\nimbalance among languages, poses optimization tension between high resource and\nlow resource languages where the found multilingual solution is often\nsub-optimal for low resources. We show that common training method which\nupsamples low resources can not robustly optimize population loss with risks of\neither underfitting high resource languages or overfitting low resource ones.\nDrawing on recent findings on the geometry of loss landscape and its effect on\ngeneralization, we propose a principled optimization algorithm, Curvature Aware\nTask Scaling (CATS), which adaptively rescales gradients from different tasks\nwith a meta objective of guiding multilingual training to low-curvature\nneighborhoods with uniformly low loss for all languages. We ran experiments on\ncommon benchmarks (TED, WMT and OPUS-100) with varying degrees of data\nimbalance. CATS effectively improved multilingual optimization and as a result\ndemonstrated consistent gains on low resources ( to BLEU) without hurting high\nresources. In addition, CATS is robust to overparameterization and large batch\nsize training, making it a promising training method for massive multilingual\nmodels that truly improve low resource languages.",
          "link": "http://arxiv.org/abs/2104.07639",
          "publishedOn": "2021-06-15T01:45:18.156Z",
          "wordCount": 685,
          "title": "Robust Optimization for Multilingual Translation with Imbalanced Data. (arXiv:2104.07639v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06947",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_A/0/1/0/all/0/1\">Ailin Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hooi_B/0/1/0/all/0/1\">Bryan Hooi</a>",
          "description": "Given high-dimensional time series data (e.g., sensor data), how can we\ndetect anomalous events, such as system faults and attacks? More challengingly,\nhow can we do this in a way that captures complex inter-sensor relationships,\nand detects and explains anomalies which deviate from these relationships?\nRecently, deep learning approaches have enabled improvements in anomaly\ndetection in high-dimensional datasets; however, existing methods do not\nexplicitly learn the structure of existing relationships between variables, or\nuse them to predict the expected behavior of time series. Our approach combines\na structure learning approach with graph neural networks, additionally using\nattention weights to provide explainability for the detected anomalies.\nExperiments on two real-world sensor datasets with ground truth anomalies show\nthat our method detects anomalies more accurately than baseline approaches,\naccurately captures correlations between sensors, and allows users to deduce\nthe root cause of a detected anomaly.",
          "link": "http://arxiv.org/abs/2106.06947",
          "publishedOn": "2021-06-15T01:45:18.141Z",
          "wordCount": 578,
          "title": "Graph Neural Network-Based Anomaly Detection in Multivariate Time Series. (arXiv:2106.06947v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2103.00164",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Menglin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Z/0/1/0/all/0/1\">Ziqiao Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+King_I/0/1/0/all/0/1\">Irwin King</a>",
          "description": "Dynamic graphs arise in a plethora of practical scenarios such as social\nnetworks, communication networks, and financial transaction networks. Given a\ndynamic graph, it is fundamental and essential to learn a graph representation\nthat is expected not only to preserve structural proximity but also jointly\ncapture the time-evolving patterns. Recently, graph convolutional network (GCN)\nhas been widely explored and used in non-Euclidean application domains. The\nmain success of GCN, especially in handling dependencies and passing messages\nwithin nodes, lies in its approximation to Laplacian smoothing. As a matter of\nfact, this smoothing technique can not only encourage must-link node pairs to\nget closer but also push cannot-link pairs to shrink together, which\npotentially cause serious feature shrink or oversmoothing problem, especially\nwhen stacking graph convolution in multiple layers or steps. For learning\ntime-evolving patterns, a natural solution is to preserve historical state and\ncombine it with the current interactions to obtain the most recent\nrepresentation. Then the serious feature shrink or oversmoothing problem could\nhappen when stacking graph convolution explicitly or implicitly according to\ncurrent prevalent methods, which would make nodes too similar to distinguish\neach other. To solve this problem in dynamic graph embedding, we analyze the\nshrinking properties in the node embedding space at first, and then design a\nsimple yet versatile method, which exploits L2 feature normalization constraint\nto rescale all nodes to hypersphere of a unit ball so that nodes would not\nshrink together, and yet similar nodes can still get closer. Extensive\nexperiments on four real-world dynamic graph datasets compared with competitive\nbaseline models demonstrate the effectiveness of the proposed method.",
          "link": "http://arxiv.org/abs/2103.00164",
          "publishedOn": "2021-06-15T01:45:18.070Z",
          "wordCount": 720,
          "title": "FeatureNorm: L2 Feature Normalization for Dynamic Graph Embedding. (arXiv:2103.00164v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.13962",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Leibfried_F/0/1/0/all/0/1\">Felix Leibfried</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dutordoir_V/0/1/0/all/0/1\">Vincent Dutordoir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+John_S/0/1/0/all/0/1\">ST John</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durrande_N/0/1/0/all/0/1\">Nicolas Durrande</a>",
          "description": "Gaussian processes (GPs) provide a framework for Bayesian inference that can\noffer principled uncertainty estimates for a large range of problems. For\nexample, if we consider regression problems with Gaussian likelihoods, a GP\nmodel enjoys a posterior in closed form. However, identifying the posterior GP\nscales cubically with the number of training examples and requires to store all\nexamples in memory. In order to overcome these obstacles, sparse GPs have been\nproposed that approximate the true posterior GP with pseudo-training examples.\nImportantly, the number of pseudo-training examples is user-defined and enables\ncontrol over computational and memory complexity. In the general case, sparse\nGPs do not enjoy closed-form solutions and one has to resort to approximate\ninference. In this context, a convenient choice for approximate inference is\nvariational inference (VI), where the problem of Bayesian inference is cast as\nan optimization problem -- namely, to maximize a lower bound of the log\nmarginal likelihood. This paves the way for a powerful and versatile framework,\nwhere pseudo-training examples are treated as optimization arguments of the\napproximate posterior that are jointly identified together with hyperparameters\nof the generative model (i.e. prior and likelihood). The framework can\nnaturally handle a wide scope of supervised learning problems, ranging from\nregression with heteroscedastic and non-Gaussian likelihoods to classification\nproblems with discrete labels, but also multilabel problems. The purpose of\nthis tutorial is to provide access to the basic matter for readers without\nprior knowledge in both GPs and VI. A proper exposition to the subject enables\nalso access to more recent advances (like importance-weighted VI as well as\ninterdomain, multioutput and deep GPs) that can serve as an inspiration for new\nresearch ideas.",
          "link": "http://arxiv.org/abs/2012.13962",
          "publishedOn": "2021-06-15T01:45:18.022Z",
          "wordCount": 810,
          "title": "A Tutorial on Sparse Gaussian Processes and Variational Inference. (arXiv:2012.13962v10 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2002.04839",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ziyin_L/0/1/0/all/0/1\">Liu Ziyin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhikang T.Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ueda_M/0/1/0/all/0/1\">Masahito Ueda</a>",
          "description": "We identity a by-far-unrecognized problem of Adam-style optimizers which\nresults from unnecessary coupling between momentum and adaptivity. The coupling\nleads to instability and divergence when the momentum and adaptivity parameters\nare mismatched. In this work, we propose a method, Laprop, which decouples\nmomentum and adaptivity in the Adam-style methods. We show that the decoupling\nleads to greater flexibility in the hyperparameters and allows for a\nstraightforward interpolation between the signed gradient methods and the\nadaptive gradient methods. We experimentally show that Laprop has consistently\nimproved speed and stability over Adam on a variety of tasks. We also bound the\nregret of Laprop on a convex problem and show that our bound differs from that\nof Adam by a key factor, which demonstrates its advantage.",
          "link": "http://arxiv.org/abs/2002.04839",
          "publishedOn": "2021-06-15T01:45:18.015Z",
          "wordCount": 587,
          "title": "LaProp: Separating Momentum and Adaptivity in Adam. (arXiv:2002.04839v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06788",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qiufeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_X/0/1/0/all/0/1\">Xin Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1\">Shuxia Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_S/0/1/0/all/0/1\">Shiyu Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_L/0/1/0/all/0/1\">Lei Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_N/0/1/0/all/0/1\">Ning Xu</a>",
          "description": "Although deep learning has made significant progress on fixed large-scale\ndatasets, it typically encounters challenges regarding improperly detecting\nnew/unseen classes in the open-world classification, over-parametrized, and\noverfitting small samples. In contrast, biological systems can overcome the\nabove difficulties very well. Individuals inherit an innate gene from\ncollective creatures that have evolved over hundreds of millions of years, and\ncan learn new skills through a few examples. Inspired by this, we propose a\npractical collective-individual paradigm where open-world tasks are trained in\nsequence using an evolution (expandable) network. To be specific, we\ninnovatively introduce learngene that inherits the meta-knowledge from the\ncollective model and reconstructs a new lightweight individual model for the\ntarget task, to realize the collective-individual paradigm. Particularly, we\npresent a novel criterion that can discover the learngene in the collective\nmodel, according to the gradient information. Finally, the individual model is\ntrained only with a few samples in the absence of the source data. We\ndemonstrate the effectiveness of our approach in an extensive empirical study\nand theoretical analysis.",
          "link": "http://arxiv.org/abs/2106.06788",
          "publishedOn": "2021-06-15T01:45:17.959Z",
          "wordCount": 601,
          "title": "Learngene: From Open-World to Your Learning Task. (arXiv:2106.06788v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2101.07393",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hanjie_A/0/1/0/all/0/1\">Austin W. Hanjie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_V/0/1/0/all/0/1\">Victor Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narasimhan_K/0/1/0/all/0/1\">Karthik Narasimhan</a>",
          "description": "We investigate the use of natural language to drive the generalization of\ncontrol policies and introduce the new multi-task environment Messenger with\nfree-form text manuals describing the environment dynamics. Unlike previous\nwork, Messenger does not assume prior knowledge connecting text and state\nobservations $-$ the control policy must simultaneously ground the game manual\nto entity symbols and dynamics in the environment. We develop a new model, EMMA\n(Entity Mapper with Multi-modal Attention) which uses an entity-conditioned\nattention module that allows for selective focus over relevant descriptions in\nthe manual for each entity in the environment. EMMA is end-to-end\ndifferentiable and learns a latent grounding of entities and dynamics from text\nto observations using only environment rewards. EMMA achieves successful\nzero-shot generalization to unseen games with new dynamics, obtaining a 40%\nhigher win rate compared to multiple baselines. However, win rate on the\nhardest stage of Messenger remains low (10%), demonstrating the need for\nadditional work in this direction.",
          "link": "http://arxiv.org/abs/2101.07393",
          "publishedOn": "2021-06-15T01:45:17.930Z",
          "wordCount": 638,
          "title": "Grounding Language to Entities and Dynamics for Generalization in Reinforcement Learning. (arXiv:2101.07393v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.04657",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sandler_M/0/1/0/all/0/1\">Mark Sandler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vladymyrov_M/0/1/0/all/0/1\">Max Vladymyrov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhmoginov_A/0/1/0/all/0/1\">Andrey Zhmoginov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miller_N/0/1/0/all/0/1\">Nolan Miller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jackson_A/0/1/0/all/0/1\">Andrew Jackson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madams_T/0/1/0/all/0/1\">Tom Madams</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arcas_B/0/1/0/all/0/1\">Blaise Aguera y Arcas</a>",
          "description": "In this paper, we introduce a new type of generalized neural network where\nneurons and synapses maintain multiple states. We show that classical\ngradient-based backpropagation in neural networks can be seen as a special case\nof a two-state network where one state is used for activations and another for\ngradients, with update rules derived from the chain rule. In our generalized\nframework, networks have neither explicit notion of nor ever receive gradients.\nThe synapses and neurons are updated using a bidirectional Hebb-style update\nrule parameterized by a shared low-dimensional \"genome\". We show that such\ngenomes can be meta-learned from scratch, using either conventional\noptimization techniques, or evolutionary strategies, such as CMA-ES. Resulting\nupdate rules generalize to unseen tasks and train faster than gradient descent\nbased optimizers for several standard computer vision and synthetic tasks.",
          "link": "http://arxiv.org/abs/2104.04657",
          "publishedOn": "2021-06-15T01:45:17.924Z",
          "wordCount": 600,
          "title": "Meta-Learning Bidirectional Update Rules. (arXiv:2104.04657v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06680",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_M/0/1/0/all/0/1\">Mridul Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_Q/0/1/0/all/0/1\">Qinbo Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aggarwal_V/0/1/0/all/0/1\">Vaneet Aggarwal</a>",
          "description": "We consider the problem of constrained Markov Decision Process (CMDP) where\nan agent interacts with a unichain Markov Decision Process. At every\ninteraction, the agent obtains a reward. Further, there are $K$ cost functions.\nThe agent aims to maximize the long-term average reward while simultaneously\nkeeping the $K$ long-term average costs lower than a certain threshold. In this\npaper, we propose CMDP-PSRL, a posterior sampling based algorithm using which\nthe agent can learn optimal policies to interact with the CMDP. Further, for\nMDP with $S$ states, $A$ actions, and diameter $D$, we prove that following\nCMDP-PSRL algorithm, the agent can bound the regret of not accumulating rewards\nfrom optimal policy by $\\Tilde{O}(poly(DSA)\\sqrt{T})$. Further, we show that\nthe violations for any of the $K$ constraints is also bounded by\n$\\Tilde{O}(poly(DSA)\\sqrt{T})$. To the best of our knowledge, this is the first\nwork which obtains a $\\Tilde{O}(\\sqrt{T})$ regret bounds for ergodic MDPs with\nlong-term average constraints.",
          "link": "http://arxiv.org/abs/2106.06680",
          "publishedOn": "2021-06-15T01:45:17.918Z",
          "wordCount": 583,
          "title": "Markov Decision Processes with Long-Term Average Constraints. (arXiv:2106.06680v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.09626",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wenjie Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barik_A/0/1/0/all/0/1\">Adarsh Barik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Honorio_J/0/1/0/all/0/1\">Jean Honorio</a>",
          "description": "Stochastic high dimensional bandit problems with low dimensional structures\nare useful in different applications such as online advertising and drug\ndiscovery. In this work, we propose a simple unified algorithm for such\nproblems and present a general analysis framework for the regret upper bound of\nour algorithm. We show that under some mild unified assumptions, our algorithm\ncan be applied to different high dimensional bandit problems. Our framework\nutilizes the low dimensional structure to guide the parameter estimation in the\nproblem, therefore our algorithm achieves the best regret bounds in the LASSO\nbandit, as well as novel bounds in the low-rank matrix bandit, the group sparse\nmatrix bandit, and in a new problem: the multi-agent LASSO bandit.",
          "link": "http://arxiv.org/abs/2102.09626",
          "publishedOn": "2021-06-15T01:45:17.912Z",
          "wordCount": 574,
          "title": "A Simple Unified Framework for High Dimensional Bandit Problems. (arXiv:2102.09626v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06842",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Keynan_S/0/1/0/all/0/1\">Shai Keynan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarafian_E/0/1/0/all/0/1\">Elad Sarafian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kraus_S/0/1/0/all/0/1\">Sarit Kraus</a>",
          "description": "The Reinforcement Learning (RL) building blocks, i.e. Q-functions and policy\nnetworks, usually take elements from the cartesian product of two domains as\ninput. In particular, the input of the Q-function is both the state and the\naction, and in multi-task problems (Meta-RL) the policy can take a state and a\ncontext. Standard architectures tend to ignore these variables' underlying\ninterpretations and simply concatenate their features into a single vector. In\nthis work, we argue that this choice may lead to poor gradient estimation in\nactor-critic algorithms and high variance learning steps in Meta-RL algorithms.\nTo consider the interaction between the input variables, we suggest using a\nHypernetwork architecture where a primary network determines the weights of a\nconditional dynamic network. We show that this approach improves the gradient\napproximation and reduces the learning step variance, which both accelerates\nlearning and improves the final performance. We demonstrate a consistent\nimprovement across different locomotion tasks and different algorithms both in\nRL (TD3 and SAC) and in Meta-RL (MAML and PEARL).",
          "link": "http://arxiv.org/abs/2106.06842",
          "publishedOn": "2021-06-15T01:45:17.835Z",
          "wordCount": 597,
          "title": "Recomposing the Reinforcement Learning Building Blocks with Hypernetworks. (arXiv:2106.06842v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06843",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Hangyu Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jinjin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shiqing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1\">Yaochu Jin</a>",
          "description": "Federated learning is an emerging distributed machine learning framework for\nprivacy preservation. However, models trained in federated learning usually\nhave worse performance than those trained in the standard centralized learning\nmode, especially when the training data are not independent and identically\ndistributed (Non-IID) on the local devices. In this survey, we pro-vide a\ndetailed analysis of the influence of Non-IID data on both parametric and\nnon-parametric machine learning models in both horizontal and vertical\nfederated learning. In addition, cur-rent research work on handling challenges\nof Non-IID data in federated learning are reviewed, and both advantages and\ndisadvantages of these approaches are discussed. Finally, we suggest several\nfuture research directions before concluding the paper.",
          "link": "http://arxiv.org/abs/2106.06843",
          "publishedOn": "2021-06-15T01:45:17.830Z",
          "wordCount": 543,
          "title": "Federated Learning on Non-IID Data: A Survey. (arXiv:2106.06843v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2003.11991",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Gupta_S/0/1/0/all/0/1\">Shantanu Gupta</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lipton_Z/0/1/0/all/0/1\">Zachary C. Lipton</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Childers_D/0/1/0/all/0/1\">David Childers</a>",
          "description": "Given a causal graph, the do-calculus can express treatment effects as\nfunctionals of the observational joint distribution that can be estimated\nempirically. Sometimes the do-calculus identifies multiple valid formulae,\nprompting us to compare the statistical properties of the corresponding\nestimators. For example, the backdoor formula applies when all confounders are\nobserved and the frontdoor formula applies when an observed mediator transmits\nthe causal effect. In this paper, we investigate the over-identified scenario\nwhere both confounders and mediators are observed, rendering both estimators\nvalid. Addressing the linear Gaussian causal model, we demonstrate that either\nestimator can dominate the other by an unbounded constant factor. Next, we\nderive an optimal estimator, which leverages all observed variables, and bound\nits finite-sample variance. We show that it strictly outperforms the backdoor\nand frontdoor estimators and that this improvement can be unbounded. We also\npresent a procedure for combining two datasets, one with observed confounders\nand another with observed mediators. Finally, we evaluate our methods on both\nsimulated data and the IHDP and JTPA datasets.",
          "link": "http://arxiv.org/abs/2003.11991",
          "publishedOn": "2021-06-15T01:45:17.824Z",
          "wordCount": 630,
          "title": "Estimating Treatment Effects with Observed Confounders and Mediators. (arXiv:2003.11991v3 [stat.ME] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1911.11090",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Elsken_T/0/1/0/all/0/1\">Thomas Elsken</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Staffler_B/0/1/0/all/0/1\">Benedikt Staffler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Metzen_J/0/1/0/all/0/1\">Jan Hendrik Metzen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hutter_F/0/1/0/all/0/1\">Frank Hutter</a>",
          "description": "The recent progress in neural architecture search (NAS) has allowed scaling\nthe automated design of neural architectures to real-world domains, such as\nobject detection and semantic segmentation. However, one prerequisite for the\napplication of NAS are large amounts of labeled data and compute resources.\nThis renders its application challenging in few-shot learning scenarios, where\nmany related tasks need to be learned, each with limited amounts of data and\ncompute time. Thus, few-shot learning is typically done with a fixed neural\narchitecture. To improve upon this, we propose MetaNAS, the first method which\nfully integrates NAS with gradient-based meta-learning. MetaNAS optimizes a\nmeta-architecture along with the meta-weights during meta-training. During\nmeta-testing, architectures can be adapted to a novel task with a few steps of\nthe task optimizer, that is: task adaptation becomes computationally cheap and\nrequires only little data per task. Moreover, MetaNAS is agnostic in that it\ncan be used with arbitrary model-agnostic meta-learning algorithms and\narbitrary gradient-based NAS methods. %We present encouraging results for\nMetaNAS with a combination of DARTS and REPTILE on few-shot classification\nbenchmarks. Empirical results on standard few-shot classification benchmarks\nshow that MetaNAS with a combination of DARTS and REPTILE yields\nstate-of-the-art results.",
          "link": "http://arxiv.org/abs/1911.11090",
          "publishedOn": "2021-06-15T01:45:17.818Z",
          "wordCount": 676,
          "title": "Meta-Learning of Neural Architectures for Few-Shot Learning. (arXiv:1911.11090v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06946",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Horvath_M/0/1/0/all/0/1\">Mikl&#xf3;s Z. Horv&#xe1;th</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muller_M/0/1/0/all/0/1\">Mark Niklas M&#xfc;ller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fischer_M/0/1/0/all/0/1\">Marc Fischer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vechev_M/0/1/0/all/0/1\">Martin Vechev</a>",
          "description": "Randomized Smoothing (RS) is a promising method for obtaining robustness\ncertificates by evaluating a base model under noise. In this work we: (i)\ntheoretically motivate why ensembles are a particularly suitable choice as base\nmodels for RS, and (ii) empirically confirm this choice, obtaining state of the\nart results in multiple settings. The key insight of our work is that the\nreduced variance of ensembles over the perturbations introduced in RS leads to\nsignificantly more consistent classifications for a given input, in turn\nleading to substantially increased certifiable radii for difficult samples. We\nalso introduce key optimizations which enable an up to 50-fold decrease in\nsample complexity of RS, thus drastically reducing its computational overhead.\nExperimentally, we show that ensembles of only 3 to 10 classifiers consistently\nimprove on the strongest single model with respect to their average certified\nradius (ACR) by 5% to 21% on both CIFAR-10 and ImageNet. On the latter, we\nachieve a state-of-the-art ACR of 1.11. We release all code and models required\nto reproduce our results upon publication.",
          "link": "http://arxiv.org/abs/2106.06946",
          "publishedOn": "2021-06-15T01:45:17.801Z",
          "wordCount": 608,
          "title": "Boosting Randomized Smoothing with Variance Reduced Classifiers. (arXiv:2106.06946v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2007.01612",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Neu_G/0/1/0/all/0/1\">Gergely Neu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Olkhovskaya_J/0/1/0/all/0/1\">Julia Olkhovskaya</a>",
          "description": "We consider an online learning problem where the learner interacts with a\nMarkov decision process in a sequence of episodes, where the reward function is\nallowed to change between episodes in an adversarial manner and the learner\nonly gets to observe the rewards associated with its actions. We allow the\nstate space to be arbitrarily large, but we assume that all action-value\nfunctions can be represented as linear functions in terms of a known\nlow-dimensional feature map, and that the learner has access to a simulator of\nthe environment that allows generating trajectories from the true MDP dynamics.\nOur main contribution is developing a computationally efficient algorithm that\nwe call MDP-LinExp3, and prove that its regret is bounded by\n$\\widetilde{\\mathcal{O}}\\big(H^2 T^{2/3} (dK)^{1/3}\\big)$, where $T$ is the\nnumber of episodes, $H$ is the number of steps in each episode, $K$ is the\nnumber of actions, and $d$ is the dimension of the feature map. We also show\nthat the regret can be improved to $\\widetilde{\\mathcal{O}}\\big(H^2\n\\sqrt{TdK}\\big)$ under much stronger assumptions on the MDP dynamics. To our\nknowledge, MDP-LinExp3 is the first provably efficient algorithm for this\nproblem setting.",
          "link": "http://arxiv.org/abs/2007.01612",
          "publishedOn": "2021-06-15T01:45:17.795Z",
          "wordCount": 646,
          "title": "Online learning in MDPs with linear function approximation and bandit feedback. (arXiv:2007.01612v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06743",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Varmazyar_H/0/1/0/all/0/1\">Hadi Varmazyar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yousefi_Banaem_H/0/1/0/all/0/1\">Hossein Yousefi-Banaem</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Malekzadeh_S/0/1/0/all/0/1\">Saber Malekzadeh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gharehaghaji_N/0/1/0/all/0/1\">Nahideh Gharehaghaji</a>",
          "description": "Background: Alzheimers disease is a progressive neurodegenerative disorder\nand the main cause of dementia in aging. Hippocampus is prone to changes in the\nearly stages of Alzheimers disease. Detection and observation of the\nhippocampus changes using magnetic resonance imaging (MRI) before the onset of\nAlzheimers disease leads to the faster preventive and therapeutic measures.\nObjective: The aim of this study was the segmentation of the hippocampus in\nmagnetic resonance (MR) images of Alzheimers patients using deep machine\nlearning method. Methods: U-Net architecture of convolutional neural network\nwas proposed to segment the hippocampus in the real MRI data. The MR images of\nthe 100 and 35 patients available in Alzheimers disease Neuroimaging Initiative\n(ADNI) dataset, was used for the train and test of the model, respectively. The\nperformance of the proposed method was compared with manual segmentation by\nmeasuring the similarity metrics. Results: The desired segmentation achieved\nafter 10 iterations. A Dice similarity coefficient (DSC) = 92.3%, sensitivity =\n96.5%, positive predicted value (PPV) = 90.4%, and Intersection over Union\n(IoU) value for the train 92.94 and test 92.93 sets were obtained which are\nacceptable. Conclusion: The proposed approach is promising and can be extended\nin the prognosis of Alzheimers disease by the prediction of the hippocampus\nvolume changes in the early stage of the disease.",
          "link": "http://arxiv.org/abs/2106.06743",
          "publishedOn": "2021-06-15T01:45:17.789Z",
          "wordCount": 674,
          "title": "Hippocampus segmentation in magnetic resonance images of Alzheimer's patients using Deep machine learning. (arXiv:2106.06743v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.06548",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sukhbaatar_S/0/1/0/all/0/1\">Sainbayar Sukhbaatar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ju_D/0/1/0/all/0/1\">Da Ju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poff_S/0/1/0/all/0/1\">Spencer Poff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roller_S/0/1/0/all/0/1\">Stephen Roller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szlam_A/0/1/0/all/0/1\">Arthur Szlam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weston_J/0/1/0/all/0/1\">Jason Weston</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_A/0/1/0/all/0/1\">Angela Fan</a>",
          "description": "Attention mechanisms have shown promising results in sequence modeling tasks\nthat require long-term memory. Recent work investigated mechanisms to reduce\nthe computational cost of preserving and storing memories. However, not all\ncontent in the past is equally important to remember. We propose Expire-Span, a\nmethod that learns to retain the most important information and expire the\nirrelevant information. This forgetting of memories enables Transformers to\nscale to attend over tens of thousands of previous timesteps efficiently, as\nnot all states from previous timesteps are preserved. We demonstrate that\nExpire-Span can help models identify and retain critical information and show\nit can achieve strong performance on reinforcement learning tasks specifically\ndesigned to challenge this functionality. Next, we show that Expire-Span can\nscale to memories that are tens of thousands in size, setting a new state of\nthe art on incredibly long context tasks such as character-level language\nmodeling and a frame-by-frame moving objects task. Finally, we analyze the\nefficiency of Expire-Span compared to existing approaches and demonstrate that\nit trains faster and uses less memory.",
          "link": "http://arxiv.org/abs/2105.06548",
          "publishedOn": "2021-06-15T01:45:17.782Z",
          "wordCount": 645,
          "title": "Not All Memories are Created Equal: Learning to Forget by Expiring. (arXiv:2105.06548v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.15134",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wen_Z/0/1/0/all/0/1\">Zixin Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuanzhi Li</a>",
          "description": "How can neural networks trained by contrastive learning extract features from\nthe unlabeled data? Why does contrastive learning usually need much stronger\ndata augmentations than supervised learning to ensure good representations?\nThese questions involve both the optimization and statistical aspects of deep\nlearning, but can hardly be answered by analyzing supervised learning, where\nthe target functions are the highest pursuit. Indeed, in self-supervised\nlearning, it is inevitable to relate to the optimization/generalization of\nneural networks to how they can encode the latent structures in the data, which\nwe refer to as the feature learning process.\n\nIn this work, we formally study how contrastive learning learns the feature\nrepresentations for neural networks by analyzing its feature learning process.\nWe consider the case where our data are comprised of two types of features: the\nmore semantically aligned sparse features which we want to learn from, and the\nother dense features we want to avoid. Theoretically, we prove that contrastive\nlearning using $\\mathbf{ReLU}$ networks provably learns the desired sparse\nfeatures if proper augmentations are adopted. We present an underlying\nprinciple called $\\textbf{feature decoupling}$ to explain the effects of\naugmentations, where we theoretically characterize how augmentations can reduce\nthe correlations of dense features between positive samples while keeping the\ncorrelations of sparse features intact, thereby forcing the neural networks to\nlearn from the self-supervision of sparse features. Empirically, we verified\nthat the feature decoupling principle matches the underlying mechanism of\ncontrastive learning in practice.",
          "link": "http://arxiv.org/abs/2105.15134",
          "publishedOn": "2021-06-15T01:45:17.776Z",
          "wordCount": 703,
          "title": "Toward Understanding the Feature Learning Process of Self-supervised Contrastive Learning. (arXiv:2105.15134v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.01558",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_R/0/1/0/all/0/1\">Rui Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1\">Yanmin Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yuanxiong Guo</a>",
          "description": "Federated learning (FL) enables distributed agents to collaboratively learn a\ncentralized model without sharing their raw data with each other. However, data\nlocality does not provide sufficient privacy protection, and it is desirable to\nfacilitate FL with rigorous differential privacy (DP) guarantee. Existing DP\nmechanisms would introduce random noise with magnitude proportional to the\nmodel size, which can be quite large in deep neural networks. In this paper, we\npropose a new FL framework with sparsification-amplified privacy. Our approach\nintegrates random sparsification with gradient perturbation on each agent to\namplify privacy guarantee. Since sparsification would increase the number of\ncommunication rounds required to achieve a certain target accuracy, which is\nunfavorable for DP guarantee, we further introduce acceleration techniques to\nhelp reduce the privacy cost. We rigorously analyze the convergence of our\napproach and utilize Renyi DP to tightly account the end-to-end DP guarantee.\nExtensive experiments on benchmark datasets validate that our approach\noutperforms previous differentially-private FL approaches in both privacy\nguarantee and communication efficiency.",
          "link": "http://arxiv.org/abs/2008.01558",
          "publishedOn": "2021-06-15T01:45:17.756Z",
          "wordCount": 637,
          "title": "Federated Learning with Sparsification-Amplified Privacy and Adaptive Optimization. (arXiv:2008.01558v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.04223",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sayin_M/0/1/0/all/0/1\">Muhammed O. Sayin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parise_F/0/1/0/all/0/1\">Francesca Parise</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ozdaglar_A/0/1/0/all/0/1\">Asuman Ozdaglar</a>",
          "description": "We present fictitious play dynamics for stochastic games and analyze its\nconvergence properties in zero-sum stochastic games. Our dynamics involves\nplayers forming beliefs on opponent strategy and their own continuation payoff\n(Q-function), and playing a greedy best response using estimated continuation\npayoffs. Players update their beliefs from observations of opponent actions. A\nkey property of the learning dynamics is that update of the beliefs on\nQ-functions occurs at a slower timescale than update of the beliefs on\nstrategies. We show both in the model-based and model-free cases (without\nknowledge of player payoff functions and state transition probabilities), the\nbeliefs on strategies converge to a stationary mixed Nash equilibrium of the\nzero-sum stochastic game.",
          "link": "http://arxiv.org/abs/2010.04223",
          "publishedOn": "2021-06-15T01:45:17.749Z",
          "wordCount": 596,
          "title": "Fictitious play in zero-sum stochastic games. (arXiv:2010.04223v4 [cs.GT] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.05724",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Indelman_H/0/1/0/all/0/1\">Hedda Cohen Indelman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hazan_T/0/1/0/all/0/1\">Tamir Hazan</a>",
          "description": "Direct loss minimization is a popular approach for learning predictors over\nstructured label spaces. This approach is computationally appealing as it\nreplaces integration with optimization and allows to propagate gradients in a\ndeep net using loss-perturbed prediction. Recently, this technique was extended\nto generative models, while introducing a randomized predictor that samples a\nstructure from a randomly perturbed score function. In this work, we learn the\nvariance of these randomized structured predictors and show that it balances\nbetter between the learned score function and the randomized noise in\nstructured prediction. We demonstrate empirically the effectiveness of learning\nthe balance between the signal and the random noise in structured discrete\nspaces.",
          "link": "http://arxiv.org/abs/2007.05724",
          "publishedOn": "2021-06-15T01:45:17.741Z",
          "wordCount": 566,
          "title": "Learning Randomly Perturbed Structured Predictors for Direct Loss Minimization. (arXiv:2007.05724v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2002.10904",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rucker_M/0/1/0/all/0/1\">Mark A. Rucker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watson_L/0/1/0/all/0/1\">Layne T. Watson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barnes_L/0/1/0/all/0/1\">Laura E. Barnes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gerber_M/0/1/0/all/0/1\">Matthew S. Gerber</a>",
          "description": "It has been well demonstrated that inverse reinforcement learning (IRL) is an\neffective technique for teaching machines to perform tasks at human skill\nlevels given human demonstrations (i.e., human to machine apprenticeship\nlearning). This paper seeks to show that a similar application can be\ndemonstrated with human learners. That is, given demonstrations from human\nexperts inverse reinforcement learning techniques can be used to teach other\nhumans to perform at higher skill levels (i.e., human to human apprenticeship\nlearning). To show this two experiments were conducted using a simple,\nreal-time web game where players were asked to touch targets in order to earn\nas many points as possible. For the experiment player performance was defined\nas the number of targets a player touched, irrespective of the points that a\nplayer actually earned. This allowed for in-game points to be modified and the\neffect of these alterations on performance measured. At no time were\nparticipants told the true performance metric. To determine the point\nmodifications IRL was applied on demonstrations of human experts playing the\ngame. The results of the experiment show with significance that performance\nimproved over the control for select treatment groups. Finally, in addition to\nthe experiment, we also detail the algorithmic challenges we faced when\nconducting the experiment and the techniques we used to overcome them.",
          "link": "http://arxiv.org/abs/2002.10904",
          "publishedOn": "2021-06-15T01:45:17.735Z",
          "wordCount": 701,
          "title": "Human Apprenticeship Learning via Kernel-based Inverse Reinforcement Learning. (arXiv:2002.10904v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.06648",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ndiaye_E/0/1/0/all/0/1\">Eugene Ndiaye</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Takeuchi_I/0/1/0/all/0/1\">Ichiro Takeuchi</a>",
          "description": "Conformal prediction constructs a confidence set for an unobserved response\nof a feature vector based on previous identically distributed and exchangeable\nobservations of responses and features. It has a coverage guarantee at any\nnominal level without additional assumptions on their distribution. Its\ncomputation deplorably requires a refitting procedure for all replacement\ncandidates of the target response. In regression settings, this corresponds to\nan infinite number of model fit. Apart from relatively simple estimators that\ncan be written as pieces of linear function of the response, efficiently\ncomputing such sets is difficult and is still considered as an open problem. We\nexploit the fact that, \\emph{often}, conformal prediction sets are intervals\nwhose boundaries can be efficiently approximated by classical root-finding\nalgorithm. We investigate how this approach can overcome many limitations of\nformerly used strategies and we discuss its complexity and drawbacks.",
          "link": "http://arxiv.org/abs/2104.06648",
          "publishedOn": "2021-06-15T01:45:17.727Z",
          "wordCount": 581,
          "title": "Root-finding Approaches for Computing Conformal Prediction Set. (arXiv:2104.06648v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06896",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yunhao Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mengmeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianbu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1\">Weiwei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_R/0/1/0/all/0/1\">Ran Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_Q/0/1/0/all/0/1\">Qian Du</a>",
          "description": "The monitoring of coastal wetlands is of great importance to the protection\nof marine and terrestrial ecosystems. However, due to the complex environment,\nsevere vegetation mixture, and difficulty of access, it is impossible to\naccurately classify coastal wetlands and identify their species with\ntraditional classifiers. Despite the integration of multisource remote sensing\ndata for performance enhancement, there are still challenges with acquiring and\nexploiting the complementary merits from multisource data. In this paper, the\nDeepwise Feature Interaction Network (DFINet) is proposed for wetland\nclassification. A depthwise cross attention module is designed to extract\nself-correlation and cross-correlation from multisource feature pairs. In this\nway, meaningful complementary information is emphasized for classification.\nDFINet is optimized by coordinating consistency loss, discrimination loss, and\nclassification loss. Accordingly, DFINet reaches the standard solution-space\nunder the regularity of loss functions, while the spatial consistency and\nfeature discrimination are preserved. Comprehensive experimental results on two\nhyperspectral and multispectral wetland datasets demonstrate that the proposed\nDFINet outperforms other competitive methods in terms of overall accuracy.",
          "link": "http://arxiv.org/abs/2106.06896",
          "publishedOn": "2021-06-15T01:45:17.709Z",
          "wordCount": 621,
          "title": "Hyperspectral and Multispectral Classification for Coastal Wetland Using Depthwise Feature Interaction Network. (arXiv:2106.06896v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06898",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zongyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kovachki_N/0/1/0/all/0/1\">Nikola Kovachki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azizzadenesheli_K/0/1/0/all/0/1\">Kamyar Azizzadenesheli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Burigede Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharya_K/0/1/0/all/0/1\">Kaushik Bhattacharya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stuart_A/0/1/0/all/0/1\">Andrew Stuart</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1\">Anima Anandkumar</a>",
          "description": "Chaotic systems are notoriously challenging to predict because of their\ninstability. Small errors accumulate in the simulation of each time step,\nresulting in completely different trajectories. However, the trajectories of\nmany prominent chaotic systems live in a low-dimensional subspace (attractor).\nIf the system is Markovian, the attractor is uniquely determined by the Markov\noperator that maps the evolution of infinitesimal time steps. This makes it\npossible to predict the behavior of the chaotic system by learning the Markov\noperator even if we cannot predict the exact trajectory. Recently, a new\nframework for learning resolution-invariant solution operators for PDEs was\nproposed, known as neural operators. In this work, we train a Markov neural\noperator (MNO) with only the local one-step evolution information. We then\ncompose the learned operator to obtain the global attractor and invariant\nmeasure. Such a Markov neural operator forms a discrete semigroup and we\nempirically observe that does not collapse or blow up. Experiments show neural\noperators are more accurate and stable compared to previous methods on chaotic\nsystems such as the Kuramoto-Sivashinsky and Navier-Stokes equations.",
          "link": "http://arxiv.org/abs/2106.06898",
          "publishedOn": "2021-06-15T01:45:17.702Z",
          "wordCount": 611,
          "title": "Markov Neural Operators for Learning Chaotic Systems. (arXiv:2106.06898v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/1912.09522",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Siqi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hauskrecht_M/0/1/0/all/0/1\">Milos Hauskrecht</a>",
          "description": "Continuous-time event sequences represent discrete events occurring in\ncontinuous time. Such sequences arise frequently in real-life. Usually we\nexpect the sequences to follow some regular pattern over time. However,\nsometimes these patterns may be interrupted by unexpected absence or\noccurrences of events. Identification of these unexpected cases can be very\nimportant as they may point to abnormal situations that need human attention.\nIn this work, we study and develop methods for detecting outliers in\ncontinuous-time event sequences, including unexpected absence and unexpected\noccurrences of events. Since the patterns that event sequences tend to follow\nmay change in different contexts, we develop outlier detection methods based on\npoint processes that can take context information into account. Our methods are\nbased on Bayesian decision theory and hypothesis testing with theoretical\nguarantees. To test the performance of the methods, we conduct experiments on\nboth synthetic data and real-world clinical data and show the effectiveness of\nthe proposed methods.",
          "link": "http://arxiv.org/abs/1912.09522",
          "publishedOn": "2021-06-15T01:45:17.696Z",
          "wordCount": 616,
          "title": "Event Outlier Detection in Continuous Time. (arXiv:1912.09522v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.07435",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shiebler_D/0/1/0/all/0/1\">Dan Shiebler</a>",
          "description": "We adapt previous research on category theory and topological unsupervised\nlearning to develop a functorial perspective on manifold learning. We first\ncharacterize manifold learning algorithms as functors that map pseudometric\nspaces to optimization objectives and factor through hierachical clustering\nfunctors. We then use this characterization to prove refinement bounds on\nmanifold learning loss functions and construct a hierarchy of manifold learning\nalgorithms based on their invariants. We express several popular manifold\nlearning algorithms as functors at different levels of this hierarchy,\nincluding Metric Multidimensional Scaling, IsoMap, and UMAP. Next, we use\ninterleaving distance to study the stability of a broad class of manifold\nlearning algorithms. We present bounds on how closely the embeddings these\nalgorithms produce from noisy data approximate the embeddings they would learn\nfrom noiseless data. Finally, we use our framework to derive a set of novel\nmanifold learning algorithms, which we experimentally demonstrate are\ncompetitive with the state of the art.",
          "link": "http://arxiv.org/abs/2011.07435",
          "publishedOn": "2021-06-15T01:45:17.688Z",
          "wordCount": 619,
          "title": "Functorial Manifold Learning. (arXiv:2011.07435v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06955",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maene_J/0/1/0/all/0/1\">Jaron Maene</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Mingxiao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moens_M/0/1/0/all/0/1\">Marie-Francine Moens</a>",
          "description": "The lottery ticket hypothesis states that sparse subnetworks exist in\nrandomly initialized dense networks that can be trained to the same accuracy as\nthe dense network they reside in. However, the subsequent work has failed to\nreplicate this on large-scale models and required rewinding to an early stable\nstate instead of initialization. We show that by using a training method that\nis stable with respect to linear mode connectivity, large networks can also be\nentirely rewound to initialization. Our subsequent experiments on common vision\ntasks give strong credence to the hypothesis in Evci et al. (2020b) that\nlottery tickets simply retrain to the same regions (although not necessarily to\nthe same basin). These results imply that existing lottery tickets could not\nhave been found without the preceding dense training by iterative magnitude\npruning, raising doubts about the use of the lottery ticket hypothesis.",
          "link": "http://arxiv.org/abs/2106.06955",
          "publishedOn": "2021-06-15T01:45:17.682Z",
          "wordCount": 566,
          "title": "Towards Understanding Iterative Magnitude Pruning: Why Lottery Tickets Win. (arXiv:2106.06955v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2012.08156",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1\">Sagar Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1\">Keke Chen</a>",
          "description": "With the ever-growing data and the need for developing powerful machine\nlearning models, data owners increasingly depend on various untrusted platforms\n(e.g., public clouds, edges, and machine learning service providers) for\nscalable processing or collaborative learning. Thus, sensitive data and models\nare in danger of unauthorized access, misuse, and privacy compromises. A\nrelatively new body of research confidentially trains machine learning models\non protected data to address these concerns. In this survey, we summarize\nnotable studies in this emerging area of research. With a unified framework, we\nhighlight the critical challenges and innovations in outsourcing machine\nlearning confidentially. We focus on the cryptographic approaches for\nconfidential machine learning (CML), primarily on model training, while also\ncovering other directions such as perturbation-based approaches and CML in the\nhardware-assisted computing environment. The discussion will take a holistic\nway to consider a rich context of the related threat models, security\nassumptions, design principles, and associated trade-offs amongst data utility,\ncost, and confidentiality.",
          "link": "http://arxiv.org/abs/2012.08156",
          "publishedOn": "2021-06-15T01:45:17.676Z",
          "wordCount": 618,
          "title": "Confidential Machine Learning on Untrusted Platforms: A Survey. (arXiv:2012.08156v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.00382",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1\">Dong-Ki Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Miao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riemer_M/0/1/0/all/0/1\">Matthew Riemer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1\">Chuangchuang Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdulhai_M/0/1/0/all/0/1\">Marwa Abdulhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Habibi_G/0/1/0/all/0/1\">Golnaz Habibi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lopez_Cot_S/0/1/0/all/0/1\">Sebastian Lopez-Cot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tesauro_G/0/1/0/all/0/1\">Gerald Tesauro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+How_J/0/1/0/all/0/1\">Jonathan P. How</a>",
          "description": "A fundamental challenge in multiagent reinforcement learning is to learn\nbeneficial behaviors in a shared environment with other simultaneously learning\nagents. In particular, each agent perceives the environment as effectively\nnon-stationary due to the changing policies of other agents. Moreover, each\nagent is itself constantly learning, leading to natural non-stationarity in the\ndistribution of experiences encountered. In this paper, we propose a novel\nmeta-multiagent policy gradient theorem that directly accounts for the\nnon-stationary policy dynamics inherent to multiagent learning settings. This\nis achieved by modeling our gradient updates to consider both an agent's own\nnon-stationary policy dynamics and the non-stationary policy dynamics of other\nagents in the environment. We show that our theoretically grounded approach\nprovides a general solution to the multiagent learning problem, which\ninherently comprises all key aspects of previous state of the art approaches on\nthis topic. We test our method on a diverse suite of multiagent benchmarks and\ndemonstrate a more efficient ability to adapt to new agents as they learn than\nbaseline methods across the full spectrum of mixed incentive, competitive, and\ncooperative domains.",
          "link": "http://arxiv.org/abs/2011.00382",
          "publishedOn": "2021-06-15T01:45:17.659Z",
          "wordCount": 704,
          "title": "A Policy Gradient Algorithm for Learning to Learn in Multiagent Reinforcement Learning. (arXiv:2011.00382v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.01158",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tushar_F/0/1/0/all/0/1\">Fakrul Islam Tushar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DAnniballe_V/0/1/0/all/0/1\">Vincent M. D&#x27;Anniballe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_R/0/1/0/all/0/1\">Rui Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mazurowski_M/0/1/0/all/0/1\">Maciej A. Mazurowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_W/0/1/0/all/0/1\">Wanyi Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samei_E/0/1/0/all/0/1\">Ehsan Samei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubin_G/0/1/0/all/0/1\">Geoffrey D. Rubin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lo_J/0/1/0/all/0/1\">Joseph Y. Lo</a>",
          "description": "Background: Training deep learning classifiers typically requires massive\namounts of manual annotation. Weak supervision may leverage existing medical\ndata to classify multiple diseases and organ systems. Purpose: To design\nmulti-disease classifiers for body computed tomography (CT) scans using\nautomatically extracted labels from radiology text reports. Materials &\nMethods: This retrospective study deployed rule-based algorithms to extract\n19,255 disease labels from reports of 13,667 body CT scans of 12,092 subjects\nfor training. Using a 3D DenseVNet, three organ systems were segmented:\nlungs/pleura, liver/gallbladder, and kidneys/ureters. For each organ, a 3D\nconvolutional neural network classified normality versus four common diseases.\nTesting was performed on an additional 2,158 CT volumes relative to 2,875\nmanually derived reference labels. Results: Manual validation of the extracted\nlabels confirmed 91 to 99% accuracy. Performance using the receiver operating\ncharacteristic area under the curve (AUC) for lungs/pleura labels were as\nfollows: atelectasis 0.77 (95% CI: 0.74 to 0.81), nodule 0.65 (0.61 to 0.69),\nemphysema 0.89 (0.86 to 0.92), effusion 0.97 (0.96 to 0.98), and normal 0.89\n(0.87 to 0.91). For liver/gallbladder: stone 0.62 (0.56 to 0.67), lesion 0.73\n(0.69 to 0.77), dilation 0.87 (0.84 to 0.90), fatty 0.89 (0.86 to 0.92), and\nnormal 0.82 (0.78 to 0.85). For kidneys/ureters: stone 0.83 (0.79 to 0.87),\natrophy 0.92 (0.89 to 0.94), lesion 0.68 (0.64 to 0.72), cyst 0.70 (0.66 to\n0.73), and normal 0.79 (0.75 to 0.83). Conclusion: Weakly supervised deep\nlearning classifiers leveraged massive amounts of unannotated body CT data to\nclassify multiple organ systems and diverse diseases.",
          "link": "http://arxiv.org/abs/2008.01158",
          "publishedOn": "2021-06-15T01:45:17.653Z",
          "wordCount": 749,
          "title": "Multi-Disease Classification of 13,667 Body CT Scans Using Weakly Supervised Deep Learning. (arXiv:2008.01158v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06828",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1\">Ying Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hui Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yaodong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Z/0/1/0/all/0/1\">Zheng Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Minne Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jun Wang</a>",
          "description": "Trust region methods are widely applied in single-agent reinforcement\nlearning problems due to their monotonic performance-improvement guarantee at\nevery iteration. Nonetheless, when applied in multi-agent settings, the\nguarantee of trust region methods no longer holds because an agent's payoff is\nalso affected by other agents' adaptive behaviors. To tackle this problem, we\nconduct a game-theoretical analysis in the policy space, and propose a\nmulti-agent trust region learning method (MATRL), which enables trust region\noptimization for multi-agent learning. Specifically, MATRL finds a stable\nimprovement direction that is guided by the solution concept of Nash\nequilibrium at the meta-game level. We derive the monotonic improvement\nguarantee in multi-agent settings and empirically show the local convergence of\nMATRL to stable fixed points in the two-player rotational differential game. To\ntest our method, we evaluate MATRL in both discrete and continuous multiplayer\ngeneral-sum games including checker and switch grid worlds, multi-agent MuJoCo,\nand Atari games. Results suggest that MATRL significantly outperforms strong\nmulti-agent reinforcement learning baselines.",
          "link": "http://arxiv.org/abs/2106.06828",
          "publishedOn": "2021-06-15T01:45:17.645Z",
          "wordCount": 626,
          "title": "A Game-Theoretic Approach to Multi-Agent Trust Region Optimization. (arXiv:2106.06828v1 [cs.MA])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06621",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Greydanus_S/0/1/0/all/0/1\">Sam Greydanus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Stefan Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fern_A/0/1/0/all/0/1\">Alan Fern</a>",
          "description": "Neural networks are a popular tool for modeling sequential data but they\ngenerally do not treat time as a continuous variable. Neural ODEs represent an\nimportant exception: they parameterize the time derivative of a hidden state\nwith a neural network and then integrate over arbitrary amounts of time. But\nthese parameterizations, which have arbitrary curvature, can be hard to\nintegrate and thus train and evaluate. In this paper, we propose making a\npiecewise-constant approximation to Neural ODEs to mitigate these issues. Our\nmodel can be integrated exactly via Euler integration and can generate\nautoregressive samples in 3-20 times fewer steps than comparable RNN and\nODE-RNN models. We evaluate our model on several synthetic physics tasks and a\nplanning task inspired by the game of billiards. We find that it matches the\nperformance of baseline approaches while requiring less time to train and\nevaluate.",
          "link": "http://arxiv.org/abs/2106.06621",
          "publishedOn": "2021-06-15T01:45:17.639Z",
          "wordCount": 566,
          "title": "Piecewise-constant Neural ODEs. (arXiv:2106.06621v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06761",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Burduk_R/0/1/0/all/0/1\">Robert Burduk</a>",
          "description": "The ensemble methods are meta-algorithms that combine several base machine\nlearning techniques to increase the effectiveness of the classification. Many\nexisting committees of classifiers use the classifier selection process to\ndetermine the optimal set of base classifiers. In this article, we propose the\nclassifiers selection framework with relearning base classifiers. Additionally,\nwe use in the proposed framework the new generated feature, which can be\nobtained after the relearning process. The proposed technique was compared with\nstate-of-the-art ensemble methods using three benchmark datasets and one\nsynthetic dataset. Four classification performance measures are used to\nevaluate the proposed method.",
          "link": "http://arxiv.org/abs/2106.06761",
          "publishedOn": "2021-06-15T01:45:17.623Z",
          "wordCount": 515,
          "title": "Relearning ensemble selection based on new generated features. (arXiv:2106.06761v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2009.05567",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brophy_J/0/1/0/all/0/1\">Jonathan Brophy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lowd_D/0/1/0/all/0/1\">Daniel Lowd</a>",
          "description": "Responding to user data deletion requests, removing noisy examples, or\ndeleting corrupted training data are just a few reasons for wanting to delete\ninstances from a machine learning (ML) model. However, efficiently removing\nthis data from an ML model is generally difficult. In this paper, we introduce\ndata removal-enabled (DaRE) forests, a variant of random forests that enables\nthe removal of training data with minimal retraining. Model updates for each\nDaRE tree in the forest are exact, meaning that removing instances from a DaRE\nmodel yields exactly the same model as retraining from scratch on updated data.\n\nDaRE trees use randomness and caching to make data deletion efficient. The\nupper levels of DaRE trees use random nodes, which choose split attributes and\nthresholds uniformly at random. These nodes rarely require updates because they\nonly minimally depend on the data. At the lower levels, splits are chosen to\ngreedily optimize a split criterion such as Gini index or mutual information.\nDaRE trees cache statistics at each node and training data at each leaf, so\nthat only the necessary subtrees are updated as data is removed. For numerical\nattributes, greedy nodes optimize over a random subset of thresholds, so that\nthey can maintain statistics while approximating the optimal threshold. By\nadjusting the number of thresholds considered for greedy nodes, and the number\nof random nodes, DaRE trees can trade off between more accurate predictions and\nmore efficient updates.\n\nIn experiments on 13 real-world datasets and one synthetic dataset, we find\nDaRE forests delete data orders of magnitude faster than retraining from\nscratch while sacrificing little to no predictive power.",
          "link": "http://arxiv.org/abs/2009.05567",
          "publishedOn": "2021-06-15T01:45:17.617Z",
          "wordCount": 726,
          "title": "Machine Unlearning for Random Forests. (arXiv:2009.05567v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.05153",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Chen_X/0/1/0/all/0/1\">Xin Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1\">Yingying Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shimada_J/0/1/0/all/0/1\">Jun Shimada</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_N/0/1/0/all/0/1\">Na Li</a>",
          "description": "This paper studies the automated control method for regulating air\nconditioner (AC) loads in incentive-based residential demand response (DR). The\ncritical challenge is that the customer responses to load adjustment are\nuncertain and unknown in practice. In this paper, we formulate the AC control\nproblem in a DR event as a multi-period stochastic optimization that integrates\nthe indoor thermal dynamics and customer opt-out status transition.\nSpecifically, machine learning techniques including Gaussian process and\nlogistic regression are employed to learn the unknown thermal dynamics model\nand customer opt-out behavior model, respectively. We consider two typical DR\nobjectives for AC load control: 1) minimizing the total demand, 2) closely\ntracking a regulated power trajectory. Based on the Thompson sampling\nframework, we propose an online DR control algorithm to learn customer\nbehaviors and make real-time AC control schemes. This algorithm considers the\ninfluence of various environmental factors on customer behaviors and is\nimplemented in a distributed fashion to preserve the privacy of customers.\nNumerical simulations demonstrate the control optimality and learning\nefficiency of the proposed algorithm.",
          "link": "http://arxiv.org/abs/2010.05153",
          "publishedOn": "2021-06-15T01:45:17.611Z",
          "wordCount": 626,
          "title": "Online Learning and Distributed Control for Residential Demand Response. (arXiv:2010.05153v2 [eess.SY] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.03323",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Podkopaev_A/0/1/0/all/0/1\">Aleksandr Podkopaev</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ramdas_A/0/1/0/all/0/1\">Aaditya Ramdas</a>",
          "description": "Trustworthy deployment of ML models requires a proper measure of uncertainty,\nespecially in safety-critical applications. We focus on uncertainty\nquantification (UQ) for classification problems via two avenues -- prediction\nsets using conformal prediction and calibration of probabilistic predictors by\npost-hoc binning -- since these possess distribution-free guarantees for i.i.d.\ndata. Two common ways of generalizing beyond the i.i.d. setting include\nhandling covariate and label shift. Within the context of distribution-free UQ,\nthe former has already received attention, but not the latter. It is known that\nlabel shift hurts prediction, and we first argue that it also hurts UQ, by\nshowing degradation in coverage and calibration. Piggybacking on recent\nprogress in addressing label shift (for better prediction), we examine the\nright way to achieve UQ by reweighting the aforementioned conformal and\ncalibration procedures whenever some unlabeled data from the target\ndistribution is available. We examine these techniques theoretically in a\ndistribution-free framework and demonstrate their excellent practical\nperformance.",
          "link": "http://arxiv.org/abs/2103.03323",
          "publishedOn": "2021-06-15T01:45:17.605Z",
          "wordCount": 607,
          "title": "Distribution-free uncertainty quantification for classification under label shift. (arXiv:2103.03323v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06921",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1\">Sixing Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_P/0/1/0/all/0/1\">Phuong Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anwar_A/0/1/0/all/0/1\">Ali Anwar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jannesari_A/0/1/0/all/0/1\">Ali Jannesari</a>",
          "description": "Federated Learning~(FL) has emerged as a new paradigm of training machine\nlearning models without sacrificing data security and privacy. Learning models\nat edge devices such as cell phones is one of the most common use case of FL.\nHowever, the limited computing power and energy constraints of edge devices\nhinder the adoption of FL for both model training and deployment, especially\nfor the resource-hungry Deep Neural Networks~(DNNs). To this end, many model\ncompression methods have been proposed and network pruning is among the most\nwell-known. However, a pruning policy for a given model is highly\ndataset-dependent, which is not suitable for non-Independent and Identically\nDistributed~(Non-IID) FL edge devices. In this paper, we present an adaptive\npruning scheme for edge devices in an FL system, which applies dataset-aware\ndynamic pruning for inference acceleration on Non-IID datasets. Our evaluation\nshows that the proposed method accelerates inference by $2\\times$~($50\\%$ FLOPs\nreduction) while maintaining the model's quality on edge devices.",
          "link": "http://arxiv.org/abs/2106.06921",
          "publishedOn": "2021-06-15T01:45:17.599Z",
          "wordCount": 585,
          "title": "Adaptive Dynamic Pruning for Non-IID Federated Learning. (arXiv:2106.06921v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06811",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pritom_M/0/1/0/all/0/1\">Mir Mehedi A. Pritom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_R/0/1/0/all/0/1\">Rosana Montanez Rodriguez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1\">Asad Ali Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nugroho_S/0/1/0/all/0/1\">Sebastian A. Nugroho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alrashydah_E/0/1/0/all/0/1\">Esra&#x27;a Alrashydah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruiz_B/0/1/0/all/0/1\">Beatrice N. Ruiz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rios_A/0/1/0/all/0/1\">Anthony Rios</a>",
          "description": "COVID-19 pandemic has generated what public health officials called an\ninfodemic of misinformation. As social distancing and stay-at-home orders came\ninto effect, many turned to social media for socializing. This increase in\nsocial media usage has made it a prime vehicle for the spreading of\nmisinformation. This paper presents a mechanism to detect COVID-19\nhealth-related misinformation in social media following an interdisciplinary\napproach. Leveraging social psychology as a foundation and existing\nmisinformation frameworks, we defined misinformation themes and associated\nkeywords incorporated into the misinformation detection mechanism using applied\nmachine learning techniques. Next, using the Twitter dataset, we explored the\nperformance of the proposed methodology using multiple state-of-the-art machine\nlearning classifiers. Our method shows promising results with at most 78%\naccuracy in classifying health-related misinformation versus true information\nusing uni-gram-based NLP feature generations from tweets and the Decision Tree\nclassifier. We also provide suggestions on alternatives for countering\nmisinformation and ethical consideration for the study.",
          "link": "http://arxiv.org/abs/2106.06811",
          "publishedOn": "2021-06-15T01:45:17.592Z",
          "wordCount": 656,
          "title": "Case Study on Detecting COVID-19 Health-Related Misinformation in Social Media. (arXiv:2106.06811v1 [cs.SI])"
        },
        {
          "id": "http://arxiv.org/abs/2006.05468",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kapoor_S/0/1/0/all/0/1\">Sanyam Kapoor</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Karaletsos_T/0/1/0/all/0/1\">Theofanis Karaletsos</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bui_T/0/1/0/all/0/1\">Thang D. Bui</a>",
          "description": "Through sequential construction of posteriors on observing data online,\nBayes' theorem provides a natural framework for continual learning. We develop\nVariational Auto-Regressive Gaussian Processes (VAR-GPs), a principled\nposterior updating mechanism to solve sequential tasks in continual learning.\nBy relying on sparse inducing point approximations for scalable posteriors, we\npropose a novel auto-regressive variational distribution which reveals two\nfruitful connections to existing results in Bayesian inference, expectation\npropagation and orthogonal inducing points. Mean predictive entropy estimates\nshow VAR-GPs prevent catastrophic forgetting, which is empirically supported by\nstrong performance on modern continual learning benchmarks against competitive\nbaselines. A thorough ablation study demonstrates the efficacy of our modeling\nchoices.",
          "link": "http://arxiv.org/abs/2006.05468",
          "publishedOn": "2021-06-15T01:45:17.576Z",
          "wordCount": 565,
          "title": "Variational Auto-Regressive Gaussian Processes for Continual Learning. (arXiv:2006.05468v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.01440",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhuzhel_V/0/1/0/all/0/1\">Vladislav Zhuzhel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rivera_Castro_R/0/1/0/all/0/1\">Rodrigo Rivera-Castro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaploukhaya_N/0/1/0/all/0/1\">Nina Kaploukhaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mironova_L/0/1/0/all/0/1\">Liliya Mironova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaytsev_A/0/1/0/all/0/1\">Alexey Zaytsev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burnaev_E/0/1/0/all/0/1\">Evgeny Burnaev</a>",
          "description": "Cohort analysis is a pervasive activity in web analytics. One divides users\ninto groups according to specific criteria and tracks their behavior over time.\nDespite its extensive use, academic circles do not discuss cohort analysis to\nevaluate user behavior online. This work introduces an unsupervised\nnon-parametric approach to group Internet users based on their activities. In\ncomparison, canonical methods in marketing and engineering-based techniques\nunderperform. COHORTNEY is the first machine learning-based cohort analysis\nalgorithm with a robust theoretical explanation.",
          "link": "http://arxiv.org/abs/2104.01440",
          "publishedOn": "2021-06-15T01:45:17.569Z",
          "wordCount": 539,
          "title": "COHORTNEY: Non-Parametric Clustering of Event Sequences. (arXiv:2104.01440v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.13052",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chu_Z/0/1/0/all/0/1\">Zhendong Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jing Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongning Wang</a>",
          "description": "Crowdsourcing provides a practical way to obtain large amounts of labeled\ndata at a low cost. However, the annotation quality of annotators varies\nconsiderably, which imposes new challenges in learning a high-quality model\nfrom the crowdsourced annotations. In this work, we provide a new perspective\nto decompose annotation noise into common noise and individual noise and\ndifferentiate the source of confusion based on instance difficulty and\nannotator expertise on a per-instance-annotator basis. We realize this new\ncrowdsourcing model by an end-to-end learning solution with two types of noise\nadaptation layers: one is shared across annotators to capture their commonly\nshared confusions, and the other one is pertaining to each annotator to realize\nindividual confusion. To recognize the source of noise in each annotation, we\nuse an auxiliary network to choose the two noise adaptation layers with respect\nto both instances and annotators. Extensive experiments on both synthesized and\nreal-world benchmarks demonstrate the effectiveness of our proposed common\nnoise adaptation solution.",
          "link": "http://arxiv.org/abs/2012.13052",
          "publishedOn": "2021-06-15T01:45:17.563Z",
          "wordCount": 624,
          "title": "Learning from Crowds by Modeling Common Confusions. (arXiv:2012.13052v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06685",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Picot_M/0/1/0/all/0/1\">Marine Picot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Messina_F/0/1/0/all/0/1\">Francisco Messina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boudiaf_M/0/1/0/all/0/1\">Malik Boudiaf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Labeau_F/0/1/0/all/0/1\">Fabrice Labeau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ayed_I/0/1/0/all/0/1\">Ismail Ben Ayed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piantanida_P/0/1/0/all/0/1\">Pablo Piantanida</a>",
          "description": "Adversarial robustness has become a topic of growing interest in machine\nlearning since it was observed that neural networks tend to be brittle. We\npropose an information-geometric formulation of adversarial defense and\nintroduce FIRE, a new Fisher-Rao regularization for the categorical\ncross-entropy loss, which is based on the geodesic distance between natural and\nperturbed input features. Based on the information-geometric properties of the\nclass of softmax distributions, we derive an explicit characterization of the\nFisher-Rao Distance (FRD) for the binary and multiclass cases, and draw some\ninteresting properties as well as connections with standard regularization\nmetrics. Furthermore, for a simple linear and Gaussian model, we show that all\nPareto-optimal points in the accuracy-robustness region can be reached by FIRE\nwhile other state-of-the-art methods fail. Empirically, we evaluate the\nperformance of various classifiers trained with the proposed loss on standard\ndatasets, showing up to 2\\% of improvements in terms of robustness while\nreducing the training time by 20\\% over the best-performing methods.",
          "link": "http://arxiv.org/abs/2106.06685",
          "publishedOn": "2021-06-15T01:45:17.555Z",
          "wordCount": 595,
          "title": "Adversarial Robustness via Fisher-Rao Regularization. (arXiv:2106.06685v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06579",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Venkatesha_Y/0/1/0/all/0/1\">Yeshwanth Venkatesha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Youngeun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tassiulas_L/0/1/0/all/0/1\">Leandros Tassiulas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panda_P/0/1/0/all/0/1\">Priyadarshini Panda</a>",
          "description": "As neural networks get widespread adoption in resource-constrained embedded\ndevices, there is a growing need for low-power neural systems. Spiking Neural\nNetworks (SNNs)are emerging to be an energy-efficient alternative to the\ntraditional Artificial Neural Networks (ANNs) which are known to be\ncomputationally intensive. From an application perspective, as federated\nlearning involves multiple energy-constrained devices, there is a huge scope to\nleverage energy efficiency provided by SNNs. Despite its importance, there has\nbeen little attention on training SNNs on a large-scale distributed system like\nfederated learning. In this paper, we bring SNNs to a more realistic federated\nlearning scenario. Specifically, we propose a federated learning framework for\ndecentralized and privacy-preserving training of SNNs. To validate the proposed\nfederated learning framework, we experimentally evaluate the advantages of SNNs\non various aspects of federated learning with CIFAR10 and CIFAR100 benchmarks.\nWe observe that SNNs outperform ANNs in terms of overall accuracy by over 15%\nwhen the data is distributed across a large number of clients in the federation\nwhile providing up to5.3x energy efficiency. In addition to efficiency, we also\nanalyze the sensitivity of the proposed federated SNN framework to data\ndistribution among the clients, stragglers, and gradient noise and perform a\ncomprehensive comparison with ANNs.",
          "link": "http://arxiv.org/abs/2106.06579",
          "publishedOn": "2021-06-15T01:45:17.549Z",
          "wordCount": 636,
          "title": "Federated Learning with Spiking Neural Networks. (arXiv:2106.06579v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2103.01638",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fumero_M/0/1/0/all/0/1\">Marco Fumero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cosmo_L/0/1/0/all/0/1\">Luca Cosmo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Melzi_S/0/1/0/all/0/1\">Simone Melzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodola_E/0/1/0/all/0/1\">Emanuele Rodol&#xe0;</a>",
          "description": "We propose a novel approach to disentangle the generative factors of\nvariation underlying a given set of observations. Our method builds upon the\nidea that the (unknown) low-dimensional manifold underlying the data space can\nbe explicitly modeled as a product of submanifolds. This definition of\ndisentanglement gives rise to a novel weakly-supervised algorithm for\nrecovering the unknown explanatory factors behind the data. At training time,\nour algorithm only requires pairs of non i.i.d. data samples whose elements\nshare at least one, possibly multidimensional, generative factor of variation.\nWe require no knowledge on the nature of these transformations, and do not make\nany limiting assumption on the properties of each subspace. Our approach is\neasy to implement, and can be successfully applied to different kinds of data\n(from images to 3D surfaces) undergoing arbitrary transformations. In addition\nto standard synthetic benchmarks, we showcase our method in challenging\nreal-world applications, where we compare favorably with the state of the art.",
          "link": "http://arxiv.org/abs/2103.01638",
          "publishedOn": "2021-06-15T01:45:17.528Z",
          "wordCount": 626,
          "title": "Learning disentangled representations via product manifold projection. (arXiv:2103.01638v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.03853",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Xin_R/0/1/0/all/0/1\">Ran Xin</a>, <a href=\"http://arxiv.org/find/math/1/au:+Khan_U/0/1/0/all/0/1\">Usman A. Khan</a>, <a href=\"http://arxiv.org/find/math/1/au:+Kar_S/0/1/0/all/0/1\">Soummya Kar</a>",
          "description": "We study decentralized non-convex finite-sum minimization problems described\nover a network of nodes, where each node possesses a local batch of data\nsamples. In this context, we analyze a single-timescale randomized incremental\ngradient method, called GT-SAGA. GT-SAGA is computationally efficient as it\nevaluates one component gradient per node per iteration and achieves provably\nfast and robust performance by leveraging node-level variance reduction and\nnetwork-level gradient tracking. For general smooth non-convex problems, we\nshow the almost sure and mean-squared convergence of GT-SAGA to a first-order\nstationary point and further describe regimes of practical significance where\nit outperforms the existing approaches and achieves a network\ntopology-independent iteration complexity respectively. When the global\nfunction satisfies the Polyak-Lojaciewisz condition, we show that GT-SAGA\nexhibits linear convergence to an optimal solution in expectation and describe\nregimes of practical interest where the performance is network\ntopology-independent and improves upon the existing methods. Numerical\nexperiments are included to highlight the main convergence aspects of GT-SAGA\nin non-convex settings.",
          "link": "http://arxiv.org/abs/2011.03853",
          "publishedOn": "2021-06-15T01:45:17.519Z",
          "wordCount": 633,
          "title": "A fast randomized incremental gradient method for decentralized non-convex optimization. (arXiv:2011.03853v2 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06804",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Barbiero_P/0/1/0/all/0/1\">Pietro Barbiero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ciravegna_G/0/1/0/all/0/1\">Gabriele Ciravegna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giannini_F/0/1/0/all/0/1\">Francesco Giannini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lio_P/0/1/0/all/0/1\">Pietro Li&#xf3;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gori_M/0/1/0/all/0/1\">Marco Gori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Melacci_S/0/1/0/all/0/1\">Stefano Melacci</a>",
          "description": "Explainable artificial intelligence has rapidly emerged since lawmakers have\nstarted requiring interpretable models for safety-critical domains.\nConcept-based neural networks have arisen as explainable-by-design methods as\nthey leverage human-understandable symbols (i.e. concepts) to predict class\nmemberships. However, most of these approaches focus on the identification of\nthe most relevant concepts but do not provide concise, formal explanations of\nhow such concepts are leveraged by the classifier to make predictions. In this\npaper, we propose a novel end-to-end differentiable approach enabling the\nextraction of logic explanations from neural networks using the formalism of\nFirst-Order Logic. The method relies on an entropy-based criterion which\nautomatically identifies the most relevant concepts. We consider four different\ncase studies to demonstrate that: (i) this entropy-based criterion enables the\ndistillation of concise logic explanations in safety-critical domains from\nclinical data to computer vision; (ii) the proposed approach outperforms\nstate-of-the-art white-box models in terms of classification accuracy.",
          "link": "http://arxiv.org/abs/2106.06804",
          "publishedOn": "2021-06-15T01:45:17.495Z",
          "wordCount": 591,
          "title": "Entropy-based Logic Explanations of Neural Networks. (arXiv:2106.06804v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06688",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pandey_P/0/1/0/all/0/1\">Pankaj Pandey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miyapuram_K/0/1/0/all/0/1\">Krishna Prasad Miyapuram</a>",
          "description": "Several Convolutional Deep Learning models have been proposed to classify the\ncognitive states utilizing several neuro-imaging domains. These models have\nachieved significant results, but they are heavily designed with millions of\nparameters, which increases train and test time, making the model complex and\nless suitable for real-time analysis. This paper proposes a simple, lightweight\nCNN model to classify cognitive states from Electroencephalograph (EEG)\nrecordings. We develop a novel pipeline to learn distinct cognitive\nrepresentation consisting of two stages. The first stage is to generate the 2D\nspectral images from neural time series signals in a particular frequency band.\nImages are generated to preserve the relationship between the neighboring\nelectrodes and the spectral property of the cognitive events. The second is to\ndevelop a time-efficient, computationally less loaded, and high-performing\nmodel. We design a network containing 4 blocks and major components include\nstandard and depth-wise convolution for increasing the performance and followed\nby separable convolution to decrease the number of parameters which maintains\nthe tradeoff between time and performance. We experiment on open access EEG\nmeditation dataset comprising expert, nonexpert meditative, and control states.\nWe compare performance with six commonly used machine learning classifiers and\nfour state of the art deep learning models. We attain comparable performance\nutilizing less than 4\\% of the parameters of other models. This model can be\nemployed in a real-time computation environment such as neurofeedback.",
          "link": "http://arxiv.org/abs/2106.06688",
          "publishedOn": "2021-06-15T01:45:17.475Z",
          "wordCount": 678,
          "title": "BRAIN2DEPTH: Lightweight CNN Model for Classification of Cognitive States from EEG Recordings. (arXiv:2106.06688v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06899",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Ankit Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dar_G/0/1/0/all/0/1\">Guy Dar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goodman_S/0/1/0/all/0/1\">Shaya Goodman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ciprut_D/0/1/0/all/0/1\">David Ciprut</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berant_J/0/1/0/all/0/1\">Jonathan Berant</a>",
          "description": "Following the success of dot-product attention in Transformers, numerous\napproximations have been recently proposed to address its quadratic complexity\nwith respect to the input length. While these variants are memory and compute\nefficient, it is not possible to directly use them with popular pre-trained\nlanguage models trained using vanilla attention, without an expensive\ncorrective pre-training stage. In this work, we propose a simple yet highly\naccurate approximation for vanilla attention. We process the queries in chunks,\nand for each query, compute the top-$k$ scores with respect to the keys. Our\napproach offers several advantages: (a) its memory usage is linear in the input\nsize, similar to linear attention variants, such as Performer and RFA (b) it is\na drop-in replacement for vanilla attention that does not require any\ncorrective pre-training, and (c) it can also lead to significant memory savings\nin the feed-forward layers after casting them into the familiar query-key-value\nframework. We evaluate the quality of top-$k$ approximation for multi-head\nattention layers on the Long Range Arena Benchmark, and for feed-forward layers\nof T5 and UnifiedQA on multiple QA datasets. We show our approach leads to\naccuracy that is nearly-identical to vanilla attention in multiple setups\nincluding training from scratch, fine-tuning, and zero-shot inference.",
          "link": "http://arxiv.org/abs/2106.06899",
          "publishedOn": "2021-06-15T01:45:17.458Z",
          "wordCount": 630,
          "title": "Memory-efficient Transformers via Top-$k$ Attention. (arXiv:2106.06899v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2104.05752",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cha_S/0/1/0/all/0/1\">Sujeong Cha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_W/0/1/0/all/0/1\">Wangrui Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_H/0/1/0/all/0/1\">Hyun Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Phung_M/0/1/0/all/0/1\">My Phung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Picheny_M/0/1/0/all/0/1\">Michael Picheny</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuo_H/0/1/0/all/0/1\">Hong-Kwang Kuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thomas_S/0/1/0/all/0/1\">Samuel Thomas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morais_E/0/1/0/all/0/1\">Edmilson Morais</a>",
          "description": "A major focus of recent research in spoken language understanding (SLU) has\nbeen on the end-to-end approach where a single model can predict intents\ndirectly from speech inputs without intermediate transcripts. However, this\napproach presents some challenges. First, since speech can be considered as\npersonally identifiable information, in some cases only automatic speech\nrecognition (ASR) transcripts are accessible. Second, intent-labeled speech\ndata is scarce. To address the first challenge, we propose a novel system that\ncan predict intents from flexible types of inputs: speech, ASR transcripts, or\nboth. We demonstrate strong performance for either modality separately, and\nwhen both speech and ASR transcripts are available, through system combination,\nwe achieve better results than using a single input modality. To address the\nsecond challenge, we leverage a semantically robust pre-trained BERT model and\nadopt a cross-modal system that co-trains text embeddings and acoustic\nembeddings in a shared latent space. We further enhance this system by\nutilizing an acoustic module pre-trained on LibriSpeech and domain-adapting the\ntext module on our target datasets. Our experiments show significant advantages\nfor these pre-training and fine-tuning strategies, resulting in a system that\nachieves competitive intent-classification performance on Snips SLU and Fluent\nSpeech Commands datasets.",
          "link": "http://arxiv.org/abs/2104.05752",
          "publishedOn": "2021-06-15T01:45:17.245Z",
          "wordCount": 689,
          "title": "Speak or Chat with Me: End-to-End Spoken Language Understanding System with Flexible Inputs. (arXiv:2104.05752v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09356",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rezaei_S/0/1/0/all/0/1\">Seyed Saeed Changiz Rezaei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_F/0/1/0/all/0/1\">Fred X. Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_D/0/1/0/all/0/1\">Di Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salameh_M/0/1/0/all/0/1\">Mohammad Salameh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mills_K/0/1/0/all/0/1\">Keith Mills</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lian_S/0/1/0/all/0/1\">Shuo Lian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1\">Wei Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jui_S/0/1/0/all/0/1\">Shangling Jui</a>",
          "description": "Despite the empirical success of neural architecture search (NAS) in deep\nlearning applications, the optimality, reproducibility and cost of NAS schemes\nremain hard to assess. In this paper, we propose Generative Adversarial NAS\n(GA-NAS) with theoretically provable convergence guarantees, promoting\nstability and reproducibility in neural architecture search. Inspired by\nimportance sampling, GA-NAS iteratively fits a generator to previously\ndiscovered top architectures, thus increasingly focusing on important parts of\na large search space. Furthermore, we propose an efficient adversarial learning\napproach, where the generator is trained by reinforcement learning based on\nrewards provided by a discriminator, thus being able to explore the search\nspace without evaluating a large number of architectures. Extensive experiments\nshow that GA-NAS beats the best published results under several cases on three\npublic NAS benchmarks. In the meantime, GA-NAS can handle ad-hoc search\nconstraints and search spaces. We show that GA-NAS can be used to improve\nalready optimized baselines found by other NAS methods, including EfficientNet\nand ProxylessNAS, in terms of ImageNet accuracy or the number of parameters, in\ntheir original search space.",
          "link": "http://arxiv.org/abs/2105.09356",
          "publishedOn": "2021-06-15T01:45:17.236Z",
          "wordCount": 655,
          "title": "Generative Adversarial Neural Architecture Search. (arXiv:2105.09356v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.05632",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1\">Renyi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_M/0/1/0/all/0/1\">Molei Tao</a>",
          "description": "We consider the learning and prediction of nonlinear time series generated by\na latent symplectic map. A special case is (not necessarily separable)\nHamiltonian systems, whose solution flows give such symplectic maps. For this\nspecial case, both generic approaches based on learning the vector field of the\nlatent ODE and specialized approaches based on learning the Hamiltonian that\ngenerates the vector field exist. Our method, however, is different as it does\nnot rely on the vector field nor assume its existence; instead, it directly\nlearns the symplectic evolution map in discrete time. Moreover, we do so by\nrepresenting the symplectic map via a generating function, which we approximate\nby a neural network (hence the name GFNN). This way, our approximation of the\nevolution map is always \\emph{exactly} symplectic. This additional geometric\nstructure allows the local prediction error at each step to accumulate in a\ncontrolled fashion, and we will prove, under reasonable assumptions, that the\nglobal prediction error grows at most \\emph{linearly} with long prediction\ntime, which significantly improves an otherwise exponential growth. In\naddition, as a map-based and thus purely data-driven method, GFNN avoids two\nadditional sources of inaccuracies common in vector-field based approaches,\nnamely the error in approximating the vector field by finite difference of the\ndata, and the error in numerical integration of the vector field for making\npredictions. Numerical experiments further demonstrate our claims.",
          "link": "http://arxiv.org/abs/2103.05632",
          "publishedOn": "2021-06-15T01:45:17.227Z",
          "wordCount": 700,
          "title": "Data-driven Prediction of General Hamiltonian Dynamics via Learning Exactly-Symplectic Maps. (arXiv:2103.05632v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.05077",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chrysos_G/0/1/0/all/0/1\">Grigorios G Chrysos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Georgopoulos_M/0/1/0/all/0/1\">Markos Georgopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panagakis_Y/0/1/0/all/0/1\">Yannis Panagakis</a>",
          "description": "Generative modeling has evolved to a notable field of machine learning. Deep\npolynomial neural networks (PNNs) have demonstrated impressive results in\nunsupervised image generation, where the task is to map an input vector (i.e.,\nnoise) to a synthesized image. However, the success of PNNs has not been\nreplicated in conditional generation tasks, such as super-resolution. Existing\nPNNs focus on single-variable polynomial expansions which do not fare well to\ntwo-variable inputs, i.e., the noise variable and the conditional variable. In\nthis work, we introduce a general framework, called CoPE, that enables a\npolynomial expansion of two input variables and captures their auto- and\ncross-correlations. We exhibit how CoPE can be trivially augmented to accept an\narbitrary number of input variables. CoPE is evaluated in five tasks\n(class-conditional generation, inverse problems, edges-to-image translation,\nimage-to-image translation, attribute-guided generation) involving eight\ndatasets. The thorough evaluation suggests that CoPE can be useful for tackling\ndiverse conditional generation tasks.",
          "link": "http://arxiv.org/abs/2104.05077",
          "publishedOn": "2021-06-15T01:45:17.218Z",
          "wordCount": 612,
          "title": "CoPE: Conditional image generation using Polynomial Expansions. (arXiv:2104.05077v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.12668",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tsukamoto_H/0/1/0/all/0/1\">Hiroyasu Tsukamoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chung_S/0/1/0/all/0/1\">Soon-Jo Chung</a>",
          "description": "This paper presents Learning-based Autonomous Guidance with RObustness and\nStability guarantees (LAG-ROS), which provides machine learning-based nonlinear\nmotion planners with formal robustness and stability guarantees, by designing a\ndifferential Lyapunov function using contraction theory. LAG-ROS utilizes a\nneural network to model a robust tracking controller independently of a target\ntrajectory, for which we show that the Euclidean distance between the target\nand controlled trajectories is exponentially bounded linearly in the learning\nerror, even under the existence of bounded external disturbances. We also\npresent a convex optimization approach that minimizes the steady-state bound of\nthe tracking error to construct the robust control law for neural network\ntraining. In numerical simulations, it is demonstrated that the proposed method\nindeed possesses superior properties of robustness and nonlinear stability\nresulting from contraction theory, whilst retaining the computational\nefficiency of existing learning-based motion planners.",
          "link": "http://arxiv.org/abs/2102.12668",
          "publishedOn": "2021-06-15T01:45:17.212Z",
          "wordCount": 623,
          "title": "Learning-based Robust Motion Planning with Guaranteed Stability: A Contraction Theory Approach. (arXiv:2102.12668v3 [cs.RO] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.01826",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Levanon_S/0/1/0/all/0/1\">Sagi Levanon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosenfeld_N/0/1/0/all/0/1\">Nir Rosenfeld</a>",
          "description": "Strategic classification regards the problem of learning in settings where\nusers can strategically modify their features to improve outcomes. This setting\napplies broadly and has received much recent attention. But despite its\npractical significance, work in this space has so far been predominantly\ntheoretical. In this paper we present a learning framework for strategic\nclassification that is practical. Our approach directly minimizes the\n\"strategic\" empirical risk, achieved by differentiating through the strategic\nresponse of users. This provides flexibility that allows us to extend beyond\nthe original problem formulation and towards more realistic learning scenarios.\nA series of experiments demonstrates the effectiveness of our approach on\nvarious learning settings.",
          "link": "http://arxiv.org/abs/2103.01826",
          "publishedOn": "2021-06-15T01:45:17.204Z",
          "wordCount": 552,
          "title": "Strategic Classification Made Practical. (arXiv:2103.01826v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02297",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Kim_J/0/1/0/all/0/1\">Ji-Hoon Kim</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_S/0/1/0/all/0/1\">Sang-Hoon Lee</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_J/0/1/0/all/0/1\">Ji-Hyun Lee</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_S/0/1/0/all/0/1\">Seong-Whan Lee</a>",
          "description": "Although recent works on neural vocoder have improved the quality of\nsynthesized audio, there still exists a gap between generated and ground-truth\naudio in frequency space. This difference leads to spectral artifacts such as\nhissing noise or reverberation, and thus degrades the sample quality. In this\npaper, we propose Fre-GAN which achieves frequency-consistent audio synthesis\nwith highly improved generation quality. Specifically, we first present\nresolution-connected generator and resolution-wise discriminators, which help\nlearn various scales of spectral distributions over multiple frequency bands.\nAdditionally, to reproduce high-frequency components accurately, we leverage\ndiscrete wavelet transform in the discriminators. From our experiments, Fre-GAN\nachieves high-fidelity waveform generation with a gap of only 0.03 MOS compared\nto ground-truth audio while outperforming standard models in quality.",
          "link": "http://arxiv.org/abs/2106.02297",
          "publishedOn": "2021-06-15T01:45:17.166Z",
          "wordCount": 573,
          "title": "Fre-GAN: Adversarial Frequency-consistent Audio Synthesis. (arXiv:2106.02297v2 [eess.AS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.10040",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Combettes_C/0/1/0/all/0/1\">Cyrille W. Combettes</a>, <a href=\"http://arxiv.org/find/math/1/au:+Pokutta_S/0/1/0/all/0/1\">Sebastian Pokutta</a>",
          "description": "The Frank-Wolfe algorithm is a method for constrained optimization that\nrelies on linear minimizations, as opposed to projections. Therefore, a\nmotivation put forward in a large body of work on the Frank-Wolfe algorithm is\nthe computational advantage of solving linear minimizations instead of\nprojections. However, the discussions supporting this advantage are often too\nsuccinct or incomplete. In this paper, we review the complexity bounds for both\ntasks on several sets commonly used in optimization. Projection methods onto\nthe $\\ell_p$-ball, $p\\in\\left]1,2\\right[\\cup\\left]2,+\\infty\\right[$, and the\nBirkhoff polytope are also proposed.",
          "link": "http://arxiv.org/abs/2101.10040",
          "publishedOn": "2021-06-15T01:45:17.151Z",
          "wordCount": 545,
          "title": "Complexity of Linear Minimization and Projection on Some Sets. (arXiv:2101.10040v2 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.07108",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yan_S/0/1/0/all/0/1\">Shen Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_K/0/1/0/all/0/1\">Kaiqiang Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mi Zhang</a>",
          "description": "Recent works (White et al., 2020a; Yan et al., 2020) demonstrate the\nimportance of architecture encodings in Neural Architecture Search (NAS). These\nencodings encode either structure or computation information of the neural\narchitectures. Compared to structure-aware encodings, computation-aware\nencodings map architectures with similar accuracies to the same region, which\nimproves the downstream architecture search performance (Zhang et al., 2019;\nWhite et al., 2020a). In this work, we introduce a Computation-Aware\nTransformer-based Encoding method called CATE. Different from existing\ncomputation-aware encodings based on fixed transformation (e.g. path encoding),\nCATE employs a pairwise pre-training scheme to learn computation-aware\nencodings using Transformers with cross-attention. Such learned encodings\ncontain dense and contextualized computation information of neural\narchitectures. We compare CATE with eleven encodings under three major\nencoding-dependent NAS subroutines in both small and large search spaces. Our\nexperiments show that CATE is beneficial to the downstream search, especially\nin the large search space. Moreover, the outside search space experiment\ndemonstrates its superior generalization ability beyond the search space on\nwhich it was trained. Our code is available at:\nhttps://github.com/MSU-MLSys-Lab/CATE.",
          "link": "http://arxiv.org/abs/2102.07108",
          "publishedOn": "2021-06-15T01:45:17.145Z",
          "wordCount": 635,
          "title": "CATE: Computation-aware Neural Architecture Encoding with Transformers. (arXiv:2102.07108v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.02414",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_Y/0/1/0/all/0/1\">Yivan Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Niu_G/0/1/0/all/0/1\">Gang Niu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masashi Sugiyama</a>",
          "description": "Many weakly supervised classification methods employ a noise transition\nmatrix to capture the class-conditional label corruption. To estimate the\ntransition matrix from noisy data, existing methods often need to estimate the\nnoisy class-posterior, which could be unreliable due to the overconfidence of\nneural networks. In this work, we propose a theoretically grounded method that\ncan estimate the noise transition matrix and learn a classifier simultaneously,\nwithout relying on the error-prone noisy class-posterior estimation.\nConcretely, inspired by the characteristics of the stochastic label corruption\nprocess, we propose total variation regularization, which encourages the\npredicted probabilities to be more distinguishable from each other. Under mild\nassumptions, the proposed method yields a consistent estimator of the\ntransition matrix. We show the effectiveness of the proposed method through\nexperiments on benchmark and real-world datasets.",
          "link": "http://arxiv.org/abs/2102.02414",
          "publishedOn": "2021-06-15T01:45:17.125Z",
          "wordCount": 586,
          "title": "Learning Noise Transition Matrix from Only Noisy Labels via Total Variation Regularization. (arXiv:2102.02414v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.07475",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Christianos_F/0/1/0/all/0/1\">Filippos Christianos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papoudakis_G/0/1/0/all/0/1\">Georgios Papoudakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahman_A/0/1/0/all/0/1\">Arrasy Rahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Albrecht_S/0/1/0/all/0/1\">Stefano V. Albrecht</a>",
          "description": "Sharing parameters in multi-agent deep reinforcement learning has played an\nessential role in allowing algorithms to scale to a large number of agents.\nParameter sharing between agents significantly decreases the number of\ntrainable parameters, shortening training times to tractable levels, and has\nbeen linked to more efficient learning. However, having all agents share the\nsame parameters can also have a detrimental effect on learning. We demonstrate\nthe impact of parameter sharing methods on training speed and converged\nreturns, establishing that when applied indiscriminately, their effectiveness\nis highly dependent on the environment. We propose a novel method to\nautomatically identify agents which may benefit from sharing parameters by\npartitioning them based on their abilities and goals. Our approach combines the\nincreased sample efficiency of parameter sharing with the representational\ncapacity of multiple independent networks to reduce training time and increase\nfinal returns.",
          "link": "http://arxiv.org/abs/2102.07475",
          "publishedOn": "2021-06-15T01:45:17.007Z",
          "wordCount": 616,
          "title": "Scaling Multi-Agent Reinforcement Learning with Selective Parameter Sharing. (arXiv:2102.07475v2 [cs.MA] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.00151",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Le_H/0/1/0/all/0/1\">Hung Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sankar_C/0/1/0/all/0/1\">Chinnadhurai Sankar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moon_S/0/1/0/all/0/1\">Seungwhan Moon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beirami_A/0/1/0/all/0/1\">Ahmad Beirami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geramifard_A/0/1/0/all/0/1\">Alborz Geramifard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kottur_S/0/1/0/all/0/1\">Satwik Kottur</a>",
          "description": "A video-grounded dialogue system is required to understand both dialogue,\nwhich contains semantic dependencies from turn to turn, and video, which\ncontains visual cues of spatial and temporal scene variations. Building such\ndialogue systems is a challenging problem, involving various reasoning types on\nboth visual and language inputs. Existing benchmarks do not have enough\nannotations to thoroughly analyze dialogue systems and understand their\ncapabilities and limitations in isolation. These benchmarks are also not\nexplicitly designed to minimise biases that models can exploit without actual\nreasoning. To address these limitations, in this paper, we present DVD, a\nDiagnostic Dataset for Video-grounded Dialogues. The dataset is designed to\ncontain minimal biases and has detailed annotations for the different types of\nreasoning over the spatio-temporal space of video. Dialogues are synthesized\nover multiple question turns, each of which is injected with a set of\ncross-turn semantic relationships. We use DVD to analyze existing approaches,\nproviding interesting insights into their abilities and limitations. In total,\nDVD is built from $11k$ CATER synthetic videos and contains $10$ instances of\n$10$-round dialogues for each video, resulting in more than $100k$ dialogues\nand $1M$ question-answer pairs. Our code and dataset are publicly available at\nhttps://github.com/facebookresearch/DVDialogues.",
          "link": "http://arxiv.org/abs/2101.00151",
          "publishedOn": "2021-06-15T01:45:16.958Z",
          "wordCount": 688,
          "title": "DVD: A Diagnostic Dataset for Multi-step Reasoning in Video Grounded Dialogue. (arXiv:2101.00151v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06615",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Noci_L/0/1/0/all/0/1\">Lorenzo Noci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bachmann_G/0/1/0/all/0/1\">Gregor Bachmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_K/0/1/0/all/0/1\">Kevin Roth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nowozin_S/0/1/0/all/0/1\">Sebastian Nowozin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hofmann_T/0/1/0/all/0/1\">Thomas Hofmann</a>",
          "description": "Recent works on Bayesian neural networks (BNNs) have highlighted the need to\nbetter understand the implications of using Gaussian priors in combination with\nthe compositional structure of the network architecture. Similar in spirit to\nthe kind of analysis that has been developed to devise better initialization\nschemes for neural networks (cf. He- or Xavier initialization), we derive a\nprecise characterization of the prior predictive distribution of finite-width\nReLU networks with Gaussian weights. While theoretical results have been\nobtained for their heavy-tailedness, the full characterization of the prior\npredictive distribution (i.e. its density, CDF and moments), remained unknown\nprior to this work. Our analysis, based on the Meijer-G function, allows us to\nquantify the influence of architectural choices such as the width or depth of\nthe network on the resulting shape of the prior predictive distribution. We\nalso formally connect our results to previous work in the infinite width\nsetting, demonstrating that the moments of the distribution converge to those\nof a normal log-normal mixture in the infinite depth limit. Finally, our\nresults provide valuable guidance on prior design: for instance, controlling\nthe predictive variance with depth- and width-informed priors on the weights of\nthe network.",
          "link": "http://arxiv.org/abs/2106.06615",
          "publishedOn": "2021-06-15T01:45:16.951Z",
          "wordCount": 627,
          "title": "Precise characterization of the prior predictive distribution of deep ReLU networks. (arXiv:2106.06615v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06616",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_W/0/1/0/all/0/1\">Wenshuo Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kandasamy_K/0/1/0/all/0/1\">Kirthevasan Kandasamy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1\">Joseph E Gonzalez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1\">Michael I. Jordan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stoica_I/0/1/0/all/0/1\">Ion Stoica</a>",
          "description": "The sharing of scarce resources among multiple rational agents is one of the\nclassical problems in economics. In exchange economies, which are used to model\nsuch situations, agents begin with an initial endowment of resources and\nexchange them in a way that is mutually beneficial until they reach a\ncompetitive equilibrium (CE). CE allocations are Pareto efficient and fair.\nConsequently, they are used widely in designing mechanisms for fair division.\nHowever, computing CEs requires the knowledge of agent preferences which are\nunknown in several applications of interest. In this work, we explore a new\nonline learning mechanism, which, on each round, allocates resources to the\nagents and collects stochastic feedback on their experience in using that\nallocation. Its goal is to learn the agent utilities via this feedback and\nimitate the allocations at a CE in the long run. We quantify CE behavior via\ntwo losses and propose a randomized algorithm which achieves\n$\\bigOtilde(\\sqrt{T})$ loss after $T$ rounds under both criteria. Empirically,\nwe demonstrate the effectiveness of this mechanism through numerical\nsimulations.",
          "link": "http://arxiv.org/abs/2106.06616",
          "publishedOn": "2021-06-15T01:45:16.926Z",
          "wordCount": 605,
          "title": "Online Learning of Competitive Equilibria in Exchange Economies. (arXiv:2106.06616v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06976",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moghadam_M/0/1/0/all/0/1\">Monireh Mohebbi Moghadam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boroumand_B/0/1/0/all/0/1\">Bahar Boroumand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jalali_M/0/1/0/all/0/1\">Mohammad Jalali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zareian_A/0/1/0/all/0/1\">Arman Zareian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Javad_A/0/1/0/all/0/1\">Alireza Daei Javad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manshaei_M/0/1/0/all/0/1\">Mohammad Hossein Manshaei</a>",
          "description": "Generative Adversarial Network, as a promising research direction in the AI\ncommunity, recently attracts considerable attention due to its ability to\ngenerating high-quality realistic data. GANs are a competing game between two\nneural networks trained in an adversarial manner to reach a Nash equilibrium.\nDespite the improvement accomplished in GANs in the last years, there remain\nseveral issues to solve. In this way, how to tackle these issues and make\nadvances leads to rising research interests. This paper reviews literature that\nleverages the game theory in GANs and addresses how game models can relieve\nspecific generative models' challenges and improve the GAN's performance. In\nparticular, we firstly review some preliminaries, including the basic GAN model\nand some game theory backgrounds. After that, we present our taxonomy to\nsummarize the state-of-the-art solutions into three significant categories:\nmodified game model, modified architecture, and modified learning method. The\nclassification is based on the modifications made in the basic model by the\nproposed approaches from the game-theoretic perspective. We further classify\neach category into several subcategories. Following the proposed taxonomy, we\nexplore the main objective of each class and review the recent work in each\ngroup. Finally, we discuss the remaining challenges in this field and present\nthe potential future research topics.",
          "link": "http://arxiv.org/abs/2106.06976",
          "publishedOn": "2021-06-15T01:45:16.912Z",
          "wordCount": 663,
          "title": "Game of GANs: Game Theoretical Models for Generative Adversarial Networks. (arXiv:2106.06976v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2010.14860",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lucke_J/0/1/0/all/0/1\">J&#xf6;rg L&#xfc;cke</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Forster_D/0/1/0/all/0/1\">Dennis Forster</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dai_Z/0/1/0/all/0/1\">Zhenwen Dai</a>",
          "description": "The central objective function of a variational autoencoder (VAE) is its\nvariational lower bound. Here we show that for standard VAEs the variational\nbound converges to a value given by the sum of three entropies: the (negative)\nentropy of the latent distribution, the expected (negative) entropy of the\nobservable distribution, and the average entropy of the variational\ndistributions. Our derived analytical results are exact and apply for small as\nwell as complex neural networks for decoder and encoder. Furthermore, they\napply for finitely and infinitely many data points and at any stationary point\n(including local and global maxima). As a consequence, we show that the\nvariance parameters of encoder and decoder play the key role in determining the\nvalues of variational bounds at stationary points. Furthermore, the obtained\nresults can allow for closed-form analytical expressions at points of\nconvergence, which may be unexpected as neither variational lower bounds of\nVAEs nor log-likelihoods of VAEs are closed-form during learning. As our main\ncontribution, we provide the proofs for convergence of standard VAEs to sums of\nentropies. Furthermore, we numerically verify our analytical results and\ndiscuss some potential applications. The obtained equality to entropy sums\nprovides novel information on those points in parameter space that variational\nlearning converges to. As such, we believe, they can contribute to our\nunderstanding of established as well as novel VAE approaches.",
          "link": "http://arxiv.org/abs/2010.14860",
          "publishedOn": "2021-06-15T01:45:16.905Z",
          "wordCount": 704,
          "title": "The Evidence Lower Bound of Variational Autoencoders Converges to a Sum of Three Entropies. (arXiv:2010.14860v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06920",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Katuwandeniya_K/0/1/0/all/0/1\">Kavindie Katuwandeniya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiss_S/0/1/0/all/0/1\">Stefan H. Kiss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_L/0/1/0/all/0/1\">Lei Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miro_J/0/1/0/all/0/1\">Jaime Valls Miro</a>",
          "description": "A multi-modal framework to generated user intention distributions when\noperating a mobile vehicle is proposed in this work. The model learns from past\nobserved trajectories and leverages traversability information derived from the\nvisual surroundings to produce a set of future trajectories, suitable to be\ndirectly embedded into a perception-action shared control strategy on a mobile\nagent, or as a safety layer to supervise the prudent operation of the vehicle.\nWe base our solution on a conditional Generative Adversarial Network with\nLong-Short Term Memory cells to capture trajectory distributions conditioned on\npast trajectories, further fused with traversability probabilities derived from\nvisual segmentation with a Convolutional Neural Network. The proposed\ndata-driven framework results in a significant reduction in error of the\npredicted trajectories (versus the ground truth) from comparable strategies in\nthe literature (e.g. Social-GAN) that fail to account for information other\nthan the agent's past history. Experiments were conducted on a dataset\ncollected with a custom wheelchair model built onto the open-source urban\ndriving simulator CARLA, proving also that the proposed framework can be used\nwith a small, un-annotated dataset.",
          "link": "http://arxiv.org/abs/2106.06920",
          "publishedOn": "2021-06-15T01:45:16.897Z",
          "wordCount": 610,
          "title": "Multi-modal Scene-compliant User Intention Estimation for Navigation. (arXiv:2106.06920v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06741",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Li_M/0/1/0/all/0/1\">Mengmeng Li</a>, <a href=\"http://arxiv.org/find/math/1/au:+Sutter_T/0/1/0/all/0/1\">Tobias Sutter</a>, <a href=\"http://arxiv.org/find/math/1/au:+Kuhn_D/0/1/0/all/0/1\">Daniel Kuhn</a>",
          "description": "We study a stochastic program where the probability distribution of the\nuncertain problem parameters is unknown and only indirectly observed via\nfinitely many correlated samples generated by an unknown Markov chain with $d$\nstates. We propose a data-driven distributionally robust optimization model to\nestimate the problem's objective function and optimal solution. By leveraging\nresults from large deviations theory, we derive statistical guarantees on the\nquality of these estimators. The underlying worst-case expectation problem is\nnonconvex and involves $\\mathcal O(d^2)$ decision variables. Thus, it cannot be\nsolved efficiently for large $d$. By exploiting the structure of this problem,\nwe devise a customized Frank-Wolfe algorithm with convex direction-finding\nsubproblems of size $\\mathcal O(d)$. We prove that this algorithm finds a\nstationary point efficiently under mild conditions. The efficiency of the\nmethod is predicated on a dimensionality reduction enabled by a dual\nreformulation. Numerical experiments indicate that our approach has better\ncomputational and statistical properties than the state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2106.06741",
          "publishedOn": "2021-06-15T01:45:16.884Z",
          "wordCount": 587,
          "title": "Distributionally Robust Optimization with Markovian Data. (arXiv:2106.06741v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06984",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuhang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Shikuang Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1\">Xin Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_R/0/1/0/all/0/1\">Ruihao Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_S/0/1/0/all/0/1\">Shi Gu</a>",
          "description": "Spiking Neural Network (SNN) has been recognized as one of the next\ngeneration of neural networks. Conventionally, SNN can be converted from a\npre-trained ANN by only replacing the ReLU activation to spike activation while\nkeeping the parameters intact. Perhaps surprisingly, in this work we show that\na proper way to calibrate the parameters during the conversion of ANN to SNN\ncan bring significant improvements. We introduce SNN Calibration, a cheap but\nextraordinarily effective method by leveraging the knowledge within a\npre-trained Artificial Neural Network (ANN). Starting by analyzing the\nconversion error and its propagation through layers theoretically, we propose\nthe calibration algorithm that can correct the error layer-by-layer. The\ncalibration only takes a handful number of training data and several minutes to\nfinish. Moreover, our calibration algorithm can produce SNN with\nstate-of-the-art architecture on the large-scale ImageNet dataset, including\nMobileNet and RegNet. Extensive experiments demonstrate the effectiveness and\nefficiency of our algorithm. For example, our advanced pipeline can increase up\nto 69% top-1 accuracy when converting MobileNet on ImageNet compared to\nbaselines. Codes are released at https://github.com/yhhhli/SNN_Calibration.",
          "link": "http://arxiv.org/abs/2106.06984",
          "publishedOn": "2021-06-15T01:45:16.794Z",
          "wordCount": 613,
          "title": "A Free Lunch From ANN: Towards Efficient, Accurate Spiking Neural Networks Calibration. (arXiv:2106.06984v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.04779",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1\">Yu Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiusheng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_W/0/1/0/all/0/1\">Weizhen Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhendawade_N/0/1/0/all/0/1\">Nikhil Bhendawade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1\">Yeyun Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1\">Nan Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ruofei Zhang</a>",
          "description": "Transformer model with multi-head attention requires caching intermediate\nresults for efficient inference in generation tasks. However, cache brings new\nmemory-related costs and prevents leveraging larger batch size for faster\nspeed. We propose memory-efficient lossless attention (called EL-attention) to\naddress this issue. It avoids heavy operations for building multi-head keys and\nvalues, cache for them is not needed. EL-attention constructs an ensemble of\nattention results by expanding query while keeping key and value shared. It\nproduces the same result as multi-head attention with less GPU memory and\nfaster inference speed. We conduct extensive experiments on Transformer, BART,\nand GPT-2 for summarization and question generation tasks. The results show\nEL-attention speeds up existing models by 1.6x to 5.3x without accuracy loss.",
          "link": "http://arxiv.org/abs/2105.04779",
          "publishedOn": "2021-06-15T01:45:16.717Z",
          "wordCount": 589,
          "title": "EL-Attention: Memory Efficient Lossless Attention for Generation. (arXiv:2105.04779v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06682",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Liang_S/0/1/0/all/0/1\">Senwei Liang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Jiang_S/0/1/0/all/0/1\">Shixiao W. Jiang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Harlim_J/0/1/0/all/0/1\">John Harlim</a>, <a href=\"http://arxiv.org/find/math/1/au:+Yang_H/0/1/0/all/0/1\">Haizhao Yang</a>",
          "description": "This paper proposes a mesh-free computational framework and machine learning\ntheory for solving elliptic PDEs on unknown manifolds, identified with point\nclouds, based on diffusion maps (DM) and deep learning. The PDE solver is\nformulated as a supervised learning task to solve a least-squares regression\nproblem that imposes an algebraic equation approximating a PDE (and boundary\nconditions if applicable). This algebraic equation involves a graph-Laplacian\ntype matrix obtained via DM asymptotic expansion, which is a consistent\nestimator of second-order elliptic differential operators. The resulting\nnumerical method is to solve a highly non-convex empirical risk minimization\nproblem subjected to a solution from a hypothesis space of neural-network type\nfunctions. In a well-posed elliptic PDE setting, when the hypothesis space\nconsists of feedforward neural networks with either infinite width or depth, we\nshow that the global minimizer of the empirical loss function is a consistent\nsolution in the limit of large training data. When the hypothesis space is a\ntwo-layer neural network, we show that for a sufficiently large width, the\ngradient descent method can identify a global minimizer of the empirical loss\nfunction. Supporting numerical examples demonstrate the convergence of the\nsolutions and the effectiveness of the proposed solver in avoiding numerical\nissues that hampers the traditional approach when a large data set becomes\navailable, e.g., large matrix inversion.",
          "link": "http://arxiv.org/abs/2106.06682",
          "publishedOn": "2021-06-15T01:45:16.711Z",
          "wordCount": 648,
          "title": "Solving PDEs on Unknown Manifolds with Machine Learning. (arXiv:2106.06682v1 [math.NA])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06796",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wadu_M/0/1/0/all/0/1\">Madhusanka Manimel Wadu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samarakoon_S/0/1/0/all/0/1\">Sumudu Samarakoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bennis_M/0/1/0/all/0/1\">Mehdi Bennis</a>",
          "description": "The performance of federated learning (FL) over wireless networks depend on\nthe reliability of the client-server connectivity and clients' local\ncomputation capabilities. In this article we investigate the problem of client\nscheduling and resource block (RB) allocation to enhance the performance of\nmodel training using FL, over a pre-defined training duration under imperfect\nchannel state information (CSI) and limited local computing resources. First,\nwe analytically derive the gap between the training losses of FL with clients\nscheduling and a centralized training method for a given training duration.\nThen, we formulate the gap of the training loss minimization over client\nscheduling and RB allocation as a stochastic optimization problem and solve it\nusing Lyapunov optimization. A Gaussian process regression-based channel\nprediction method is leveraged to learn and track the wireless channel, in\nwhich, the clients' CSI predictions and computing power are incorporated into\nthe scheduling decision. Using an extensive set of simulations, we validate the\nrobustness of the proposed method under both perfect and imperfect CSI over an\narray of diverse data distributions. Results show that the proposed method\nreduces the gap of the training accuracy loss by up to 40.7% compared to\nstate-of-theart client scheduling and RB allocation methods.",
          "link": "http://arxiv.org/abs/2106.06796",
          "publishedOn": "2021-06-15T01:45:16.689Z",
          "wordCount": 641,
          "title": "Joint Client Scheduling and Resource Allocation under Channel Uncertainty in Federated Learning. (arXiv:2106.06796v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2003.00330",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lamb_L/0/1/0/all/0/1\">Luis C. Lamb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garcez_A/0/1/0/all/0/1\">Artur Garcez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gori_M/0/1/0/all/0/1\">Marco Gori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prates_M/0/1/0/all/0/1\">Marcelo Prates</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Avelar_P/0/1/0/all/0/1\">Pedro Avelar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vardi_M/0/1/0/all/0/1\">Moshe Vardi</a>",
          "description": "Neural-symbolic computing has now become the subject of interest of both\nacademic and industry research laboratories. Graph Neural Networks (GNN) have\nbeen widely used in relational and symbolic domains, with widespread\napplication of GNNs in combinatorial optimization, constraint satisfaction,\nrelational reasoning and other scientific domains. The need for improved\nexplainability, interpretability and trust of AI systems in general demands\nprincipled methodologies, as suggested by neural-symbolic computing. In this\npaper, we review the state-of-the-art on the use of GNNs as a model of\nneural-symbolic computing. This includes the application of GNNs in several\ndomains as well as its relationship to current developments in neural-symbolic\ncomputing.",
          "link": "http://arxiv.org/abs/2003.00330",
          "publishedOn": "2021-06-15T01:45:16.653Z",
          "wordCount": 645,
          "title": "Graph Neural Networks Meet Neural-Symbolic Computing: A Survey and Perspective. (arXiv:2003.00330v7 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06784",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Khan_Z/0/1/0/all/0/1\">Zohaib Amjad Khan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Beghdadi_A/0/1/0/all/0/1\">Azeddine Beghdadi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kaaniche_M/0/1/0/all/0/1\">Mounir Kaaniche</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cheikh_F/0/1/0/all/0/1\">Faouzi Alaya Cheikh</a>",
          "description": "Laparoscopic images and videos are often affected by different types of\ndistortion like noise, smoke, blur and nonuniform illumination. Automatic\ndetection of these distortions, followed generally by application of\nappropriate image quality enhancement methods, is critical to avoid errors\nduring surgery. In this context, a crucial step involves an objective\nassessment of the image quality, which is a two-fold problem requiring both the\nclassification of the distortion type affecting the image and the estimation of\nthe severity level of that distortion. Unlike existing image quality measures\nwhich focus mainly on estimating a quality score, we propose in this paper to\nformulate the image quality assessment task as a multi-label classification\nproblem taking into account both the type as well as the severity level (or\nrank) of distortions. Here, this problem is then solved by resorting to a deep\nneural networks based approach. The obtained results on a laparoscopic image\ndataset show the efficiency of the proposed approach.",
          "link": "http://arxiv.org/abs/2106.06784",
          "publishedOn": "2021-06-15T01:45:16.640Z",
          "wordCount": 611,
          "title": "Residual Networks based Distortion Classification and Ranking for Laparoscopic Image Quality Assessment. (arXiv:2106.06784v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2102.03716",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_W/0/1/0/all/0/1\">Wuxinlin Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_C/0/1/0/all/0/1\">Chenhui Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1\">Zhiqiang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1\">Yaohui Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhiru Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1\">Zhuo Feng</a>",
          "description": "A black-box spectral method is introduced for evaluating the adversarial\nrobustness of a given machine learning (ML) model. Our approach, named SPADE,\nexploits bijective distance mapping between the input/output graphs constructed\nfor approximating the manifolds corresponding to the input/output data. By\nleveraging the generalized Courant-Fischer theorem, we propose a SPADE score\nfor evaluating the adversarial robustness of a given model, which is proved to\nbe an upper bound of the best Lipschitz constant under the manifold setting. To\nreveal the most non-robust data samples highly vulnerable to adversarial\nattacks, we develop a spectral graph embedding procedure leveraging dominant\ngeneralized eigenvectors. This embedding step allows assigning each data sample\na robustness score that can be further harnessed for more effective adversarial\ntraining. Our experiments show the proposed SPADE method leads to promising\nempirical results for neural network models that are adversarially trained with\nthe MNIST and CIFAR-10 data sets.",
          "link": "http://arxiv.org/abs/2102.03716",
          "publishedOn": "2021-06-15T01:45:16.631Z",
          "wordCount": 635,
          "title": "SPADE: A Spectral Method for Black-Box Adversarial Robustness Evaluation. (arXiv:2102.03716v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2002.03629",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yang Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_C/0/1/0/all/0/1\">Chenlin Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_R/0/1/0/all/0/1\">Renjie Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ermon_S/0/1/0/all/0/1\">Stefano Ermon</a>",
          "description": "Feedforward computation, such as evaluating a neural network or sampling from\nan autoregressive model, is ubiquitous in machine learning. The sequential\nnature of feedforward computation, however, requires a strict order of\nexecution and cannot be easily accelerated with parallel computing. To enable\nparallelization, we frame the task of feedforward computation as solving a\nsystem of nonlinear equations. We then propose to find the solution using a\nJacobi or Gauss-Seidel fixed-point iteration method, as well as hybrid methods\nof both. Crucially, Jacobi updates operate independently on each equation and\ncan be executed in parallel. Our method is guaranteed to give exactly the same\nvalues as the original feedforward computation with a reduced (or equal) number\nof parallelizable iterations, and hence reduced time given sufficient parallel\ncomputing power. Experimentally, we demonstrate the effectiveness of our\napproach in accelerating (i) backpropagation of RNNs, (ii) evaluation of\nDenseNets, and (iii) autoregressive sampling of MADE and PixelCNN++, with\nspeedup factors between 2.1 and 26 under various settings.",
          "link": "http://arxiv.org/abs/2002.03629",
          "publishedOn": "2021-06-15T01:45:16.611Z",
          "wordCount": 623,
          "title": "Accelerating Feedforward Computation via Parallel Nonlinear Equation Solving. (arXiv:2002.03629v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.06810",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yuandong Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xinlei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganguli_S/0/1/0/all/0/1\">Surya Ganguli</a>",
          "description": "While contrastive approaches of self-supervised learning (SSL) learn\nrepresentations by minimizing the distance between two augmented views of the\nsame data point (positive pairs) and maximizing views from different data\npoints (negative pairs), recent \\emph{non-contrastive} SSL (e.g., BYOL and\nSimSiam) show remarkable performance {\\it without} negative pairs, with an\nextra learnable predictor and a stop-gradient operation. A fundamental question\narises: why do these methods not collapse into trivial representations? We\nanswer this question via a simple theoretical study and propose a novel\napproach, DirectPred, that \\emph{directly} sets the linear predictor based on\nthe statistics of its inputs, without gradient training. On ImageNet, it\nperforms comparably with more complex two-layer non-linear predictors that\nemploy BatchNorm and outperforms a linear predictor by $2.5\\%$ in 300-epoch\ntraining (and $5\\%$ in 60-epoch). DirectPred is motivated by our theoretical\nstudy of the nonlinear learning dynamics of non-contrastive SSL in simple\nlinear networks. Our study yields conceptual insights into how non-contrastive\nSSL methods learn, how they avoid representational collapse, and how multiple\nfactors, like predictor networks, stop-gradients, exponential moving averages,\nand weight decay all come into play. Our simple theory recapitulates the\nresults of real-world ablation studies in both STL-10 and ImageNet. Code is\nreleased\\footnote{\\url{https://github.com/facebookresearch/luckmatters/tree/master/ssl}}.",
          "link": "http://arxiv.org/abs/2102.06810",
          "publishedOn": "2021-06-15T01:45:16.589Z",
          "wordCount": 664,
          "title": "Understanding self-supervised Learning Dynamics without Contrastive Pairs. (arXiv:2102.06810v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.13906",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Martin_J/0/1/0/all/0/1\">J&#xf6;rg Martin</a>",
          "description": "In cases where a Wasserstein GAN depends on a condition the latter is usually\nhandled via an expectation within the loss function. Depending on the way this\nis motivated, the discriminator is either required to be Lipschitz-1 in both or\nin only one of its arguments. For the weaker requirement to become usable one\nneeds to exchange a supremum and an expectation. This is a mathematically\nperilous operation, which is, so far, only partially justified in the\nliterature. This short mathematical note intends to fill this gap and provides\nthe mathematical rationale for discriminators that are only partially\nLipschitz-1 for cases where this approach is more appropriate or successful.",
          "link": "http://arxiv.org/abs/2103.13906",
          "publishedOn": "2021-06-15T01:45:16.578Z",
          "wordCount": 556,
          "title": "About exchanging expectation and supremum for conditional Wasserstein GANs. (arXiv:2103.13906v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.10630",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Killamsetty_K/0/1/0/all/0/1\">Krishnateja Killamsetty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sivasubramanian_D/0/1/0/all/0/1\">Durga Sivasubramanian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramakrishnan_G/0/1/0/all/0/1\">Ganesh Ramakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iyer_R/0/1/0/all/0/1\">Rishabh Iyer</a>",
          "description": "Large scale machine learning and deep models are extremely data-hungry.\nUnfortunately, obtaining large amounts of labeled data is expensive, and\ntraining state-of-the-art models (with hyperparameter tuning) requires\nsignificant computing resources and time. Secondly, real-world data is noisy\nand imbalanced. As a result, several recent papers try to make the training\nprocess more efficient and robust. However, most existing work either focuses\non robustness or efficiency, but not both. In this work, we introduce Glister,\na GeneraLIzation based data Subset selecTion for Efficient and Robust learning\nframework. We formulate Glister as a mixed discrete-continuous bi-level\noptimization problem to select a subset of the training data, which maximizes\nthe log-likelihood on a held-out validation set. Next, we propose an iterative\nonline algorithm Glister-Online, which performs data selection iteratively\nalong with the parameter updates and can be applied to any loss-based learning\nalgorithm. We then show that for a rich class of loss functions including\ncross-entropy, hinge-loss, squared-loss, and logistic-loss, the inner discrete\ndata selection is an instance of (weakly) submodular optimization, and we\nanalyze conditions for which Glister-Online reduces the validation loss and\nconverges. Finally, we propose Glister-Active, an extension to batch active\nlearning, and we empirically demonstrate the performance of Glister on a wide\nrange of tasks including, (a) data selection to reduce training time, (b)\nrobust learning under label noise and imbalance settings, and (c) batch-active\nlearning with several deep and shallow models. We show that our framework\nimproves upon state of the art both in efficiency and accuracy (in cases (a)\nand (c)) and is more efficient compared to other state-of-the-art robust\nlearning algorithms in case (b).",
          "link": "http://arxiv.org/abs/2012.10630",
          "publishedOn": "2021-06-15T01:45:16.546Z",
          "wordCount": 760,
          "title": "GLISTER: Generalization based Data Subset Selection for Efficient and Robust Learning. (arXiv:2012.10630v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03039",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ban_Y/0/1/0/all/0/1\">Yikun Ban</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jingrui He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cook_C/0/1/0/all/0/1\">Curtiss B. Cook</a>",
          "description": "Contextual multi-armed bandit has shown to be an effective tool in\nrecommender systems. In this paper, we study a novel problem of multi-facet\nbandits involving a group of bandits, each characterizing the users' needs from\none unique aspect. In each round, for the given user, we need to select one arm\nfrom each bandit, such that the combination of all arms maximizes the final\nreward. This problem can find immediate applications in E-commerce, healthcare,\netc. To address this problem, we propose a novel algorithm, named MuFasa, which\nutilizes an assembled neural network to jointly learn the underlying reward\nfunctions of multiple bandits. It estimates an Upper Confidence Bound (UCB)\nlinked with the expected reward to balance between exploitation and\nexploration. Under mild assumptions, we provide the regret analysis of MuFasa.\nIt can achieve the near-optimal $\\widetilde{ \\mathcal{O}}((K+1)\\sqrt{T})$\nregret bound where $K$ is the number of bandits and $T$ is the number of played\nrounds. Furthermore, we conduct extensive experiments to show that MuFasa\noutperforms strong baselines on real-world data sets.",
          "link": "http://arxiv.org/abs/2106.03039",
          "publishedOn": "2021-06-15T01:45:16.532Z",
          "wordCount": 611,
          "title": "Multi-facet Contextual Bandits: A Neural Network Perspective. (arXiv:2106.03039v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.03818",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiashuo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Zheyuan Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_P/0/1/0/all/0/1\">Peng Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1\">Zheyan Shen</a>",
          "description": "Machine learning algorithms with empirical risk minimization usually suffer\nfrom poor generalization performance due to the greedy exploitation of\ncorrelations among the training data, which are not stable under distributional\nshifts. Recently, some invariant learning methods for out-of-distribution (OOD)\ngeneralization have been proposed by leveraging multiple training environments\nto find invariant relationships. However, modern datasets are frequently\nassembled by merging data from multiple sources without explicit source labels.\nThe resultant unobserved heterogeneity renders many invariant learning methods\ninapplicable. In this paper, we propose Heterogeneous Risk Minimization (HRM)\nframework to achieve joint learning of latent heterogeneity among the data and\ninvariant relationship, which leads to stable prediction despite distributional\nshifts. We theoretically characterize the roles of the environment labels in\ninvariant learning and justify our newly proposed HRM framework. Extensive\nexperimental results validate the effectiveness of our HRM framework.",
          "link": "http://arxiv.org/abs/2105.03818",
          "publishedOn": "2021-06-15T01:45:16.505Z",
          "wordCount": 596,
          "title": "Heterogeneous Risk Minimization. (arXiv:2105.03818v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10682",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_H/0/1/0/all/0/1\">Haitong Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guan_Y/0/1/0/all/0/1\">Yang Guan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shegnbo Eben Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiangteng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1\">Sifa Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jianyu Chen</a>",
          "description": "The safety constraints commonly used by existing safe reinforcement learning\n(RL) methods are defined only on expectation of initial states, but allow each\ncertain state to be unsafe, which is unsatisfying for real-world\nsafety-critical tasks. In this paper, we introduce the feasible actor-critic\n(FAC) algorithm, which is the first model-free constrained RL method that\nconsiders statewise safety, e.g, safety for each initial state. We claim that\nsome states are inherently unsafe no matter what policy we choose, while for\nother states there exist policies ensuring safety, where we say such states and\npolicies are feasible. By constructing a statewise Lagrange function available\non RL sampling and adopting an additional neural network to approximate the\nstatewise Lagrange multiplier, we manage to obtain the optimal feasible policy\nwhich ensures safety for each feasible state and the safest possible policy for\ninfeasible states. Furthermore, the trained multiplier net can indicate whether\na given state is feasible or not through the statewise complementary slackness\ncondition. We provide theoretical guarantees that FAC outperforms previous\nexpectation-based constrained RL methods in terms of both constraint\nsatisfaction and reward optimization. Experimental results on both robot\nlocomotive tasks and safe exploration tasks verify the safety enhancement and\nfeasibility interpretation of the proposed method.",
          "link": "http://arxiv.org/abs/2105.10682",
          "publishedOn": "2021-06-15T01:45:16.498Z",
          "wordCount": 673,
          "title": "Feasible Actor-Critic: Constrained Reinforcement Learning for Ensuring Statewise Safety. (arXiv:2105.10682v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.10626",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sharma_Y/0/1/0/all/0/1\">Yash Sharma</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shrivastava_A/0/1/0/all/0/1\">Aman Shrivastava</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ehsan_L/0/1/0/all/0/1\">Lubaina Ehsan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Moskaluk_C/0/1/0/all/0/1\">Christopher A. Moskaluk</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Syed_S/0/1/0/all/0/1\">Sana Syed</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Brown_D/0/1/0/all/0/1\">Donald E. Brown</a>",
          "description": "In recent years, the availability of digitized Whole Slide Images (WSIs) has\nenabled the use of deep learning-based computer vision techniques for automated\ndisease diagnosis. However, WSIs present unique computational and algorithmic\nchallenges. WSIs are gigapixel-sized ($\\sim$100K pixels), making them\ninfeasible to be used directly for training deep neural networks. Also, often\nonly slide-level labels are available for training as detailed annotations are\ntedious and can be time-consuming for experts. Approaches using\nmultiple-instance learning (MIL) frameworks have been shown to overcome these\nchallenges. Current state-of-the-art approaches divide the learning framework\ninto two decoupled parts: a convolutional neural network (CNN) for encoding the\npatches followed by an independent aggregation approach for slide-level\nprediction. In this approach, the aggregation step has no bearing on the\nrepresentations learned by the CNN encoder. We have proposed an end-to-end\nframework that clusters the patches from a WSI into ${k}$-groups, samples\n${k}'$ patches from each group for training, and uses an adaptive attention\nmechanism for slide level prediction; Cluster-to-Conquer (C2C). We have\ndemonstrated that dividing a WSI into clusters can improve the model training\nby exposing it to diverse discriminative features extracted from the patches.\nWe regularized the clustering mechanism by introducing a KL-divergence loss\nbetween the attention weights of patches in a cluster and the uniform\ndistribution. The framework is optimized end-to-end on slide-level\ncross-entropy, patch-level cross-entropy, and KL-divergence loss\n(Implementation: https://github.com/YashSharma/C2C).",
          "link": "http://arxiv.org/abs/2103.10626",
          "publishedOn": "2021-06-15T01:45:16.492Z",
          "wordCount": 711,
          "title": "Cluster-to-Conquer: A Framework for End-to-End Multi-Instance Learning for Whole Slide Image Classification. (arXiv:2103.10626v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06639",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_J/0/1/0/all/0/1\">John Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malik_K/0/1/0/all/0/1\">Kshitiz Malik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_H/0/1/0/all/0/1\">Hongyuan Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yousefpour_A/0/1/0/all/0/1\">Ashkan Yousefpour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rabbat_M/0/1/0/all/0/1\">Michael Rabbat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Esmaeili_M/0/1/0/all/0/1\">Mani Malek Esmaeili</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huba_D/0/1/0/all/0/1\">Dzmitry Huba</a>",
          "description": "Federated Learning (FL) trains a shared model across distributed devices\nwhile keeping the training data on the devices. Most FL schemes are\nsynchronous: they perform a synchronized aggregation of model updates from\nindividual devices. Synchronous training can be slow because of late-arriving\ndevices (stragglers). On the other hand, completely asynchronous training makes\nFL less private because of incompatibility with secure aggregation. In this\nwork, we propose a model aggregation scheme, FedBuff, that combines the best\nproperties of synchronous and asynchronous FL. Similar to synchronous FL,\nFedBuff is compatible with secure aggregation. Similar to asynchronous FL,\nFedBuff is robust to stragglers. In FedBuff, clients trains asynchronously and\nsend updates to the server. The server aggregates client updates in a private\nbuffer until updates have been received, at which point a server model update\nis immediately performed. We provide theoretical convergence guarantees for\nFedBuff in a non-convex setting. Empirically, FedBuff converges up to 3.8x\nfaster than previous proposals for synchronous FL (e.g., FedAvgM), and up to\n2.5x faster than previous proposals for asynchronous FL (e.g., FedAsync). We\nshow that FedBuff is robust to different staleness distributions and is more\nscalable than synchronous FL techniques.",
          "link": "http://arxiv.org/abs/2106.06639",
          "publishedOn": "2021-06-15T01:45:16.485Z",
          "wordCount": 619,
          "title": "Federated Learning with Buffered Asynchronous Aggregation. (arXiv:2106.06639v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2103.13308",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Radovanovic_A/0/1/0/all/0/1\">Ana Radovanovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Bokan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Talukdar_S/0/1/0/all/0/1\">Saurav Talukdar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_B/0/1/0/all/0/1\">Binz Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duarte_A/0/1/0/all/0/1\">Alexandre Duarte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shahbazi_M/0/1/0/all/0/1\">Mahya Shahbazi</a>",
          "description": "Datacenter power demand has been continuously growing and is the key driver\nof its cost. An accurate mapping of compute resources (CPU, RAM, etc.) and\nhardware types (servers, accelerators, etc.) to power consumption has emerged\nas a critical requirement for major Web and cloud service providers. With the\nglobal growth in datacenter capacity and associated power consumption, such\nmodels are essential for important decisions around datacenter design and\noperation. In this paper, we discuss two classes of statistical power models\ndesigned and validated to be accurate, simple, interpretable and applicable to\nall hardware configurations and workloads across hyperscale datacenters of\nGoogle fleet. To the best of our knowledge, this is the largest scale power\nmodeling study of this kind, in both the scope of diverse datacenter planning\nand real-time management use cases, as well as the variety of hardware\nconfigurations and workload types used for modeling and validation. We\ndemonstrate that the proposed statistical modeling techniques, while simple and\nscalable, predict power with less than 5% Mean Absolute Percent Error (MAPE)\nfor more than 95% diverse Power Distribution Units (more than 2000) using only\n4 features. This performance matches the reported accuracy of the previous\nstarted-of-the-art methods, while using significantly less features and\ncovering a wider range of use cases.",
          "link": "http://arxiv.org/abs/2103.13308",
          "publishedOn": "2021-06-15T01:45:16.479Z",
          "wordCount": 679,
          "title": "Power Modeling for Effective Datacenter Planning and Compute Management. (arXiv:2103.13308v2 [cs.DC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.03198",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Murata_T/0/1/0/all/0/1\">Tomoya Murata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suzuki_T/0/1/0/all/0/1\">Taiji Suzuki</a>",
          "description": "Recently, local SGD has got much attention and been extensively studied in\nthe distributed learning community to overcome the communication bottleneck\nproblem. However, the superiority of local SGD to minibatch SGD only holds in\nquite limited situations. In this paper, we study a new local algorithm called\nBias-Variance Reduced Local SGD (BVR-L-SGD) for nonconvex distributed\noptimization. Algorithmically, our proposed bias and variance reduced local\ngradient estimator fully utilizes small second-order heterogeneity of local\nobjectives and suggests randomly picking up one of the local models instead of\ntaking the average of them when workers are synchronized. Theoretically, under\nsmall heterogeneity of local objectives, we show that BVR-L-SGD achieves better\ncommunication complexity than both the previous non-local and local methods\nunder mild conditions, and particularly BVR-L-SGD is the first method that\nbreaks the barrier of communication complexity $\\Theta(1/\\varepsilon)$ for\ngeneral nonconvex smooth objectives when the heterogeneity is small and the\nlocal computation budget is large. Numerical results are given to verify the\ntheoretical findings and give empirical evidence of the superiority of our\nmethod.",
          "link": "http://arxiv.org/abs/2102.03198",
          "publishedOn": "2021-06-15T01:45:16.455Z",
          "wordCount": 630,
          "title": "Bias-Variance Reduced Local SGD for Less Heterogeneous Federated Learning. (arXiv:2102.03198v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.05284",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Liyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1\">Haipeng Luo</a>",
          "description": "We make significant progress toward the stochastic shortest path problem with\nadversarial costs and unknown transition. Specifically, we develop algorithms\nthat achieve $\\widetilde{O}(\\sqrt{S^2ADT_\\star K})$ regret for the\nfull-information setting and $\\widetilde{O}(\\sqrt{S^3A^2DT_\\star K})$ regret\nfor the bandit feedback setting, where $D$ is the diameter, $T_\\star$ is the\nexpected hitting time of the optimal policy, $S$ is the number of states, $A$\nis the number of actions, and $K$ is the number of episodes. Our work strictly\nimproves (Rosenberg and Mansour, 2020) in the full information setting, extends\n(Chen et al., 2020) from known transition to unknown transition, and is also\nthe first to consider the most challenging combination: bandit feedback with\nadversarial costs and unknown transition. To remedy the gap between our upper\nbounds and the current best lower bounds constructed via a stochastically\noblivious adversary, we also propose algorithms with near-optimal regret for\nthis special case.",
          "link": "http://arxiv.org/abs/2102.05284",
          "publishedOn": "2021-06-15T01:45:16.442Z",
          "wordCount": 615,
          "title": "Finding the Stochastic Shortest Path with Low Regret: The Adversarial Cost and Unknown Transition Case. (arXiv:2102.05284v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.07060",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Deo_A/0/1/0/all/0/1\">Anand Deo</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Murthy_K/0/1/0/all/0/1\">Karthyek Murthy</a>",
          "description": "Motivated by the increasing adoption of models which facilitate greater\nautomation in risk management and decision-making, this paper presents a novel\nImportance Sampling (IS) scheme for measuring distribution tails of objectives\nmodelled with enabling tools such as feature-based decision rules, mixed\ninteger linear programs, deep neural networks, etc. Conventional efficient IS\napproaches suffer from feasibility and scalability concerns due to the need to\nintricately tailor the sampler to the underlying probability distribution and\nthe objective. This challenge is overcome in the proposed black-box scheme by\nautomating the selection of an effective IS distribution with a transformation\nthat implicitly learns and replicates the concentration properties observed in\nless rare samples. This novel approach is guided by a large deviations\nprinciple that brings out the phenomenon of self-similarity of optimal IS\ndistributions. The proposed sampler is the first to attain asymptotically\noptimal variance reduction across a spectrum of multivariate distributions\ndespite being oblivious to the underlying structure. The large deviations\nprinciple additionally results in new distribution tail asymptotics capable of\nyielding operational insights. The applicability is illustrated by considering\nproduct distribution networks and portfolio credit risk models informed by\nneural networks as examples.",
          "link": "http://arxiv.org/abs/2102.07060",
          "publishedOn": "2021-06-15T01:45:16.435Z",
          "wordCount": 651,
          "title": "Achieving Efficiency in Black Box Simulation of Distribution Tails with Self-structuring Importance Samplers. (arXiv:2102.07060v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.04627",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zantedeschi_V/0/1/0/all/0/1\">Valentina Zantedeschi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kusner_M/0/1/0/all/0/1\">Matt J. Kusner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niculae_V/0/1/0/all/0/1\">Vlad Niculae</a>",
          "description": "We address the problem of learning binary decision trees that partition data\nfor some downstream task. We propose to learn discrete parameters (i.e., for\ntree traversals and node pruning) and continuous parameters (i.e., for tree\nsplit functions and prediction functions) simultaneously using argmin\ndifferentiation. We do so by sparsely relaxing a mixed-integer program for the\ndiscrete parameters, to allow gradients to pass through the program to\ncontinuous parameters. We derive customized algorithms to efficiently compute\nthe forward and backward passes. This means that our tree learning procedure\ncan be used as an (implicit) layer in arbitrary deep networks, and can be\noptimized with arbitrary loss functions. We demonstrate that our approach\nproduces binary trees that are competitive with existing single tree and\nensemble approaches, in both supervised and unsupervised settings. Further,\napart from greedy approaches (which do not have competitive accuracies), our\nmethod is faster to train than all other tree-learning baselines we compare\nwith. The code for reproducing the results is available at\nhttps://github.com/vzantedeschi/LatentTrees.",
          "link": "http://arxiv.org/abs/2010.04627",
          "publishedOn": "2021-06-15T01:45:16.411Z",
          "wordCount": 626,
          "title": "Learning Binary Decision Trees by Argmin Differentiation. (arXiv:2010.04627v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.11387",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Boateng_G/0/1/0/all/0/1\">George Boateng</a>",
          "description": "Introductory hands-on courses such as our smartphone-based coding course,\nSuaCode require a lot of support for students to accomplish learning goals.\nOnline environments make it even more difficult to get assistance especially\nmore recently because of COVID-19. Given the multilingual context of SuaCode\nstudents - learners across 42 African countries that are mostly Anglophone or\nFrancophone - in this work, we developed a bilingual Artificial Intelligence\n(AI) Teaching Assistant (TA) - Kwame - that provides answers to students'\ncoding questions from SuaCode courses in English and French. Kwame is a\nSentence-BERT (SBERT)-based question-answering (QA) system that we trained and\nevaluated offline using question-answer pairs created from the course's\nquizzes, lesson notes and students' questions in past cohorts. Kwame finds the\nparagraph most semantically similar to the question via cosine similarity. We\ncompared the system with TF-IDF and Universal Sentence Encoder. Our results\nshowed that fine-tuning on the course data and returning the top 3 and 5\nanswers improved the accuracy results. Kwame will make it easy for students to\nget quick and accurate answers to questions in SuaCode courses.",
          "link": "http://arxiv.org/abs/2010.11387",
          "publishedOn": "2021-06-15T01:45:16.398Z",
          "wordCount": 701,
          "title": "Kwame: A Bilingual AI Teaching Assistant for Online SuaCode Courses. (arXiv:2010.11387v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.11256",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Long_Z/0/1/0/all/0/1\">Ziang Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_P/0/1/0/all/0/1\">Penghang Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xin_J/0/1/0/all/0/1\">Jack Xin</a>",
          "description": "Quantized or low-bit neural networks are attractive due to their inference\nefficiency. However, training deep neural networks with quantized activations\ninvolves minimizing a discontinuous and piecewise constant loss function. Such\na loss function has zero gradients almost everywhere (a.e.), which makes the\nconventional gradient-based algorithms inapplicable. To this end, we study a\nnovel class of \\emph{biased} first-order oracle, termed coarse gradient, for\novercoming the vanished gradient issue. A coarse gradient is generated by\nreplacing the a.e. zero derivatives of quantized (i.e., stair-case) ReLU\nactivation composited in the chain rule with some heuristic proxy derivative\ncalled straight-through estimator (STE). Although having been widely used in\ntraining quantized networks empirically, fundamental questions like when and\nwhy the ad-hoc STE trick works, still lacks theoretical understanding. In this\npaper, we propose a class of STEs with certain monotonicity, and consider their\napplications to the training of a two-linear-layer network with quantized\nactivation functions for non-linear multi-category classification. We establish\nperformance guarantees for the proposed STEs by showing that the corresponding\ncoarse gradient methods converge to the global minimum, which leads to a\nperfect classification. Lastly, we present experimental results on synthetic\ndata as well as MNIST dataset to verify our theoretical findings and\ndemonstrate the effectiveness of our proposed STEs.",
          "link": "http://arxiv.org/abs/2011.11256",
          "publishedOn": "2021-06-15T01:45:16.379Z",
          "wordCount": 662,
          "title": "Learning Quantized Neural Nets by Coarse Gradient Method for Non-linear Classification. (arXiv:2011.11256v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02096",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Yu_B/0/1/0/all/0/1\">Byeongsu Yu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+You_K/0/1/0/all/0/1\">Kisung You</a>",
          "description": "We introduce a linear dimensionality reduction technique preserving\ntopological features via persistent homology. The method is designed to find\nlinear projection $L$ which preserves the persistent diagram of a point cloud\n$\\mathbb{X}$ via simulated annealing. The projection $L$ induces a set of\ncanonical simplicial maps from the Rips (or \\v{C}ech) filtration of\n$\\mathbb{X}$ to that of $L\\mathbb{X}$. In addition to the distance between\npersistent diagrams, the projection induces a map between filtrations, called\nfiltration homomorphism. Using the filtration homomorphism, one can measure the\ndifference between shapes of two filtrations directly comparing simplicial\ncomplexes with respect to quasi-isomorphism $\\mu_{\\operatorname{quasi-iso}}$ or\nstrong homotopy equivalence $\\mu_{\\operatorname{equiv}}$. These\n$\\mu_{\\operatorname{quasi-iso}}$ and $\\mu_{\\operatorname{equiv}}$ measures how\nmuch portion of corresponding simplicial complexes is quasi-isomorphic or\nhomotopy equivalence respectively. We validate the effectiveness of our\nframework with simple examples.",
          "link": "http://arxiv.org/abs/2106.02096",
          "publishedOn": "2021-06-15T01:45:16.315Z",
          "wordCount": 592,
          "title": "Shape-Preserving Dimensionality Reduction : An Algorithm and Measures of Topological Equivalence. (arXiv:2106.02096v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06695",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kapoor_S/0/1/0/all/0/1\">Sanyam Kapoor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Finzi_M/0/1/0/all/0/1\">Marc Finzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Ke Alexander Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilson_A/0/1/0/all/0/1\">Andrew Gordon Wilson</a>",
          "description": "State-of-the-art methods for scalable Gaussian processes use iterative\nalgorithms, requiring fast matrix vector multiplies (MVMs) with the covariance\nkernel. The Structured Kernel Interpolation (SKI) framework accelerates these\nMVMs by performing efficient MVMs on a grid and interpolating back to the\noriginal space. In this work, we develop a connection between SKI and the\npermutohedral lattice used for high-dimensional fast bilateral filtering. Using\na sparse simplicial grid instead of a dense rectangular one, we can perform GP\ninference exponentially faster in the dimension than SKI. Our approach,\nSimplex-GP, enables scaling SKI to high dimensions, while maintaining strong\npredictive performance. We additionally provide a CUDA implementation of\nSimplex-GP, which enables significant GPU acceleration of MVM based inference.",
          "link": "http://arxiv.org/abs/2106.06695",
          "publishedOn": "2021-06-15T01:45:16.284Z",
          "wordCount": 564,
          "title": "SKIing on Simplices: Kernel Interpolation on the Permutohedral Lattice for Scalable Gaussian Processes. (arXiv:2106.06695v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2008.10898",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhize Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bao_H/0/1/0/all/0/1\">Hongyan Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiangliang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Richtarik_P/0/1/0/all/0/1\">Peter Richt&#xe1;rik</a>",
          "description": "In this paper, we propose a novel stochastic gradient estimator --\nProbAbilistic Gradient Estimator (PAGE) -- for nonconvex optimization. PAGE is\neasy to implement as it is designed via a small adjustment to vanilla SGD: in\neach iteration, PAGE uses the vanilla minibatch SGD update with probability\n$p_t$ or reuses the previous gradient with a small adjustment, at a much lower\ncomputational cost, with probability $1-p_t$. We give a simple formula for the\noptimal choice of $p_t$. Moreover, we prove the first tight lower bound\n$\\Omega(n+\\frac{\\sqrt{n}}{\\epsilon^2})$ for nonconvex finite-sum problems,\nwhich also leads to a tight lower bound $\\Omega(b+\\frac{\\sqrt{b}}{\\epsilon^2})$\nfor nonconvex online problems, where $b:= \\min\\{\\frac{\\sigma^2}{\\epsilon^2},\nn\\}$. Then, we show that PAGE obtains the optimal convergence results\n$O(n+\\frac{\\sqrt{n}}{\\epsilon^2})$ (finite-sum) and\n$O(b+\\frac{\\sqrt{b}}{\\epsilon^2})$ (online) matching our lower bounds for both\nnonconvex finite-sum and online problems. Besides, we also show that for\nnonconvex functions satisfying the Polyak-\\L{}ojasiewicz (PL) condition, PAGE\ncan automatically switch to a faster linear convergence rate $O(\\cdot\\log\n\\frac{1}{\\epsilon})$. Finally, we conduct several deep learning experiments\n(e.g., LeNet, VGG, ResNet) on real datasets in PyTorch showing that PAGE not\nonly converges much faster than SGD in training but also achieves the higher\ntest accuracy, validating the optimal theoretical results and confirming the\npractical superiority of PAGE.",
          "link": "http://arxiv.org/abs/2008.10898",
          "publishedOn": "2021-06-15T01:45:16.278Z",
          "wordCount": 702,
          "title": "PAGE: A Simple and Optimal Probabilistic Gradient Estimator for Nonconvex Optimization. (arXiv:2008.10898v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.03934",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1\">Minqi Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grefenstette_E/0/1/0/all/0/1\">Edward Grefenstette</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rocktaschel_T/0/1/0/all/0/1\">Tim Rockt&#xe4;schel</a>",
          "description": "Environments with procedurally generated content serve as important\nbenchmarks for testing systematic generalization in deep reinforcement\nlearning. In this setting, each level is an algorithmically created environment\ninstance with a unique configuration of its factors of variation. Training on a\nprespecified subset of levels allows for testing generalization to unseen\nlevels. What can be learned from a level depends on the current policy, yet\nprior work defaults to uniform sampling of training levels independently of the\npolicy. We introduce Prioritized Level Replay (PLR), a general framework for\nselectively sampling the next training level by prioritizing those with higher\nestimated learning potential when revisited in the future. We show TD-errors\neffectively estimate a level's future learning potential and, when used to\nguide the sampling procedure, induce an emergent curriculum of increasingly\ndifficult levels. By adapting the sampling of training levels, PLR\nsignificantly improves sample efficiency and generalization on Procgen\nBenchmark--matching the previous state-of-the-art in test return--and readily\ncombines with other methods. Combined with the previous leading method, PLR\nraises the state-of-the-art to over 76% improvement in test return relative to\nstandard RL baselines.",
          "link": "http://arxiv.org/abs/2010.03934",
          "publishedOn": "2021-06-15T01:45:16.272Z",
          "wordCount": 643,
          "title": "Prioritized Level Replay. (arXiv:2010.03934v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1912.07812",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1\">Guangyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Etemad_A/0/1/0/all/0/1\">Ali Etemad</a>",
          "description": "Driver vigilance estimation is an important task for transportation safety.\nWearable and portable brain-computer interface devices provide a powerful means\nfor real-time monitoring of the vigilance level of drivers to help with\navoiding distracted or impaired driving. In this paper, we propose a novel\nmultimodal architecture for in-vehicle vigilance estimation from\nElectroencephalogram and Electrooculogram. To enable the system to focus on the\nmost salient parts of the learned multimodal representations, we propose an\narchitecture composed of a capsule attention mechanism following a deep Long\nShort-Term Memory (LSTM) network. Our model learns hierarchical dependencies in\nthe data through the LSTM and capsule feature representation layers. To better\nexplore the discriminative ability of the learned representations, we study the\neffect of the proposed capsule attention mechanism including the number of\ndynamic routing iterations as well as other parameters. Experiments show the\nrobustness of our method by outperforming other solutions and baseline\ntechniques, setting a new state-of-the-art. We then provide an analysis on\ndifferent frequency bands and brain regions to evaluate their suitability for\ndriver vigilance estimation. Lastly, an analysis on the role of capsule\nattention, multimodality, and robustness to noise is performed, highlighting\nthe advantages of our approach.",
          "link": "http://arxiv.org/abs/1912.07812",
          "publishedOn": "2021-06-15T01:45:16.266Z",
          "wordCount": 700,
          "title": "Capsule Attention for Multimodal EEG-EOG Representation Learning with Application to Driver Vigilance Estimation. (arXiv:1912.07812v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06600",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yasunaga_M/0/1/0/all/0/1\">Michihiro Yasunaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1\">Percy Liang</a>",
          "description": "We consider repair tasks: given a critic (e.g., compiler) that assesses the\nquality of an input, the goal is to train a fixer that converts a bad example\n(e.g., code with syntax errors) into a good one (e.g., code with no errors).\nExisting works create training data consisting of (bad, good) pairs by\ncorrupting good examples using heuristics (e.g., dropping tokens). However,\nfixers trained on this synthetically-generated data do not extrapolate well to\nthe real distribution of bad inputs. To bridge this gap, we propose a new\ntraining approach, Break-It-Fix-It (BIFI), which has two key ideas: (i) we use\nthe critic to check a fixer's output on real bad inputs and add good (fixed)\noutputs to the training data, and (ii) we train a breaker to generate realistic\nbad code from good code. Based on these ideas, we iteratively update the\nbreaker and the fixer while using them in conjunction to generate more paired\ndata. We evaluate BIFI on two code repair datasets: GitHub-Python, a new\ndataset we introduce where the goal is to repair Python code with AST parse\nerrors; and DeepFix, where the goal is to repair C code with compiler errors.\nBIFI outperforms existing methods, obtaining 90.5% repair accuracy on\nGitHub-Python (+28.5%) and 71.7% on DeepFix (+5.6%). Notably, BIFI does not\nrequire any labeled data; we hope it will be a strong starting point for\nunsupervised learning of various repair tasks.",
          "link": "http://arxiv.org/abs/2106.06600",
          "publishedOn": "2021-06-15T01:45:16.232Z",
          "wordCount": 669,
          "title": "Break-It-Fix-It: Unsupervised Learning for Program Repair. (arXiv:2106.06600v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.09695",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ciolino_M/0/1/0/all/0/1\">Matthew Ciolino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalin_J/0/1/0/all/0/1\">Josh Kalin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noever_D/0/1/0/all/0/1\">David Noever</a>",
          "description": "Production machine learning systems are consistently under attack by\nadversarial actors. Various deep learning models must be capable of accurately\ndetecting fake or adversarial input while maintaining speed. In this work, we\npropose one piece of the production protection system: detecting an incoming\nadversarial attack and its characteristics. Detecting types of adversarial\nattacks has two primary effects: the underlying model can be trained in a\nstructured manner to be robust from those attacks and the attacks can be\npotentially filtered out in real-time before causing any downstream damage. The\nadversarial image classification space is explored for models commonly used in\ntransfer learning.",
          "link": "http://arxiv.org/abs/2102.09695",
          "publishedOn": "2021-06-15T01:45:16.173Z",
          "wordCount": 581,
          "title": "Fortify Machine Learning Production Systems: Detect and Classify Adversarial Attacks. (arXiv:2102.09695v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.10902",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Liu_G/0/1/0/all/0/1\">Ge Liu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Dimitrakakis_A/0/1/0/all/0/1\">Alexander Dimitrakakis</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Carter_B/0/1/0/all/0/1\">Brandon Carter</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Gifford_D/0/1/0/all/0/1\">David Gifford</a>",
          "description": "We introduce the maximum $n$-times coverage problem that selects $k$ overlays\nto maximize the summed coverage of weighted elements, where each element must\nbe covered at least $n$ times. We also define the min-cost $n$-times coverage\nproblem where the objective is to select the minimum set of overlays such that\nthe sum of the weights of elements that are covered at least $n$ times is at\nleast $\\tau$. Maximum $n$-times coverage is a generalization of the multi-set\nmulti-cover problem, is NP-complete, and is not submodular. We introduce two\nnew practical solutions for $n$-times coverage based on integer linear\nprogramming and sequential greedy optimization. We show that maximum $n$-times\ncoverage is a natural way to frame peptide vaccine design, and find that it\nproduces a pan-strain COVID-19 vaccine design that is superior to 29 other\npublished designs in predicted population coverage and the expected number of\npeptides displayed by each individual's HLA molecules.",
          "link": "http://arxiv.org/abs/2101.10902",
          "publishedOn": "2021-06-15T01:45:16.147Z",
          "wordCount": 644,
          "title": "Maximum n-times Coverage for Vaccine Design. (arXiv:2101.10902v2 [q-bio.QM] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.08477",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nanayakkara_T/0/1/0/all/0/1\">Thesath Nanayakkara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clermont_G/0/1/0/all/0/1\">Gilles Clermont</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Langmead_C/0/1/0/all/0/1\">Christopher James Langmead</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swigon_D/0/1/0/all/0/1\">David Swigon</a>",
          "description": "Sepsis is a potentially life threatening inflammatory response to infection\nor severe tissue damage. It has a highly variable clinical course, requiring\nconstant monitoring of the patient's state to guide the management of\nintravenous fluids and vasopressors, among other interventions. Despite decades\nof research, there's still debate among experts on optimal treatment. Here, we\ncombine for the first time, distributional deep reinforcement learning with\nmechanistic physiological models to find personalized sepsis treatment\nstrategies. Our method handles partial observability by leveraging known\ncardiovascular physiology, introducing a novel physiology-driven recurrent\nautoencoder, and quantifies the uncertainty of its own results. Moreover, we\nintroduce a framework for uncertainty aware decision support with humans in the\nloop. We show that our method learns physiologically explainable, robust\npolicies that are consistent with clinical knowledge. Further our method\nconsistently identifies high risk states that lead to death, which could\npotentially benefit from more frequent vasopressor administration, providing\nvaluable guidance for future research",
          "link": "http://arxiv.org/abs/2101.08477",
          "publishedOn": "2021-06-15T01:45:16.122Z",
          "wordCount": 634,
          "title": "Unifying Cardiovascular Modelling with Deep Reinforcement Learning for Uncertainty Aware Control of Sepsis Treatment. (arXiv:2101.08477v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06663",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zou_X/0/1/0/all/0/1\">Xu Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Q/0/1/0/all/0/1\">Qinkai Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1\">Yuxiao Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guan_X/0/1/0/all/0/1\">Xinyu Guan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kharlamov_E/0/1/0/all/0/1\">Evgeny Kharlamov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jialiang Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jie Tang</a>",
          "description": "Graph Neural Networks (GNNs) have achieved promising performance in various\nreal-world applications. However, recent studies have shown that GNNs are\nvulnerable to adversarial attacks. In this paper, we study a\nrecently-introduced realistic attack scenario on graphs -- graph injection\nattack (GIA). In the GIA scenario, the adversary is not able to modify the\nexisting link structure and node attributes of the input graph, instead the\nattack is performed by injecting adversarial nodes into it. We present an\nanalysis on the topological vulnerability of GNNs under GIA setting, based on\nwhich we propose the Topological Defective Graph Injection Attack (TDGIA) for\neffective injection attacks. TDGIA first introduces the topological defective\nedge selection strategy to choose the original nodes for connecting with the\ninjected ones. It then designs the smooth feature optimization objective to\ngenerate the features for the injected nodes. Extensive experiments on\nlarge-scale datasets show that TDGIA can consistently and significantly\noutperform various attack baselines in attacking dozens of defense GNN models.\nNotably, the performance drop on target GNNs resultant from TDGIA is more than\ndouble the damage brought by the best attack solution among hundreds of\nsubmissions on KDD-CUP 2020.",
          "link": "http://arxiv.org/abs/2106.06663",
          "publishedOn": "2021-06-15T01:45:16.046Z",
          "wordCount": 629,
          "title": "TDGIA:Effective Injection Attacks on Graph Neural Networks. (arXiv:2106.06663v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00273",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Haibin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Andy T. Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhiyong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_H/0/1/0/all/0/1\">Helen Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hung-yi Lee</a>",
          "description": "Previous works have shown that automatic speaker verification (ASV) is\nseriously vulnerable to malicious spoofing attacks, such as replay, synthetic\nspeech, and recently emerged adversarial attacks. Great efforts have been\ndedicated to defending ASV against replay and synthetic speech; however, only a\nfew approaches have been explored to deal with adversarial attacks. All the\nexisting approaches to tackle adversarial attacks for ASV require the knowledge\nfor adversarial samples generation, but it is impractical for defenders to know\nthe exact attack algorithms that are applied by the in-the-wild attackers. This\nwork is among the first to perform adversarial defense for ASV without knowing\nthe specific attack algorithms. Inspired by self-supervised learning models\n(SSLMs) that possess the merits of alleviating the superficial noise in the\ninputs and reconstructing clean samples from the interrupted ones, this work\nregards adversarial perturbations as one kind of noise and conducts adversarial\ndefense for ASV by SSLMs. Specifically, we propose to perform adversarial\ndefense from two perspectives: 1) adversarial perturbation purification and 2)\nadversarial perturbation detection. Experimental results show that our\ndetection module effectively shields the ASV by detecting adversarial samples\nwith an accuracy of around 80%. Moreover, since there is no common metric for\nevaluating the adversarial defense performance for ASV, this work also\nformalizes evaluation metrics for adversarial defense considering both\npurification and detection based approaches into account. We sincerely\nencourage future works to benchmark their approaches based on the proposed\nevaluation framework.",
          "link": "http://arxiv.org/abs/2106.00273",
          "publishedOn": "2021-06-15T01:45:16.036Z",
          "wordCount": 704,
          "title": "Improving the Adversarial Robustness for Speaker Verification by Self-Supervised Learning. (arXiv:2106.00273v2 [cs.SD] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.11592",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghalme_G/0/1/0/all/0/1\">Ganesh Ghalme</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nair_V/0/1/0/all/0/1\">Vineet Nair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eilat_I/0/1/0/all/0/1\">Itay Eilat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Talgam_Cohen_I/0/1/0/all/0/1\">Inbal Talgam-Cohen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosenfeld_N/0/1/0/all/0/1\">Nir Rosenfeld</a>",
          "description": "Strategic classification studies the interaction between a classification\nrule and the strategic agents it governs. Under the assumption that the\nclassifier is known, rational agents respond to it by manipulating their\nfeatures. However, in many real-life scenarios of high-stake classification\n(e.g., credit scoring), the classifier is not revealed to the agents, which\nleads agents to attempt to learn the classifier and game it too. In this paper\nwe generalize the strategic classification model to such scenarios. We define\nthe price of opacity as the difference in prediction error between opaque and\ntransparent strategy-robust classifiers, characterize it, and give a sufficient\ncondition for this price to be strictly positive, in which case transparency is\nthe recommended policy. Our experiments show how Hardt et al.'s robust\nclassifier is affected by keeping agents in the dark.",
          "link": "http://arxiv.org/abs/2102.11592",
          "publishedOn": "2021-06-15T01:45:16.000Z",
          "wordCount": 591,
          "title": "Strategic Classification in the Dark. (arXiv:2102.11592v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06573",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ge_R/0/1/0/all/0/1\">Rong Ge</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ren_Y/0/1/0/all/0/1\">Yunwei Ren</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_X/0/1/0/all/0/1\">Xiang Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhou_M/0/1/0/all/0/1\">Mo Zhou</a>",
          "description": "In this paper we study the training dynamics for gradient flow on\nover-parametrized tensor decomposition problems. Empirically, such training\nprocess often first fits larger components and then discovers smaller\ncomponents, which is similar to a tensor deflation process that is commonly\nused in tensor decomposition algorithms. We prove that for orthogonally\ndecomposable tensor, a slightly modified version of gradient flow would follow\na tensor deflation process and recover all the tensor components. Our proof\nsuggests that for orthogonal tensors, gradient flow dynamics works similarly as\ngreedy low-rank learning in the matrix setting, which is a first step towards\nunderstanding the implicit regularization effect of over-parametrized models\nfor low-rank tensors.",
          "link": "http://arxiv.org/abs/2106.06573",
          "publishedOn": "2021-06-15T01:45:15.988Z",
          "wordCount": 536,
          "title": "Understanding Deflation Process in Over-parametrized Tensor Decomposition. (arXiv:2106.06573v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2101.02523",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ochal_M/0/1/0/all/0/1\">Mateusz Ochal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patacchiola_M/0/1/0/all/0/1\">Massimiliano Patacchiola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Storkey_A/0/1/0/all/0/1\">Amos Storkey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vazquez_J/0/1/0/all/0/1\">Jose Vazquez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Sen Wang</a>",
          "description": "Few-Shot Learning (FSL) algorithms are commonly trained through Meta-Learning\n(ML), which exposes models to batches of tasks sampled from a meta-dataset to\nmimic tasks seen during evaluation. However, the standard training procedures\noverlook the real-world dynamics where classes commonly occur at different\nfrequencies. While it is generally understood that class imbalance harms the\nperformance of supervised methods, limited research examines the impact of\nimbalance on the FSL evaluation task. Our analysis compares 10 state-of-the-art\nmeta-learning and FSL methods on different imbalance distributions and\nrebalancing techniques. Our results reveal that 1) some FSL methods display a\nnatural disposition against imbalance while most other approaches produce a\nperformance drop by up to 17\\% compared to the balanced task without the\nappropriate mitigation; 2) contrary to popular belief, many meta-learning\nalgorithms will not automatically learn to balance from exposure to imbalanced\ntraining tasks; 3) classical rebalancing strategies, such as random\noversampling, can still be very effective, leading to state-of-the-art\nperformances and should not be overlooked; 4) FSL methods are more robust\nagainst meta-dataset imbalance than imbalance at the task-level with a similar\nimbalance ratio ($\\rho<20$), with the effect holding even in long-tail datasets\nunder a larger imbalance ($\\rho=65$).",
          "link": "http://arxiv.org/abs/2101.02523",
          "publishedOn": "2021-06-15T01:45:15.982Z",
          "wordCount": 677,
          "title": "Few-Shot Learning with Class Imbalance. (arXiv:2101.02523v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.02068",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1\">Bo Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghaddar_B/0/1/0/all/0/1\">Bissan Ghaddar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nathwani_J/0/1/0/all/0/1\">Jatin Nathwani</a>",
          "description": "The past decade has seen a rapid penetration of electric vehicles (EV) in the\nmarket, more and more logistics and transportation companies start to deploy\nEVs for service provision. In order to model the operations of a commercial EV\nfleet, we utilize the EV routing problem with time windows (EVRPTW). In this\nresearch, we propose an end-to-end deep reinforcement learning framework to\nsolve the EVRPTW. In particular, we develop an attention model incorporating\nthe pointer network and a graph embedding technique to parameterize a\nstochastic policy for solving the EVRPTW. The model is then trained using\npolicy gradient with rollout baseline. Our numerical studies show that the\nproposed model is able to efficiently solve EVRPTW instances of large sizes\nthat are not solvable with any existing approaches.",
          "link": "http://arxiv.org/abs/2010.02068",
          "publishedOn": "2021-06-15T01:45:15.966Z",
          "wordCount": 606,
          "title": "Deep Reinforcement Learning for Electric Vehicle Routing Problem with Time Windows. (arXiv:2010.02068v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.10333",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Karimireddy_S/0/1/0/all/0/1\">Sai Praneeth Karimireddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1\">Lie He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaggi_M/0/1/0/all/0/1\">Martin Jaggi</a>",
          "description": "Byzantine robustness has received significant attention recently given its\nimportance for distributed and federated learning. In spite of this, we\nidentify severe flaws in existing algorithms even when the data across the\nparticipants is identically distributed. First, we show realistic examples\nwhere current state of the art robust aggregation rules fail to converge even\nin the absence of any Byzantine attackers. Secondly, we prove that even if the\naggregation rules may succeed in limiting the influence of the attackers in a\nsingle round, the attackers can couple their attacks across time eventually\nleading to divergence. To address these issues, we present two surprisingly\nsimple strategies: a new robust iterative clipping procedure, and incorporating\nworker momentum to overcome time-coupled attacks. This is the first provably\nrobust method for the standard stochastic optimization setting. Our code is\nopen sourced at https://github.com/epfml/byzantine-robust-optimizer.",
          "link": "http://arxiv.org/abs/2012.10333",
          "publishedOn": "2021-06-15T01:45:15.959Z",
          "wordCount": 621,
          "title": "Learning from History for Byzantine Robust Optimization. (arXiv:2012.10333v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.07983",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kyrillidis_A/0/1/0/all/0/1\">Anastasios Kyrillidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vardi_M/0/1/0/all/0/1\">Moshe Y. Vardi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhiwei Zhang</a>",
          "description": "We explore the potential of continuous local search (CLS) in SAT solving by\nproposing a novel approach for finding a solution of a hybrid system of Boolean\nconstraints. The algorithm is based on CLS combined with belief propagation on\nbinary decision diagrams (BDDs). Our framework accepts all Boolean constraints\nthat admit compact BDDs, including symmetric Boolean constraints and\nsmall-coefficient pseudo-Boolean constraints as interesting families. We\npropose a novel algorithm for efficiently computing the gradient needed by CLS.\nWe study the capabilities and limitations of our versatile CLS solver, GradSAT,\nby applying it on many benchmark instances. The experimental results indicate\nthat GradSAT can be a useful addition to the portfolio of existing SAT and\nMaxSAT solvers for solving Boolean satisfiability and optimization problems.",
          "link": "http://arxiv.org/abs/2012.07983",
          "publishedOn": "2021-06-15T01:45:15.945Z",
          "wordCount": 601,
          "title": "On Continuous Local BDD-Based Search for Hybrid SAT Solving. (arXiv:2012.07983v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1905.10696",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ororbia_A/0/1/0/all/0/1\">Alexander Ororbia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mali_A/0/1/0/all/0/1\">Ankur Mali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kifer_D/0/1/0/all/0/1\">Daniel Kifer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giles_C/0/1/0/all/0/1\">C. Lee Giles</a>",
          "description": "In lifelong learning systems, especially those based on artificial neural\nnetworks, one of the biggest obstacles is the severe inability to retain old\nknowledge as new information is encountered. This phenomenon is known as\ncatastrophic forgetting. In this article, we propose a new kind of\nconnectionist architecture, the Sequential Neural Coding Network, that is\nrobust to forgetting when learning from streams of data points and, unlike\nnetworks of today, does not learn via the immensely popular back-propagation of\nerrors. Grounded in the neurocognitive theory of predictive processing, our\nmodel adapts its synapses in a biologically-plausible fashion, while another,\ncomplementary neural system rapidly learns to direct and control this\ncortex-like structure by mimicking the task-executive control functionality of\nthe basal ganglia. In our experiments, we demonstrate that our self-organizing\nsystem experiences significantly less forgetting as compared to standard neural\nmodels and outperforms a wide swath of previously proposed methods even though\nit is trained across task datasets in a stream-like fashion. The promising\nperformance of our complementary system on benchmarks, e.g., SplitMNIST, Split\nFashion MNIST, and Split NotMNIST, offers evidence that by incorporating\nmechanisms prominent in real neuronal systems, such as competition, sparse\nactivation patterns, and iterative input processing, a new possibility for\ntackling the grand challenge of lifelong machine learning opens up.",
          "link": "http://arxiv.org/abs/1905.10696",
          "publishedOn": "2021-06-15T01:45:15.922Z",
          "wordCount": 698,
          "title": "Lifelong Neural Predictive Coding: Learning Cumulatively Online without Forgetting. (arXiv:1905.10696v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.03194",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chen_X/0/1/0/all/0/1\">Xinyu Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1\">Yixian Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Saunier_N/0/1/0/all/0/1\">Nicolas Saunier</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sun_L/0/1/0/all/0/1\">Lijun Sun</a>",
          "description": "Missing value problem in spatiotemporal traffic data has long been a\nchallenging topic, in particular for large-scale and high-dimensional data with\ncomplex missing mechanisms and diverse degrees of missingness. Recent studies\nbased on tensor nuclear norm have demonstrated the superiority of tensor\nlearning in imputation tasks by effectively characterizing the complex\ncorrelations/dependencies in spatiotemporal data. However, despite the\npromising results, these approaches do not scale well to large data tensors. In\nthis paper, we focus on addressing the missing data imputation problem for\nlarge-scale spatiotemporal traffic data. To achieve both high accuracy and\nefficiency, we develop a scalable tensor learning model -- Low-Tubal-Rank\nSmoothing Tensor Completion (LSTC-Tubal) -- based on the existing framework of\nLow-Rank Tensor Completion, which is well-suited for spatiotemporal traffic\ndata that is characterized by multidimensional structure of location$\\times$\ntime of day $\\times$ day. In particular, the proposed LSTC-Tubal model involves\na scalable tensor nuclear norm minimization scheme by integrating linear\nunitary transformation. Therefore, tensor nuclear norm minimization can be\nsolved by singular value thresholding on the transformed matrix of each day\nwhile the day-to-day correlation can be effectively preserved by the unitary\ntransform matrix. We compare LSTC-Tubal with state-of-the-art baseline models,\nand find that LSTC-Tubal can achieve competitive accuracy with a significantly\nlower computational cost. In addition, the LSTC-Tubal will also benefit other\ntasks in modeling large-scale spatiotemporal traffic data, such as\nnetwork-level traffic forecasting.",
          "link": "http://arxiv.org/abs/2008.03194",
          "publishedOn": "2021-06-15T01:45:15.899Z",
          "wordCount": 698,
          "title": "Scalable Low-Rank Tensor Learning for Spatiotemporal Traffic Data Imputation. (arXiv:2008.03194v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06762",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Darvariu_V/0/1/0/all/0/1\">Victor-Alexandru Darvariu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hailes_S/0/1/0/all/0/1\">Stephen Hailes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Musolesi_M/0/1/0/all/0/1\">Mirco Musolesi</a>",
          "description": "Public goods games represent insightful settings for studying incentives for\nindividual agents to make contributions that, while costly for each of them,\nbenefit the wider society. In this work, we adopt the perspective of a central\nplanner with a global view of a network of self-interested agents and the goal\nof maximizing some desired property in the context of a best-shot public goods\ngame. Existing algorithms for this known NP-complete problem find solutions\nthat are sub-optimal and cannot optimize for criteria other than social\nwelfare.\n\nIn order to efficiently solve public goods games, our proposed method\ndirectly exploits the correspondence between equilibria and the Maximal\nIndependent Set (mIS) structural property of graphs. In particular, we define a\nMarkov Decision Process, which incrementally generates an mIS, and adopt a\nplanning method to search for equilibria, outperforming existing methods.\nFurthermore, we devise an imitation learning technique that uses demonstrations\nof the search to obtain a graph neural network parametrized policy which\nquickly generalizes to unseen game instances. Our evaluation results show that\nthis policy is able to reach 99.5% of the performance of the planning method\nwhile being approximately three orders of magnitude faster to evaluate on the\nlargest graphs tested. The methods presented in this work can be applied to a\nlarge class of public goods games of potentially high societal impact.",
          "link": "http://arxiv.org/abs/2106.06762",
          "publishedOn": "2021-06-15T01:45:15.893Z",
          "wordCount": 664,
          "title": "Solving Graph-based Public Good Games with Tree Search and Imitation Learning. (arXiv:2106.06762v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2009.13504",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liao_P/0/1/0/all/0/1\">Peiyuan Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Han Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1\">Keyulu Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaakkola_T/0/1/0/all/0/1\">Tommi Jaakkola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gordon_G/0/1/0/all/0/1\">Geoffrey Gordon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jegelka_S/0/1/0/all/0/1\">Stefanie Jegelka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1\">Ruslan Salakhutdinov</a>",
          "description": "While the advent of Graph Neural Networks (GNNs) has greatly improved node\nand graph representation learning in many applications, the neighborhood\naggregation scheme exposes additional vulnerabilities to adversaries seeking to\nextract node-level information about sensitive attributes. In this paper, we\nstudy the problem of protecting sensitive attributes by information obfuscation\nwhen learning with graph structured data. We propose a framework to locally\nfilter out pre-determined sensitive attributes via adversarial training with\nthe total variation and the Wasserstein distance. Our method creates a strong\ndefense against inference attacks, while only suffering small loss in task\nperformance. Theoretically, we analyze the effectiveness of our framework\nagainst a worst-case adversary, and characterize an inherent trade-off between\nmaximizing predictive accuracy and minimizing information leakage. Experiments\nacross multiple datasets from recommender systems, knowledge graphs and quantum\nchemistry demonstrate that the proposed approach provides a robust defense\nacross various graph structures and tasks, while producing competitive GNN\nencoders for downstream tasks.",
          "link": "http://arxiv.org/abs/2009.13504",
          "publishedOn": "2021-06-15T01:45:15.855Z",
          "wordCount": 667,
          "title": "Information Obfuscation of Graph Neural Networks. (arXiv:2009.13504v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06988",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhangy_W/0/1/0/all/0/1\">Weichuan Zhangy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liuy_X/0/1/0/all/0/1\">Xuefang Liuy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_Z/0/1/0/all/0/1\">Zhe Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yongsheng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1\">Changming Sun</a>",
          "description": "Metric-based few-shot fine-grained image classification (FSFGIC) aims to\nlearn a transferable feature embedding network by estimating the similarities\nbetween query images and support classes from very few examples. In this work,\nwe propose, for the first time, to introduce the non-linear data projection\nconcept into the design of FSFGIC architecture in order to address the limited\nsample problem in few-shot learning and at the same time to increase the\ndiscriminability of the model for fine-grained image classification.\nSpecifically, we first design a feature re-abstraction embedding network that\nhas the ability to not only obtain the required semantic features for effective\nmetric learning but also re-enhance such features with finer details from input\nimages. Then the descriptors of the query images and the support classes are\nprojected into different non-linear spaces in our proposed similarity metric\nlearning network to learn discriminative projection factors. This design can\neffectively operate in the challenging and restricted condition of a FSFGIC\ntask for making the distance between the samples within the same class smaller\nand the distance between samples from different classes larger and for reducing\nthe coupling relationship between samples from different categories.\nFurthermore, a novel similarity measure based on the proposed non-linear data\nproject is presented for evaluating the relationships of feature information\nbetween a query image and a support set. It is worth to note that our proposed\narchitecture can be easily embedded into any episodic training mechanisms for\nend-to-end training from scratch. Extensive experiments on FSFGIC tasks\ndemonstrate the superiority of the proposed methods over the state-of-the-art\nbenchmarks.",
          "link": "http://arxiv.org/abs/2106.06988",
          "publishedOn": "2021-06-15T01:45:15.826Z",
          "wordCount": 701,
          "title": "NDPNet: A novel non-linear data projection network for few-shot fine-gained image classification. (arXiv:2106.06988v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06755",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Goyal_D/0/1/0/all/0/1\">Dishant Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaiswal_R/0/1/0/all/0/1\">Ragesh Jaiswal</a>",
          "description": "In this work, we study the socially fair $k$-median/$k$-means problem. We are\ngiven a set of points $P$ in a metric space $\\mathcal{X}$ with a distance\nfunction $d(.,.)$. There are $\\ell$ groups: $P_1,\\dotsc,P_{\\ell} \\subseteq P$.\nWe are also given a set $F$ of feasible centers in $\\mathcal{X}$. The goal of\nthe socially fair $k$-median problem is to find a set $C \\subseteq F$ of $k$\ncenters that minimizes the maximum average cost over all the groups. That is,\nfind $C$ that minimizes the objective function $\\Phi(C,P) \\equiv \\max_{j}\n\\sum_{x \\in P_j} d(C,x)/|P_j|$, where $d(C,x)$ is the distance of $x$ to the\nclosest center in $C$. The socially fair $k$-means problem is defined similarly\nby using squared distances, i.e., $d^{2}(.,.)$ instead of $d(.,.)$. In this\nwork, we design $(5+\\varepsilon)$ and $(33 + \\varepsilon)$ approximation\nalgorithms for the socially fair $k$-median and $k$-means problems,\nrespectively. For the parameters: $k$ and $\\ell$, the algorithms have an FPT\n(fixed parameter tractable) running time of $f(k,\\ell,\\varepsilon) \\cdot n$ for\n$f(k,\\ell,\\varepsilon) = 2^{{O}(k \\, \\ell/\\varepsilon)}$ and $n = |P \\cup F|$.\nWe also study a special case of the problem where the centers are allowed to be\nchosen from the point set $P$, i.e., $P \\subseteq F$. For this special case,\nour algorithms give better approximation guarantees of $(4+\\varepsilon)$ and\n$(18+\\varepsilon)$ for the socially fair $k$-median and $k$-means problems,\nrespectively. Furthermore, we convert these algorithms to constant pass\nlog-space streaming algorithms. Lastly, we show FPT hardness of approximation\nresults for the problem with a small gap between our upper and lower bounds.",
          "link": "http://arxiv.org/abs/2106.06755",
          "publishedOn": "2021-06-15T01:45:15.819Z",
          "wordCount": 686,
          "title": "FPT Approximation for Socially Fair Clustering. (arXiv:2106.06755v1 [cs.DS])"
        },
        {
          "id": "http://arxiv.org/abs/2006.10529",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lakshminarayanan_C/0/1/0/all/0/1\">Chandrashekar Lakshminarayanan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1\">Amit Vikram Singh</a>",
          "description": "Rectified linear unit (ReLU) activations can also be thought of as 'gates',\nwhich, either pass or stop their pre-activation input when they are 'on' (when\nthe pre-activation input is positive) or 'off' (when the pre-activation input\nis negative) respectively. A deep neural network (DNN) with ReLU activations\nhas many gates, and the on/off status of each gate changes across input\nexamples as well as network weights. For a given input example, only a subset\nof gates are 'active', i.e., on, and the sub-network of weights connected to\nthese active gates is responsible for producing the output. At randomised\ninitialisation, the active sub-network corresponding to a given input example\nis random. During training, as the weights are learnt, the active sub-networks\nare also learnt, and potentially hold very valuable information. In this paper,\nwe analytically characterise the role of active sub-networks in deep learning.\nTo this end, we encode the on/off state of the gates of a given input in a\nnovel 'neural path feature' (NPF), and the weights of the DNN are encoded in a\nnovel 'neural path value' (NPV). Further, we show that the output of network is\nindeed the inner product of NPF and NPV. The main result of the paper shows\nthat the 'neural path kernel' associated with the NPF is a fundamental quantity\nthat characterises the information stored in the gates of a DNN. We show via\nexperiments (on MNIST and CIFAR-10) that in standard DNNs with ReLU activations\nNPFs are learnt during training and such learning is key for generalisation.\nFurthermore, NPFs and NPVs can be learnt in two separate networks and such\nlearning also generalises well in experiments.",
          "link": "http://arxiv.org/abs/2006.10529",
          "publishedOn": "2021-06-15T01:45:15.813Z",
          "wordCount": 749,
          "title": "Neural Path Features and Neural Path Kernel : Understanding the role of gates in deep learning. (arXiv:2006.10529v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.14512",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liang_K/0/1/0/all/0/1\">Kaizhao Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jacky Y. Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koyejo_O/0/1/0/all/0/1\">Oluwasanmi Koyejo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>",
          "description": "Knowledge transferability, or transfer learning, has been widely adopted to\nallow a pre-trained model in the source domain to be effectively adapted to\ndownstream tasks in the target domain. It is thus important to explore and\nunderstand the factors affecting knowledge transferability. In this paper, as\nthe first work, we analyze and demonstrate the connections between knowledge\ntransferability and another important phenomenon--adversarial transferability,\n\\emph{i.e.}, adversarial examples generated against one model can be\ntransferred to attack other models. Our theoretical studies show that\nadversarial transferability indicates knowledge transferability and vice versa.\nMoreover, based on the theoretical insights, we propose two practical\nadversarial transferability metrics to characterize this process, serving as\nbidirectional indicators between adversarial and knowledge transferability. We\nconduct extensive experiments for different scenarios on diverse datasets,\nshowing a positive correlation between adversarial transferability and\nknowledge transferability. Our findings will shed light on future research\nabout effective knowledge transfer learning and adversarial transferability\nanalyses.",
          "link": "http://arxiv.org/abs/2006.14512",
          "publishedOn": "2021-06-15T01:45:15.792Z",
          "wordCount": 628,
          "title": "Uncovering the Connections Between Adversarial Transferability and Knowledge Transferability. (arXiv:2006.14512v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1904.12171",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hou_B/0/1/0/all/0/1\">Bo-Jian Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lijun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zhi-Hua Zhou</a>",
          "description": "Learning with feature evolution studies the scenario where the features of\nthe data streams can evolve, i.e., old features vanish and new features emerge.\nIts goal is to keep the model always performing well even when the features\nhappen to evolve. To tackle this problem, canonical methods assume that the old\nfeatures will vanish simultaneously and the new features themselves will emerge\nsimultaneously as well. They also assume there is an overlapping period where\nold and new features both exist when the feature space starts to change.\nHowever, in reality, the feature evolution could be unpredictable, which means\nthe features can vanish or emerge arbitrarily, causing the overlapping period\nincomplete. In this paper, we propose a novel paradigm: Prediction with\nUnpredictable Feature Evolution (PUFE) where the feature evolution is\nunpredictable. To address this problem, we fill the incomplete overlapping\nperiod and formulate it as a new matrix completion problem. We give a\ntheoretical bound on the least number of observed entries to make the\noverlapping period intact. With this intact overlapping period, we leverage an\nensemble method to take the advantage of both the old and new feature spaces\nwithout manually deciding which base models should be incorporated. Theoretical\nand experimental results validate that our method can always follow the best\nbase models and thus realize the goal of learning with feature evolution.",
          "link": "http://arxiv.org/abs/1904.12171",
          "publishedOn": "2021-06-15T01:45:15.780Z",
          "wordCount": 672,
          "title": "Prediction with Unpredictable Feature Evolution. (arXiv:1904.12171v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1907.12972",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Levie_R/0/1/0/all/0/1\">Ron Levie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Wei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bucci_L/0/1/0/all/0/1\">Lorenzo Bucci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bronstein_M/0/1/0/all/0/1\">Michael M. Bronstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kutyniok_G/0/1/0/all/0/1\">Gitta Kutyniok</a>",
          "description": "This paper focuses on spectral graph convolutional neural networks\n(ConvNets), where filters are defined as elementwise multiplication in the\nfrequency domain of a graph. In machine learning settings where the dataset\nconsists of signals defined on many different graphs, the trained ConvNet\nshould generalize to signals on graphs unseen in the training set. It is thus\nimportant to transfer ConvNets between graphs. Transferability, which is a\ncertain type of generalization capability, can be loosely defined as follows:\nif two graphs describe the same phenomenon, then a single filter or ConvNet\nshould have similar repercussions on both graphs. This paper aims at debunking\nthe common misconception that spectral filters are not transferable. We show\nthat if two graphs discretize the same \"continuous\" space, then a spectral\nfilter or ConvNet has approximately the same repercussion on both graphs. Our\nanalysis is more permissive than the standard analysis. Transferability is\ntypically described as the robustness of the filter to small graph\nperturbations and re-indexing of the vertices. Our analysis accounts also for\nlarge graph perturbations. We prove transferability between graphs that can\nhave completely different dimensions and topologies, only requiring that both\ngraphs discretize the same underlying space in some generic sense.",
          "link": "http://arxiv.org/abs/1907.12972",
          "publishedOn": "2021-06-15T01:45:15.743Z",
          "wordCount": 667,
          "title": "Transferability of Spectral Graph Convolutional Neural Networks. (arXiv:1907.12972v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06654",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Evtimov_I/0/1/0/all/0/1\">Ivan Evtimov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Covert_I/0/1/0/all/0/1\">Ian Covert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kusupati_A/0/1/0/all/0/1\">Aditya Kusupati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kohno_T/0/1/0/all/0/1\">Tadayoshi Kohno</a>",
          "description": "When data is publicly released for human consumption, it is unclear how to\nprevent its unauthorized usage for machine learning purposes. Successful model\ntraining may be preventable with carefully designed dataset modifications, and\nwe present a proof-of-concept approach for the image classification setting. We\npropose methods based on the notion of adversarial shortcuts, which encourage\nmodels to rely on non-robust signals rather than semantic features, and our\nexperiments demonstrate that these measures successfully prevent deep learning\nmodels from achieving high accuracy on real, unmodified data examples.",
          "link": "http://arxiv.org/abs/2106.06654",
          "publishedOn": "2021-06-15T01:45:15.737Z",
          "wordCount": 521,
          "title": "Disrupting Model Training with Adversarial Shortcuts. (arXiv:2106.06654v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06603",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meehan_C/0/1/0/all/0/1\">Casey Meehan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chowdhury_A/0/1/0/all/0/1\">Amrita Roy Chowdhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhuri_K/0/1/0/all/0/1\">Kamalika Chaudhuri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jha_S/0/1/0/all/0/1\">Somesh Jha</a>",
          "description": "ldp deployments are vulnerable to inference attacks as an adversary can link\nthe noisy responses to their identity and subsequently, auxiliary information\nusing the order of the data. An alternative model, shuffle DP, prevents this by\nshuffling the noisy responses uniformly at random. However, this limits the\ndata learnability -- only symmetric functions (input order agnostic) can be\nlearned. In this paper, we strike a balance and propose a generalized shuffling\nframework that interpolates between the two deployment models. We show that\nsystematic shuffling of the noisy responses can thwart specific inference\nattacks while retaining some meaningful data learnability. To this end, we\npropose a novel privacy guarantee, d-sigma privacy, that captures the privacy\nof the order of a data sequence. d-sigma privacy allows tuning the granularity\nat which the ordinal information is maintained, which formalizes the degree the\nresistance to inference attacks trading it off with data learnability.\nAdditionally, we propose a novel shuffling mechanism that can achieve d-sigma\nprivacy and demonstrate the practicality of our mechanism via evaluation on\nreal-world datasets.",
          "link": "http://arxiv.org/abs/2106.06603",
          "publishedOn": "2021-06-15T01:45:15.722Z",
          "wordCount": 596,
          "title": "A Shuffling Framework for Local Differential Privacy. (arXiv:2106.06603v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/1906.00460",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Malyshkin_V/0/1/0/all/0/1\">Vladislav Gennadievich Malyshkin</a>",
          "description": "Problems of interpolation, classification, and clustering are considered. In\nthe tenets of Radon--Nikodym approach $\\langle f(\\mathbf{x})\\psi^2 \\rangle /\n\\langle\\psi^2\\rangle$, where the $\\psi(\\mathbf{x})$ is a linear function on\ninput attributes, all the answers are obtained from a generalized eigenproblem\n$|f|\\psi^{[i]}\\rangle = \\lambda^{[i]} |\\psi^{[i]}\\rangle$. The solution to the\ninterpolation problem is a regular Radon-Nikodym derivative. The solution to\nthe classification problem requires prior and posterior probabilities that are\nobtained using the Lebesgue quadrature[1] technique. Whereas in a Bayesian\napproach new observations change only outcome probabilities, in the\nRadon-Nikodym approach not only outcome probabilities but also the probability\nspace $|\\psi^{[i]}\\rangle$ change with new observations. This is a remarkable\nfeature of the approach: both the probabilities and the probability space are\nconstructed from the data. The Lebesgue quadrature technique can be also\napplied to the optimal clustering problem. The problem is solved by\nconstructing a Gaussian quadrature on the Lebesgue measure. A distinguishing\nfeature of the Radon-Nikodym approach is the knowledge of the invariant group:\nall the answers are invariant relatively any non-degenerated linear transform\nof input vector $\\mathbf{x}$ components. A software product implementing the\nalgorithms of interpolation, classification, and optimal clustering is\navailable from the authors.",
          "link": "http://arxiv.org/abs/1906.00460",
          "publishedOn": "2021-06-15T01:45:15.716Z",
          "wordCount": 840,
          "title": "On The Radon-Nikodym Spectral Approach With Optimal Clustering. (arXiv:1906.00460v16 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06778",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ye_L/0/1/0/all/0/1\">Longqing Ye</a>",
          "description": "Convolutional networks (ConvNets) have shown impressive capability to solve\nvarious vision tasks. Nevertheless, the trade-off between performance and\nefficiency is still a challenge for a feasible model deployment on\nresource-constrained platforms. In this paper, we introduce a novel concept\ntermed multi-path fully connected pattern (MPFC) to rethink the\ninterdependencies of topology pattern, accuracy and efficiency for ConvNets.\nInspired by MPFC, we further propose a dual-branch module named dynamic clone\ntransformer (DCT) where one branch generates multiple replicas from inputs and\nanother branch reforms those clones through a series of difference vectors\nconditional on inputs itself to produce more variants. This operation allows\nthe self-expansion of channel-wise information in a data-driven way with little\ncomputational cost while providing sufficient learning capacity, which is a\npotential unit to replace computationally expensive pointwise convolution as an\nexpansion layer in the bottleneck structure.",
          "link": "http://arxiv.org/abs/2106.06778",
          "publishedOn": "2021-06-15T01:45:15.703Z",
          "wordCount": 567,
          "title": "Dynamic Clone Transformer for Efficient Convolutional Neural Netwoks. (arXiv:2106.06778v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/1905.12418",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alsubaihi_S/0/1/0/all/0/1\">Salman Alsubaihi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bibi_A/0/1/0/all/0/1\">Adel Bibi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alfadly_M/0/1/0/all/0/1\">Modar Alfadly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamdi_A/0/1/0/all/0/1\">Abdullah Hamdi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghanem_B/0/1/0/all/0/1\">Bernard Ghanem</a>",
          "description": "Training Deep Neural Networks that are robust to norm bounded adversarial\nattacks remains an elusive problem. While exact and inexact verification-based\nmethods are generally too expensive to train large networks, it was\ndemonstrated that bounded input intervals can be inexpensively propagated from\na layer to another through deep networks. This interval bound propagation\napproach (IBP) not only has improved both robustness and certified accuracy but\nwas the first to be employed on large/deep networks. However, due to the very\nloose nature of the IBP bounds, the required training procedure is complex and\ninvolved. In this paper, we closely examine the bounds of a block of layers\ncomposed in the form of Affine-ReLU-Affine. To this end, we propose expected\ntight bounds (true bounds in expectation), referred to as ETB, which are\nprovably tighter than IBP bounds in expectation. We then extend this result to\ndeeper networks through blockwise propagation and show that we can achieve\norders of magnitudes tighter bounds compared to IBP. Furthermore, using a\nsimple standard training procedure, we can achieve impressive\nrobustness-accuracy trade-off on both MNIST and CIFAR10.",
          "link": "http://arxiv.org/abs/1905.12418",
          "publishedOn": "2021-06-15T01:45:15.697Z",
          "wordCount": 678,
          "title": "Expected Tight Bounds for Robust Training. (arXiv:1905.12418v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06873",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ding_K/0/1/0/all/0/1\">Kaize Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianling Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jundong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caverlee_J/0/1/0/all/0/1\">James Caverlee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Huan Liu</a>",
          "description": "Graphs are widely used to model the relational structure of data, and the\nresearch of graph machine learning (ML) has a wide spectrum of applications\nranging from drug design in molecular graphs to friendship recommendation in\nsocial networks. Prevailing approaches for graph ML typically require abundant\nlabeled instances in achieving satisfactory results, which is commonly\ninfeasible in real-world scenarios since labeled data for newly emerged\nconcepts (e.g., new categorizations of nodes) on graphs is limited. Though\nmeta-learning has been applied to different few-shot graph learning problems,\nmost existing efforts predominately assume that all the data from those seen\nclasses is gold-labeled, while those methods may lose their efficacy when the\nseen data is weakly-labeled with severe label noise. As such, we aim to\ninvestigate a novel problem of weakly-supervised graph meta-learning for\nimproving the model robustness in terms of knowledge transfer. To achieve this\ngoal, we propose a new graph meta-learning framework -- Graph Hallucination\nNetworks (Meta-GHN) in this paper. Based on a new robustness-enhanced episodic\ntraining, Meta-GHN is meta-learned to hallucinate clean node representations\nfrom weakly-labeled data and extracts highly transferable meta-knowledge, which\nenables the model to quickly adapt to unseen tasks with few labeled instances.\nExtensive experiments demonstrate the superiority of Meta-GHN over existing\ngraph meta-learning studies on the task of weakly-supervised few-shot node\nclassification.",
          "link": "http://arxiv.org/abs/2106.06873",
          "publishedOn": "2021-06-15T01:45:15.684Z",
          "wordCount": 640,
          "title": "Weakly-supervised Graph Meta-learning for Few-shot Node Classification. (arXiv:2106.06873v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06631",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Parmentier_A/0/1/0/all/0/1\">Axel Parmentier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vidal_T/0/1/0/all/0/1\">Thibaut Vidal</a>",
          "description": "Counterfactual explanations are usually generated through heuristics that are\nsensitive to the search's initial conditions. The absence of guarantees of\nperformance and robustness hinders trustworthiness. In this paper, we take a\ndisciplined approach towards counterfactual explanations for tree ensembles. We\nadvocate for a model-based search aiming at \"optimal\" explanations and propose\nefficient mixed-integer programming approaches. We show that isolation forests\ncan be modeled within our framework to focus the search on plausible\nexplanations with a low outlier score. We provide comprehensive coverage of\nadditional constraints that model important objectives, heterogeneous data\ntypes, structural constraints on the feature space, along with resource and\nactionability restrictions. Our experimental analyses demonstrate that the\nproposed search approach requires a computational effort that is orders of\nmagnitude smaller than previous mathematical programming algorithms. It scales\nup to large data sets and tree ensembles, where it provides, within seconds,\nsystematic explanations grounded on well-defined models solved to optimality.",
          "link": "http://arxiv.org/abs/2106.06631",
          "publishedOn": "2021-06-15T01:45:15.678Z",
          "wordCount": 600,
          "title": "Optimal Counterfactual Explanations in Tree Ensembles. (arXiv:2106.06631v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06610",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Villar_S/0/1/0/all/0/1\">Soledad Villar</a> (JHU), <a href=\"http://arxiv.org/find/cs/1/au:+Hogg_D/0/1/0/all/0/1\">David W.Hogg</a> (Flatiron, NYU), <a href=\"http://arxiv.org/find/cs/1/au:+Storey_Fisher_K/0/1/0/all/0/1\">Kate Storey-Fisher</a> (NYU), <a href=\"http://arxiv.org/find/cs/1/au:+Yao_W/0/1/0/all/0/1\">Weichi Yao</a> (NYU), <a href=\"http://arxiv.org/find/cs/1/au:+Blum_Smith_B/0/1/0/all/0/1\">Ben Blum-Smith</a> (NYU)",
          "description": "There has been enormous progress in the last few years in designing\nconceivable (though not always practical) neural networks that respect the\ngauge symmetries -- or coordinate freedom -- of physical law. Some of these\nframeworks make use of irreducible representations, some make use of higher\norder tensor objects, and some apply symmetry-enforcing constraints. Different\nphysical laws obey different combinations of fundamental symmetries, but a\nlarge fraction (possibly all) of classical physics is equivariant to\ntranslation, rotation, reflection (parity), boost (relativity), and\npermutations. Here we show that it is simple to parameterize universally\napproximating polynomial functions that are equivariant under these symmetries,\nor under the Euclidean, Lorentz, and Poincar\\'e groups, at any dimensionality\n$d$. The key observation is that nonlinear O($d$)-equivariant (and\nrelated-group-equivariant) functions can be expressed in terms of a lightweight\ncollection of scalars -- scalar products and scalar contractions of the scalar,\nvector, and tensor inputs. These results demonstrate theoretically that\ngauge-invariant deep learning models for classical physics with good scaling\nfor large problems are feasible right now.",
          "link": "http://arxiv.org/abs/2106.06610",
          "publishedOn": "2021-06-15T01:45:15.671Z",
          "wordCount": 618,
          "title": "Scalars are universal: Gauge-equivariant machine learning, structured like classical physics. (arXiv:2106.06610v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06917",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alparslan_Y/0/1/0/all/0/1\">Yigit Alparslan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_E/0/1/0/all/0/1\">Edward Kim</a>",
          "description": "In this paper, we explore the effect of architecture completeness on\nadversarial robustness. We train models with different architectures on\nCIFAR-10 and MNIST dataset. For each model, we vary different number of layers\nand different number of nodes in the layer. For every architecture candidate,\nwe use Fast Gradient Sign Method (FGSM) to generate untargeted adversarial\nattacks and use adversarial training to defend against those attacks. For each\narchitecture candidate, we report pre-attack, post-attack and post-defense\naccuracy for the model as well as the architecture parameters and the impact of\ncompleteness to the model accuracies.",
          "link": "http://arxiv.org/abs/2106.06917",
          "publishedOn": "2021-06-15T01:45:15.638Z",
          "wordCount": 517,
          "title": "ATRAS: Adversarially Trained Robust Architecture Search. (arXiv:2106.06917v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06691",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Schein_A/0/1/0/all/0/1\">Aaron Schein</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nagulpally_A/0/1/0/all/0/1\">Anjali Nagulpally</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wallach_H/0/1/0/all/0/1\">Hanna Wallach</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Flaherty_P/0/1/0/all/0/1\">Patrick Flaherty</a>",
          "description": "We present a new non-negative matrix factorization model for $(0,1)$\nbounded-support data based on the doubly non-central beta (DNCB) distribution,\na generalization of the beta distribution. The expressiveness of the DNCB\ndistribution is particularly useful for modeling DNA methylation datasets,\nwhich are typically highly dispersed and multi-modal; however, the model\nstructure is sufficiently general that it can be adapted to many other domains\nwhere latent representations of $(0,1)$ bounded-support data are of interest.\nAlthough the DNCB distribution lacks a closed-form conjugate prior, several\naugmentations let us derive an efficient posterior inference algorithm composed\nentirely of analytic updates. Our model improves out-of-sample predictive\nperformance on both real and synthetic DNA methylation datasets over\nstate-of-the-art methods in bioinformatics. In addition, our model yields\nmeaningful latent representations that accord with existing biological\nknowledge.",
          "link": "http://arxiv.org/abs/2106.06691",
          "publishedOn": "2021-06-15T01:45:15.626Z",
          "wordCount": 583,
          "title": "Doubly Non-Central Beta Matrix Factorization for DNA Methylation Data. (arXiv:2106.06691v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06880",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Safran_I/0/1/0/all/0/1\">Itay Safran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shamir_O/0/1/0/all/0/1\">Ohad Shamir</a>",
          "description": "Recently, there has been much interest in studying the convergence rates of\nwithout-replacement SGD, and proving that it is faster than with-replacement\nSGD in the worst case. However, these works ignore or do not provide tight\nbounds in terms of the problem's geometry, including its condition number.\nPerhaps surprisingly, we prove that when the condition number is taken into\naccount, without-replacement SGD \\emph{does not} significantly improve on\nwith-replacement SGD in terms of worst-case bounds, unless the number of epochs\n(passes over the data) is larger than the condition number. Since many problems\nin machine learning and other areas are both ill-conditioned and involve large\ndatasets, this indicates that without-replacement does not necessarily improve\nover with-replacement sampling for realistic iteration budgets. We show this by\nproviding new lower and upper bounds which are tight (up to log factors), for\nquadratic problems with commuting quadratic terms, precisely quantifying the\ndependence on the problem parameters.",
          "link": "http://arxiv.org/abs/2106.06880",
          "publishedOn": "2021-06-15T01:45:15.617Z",
          "wordCount": 578,
          "title": "Random Shuffling Beats SGD Only After Many Epochs on Ill-Conditioned Problems. (arXiv:2106.06880v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06819",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sinha_A/0/1/0/all/0/1\">Abhishek Sinha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1\">Jiaming Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_C/0/1/0/all/0/1\">Chenlin Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ermon_S/0/1/0/all/0/1\">Stefano Ermon</a>",
          "description": "Conditional generative models of high-dimensional images have many\napplications, but supervision signals from conditions to images can be\nexpensive to acquire. This paper describes Diffusion-Decoding models with\nContrastive representations (D2C), a paradigm for training unconditional\nvariational autoencoders (VAEs) for few-shot conditional image generation. D2C\nuses a learned diffusion-based prior over the latent representations to improve\ngeneration and contrastive self-supervised learning to improve representation\nquality. D2C can adapt to novel generation tasks conditioned on labels or\nmanipulation constraints, by learning from as few as 100 labeled examples. On\nconditional generation from new labels, D2C achieves superior performance over\nstate-of-the-art VAEs and diffusion models. On conditional image manipulation,\nD2C generations are two orders of magnitude faster to produce over StyleGAN2\nones and are preferred by 50% - 60% of the human evaluators in a double-blind\nstudy.",
          "link": "http://arxiv.org/abs/2106.06819",
          "publishedOn": "2021-06-15T01:45:15.596Z",
          "wordCount": 567,
          "title": "D2C: Diffusion-Denoising Models for Few-shot Conditional Generation. (arXiv:2106.06819v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/1907.08738",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lee_T/0/1/0/all/0/1\">Taehee Lee</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lisiecki_L/0/1/0/all/0/1\">Lorraine E. Lisiecki</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rand_D/0/1/0/all/0/1\">Devin Rand</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gebbie_G/0/1/0/all/0/1\">Geoffrey Gebbie</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lawrence_C/0/1/0/all/0/1\">Charles E. Lawrence</a>",
          "description": "We first introduce a novel profile-based alignment algorithm, the multiple\ncontinuous Signal Alignment algorithm with Gaussian Process Regression profiles\n(SA-GPR). SA-GPR addresses the limitations of currently available signal\nalignment methods by adopting a hybrid of the particle smoothing and\nMarkov-chain Monte Carlo (MCMC) algorithms to align signals, and by applying\nthe Gaussian process regression to construct profiles to be aligned\ncontinuously. SA-GPR shares all the strengths of the existing alignment\nalgorithms that depend on profiles but is more exact in the sense that profiles\ndo not need to be discretized as sequential bins. The uncertainty of\nperformance over the resolution of such bins is thereby eliminated. This\nmethodology produces alignments that are consistent, that regularize extreme\ncases, and that properly reflect the inherent uncertainty.\n\nThen we extend SA-GPR to a specific problem in the field of paleoceanography\nwith a method called Bayesian Inference Gaussian Process Multiproxy Alignment\nof Continuous Signals (BIGMACS). The goal of BIGMACS is to infer continuous\nages for ocean sediment cores using two classes of age proxies: proxies that\nexplicitly return calendar ages (e.g., radiocarbon) and those used to\nsynchronize ages in multiple marine records (e.g., an oxygen isotope based\nmarine proxy known as benthic ${\\delta}^{18}{\\rm O}$). BIGMACS integrates these\ntwo proxies by iteratively performing two steps: profile construction from\nbenthic ${\\delta}^{18}{\\rm O}$ age models and alignment of each core to the\nprofile also reflecting radiocarbon dates. We use BIGMACS to construct a new\nDeep Northeastern Atlantic stack (i.e., a profile from a particular benthic\n${\\delta}^{18}{\\rm O}$ records) of five ocean sediment cores. We conclude by\nconstructing multiproxy age models for two additional cores from the same\nregion by aligning them to the stack.",
          "link": "http://arxiv.org/abs/1907.08738",
          "publishedOn": "2021-06-15T01:45:15.577Z",
          "wordCount": 765,
          "title": "Bayesian Inference Gaussian Process Multiproxy Alignment of Continuous Signals (BIGMACS): Applications for Paleoceanography. (arXiv:1907.08738v4 [stat.AP] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06667",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Dian Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Hongxin Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qian Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yinli Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Cong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1\">Chao Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qi Li</a>",
          "description": "Transfer learning eases the burden of training a well-performed model from\nscratch, especially when training data is scarce and computation power is\nlimited. In deep learning, a typical strategy for transfer learning is to\nfreeze the early layers of a pre-trained model and fine-tune the rest of its\nlayers on the target domain. Previous work focuses on the accuracy of the\ntransferred model but neglects the transfer of adversarial robustness. In this\nwork, we first show that transfer learning improves the accuracy on the target\ndomain but degrades the inherited robustness of the target model. To address\nsuch a problem, we propose a novel cooperative adversarially-robust transfer\nlearning (CARTL) by pre-training the model via feature distance minimization\nand fine-tuning the pre-trained model with non-expansive fine-tuning for target\ndomain tasks. Empirical results show that CARTL improves the inherited\nrobustness by about 28% at most compared with the baseline with the same degree\nof accuracy. Furthermore, we study the relationship between the batch\nnormalization (BN) layers and the robustness in the context of transfer\nlearning, and we reveal that freezing BN layers can further boost the\nrobustness transfer.",
          "link": "http://arxiv.org/abs/2106.06667",
          "publishedOn": "2021-06-15T01:45:15.548Z",
          "wordCount": 618,
          "title": "CARTL: Cooperative Adversarially-Robust Transfer Learning. (arXiv:2106.06667v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06983",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Esmaeili_A/0/1/0/all/0/1\">Ashkan Esmaeili</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joneidi_M/0/1/0/all/0/1\">Mohsen Joneidi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salimitari_M/0/1/0/all/0/1\">Mehrdad Salimitari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khalid_U/0/1/0/all/0/1\">Umar Khalid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahnavard_N/0/1/0/all/0/1\">Nazanin Rahnavard</a>",
          "description": "The problem of simultaneous column and row subset selection is addressed in\nthis paper. The column space and row space of a matrix are spanned by its left\nand right singular vectors, respectively. However, the singular vectors are not\nwithin actual columns/rows of the matrix. In this paper, an iterative approach\nis proposed to capture the most structural information of columns/rows via\nselecting a subset of actual columns/rows. This algorithm is referred to as\ntwo-way spectrum pursuit (TWSP) which provides us with an accurate solution for\nthe CUR matrix decomposition. TWSP is applicable in a wide range of\napplications since it enjoys a linear complexity w.r.t. number of original\ncolumns/rows. We demonstrated the application of TWSP for joint channel and\nsensor selection in cognitive radio networks, informative users and contents\ndetection, and efficient supervised data reduction.",
          "link": "http://arxiv.org/abs/2106.06983",
          "publishedOn": "2021-06-15T01:45:15.525Z",
          "wordCount": 573,
          "title": "Two-way Spectrum Pursuit for CUR Decomposition and Its Application in Joint Column/Row Subset Selection. (arXiv:2106.06983v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06891",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Lin_F/0/1/0/all/0/1\">Feng Lin</a>, <a href=\"http://arxiv.org/find/math/1/au:+Li_W/0/1/0/all/0/1\">Weiyu Li</a>, <a href=\"http://arxiv.org/find/math/1/au:+Ling_Q/0/1/0/all/0/1\">Qing Ling</a>",
          "description": "This paper aims to solve a distributed learning problem under Byzantine\nattacks. In the underlying distributed system, a number of unknown but\nmalicious workers (termed as Byzantine workers) can send arbitrary messages to\nthe master and bias the learning process, due to data corruptions, computation\nerrors or malicious attacks. Prior work has considered a total variation (TV)\nnorm-penalized approximation formulation to handle the Byzantine attacks, where\nthe TV norm penalty forces the regular workers' local variables to be close,\nand meanwhile, tolerates the outliers sent by the Byzantine workers. To solve\nthe TV norm-penalized approximation formulation, we propose a Byzantine-robust\nstochastic alternating direction method of multipliers (ADMM) that fully\nutilizes the separable problem structure. Theoretically, we prove that the\nproposed method converges to a bounded neighborhood of the optimal solution at\na rate of O(1/k) under mild assumptions, where k is the number of iterations\nand the size of neighborhood is determined by the number of Byzantine workers.\nNumerical experiments on the MNIST and COVERTYPE datasets demonstrate the\neffectiveness of the proposed method to various Byzantine attacks.",
          "link": "http://arxiv.org/abs/2106.06891",
          "publishedOn": "2021-06-15T01:45:15.518Z",
          "wordCount": 615,
          "title": "Stochastic Alternating Direction Method of Multipliers for Byzantine-Robust Distributed Learning. (arXiv:2106.06891v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06795",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Karim_M/0/1/0/all/0/1\">Mohammed Asad Karim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verma_V/0/1/0/all/0/1\">Vinay Kumar Verma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_P/0/1/0/all/0/1\">Pravendra Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Namboodiri_V/0/1/0/all/0/1\">Vinay Namboodiri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rai_P/0/1/0/all/0/1\">Piyush Rai</a>",
          "description": "We propose a novel approach for class incremental online learning in a\nlimited data setting. This problem setting is challenging because of the\nfollowing constraints: (1) Classes are given incrementally, which necessitates\na class incremental learning approach; (2) Data for each class is given in an\nonline fashion, i.e., each training example is seen only once during training;\n(3) Each class has very few training examples; and (4) We do not use or assume\naccess to any replay/memory to store data from previous classes. Therefore, in\nthis setting, we have to handle twofold problems of catastrophic forgetting and\noverfitting. In our approach, we learn robust representations that are\ngeneralizable across tasks without suffering from the problems of catastrophic\nforgetting and overfitting to accommodate future classes with limited samples.\nOur proposed method leverages the meta-learning framework with knowledge\nconsolidation. The meta-learning framework helps the model for rapid learning\nwhen samples appear in an online fashion. Simultaneously, knowledge\nconsolidation helps to learn a robust representation against forgetting under\nonline updates to facilitate future learning. Our approach significantly\noutperforms other methods on several benchmarks.",
          "link": "http://arxiv.org/abs/2106.06795",
          "publishedOn": "2021-06-15T01:45:15.488Z",
          "wordCount": 631,
          "title": "Knowledge Consolidation based Class Incremental Online Learning with Limited Data. (arXiv:2106.06795v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06593",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1\">Kedan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chong_M/0/1/0/all/0/1\">Min jin Chong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jeffrey Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jingen Liu</a>",
          "description": "Virtual try-on methods aim to generate images of fashion models wearing\narbitrary combinations of garments. This is a challenging task because the\ngenerated image must appear realistic and accurately display the interaction\nbetween garments. Prior works produce images that are filled with artifacts and\nfail to capture important visual details necessary for commercial applications.\nWe propose Outfit Visualization Net (OVNet) to capture these important details\n(e.g. buttons, shading, textures, realistic hemlines, and interactions between\ngarments) and produce high quality multiple-garment virtual try-on images.\nOVNet consists of 1) a semantic layout generator and 2) an image generation\npipeline using multiple coordinated warps. We train the warper to output\nmultiple warps using a cascade loss, which refines each successive warp to\nfocus on poorly generated regions of a previous warp and yields consistent\nimprovements in detail. In addition, we introduce a method for matching outfits\nwith the most suitable model and produce significant improvements for both our\nand other previous try-on methods. Through quantitative and qualitative\nanalysis, we demonstrate our method generates substantially higher-quality\nstudio images compared to prior works for multi-garment outfits. An interactive\ninterface powered by this method has been deployed on fashion e-commerce\nwebsites and received overwhelmingly positive feedback.",
          "link": "http://arxiv.org/abs/2106.06593",
          "publishedOn": "2021-06-15T01:45:15.436Z",
          "wordCount": 653,
          "title": "Toward Accurate and Realistic Outfits Visualization with Attention to Details. (arXiv:2106.06593v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06657",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1\">Zhili Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Shaobo Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_S/0/1/0/all/0/1\">Simon S. Du</a>",
          "description": "This paper studies zero-shot domain adaptation where each domain is indexed\non a multi-dimensional array, and we only have data from a small subset of\ndomains. Our goal is to produce predictors that perform well on \\emph{unseen}\ndomains. We propose a model which consists of a domain-invariant latent\nrepresentation layer and a domain-specific linear prediction layer with a\nlow-rank tensor structure. Theoretically, we present explicit sample complexity\nbounds to characterize the prediction error on unseen domains in terms of the\nnumber of domains with training data and the number of data per domain. To our\nknowledge, this is the first finite-sample guarantee for zero-shot domain\nadaptation. In addition, we provide experiments on two-way MNIST and four-way\nfiber sensing datasets to demonstrate the effectiveness of our proposed model.",
          "link": "http://arxiv.org/abs/2106.06657",
          "publishedOn": "2021-06-15T01:45:15.425Z",
          "wordCount": 551,
          "title": "Provable Adaptation across Multiway Domains via Representation Learning. (arXiv:2106.06657v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06683",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jialu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Eric Wang</a>",
          "description": "Recently pre-trained multimodal models, such as CLIP, have received a surge\nof attention for their exceptional capabilities towards connecting images and\nnatural language. The textual representations in English can be desirably\ntransferred to multilingualism and support promising downstream multimodal\ntasks for different languages. Nevertheless, previous fairness discourse in\nvision-and-language learning mainly focuses on monolingual representational\nbiases, and rarely scrutinizes the principles of multilingual fairness in this\nmultimodal setting, where one language is equated to a group of individuals and\nimages provide the universal grounding for bridging different languages.\n\nIn this paper, we provide a nuanced understanding of individual fairness and\ngroup fairness by viewing language as the recipient of fairness notions. We\ndefine new fairness notions within multilingual context and analytically\narticulate that, pre-trained vision-and-language representations are\nindividually fair across languages but not guaranteed to group fairness.\nFurthermore, we conduct extensive experiments to explore the prevalent group\ndisparity across languages and protected groups including race, gender and age.",
          "link": "http://arxiv.org/abs/2106.06683",
          "publishedOn": "2021-06-15T01:45:15.289Z",
          "wordCount": 593,
          "title": "Assessing Multilingual Fairness in Pre-trained Multimodal Representations. (arXiv:2106.06683v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2103.02014",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mladenovic_A/0/1/0/all/0/1\">Andjela Mladenovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bose_A/0/1/0/all/0/1\">Avishek Joey Bose</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berard_H/0/1/0/all/0/1\">Hugo Berard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamilton_W/0/1/0/all/0/1\">William L. Hamilton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lacoste_Julien_S/0/1/0/all/0/1\">Simon Lacoste-Julien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vincent_P/0/1/0/all/0/1\">Pascal Vincent</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gidel_G/0/1/0/all/0/1\">Gauthier Gidel</a>",
          "description": "Adversarial attacks expose important vulnerabilities of deep learning models,\nyet little attention has been paid to settings where data arrives as a stream.\nIn this paper, we formalize the online adversarial attack problem, emphasizing\ntwo key elements found in real-world use-cases: attackers must operate under\npartial knowledge of the target model, and the decisions made by the attacker\nare irrevocable since they operate on a transient data stream. We first\nrigorously analyze a deterministic variant of the online threat model by\ndrawing parallels to the well-studied $k$-secretary problem in theoretical\ncomputer science and propose Virtual+, a simple yet practical online algorithm.\nOur main theoretical result show Virtual+ yields provably the best competitive\nratio over all single-threshold algorithms for $k<5$ -- extending previous\nanalysis of the $k$-secretary problem. We also introduce the \\textit{stochastic\n$k$-secretary} -- effectively reducing online blackbox transfer attacks to a\n$k$-secretary problem under noise -- and prove theoretical bounds on the\nperformance of \\textit{any} online algorithms adapted to this setting. Finally,\nwe complement our theoretical results by conducting experiments on both MNIST\nand CIFAR-10 with both vanilla and robust classifiers, revealing not only the\nnecessity of online algorithms in achieving near-optimal performance but also\nthe rich interplay of a given attack strategy towards online attack selection,\nenabling simple strategies like FGSM to outperform classically strong whitebox\nadversaries.",
          "link": "http://arxiv.org/abs/2103.02014",
          "publishedOn": "2021-06-14T22:41:41.478Z",
          "wordCount": 696,
          "title": "Online Adversarial Attacks. (arXiv:2103.02014v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.09612",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_Q/0/1/0/all/0/1\">Quynh Nguyen</a>",
          "description": "We give a simple proof for the global convergence of gradient descent in\ntraining deep ReLU networks with the standard square loss, and show some of its\nimprovements over the state-of-the-art. In particular, while prior works\nrequire all the hidden layers to be wide with width at least $\\Omega(N^8)$ ($N$\nbeing the number of training samples), we require a single wide layer of\nlinear, quadratic or cubic width depending on the type of initialization.\nUnlike many recent proofs based on the Neural Tangent Kernel (NTK), our proof\nneed not track the evolution of the entire NTK matrix, or more generally, any\nquantities related to the changes of activation patterns during training.\nInstead, we only need to track the evolution of the output at the last hidden\nlayer, which can be done much more easily thanks to the Lipschitz property of\nReLU. Some highlights of our setting: (i) all the layers are trained with\nstandard gradient descent, (ii) the network has standard parameterization as\nopposed to the NTK one, and (iii) the network has a single wide layer as\nopposed to having all wide hidden layers as in most of NTK-related results.",
          "link": "http://arxiv.org/abs/2101.09612",
          "publishedOn": "2021-06-14T22:41:41.457Z",
          "wordCount": 669,
          "title": "On the Proof of Global Convergence of Gradient Descent for Deep ReLU Networks with Linear Widths. (arXiv:2101.09612v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02770",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1\">Dongxia Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chinazzi_M/0/1/0/all/0/1\">Matteo Chinazzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vespignani_A/0/1/0/all/0/1\">Alessandro Vespignani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yi-An Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_R/0/1/0/all/0/1\">Rose Yu</a>",
          "description": "Stochastic simulations such as large-scale, spatiotemporal, age-structured\nepidemic models are computationally expensive at fine-grained resolution. We\npropose Interactive Neural Process (INP), an interactive framework to\ncontinuously learn a deep learning surrogate model and accelerate simulation.\nOur framework is based on the novel integration of Bayesian active learning,\nstochastic simulation and deep sequence modeling. In particular, we develop a\nnovel spatiotemporal neural process model to mimic the underlying process\ndynamics. Our model automatically infers the latent process which describes the\nintrinsic uncertainty of the simulator. This also gives rise to a new\nacquisition function that can quantify the uncertainty of deep learning\npredictions. We design Bayesian active learning algorithms to iteratively query\nthe simulator, gather more data, and continuously improve the model. We perform\ntheoretical analysis and demonstrate that our approach reduces sample\ncomplexity compared with random sampling in high dimension. Empirically, we\ndemonstrate our framework can faithfully imitate the behavior of a complex\ninfectious disease simulator with a small number of examples, enabling rapid\nsimulation and scenario exploration.",
          "link": "http://arxiv.org/abs/2106.02770",
          "publishedOn": "2021-06-14T22:41:41.445Z",
          "wordCount": 614,
          "title": "Accelerating Stochastic Simulation with Interactive Neural Processes. (arXiv:2106.02770v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.05313",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Remlinger_C/0/1/0/all/0/1\">Carl Remlinger</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mikael_J/0/1/0/all/0/1\">Joseph Mikael</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Elie_R/0/1/0/all/0/1\">Romuald Elie</a>",
          "description": "We introduce three new generative models for time series. Based on Euler\ndiscretization and Wasserstein metrics, they are able to capture time marginal\ndistributions and temporal dynamics. Two of these methods rely on the\nadaptation of generative adversarial networks (GANs) to time series. Both of\nthem outperform state-of-the-art benchmarks by capturing the underlying\ntemporal structure on synthetic time series. The third algorithm, called\nConditional Euler Generator (CEGEN), minimizes a dedicated distance between the\ntransition probability distributions over all time steps. In the context of Ito\nprocesses, we provide theoretical guarantees that minimizing this criterion\nimplies accurate estimations of the drift and volatility parameters. We\ndemonstrate empirically that CEGEN outperforms state-of-the-art and GAN\ngenerators on both marginal and temporal dynamics metrics. Besides, it\nidentifies accurate correlation structures in high dimension. When few data\npoints are available, we verify the effectiveness of CEGEN, when combined with\ntransfer learning methods on Monte Carlo simulations. Finally, we illustrate\nthe robustness of our method on various real-world datasets.",
          "link": "http://arxiv.org/abs/2102.05313",
          "publishedOn": "2021-06-14T22:41:41.415Z",
          "wordCount": 636,
          "title": "Conditional and Adversarial Euler-based Generators For Time Series. (arXiv:2102.05313v4 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.09500",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sapir_M/0/1/0/all/0/1\">Marina Sapir</a>",
          "description": "I propose a new, logical, foundation for ML. ML is approached as a problem of\nmaximizing consistency of a hypothesis in a context of a given training set.\nNonjudgmental logic (NjL) with modalities ``It appears that'', ``Assume that''\nis introduced to formalize and quantify the inconsistency. Many popular ML\nalgorithms (from hierarchical clustering to k-NN and SVM) are shown to\ncorroborate the conjecture. In addition, it is demonstrated that NjL allows to\nformalize and solve several general learning problems which are not considered\nas ML usually.",
          "link": "http://arxiv.org/abs/2006.09500",
          "publishedOn": "2021-06-14T22:41:41.392Z",
          "wordCount": 537,
          "title": "Logic of Machine Learning. (arXiv:2006.09500v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.01618",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jun-Kun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chi-Heng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abernethy_J/0/1/0/all/0/1\">Jacob Abernethy</a>",
          "description": "Incorporating a so-called \"momentum\" dynamic in gradient descent methods is\nwidely used in neural net training as it has been broadly observed that, at\nleast empirically, it often leads to significantly faster convergence. At the\nsame time, there are very few theoretical guarantees in the literature to\nexplain this apparent acceleration effect. Even for the classical strongly\nconvex quadratic problems, several existing results only show Polyak's momentum\nhas an accelerated linear rate asymptotically. In this paper, we first revisit\nthe quadratic problems and show a non-asymptotic accelerated linear rate of\nPolyak's momentum. Then, we provably show that Polyak's momentum achieves\nacceleration for training a one-layer wide ReLU network and a deep linear\nnetwork, which are perhaps the two most popular canonical models for studying\noptimization and deep learning in the literature. Prior work Du at al. 2019 and\nWu et al. 2019 showed that using vanilla gradient descent, and with an use of\nover-parameterization, the error decays as $(1- \\Theta(\\frac{1}{ \\kappa'}))^t$\nafter $t$ iterations, where $\\kappa'$ is the condition number of a Gram Matrix.\nOur result shows that with the appropriate choice of parameters Polyak's\nmomentum has a rate of $(1-\\Theta(\\frac{1}{\\sqrt{\\kappa'}}))^t$. For the deep\nlinear network, prior work Hu et al. 2020 showed that vanilla gradient descent\nhas a rate of $(1-\\Theta(\\frac{1}{\\kappa}))^t$, where $\\kappa$ is the condition\nnumber of a data matrix. Our result shows an acceleration rate $(1-\n\\Theta(\\frac{1}{\\sqrt{\\kappa}}))^t$ is achievable by Polyak's momentum. All the\nresults in this work are obtained from a modular analysis, which can be of\nindependent interest. This work establishes that momentum does indeed speed up\nneural net training.",
          "link": "http://arxiv.org/abs/2010.01618",
          "publishedOn": "2021-06-14T22:41:41.359Z",
          "wordCount": 789,
          "title": "A Modular Analysis of Provable Acceleration via Polyak's Momentum: Training a Wide ReLU Network and a Deep Linear Network. (arXiv:2010.01618v6 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.07006",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Camuto_A/0/1/0/all/0/1\">Alexander Camuto</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_X/0/1/0/all/0/1\">Xiaoyu Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhu_L/0/1/0/all/0/1\">Lingjiong Zhu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Holmes_C/0/1/0/all/0/1\">Chris Holmes</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gurbuzbalaban_M/0/1/0/all/0/1\">Mert G&#xfc;rb&#xfc;zbalaban</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Simsekli_U/0/1/0/all/0/1\">Umut &#x15e;im&#x15f;ekli</a>",
          "description": "Gaussian noise injections (GNIs) are a family of simple and widely-used\nregularisation methods for training neural networks, where one injects additive\nor multiplicative Gaussian noise to the network activations at every iteration\nof the optimisation algorithm, which is typically chosen as stochastic gradient\ndescent (SGD). In this paper we focus on the so-called `implicit effect' of\nGNIs, which is the effect of the injected noise on the dynamics of SGD. We show\nthat this effect induces an asymmetric heavy-tailed noise on SGD gradient\nupdates. In order to model this modified dynamics, we first develop a\nLangevin-like stochastic differential equation that is driven by a general\nfamily of asymmetric heavy-tailed noise. Using this model we then formally\nprove that GNIs induce an `implicit bias', which varies depending on the\nheaviness of the tails and the level of asymmetry. Our empirical results\nconfirm that different types of neural networks trained with GNIs are\nwell-modelled by the proposed dynamics and that the implicit effect of these\ninjections induces a bias that degrades the performance of networks.",
          "link": "http://arxiv.org/abs/2102.07006",
          "publishedOn": "2021-06-14T01:38:56.498Z",
          "wordCount": 634,
          "title": "Asymmetric Heavy Tails and Implicit Bias in Gaussian Noise Injections. (arXiv:2102.07006v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.09690",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tony Z. Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wallace_E/0/1/0/all/0/1\">Eric Wallace</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1\">Shi Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klein_D/0/1/0/all/0/1\">Dan Klein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Sameer Singh</a>",
          "description": "GPT-3 can perform numerous tasks when provided a natural language prompt that\ncontains a few training examples. We show that this type of few-shot learning\ncan be unstable: the choice of prompt format, training examples, and even the\norder of the training examples can cause accuracy to vary from near chance to\nnear state-of-the-art. We demonstrate that this instability arises from the\nbias of language models towards predicting certain answers, e.g., those that\nare placed near the end of the prompt or are common in the pre-training data.\nTo mitigate this, we first estimate the model's bias towards each answer by\nasking for its prediction when given the training prompt and a content-free\ntest input such as \"N/A\". We then fit calibration parameters that cause the\nprediction for this input to be uniform across answers. On a diverse set of\ntasks, this contextual calibration procedure substantially improves GPT-3 and\nGPT-2's average accuracy (up to 30.0% absolute) and reduces variance across\ndifferent choices of the prompt.",
          "link": "http://arxiv.org/abs/2102.09690",
          "publishedOn": "2021-06-14T01:38:56.490Z",
          "wordCount": 632,
          "title": "Calibrate Before Use: Improving Few-Shot Performance of Language Models. (arXiv:2102.09690v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06533",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bhattad_A/0/1/0/all/0/1\">Anand Bhattad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dundar_A/0/1/0/all/0/1\">Aysegul Dundar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Guilin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_A/0/1/0/all/0/1\">Andrew Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Catanzaro_B/0/1/0/all/0/1\">Bryan Catanzaro</a>",
          "description": "Humans can easily infer the underlying 3D geometry and texture of an object\nonly from a single 2D image. Current computer vision methods can do this, too,\nbut suffer from view generalization problems - the models inferred tend to make\npoor predictions of appearance in novel views. As for generalization problems\nin machine learning, the difficulty is balancing single-view accuracy (cf.\ntraining error; bias) with novel view accuracy (cf. test error; variance). We\ndescribe a class of models whose geometric rigidity is easily controlled to\nmanage this tradeoff. We describe a cycle consistency loss that improves view\ngeneralization (roughly, a model from a generated view should predict the\noriginal view well). View generalization of textures requires that models share\ntexture information, so a car seen from the back still has headlights because\nother cars have headlights. We describe a cycle consistency loss that\nencourages model textures to be aligned, so as to encourage sharing. We compare\nour method against the state-of-the-art method and show both qualitative and\nquantitative improvements.",
          "link": "http://arxiv.org/abs/2106.06533",
          "publishedOn": "2021-06-14T01:38:56.482Z",
          "wordCount": 620,
          "title": "View Generalization for Single Image Textured 3D Models. (arXiv:2106.06533v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2012.01316",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1\">Yilun Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shuang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1\">Joshua Tenenbaum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mordatch_I/0/1/0/all/0/1\">Igor Mordatch</a>",
          "description": "Contrastive divergence is a popular method of training energy-based models,\nbut is known to have difficulties with training stability. We propose an\nadaptation to improve contrastive divergence training by scrutinizing a\ngradient term that is difficult to calculate and is often left out for\nconvenience. We show that this gradient term is numerically significant and in\npractice is important to avoid training instabilities, while being tractable to\nestimate. We further highlight how data augmentation and multi-scale processing\ncan be used to improve model robustness and generation quality. Finally, we\nempirically evaluate stability of model architectures and show improved\nperformance on a host of benchmarks and use cases,such as image generation, OOD\ndetection, and compositional generation.",
          "link": "http://arxiv.org/abs/2012.01316",
          "publishedOn": "2021-06-14T01:38:56.462Z",
          "wordCount": 596,
          "title": "Improved Contrastive Divergence Training of Energy Based Models. (arXiv:2012.01316v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.06192",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rister_B/0/1/0/all/0/1\">Blaine Rister</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubin_D/0/1/0/all/0/1\">Daniel L. Rubin</a>",
          "description": "Neuron death is a complex phenomenon with implications for model\ntrainability: the deeper the network, the lower the probability of finding a\nvalid initialization. In this work, we derive both upper and lower bounds on\nthe probability that a ReLU network is initialized to a trainable point, as a\nfunction of model hyperparameters. We show that it is possible to increase the\ndepth of a network indefinitely, so long as the width increases as well.\nFurthermore, our bounds are asymptotically tight under reasonable assumptions:\nfirst, the upper bound coincides with the true probability for a single-layer\nnetwork with the largest possible input set. Second, the true probability\nconverges to our lower bound as the input set shrinks to a single point, or as\nthe network complexity grows under an assumption about the output variance. We\nconfirm these results by numerical simulation, showing rapid convergence to the\nlower bound with increasing network depth. Then, motivated by the theory, we\npropose a practical sign flipping scheme which guarantees that the ratio of\nliving data points in a $k$-layer network is at least $2^{-k}$. Finally, we\nshow how these issues are mitigated by network design features currently seen\nin practice, such as batch normalization, residual connections, dense networks\nand skip connections. This suggests that neuron death may provide insight into\nthe efficacy of various model architectures.",
          "link": "http://arxiv.org/abs/2007.06192",
          "publishedOn": "2021-06-14T01:38:56.451Z",
          "wordCount": 685,
          "title": "Probabilistic bounds on neuron death in deep rectifier networks. (arXiv:2007.06192v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.11568",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mengyan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ong_C/0/1/0/all/0/1\">Cheng Soon Ong</a>",
          "description": "We consider a variant of the best arm identification task in stochastic\nmulti-armed bandits. Motivated by risk-averse decision-making problems, our\ngoal is to identify a set of $m$ arms with the highest $\\tau$-quantile values\nwithin a fixed budget. We prove asymmetric two-sided concentration inequalities\nfor order statistics and quantiles of random variables that have non-decreasing\nhazard rate, which may be of independent interest. With these inequalities, we\nanalyse a quantile version of Successive Accepts and Rejects (Q-SAR). We derive\nan upper bound for the probability of arm misidentification, the first\njustification of a quantile based algorithm for fixed budget multiple best arms\nidentification. We show illustrative experiments for best arm identification.",
          "link": "http://arxiv.org/abs/2010.11568",
          "publishedOn": "2021-06-14T01:38:56.444Z",
          "wordCount": 566,
          "title": "Quantile Bandits for Best Arms Identification. (arXiv:2010.11568v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.07641",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rizk_G/0/1/0/all/0/1\">Geovani Rizk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thomas_A/0/1/0/all/0/1\">Albert Thomas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Colin_I/0/1/0/all/0/1\">Igor Colin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laraki_R/0/1/0/all/0/1\">Rida Laraki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chevaleyre_Y/0/1/0/all/0/1\">Yann Chevaleyre</a>",
          "description": "We introduce a new graphical bilinear bandit problem where a learner (or a\n\\emph{central entity}) allocates arms to the nodes of a graph and observes for\neach edge a noisy bilinear reward representing the interaction between the two\nend nodes. We study the best arm identification problem in which the learner\nwants to find the graph allocation maximizing the sum of the bilinear rewards.\nBy efficiently exploiting the geometry of this bandit problem, we propose a\n\\emph{decentralized} allocation strategy based on random sampling with\ntheoretical guarantees. In particular, we characterize the influence of the\ngraph structure (e.g. star, complete or circle) on the convergence rate and\npropose empirical experiments that confirm this dependency.",
          "link": "http://arxiv.org/abs/2012.07641",
          "publishedOn": "2021-06-14T01:38:56.437Z",
          "wordCount": 574,
          "title": "Best Arm Identification in Graphical Bilinear Bandits. (arXiv:2012.07641v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.04764",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yildiz_C/0/1/0/all/0/1\">&#xc7;a&#x11f;atay Y&#x131;ld&#x131;z</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heinonen_M/0/1/0/all/0/1\">Markus Heinonen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lahdesmaki_H/0/1/0/all/0/1\">Harri L&#xe4;hdesm&#xe4;ki</a>",
          "description": "Model-based reinforcement learning (MBRL) approaches rely on discrete-time\nstate transition models whereas physical systems and the vast majority of\ncontrol tasks operate in continuous-time. To avoid time-discretization\napproximation of the underlying process, we propose a continuous-time MBRL\nframework based on a novel actor-critic method. Our approach also infers the\nunknown state evolution differentials with Bayesian neural ordinary\ndifferential equations (ODE) to account for epistemic uncertainty. We implement\nand test our method on a new ODE-RL suite that explicitly solves\ncontinuous-time control systems. Our experiments illustrate that the model is\nrobust against irregular and noisy data, is sample-efficient, and can solve\ncontrol problems which pose challenges to discrete-time MBRL methods.",
          "link": "http://arxiv.org/abs/2102.04764",
          "publishedOn": "2021-06-14T01:38:56.430Z",
          "wordCount": 565,
          "title": "Continuous-Time Model-Based Reinforcement Learning. (arXiv:2102.04764v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03211",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1\">Nhuong V. Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Legitime_S/0/1/0/all/0/1\">Sybille Legitime</a>",
          "description": "Extreme events are occurrences whose magnitude and potential cause extensive\ndamage on people, infrastructure, and the environment. Motivated by the extreme\nnature of the current global health landscape, which is plagued by the\ncoronavirus pandemic, we seek to better understand and model extreme events.\nModeling extreme events is common in practice and plays an important role in\ntime-series prediction applications. Our goal is to (i) compare and investigate\nthe effect of some common extreme events modeling methods to explore which\nmethod can be practical in reality and (ii) accelerate the deep learning\ntraining process, which commonly uses deep recurrent neural network (RNN), by\nimplementing the asynchronous local Stochastic Gradient Descent (SGD) framework\namong multiple compute nodes. In order to verify our distributed extreme events\nmodeling, we evaluate our proposed framework on a stock data set S\\&P500, with\na standard recurrent neural network. Our intuition is to explore the (best)\nextreme events modeling method which could work well under the distributed deep\nlearning setting. Moreover, by using asynchronous distributed learning, we aim\nto significantly reduce the communication cost among the compute nodes and\ncentral server, which is the main bottleneck of almost all distributed learning\nframeworks.\n\nWe implement our proposed work and evaluate its performance on representative\ndata sets, such as S&P500 stock in $5$-year period. The experimental results\nvalidate the correctness of the design principle and show a significant\ntraining duration reduction upto $8$x, compared to the baseline single compute\nnode. Our results also show that our proposed work can achieve the same level\nof test accuracy, compared to the baseline setting.",
          "link": "http://arxiv.org/abs/2106.03211",
          "publishedOn": "2021-06-14T01:38:56.408Z",
          "wordCount": 764,
          "title": "Distributed Learning and its Application for Time-Series Prediction. (arXiv:2106.03211v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06475",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Baghali_S/0/1/0/all/0/1\">Sina Baghali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasan_S/0/1/0/all/0/1\">Samiul Hasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1\">Zhaomiao Guo</a>",
          "description": "The increasing market penetration of electric vehicles (EVs) may pose\nsignificant electricity demand on power systems. This electricity demand is\naffected by the inherent uncertainties of EVs' travel behavior that makes\nforecasting the daily charging demand (CD) very challenging. In this project,\nwe use the National House Hold Survey (NHTS) data to form sequences of trips,\nand develop machine learning models to predict the parameters of the next trip\nof the drivers, including trip start time, end time, and distance. These\nparameters are later used to model the temporal charging behavior of EVs. The\nsimulation results show that the proposed modeling can effectively estimate the\ndaily CD pattern based on travel behavior of EVs, and simple machine learning\ntechniques can forecast the travel parameters with acceptable accuracy.",
          "link": "http://arxiv.org/abs/2106.06475",
          "publishedOn": "2021-06-14T01:38:56.398Z",
          "wordCount": 575,
          "title": "Analyzing the Travel and Charging Behavior of Electric Vehicles -- A Data-driven Approach. (arXiv:2106.06475v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06437",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cunningham_P/0/1/0/all/0/1\">Padraig Cunningham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kathirgamanathan_B/0/1/0/all/0/1\">Bahavathy Kathirgamanathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Delany_S/0/1/0/all/0/1\">Sarah Jane Delany</a>",
          "description": "In Machine Learning, feature selection entails selecting a subset of the\navailable features in a dataset to use for model development. There are many\nmotivations for feature selection, it may result in better models, it may\nprovide insight into the data and it may deliver economies in data gathering or\ndata processing. For these reasons feature selection has received a lot of\nattention in data analytics research. In this paper we provide an overview of\nthe main methods and present practical examples with Python implementations.\nWhile the main focus is on supervised feature selection techniques, we also\ncover some feature transformation methods.",
          "link": "http://arxiv.org/abs/2106.06437",
          "publishedOn": "2021-06-14T01:38:56.391Z",
          "wordCount": 525,
          "title": "Feature Selection Tutorial with Python Examples. (arXiv:2106.06437v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03640",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Masters_D/0/1/0/all/0/1\">Dominic Masters</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Labatie_A/0/1/0/all/0/1\">Antoine Labatie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eaton_Rosen_Z/0/1/0/all/0/1\">Zach Eaton-Rosen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luschi_C/0/1/0/all/0/1\">Carlo Luschi</a>",
          "description": "Much recent research has been dedicated to improving the efficiency of\ntraining and inference for image classification. This effort has commonly\nfocused on explicitly improving theoretical efficiency, often measured as\nImageNet validation accuracy per FLOP. These theoretical savings have, however,\nproven challenging to achieve in practice, particularly on high-performance\ntraining accelerators.\n\nIn this work, we focus on improving the practical efficiency of the\nstate-of-the-art EfficientNet models on a new class of accelerator, the\nGraphcore IPU. We do this by extending this family of models in the following\nways: (i) generalising depthwise convolutions to group convolutions; (ii)\nadding proxy-normalized activations to match batch normalization performance\nwith batch-independent statistics; (iii) reducing compute by lowering the\ntraining resolution and inexpensively fine-tuning at higher resolution. We find\nthat these three methods improve the practical efficiency for both training and\ninference. Our code will be made available online.",
          "link": "http://arxiv.org/abs/2106.03640",
          "publishedOn": "2021-06-14T01:38:56.380Z",
          "wordCount": 605,
          "title": "Making EfficientNet More Efficient: Exploring Batch-Independent Normalization, Group Convolutions and Reduced Resolution Training. (arXiv:2106.03640v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.03636",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Liu_K/0/1/0/all/0/1\">Kangqiao Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ziyin_L/0/1/0/all/0/1\">Liu Ziyin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ueda_M/0/1/0/all/0/1\">Masahito Ueda</a>",
          "description": "In the vanishing learning rate regime, stochastic gradient descent (SGD) is\nnow relatively well understood. In this work, we propose to study the basic\nproperties of SGD and its variants in the non-vanishing learning rate regime.\nThe focus is on deriving exactly solvable results and discussing their\nimplications. The main contributions of this work are to derive the stationary\ndistribution for discrete-time SGD in a quadratic loss function with and\nwithout momentum; in particular, one implication of our result is that the\nfluctuation caused by discrete-time dynamics takes a distorted shape and is\ndramatically larger than a continuous-time theory could predict. Examples of\napplications of the proposed theory considered in this work include the\napproximation error of variants of SGD, the effect of minibatch noise, the\noptimal Bayesian inference, the escape rate from a sharp minimum, and the\nstationary covariance of a few second-order methods including damped Newton's\nmethod, natural gradient descent, and Adam.",
          "link": "http://arxiv.org/abs/2012.03636",
          "publishedOn": "2021-06-14T01:38:56.373Z",
          "wordCount": 649,
          "title": "Noise and Fluctuation of Finite Learning Rate Stochastic Gradient Descent. (arXiv:2012.03636v4 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.02569",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Liu_Q/0/1/0/all/0/1\">Qingfeng Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Feng_Y/0/1/0/all/0/1\">Yang Feng</a>",
          "description": "We propose a new ensemble framework for supervised learning, called machine\ncollaboration (MaC), using a collection of base machines for prediction tasks.\nUnlike bagging/stacking (a parallel & independent framework) and boosting (a\nsequential & top-down framework), MaC is a type of circular & interactive\nlearning framework. The circular & interactive feature helps the base machines\nto transfer information circularly and update their structures and parameters\naccordingly. The theoretical result on the risk bound of the estimator from MaC\nreveals that the circular & interactive feature can help MaC reduce risk via a\nparsimonious ensemble. We conduct extensive experiments on MaC using both\nsimulated data and 119 benchmark real datasets. The results demonstrate that in\nmost cases, MaC performs significantly better than several other\nstate-of-the-art methods, including classification and regression trees, neural\nnetworks, stacking, and boosting.",
          "link": "http://arxiv.org/abs/2105.02569",
          "publishedOn": "2021-06-14T01:38:56.355Z",
          "wordCount": 584,
          "title": "Machine Collaboration. (arXiv:2105.02569v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14866",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Camuto_A/0/1/0/all/0/1\">Alexander Camuto</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Willetts_M/0/1/0/all/0/1\">Matthew Willetts</a>",
          "description": "In this work we study Variational Autoencoders (VAEs) from the perspective of\nharmonic analysis. By viewing a VAE's latent space as a Gaussian Space, a\nvariety of measure space, we derive a series of results that show that the\nencoder variance of a VAE controls the frequency content of the functions\nparameterised by the VAE encoder and decoder neural networks. In particular we\ndemonstrate that larger encoder variances reduce the high frequency content of\nthese functions. Our analysis allows us to show that increasing this variance\neffectively induces a soft Lipschitz constraint on the decoder network of a\nVAE, which is a core contributor to the adversarial robustness of VAEs. We\nfurther demonstrate that adding Gaussian noise to the input of a VAE allows us\nto more finely control the frequency content and the Lipschitz constant of the\nVAE encoder networks. To support our theoretical analysis we run experiments\nwith VAEs with small fully-connected neural networks and with larger\nconvolutional networks, demonstrating empirically that our theory holds for a\nvariety of neural network architectures.",
          "link": "http://arxiv.org/abs/2105.14866",
          "publishedOn": "2021-06-14T01:38:56.348Z",
          "wordCount": 629,
          "title": "Variational Autoencoders: A Harmonic Perspective. (arXiv:2105.14866v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.02710",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jennifer J. Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karigo_T/0/1/0/all/0/1\">Tomomi Karigo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_D/0/1/0/all/0/1\">Dipam Chakraborty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohanty_S/0/1/0/all/0/1\">Sharada P. Mohanty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wild_B/0/1/0/all/0/1\">Benjamin Wild</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Q/0/1/0/all/0/1\">Quan Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anderson_D/0/1/0/all/0/1\">David J. Anderson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perona_P/0/1/0/all/0/1\">Pietro Perona</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yue_Y/0/1/0/all/0/1\">Yisong Yue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kennedy_A/0/1/0/all/0/1\">Ann Kennedy</a>",
          "description": "Multi-agent behavior modeling aims to understand the interactions that occur\nbetween agents. We present a multi-agent dataset from behavioral neuroscience,\nthe Caltech Mouse Social Interactions (CalMS21) Dataset. Our dataset consists\nof trajectory data of social interactions, recorded from videos of freely\nbehaving mice in a standard resident-intruder assay. To help accelerate\nbehavioral studies, the CalMS21 dataset provides benchmarks to evaluate the\nperformance of automated behavior classification methods in three settings: (1)\nfor training on large behavioral datasets all annotated by a single annotator,\n(2) for style transfer to learn inter-annotator differences in behavior\ndefinitions, and (3) for learning of new behaviors of interest given limited\ntraining data. The dataset consists of 6 million frames of unlabeled tracked\nposes of interacting mice, as well as over 1 million frames with tracked poses\nand corresponding frame-level behavior annotations. The challenge of our\ndataset is to be able to classify behaviors accurately using both labeled and\nunlabeled tracking data, as well as being able to generalize to new settings.",
          "link": "http://arxiv.org/abs/2104.02710",
          "publishedOn": "2021-06-14T01:38:56.339Z",
          "wordCount": 662,
          "title": "The Multi-Agent Behavior Dataset: Mouse Dyadic Social Interactions. (arXiv:2104.02710v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.10836",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meng_T/0/1/0/all/0/1\">Tao Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>",
          "description": "Structured output prediction problems (e.g., sequential tagging, hierarchical\nmulti-class classification) often involve constraints over the output label\nspace. These constraints interact with the learned models to filter infeasible\nsolutions and facilitate in building an accountable system. However, although\nconstraints are useful, they are often based on hand-crafted rules. This raises\na question -- \\emph{can we mine constraints and rules from data based on a\nlearning algorithm?}\n\nIn this paper, we present a general framework for mining constraints from\ndata. In particular, we consider the inference in structured output prediction\nas an integer linear programming (ILP) problem. Then, given the coefficients of\nthe objective function and the corresponding solution, we mine the underlying\nconstraints by estimating the outer and inner polytopes of the feasible set. We\nverify the proposed constraint mining algorithm in various synthetic and\nreal-world applications and demonstrate that the proposed approach successfully\nidentifies the feasible set at scale.\n\nIn particular, we show that our approach can learn to solve 9x9 Sudoku\npuzzles and minimal spanning tree problems from examples without providing the\nunderlying rules. Our algorithm can also integrate with a neural network model\nto learn the hierarchical label structure of a multi-label classification task.\nBesides, we provide a theoretical analysis about the tightness of the polytopes\nand the reliability of the mined constraints.",
          "link": "http://arxiv.org/abs/2006.10836",
          "publishedOn": "2021-06-14T01:38:56.331Z",
          "wordCount": 681,
          "title": "An Integer Linear Programming Framework for Mining Constraints from Data. (arXiv:2006.10836v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.07869",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Papoudakis_G/0/1/0/all/0/1\">Georgios Papoudakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Christianos_F/0/1/0/all/0/1\">Filippos Christianos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schafer_L/0/1/0/all/0/1\">Lukas Sch&#xe4;fer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Albrecht_S/0/1/0/all/0/1\">Stefano V. Albrecht</a>",
          "description": "Multi-agent deep reinforcement learning (MARL) suffers from a lack of\ncommonly-used evaluation tasks and criteria, making comparisons between\napproaches difficult. In this work, we consistently evaluate and compare three\ndifferent classes of MARL algorithms (independent learning, centralised\nmulti-agent policy gradient, value decomposition) in a diverse range of\ncooperative multi-agent learning tasks. Our experiments serve as a reference\nfor the expected performance of algorithms across different learning tasks, and\nwe provide insights regarding the effectiveness of different learning\napproaches. We open-source EPyMARL, which extends the PyMARL\ncodebase~\\citep{samvelyan19smac} to include additional algorithms and allow for\nflexible configuration of algorithm implementation details such as parameter\nsharing. Finally, we open-source two environments for multi-agent research\nwhich focus on coordination under sparse rewards.",
          "link": "http://arxiv.org/abs/2006.07869",
          "publishedOn": "2021-06-14T01:38:56.323Z",
          "wordCount": 596,
          "title": "Benchmarking Multi-Agent Deep Reinforcement Learning Algorithms in Cooperative Tasks. (arXiv:2006.07869v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.00990",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pope_A/0/1/0/all/0/1\">Adrian P. Pope</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ide_J/0/1/0/all/0/1\">Jaime S. Ide</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Micovic_D/0/1/0/all/0/1\">Daria Micovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diaz_H/0/1/0/all/0/1\">Henry Diaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosenbluth_D/0/1/0/all/0/1\">David Rosenbluth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ritholtz_L/0/1/0/all/0/1\">Lee Ritholtz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Twedt_J/0/1/0/all/0/1\">Jason C. Twedt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walker_T/0/1/0/all/0/1\">Thayne T. Walker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alcedo_K/0/1/0/all/0/1\">Kevin Alcedo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Javorsek_D/0/1/0/all/0/1\">Daniel Javorsek</a>",
          "description": "Artificial Intelligence (AI) is becoming a critical component in the defense\nindustry, as recently demonstrated by DARPA`s AlphaDogfight Trials (ADT). ADT\nsought to vet the feasibility of AI algorithms capable of piloting an F-16 in\nsimulated air-to-air combat. As a participant in ADT, Lockheed Martin`s (LM)\napproach combines a hierarchical architecture with maximum-entropy\nreinforcement learning (RL), integrates expert knowledge through reward\nshaping, and supports modularity of policies. This approach achieved a $2^{nd}$\nplace finish in the final ADT event (among eight total competitors) and\ndefeated a graduate of the US Air Force's (USAF) F-16 Weapons Instructor Course\nin match play.",
          "link": "http://arxiv.org/abs/2105.00990",
          "publishedOn": "2021-06-14T01:38:56.302Z",
          "wordCount": 583,
          "title": "Hierarchical Reinforcement Learning for Air-to-Air Combat. (arXiv:2105.00990v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.07749",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chebotar_Y/0/1/0/all/0/1\">Yevgen Chebotar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hausman_K/0/1/0/all/0/1\">Karol Hausman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yao Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_T/0/1/0/all/0/1\">Ted Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalashnikov_D/0/1/0/all/0/1\">Dmitry Kalashnikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Varley_J/0/1/0/all/0/1\">Jake Varley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Irpan_A/0/1/0/all/0/1\">Alex Irpan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eysenbach_B/0/1/0/all/0/1\">Benjamin Eysenbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Julian_R/0/1/0/all/0/1\">Ryan Julian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1\">Chelsea Finn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1\">Sergey Levine</a>",
          "description": "We consider the problem of learning useful robotic skills from previously\ncollected offline data without access to manually specified rewards or\nadditional online exploration, a setting that is becoming increasingly\nimportant for scaling robot learning by reusing past robotic data. In\nparticular, we propose the objective of learning a functional understanding of\nthe environment by learning to reach any goal state in a given dataset. We\nemploy goal-conditioned Q-learning with hindsight relabeling and develop\nseveral techniques that enable training in a particularly challenging offline\nsetting. We find that our method can operate on high-dimensional camera images\nand learn a variety of skills on real robots that generalize to previously\nunseen scenes and objects. We also show that our method can learn to reach\nlong-horizon goals across multiple episodes through goal chaining, and learn\nrich representations that can help with downstream tasks through pre-training\nor auxiliary objectives. The videos of our experiments can be found at\nhttps://actionable-models.github.io",
          "link": "http://arxiv.org/abs/2104.07749",
          "publishedOn": "2021-06-14T01:38:56.294Z",
          "wordCount": 640,
          "title": "Actionable Models: Unsupervised Offline Reinforcement Learning of Robotic Skills. (arXiv:2104.07749v3 [cs.RO] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06150",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1\">Jialin Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_D/0/1/0/all/0/1\">Da Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Lin F. Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karypis_G/0/1/0/all/0/1\">Geroge Karypis</a>",
          "description": "Graph neural networks (GNNs) are powerful tools for learning from graph data\nand are widely used in various applications such as social network\nrecommendation, fraud detection, and graph search. The graphs in these\napplications are typically large, usually containing hundreds of millions of\nnodes. Training GNN models on such large graphs efficiently remains a big\nchallenge. Despite a number of sampling-based methods have been proposed to\nenable mini-batch training on large graphs, these methods have not been proved\nto work on truly industry-scale graphs, which require GPUs or mixed-CPU-GPU\ntraining. The state-of-the-art sampling-based methods are usually not optimized\nfor these real-world hardware setups, in which data movement between CPUs and\nGPUs is a bottleneck. To address this issue, we propose Global Neighborhood\nSampling that aims at training GNNs on giant graphs specifically for\nmixed-CPU-GPU training. The algorithm samples a global cache of nodes\nperiodically for all mini-batches and stores them in GPUs. This global cache\nallows in-GPU importance sampling of mini-batches, which drastically reduces\nthe number of nodes in a mini-batch, especially in the input layer, to reduce\ndata copy between CPU and GPU and mini-batch computation without compromising\nthe training convergence rate or model accuracy. We provide a highly efficient\nimplementation of this method and show that our implementation outperforms an\nefficient node-wise neighbor sampling baseline by a factor of 2X-4X on giant\ngraphs. It outperforms an efficient implementation of LADIES with small layers\nby a factor of 2X-14X while achieving much higher accuracy than LADIES.We also\ntheoretically analyze the proposed algorithm and show that with cached node\ndata of a proper size, it enjoys a comparable convergence rate as the\nunderlying node-wise sampling method.",
          "link": "http://arxiv.org/abs/2106.06150",
          "publishedOn": "2021-06-14T01:38:56.287Z",
          "wordCount": 720,
          "title": "Global Neighbor Sampling for Mixed CPU-GPU Training on Giant Graphs. (arXiv:2106.06150v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2103.11888",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ali_A/0/1/0/all/0/1\">Ameen Ali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galanti_T/0/1/0/all/0/1\">Tomer Galanti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheltonozhskiy_E/0/1/0/all/0/1\">Evgeniy Zheltonozhskiy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baskin_C/0/1/0/all/0/1\">Chaim Baskin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolf_L/0/1/0/all/0/1\">Lior Wolf</a>",
          "description": "We consider the problem of the extraction of semantic attributes, supervised\nonly with classification labels. For example, when learning to classify images\nof birds into species, we would like to observe the emergence of features that\nzoologists use to classify birds. To tackle this problem, we propose training a\nneural network with discrete features in the last layer, which is followed by\ntwo heads: a multi-layered perceptron (MLP) and a decision tree. Since decision\ntrees utilize simple binary decision stumps we expect those discrete features\nto obtain semantic meaning. We present a theoretical analysis as well as a\npractical method for learning in the intersection of two hypothesis classes.\nOur results on multiple benchmarks show an improved ability to extract a set of\nfeatures that are highly correlated with the set of unseen attributes.",
          "link": "http://arxiv.org/abs/2103.11888",
          "publishedOn": "2021-06-14T01:38:56.278Z",
          "wordCount": 583,
          "title": "Weakly Supervised Recovery of Semantic Attributes. (arXiv:2103.11888v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.10834",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Levine_A/0/1/0/all/0/1\">Alexander Levine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feizi_S/0/1/0/all/0/1\">Soheil Feizi</a>",
          "description": "Randomized smoothing is a general technique for computing sample-dependent\nrobustness guarantees against adversarial attacks for deep classifiers. Prior\nworks on randomized smoothing against L_1 adversarial attacks use additive\nsmoothing noise and provide probabilistic robustness guarantees. In this work,\nwe propose a non-additive and deterministic smoothing method, Deterministic\nSmoothing with Splitting Noise (DSSN). To develop DSSN, we first develop SSN, a\nrandomized method which involves generating each noisy smoothing sample by\nfirst randomly splitting the input space and then returning a representation of\nthe center of the subdivision occupied by the input sample. In contrast to\nuniform additive smoothing, the SSN certification does not require the random\nnoise components used to be independent. Thus, smoothing can be done\neffectively in just one dimension and can therefore be efficiently derandomized\nfor quantized data (e.g., images). To the best of our knowledge, this is the\nfirst work to provide deterministic \"randomized smoothing\" for a norm-based\nadversarial threat model while allowing for an arbitrary classifier (i.e., a\ndeep model) to be used as a base classifier and without requiring an\nexponential number of smoothing samples. On CIFAR-10 and ImageNet datasets, we\nprovide substantially larger L_1 robustness certificates compared to prior\nworks, establishing a new state-of-the-art. The determinism of our method also\nleads to significantly faster certificate computation. Code is available at:\nhttps://github.com/alevine0/smoothingSplittingNoise",
          "link": "http://arxiv.org/abs/2103.10834",
          "publishedOn": "2021-06-14T01:38:56.270Z",
          "wordCount": 670,
          "title": "Improved, Deterministic Smoothing for L_1 Certified Robustness. (arXiv:2103.10834v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14742",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Linzner_D/0/1/0/all/0/1\">Dominik Linzner</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Koeppl_H/0/1/0/all/0/1\">Heinz Koeppl</a>",
          "description": "We consider the problem of learning structures and parameters of\nContinuous-time Bayesian Networks (CTBNs) from time-course data under minimal\nexperimental resources. In practice, the cost of generating experimental data\nposes a bottleneck, especially in the natural and social sciences. A popular\napproach to overcome this is Bayesian optimal experimental design (BOED).\nHowever, BOED becomes infeasible in high-dimensional settings, as it involves\nintegration over all possible experimental outcomes. We propose a novel\ncriterion for experimental design based on a variational approximation of the\nexpected information gain. We show that for CTBNs, a semi-analytical expression\nfor this criterion can be calculated for structure and parameter learning. By\ndoing so, we can replace sampling over experimental outcomes by solving the\nCTBNs master-equation, for which scalable approximations exist. This alleviates\nthe computational burden of sampling possible experimental outcomes in\nhigh-dimensions. We employ this framework in order to recommend interventional\nsequences. In this context, we extend the CTBN model to conditional CTBNs in\norder to incorporate interventions. We demonstrate the performance of our\ncriterion on synthetic and real-world data.",
          "link": "http://arxiv.org/abs/2105.14742",
          "publishedOn": "2021-06-14T01:38:56.248Z",
          "wordCount": 619,
          "title": "Active Learning of Continuous-time Bayesian Networks through Interventions. (arXiv:2105.14742v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06519",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ganesan_K/0/1/0/all/0/1\">Karthik Ganesan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bamdev_P/0/1/0/all/0/1\">Pakhi Bamdev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+B_J/0/1/0/all/0/1\">Jaivarsan B</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venugopal_A/0/1/0/all/0/1\">Amresh Venugopal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tushar_A/0/1/0/all/0/1\">Abhinav Tushar</a>",
          "description": "Spoken Language Understanding (SLU) systems parse speech into semantic\nstructures like dialog acts and slots. This involves the use of an Automatic\nSpeech Recognizer (ASR) to transcribe speech into multiple text alternatives\n(hypotheses). Transcription errors, common in ASRs, impact downstream SLU\nperformance negatively. Approaches to mitigate such errors involve using richer\ninformation from the ASR, either in form of N-best hypotheses or word-lattices.\nWe hypothesize that transformer models learn better with a simpler utterance\nrepresentation using the concatenation of the N-best ASR alternatives, where\neach alternative is separated by a special delimiter [SEP]. In our work, we\ntest our hypothesis by using concatenated N-best ASR alternatives as the input\nto transformer encoder models, namely BERT and XLM-RoBERTa, and achieve\nperformance equivalent to the prior state-of-the-art model on DSTC2 dataset. We\nalso show that our approach significantly outperforms the prior\nstate-of-the-art when subjected to the low data regime. Additionally, this\nmethodology is accessible to users of third-party ASR APIs which do not provide\nword-lattice information.",
          "link": "http://arxiv.org/abs/2106.06519",
          "publishedOn": "2021-06-14T01:38:56.241Z",
          "wordCount": 623,
          "title": "N-Best ASR Transformer: Enhancing SLU Performance using Multiple ASR Hypotheses. (arXiv:2106.06519v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06526",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1\">Shiji Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Han Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shanghang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lianzhe Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_H/0/1/0/all/0/1\">Heng Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">Wenwu Zhu</a>",
          "description": "Models trained with offline data often suffer from continual distribution\nshifts and expensive labeling in changing environments. This calls for a new\nonline learning paradigm where the learner can continually adapt to changing\nenvironments with limited labels. In this paper, we propose a new online\nsetting -- Online Active Continual Adaptation, where the learner aims to\ncontinually adapt to changing distributions using both unlabeled samples and\nactive queries of limited labels. To this end, we propose Online Self-Adaptive\nMirror Descent (OSAMD), which adopts an online teacher-student structure to\nenable online self-training from unlabeled data, and a margin-based criterion\nthat decides whether to query the labels to track changing distributions.\nTheoretically, we show that, in the separable case, OSAMD has an $O({T}^{1/2})$\ndynamic regret bound under mild assumptions, which is even tighter than the\nlower bound $\\Omega(T^{2/3})$ of traditional online learning with full labels.\nIn the general case, we show a regret bound of $O({\\alpha^*}^{1/3} {T}^{2/3} +\n\\alpha^* T)$, where $\\alpha^*$ denotes the separability of domains and is\nusually small. Our theoretical results show that OSAMD can fast adapt to\nchanging environments with active queries. Empirically, we demonstrate that\nOSAMD achieves favorable regrets under changing environments with limited\nlabels on both simulated and real-world data, which corroborates our\ntheoretical findings.",
          "link": "http://arxiv.org/abs/2106.06526",
          "publishedOn": "2021-06-14T01:38:56.234Z",
          "wordCount": 644,
          "title": "Online Continual Adaptation with Active Self-Training. (arXiv:2106.06526v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.05596",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qi_Z/0/1/0/all/0/1\">Zhiyuan Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Ziheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiaoyan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_Y/0/1/0/all/0/1\">Yuejia Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yefeng Zheng</a>",
          "description": "Knowledge Graph (KG) alignment is to discover the mappings (i.e., equivalent\nentities, relations, and others) between two KGs. The existing methods can be\ndivided into the embedding-based models, and the conventional reasoning and\nlexical matching based systems. The former compute the similarity of entities\nvia their cross-KG embeddings, but they usually rely on an ideal supervised\nlearning setting for good performance and lack appropriate reasoning to avoid\nlogically wrong mappings; while the latter address the reasoning issue but are\npoor at utilizing the KG graph structures and the entity contexts. In this\nstudy, we aim at combining the above two solutions and thus propose an\niterative framework named PRASE which is based on probabilistic reasoning and\nsemantic embedding. It learns the KG embeddings via entity mappings from a\nprobabilistic reasoning system named PARIS, and feeds the resultant entity\nmappings and embeddings back into PARIS for augmentation. The PRASE framework\nis compatible with different embedding-based models, and our experiments on\nmultiple datasets have demonstrated its state-of-the-art performance.",
          "link": "http://arxiv.org/abs/2105.05596",
          "publishedOn": "2021-06-14T01:38:56.227Z",
          "wordCount": 653,
          "title": "Unsupervised Knowledge Graph Alignment by Probabilistic Reasoning and Semantic Embedding. (arXiv:2105.05596v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06115",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yoon_J/0/1/0/all/0/1\">Jinsung Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sohn_K/0/1/0/all/0/1\">Kihyuk Sohn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chun-Liang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arik_S/0/1/0/all/0/1\">Sercan O. Arik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1\">Chen-Yu Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfister_T/0/1/0/all/0/1\">Tomas Pfister</a>",
          "description": "Anomaly detection (AD), separating anomalies from normal data, has various\napplications across domains, from manufacturing to healthcare. While most\nprevious works have shown to be effective for cases with fully or partially\nlabeled data, they are less practical for AD applications due to tedious data\nlabeling processes. In this work, we focus on unsupervised AD problems whose\nentire training data are unlabeled and may contain both normal and anomalous\nsamples. To tackle this problem, we build a robust one-class classification\nframework via data refinement. To refine the data accurately, we propose an\nensemble of one-class classifiers, each of which is trained on a disjoint\nsubset of training data. Moreover, we propose a self-training of deep\nrepresentation one-class classifiers (STOC) that iteratively refines the data\nand deep representations. In experiments, we show the efficacy of our method\nfor unsupervised anomaly detection on benchmarks from image and tabular data\ndomains. For example, with a 10% anomaly ratio on CIFAR-10 data, the proposed\nmethod outperforms state-of-the-art one-class classification method by 6.3 AUC\nand 12.5 average precision.",
          "link": "http://arxiv.org/abs/2106.06115",
          "publishedOn": "2021-06-14T01:38:56.220Z",
          "wordCount": 599,
          "title": "Self-Trained One-class Classification for Unsupervised Anomaly Detection. (arXiv:2106.06115v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06171",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Phuc_L/0/1/0/all/0/1\">Luu Huu Phuc</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takeuchi_K/0/1/0/all/0/1\">Koh Takeuchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Okajima_S/0/1/0/all/0/1\">Seiji Okajima</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tolmachev_A/0/1/0/all/0/1\">Arseny Tolmachev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takebayashi_T/0/1/0/all/0/1\">Tomoyoshi Takebayashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maruhashi_K/0/1/0/all/0/1\">Koji Maruhashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kashima_H/0/1/0/all/0/1\">Hisashi Kashima</a>",
          "description": "Multi-relational graph is a ubiquitous and important data structure, allowing\nflexible representation of multiple types of interactions and relations between\nentities. Similar to other graph-structured data, link prediction is one of the\nmost important tasks on multi-relational graphs and is often used for knowledge\ncompletion. When related graphs coexist, it is of great benefit to build a\nlarger graph via integrating the smaller ones. The integration requires\npredicting hidden relational connections between entities belonged to different\ngraphs (inter-domain link prediction). However, this poses a real challenge to\nexisting methods that are exclusively designed for link prediction between\nentities of the same graph only (intra-domain link prediction). In this study,\nwe propose a new approach to tackle the inter-domain link prediction problem by\nsoftly aligning the entity distributions between different domains with optimal\ntransport and maximum mean discrepancy regularizers. Experiments on real-world\ndatasets show that optimal transport regularizer is beneficial and considerably\nimproves the performance of baseline methods.",
          "link": "http://arxiv.org/abs/2106.06171",
          "publishedOn": "2021-06-14T01:38:56.202Z",
          "wordCount": 587,
          "title": "Inter-domain Multi-relational Link Prediction. (arXiv:2106.06171v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06279",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kozuno_T/0/1/0/all/0/1\">Tadashi Kozuno</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Menard_P/0/1/0/all/0/1\">Pierre M&#xe9;nard</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Munos_R/0/1/0/all/0/1\">R&#xe9;mi Munos</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Valko_M/0/1/0/all/0/1\">Michal Valko</a>",
          "description": "We study the problem of learning a Nash equilibrium (NE) in an imperfect\ninformation game (IIG) through self-play. Precisely, we focus on two-player,\nzero-sum, episodic, tabular IIG under the perfect-recall assumption where the\nonly feedback is realizations of the game (bandit feedback). In particular, the\ndynamic of the IIG is not known -- we can only access it by sampling or\ninteracting with a game simulator. For this learning setting, we provide the\nImplicit Exploration Online Mirror Descent (IXOMD) algorithm. It is a\nmodel-free algorithm with a high-probability bound on the convergence rate to\nthe NE of order $1/\\sqrt{T}$ where $T$ is the number of played games. Moreover,\nIXOMD is computationally efficient as it needs to perform the updates only\nalong the sampled trajectory.",
          "link": "http://arxiv.org/abs/2106.06279",
          "publishedOn": "2021-06-14T01:38:56.196Z",
          "wordCount": 563,
          "title": "Model-Free Learning for Two-Player Zero-Sum Partially Observable Markov Games with Perfect Recall. (arXiv:2106.06279v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.02078",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sridhar_K/0/1/0/all/0/1\">Kaustubh Sridhar</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sokolsky_O/0/1/0/all/0/1\">Oleg Sokolsky</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lee_I/0/1/0/all/0/1\">Insup Lee</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Weimer_J/0/1/0/all/0/1\">James Weimer</a>",
          "description": "Improving adversarial robustness of neural networks remains a major\nchallenge. Fundamentally, training a network is a parameter estimation problem.\nIn adaptive control theory, maintaining persistency of excitation (PoE) is\nintegral to ensuring convergence of parameter estimates in dynamical systems to\ntheir robust optima. In this work, we show that network training using gradient\ndescent is equivalent to a dynamical system parameter estimation problem.\nLeveraging this relationship, we prove a sufficient condition for PoE of\ngradient descent is achieved when the learning rate is less than the inverse of\nthe Lipschitz constant of the gradient of loss function. We provide an\nefficient technique for estimating the corresponding Lipschitz constant using\nextreme value theory and demonstrate that by only scaling the learning rate\nschedule we can increase adversarial accuracy by up to 15% points on benchmark\ndatasets. Our approach also universally increases the adversarial accuracy by\n0.1% to 0.3% points in various state-of-the-art adversarially trained models on\nthe AutoAttack benchmark, where every small margin of improvement is\nsignificant.",
          "link": "http://arxiv.org/abs/2106.02078",
          "publishedOn": "2021-06-14T01:38:56.189Z",
          "wordCount": 630,
          "title": "Robust Learning via Persistency of Excitation. (arXiv:2106.02078v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.00651",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zavatone_Veth_J/0/1/0/all/0/1\">Jacob A. Zavatone-Veth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Canatar_A/0/1/0/all/0/1\">Abdulkadir Canatar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pehlevan_C/0/1/0/all/0/1\">Cengiz Pehlevan</a>",
          "description": "Recent works have suggested that finite Bayesian neural networks may\noutperform their infinite cousins because finite networks can flexibly adapt\ntheir internal representations. However, our theoretical understanding of how\nthe learned hidden layer representations of finite networks differ from the\nfixed representations of infinite networks remains incomplete. Perturbative\nfinite-width corrections to the network prior and posterior have been studied,\nbut the asymptotics of learned features have not been fully characterized.\nHere, we argue that the leading finite-width corrections to the average feature\nkernels for any Bayesian network with linear readout and quadratic cost have a\nlargely universal form. We illustrate this explicitly for two classes of fully\nconnected networks: deep linear networks and networks with a single nonlinear\nhidden layer. Our results begin to elucidate which features of data wide\nBayesian neural networks learn to represent.",
          "link": "http://arxiv.org/abs/2106.00651",
          "publishedOn": "2021-06-14T01:38:56.183Z",
          "wordCount": 603,
          "title": "Asymptotics of representation learning in finite Bayesian neural networks. (arXiv:2106.00651v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02522",
          "author": "<a href=\"http://arxiv.org/find/q-fin/1/au:+Wu_J/0/1/0/all/0/1\">Junran Wu</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Xu_K/0/1/0/all/0/1\">Ke Xu</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Chen_X/0/1/0/all/0/1\">Xueyuan Chen</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Li_S/0/1/0/all/0/1\">Shangzhe Li</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Zhao_J/0/1/0/all/0/1\">Jichang Zhao</a>",
          "description": "Stock prediction, with the purpose of forecasting the future price trends of\nstocks, is crucial for maximizing profits from stock investments. While great\nresearch efforts have been devoted to exploiting deep neural networks for\nimproved stock prediction, two major issues still exist in recent studies.\nFirst, the capture of long-range dependencies in time series is not\nsufficiently addressed. Second, the chaotic property of financial time series\nfundamentally lowers prediction performance. In this study, we propose a novel\nframework to address both issues regarding stock prediction. Specifically, in\nterms of transforming time series into complex networks, we convert market\nprice series into graphs. Then, structural information, referring to\nassociations among temporal points and the node weights, is extracted from the\nmapped graphs to resolve the problems regarding long-range dependencies and the\nchaotic property. We take graph embeddings to represent the associations among\ntemporal points as the prediction model inputs. Node weights are used as a\npriori knowledge to enhance the learning of temporal attention. The\neffectiveness of our proposed framework is validated using real-world stock\ndata, and our approach obtains the best performance among several\nstate-of-the-art benchmarks. Moreover, in the conducted trading simulations,\nour framework further obtains the highest cumulative profits. Our results\nsupplement the existing applications of complex network methods in the\nfinancial realm and provide insightful implications for investment applications\nregarding decision support in financial markets.",
          "link": "http://arxiv.org/abs/2106.02522",
          "publishedOn": "2021-06-14T01:38:56.176Z",
          "wordCount": 690,
          "title": "Price graphs: Utilizing the structural information of financial time series for stock prediction. (arXiv:2106.02522v2 [q-fin.ST] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10446",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chan_K/0/1/0/all/0/1\">Kwan Ho Ryan Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yaodong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1\">Chong You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_H/0/1/0/all/0/1\">Haozhi Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wright_J/0/1/0/all/0/1\">John Wright</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yi Ma</a>",
          "description": "This work attempts to provide a plausible theoretical framework that aims to\ninterpret modern deep (convolutional) networks from the principles of data\ncompression and discriminative representation. We argue that for\nhigh-dimensional multi-class data, the optimal linear discriminative\nrepresentation maximizes the coding rate difference between the whole dataset\nand the average of all the subsets. We show that the basic iterative gradient\nascent scheme for optimizing the rate reduction objective naturally leads to a\nmulti-layer deep network, named ReduNet, which shares common characteristics of\nmodern deep networks. The deep layered architectures, linear and nonlinear\noperators, and even parameters of the network are all explicitly constructed\nlayer-by-layer via forward propagation, although they are amenable to\nfine-tuning via back propagation. All components of so-obtained ``white-box''\nnetwork have precise optimization, statistical, and geometric interpretation.\nMoreover, all linear operators of the so-derived network naturally become\nmulti-channel convolutions when we enforce classification to be rigorously\nshift-invariant. The derivation in the invariant setting suggests a trade-off\nbetween sparsity and invariance, and also indicates that such a deep\nconvolution network is significantly more efficient to construct and learn in\nthe spectral domain. Our preliminary simulations and experiments clearly verify\nthe effectiveness of both the rate reduction objective and the associated\nReduNet. All code and data are available at https://github.com/Ma-Lab-Berkeley.",
          "link": "http://arxiv.org/abs/2105.10446",
          "publishedOn": "2021-06-14T01:38:56.157Z",
          "wordCount": 723,
          "title": "ReduNet: A White-box Deep Network from the Principle of Maximizing Rate Reduction. (arXiv:2105.10446v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06418",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jansson_Y/0/1/0/all/0/1\">Ylva Jansson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lindeberg_T/0/1/0/all/0/1\">Tony Lindeberg</a>",
          "description": "The ability to handle large scale variations is crucial for many real world\nvisual tasks. A straightforward approach for handling scale in a deep network\nis to process an image at several scales simultaneously in a set of scale\nchannels. Scale invariance can then, in principle, be achieved by using weight\nsharing between the scale channels together with max or average pooling over\nthe outputs from the scale channels. The ability of such scale channel networks\nto generalise to scales not present in the training set over significant scale\nranges has, however, not previously been explored.\n\nIn this paper, we present a systematic study of this methodology by\nimplementing different types of scale channel networks and evaluating their\nability to generalise to previously unseen scales. We develop a formalism for\nanalysing the covariance and invariance properties of scale channel networks,\nand explore how different design choices, unique to scaling transformations,\naffect the overall performance of scale channel networks. We first show that\ntwo previously proposed scale channel network designs do not generalise well to\nscales not present in the training set. We explain theoretically and\ndemonstrate experimentally why generalisation fails in these cases.\n\nWe then propose a new type of foveated scale channel architecture}, where the\nscale channels process increasingly larger parts of the image with decreasing\nresolution. This new type of scale channel network is shown to generalise\nextremely well, provided sufficient image resolution and the absence of\nboundary effects. Our proposed FovMax and FovAvg networks perform almost\nidentically over a scale range of 8, also when training on single scale\ntraining data, and do also give improved performance when learning from\ndatasets with large scale variations in the small sample regime.",
          "link": "http://arxiv.org/abs/2106.06418",
          "publishedOn": "2021-06-14T01:38:56.150Z",
          "wordCount": 734,
          "title": "Scale-invariant scale-channel networks: Deep networks that generalise to previously unseen scales. (arXiv:2106.06418v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06291",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Talpur_A/0/1/0/all/0/1\">Anum Talpur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurusamy_M/0/1/0/all/0/1\">Mohan Gurusamy</a>",
          "description": "The growth of 5G and edge computing has enabled the emergence of Internet of\nVehicles. It supports different types of services with different resource and\nservice requirements. However, limited resources at the edge, high mobility of\nvehicles, increasing demand, and dynamicity in service request-types have made\nservice placement a challenging task. A typical static placement solution is\nnot effective as it does not consider the traffic mobility and service\ndynamics. Handling dynamics in IoV for service placement is an important and\nchallenging problem which is the primary focus of our work in this paper. We\npropose a Deep Reinforcement Learning-based Dynamic Service Placement (DRLD-SP)\nframework with the objective of minimizing the maximum edge resource usage and\nservice delay while considering the vehicle's mobility, varying demand, and\ndynamics in the requests for different types of services. We use SUMO and\nMATLAB to carry out simulation experiments. The experimental results show that\nthe proposed DRLD-SP approach is effective and outperforms other static and\ndynamic placement approaches.",
          "link": "http://arxiv.org/abs/2106.06291",
          "publishedOn": "2021-06-14T01:38:56.142Z",
          "wordCount": 610,
          "title": "DRLD-SP: A Deep Reinforcement Learning-based Dynamic Service Placement in Edge-Enabled Internet of Vehicles. (arXiv:2106.06291v1 [cs.NI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06295",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Irie_K/0/1/0/all/0/1\">Kazuki Irie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schlag_I/0/1/0/all/0/1\">Imanol Schlag</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Csordas_R/0/1/0/all/0/1\">R&#xf3;bert Csord&#xe1;s</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidhuber_J/0/1/0/all/0/1\">J&#xfc;rgen Schmidhuber</a>",
          "description": "Transformers with linearised attention (\"linear Transformers\") have\ndemonstrated the practical scalability and effectiveness of outer product-based\nFast Weight Programmers (FWPs) from the '90s. However, the original FWP\nformulation is more general than the one of linear Transformers: a slow neural\nnetwork (NN) continually reprograms the weights of a fast NN with arbitrary NN\narchitectures. In existing linear Transformers, both NNs are feedforward and\nconsist of a single layer. Here we explore new variations by adding recurrence\nto the slow and fast nets. We evaluate our novel recurrent FWPs (RFWPs) on two\nsynthetic algorithmic tasks (code execution and sequential ListOps),\nWikitext-103 language models, and on the Atari 2600 2D game environment. Our\nmodels exhibit properties of Transformers and RNNs. In the reinforcement\nlearning setting, we report large improvements over LSTM in several Atari\ngames. Our code is public.",
          "link": "http://arxiv.org/abs/2106.06295",
          "publishedOn": "2021-06-14T01:38:56.135Z",
          "wordCount": 562,
          "title": "Going Beyond Linear Transformers with Recurrent Fast Weight Programmers. (arXiv:2106.06295v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06426",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Greshler_G/0/1/0/all/0/1\">Gal Greshler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shaham_T/0/1/0/all/0/1\">Tamar Rott Shaham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Michaeli_T/0/1/0/all/0/1\">Tomer Michaeli</a>",
          "description": "Models for audio generation are typically trained on hours of recordings.\nHere, we illustrate that capturing the essence of an audio source is typically\npossible from as little as a few tens of seconds from a single training signal.\nSpecifically, we present a GAN-based generative model that can be trained on\none short audio signal from any domain (e.g. speech, music, etc.) and does not\nrequire pre-training or any other form of external supervision. Once trained,\nour model can generate random samples of arbitrary duration that maintain\nsemantic similarity to the training waveform, yet exhibit new compositions of\nits audio primitives. This enables a long line of interesting applications,\nincluding generating new jazz improvisations or new a-cappella rap variants\nbased on a single short example, producing coherent modifications to famous\nsongs (e.g. adding a new verse to a Beatles song based solely on the original\nrecording), filling-in of missing parts (inpainting), extending the bandwidth\nof a speech signal (super-resolution), and enhancing old recordings without\naccess to any clean training example. We show that in all cases, no more than\n20 seconds of training audio commonly suffice for our model to achieve\nstate-of-the-art results. This is despite its complete lack of prior knowledge\nabout the nature of audio signals in general.",
          "link": "http://arxiv.org/abs/2106.06426",
          "publishedOn": "2021-06-14T01:38:56.127Z",
          "wordCount": 647,
          "title": "Catch-A-Waveform: Learning to Generate Audio from a Single Short Example. (arXiv:2106.06426v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06196",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yonggang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_M/0/1/0/all/0/1\">Mingming Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tongliang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1\">Gang Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_X/0/1/0/all/0/1\">Xinmei Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1\">Bo Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1\">Bernhard Sch&#xf6;lkopf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kun Zhang</a>",
          "description": "The adversarial vulnerability of deep neural networks has attracted\nsignificant attention in machine learning. From a causal viewpoint, adversarial\nattacks can be considered as a specific type of distribution change on natural\ndata. As causal reasoning has an instinct for modeling distribution change, we\npropose to incorporate causality into mitigating adversarial vulnerability.\nHowever, causal formulations of the intuition of adversarial attack and the\ndevelopment of robust DNNs are still lacking in the literature. To bridge this\ngap, we construct a causal graph to model the generation process of adversarial\nexamples and define the adversarial distribution to formalize the intuition of\nadversarial attacks. From a causal perspective, we find that the label is\nspuriously correlated with the style (content-independent) information when an\ninstance is given. The spurious correlation implies that the adversarial\ndistribution is constructed via making the statistical conditional association\nbetween style information and labels drastically different from that in natural\ndistribution. Thus, DNNs that fit the spurious correlation are vulnerable to\nthe adversarial distribution. Inspired by the observation, we propose the\nadversarial distribution alignment method to eliminate the difference between\nthe natural distribution and the adversarial distribution. Extensive\nexperiments demonstrate the efficacy of the proposed method. Our method can be\nseen as the first attempt to leverage causality for mitigating adversarial\nvulnerability.",
          "link": "http://arxiv.org/abs/2106.06196",
          "publishedOn": "2021-06-14T01:38:56.111Z",
          "wordCount": 643,
          "title": "Adversarial Robustness through the Lens of Causality. (arXiv:2106.06196v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2006.16495",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wang_X/0/1/0/all/0/1\">Xiang Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yuan_S/0/1/0/all/0/1\">Shuai Yuan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wu_C/0/1/0/all/0/1\">Chenwei Wu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ge_R/0/1/0/all/0/1\">Rong Ge</a>",
          "description": "Choosing the right parameters for optimization algorithms is often the key to\ntheir success in practice. Solving this problem using a learning-to-learn\napproach -- using meta-gradient descent on a meta-objective based on the\ntrajectory that the optimizer generates -- was recently shown to be effective.\nHowever, the meta-optimization problem is difficult. In particular, the\nmeta-gradient can often explode/vanish, and the learned optimizer may not have\ngood generalization performance if the meta-objective is not chosen carefully.\nIn this paper we give meta-optimization guarantees for the learning-to-learn\napproach on a simple problem of tuning the step size for quadratic loss. Our\nresults show that the na\\\"ive objective suffers from meta-gradient\nexplosion/vanishing problem. Although there is a way to design the\nmeta-objective so that the meta-gradient remains polynomially bounded,\ncomputing the meta-gradient directly using backpropagation leads to numerical\nissues. We also characterize when it is necessary to compute the meta-objective\non a separate validation set to ensure the generalization performance of the\nlearned optimizer. Finally, we verify our results empirically and show that a\nsimilar phenomenon appears even for more complicated learned optimizers\nparametrized by neural networks.",
          "link": "http://arxiv.org/abs/2006.16495",
          "publishedOn": "2021-06-14T01:38:56.104Z",
          "wordCount": 640,
          "title": "Guarantees for Tuning the Step Size using a Learning-to-Learn Approach. (arXiv:2006.16495v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.03788",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Guan-Horng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tianrong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Theodorou_E/0/1/0/all/0/1\">Evangelos A. Theodorou</a>",
          "description": "The connection between training deep neural networks (DNNs) and optimal\ncontrol theory (OCT) has attracted considerable attention as a principled tool\nof algorithmic design. Despite few attempts being made, they have been limited\nto architectures where the layer propagation resembles a Markovian dynamical\nsystem. This casts doubts on their flexibility to modern networks that heavily\nrely on non-Markovian dependencies between layers (e.g. skip connections in\nresidual networks). In this work, we propose a novel dynamic game perspective\nby viewing each layer as a player in a dynamic game characterized by the DNN\nitself. Through this lens, different classes of optimizers can be seen as\nmatching different types of Nash equilibria, depending on the implicit\ninformation structure of each (p)layer. The resulting method, called Dynamic\nGame Theoretic Neural Optimizer (DGNOpt), not only generalizes OCT-inspired\noptimizers to richer network class; it also motivates a new training principle\nby solving a multi-player cooperative game. DGNOpt shows convergence\nimprovements over existing methods on image classification datasets with\nresidual and inception networks. Our work marries strengths from both OCT and\ngame theory, paving ways to new algorithmic opportunities from robust optimal\ncontrol and bandit-based optimization.",
          "link": "http://arxiv.org/abs/2105.03788",
          "publishedOn": "2021-06-14T01:38:56.097Z",
          "wordCount": 660,
          "title": "Dynamic Game Theoretic Neural Optimizer. (arXiv:2105.03788v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06243",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kandanaarachchi_S/0/1/0/all/0/1\">Sevvandi Kandanaarachchi</a>",
          "description": "Constructing an ensemble from a heterogeneous set of unsupervised anomaly\ndetection methods is challenging because the class labels or the ground truth\nis unknown. Thus, traditional ensemble techniques that use the response\nvariable or the class labels cannot be used to construct an ensemble for\nunsupervised anomaly detection.\n\nWe use Item Response Theory (IRT) -- a class of models used in educational\npsychometrics to assess student and test question characteristics -- to\nconstruct an unsupervised anomaly detection ensemble. IRT's latent trait\ncomputation lends itself to anomaly detection because the latent trait can be\nused to uncover the hidden ground truth. Using a novel IRT mapping to the\nanomaly detection problem, we construct an ensemble that can downplay noisy,\nnon-discriminatory methods and accentuate sharper methods. We demonstrate the\neffectiveness of the IRT ensemble on an extensive data repository, by comparing\nits performance to other ensemble techniques.",
          "link": "http://arxiv.org/abs/2106.06243",
          "publishedOn": "2021-06-14T01:38:56.090Z",
          "wordCount": 573,
          "title": "Unsupervised Anomaly Detection Ensembles using Item Response Theory. (arXiv:2106.06243v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06152",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lv_J/0/1/0/all/0/1\">Jiaqi Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_L/0/1/0/all/0/1\">Lei Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1\">Miao Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+An_B/0/1/0/all/0/1\">Bo An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1\">Gang Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_X/0/1/0/all/0/1\">Xin Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masashi Sugiyama</a>",
          "description": "Partial-label (PL) learning is a typical weakly supervised classification\nproblem, where a PL of an instance is a set of candidate labels such that a\nfixed but unknown candidate is the true label. For PL learning, there are two\nlines of research: (a) the identification-based strategy (IBS) purifies each\nlabel set and extracts the true label; (b) the average-based strategy (ABS)\ntreats all candidates equally for training. In the past two decades, IBS was a\nmuch hotter topic than ABS, since it was believed that IBS is more promising.\nIn this paper, we theoretically analyze ABS and find it also promising in the\nsense of the robustness of its loss functions. Specifically, we consider five\nproblem settings for the generation of clean or noisy PLs, and we prove that\naverage PL losses with bounded multi-class losses are always robust under mild\nassumptions on the domination of true labels, while average PL losses with\nunbounded multi-class losses (e.g., the cross-entropy loss) may not be robust.\nWe also conduct experiments to validate our theoretical findings. Note that IBS\nis heuristic, and we cannot prove its robustness by a similar proof technique;\nhence, ABS is more advantageous from a theoretical point of view, and it is\nworth paying attention to the design of more advanced PL learning methods\nfollowing ABS.",
          "link": "http://arxiv.org/abs/2106.06152",
          "publishedOn": "2021-06-14T01:38:56.083Z",
          "wordCount": 649,
          "title": "On the Robustness of Average Losses for Partial-Label Learning. (arXiv:2106.06152v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03743",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Labatie_A/0/1/0/all/0/1\">Antoine Labatie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Masters_D/0/1/0/all/0/1\">Dominic Masters</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eaton_Rosen_Z/0/1/0/all/0/1\">Zach Eaton-Rosen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luschi_C/0/1/0/all/0/1\">Carlo Luschi</a>",
          "description": "We investigate the reasons for the performance degradation incurred with\nbatch-independent normalization. We find that the prototypical techniques of\nlayer normalization and instance normalization both induce the appearance of\nfailure modes in the neural network's pre-activations: (i) layer normalization\ninduces a collapse towards channel-wise constant functions; (ii) instance\nnormalization induces a lack of variability in instance statistics, symptomatic\nof an alteration of the expressivity. To alleviate failure mode (i) without\naggravating failure mode (ii), we introduce the technique \"Proxy Normalization\"\nthat normalizes post-activations using a proxy distribution. When combined with\nlayer normalization or group normalization, this batch-independent\nnormalization emulates batch normalization's behavior and consistently matches\nor exceeds its performance.",
          "link": "http://arxiv.org/abs/2106.03743",
          "publishedOn": "2021-06-14T01:38:56.048Z",
          "wordCount": 553,
          "title": "Proxy-Normalizing Activations to Match Batch Normalization while Removing Batch Dependence. (arXiv:2106.03743v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.13840",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chu_X/0/1/0/all/0/1\">Xiangxiang Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Z/0/1/0/all/0/1\">Zhi Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuqing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Bo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_H/0/1/0/all/0/1\">Haibing Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1\">Xiaolin Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_H/0/1/0/all/0/1\">Huaxia Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1\">Chunhua Shen</a>",
          "description": "Very recently, a variety of vision transformer architectures for dense\nprediction tasks have been proposed and they show that the design of spatial\nattention is critical to their success in these tasks. In this work, we revisit\nthe design of the spatial attention and demonstrate that a carefully-devised\nyet simple spatial attention mechanism performs favourably against the\nstate-of-the-art schemes. As a result, we propose two vision transformer\narchitectures, namely, Twins-PCPVT and Twins-SVT. Our proposed architectures\nare highly-efficient and easy to implement, only involving matrix\nmultiplications that are highly optimized in modern deep learning frameworks.\nMore importantly, the proposed architectures achieve excellent performance on a\nwide range of visual tasks including imagelevel classification as well as dense\ndetection and segmentation. The simplicity and strong performance suggest that\nour proposed architectures may serve as stronger backbones for many vision\ntasks. Our code will be released soon at\nhttps://github.com/Meituan-AutoML/Twins .",
          "link": "http://arxiv.org/abs/2104.13840",
          "publishedOn": "2021-06-14T01:38:55.853Z",
          "wordCount": 656,
          "title": "Twins: Revisiting the Design of Spatial Attention in Vision Transformers. (arXiv:2104.13840v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.13416",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Terjek_D/0/1/0/all/0/1\">D&#xe1;vid Terj&#xe9;k</a>",
          "description": "Variational representations of $f$-divergences are central to many machine\nlearning algorithms, with Lipschitz constrained variants recently gaining\nattention. Inspired by this, we define the Moreau-Yosida approximation of\n$f$-divergences with respect to the Wasserstein-$1$ metric. The corresponding\nvariational formulas provide a generalization of a number of recent results,\nnovel special cases of interest and a relaxation of the hard Lipschitz\nconstraint. Additionally, we prove that the so-called tight variational\nrepresentation of $f$-divergences can be to be taken over the quotient space of\nLipschitz functions, and give a characterization of functions achieving the\nsupremum in the variational representation. On the practical side, we propose\nan algorithm to calculate the tight convex conjugate of $f$-divergences\ncompatible with automatic differentiation frameworks. As an application of our\nresults, we propose the Moreau-Yosida $f$-GAN, providing an implementation of\nthe variational formulas for the Kullback-Leibler, reverse Kullback-Leibler,\n$\\chi^2$, reverse $\\chi^2$, squared Hellinger, Jensen-Shannon, Jeffreys,\ntriangular discrimination and total variation divergences as GANs trained on\nCIFAR-10, leading to competitive results and a simple solution to the problem\nof uniqueness of the optimal critic.",
          "link": "http://arxiv.org/abs/2102.13416",
          "publishedOn": "2021-06-14T01:38:55.846Z",
          "wordCount": 645,
          "title": "Moreau-Yosida $f$-divergences. (arXiv:2102.13416v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09163",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_H/0/1/0/all/0/1\">Hongxiang Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferianc_M/0/1/0/all/0/1\">Martin Ferianc</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodrigues_M/0/1/0/all/0/1\">Miguel Rodrigues</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Hongyu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_X/0/1/0/all/0/1\">Xinyu Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luk_W/0/1/0/all/0/1\">Wayne Luk</a>",
          "description": "Neural networks (NNs) have demonstrated their potential in a wide range of\napplications such as image recognition, decision making or recommendation\nsystems. However, standard NNs are unable to capture their model uncertainty\nwhich is crucial for many safety-critical applications including healthcare and\nautonomous vehicles. In comparison, Bayesian neural networks (BNNs) are able to\nexpress uncertainty in their prediction via a mathematical grounding.\nNevertheless, BNNs have not been as widely used in industrial practice, mainly\nbecause of their expensive computational cost and limited hardware performance.\nThis work proposes a novel FPGA-based hardware architecture to accelerate BNNs\ninferred through Monte Carlo Dropout. Compared with other state-of-the-art BNN\naccelerators, the proposed accelerator can achieve up to 4 times higher energy\nefficiency and 9 times better compute efficiency. Considering partial Bayesian\ninference, an automatic framework is proposed, which explores the trade-off\nbetween hardware and algorithmic performance. Extensive experiments are\nconducted to demonstrate that our proposed framework can effectively find the\noptimal points in the design space.",
          "link": "http://arxiv.org/abs/2105.09163",
          "publishedOn": "2021-06-14T01:38:55.837Z",
          "wordCount": 633,
          "title": "High-Performance FPGA-based Accelerator for Bayesian Neural Networks. (arXiv:2105.09163v2 [cs.AR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.03864",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maziarz_K/0/1/0/all/0/1\">Krzysztof Maziarz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jackson_Flux_H/0/1/0/all/0/1\">Henry Jackson-Flux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cameron_P/0/1/0/all/0/1\">Pashmina Cameron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sirockin_F/0/1/0/all/0/1\">Finton Sirockin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schneider_N/0/1/0/all/0/1\">Nadine Schneider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stiefl_N/0/1/0/all/0/1\">Nikolaus Stiefl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Segler_M/0/1/0/all/0/1\">Marwin Segler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brockschmidt_M/0/1/0/all/0/1\">Marc Brockschmidt</a>",
          "description": "Recent advancements in deep learning-based modeling of molecules promise to\naccelerate in silico drug discovery. A plethora of generative models is\navailable, building molecules either atom-by-atom and bond-by-bond or\nfragment-by-fragment. However, many drug discovery projects require a fixed\nscaffold to be present in the generated molecule, and incorporating that\nconstraint has only recently been explored. In this work, we propose a new\ngraph-based model that naturally supports scaffolds as initial seed of the\ngenerative procedure, which is possible because our model is not conditioned on\nthe generation history. At the same time, our generation procedure can flexibly\nchoose between adding individual atoms and entire fragments. We show that\ntraining using a randomized generation order is necessary for good performance\nwhen extending scaffolds, and that the results are further improved by\nincreasing the fragment vocabulary size. Our model pushes the state-of-the-art\nof graph-based molecule generation, while being an order of magnitude faster to\ntrain and sample from than existing approaches.",
          "link": "http://arxiv.org/abs/2103.03864",
          "publishedOn": "2021-06-14T01:38:55.830Z",
          "wordCount": 623,
          "title": "Learning to Extend Molecular Scaffolds with Structural Motifs. (arXiv:2103.03864v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.02153",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rozemberczki_B/0/1/0/all/0/1\">Benedek Rozemberczki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarkar_R/0/1/0/all/0/1\">Rik Sarkar</a>",
          "description": "What is the value of an individual model in an ensemble of binary\nclassifiers? We answer this question by introducing a class of transferable\nutility cooperative games called \\textit{ensemble games}. In machine learning\nensembles, pre-trained models cooperate to make classification decisions. To\nquantify the importance of models in these ensemble games, we define\n\\textit{Troupe} -- an efficient algorithm which allocates payoffs based on\napproximate Shapley values of the classifiers. We argue that the Shapley value\nof models in these games is an effective decision metric for choosing a high\nperforming subset of models from the ensemble. Our analytical findings prove\nthat our Shapley value estimation scheme is precise and scalable; its\nperformance increases with size of the dataset and ensemble. Empirical results\non real world graph classification tasks demonstrate that our algorithm\nproduces high quality estimates of the Shapley value. We find that Shapley\nvalues can be utilized for ensemble pruning, and that adversarial models\nreceive a low valuation. Complex classifiers are frequently found to be\nresponsible for both correct and incorrect classification decisions.",
          "link": "http://arxiv.org/abs/2101.02153",
          "publishedOn": "2021-06-14T01:38:55.810Z",
          "wordCount": 652,
          "title": "The Shapley Value of Classifiers in Ensemble Games. (arXiv:2101.02153v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06064",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Pal_S/0/1/0/all/0/1\">Soumyasundar Pal</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ma_L/0/1/0/all/0/1\">Liheng Ma</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_Y/0/1/0/all/0/1\">Yingxue Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Coates_M/0/1/0/all/0/1\">Mark Coates</a>",
          "description": "Spatio-temporal forecasting has numerous applications in analyzing wireless,\ntraffic, and financial networks. Many classical statistical models often fall\nshort in handling the complexity and high non-linearity present in time-series\ndata. Recent advances in deep learning allow for better modelling of spatial\nand temporal dependencies. While most of these models focus on obtaining\naccurate point forecasts, they do not characterize the prediction uncertainty.\nIn this work, we consider the time-series data as a random realization from a\nnonlinear state-space model and target Bayesian inference of the hidden states\nfor probabilistic forecasting. We use particle flow as the tool for\napproximating the posterior distribution of the states, as it is shown to be\nhighly effective in complex, high-dimensional settings. Thorough\nexperimentation on several real world time-series datasets demonstrates that\nour approach provides better characterization of uncertainty while maintaining\ncomparable accuracy to the state-of-the art point forecasting methods.",
          "link": "http://arxiv.org/abs/2106.06064",
          "publishedOn": "2021-06-14T01:38:55.803Z",
          "wordCount": 575,
          "title": "RNN with Particle Flow for Probabilistic Spatio-temporal Forecasting. (arXiv:2106.06064v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2102.00678",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_N/0/1/0/all/0/1\">Nan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_S/0/1/0/all/0/1\">Shida Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1\">Gang Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sato_I/0/1/0/all/0/1\">Issei Sato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masashi Sugiyama</a>",
          "description": "To cope with high annotation costs, training a classifier only from weakly\nsupervised data has attracted a great deal of attention these days. Among\nvarious approaches, strengthening supervision from completely unsupervised\nclassification is a promising direction, which typically employs class priors\nas the only supervision and trains a binary classifier from unlabeled (U)\ndatasets. While existing risk-consistent methods are theoretically grounded\nwith high flexibility, they can learn only from two U sets. In this paper, we\npropose a new approach for binary classification from $m$ U-sets for $m\\ge2$.\nOur key idea is to consider an auxiliary classification task called surrogate\nset classification (SSC), which is aimed at predicting from which U set each\nobserved data is drawn. SSC can be solved by a standard (multi-class)\nclassification method, and we use the SSC solution to obtain the final binary\nclassifier through a certain linear-fractional transformation. We built our\nmethod in a flexible and efficient end-to-end deep learning framework and prove\nit to be classifier-consistent. Through experiments, we demonstrate the\nsuperiority of our proposed method over state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2102.00678",
          "publishedOn": "2021-06-14T01:38:55.796Z",
          "wordCount": 644,
          "title": "Binary Classification from Multiple Unlabeled Datasets via Surrogate Set Classification. (arXiv:2102.00678v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.03923",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Leung_R/0/1/0/all/0/1\">Raymond Leung</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Balamurali_M/0/1/0/all/0/1\">Mehala Balamurali</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Lowe_A/0/1/0/all/0/1\">Alexander Lowe</a>",
          "description": "This paper illustrates an application of machine learning (ML) within a\ncomplex system that performs grade estimation. In surface mining, assay\nmeasurements taken from production drilling often provide useful information\nthat allows initially inaccurate surfaces created using sparse exploration data\nto be revised and subsequently improved. Recently, a Bayesian warping technique\nhas been proposed to reshape modeled surfaces using geochemical and spatial\nconstraints imposed by newly acquired blasthole data. This paper focuses on\nincorporating machine learning into this warping framework to make the\nlikelihood computation generalizable. The technique works by adjusting the\nposition of vertices on the surface to maximize the integrity of modeled\ngeological boundaries with respect to sparse geochemical observations. Its\nfoundation is laid by a Bayesian derivation in which the geological domain\nlikelihood given the chemistry, p(g|c), plays a similar role to p(y(c)|g). This\nobservation allows a manually calibrated process centered around the latter to\nbe automated since ML techniques may be used to estimate the former in a\ndata-driven way. Machine learning performance is evaluated for gradient\nboosting, neural network, random forest and other classifiers in a binary and\nmulti-class context using precision and recall rates. Once ML likelihood\nestimators are integrated in the surface warping framework, surface shaping\nperformance is evaluated using unseen data by examining the categorical\ndistribution of test samples located above and below the warped surface.\nLarge-scale validation experiments are performed to assess the overall efficacy\nof ML assisted surface warping as a fully integrated component within an ore\ngrade estimation system where the posterior mean is obtained via Gaussian\nProcess inference with a Matern 3/2 kernel.",
          "link": "http://arxiv.org/abs/2103.03923",
          "publishedOn": "2021-06-14T01:38:55.790Z",
          "wordCount": 764,
          "title": "Surface Warping Incorporating Machine Learning Assisted Domain Likelihood Estimation: A New Paradigm in Mine Geology Modelling and Automation. (arXiv:2103.03923v2 [physics.geo-ph] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.11351",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ng_Y/0/1/0/all/0/1\">Yuting Ng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasan_A/0/1/0/all/0/1\">Ali Hasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elkhalil_K/0/1/0/all/0/1\">Khalil Elkhalil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tarokh_V/0/1/0/all/0/1\">Vahid Tarokh</a>",
          "description": "We propose a new generative modeling technique for learning multidimensional\ncumulative distribution functions (CDFs) in the form of copulas. Specifically,\nwe consider certain classes of copulas known as Archimedean and hierarchical\nArchimedean copulas, popular for their parsimonious representation and ability\nto model different tail dependencies. We consider their representation as\nmixture models with Laplace transforms of latent random variables from\ngenerative neural networks. This alternative representation allows for\ncomputational efficiencies and easy sampling, especially in high dimensions. We\ndescribe multiple methods for optimizing the network parameters. Finally, we\npresent empirical results that demonstrate the efficacy of our proposed method\nin learning multidimensional CDFs and its computational efficiency compared to\nexisting methods.",
          "link": "http://arxiv.org/abs/2102.11351",
          "publishedOn": "2021-06-14T01:38:55.782Z",
          "wordCount": 564,
          "title": "Generative Archimedean Copulas. (arXiv:2102.11351v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.02966",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Stelzer_F/0/1/0/all/0/1\">Florian Stelzer</a> (1, 2 and 3), <a href=\"http://arxiv.org/find/cs/1/au:+Yanchuk_S/0/1/0/all/0/1\">Serhiy Yanchuk</a> (1) ((1) Institute of Mathematics, Technische Universit&#xe4;t Berlin, Germany, (2) Department of Mathematics, Humboldt-Universit&#xe4;t zu Berlin, Germany, (3) Institute of Computer Science, University of Tartu, Estonia)",
          "description": "The method recently introduced in arXiv:2011.10115 realizes a deep neural\nnetwork with just a single nonlinear element and delayed feedback. It is\napplicable for the description of physically implemented neural networks. In\nthis work, we present an infinite-dimensional generalization, which allows for\na more rigorous mathematical analysis and a higher flexibility in choosing the\nweight functions. Precisely speaking, the weights are described by Lebesgue\nintegrable functions instead of step functions. We also provide a functional\nback-propagation algorithm, which enables gradient descent training of the\nweights. In addition, with a slight modification, our concept realizes\nrecurrent neural networks.",
          "link": "http://arxiv.org/abs/2101.02966",
          "publishedOn": "2021-06-14T01:38:55.776Z",
          "wordCount": 588,
          "title": "Infinite-dimensional Folded-in-time Deep Neural Networks. (arXiv:2101.02966v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.03236",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Swamy_G/0/1/0/all/0/1\">Gokul Swamy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choudhury_S/0/1/0/all/0/1\">Sanjiban Choudhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bagnell_J/0/1/0/all/0/1\">J. Andrew Bagnell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhiwei Steven Wu</a>",
          "description": "We provide a unifying view of a large family of previous imitation learning\nalgorithms through the lens of moment matching. At its core, our classification\nscheme is based on whether the learner attempts to match (1) reward or (2)\naction-value moments of the expert's behavior, with each option leading to\ndiffering algorithmic approaches. By considering adversarially chosen\ndivergences between learner and expert behavior, we are able to derive bounds\non policy performance that apply for all algorithms in each of these classes,\nthe first to our knowledge. We also introduce the notion of moment\nrecoverability, implicit in many previous analyses of imitation learning, which\nallows us to cleanly delineate how well each algorithmic family is able to\nmitigate compounding errors. We derive three novel algorithm templates (AdVIL,\nAdRIL, and DAeQuIL) with strong guarantees, simple implementation, and\ncompetitive empirical performance.",
          "link": "http://arxiv.org/abs/2103.03236",
          "publishedOn": "2021-06-14T01:38:55.757Z",
          "wordCount": 612,
          "title": "Of Moments and Matching: A Game-Theoretic Framework for Closing the Imitation Gap. (arXiv:2103.03236v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.05510",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schaub_M/0/1/0/all/0/1\">Michael T. Schaub</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yu Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seby_J/0/1/0/all/0/1\">Jean-Baptiste Seby</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roddenberry_T/0/1/0/all/0/1\">T. Mitchell Roddenberry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Segarra_S/0/1/0/all/0/1\">Santiago Segarra</a>",
          "description": "In this tutorial, we provide a didactic treatment of the emerging topic of\nsignal processing on higher-order networks. Drawing analogies from discrete and\ngraph signal processing, we introduce the building blocks for processing data\non simplicial complexes and hypergraphs, two common higher-order network\nabstractions that can incorporate polyadic relationships. We provide brief\nintroductions to simplicial complexes and hypergraphs, with a special emphasis\non the concepts needed for the processing of signals supported on these\nstructures. Specifically, we discuss Fourier analysis, signal denoising, signal\ninterpolation, node embeddings, and nonlinear processing through neural\nnetworks, using these two higher-order network models. In the context of\nsimplicial complexes, we specifically focus on signal processing using the\nHodge Laplacian matrix, a multi-relational operator that leverages the special\nstructure of simplicial complexes and generalizes desirable properties of the\nLaplacian matrix in graph signal processing. For hypergraphs, we present both\nmatrix and tensor representations, and discuss the trade-offs in adopting one\nor the other. We also highlight limitations and potential research avenues,\nboth to inform practitioners and to motivate the contribution of new\nresearchers to the area.",
          "link": "http://arxiv.org/abs/2101.05510",
          "publishedOn": "2021-06-14T01:38:55.749Z",
          "wordCount": 690,
          "title": "Signal Processing on Higher-Order Networks: Livin' on the Edge ... and Beyond. (arXiv:2101.05510v3 [cs.SI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.05918",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jia_C/0/1/0/all/0/1\">Chao Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yinfei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1\">Ye Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yi-Ting Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parekh_Z/0/1/0/all/0/1\">Zarana Parekh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pham_H/0/1/0/all/0/1\">Hieu Pham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1\">Quoc V. Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sung_Y/0/1/0/all/0/1\">Yunhsuan Sung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duerig_T/0/1/0/all/0/1\">Tom Duerig</a>",
          "description": "Pre-trained representations are becoming crucial for many NLP and perception\ntasks. While representation learning in NLP has transitioned to training on raw\ntext without human annotations, visual and vision-language representations\nstill rely heavily on curated training datasets that are expensive or require\nexpert knowledge. For vision applications, representations are mostly learned\nusing datasets with explicit class labels such as ImageNet or OpenImages. For\nvision-language, popular datasets like Conceptual Captions, MSCOCO, or CLIP all\ninvolve a non-trivial data collection (and cleaning) process. This costly\ncuration process limits the size of datasets and hence hinders the scaling of\ntrained models. In this paper, we leverage a noisy dataset of over one billion\nimage alt-text pairs, obtained without expensive filtering or post-processing\nsteps in the Conceptual Captions dataset. A simple dual-encoder architecture\nlearns to align visual and language representations of the image and text pairs\nusing a contrastive loss. We show that the scale of our corpus can make up for\nits noise and leads to state-of-the-art representations even with such a simple\nlearning scheme. Our visual representation achieves strong performance when\ntransferred to classification tasks such as ImageNet and VTAB. The aligned\nvisual and language representations enables zero-shot image classification and\nalso set new state-of-the-art results on Flickr30K and MSCOCO image-text\nretrieval benchmarks, even when compared with more sophisticated\ncross-attention models. The representations also enable cross-modality search\nwith complex text and text + image queries.",
          "link": "http://arxiv.org/abs/2102.05918",
          "publishedOn": "2021-06-14T01:38:55.742Z",
          "wordCount": 733,
          "title": "Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision. (arXiv:2102.05918v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.11203",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cai_T/0/1/0/all/0/1\">Tianle Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_R/0/1/0/all/0/1\">Ruiqi Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jason D. Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_Q/0/1/0/all/0/1\">Qi Lei</a>",
          "description": "One of the central problems in machine learning is domain adaptation. Unlike\npast theoretical work, we consider a new model for subpopulation shift in the\ninput or representation space. In this work, we propose a provably effective\nframework for domain adaptation based on label propagation. In our analysis, we\nuse a simple but realistic expansion assumption, proposed in\n\\citet{wei2021theoretical}. Using a teacher classifier trained on the source\ndomain, our algorithm not only propagates to the target domain but also\nimproves upon the teacher. By leveraging existing generalization bounds, we\nalso obtain end-to-end finite-sample guarantees on the entire algorithm. In\naddition, we extend our theoretical framework to a more general setting of\nsource-to-target transfer based on a third unlabeled dataset, which can be\neasily applied in various learning scenarios. Inspired by our theory, we adapt\nconsistency-based semi-supervised learning methods to domain adaptation\nsettings and gain significant improvements.",
          "link": "http://arxiv.org/abs/2102.11203",
          "publishedOn": "2021-06-14T01:38:55.735Z",
          "wordCount": 615,
          "title": "A Theory of Label Propagation for Subpopulation Shift. (arXiv:2102.11203v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.10707",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Cai_H/0/1/0/all/0/1\">HanQin Cai</a>, <a href=\"http://arxiv.org/find/math/1/au:+Lou_Y/0/1/0/all/0/1\">Yuchen Lou</a>, <a href=\"http://arxiv.org/find/math/1/au:+McKenzie_D/0/1/0/all/0/1\">Daniel McKenzie</a>, <a href=\"http://arxiv.org/find/math/1/au:+Yin_W/0/1/0/all/0/1\">Wotao Yin</a>",
          "description": "We consider the zeroth-order optimization problem in the huge-scale setting,\nwhere the dimension of the problem is so large that performing even basic\nvector operations on the decision variables is infeasible. In this paper, we\npropose a novel algorithm, coined ZO-BCD, that exhibits favorable overall query\ncomplexity and has a much smaller per-iteration computational complexity. In\naddition, we discuss how the memory footprint of ZO-BCD can be reduced even\nfurther by the clever use of circulant measurement matrices. As an application\nof our new method, we propose the idea of crafting adversarial attacks on\nneural network based classifiers in a wavelet domain, which can result in\nproblem dimensions of over 1.7 million. In particular, we show that crafting\nadversarial examples to audio classifiers in a wavelet domain can achieve the\nstate-of-the-art attack success rate of 97.9%.",
          "link": "http://arxiv.org/abs/2102.10707",
          "publishedOn": "2021-06-14T01:38:55.721Z",
          "wordCount": 601,
          "title": "A Zeroth-Order Block Coordinate Descent Algorithm for Huge-Scale Black-Box Optimization. (arXiv:2102.10707v2 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.11376",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wilmot_C/0/1/0/all/0/1\">Charles Wilmot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Triesch_J/0/1/0/all/0/1\">Jochen Triesch</a>",
          "description": "A key competence for open-ended learning is the formation of increasingly\nabstract representations useful for driving complex behavior. Abstract\nrepresentations ignore specific details and facilitate generalization. Here we\nconsider the learning of abstract representations in a multi-modal setting with\ntwo or more input modalities. We treat the problem as a lossy compression\nproblem and show that generic lossy compression of multimodal sensory input\nnaturally extracts abstract representations that tend to strip away modalitiy\nspecific details and preferentially retain information that is shared across\nthe different modalities. Furthermore, we propose an architecture to learn\nabstract representations by identifying and retaining only the information that\nis shared across multiple modalities while discarding any modality specific\ninformation.",
          "link": "http://arxiv.org/abs/2101.11376",
          "publishedOn": "2021-06-14T01:38:55.714Z",
          "wordCount": 568,
          "title": "Learning Abstract Representations through Lossy Compression of Multi-Modal Signals. (arXiv:2101.11376v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.14203",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Watanabe_C/0/1/0/all/0/1\">Chihiro Watanabe</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Suzuki_T/0/1/0/all/0/1\">Taiji Suzuki</a>",
          "description": "Matrix reordering is a task to permute the rows and columns of a given\nobserved matrix such that the resulting reordered matrix shows meaningful or\ninterpretable structural patterns. Most existing matrix reordering techniques\nshare the common processes of extracting some feature representations from an\nobserved matrix in a predefined manner, and applying matrix reordering based on\nit. However, in some practical cases, we do not always have prior knowledge\nabout the structural pattern of an observed matrix. To address this problem, we\npropose a new matrix reordering method, called deep two-way matrix reordering\n(DeepTMR), using a neural network model. The trained network can automatically\nextract nonlinear row/column features from an observed matrix, which can then\nbe used for matrix reordering. Moreover, the proposed DeepTMR provides the\ndenoised mean matrix of a given observed matrix as an output of the trained\nnetwork. This denoised mean matrix can be used to visualize the global\nstructure of the reordered observed matrix. We demonstrate the effectiveness of\nthe proposed DeepTMR by applying it to both synthetic and practical datasets.",
          "link": "http://arxiv.org/abs/2103.14203",
          "publishedOn": "2021-06-14T01:38:55.708Z",
          "wordCount": 634,
          "title": "Deep Two-Way Matrix Reordering for Relational Data Analysis. (arXiv:2103.14203v4 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.05363",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Bohang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_T/0/1/0/all/0/1\">Tianle Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1\">Zhou Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1\">Di He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Liwei Wang</a>",
          "description": "It is well-known that standard neural networks, even with a high\nclassification accuracy, are vulnerable to small $\\ell_\\infty$-norm bounded\nadversarial perturbations. Although many attempts have been made, most previous\nworks either can only provide empirical verification of the defense to a\nparticular attack method, or can only develop a certified guarantee of the\nmodel robustness in limited scenarios. In this paper, we seek for a new\napproach to develop a theoretically principled neural network that inherently\nresists $\\ell_\\infty$ perturbations. In particular, we design a novel neuron\nthat uses $\\ell_\\infty$-distance as its basic operation (which we call\n$\\ell_\\infty$-dist neuron), and show that any neural network constructed with\n$\\ell_\\infty$-dist neurons (called $\\ell_{\\infty}$-dist net) is naturally a\n1-Lipschitz function with respect to $\\ell_\\infty$-norm. This directly provides\na rigorous guarantee of the certified robustness based on the margin of\nprediction outputs. We then prove that such networks have enough expressive\npower to approximate any 1-Lipschitz function with robust generalization\nguarantee. We further provide a holistic training strategy that can greatly\nalleviate optimization difficulties. Experimental results show that using\n$\\ell_{\\infty}$-dist nets as basic building blocks, we consistently achieve\nstate-of-the-art performance on commonly used datasets: 93.09% certified\naccuracy on MNIST ($\\epsilon=0.3$), 35.42% on CIFAR-10 ($\\epsilon=8/255$) and\n16.31% on TinyImageNet ($\\epsilon=1/255$).",
          "link": "http://arxiv.org/abs/2102.05363",
          "publishedOn": "2021-06-14T01:38:55.702Z",
          "wordCount": 696,
          "title": "Towards Certifying L-infinity Robustness using Neural Networks with L-inf-dist Neurons. (arXiv:2102.05363v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.07437",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dong_C/0/1/0/all/0/1\">Chengyu Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Liyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shang_J/0/1/0/all/0/1\">Jingbo Shang</a>",
          "description": "There are multiple intriguing problems hovering in adversarial training,\nincluding robustness-accuracy trade-off, robust overfitting, and robustness\noverestimation. These problems pose great challenges to both reliable\nevaluation and practical deployment. Here, we show that these problems share\none common cause -- low quality samples in the dataset. We first identify an\nintrinsic property of the data called \\emph{problematic score} and then design\ncontrolled experiments to investigate its connections with these problems.\nSpecifically, we find that when problematic data is removed, robust overfitting\nand robustness overestimation can be largely alleviated; and\nrobustness-accuracy trade-off becomes less significant. These observations not\nonly verify our intuition about data quality but also open new opportunities to\nadvance adversarial training. Interestingly, simply removing problematic data\nfrom adversarial training, while making the training set smaller, yields better\nrobustness for leading adversarial training strategies.",
          "link": "http://arxiv.org/abs/2102.07437",
          "publishedOn": "2021-06-14T01:38:55.695Z",
          "wordCount": 590,
          "title": "Data Profiling for Adversarial Training: On the Ruin of Problematic Data. (arXiv:2102.07437v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.12871",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1\">Han Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jiahui Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiaozhe Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Hang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1\">Xiaodan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhenguo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwok_J/0/1/0/all/0/1\">James T. Kwok</a>",
          "description": "Transformer-based models are popularly used in natural language processing\n(NLP). Its core component, self-attention, has aroused widespread interest. To\nunderstand the self-attention mechanism, a direct method is to visualize the\nattention map of a pre-trained model. Based on the patterns observed, a series\nof efficient Transformers with different sparse attention masks have been\nproposed. From a theoretical perspective, universal approximability of\nTransformer-based models is also recently proved. However, the above\nunderstanding and analysis of self-attention is based on a pre-trained model.\nTo rethink the importance analysis in self-attention, we study the significance\nof different positions in attention matrix during pre-training. A surprising\nresult is that diagonal elements in the attention map are the least important\ncompared with other attention positions. We provide a proof showing that these\ndiagonal elements can indeed be removed without deteriorating model\nperformance. Furthermore, we propose a Differentiable Attention Mask (DAM)\nalgorithm, which further guides the design of the SparseBERT. Extensive\nexperiments verify our interesting findings and illustrate the effect of the\nproposed algorithm.",
          "link": "http://arxiv.org/abs/2102.12871",
          "publishedOn": "2021-06-14T01:38:55.687Z",
          "wordCount": 633,
          "title": "SparseBERT: Rethinking the Importance Analysis in Self-attention. (arXiv:2102.12871v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.04002",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chi_H/0/1/0/all/0/1\">Haoang Chi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Feng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1\">Wenjing Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_L/0/1/0/all/0/1\">Long Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tongliang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1\">Bo Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1\">Gang Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1\">Mingyuan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masashi Sugiyama</a>",
          "description": "In learning to discover novel classes (L2DNC), we are given labeled data from\nseen classes and unlabeled data from unseen classes, and we train clustering\nmodels for the unseen classes. However, the rigorous definition of L2DNC is\nunexplored, which results in that its implicit assumptions are still unclear.\nIn this paper, we demystify assumptions behind L2DNC and find that high-level\nsemantic features should be shared among the seen and unseen classes. This\nnaturally motivates us to link L2DNC to meta-learning that has exactly the same\nassumption as L2DNC. Based on this finding, L2DNC is not only theoretically\nsolvable, but can also be empirically solved by meta-learning algorithms after\nslight modifications. This L2DNC methodology significantly reduces the amount\nof unlabeled data needed for training and makes it more practical, as\ndemonstrated in experiments. The use of very limited data is also justified by\nthe application scenario of L2DNC: since it is unnatural to label only\nseen-class data, L2DNC is sampling instead of labeling in causality. Therefore,\nunseen-class data should be collected on the way of collecting seen-class data,\nwhich is why they are novel and first need to be clustered.",
          "link": "http://arxiv.org/abs/2102.04002",
          "publishedOn": "2021-06-14T01:38:55.681Z",
          "wordCount": 661,
          "title": "Demystifying Assumptions in Learning to Discover Novel Classes. (arXiv:2102.04002v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.11391",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xitong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yixuan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brugnone_N/0/1/0/all/0/1\">Nathan Brugnone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perlmutter_M/0/1/0/all/0/1\">Michael Perlmutter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hirn_M/0/1/0/all/0/1\">Matthew Hirn</a>",
          "description": "The prevalence of graph-based data has spurred the rapid development of graph\nneural networks (GNNs) and related machine learning algorithms. Yet, despite\nthe many datasets naturally modeled as directed graphs, including citation,\nwebsite, and traffic networks, the vast majority of this research focuses on\nundirected graphs. In this paper, we propose MagNet, a spectral GNN for\ndirected graphs based on a complex Hermitian matrix known as the magnetic\nLaplacian. This matrix encodes undirected geometric structure in the magnitude\nof its entries and directional information in their phase. A \"charge\" parameter\nattunes spectral information to variation among directed cycles. We apply our\nnetwork to a variety of directed graph node classification and link prediction\ntasks showing that MagNet performs well on all tasks and that its performance\nexceeds all other methods on a majority of such tasks. The underlying\nprinciples of MagNet are such that it can be adapted to other spectral GNN\narchitectures.",
          "link": "http://arxiv.org/abs/2102.11391",
          "publishedOn": "2021-06-14T01:38:55.674Z",
          "wordCount": 633,
          "title": "MagNet: A Neural Network for Directed Graphs. (arXiv:2102.11391v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.02062",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yucheng Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_Y/0/1/0/all/0/1\">Youngsuk Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lifan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sa_C/0/1/0/all/0/1\">Christopher De Sa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Foster_D/0/1/0/all/0/1\">Dean Foster</a>",
          "description": "In large-scale time series forecasting, one often encounters the situation\nwhere the temporal patterns of time series, while drifting over time, differ\nfrom one another in the same dataset. In this paper, we provably show under\nsuch heterogeneity, training a forecasting model with commonly used stochastic\noptimizers (e.g. SGD) potentially suffers large variance on gradient\nestimation, and thus incurs long-time training. We show that this issue can be\nefficiently alleviated via stratification, which allows the optimizer to sample\nfrom pre-grouped time series strata. For better trading-off gradient variance\nand computation complexity, we further propose SCott (Stochastic Stratified\nControl Variate Gradient Descent), a variance reduced SGD-style optimizer that\nutilizes stratified sampling via control variate. In theory, we provide the\nconvergence guarantee of SCott on smooth non-convex objectives. Empirically, we\nevaluate SCott and other baseline optimizers on both synthetic and real-world\ntime series forecasting problems, and demonstrate SCott converges faster with\nrespect to both iterations and wall clock time.",
          "link": "http://arxiv.org/abs/2103.02062",
          "publishedOn": "2021-06-14T01:38:55.640Z",
          "wordCount": 623,
          "title": "Variance Reduced Training with Stratified Sampling for Forecasting Models. (arXiv:2103.02062v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.09855",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Wager_S/0/1/0/all/0/1\">Stefan Wager</a>, <a href=\"http://arxiv.org/find/math/1/au:+Xu_K/0/1/0/all/0/1\">Kuang Xu</a>",
          "description": "We propose a new diffusion-asymptotic analysis for sequentially randomized\nexperiments, including those that arise in solving multi-armed bandit problems.\nIn an experiment with $ n $ time steps, we let the mean reward gaps between\nactions scale to the order $1/\\sqrt{n}$ so as to preserve the difficulty of the\nlearning task as $n$ grows. In this regime, we show that the behavior of a\nclass of sequentially randomized Markov experiments converges to a diffusion\nlimit, given as the solution of a stochastic differential equation. The\ndiffusion limit thus enables us to derive refined, instance-specific\ncharacterization of the stochastic dynamics of adaptive experiments. As an\napplication of this framework, we use the diffusion limit to obtain several new\ninsights on the regret and belief evolution of Thompson sampling. We show that\na version of Thompson sampling with an asymptotically uninformative prior\nvariance achieves nearly-optimal instance-specific regret scaling when the\nreward gaps are relatively large. We also demonstrate that, in this regime, the\nposterior beliefs underlying Thompson sampling are highly unstable over time.",
          "link": "http://arxiv.org/abs/2101.09855",
          "publishedOn": "2021-06-14T01:38:55.630Z",
          "wordCount": 620,
          "title": "Diffusion Asymptotics for Sequential Experiments. (arXiv:2101.09855v3 [math.ST] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.13240",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Krishnamurthy_S/0/1/0/all/0/1\">Sanath Kumar Krishnamurthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hadad_V/0/1/0/all/0/1\">Vitor Hadad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Athey_S/0/1/0/all/0/1\">Susan Athey</a>",
          "description": "Computationally efficient contextual bandits are often based on estimating a\npredictive model of rewards given contexts and arms using past data. However,\nwhen the reward model is not well-specified, the bandit algorithm may incur\nunexpected regret, so recent work has focused on algorithms that are robust to\nmisspecification. We propose a simple family of contextual bandit algorithms\nthat adapt to misspecification error by reverting to a good safe policy when\nthere is evidence that misspecification is causing a regret increase. Our\nalgorithm requires only an offline regression oracle to ensure regret\nguarantees that gracefully degrade in terms of a measure of the average\nmisspecification level. Compared to prior work, we attain similar regret\nguarantees, but we do no rely on a master algorithm, and do not require more\nrobust oracles like online or constrained regression oracles (e.g., Foster et\nal. (2020a); Krishnamurthy et al. (2020)). This allows us to design algorithms\nfor more general function approximation classes.",
          "link": "http://arxiv.org/abs/2102.13240",
          "publishedOn": "2021-06-14T01:38:55.619Z",
          "wordCount": 621,
          "title": "Adapting to Misspecification in Contextual Bandits with Offline Regression Oracles. (arXiv:2102.13240v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.02438",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Foster_A/0/1/0/all/0/1\">Adam Foster</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ivanova_D/0/1/0/all/0/1\">Desi R. Ivanova</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Malik_I/0/1/0/all/0/1\">Ilyas Malik</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rainforth_T/0/1/0/all/0/1\">Tom Rainforth</a>",
          "description": "We introduce Deep Adaptive Design (DAD), a method for amortizing the cost of\nadaptive Bayesian experimental design that allows experiments to be run in\nreal-time. Traditional sequential Bayesian optimal experimental design\napproaches require substantial computation at each stage of the experiment.\nThis makes them unsuitable for most real-world applications, where decisions\nmust typically be made quickly. DAD addresses this restriction by learning an\namortized design network upfront and then using this to rapidly run (multiple)\nadaptive experiments at deployment time. This network represents a design\npolicy which takes as input the data from previous steps, and outputs the next\ndesign using a single forward pass; these design decisions can be made in\nmilliseconds during the live experiment. To train the network, we introduce\ncontrastive information bounds that are suitable objectives for the sequential\nsetting, and propose a customized network architecture that exploits key\nsymmetries. We demonstrate that DAD successfully amortizes the process of\nexperimental design, outperforming alternative strategies on a number of\nproblems.",
          "link": "http://arxiv.org/abs/2103.02438",
          "publishedOn": "2021-06-14T01:38:55.609Z",
          "wordCount": 625,
          "title": "Deep Adaptive Design: Amortizing Sequential Bayesian Experimental Design. (arXiv:2103.02438v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.08358",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Frongillo_R/0/1/0/all/0/1\">Rafael Frongillo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gomez_R/0/1/0/all/0/1\">Robert Gomez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thilagar_A/0/1/0/all/0/1\">Anish Thilagar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Waggoner_B/0/1/0/all/0/1\">Bo Waggoner</a>",
          "description": "Winner-take-all competitions in forecasting and machine-learning suffer from\ndistorted incentives. Witkowski et al. 2018 identified this problem and\nproposed ELF, a truthful mechanism to select a winner. We show that, from a\npool of $n$ forecasters, ELF requires $\\Theta(n\\log n)$ events or test data\npoints to select a near-optimal forecaster with high probability. We then show\nthat standard online learning algorithms select an $\\epsilon$-optimal\nforecaster using only $O(\\log(n) / \\epsilon^2)$ events, by way of a strong\napproximate-truthfulness guarantee. This bound matches the best possible even\nin the nonstrategic setting. We then apply these mechanisms to obtain the first\nno-regret guarantee for non-myopic strategic experts.",
          "link": "http://arxiv.org/abs/2102.08358",
          "publishedOn": "2021-06-14T01:38:55.592Z",
          "wordCount": 586,
          "title": "Efficient Competitions and Online Learning with Strategic Forecasters. (arXiv:2102.08358v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.02893",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Yoshida_S/0/1/0/all/0/1\">Shuhei M. Yoshida</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Takenouchi_T/0/1/0/all/0/1\">Takashi Takenouchi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masashi Sugiyama</a>",
          "description": "This paper discusses the problem of weakly supervised classification, in\nwhich instances are given weak labels that are produced by some\nlabel-corruption process. The goal is to derive conditions under which loss\nfunctions for weak-label learning are proper and lower-bounded -- two essential\nrequirements for the losses used in class-probability estimation. To this end,\nwe derive a representation theorem for proper losses in supervised learning,\nwhich dualizes the Savage representation. We use this theorem to characterize\nproper weak-label losses and find a condition for them to be lower-bounded.\nFrom these theoretical findings, we derive a novel regularization scheme called\ngeneralized logit squeezing, which makes any proper weak-label loss bounded\nfrom below, without losing properness. Furthermore, we experimentally\ndemonstrate the effectiveness of our proposed approach, as compared to improper\nor unbounded losses. The results highlight the importance of properness and\nlower-boundedness.",
          "link": "http://arxiv.org/abs/2103.02893",
          "publishedOn": "2021-06-14T01:38:55.562Z",
          "wordCount": 593,
          "title": "Lower-Bounded Proper Losses for Weakly Supervised Classification. (arXiv:2103.02893v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.01350",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Yang_X/0/1/0/all/0/1\">Xiangyu Yang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Wang_J/0/1/0/all/0/1\">Jiashan Wang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Wang_H/0/1/0/all/0/1\">Hao Wang</a>",
          "description": "This paper primarily focuses on computing the Euclidean projection of a\nvector onto the $\\ell_{p}$ ball in which $p\\in(0,1)$. Such a problem emerges as\nthe core building block in statistical machine learning and signal processing\ntasks because of its ability to promote sparsity. However, efficient numerical\nalgorithms for finding the projections are still not available, particularly in\nlarge-scale optimization. To meet this challenge, we first derive the\nfirst-order necessary optimality conditions of this problem using Fr\\'echet\nnormal cone. Based on this characterization, we develop a novel numerical\napproach for computing the stationary point through solving a sequence of\nprojections onto the reweighted $\\ell_{1}$-balls. This method is practically\nsimple to implement and computationally efficient. Moreover, the proposed\nalgorithm is shown to converge uniquely under mild conditions and has a\nworst-case $O(1/\\sqrt{k})$ convergence rate. Numerical experiments demonstrate\nthe efficiency of our proposed algorithm.",
          "link": "http://arxiv.org/abs/2101.01350",
          "publishedOn": "2021-06-14T01:38:55.555Z",
          "wordCount": 630,
          "title": "Towards an efficient approach for the nonconvex $\\ell_p$ ball projection: algorithm and analysis. (arXiv:2101.01350v3 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.09808",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Iuzzolino_M/0/1/0/all/0/1\">Michael L. Iuzzolino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mozer_M/0/1/0/all/0/1\">Michael C. Mozer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_S/0/1/0/all/0/1\">Samy Bengio</a>",
          "description": "Although deep feedforward neural networks share some characteristics with the\nprimate visual system, a key distinction is their dynamics. Deep nets typically\noperate in serial stages wherein each layer completes its computation before\nprocessing begins in subsequent layers. In contrast, biological systems have\ncascaded dynamics: information propagates from neurons at all layers in\nparallel but transmission occurs gradually over time, leading to speed-accuracy\ntrade offs even in feedforward architectures. We explore the consequences of\nbiologically inspired parallel hardware by constructing cascaded ResNets in\nwhich each residual block has propagation delays but all blocks update in\nparallel in a stateful manner. Because information transmitted through skip\nconnections avoids delays, the functional depth of the architecture increases\nover time, yielding anytime predictions that improve with internal-processing\ntime. We introduce a temporal-difference training loss that achieves a strictly\nsuperior speed-accuracy profile over standard losses and enables the cascaded\narchitecture to outperform state-of-the-art anytime-prediction methods. The\ncascaded architecture has intriguing properties, including: it classifies\ntypical instances more rapidly than atypical instances; it is more robust to\nboth persistent and transient noise than is a conventional ResNet; and its\ntime-varying output trace provides a signal that can be exploited to improve\ninformation processing and inference.",
          "link": "http://arxiv.org/abs/2102.09808",
          "publishedOn": "2021-06-14T01:38:55.548Z",
          "wordCount": 676,
          "title": "Improving Anytime Prediction with Parallel Cascaded Networks and a Temporal-Difference Loss. (arXiv:2102.09808v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.03502",
          "author": "<a href=\"http://arxiv.org/find/q-fin/1/au:+Huang_Z/0/1/0/all/0/1\">Zhenhan Huang</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Tanaka_F/0/1/0/all/0/1\">Fumihide Tanaka</a>",
          "description": "Financial portfolio management is one of the most applicable problems in\nreinforcement learning (RL) owing to its sequential decision-making nature.\nExisting RL-based approaches, while inspiring, often lack scalability,\nreusability, or profundity of intake information to accommodate the\never-changing capital markets. In this paper, we propose MSPM, a modularized\nand scalable, multi-agent RL-based system for financial portfolio management.\nMSPM involves two asynchronously updated units: an Evolving Agent Module (EAM)\nand Strategic Agent Module (SAM). A self-sustained EAM produces\nsignal-comprised information for a specific asset using heterogeneous data\ninputs, and each EAM employs its reusability to have connections to multiple\nSAMs. An SAM is responsible for asset reallocation in a portfolio using\nprofound information from the connected EAMs. With the elaborate architecture\nand the multi-step condensation of volatile market information, MSPM aims to\nprovide a customizable, stable, and dedicated solution to portfolio management,\nunlike existing approaches. We also tackle the data-shortage issue of\nnewly-listed stocks by transfer learning, and validate the indispensability of\nEAM with four different portfolios. Experiments on 8-year U.S. stock market\ndata prove the effectiveness of MSPM in profit accumulation, by its\noutperformance over existing benchmarks.",
          "link": "http://arxiv.org/abs/2102.03502",
          "publishedOn": "2021-06-14T01:38:55.539Z",
          "wordCount": 656,
          "title": "MSPM: A Modularized and Scalable Multi-Agent Reinforcement Learning-based System for Financial Portfolio Management. (arXiv:2102.03502v3 [q-fin.PM] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.00010",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sinha_K/0/1/0/all/0/1\">Koustuv Sinha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parthasarathi_P/0/1/0/all/0/1\">Prasanna Parthasarathi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pineau_J/0/1/0/all/0/1\">Joelle Pineau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Williams_A/0/1/0/all/0/1\">Adina Williams</a>",
          "description": "Recent investigations into the inner-workings of state-of-the-art large-scale\npre-trained Transformer-based Natural Language Understanding (NLU) models\nindicate that they appear to know humanlike syntax, at least to some extent. We\nprovide novel evidence that complicates this claim: we find that\nstate-of-the-art Natural Language Inference (NLI) models assign the same labels\nto permuted examples as they do to the original, i.e. they are largely\ninvariant to random word-order permutations. This behavior notably differs from\nthat of humans; we struggle with ungrammatical sentences. To measure the\nseverity of this issue, we propose a suite of metrics and investigate which\nproperties of particular permutations lead models to be word-order invariant.\nIn the MNLI dataset, for example, we find almost all (98.7%) examples contain\nat least one permutation which elicits the gold label. Models are sometimes\neven able to assign gold labels to permutations that they originally failed to\npredict correctly. We provide a comprehensive empirical evaluation of this\nphenomenon, and further show that this issue exists for both Transformers and\npre-Transformer RNN / ConvNet based encoders, as well as across multiple\nlanguages (English and Mandarin Chinese). Our code and data are available at\nhttps://github.com/facebookresearch/unlu.",
          "link": "http://arxiv.org/abs/2101.00010",
          "publishedOn": "2021-06-14T01:38:55.532Z",
          "wordCount": 652,
          "title": "UnNatural Language Inference. (arXiv:2101.00010v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.08598",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Terrance Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vietri_G/0/1/0/all/0/1\">Giuseppe Vietri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steinke_T/0/1/0/all/0/1\">Thomas Steinke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ullman_J/0/1/0/all/0/1\">Jonathan Ullman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhiwei Steven Wu</a>",
          "description": "In many statistical problems, incorporating priors can significantly improve\nperformance. However, the use of prior knowledge in differentially private\nquery release has remained underexplored, despite such priors commonly being\navailable in the form of public datasets, such as previous US Census releases.\nWith the goal of releasing statistics about a private dataset, we present\nPMW^Pub, which -- unlike existing baselines -- leverages public data drawn from\na related distribution as prior information. We provide a theoretical analysis\nand an empirical evaluation on the American Community Survey (ACS) and ADULT\ndatasets, which shows that our method outperforms state-of-the-art methods.\nFurthermore, PMW^Pub scales well to high-dimensional data domains, where\nrunning many existing methods would be computationally infeasible.",
          "link": "http://arxiv.org/abs/2102.08598",
          "publishedOn": "2021-06-14T01:38:55.507Z",
          "wordCount": 586,
          "title": "Leveraging Public Data for Practical Private Query Release. (arXiv:2102.08598v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.06177",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sodhani_S/0/1/0/all/0/1\">Shagun Sodhani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1\">Amy Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pineau_J/0/1/0/all/0/1\">Joelle Pineau</a>",
          "description": "The benefit of multi-task learning over single-task learning relies on the\nability to use relations across tasks to improve performance on any single\ntask. While sharing representations is an important mechanism to share\ninformation across tasks, its success depends on how well the structure\nunderlying the tasks is captured. In some real-world situations, we have access\nto metadata, or additional information about a task, that may not provide any\nnew insight in the context of a single task setup alone but inform relations\nacross multiple tasks. While this metadata can be useful for improving\nmulti-task learning performance, effectively incorporating it can be an\nadditional challenge. We posit that an efficient approach to knowledge transfer\nis through the use of multiple context-dependent, composable representations\nshared across a family of tasks. In this framework, metadata can help to learn\ninterpretable representations and provide the context to inform which\nrepresentations to compose and how to compose them. We use the proposed\napproach to obtain state-of-the-art results in Meta-World, a challenging\nmulti-task benchmark consisting of 50 distinct robotic manipulation tasks.",
          "link": "http://arxiv.org/abs/2102.06177",
          "publishedOn": "2021-06-14T01:38:55.501Z",
          "wordCount": 647,
          "title": "Multi-Task Reinforcement Learning with Context-based Representations. (arXiv:2102.06177v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.09318",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khodadadian_S/0/1/0/all/0/1\">Sajad Khodadadian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zaiwei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maguluri_S/0/1/0/all/0/1\">Siva Theja Maguluri</a>",
          "description": "In this paper, we provide finite-sample convergence guarantees for an\noff-policy variant of the natural actor-critic (NAC) algorithm based on\nImportance Sampling. In particular, we show that the algorithm converges to a\nglobal optimal policy with a sample complexity of\n$\\mathcal{O}(\\epsilon^{-3}\\log^2(1/\\epsilon))$ under an appropriate choice of\nstepsizes. In order to overcome the issue of large variance due to Importance\nSampling, we propose the $Q$-trace algorithm for the critic, which is inspired\nby the V-trace algorithm \\cite{espeholt2018impala}. This enables us to\nexplicitly control the bias and variance, and characterize the trade-off\nbetween them. As an advantage of off-policy sampling, a major feature of our\nresult is that we do not need any additional assumptions, beyond the ergodicity\nof the Markov chain induced by the behavior policy.",
          "link": "http://arxiv.org/abs/2102.09318",
          "publishedOn": "2021-06-14T01:38:55.494Z",
          "wordCount": 585,
          "title": "Finite-Sample Analysis of Off-Policy Natural Actor-Critic Algorithm. (arXiv:2102.09318v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.14193",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jastrzebski_S/0/1/0/all/0/1\">Stanislaw Jastrzebski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arpit_D/0/1/0/all/0/1\">Devansh Arpit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Astrand_O/0/1/0/all/0/1\">Oliver Astrand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kerg_G/0/1/0/all/0/1\">Giancarlo Kerg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Huan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1\">Caiming Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Socher_R/0/1/0/all/0/1\">Richard Socher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1\">Kyunghyun Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geras_K/0/1/0/all/0/1\">Krzysztof Geras</a>",
          "description": "The early phase of training a deep neural network has a dramatic effect on\nthe local curvature of the loss function. For instance, using a small learning\nrate does not guarantee stable optimization because the optimization trajectory\nhas a tendency to steer towards regions of the loss surface with increasing\nlocal curvature. We ask whether this tendency is connected to the widely\nobserved phenomenon that the choice of the learning rate strongly influences\ngeneralization. We first show that stochastic gradient descent (SGD) implicitly\npenalizes the trace of the Fisher Information Matrix (FIM), a measure of the\nlocal curvature, from the start of training. We argue it is an implicit\nregularizer in SGD by showing that explicitly penalizing the trace of the FIM\ncan significantly improve generalization. We highlight that poor final\ngeneralization coincides with the trace of the FIM attaining a large value\nearly in training, to which we refer as catastrophic Fisher explosion. Finally,\nto gain insight into the regularization effect of penalizing the trace of the\nFIM, we show that it limits memorization by reducing the learning speed of\nexamples with noisy labels more than that of the examples with clean labels.",
          "link": "http://arxiv.org/abs/2012.14193",
          "publishedOn": "2021-06-14T01:38:55.434Z",
          "wordCount": 691,
          "title": "Catastrophic Fisher Explosion: Early Phase Fisher Matrix Impacts Generalization. (arXiv:2012.14193v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.15477",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Nitanda_A/0/1/0/all/0/1\">Atsushi Nitanda</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wu_D/0/1/0/all/0/1\">Denny Wu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Suzuki_T/0/1/0/all/0/1\">Taiji Suzuki</a>",
          "description": "We propose the particle dual averaging (PDA) method, which generalizes the\ndual averaging method in convex optimization to the optimization over\nprobability distributions with quantitative runtime guarantee. The algorithm\nconsists of an inner loop and outer loop: the inner loop utilizes the Langevin\nalgorithm to approximately solve for a stationary distribution, which is then\noptimized in the outer loop. The method can thus be interpreted as an extension\nof the Langevin algorithm to naturally handle nonlinear functional on the\nprobability space. An important application of the proposed method is the\noptimization of neural network in the mean field regime, which is theoretically\nattractive due to the presence of nonlinear feature learning, but quantitative\nconvergence rate can be challenging to obtain. By adapting finite-dimensional\nconvex optimization theory into the space of distributions, we analyze PDA in\nregularized empirical / expected risk minimization, and establish quantitative\nglobal convergence in learning two-layer mean field neural networks under more\ngeneral settings. Our theoretical results are supported by numerical\nsimulations on neural networks with reasonable size.",
          "link": "http://arxiv.org/abs/2012.15477",
          "publishedOn": "2021-06-14T01:38:55.368Z",
          "wordCount": 629,
          "title": "Particle Dual Averaging: Optimization of Mean Field Neural Networks with Global Convergence Rate Analysis. (arXiv:2012.15477v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.15764",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Peeples_J/0/1/0/all/0/1\">Joshua Peeples</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walker_S/0/1/0/all/0/1\">Sarah Walker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McCurley_C/0/1/0/all/0/1\">Connor McCurley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zare_A/0/1/0/all/0/1\">Alina Zare</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keller_J/0/1/0/all/0/1\">James Keller</a>",
          "description": "In this paper, we investigate performing joint dimensionality reduction and\nclassification using a novel histogram neural network. Motivated by a popular\ndimensionality reduction approach, t-Distributed Stochastic Neighbor Embedding\n(t-SNE), our proposed method incorporates a classification loss computed on\nsamples in a low-dimensional embedding space. We compare the learned sample\nembeddings against coordinates found by t-SNE in terms of classification\naccuracy and qualitative assessment. We also explore use of various divergence\nmeasures in the t-SNE objective. The proposed method has several advantages\nsuch as readily embedding out-of-sample points and reducing feature\ndimensionality while retaining class discriminability. Our results show that\nthe proposed approach maintains and/or improves classification performance and\nreveals characteristics of features produced by neural networks that may be\nhelpful for other applications.",
          "link": "http://arxiv.org/abs/2012.15764",
          "publishedOn": "2021-06-14T01:38:55.308Z",
          "wordCount": 610,
          "title": "Divergence Regulated Encoder Network for Joint Dimensionality Reduction and Classification. (arXiv:2012.15764v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.11875",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Yemini_Y/0/1/0/all/0/1\">Yochai Yemini</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fetaya_E/0/1/0/all/0/1\">Ethan Fetaya</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Maron_H/0/1/0/all/0/1\">Haggai Maron</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gannot_S/0/1/0/all/0/1\">Sharon Gannot</a>",
          "description": "Neural networks (NNs) have been widely applied in speech processing tasks,\nand, in particular, those employing microphone arrays. Nevertheless, most\nexisting NN architectures can only deal with fixed and position-specific\nmicrophone arrays. In this paper, we present an NN architecture that can cope\nwith microphone arrays whose number and positions of the microphones are\nunknown, and demonstrate its applicability in the speech dereverberation task.\nTo this end, our approach harnesses recent advances in deep learning on\nset-structured data to design an architecture that enhances the reverberant\nlog-spectrum. We use noisy and noiseless versions of a simulated reverberant\ndataset to test the proposed architecture. Our experiments on the noisy data\nshow that the proposed scene-agnostic setup outperforms a powerful scene-aware\nframework, sometimes even with fewer microphones. With the noiseless dataset we\nshow that, in most cases, our method outperforms the position-aware network as\nwell as the state-of-the-art weighted linear prediction error (WPE) algorithm.",
          "link": "http://arxiv.org/abs/2010.11875",
          "publishedOn": "2021-06-14T01:38:55.301Z",
          "wordCount": 600,
          "title": "Scene-Agnostic Multi-Microphone Speech Dereverberation. (arXiv:2010.11875v2 [eess.AS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.07648",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhunxuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1\">Linyun He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_C/0/1/0/all/0/1\">Chunchuan Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_S/0/1/0/all/0/1\">Shay B. Cohen</a>",
          "description": "We describe an algorithm that learns two-layer residual units with rectified\nlinear unit (ReLU) activation: suppose the input $\\mathbf{x}$ is from a\ndistribution with support space $\\mathbb{R}^d$ and the ground-truth generative\nmodel is such a residual unit, given by \\[\\mathbf{y}=\n\\boldsymbol{B}^\\ast\\left[\\left(\\boldsymbol{A}^\\ast\\mathbf{x}\\right)^+ +\n\\mathbf{x}\\right]\\text{,}\\] where ground-truth network parameters\n$\\boldsymbol{A}^\\ast \\in \\mathbb{R}^{d\\times d}$ is a nonnegative full-rank\nmatrix and $\\boldsymbol{B}^\\ast \\in \\mathbb{R}^{m\\times d}$ is full-rank with\n$m \\geq d$ and for $\\mathbf{c} \\in \\mathbb{R}^d$, $[\\mathbf{c}^{+}]_i =\n\\max\\{0, c_i\\}$. We design layer-wise objectives as functionals whose analytic\nminimizers express the exact ground-truth network in terms of its parameters\nand nonlinearities. Following this objective landscape, learning residual units\nfrom finite samples can be formulated using convex optimization of a\nnonparametric function: for each layer, we first formulate the corresponding\nempirical risk minimization (ERM) as a positive semi-definite quadratic program\n(QP), then we show the solution space of the QP can be equivalently determined\nby a set of linear inequalities, which can then be efficiently solved by linear\nprogramming (LP). We further prove the statistical strong consistency of our\nalgorithm, and demonstrate the robustness and sample efficiency of our\nalgorithm by experiments.",
          "link": "http://arxiv.org/abs/2008.07648",
          "publishedOn": "2021-06-14T01:38:55.295Z",
          "wordCount": 644,
          "title": "Nonparametric Learning of Two-Layer ReLU Residual Units. (arXiv:2008.07648v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.07210",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shukla_S/0/1/0/all/0/1\">Satya Narayan Shukla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sahu_A/0/1/0/all/0/1\">Anit Kumar Sahu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Willmott_D/0/1/0/all/0/1\">Devin Willmott</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolter_J/0/1/0/all/0/1\">J. Zico Kolter</a>",
          "description": "We focus on the problem of black-box adversarial attacks, where the aim is to\ngenerate adversarial examples for deep learning models solely based on\ninformation limited to output label~(hard label) to a queried data input. We\npropose a simple and efficient Bayesian Optimization~(BO) based approach for\ndeveloping black-box adversarial attacks. Issues with BO's performance in high\ndimensions are avoided by searching for adversarial examples in a structured\nlow-dimensional subspace. We demonstrate the efficacy of our proposed attack\nmethod by evaluating both $\\ell_\\infty$ and $\\ell_2$ norm constrained\nuntargeted and targeted hard label black-box attacks on three standard datasets\n- MNIST, CIFAR-10 and ImageNet. Our proposed approach consistently achieves 2x\nto 10x higher attack success rate while requiring 10x to 20x fewer queries\ncompared to the current state-of-the-art black-box adversarial attacks.",
          "link": "http://arxiv.org/abs/2007.07210",
          "publishedOn": "2021-06-14T01:38:55.288Z",
          "wordCount": 617,
          "title": "Simple and Efficient Hard Label Black-box Adversarial Attacks in Low Query Budget Regimes. (arXiv:2007.07210v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2001.02811",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Duan_J/0/1/0/all/0/1\">Jingliang Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guan_Y/0/1/0/all/0/1\">Yang Guan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shengbo Eben Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_Y/0/1/0/all/0/1\">Yangang Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_B/0/1/0/all/0/1\">Bo Cheng</a>",
          "description": "In reinforcement learning (RL), function approximation errors are known to\neasily lead to the Q-value overestimations, thus greatly reducing policy\nperformance. This paper presents a distributional soft actor-critic (DSAC)\nalgorithm, which is an off-policy RL method for continuous control setting, to\nimprove the policy performance by mitigating Q-value overestimations. We first\ndiscover in theory that learning a distribution function of state-action\nreturns can effectively mitigate Q-value overestimations because it is capable\nof adaptively adjusting the update stepsize of the Q-value function. Then, a\ndistributional soft policy iteration (DSPI) framework is developed by embedding\nthe return distribution function into maximum entropy RL. Finally, we present a\ndeep off-policy actor-critic variant of DSPI, called DSAC, which directly\nlearns a continuous return distribution by keeping the variance of the\nstate-action returns within a reasonable range to address exploding and\nvanishing gradient problems. We evaluate DSAC on the suite of MuJoCo continuous\ncontrol tasks, achieving the state-of-the-art performance.",
          "link": "http://arxiv.org/abs/2001.02811",
          "publishedOn": "2021-06-14T01:38:55.271Z",
          "wordCount": 649,
          "title": "Distributional Soft Actor-Critic: Off-Policy Reinforcement Learning for Addressing Value Estimation Errors. (arXiv:2001.02811v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2002.11318",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kamath_S/0/1/0/all/0/1\">Sandesh Kamath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deshpande_A/0/1/0/all/0/1\">Amit Deshpande</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Subrahmanyam_K/0/1/0/all/0/1\">K V Subrahmanyam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balasubramanian_V/0/1/0/all/0/1\">Vineeth N Balasubramanian</a>",
          "description": "(Non-)robustness of neural networks to small, adversarial pixel-wise\nperturbations, and as more recently shown, to even random spatial\ntransformations (e.g., translations, rotations) entreats both theoretical and\nempirical understanding. Spatial robustness to random translations and\nrotations is commonly attained via equivariant models (e.g., StdCNNs, GCNNs)\nand training augmentation, whereas adversarial robustness is typically achieved\nby adversarial training. In this paper, we prove a quantitative trade-off\nbetween spatial and adversarial robustness in a simple statistical setting. We\ncomplement this empirically by showing that: (a) as the spatial robustness of\nequivariant models improves by training augmentation with progressively larger\ntransformations, their adversarial robustness worsens progressively, and (b) as\nthe state-of-the-art robust models are adversarially trained with progressively\nlarger pixel-wise perturbations, their spatial robustness drops progressively.\nTowards achieving pareto-optimality in this trade-off, we propose a method\nbased on curriculum learning that trains gradually on more difficult\nperturbations (both spatial and adversarial) to improve spatial and adversarial\nrobustness simultaneously.",
          "link": "http://arxiv.org/abs/2002.11318",
          "publishedOn": "2021-06-14T01:38:55.256Z",
          "wordCount": 689,
          "title": "Can we have it all? On the Trade-off between Spatial and Adversarial Robustness of Neural Networks. (arXiv:2002.11318v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.08154",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Hult_L/0/1/0/all/0/1\">Ludvig Hult</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zachariah_D/0/1/0/all/0/1\">Dave Zachariah</a>",
          "description": "Conventional methods in causal effect inferencetypically rely on specifying a\nvalid set of control variables. When this set is unknown or misspecified,\ninferences will be erroneous. We propose a method for inferring average causal\neffects when all potential confounders are observed, but thecontrol variables\nare unknown. When the data-generating process belongs to the class of acyclical\nlinear structural causal models, we prove that themethod yields asymptotically\nvalid confidence intervals. Our results build upon a smooth characterization of\nlinear directed acyclic graphs. We verify the capability of the method to\nproduce valid confidence intervals for average causal effects using synthetic\ndata, even when the appropriate specification of control variables is unknown.",
          "link": "http://arxiv.org/abs/2012.08154",
          "publishedOn": "2021-06-14T01:38:55.250Z",
          "wordCount": 564,
          "title": "Inference of Causal Effects when Control Variables are Unknown. (arXiv:2012.08154v3 [stat.ME] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.09649",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meyer_R/0/1/0/all/0/1\">Raphael A. Meyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Musco_C/0/1/0/all/0/1\">Cameron Musco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Musco_C/0/1/0/all/0/1\">Christopher Musco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1\">David P. Woodruff</a>",
          "description": "We study the problem of estimating the trace of a matrix $A$ that can only be\naccessed through matrix-vector multiplication. We introduce a new randomized\nalgorithm, Hutch++, which computes a $(1 \\pm \\epsilon)$ approximation to\n$tr(A)$ for any positive semidefinite (PSD) $A$ using just $O(1/\\epsilon)$\nmatrix-vector products. This improves on the ubiquitous Hutchinson's estimator,\nwhich requires $O(1/\\epsilon^2)$ matrix-vector products. Our approach is based\non a simple technique for reducing the variance of Hutchinson's estimator using\na low-rank approximation step, and is easy to implement and analyze. Moreover,\nwe prove that, up to a logarithmic factor, the complexity of Hutch++ is optimal\namongst all matrix-vector query algorithms, even when queries can be chosen\nadaptively. We show that it significantly outperforms Hutchinson's method in\nexperiments. While our theory mainly requires $A$ to be positive semidefinite,\nwe provide generalized guarantees for general square matrices, and show\nempirical gains in such applications.",
          "link": "http://arxiv.org/abs/2010.09649",
          "publishedOn": "2021-06-14T01:38:55.242Z",
          "wordCount": 646,
          "title": "Hutch++: Optimal Stochastic Trace Estimation. (arXiv:2010.09649v5 [cs.DS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2001.03040",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jianfeng Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1\">Zuowei Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Haizhao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shijun Zhang</a>",
          "description": "This paper establishes optimal approximation error characterization of deep\nReLU networks for smooth functions in terms of both width and depth\nsimultaneously. To that end, we first prove that multivariate polynomials can\nbe approximated by deep ReLU networks of width $\\mathcal{O}(N)$ and depth\n$\\mathcal{O}(L)$ with an approximation error $\\mathcal{O}(N^{-L})$. Through\nlocal Taylor expansions and their deep ReLU network approximations, we show\nthat deep ReLU networks of width $\\mathcal{O}(N\\ln N)$ and depth\n$\\mathcal{O}(L\\ln L)$ can approximate $f\\in C^s([0,1]^d)$ with a nearly optimal\napproximation rate $\\mathcal{O}(\\|f\\|_{C^s([0,1]^d)}N^{-2s/d}L^{-2s/d})$. Our\nestimate is non-asymptotic in the sense that it is valid for arbitrary width\nand depth specified by $N\\in\\mathbb{N}^+$ and $L\\in\\mathbb{N}^+$, respectively.",
          "link": "http://arxiv.org/abs/2001.03040",
          "publishedOn": "2021-06-14T01:38:55.233Z",
          "wordCount": 584,
          "title": "Deep Network Approximation for Smooth Functions. (arXiv:2001.03040v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.01557",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brown_D/0/1/0/all/0/1\">Daniel S. Brown</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schneider_J/0/1/0/all/0/1\">Jordan Schneider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dragan_A/0/1/0/all/0/1\">Anca D. Dragan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niekum_S/0/1/0/all/0/1\">Scott Niekum</a>",
          "description": "As humans interact with autonomous agents to perform increasingly\ncomplicated, potentially risky tasks, it is important to be able to efficiently\nevaluate an agent's performance and correctness. In this paper we formalize and\ntheoretically analyze the problem of efficient value alignment verification:\nhow to efficiently test whether the behavior of another agent is aligned with a\nhuman's values. The goal is to construct a kind of \"driver's test\" that a human\ncan give to any agent which will verify value alignment via a minimal number of\nqueries. We study alignment verification problems with both idealized humans\nthat have an explicit reward function as well as problems where they have\nimplicit values. We analyze verification of exact value alignment for rational\nagents and propose and analyze heuristic and approximate value alignment\nverification tests in a wide range of gridworlds and a continuous autonomous\ndriving domain. Finally, we prove that there exist sufficient conditions such\nthat we can verify exact and approximate alignment across an infinite set of\ntest environments via a constant-query-complexity alignment test.",
          "link": "http://arxiv.org/abs/2012.01557",
          "publishedOn": "2021-06-14T01:38:55.213Z",
          "wordCount": 627,
          "title": "Value Alignment Verification. (arXiv:2012.01557v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.09361",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ibrahim_Z/0/1/0/all/0/1\">Zina M Ibrahim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bean_D/0/1/0/all/0/1\">Daniel Bean</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Searle_T/0/1/0/all/0/1\">Thomas Searle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Honghan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shek_A/0/1/0/all/0/1\">Anthony Shek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kraljevic_Z/0/1/0/all/0/1\">Zeljko Kraljevic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galloway_J/0/1/0/all/0/1\">James Galloway</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Norton_S/0/1/0/all/0/1\">Sam Norton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teo_J/0/1/0/all/0/1\">James T Teo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dobson_R/0/1/0/all/0/1\">Richard JB Dobson</a>",
          "description": "The ability to perform accurate prognosis of patients is crucial for\nproactive clinical decision making, informed resource management and\npersonalised care. Existing outcome prediction models suffer from a low recall\nof infrequent positive outcomes. We present a highly-scalable and robust\nmachine learning framework to automatically predict adversity represented by\nmortality and ICU admission from time-series vital signs and laboratory results\nobtained within the first 24 hours of hospital admission. The stacked platform\ncomprises two components: a) an unsupervised LSTM Autoencoder that learns an\noptimal representation of the time-series, using it to differentiate the less\nfrequent patterns which conclude with an adverse event from the majority\npatterns that do not, and b) a gradient boosting model, which relies on the\nconstructed representation to refine prediction, incorporating static features\nof demographics, admission details and clinical summaries. The model is used to\nassess a patient's risk of adversity over time and provides visual\njustifications of its prediction based on the patient's static features and\ndynamic signals. Results of three case studies for predicting mortality and ICU\nadmission show that the model outperforms all existing outcome prediction\nmodels, achieving PR-AUC of 0.891 (95$%$ CI: 0.878 - 0.969) in predicting\nmortality in ICU and general ward settings and 0.908 (95$%$ CI: 0.870-0.935) in\npredicting ICU admission.",
          "link": "http://arxiv.org/abs/2011.09361",
          "publishedOn": "2021-06-14T01:38:55.206Z",
          "wordCount": 708,
          "title": "A Knowledge Distillation Ensemble Framework for Predicting Short and Long-term Hospitalisation Outcomes from Electronic Health Records Data. (arXiv:2011.09361v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1806.06142",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Strazzeri_F/0/1/0/all/0/1\">Fabio Strazzeri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanchez_Garcia_R/0/1/0/all/0/1\">Rub&#xe9;n J. S&#xe1;nchez-Garc&#xed;a</a>",
          "description": "Kleinberg introduced three natural clustering properties, or axioms, and\nshowed they cannot be simultaneously satisfied by any clustering algorithm. We\npresent a new clustering property, Monotonic Consistency, which avoids the\nwell-known problematic behaviour of Kleinberg's Consistency axiom, and the\nimpossibility result. Namely, we describe a clustering algorithm, Morse\nClustering, inspired by Morse Theory in Differential Topology, which satisfies\nKleinberg's original axioms with Consistency replaced by Monotonic Consistency.\nMorse clustering uncovers the underlying flow structure on a set or graph and\nreturns a partition into trees representing basins of attraction of critical\nvertices. We also generalise Kleinberg's axiomatic approach to sparse graphs,\nshowing an impossibility result for Consistency, and a possibility result for\nMonotonic Consistency and Morse clustering.",
          "link": "http://arxiv.org/abs/1806.06142",
          "publishedOn": "2021-06-14T01:38:55.197Z",
          "wordCount": 620,
          "title": "Possibility results for graph clustering: A novel consistency axiom. (arXiv:1806.06142v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.00344",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Konobeev_M/0/1/0/all/0/1\">Mikhail Konobeev</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kuzborskij_I/0/1/0/all/0/1\">Ilja Kuzborskij</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Szepesvari_C/0/1/0/all/0/1\">Csaba Szepesv&#xe1;ri</a>",
          "description": "A key problem in the theory of meta-learning is to understand how the task\ndistributions influence transfer risk, the expected error of a meta-learner on\na new task drawn from the unknown task distribution. In this paper, focusing on\nfixed design linear regression with Gaussian noise and a Gaussian task (or\nparameter) distribution, we give distribution-dependent lower bounds on the\ntransfer risk of any algorithm, while we also show that a novel, weighted\nversion of the so-called biased regularized regression method is able to match\nthese lower bounds up to a fixed constant factor. Notably, the weighting is\nderived from the covariance of the Gaussian task distribution. Altogether, our\nresults provide a precise characterization of the difficulty of meta-learning\nin this Gaussian setting. While this problem setting may appear simple, we show\nthat it is rich enough to unify the \"parameter sharing\" and \"representation\nlearning\" streams of meta-learning; in particular, representation learning is\nobtained as the special case when the covariance matrix of the task\ndistribution is unknown. For this case we propose to adopt the EM method, which\nis shown to enjoy efficient updates in our case. The paper is completed by an\nempirical study of EM. In particular, our experimental results show that the EM\nalgorithm can attain the lower bound as the number of tasks grows, while the\nalgorithm is also successful in competing with its alternatives when used in a\nrepresentation learning context.",
          "link": "http://arxiv.org/abs/2011.00344",
          "publishedOn": "2021-06-14T01:38:55.190Z",
          "wordCount": 679,
          "title": "A Distribution-Dependent Analysis of Meta-Learning. (arXiv:2011.00344v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.09536",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1\">Hongyao Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Z/0/1/0/all/0/1\">Zhaopeng Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_J/0/1/0/all/0/1\">Jianye Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Graves_D/0/1/0/all/0/1\">Daniel Graves</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_H/0/1/0/all/0/1\">Hangyu Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wulong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yaodong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1\">Changmin Yu</a>",
          "description": "We study Policy-extended Value Function Approximator (PeVFA) in Reinforcement\nLearning (RL), which extends conventional value function approximator (VFA) to\ntake as input not only the state (and action) but also an explicit policy\nrepresentation. Such an extension enables PeVFA to preserve values of multiple\npolicies at the same time and brings an appealing characteristic, i.e.,\n\\emph{value generalization among policies}. We formally analyze the value\ngeneralization under Generalized Policy Iteration (GPI). From theoretical and\nempirical lens, we show that generalized value estimates offered by PeVFA may\nhave lower initial approximation error to true values of successive policies,\nwhich is expected to improve consecutive value approximation during GPI. Based\non above clues, we introduce a new form of GPI with PeVFA which leverages the\nvalue generalization along policy improvement path. Moreover, we propose a\nrepresentation learning framework for RL policy, providing several approaches\nto learn effective policy embeddings from policy network parameters or\nstate-action pairs. In our experiments, we evaluate the efficacy of value\ngeneralization offered by PeVFA and policy representation learning in several\nOpenAI Gym continuous control tasks. For a representative instance of algorithm\nimplementation, Proximal Policy Optimization (PPO) re-implemented under the\nparadigm of GPI with PeVFA achieves about 40\\% performance improvement on its\nvanilla counterpart in most environments.",
          "link": "http://arxiv.org/abs/2010.09536",
          "publishedOn": "2021-06-14T01:38:55.182Z",
          "wordCount": 699,
          "title": "Represent Your Own Policies: Reinforcement Learning with Policy-extended Value Function Approximator. (arXiv:2010.09536v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06442",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Su_X/0/1/0/all/0/1\">Xiu Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_S/0/1/0/all/0/1\">Shan You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_M/0/1/0/all/0/1\">Mingkai Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Fei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_C/0/1/0/all/0/1\">Chen Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Changshui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chang Xu</a>",
          "description": "In one-shot weight sharing for NAS, the weights of each operation (at each\nlayer) are supposed to be identical for all architectures (paths) in the\nsupernet. However, this rules out the possibility of adjusting operation\nweights to cater for different paths, which limits the reliability of the\nevaluation results. In this paper, instead of counting on a single supernet, we\nintroduce $K$-shot supernets and take their weights for each operation as a\ndictionary. The operation weight for each path is represented as a convex\ncombination of items in a dictionary with a simplex code. This enables a matrix\napproximation of the stand-alone weight matrix with a higher rank ($K>1$). A\n\\textit{simplex-net} is introduced to produce architecture-customized code for\neach path. As a result, all paths can adaptively learn how to share weights in\nthe $K$-shot supernets and acquire corresponding weights for better evaluation.\n$K$-shot supernets and simplex-net can be iteratively trained, and we further\nextend the search to the channel dimension. Extensive experiments on benchmark\ndatasets validate that K-shot NAS significantly improves the evaluation\naccuracy of paths and thus brings in impressive performance improvements.",
          "link": "http://arxiv.org/abs/2106.06442",
          "publishedOn": "2021-06-14T01:38:55.163Z",
          "wordCount": 631,
          "title": "K-shot NAS: Learnable Weight-Sharing for NAS with K-shot Supernets. (arXiv:2106.06442v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2006.03204",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Petsiuk_V/0/1/0/all/0/1\">Vitali Petsiuk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_R/0/1/0/all/0/1\">Rajiv Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manjunatha_V/0/1/0/all/0/1\">Varun Manjunatha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morariu_V/0/1/0/all/0/1\">Vlad I. Morariu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehra_A/0/1/0/all/0/1\">Ashutosh Mehra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ordonez_V/0/1/0/all/0/1\">Vicente Ordonez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saenko_K/0/1/0/all/0/1\">Kate Saenko</a>",
          "description": "We propose D-RISE, a method for generating visual explanations for the\npredictions of object detectors. Utilizing the proposed similarity metric that\naccounts for both localization and categorization aspects of object detection\nallows our method to produce saliency maps that show image areas that most\naffect the prediction. D-RISE can be considered \"black-box\" in the software\ntesting sense, as it only needs access to the inputs and outputs of an object\ndetector. Compared to gradient-based methods, D-RISE is more general and\nagnostic to the particular type of object detector being tested, and does not\nneed knowledge of the inner workings of the model. We show that D-RISE can be\neasily applied to different object detectors including one-stage detectors such\nas YOLOv3 and two-stage detectors such as Faster-RCNN. We present a detailed\nanalysis of the generated visual explanations to highlight the utilization of\ncontext and possible biases learned by object detectors.",
          "link": "http://arxiv.org/abs/2006.03204",
          "publishedOn": "2021-06-14T01:38:55.155Z",
          "wordCount": 633,
          "title": "Black-box Explanation of Object Detectors via Saliency Maps. (arXiv:2006.03204v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06513",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Alberti_G/0/1/0/all/0/1\">Giovanni S. Alberti</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vito_E/0/1/0/all/0/1\">Ernesto De Vito</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lassas_M/0/1/0/all/0/1\">Matti Lassas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ratti_L/0/1/0/all/0/1\">Luca Ratti</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Santacesaria_M/0/1/0/all/0/1\">Matteo Santacesaria</a>",
          "description": "In this work, we consider the linear inverse problem $y=Ax+\\epsilon$, where\n$A\\colon X\\to Y$ is a known linear operator between the separable Hilbert\nspaces $X$ and $Y$, $x$ is a random variable in $X$ and $\\epsilon$ is a\nzero-mean random process in $Y$. This setting covers several inverse problems\nin imaging including denoising, deblurring, and X-ray tomography. Within the\nclassical framework of regularization, we focus on the case where the\nregularization functional is not given a priori but learned from data. Our\nfirst result is a characterization of the optimal generalized Tikhonov\nregularizer, with respect to the mean squared error. We find that it is\ncompletely independent of the forward operator $A$ and depends only on the mean\nand covariance of $x$. Then, we consider the problem of learning the\nregularizer from a finite training set in two different frameworks: one\nsupervised, based on samples of both $x$ and $y$, and one unsupervised, based\nonly on samples of $x$. In both cases, we prove generalization bounds, under\nsome weak assumptions on the distribution of $x$ and $\\epsilon$, including the\ncase of sub-Gaussian variables. Our bounds hold in infinite-dimensional spaces,\nthereby showing that finer and finer discretizations do not make this learning\nproblem harder. The results are validated through numerical simulations.",
          "link": "http://arxiv.org/abs/2106.06513",
          "publishedOn": "2021-06-14T01:38:55.148Z",
          "wordCount": 646,
          "title": "Learning the optimal regularizer for inverse problems. (arXiv:2106.06513v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2010.05690",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+B_L/0/1/0/all/0/1\">Lalith Bharadwaj B</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boddeda_R/0/1/0/all/0/1\">Rohit Boddeda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+K_S/0/1/0/all/0/1\">Sai Vardhan K</a>, <a href=\"http://arxiv.org/find/cs/1/au:+G_M/0/1/0/all/0/1\">Madhu G</a>",
          "description": "The issue of COVID-19, increasing with a massive mortality rate. This led to\nthe WHO declaring it as a pandemic. In this situation, it is crucial to perform\nefficient and fast diagnosis. The reverse transcript polymerase chain reaction\n(RTPCR) test is conducted to detect the presence of SARS-CoV-2. This test is\ntime-consuming and instead chest CT (or Chest X-ray) can be used for a fast and\naccurate diagnosis. Automated diagnosis is considered to be important as it\nreduces human effort and provides accurate and low-cost tests. The\ncontributions of our research are three-fold. First, it is aimed to analyse the\nbehaviour and performance of variant vision models ranging from Inception to\nNAS networks with the appropriate fine-tuning procedure. Second, the behaviour\nof these models is visually analysed by plotting CAMs for individual networks\nand determining classification performance with AUCROC curves. Thirdly, stacked\nensembles techniques are imparted to provide higher generalisation on combining\nthe fine-tuned models, in which six ensemble neural networks are designed by\ncombining the existing fine-tuned networks. Implying these stacked ensembles\nprovides a great generalization to the models. The ensemble model designed by\ncombining all the fine-tuned networks obtained a state-of-the-art accuracy\nscore of 99.17%. The precision and recall for the COVID-19 class are 99.99% and\n89.79% respectively, which resembles the robustness of the stacked ensembles.",
          "link": "http://arxiv.org/abs/2010.05690",
          "publishedOn": "2021-06-14T01:38:55.141Z",
          "wordCount": 741,
          "title": "COVID-19 Classification Using Staked Ensembles: A Comprehensive Analysis. (arXiv:2010.05690v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.01668",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fanghui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xiaolin Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yudong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suykens_J/0/1/0/all/0/1\">Johan A.K. Suykens</a>",
          "description": "In this paper, we develop a quadrature framework for large-scale kernel\nmachines via a numerical integration representation. Considering that the\nintegration domain and measure of typical kernels, e.g., Gaussian kernels,\narc-cosine kernels, are fully symmetric, we leverage deterministic fully\nsymmetric interpolatory rules to efficiently compute quadrature nodes and\nassociated weights for kernel approximation. The developed interpolatory rules\nare able to reduce the number of needed nodes while retaining a high\napproximation accuracy. Further, we randomize the above deterministic rules by\nthe classical Monte-Carlo sampling and control variates techniques with two\nmerits: 1) The proposed stochastic rules make the dimension of the feature\nmapping flexibly varying, such that we can control the discrepancy between the\noriginal and approximate kernels by tuning the dimnension. 2) Our stochastic\nrules have nice statistical properties of unbiasedness and variance reduction\nwith fast convergence rate. In addition, we elucidate the relationship between\nour deterministic/stochastic interpolatory rules and current quadrature rules\nfor kernel approximation, including the sparse grids quadrature and stochastic\nspherical-radial rules, thereby unifying these methods under our framework.\nExperimental results on several benchmark datasets show that our methods\ncompare favorably with other representative kernel approximation based methods.",
          "link": "http://arxiv.org/abs/2011.01668",
          "publishedOn": "2021-06-14T01:38:55.132Z",
          "wordCount": 660,
          "title": "Towards a Unified Quadrature Framework for Large-Scale Kernel Machines. (arXiv:2011.01668v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06440",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Michalkiewicz_M/0/1/0/all/0/1\">Mateusz Michalkiewicz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsogkas_S/0/1/0/all/0/1\">Stavros Tsogkas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parisot_S/0/1/0/all/0/1\">Sarah Parisot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baktashmotlagh_M/0/1/0/all/0/1\">Mahsa Baktashmotlagh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eriksson_A/0/1/0/all/0/1\">Anders Eriksson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belilovsky_E/0/1/0/all/0/1\">Eugene Belilovsky</a>",
          "description": "The impressive performance of deep convolutional neural networks in\nsingle-view 3D reconstruction suggests that these models perform non-trivial\nreasoning about the 3D structure of the output space. Recent work has\nchallenged this belief, showing that, on standard benchmarks, complex\nencoder-decoder architectures perform similarly to nearest-neighbor baselines\nor simple linear decoder models that exploit large amounts of per-category\ndata. However, building large collections of 3D shapes for supervised training\nis a laborious process; a more realistic and less constraining task is\ninferring 3D shapes for categories with few available training examples,\ncalling for a model that can successfully generalize to novel object classes.\nIn this work we experimentally demonstrate that naive baselines fail in this\nfew-shot learning setting, in which the network must learn informative shape\npriors for inference of new categories. We propose three ways to learn a\nclass-specific global shape prior, directly from data. Using these techniques,\nwe are able to capture multi-scale information about the 3D shape, and account\nfor intra-class variability by virtue of an implicit compositional structure.\nExperiments on the popular ShapeNet dataset show that our method outperforms a\nzero-shot baseline by over 40%, and the current state-of-the-art by over 10%,\nin terms of relative performance, in the few-shot setting.12",
          "link": "http://arxiv.org/abs/2106.06440",
          "publishedOn": "2021-06-14T01:38:55.110Z",
          "wordCount": 655,
          "title": "Learning Compositional Shape Priors for Few-Shot 3D Reconstruction. (arXiv:2106.06440v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2010.03485",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Saad_F/0/1/0/all/0/1\">Feras A. Saad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rinard_M/0/1/0/all/0/1\">Martin C. Rinard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mansinghka_V/0/1/0/all/0/1\">Vikash K. Mansinghka</a>",
          "description": "We present the Sum-Product Probabilistic Language (SPPL), a new probabilistic\nprogramming language that automatically delivers exact solutions to a broad\nrange of probabilistic inference queries. SPPL translates probabilistic\nprograms into sum-product expressions, a new symbolic representation and\nassociated semantic domain that extends standard sum-product networks to\nsupport mixed-type distributions, numeric transformations, logical formulas,\nand pointwise and set-valued constraints. We formalize SPPL via a novel\ntranslation strategy from probabilistic programs to sum-product expressions and\ngive sound exact algorithms for conditioning on and computing probabilities of\nevents. SPPL imposes a collection of restrictions on probabilistic programs to\nensure they can be translated into sum-product expressions, which allow the\nsystem to leverage new techniques for improving the scalability of translation\nand inference by automatically exploiting probabilistic structure. We implement\na prototype of SPPL with a modular architecture and evaluate it on benchmarks\nthe system targets, showing that it obtains up to 3500x speedups over\nstate-of-the-art symbolic systems on tasks such as verifying the fairness of\ndecision tree classifiers, smoothing hidden Markov models, conditioning\ntransformed random variables, and computing rare event probabilities.",
          "link": "http://arxiv.org/abs/2010.03485",
          "publishedOn": "2021-06-14T01:38:55.101Z",
          "wordCount": 689,
          "title": "SPPL: Probabilistic Programming with Fast Exact Symbolic Inference. (arXiv:2010.03485v3 [cs.PL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.14986",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kopetzki_A/0/1/0/all/0/1\">Anna-Kathrin Kopetzki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Charpentier_B/0/1/0/all/0/1\">Bertrand Charpentier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zugner_D/0/1/0/all/0/1\">Daniel Z&#xfc;gner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giri_S/0/1/0/all/0/1\">Sandhya Giri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gunnemann_S/0/1/0/all/0/1\">Stephan G&#xfc;nnemann</a>",
          "description": "Dirichlet-based uncertainty (DBU) models are a recent and promising class of\nuncertainty-aware models. DBU models predict the parameters of a Dirichlet\ndistribution to provide fast, high-quality uncertainty estimates alongside with\nclass predictions. In this work, we present the first large-scale, in-depth\nstudy of the robustness of DBU models under adversarial attacks. Our results\nsuggest that uncertainty estimates of DBU models are not robust w.r.t. three\nimportant tasks: (1) indicating correctly and wrongly classified samples; (2)\ndetecting adversarial examples; and (3) distinguishing between in-distribution\n(ID) and out-of-distribution (OOD) data. Additionally, we explore the first\napproaches to make DBU models more robust. While adversarial training has a\nminor effect, our median smoothing based approach significantly increases\nrobustness of DBU models.",
          "link": "http://arxiv.org/abs/2010.14986",
          "publishedOn": "2021-06-14T01:38:55.092Z",
          "wordCount": 586,
          "title": "Evaluating Robustness of Predictive Uncertainty Estimation: Are Dirichlet-based Models Reliable?. (arXiv:2010.14986v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.03294",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cai_T/0/1/0/all/0/1\">Tianle Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1\">Shengjie Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1\">Keyulu Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1\">Di He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tie-Yan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Liwei Wang</a>",
          "description": "Normalization is known to help the optimization of deep neural networks.\nCuriously, different architectures require specialized normalization methods.\nIn this paper, we study what normalization is effective for Graph Neural\nNetworks (GNNs). First, we adapt and evaluate the existing methods from other\ndomains to GNNs. Faster convergence is achieved with InstanceNorm compared to\nBatchNorm and LayerNorm. We provide an explanation by showing that InstanceNorm\nserves as a preconditioner for GNNs, but such preconditioning effect is weaker\nwith BatchNorm due to the heavy batch noise in graph datasets. Second, we show\nthat the shift operation in InstanceNorm results in an expressiveness\ndegradation of GNNs for highly regular graphs. We address this issue by\nproposing GraphNorm with a learnable shift. Empirically, GNNs with GraphNorm\nconverge faster compared to GNNs using other normalization. GraphNorm also\nimproves the generalization of GNNs, achieving better performance on graph\nclassification benchmarks.",
          "link": "http://arxiv.org/abs/2009.03294",
          "publishedOn": "2021-06-14T01:38:55.085Z",
          "wordCount": 633,
          "title": "GraphNorm: A Principled Approach to Accelerating Graph Neural Network Training. (arXiv:2009.03294v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06483",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Krishnamurthy_S/0/1/0/all/0/1\">Sanath Kumar Krishnamurthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Athey_S/0/1/0/all/0/1\">Susan Athey</a>",
          "description": "We study the problem of model selection for contextual bandits, in which the\nalgorithm must balance the bias-variance trade-off for model estimation while\nalso balancing the exploration-exploitation trade-off. In this paper, we\npropose the first reduction of model selection in contextual bandits to offline\nmodel selection oracles, allowing for flexible general purpose algorithms with\ncomputational requirements no worse than those for model selection for\nregression. Our main result is a new model selection guarantee for stochastic\ncontextual bandits. When one of the classes in our set is realizable, up to a\nlogarithmic dependency on the number of classes, our algorithm attains optimal\nrealizability-based regret bounds for that class under one of two conditions:\nif the time-horizon is large enough, or if an assumption that helps with\ndetecting misspecification holds. Hence our algorithm adapts to the complexity\nof this unknown class. Even when this realizable class is known, we prove\nimproved regret guarantees in early rounds by relying on simpler model classes\nfor those rounds and hence further establish the importance of model selection\nin contextual bandits.",
          "link": "http://arxiv.org/abs/2106.06483",
          "publishedOn": "2021-06-14T01:38:55.078Z",
          "wordCount": 612,
          "title": "Optimal Model Selection in Contextual Bandits with Many Classes via Offline Oracles. (arXiv:2106.06483v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2006.04647",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mellor_J/0/1/0/all/0/1\">Joseph Mellor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turner_J/0/1/0/all/0/1\">Jack Turner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Storkey_A/0/1/0/all/0/1\">Amos Storkey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crowley_E/0/1/0/all/0/1\">Elliot J. Crowley</a>",
          "description": "The time and effort involved in hand-designing deep neural networks is\nimmense. This has prompted the development of Neural Architecture Search (NAS)\ntechniques to automate this design. However, NAS algorithms tend to be slow and\nexpensive; they need to train vast numbers of candidate networks to inform the\nsearch process. This could be alleviated if we could partially predict a\nnetwork's trained accuracy from its initial state. In this work, we examine the\noverlap of activations between datapoints in untrained networks and motivate\nhow this can give a measure which is usefully indicative of a network's trained\nperformance. We incorporate this measure into a simple algorithm that allows us\nto search for powerful networks without any training in a matter of seconds on\na single GPU, and verify its effectiveness on NAS-Bench-101, NAS-Bench-201,\nNATS-Bench, and Network Design Spaces. Our approach can be readily combined\nwith more expensive search methods; we examine a simple adaptation of\nregularised evolutionary search. Code for reproducing our experiments is\navailable at https://github.com/BayesWatch/nas-without-training.",
          "link": "http://arxiv.org/abs/2006.04647",
          "publishedOn": "2021-06-14T01:38:55.057Z",
          "wordCount": 649,
          "title": "Neural Architecture Search without Training. (arXiv:2006.04647v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.03310",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sundaram_R/0/1/0/all/0/1\">Ravi Sundaram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vullikanti_A/0/1/0/all/0/1\">Anil Vullikanti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haifeng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_F/0/1/0/all/0/1\">Fan Yao</a>",
          "description": "The study of strategic or adversarial manipulation of testing data to fool a\nclassifier has attracted much recent attention. Most previous works have\nfocused on two extreme situations where any testing data point either is\ncompletely adversarial or always equally prefers the positive label. In this\npaper, we generalize both of these through a unified framework for strategic\nclassification, and introduce the notion of strategic VC-dimension (SVC) to\ncapture the PAC-learnability in our general strategic setup. SVC provably\ngeneralizes the recent concept of adversarial VC-dimension (AVC) introduced by\nCullina et al. arXiv:1806.01471. We instantiate our framework for the\nfundamental strategic linear classification problem. We fully characterize: (1)\nthe statistical learnability of linear classifiers by pinning down its SVC; (2)\nits computational tractability by pinning down the complexity of the empirical\nrisk minimization problem. Interestingly, the SVC of linear classifiers is\nalways upper bounded by its standard VC-dimension. This characterization also\nstrictly generalizes the AVC bound for linear classifiers in arXiv:1806.01471.",
          "link": "http://arxiv.org/abs/2012.03310",
          "publishedOn": "2021-06-14T01:38:55.050Z",
          "wordCount": 627,
          "title": "PAC-Learning for Strategic Classification. (arXiv:2012.03310v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06529",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pleiss_G/0/1/0/all/0/1\">Geoff Pleiss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cunningham_J/0/1/0/all/0/1\">John P. Cunningham</a>",
          "description": "Large width limits have been a recent focus of deep learning research: modulo\ncomputational practicalities, do wider networks outperform narrower ones?\nAnswering this question has been challenging, as conventional networks gain\nrepresentational power with width, potentially masking any negative effects.\nOur analysis in this paper decouples capacity and width via the generalization\nof neural networks to Deep Gaussian Processes (Deep GP), a class of\nhierarchical models that subsume neural nets. In doing so, we aim to understand\nhow width affects standard neural networks once they have sufficient capacity\nfor a given modeling task. Our theoretical and empirical results on Deep GP\nsuggest that large width is generally detrimental to hierarchical models.\nSurprisingly, we prove that even nonparametric Deep GP converge to Gaussian\nprocesses, effectively becoming shallower without any increase in\nrepresentational power. The posterior, which corresponds to a mixture of\ndata-adaptable basis functions, becomes less data-dependent with width. Our\ntail analysis demonstrates that width and depth have opposite effects: depth\naccentuates a model's non-Gaussianity, while width makes models increasingly\nGaussian. We find there is a \"sweet spot\" that maximizes test set performance\nbefore the limiting GP behavior prevents adaptability, occurring at width = 1\nor width = 2 for nonparametric Deep GP. These results make strong predictions\nabout the same phenomenon in conventional neural networks: we show empirically\nthat many neural network architectures need 10 - 500 hidden units for\nsufficient capacity - depending on the dataset - but further width degrades\ntest performance.",
          "link": "http://arxiv.org/abs/2106.06529",
          "publishedOn": "2021-06-14T01:38:55.044Z",
          "wordCount": 680,
          "title": "The Limitations of Large Width in Neural Networks: A Deep Gaussian Process Perspective. (arXiv:2106.06529v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2011.06125",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Boussioux_L/0/1/0/all/0/1\">L&#xe9;onard Boussioux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_C/0/1/0/all/0/1\">Cynthia Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guenais_T/0/1/0/all/0/1\">Th&#xe9;o Gu&#xe9;nais</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bertsimas_D/0/1/0/all/0/1\">Dimitris Bertsimas</a>",
          "description": "This paper describes a machine learning (ML) framework for tropical cyclone\nintensity and track forecasting, combining multiple distinct ML techniques and\nutilizing diverse data sources. Our framework, which we refer to as Hurricast\n(HURR), is built upon the combination of distinct data processing techniques\nusing gradient-boosted trees and novel encoder-decoder architectures, including\nCNN, GRU and Transformers components. We propose a deep-feature extractor\nmethodology to mix spatial-temporal data with statistical data efficiently. Our\nmultimodal framework unleashes the potential of making forecasts based on a\nwide range of data sources, including historical storm data, and visual data\nsuch as reanalysis atmospheric images. We evaluate our models with current\noperational forecasts in North Atlantic and Eastern Pacific basins on 2016-2019\nfor 24-hour lead time, and show our models consistently outperform\nstatistical-dynamical models and compete with the best dynamical models, while\ncomputing forecasts in seconds. Furthermore, the inclusion of Hurricast into an\noperational forecast consensus model leads to a significant improvement of 5% -\n15% over NHC's official forecast, thus highlighting the complementary\nproperties with existing approaches. In summary, our work demonstrates that\ncombining different data sources and distinct machine learning methodologies\ncan lead to superior tropical cyclone forecasting. We hope that this work opens\nthe door for further use of machine learning in meteorological forecasting.",
          "link": "http://arxiv.org/abs/2011.06125",
          "publishedOn": "2021-06-14T01:38:55.036Z",
          "wordCount": 683,
          "title": "Hurricane Forecasting: A Novel Multimodal Machine Learning Framework. (arXiv:2011.06125v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06362",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kinnunen_T/0/1/0/all/0/1\">Tomi Kinnunen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nautsch_A/0/1/0/all/0/1\">Andreas Nautsch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sahidullah_M/0/1/0/all/0/1\">Md Sahidullah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Evans_N/0/1/0/all/0/1\">Nicholas Evans</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Todisco_M/0/1/0/all/0/1\">Massimiliano Todisco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Delgado_H/0/1/0/all/0/1\">H&#xe9;ctor Delgado</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamagishi_J/0/1/0/all/0/1\">Junichi Yamagishi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Kong Aik Lee</a>",
          "description": "Whether it be for results summarization, or the analysis of classifier\nfusion, some means to compare different classifiers can often provide\nilluminating insight into their behaviour, (dis)similarity or complementarity.\nWe propose a simple method to derive 2D representation from detection scores\nproduced by an arbitrary set of binary classifiers in response to a common\ndataset. Based upon rank correlations, our method facilitates a visual\ncomparison of classifiers with arbitrary scores and with close relation to\nreceiver operating characteristic (ROC) and detection error trade-off (DET)\nanalyses. While the approach is fully versatile and can be applied to any\ndetection task, we demonstrate the method using scores produced by automatic\nspeaker verification and voice anti-spoofing systems. The former are produced\nby a Gaussian mixture model system trained with VoxCeleb data whereas the\nlatter stem from submissions to the ASVspoof 2019 challenge.",
          "link": "http://arxiv.org/abs/2106.06362",
          "publishedOn": "2021-06-14T01:38:55.030Z",
          "wordCount": 608,
          "title": "Visualizing Classifier Adjacency Relations: A Case Study in Speaker Verification and Voice Anti-Spoofing. (arXiv:2106.06362v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/1905.12346",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fanuel_M/0/1/0/all/0/1\">Micha&#xeb;l Fanuel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schreurs_J/0/1/0/all/0/1\">Joachim Schreurs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suykens_J/0/1/0/all/0/1\">Johan A.K. Suykens</a>",
          "description": "Selecting diverse and important items, called landmarks, from a large set is\na problem of interest in machine learning. As a specific example, in order to\ndeal with large training sets, kernel methods often rely on low rank matrix\nNystr\\\"om approximations based on the selection or sampling of landmarks. In\nthis context, we propose a deterministic and a randomized adaptive algorithm\nfor selecting landmark points within a training data set, which are related to\nthe minima of a sequence of kernelized Christoffel functions. Beyond the known\nconnection between Christoffel functions and leverage scores, a connection of\nour method with determinantal point processes (DPPs) is also explained. Namely,\nour construction promotes diversity among important landmark points in a way\nsimilar to DPPs. Also, we explain how our randomized adaptive algorithm can\ninfluence the accuracy of Kernel Ridge Regression.",
          "link": "http://arxiv.org/abs/1905.12346",
          "publishedOn": "2021-06-14T01:38:55.012Z",
          "wordCount": 610,
          "title": "Nystr\\\"om landmark sampling and regularized Christoffel functions. (arXiv:1905.12346v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.07249",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Creager_E/0/1/0/all/0/1\">Elliot Creager</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jacobsen_J/0/1/0/all/0/1\">J&#xf6;rn-Henrik Jacobsen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zemel_R/0/1/0/all/0/1\">Richard Zemel</a>",
          "description": "Learning models that gracefully handle distribution shifts is central to\nresearch on domain generalization, robust optimization, and fairness. A\npromising formulation is domain-invariant learning, which identifies the key\nissue of learning which features are domain-specific versus domain-invariant.\nAn important assumption in this area is that the training examples are\npartitioned into \"domains\" or \"environments\". Our focus is on the more common\nsetting where such partitions are not provided. We propose EIIL, a general\nframework for domain-invariant learning that incorporates Environment Inference\nto directly infer partitions that are maximally informative for downstream\nInvariant Learning. We show that EIIL outperforms invariant learning methods on\nthe CMNIST benchmark without using environment labels, and significantly\noutperforms ERM on worst-group performance in the Waterbirds and CivilComments\ndatasets. Finally, we establish connections between EIIL and algorithmic\nfairness, which enables EIIL to improve accuracy and calibration in a fair\nprediction problem.",
          "link": "http://arxiv.org/abs/2010.07249",
          "publishedOn": "2021-06-14T01:38:55.006Z",
          "wordCount": 611,
          "title": "Environment Inference for Invariant Learning. (arXiv:2010.07249v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2002.09773",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ergen_T/0/1/0/all/0/1\">Tolga Ergen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pilanci_M/0/1/0/all/0/1\">Mert Pilanci</a>",
          "description": "We study regularized deep neural networks (DNNs) and introduce a convex\nanalytic framework to characterize the structure of the hidden layers. We show\nthat a set of optimal hidden layer weights for a norm regularized DNN training\nproblem can be explicitly found as the extreme points of a convex set. For the\nspecial case of deep linear networks, we prove that each optimal weight matrix\naligns with the previous layers via duality. More importantly, we apply the\nsame characterization to deep ReLU networks with whitened data and prove the\nsame weight alignment holds. As a corollary, we also prove that norm\nregularized deep ReLU networks yield spline interpolation for one-dimensional\ndatasets which was previously known only for two-layer networks. Furthermore,\nwe provide closed-form solutions for the optimal layer weights when data is\nrank-one or whitened. The same analysis also applies to architectures with\nbatch normalization even for arbitrary data. Therefore, we obtain a complete\nexplanation for a recent empirical observation termed Neural Collapse where\nclass means collapse to the vertices of a simplex equiangular tight frame.",
          "link": "http://arxiv.org/abs/2002.09773",
          "publishedOn": "2021-06-14T01:38:54.999Z",
          "wordCount": 655,
          "title": "Revealing the Structure of Deep Neural Networks via Convex Duality. (arXiv:2002.09773v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.08844",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jinghan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boloor_A/0/1/0/all/0/1\">Adith Boloor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakrabarti_A/0/1/0/all/0/1\">Ayan Chakrabarti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vorobeychik_Y/0/1/0/all/0/1\">Yevgeniy Vorobeychik</a>",
          "description": "There is considerable evidence that deep neural networks are vulnerable to\nadversarial perturbations applied directly to their digital inputs. However, it\nremains an open question whether this translates to vulnerabilities in real\nsystems. For example, an attack on self-driving cars would in practice entail\nmodifying the driving environment, which then impacts the video inputs to the\ncar's controller, thereby indirectly leading to incorrect driving decisions.\nSuch attacks require accounting for system dynamics and tracking viewpoint\nchanges. We propose a scalable approach for finding adversarial modifications\nof a simulated autonomous driving environment using a differentiable\napproximation for the mapping from environmental modifications (rectangles on\nthe road) to the corresponding video inputs to the controller neural network.\nGiven the parameters of the rectangles, our proposed differentiable mapping\ncomposites them onto pre-recorded video streams of the original environment,\naccounting for geometric and color variations. Moreover, we propose a multiple\ntrajectory sampling approach that enables our attacks to be robust to a car's\nself-correcting behavior. When combined with a neural network-based controller,\nour approach allows the design of adversarial modifications through end-to-end\ngradient-based optimization. Using the Carla autonomous driving simulator, we\nshow that our approach is significantly more scalable and far more effective at\nidentifying autonomous vehicle vulnerabilities in simulation experiments than a\nstate-of-the-art approach based on Bayesian Optimization.",
          "link": "http://arxiv.org/abs/2010.08844",
          "publishedOn": "2021-06-14T01:38:54.988Z",
          "wordCount": 694,
          "title": "Finding Physical Adversarial Examples for Autonomous Driving with Fast and Differentiable Image Compositing. (arXiv:2010.08844v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.16617",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Acharyya_R/0/1/0/all/0/1\">Rupam Acharyya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chattoraj_A/0/1/0/all/0/1\">Ankani Chattoraj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Boyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1\">Shouman Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stefankovic_D/0/1/0/all/0/1\">Daniel Stefankovic</a>",
          "description": "Deep learning architectures with a huge number of parameters are often\ncompressed using pruning techniques to ensure computational efficiency of\ninference during deployment. Despite multitude of empirical advances, there is\na lack of theoretical understanding of the effectiveness of different pruning\nmethods. We inspect different pruning techniques under the statistical\nmechanics formulation of a teacher-student framework and derive their\ngeneralization error (GE) bounds. It has been shown that Determinantal Point\nProcess (DPP) based node pruning method is notably superior to competing\napproaches when tested on real datasets. Using GE bounds in the aforementioned\nsetup we provide theoretical guarantees for their empirical observations.\nAnother consistent finding in literature is that sparse neural networks (edge\npruned) generalize better than dense neural networks (node pruned) for a fixed\nnumber of parameters. We use our theoretical setup to prove this finding and\nshow that even the baseline random edge pruning method performs better than the\nDPP node pruning method. We also validate this empirically on real datasets.",
          "link": "http://arxiv.org/abs/2006.16617",
          "publishedOn": "2021-06-14T01:38:54.980Z",
          "wordCount": 639,
          "title": "Statistical Mechanical Analysis of Neural Network Pruning. (arXiv:2006.16617v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.07615",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ath_G/0/1/0/all/0/1\">George De Ath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Everson_R/0/1/0/all/0/1\">Richard M. Everson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fieldsend_J/0/1/0/all/0/1\">Jonathan E. Fieldsend</a>",
          "description": "Batch Bayesian optimisation (BO) is a successful technique for the\noptimisation of expensive black-box functions. Asynchronous BO can reduce\nwallclock time by starting a new evaluation as soon as another finishes, thus\nmaximising resource utilisation. To maximise resource allocation, we develop a\nnovel asynchronous BO method, AEGiS (Asynchronous $\\epsilon$-Greedy Global\nSearch) that combines greedy search, exploiting the surrogate's mean\nprediction, with Thompson sampling and random selection from the approximate\nPareto set describing the trade-off between exploitation (surrogate mean\nprediction) and exploration (surrogate posterior variance). We demonstrate\nempirically the efficacy of AEGiS on synthetic benchmark problems,\nmeta-surrogate hyperparameter tuning problems and real-world problems, showing\nthat AEGiS generally outperforms existing methods for asynchronous BO. When a\nsingle worker is available performance is no worse than BO using expected\nimprovement.",
          "link": "http://arxiv.org/abs/2010.07615",
          "publishedOn": "2021-06-14T01:38:54.962Z",
          "wordCount": 625,
          "title": "Asynchronous \\epsilon-Greedy Bayesian Optimisation. (arXiv:2010.07615v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06478",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Liwei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beek_A/0/1/0/all/0/1\">Anton van Beek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Da_D/0/1/0/all/0/1\">Daicong Da</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_Y/0/1/0/all/0/1\">Yu-Chin Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_P/0/1/0/all/0/1\">Ping Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wei Chen</a>",
          "description": "For natural frequency optimization of engineering structures, cellular\ncomposites have been shown to possess an edge over solid. However, existing\nmultiscale design methods for cellular composites are either computationally\nexhaustive or confined to a single class of microstructures. In this paper, we\npropose a data-driven topology optimization (TO) approach to enable the\nmultiscale design of cellular structures with various choices of microstructure\nclasses. The key component is a newly proposed latent-variable Gaussian process\n(LVGP) model through which different classes of microstructures are mapped into\na low-dimensional continuous latent space. It provides an interpretable\ndistance metric between classes and captures their effects on the homogenized\nstiffness tensors. By introducing latent vectors as design variables, a\ndifferentiable transition of stiffness matrix between classes can be easily\nachieved with an analytical gradient. After integrating LVGP with the\ndensity-based TO, an efficient data-driven cellular composite optimization\nprocess is developed to enable concurrent exploration of microstructure\nconcepts and the associated volume fractions for natural frequency\noptimization. Examples reveal that the proposed cellular designs with\nmulticlass microstructures achieve higher natural frequencies than both\nsingle-scale and single-class designs. This framework can be easily extended to\nother multi-scale TO problems, such as thermal compliance and dynamic response\noptimization.",
          "link": "http://arxiv.org/abs/2106.06478",
          "publishedOn": "2021-06-14T01:38:54.954Z",
          "wordCount": 659,
          "title": "Data-Driven Multiscale Design of Cellular Composites with Multiclass Microstructures for Natural Frequency Maximization. (arXiv:2106.06478v1 [cs.CE])"
        },
        {
          "id": "http://arxiv.org/abs/2006.08816",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Cheng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheung_G/0/1/0/all/0/1\">Gene Cheung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1\">Wei Hu</a>",
          "description": "Given a convex and differentiable objective $Q(\\M)$ for a real symmetric\nmatrix $\\M$ in the positive definite (PD) cone -- used to compute Mahalanobis\ndistances -- we propose a fast general metric learning framework that is\nentirely projection-free. We first assume that $\\M$ resides in a space $\\cS$ of\ngeneralized graph Laplacian matrices corresponding to balanced signed graphs.\n$\\M \\in \\cS$ that is also PD is called a graph metric matrix. Unlike low-rank\nmetric matrices common in the literature, $\\cS$ includes the important\ndiagonal-only matrices as a special case. The key theorem to circumvent full\neigen-decomposition and enable fast metric matrix optimization is Gershgorin\ndisc perfect alignment (GDPA): given $\\M \\in \\cS$ and diagonal matrix $\\S$,\nwhere $S_{ii} = 1/v_i$ and $\\v$ is $\\M$'s first eigenvector, we prove that\nGershgorin disc left-ends of similarity transform $\\B = \\S \\M \\S^{-1}$ are\nperfectly aligned at the smallest eigenvalue $\\lambda_{\\min}$. Using this\ntheorem, we replace the PD cone constraint in the metric learning problem with\ntightest possible linear constraints per iteration, so that the alternating\noptimization of the diagonal / off-diagonal terms in $\\M$ can be solved\nefficiently as linear programs via the Frank-Wolfe method. We update $\\v$ using\nLocally Optimal Block Preconditioned Conjugate Gradient (LOBPCG) with warm\nstart as entries in $\\M$ are optimized successively. Experiments show that our\ngraph metric optimization is significantly faster than cone-projection schemes,\nand produces competitive binary classification performance.",
          "link": "http://arxiv.org/abs/2006.08816",
          "publishedOn": "2021-06-14T01:38:54.527Z",
          "wordCount": 731,
          "title": "Signed Graph Metric Learning via Gershgorin Disc Perfect Alignment. (arXiv:2006.08816v6 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.08166",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Makarova_A/0/1/0/all/0/1\">Anastasia Makarova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1\">Huibin Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perrone_V/0/1/0/all/0/1\">Valerio Perrone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klein_A/0/1/0/all/0/1\">Aaron Klein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faddoul_J/0/1/0/all/0/1\">Jean Baptiste Faddoul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krause_A/0/1/0/all/0/1\">Andreas Krause</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seeger_M/0/1/0/all/0/1\">Matthias Seeger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Archambeau_C/0/1/0/all/0/1\">Cedric Archambeau</a>",
          "description": "Tuning machine learning models with Bayesian optimization (BO) is a\nsuccessful strategy to find good hyperparameters. BO defines an iterative\nprocedure where a cross-validated metric is evaluated on promising\nhyperparameters. In practice, however, an improvement of the validation metric\nmay not translate in better predictive performance on a test set, especially\nwhen tuning models trained on small datasets. In other words, unlike\nconventional wisdom dictates, BO can overfit. In this paper, we carry out the\nfirst systematic investigation of overfitting in BO and demonstrate that this\nissue is serious, yet often overlooked in practice. We propose a novel\ncriterion to early stop BO, which aims to maintain the solution quality while\nsaving the unnecessary iterations that can lead to overfitting. Experiments on\nreal-world hyperparameter optimization problems show that our approach\neffectively meets these goals and is more adaptive comparing to baselines.",
          "link": "http://arxiv.org/abs/2104.08166",
          "publishedOn": "2021-06-14T01:38:54.519Z",
          "wordCount": 622,
          "title": "Overfitting in Bayesian Optimization: an empirical study and early-stopping solution. (arXiv:2104.08166v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.11883",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pan_L/0/1/0/all/0/1\">Ling Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rashid_T/0/1/0/all/0/1\">Tabish Rashid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1\">Bei Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1\">Longbo Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Whiteson_S/0/1/0/all/0/1\">Shimon Whiteson</a>",
          "description": "Tackling overestimation in $Q$-learning is an important problem that has been\nextensively studied in single-agent reinforcement learning, but has received\ncomparatively little attention in the multi-agent setting. In this work, we\nempirically demonstrate that QMIX, a popular $Q$-learning algorithm for\ncooperative multi-agent reinforcement learning (MARL), suffers from a more\nsevere overestimation in practice than previously acknowledged, and is not\nmitigated by existing approaches. We rectify this with a novel\nregularization-based update scheme that penalizes large joint action-values\nthat deviate from a baseline and demonstrate its effectiveness in stabilizing\nlearning. Furthermore, we propose to employ a softmax operator, which we\nefficiently approximate in a novel way in the multi-agent setting, to further\nreduce the potential overestimation bias. Our approach, Regularized Softmax\n(RES) Deep Multi-Agent $Q$-Learning, is general and can be applied to any\n$Q$-learning based MARL algorithm. We demonstrate that, when applied to QMIX,\nRES avoids severe overestimation and significantly improves performance,\nyielding state-of-the-art results in a variety of cooperative multi-agent\ntasks, including the challenging StarCraft II micromanagement benchmarks.",
          "link": "http://arxiv.org/abs/2103.11883",
          "publishedOn": "2021-06-14T01:38:54.513Z",
          "wordCount": 622,
          "title": "Regularized Softmax Deep Multi-Agent $Q$-Learning. (arXiv:2103.11883v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.07788",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rozemberczki_B/0/1/0/all/0/1\">Benedek Rozemberczki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scherer_P/0/1/0/all/0/1\">Paul Scherer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yixuan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panagopoulos_G/0/1/0/all/0/1\">George Panagopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riedel_A/0/1/0/all/0/1\">Alexander Riedel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Astefanoaei_M/0/1/0/all/0/1\">Maria Astefanoaei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiss_O/0/1/0/all/0/1\">Oliver Kiss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beres_F/0/1/0/all/0/1\">Ferenc Beres</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lopez_G/0/1/0/all/0/1\">Guzm&#xe1;n L&#xf3;pez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Collignon_N/0/1/0/all/0/1\">Nicolas Collignon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarkar_R/0/1/0/all/0/1\">Rik Sarkar</a>",
          "description": "We present PyTorch Geometric Temporal a deep learning framework combining\nstate-of-the-art machine learning algorithms for neural spatiotemporal signal\nprocessing. The main goal of the library is to make temporal geometric deep\nlearning available for researchers and machine learning practitioners in a\nunified easy-to-use framework. PyTorch Geometric Temporal was created with\nfoundations on existing libraries in the PyTorch eco-system, streamlined neural\nnetwork layer definitions, temporal snapshot generators for batching, and\nintegrated benchmark datasets. These features are illustrated with a\ntutorial-like case study. Experiments demonstrate the predictive performance of\nthe models implemented in the library on real world problems such as\nepidemiological forecasting, ridehail demand prediction and web-traffic\nmanagement. Our sensitivity analysis of runtime shows that the framework can\npotentially operate on web-scale datasets with rich temporal features and\nspatial structure.",
          "link": "http://arxiv.org/abs/2104.07788",
          "publishedOn": "2021-06-14T01:38:54.496Z",
          "wordCount": 627,
          "title": "PyTorch Geometric Temporal: Spatiotemporal Signal Processing with Neural Machine Learning Models. (arXiv:2104.07788v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.06469",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Hao Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jianing Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_G/0/1/0/all/0/1\">Guangxiang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_Z/0/1/0/all/0/1\">Zhizhou Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chongjie Zhang</a>",
          "description": "Episodic memory-based methods can rapidly latch onto past successful\nstrategies by a non-parametric memory and improve sample efficiency of\ntraditional reinforcement learning. However, little effort is put into the\ncontinuous domain, where a state is never visited twice, and previous episodic\nmethods fail to efficiently aggregate experience across trajectories. To\naddress this problem, we propose Generalizable Episodic Memory (GEM), which\neffectively organizes the state-action values of episodic memory in a\ngeneralizable manner and supports implicit planning on memorized trajectories.\nGEM utilizes a double estimator to reduce the overestimation bias induced by\nvalue propagation in the planning process. Empirical evaluation shows that our\nmethod significantly outperforms existing trajectory-based methods on various\nMuJoCo continuous control tasks. To further show the general applicability, we\nevaluate our method on Atari games with discrete action space, which also shows\na significant improvement over baseline algorithms.",
          "link": "http://arxiv.org/abs/2103.06469",
          "publishedOn": "2021-06-14T01:38:54.489Z",
          "wordCount": 606,
          "title": "Generalizable Episodic Memory for Deep Reinforcement Learning. (arXiv:2103.06469v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.07878",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chitra_U/0/1/0/all/0/1\">Uthsav Chitra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_K/0/1/0/all/0/1\">Kimberly Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jasper C.H. Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raphael_B/0/1/0/all/0/1\">Benjamin J. Raphael</a>",
          "description": "Anomaly estimation, or the problem of finding a subset of a dataset that\ndiffers from the rest of the dataset, is a classic problem in machine learning\nand data mining. In both theoretical work and in applications, the anomaly is\nassumed to have a specific structure defined by membership in an\n$\\textit{anomaly family}$. For example, in temporal data the anomaly family may\nbe time intervals, while in network data the anomaly family may be connected\nsubgraphs. The most prominent approach for anomaly estimation is to compute the\nMaximum Likelihood Estimator (MLE) of the anomaly; however, it was recently\nobserved that for normally distributed data, the MLE is a $\\textit{biased}$\nestimator for some anomaly families. In this work, we demonstrate that in the\nnormal means setting, the bias of the MLE depends on the size of the anomaly\nfamily. We prove that if the number of sets in the anomaly family that contain\nthe anomaly is sub-exponential, then the MLE is asymptotically unbiased. We\nalso provide empirical evidence that the converse is true: if the number of\nsuch sets is exponential, then the MLE is asymptotically biased. Our analysis\nunifies a number of earlier results on the bias of the MLE for specific anomaly\nfamilies. Next, we derive a new anomaly estimator using a mixture model, and we\nprove that our anomaly estimator is asymptotically unbiased regardless of the\nsize of the anomaly family. We illustrate the advantages of our estimator\nversus the MLE on disease outbreak and highway traffic data.",
          "link": "http://arxiv.org/abs/2007.07878",
          "publishedOn": "2021-06-14T01:38:54.483Z",
          "wordCount": 731,
          "title": "Quantifying and Reducing Bias in Maximum Likelihood Estimation of Structured Anomalies. (arXiv:2007.07878v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.00100",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Young-min Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_Y/0/1/0/all/0/1\">Young-chul Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_K/0/1/0/all/0/1\">Kwangjin Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeon_M/0/1/0/all/0/1\">Moongu Jeon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Seong-Whan Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pedrycz_W/0/1/0/all/0/1\">Witold Pedrycz</a>",
          "description": "In this paper, we propose a highly practical fully online multi-object\ntracking and segmentation (MOTS) method that uses instance segmentation results\nas an input. The proposed method is based on the Gaussian mixture probability\nhypothesis density (GMPHD) filter, a hierarchical data association (HDA), and a\nmask-based affinity fusion (MAF) model to achieve high-performance online\ntracking. The HDA consists of two associations: segment-to-track and\ntrack-to-track associations. One affinity, for position and motion, is computed\nby using the GMPHD filter, and the other affinity, for appearance is computed\nby using the responses from a single object tracker such as a kernalized\ncorrelation filter. These two affinities are simply fused by using a\nscore-level fusion method such as min-max normalization referred to as MAF. In\naddition, to reduce the number of false positive segments, we adopt mask\nIoU-based merging (mask merging). The proposed MOTS framework with the key\nmodules: HDA, MAF, and mask merging, is easily extensible to simultaneously\ntrack multiple types of objects with CPU only execution in parallel processing.\nIn addition, the developed framework only requires simple parameter tuning\nunlike many existing MOTS methods that need intensive hyperparameter\noptimization. In the experiments on the two popular MOTS datasets, the key\nmodules show some improvements. For instance, ID-switch decreases by more than\nhalf compared to a baseline method in the training sets. In conclusion, our\ntracker achieves state-of-the-art MOTS performance in the test sets.",
          "link": "http://arxiv.org/abs/2009.00100",
          "publishedOn": "2021-06-14T01:38:54.476Z",
          "wordCount": 708,
          "title": "Online Multi-Object Tracking and Segmentation with GMPHD Filter and Mask-based Affinity Fusion. (arXiv:2009.00100v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06427",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Biggio_L/0/1/0/all/0/1\">Luca Biggio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bendinelli_T/0/1/0/all/0/1\">Tommaso Bendinelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neitz_A/0/1/0/all/0/1\">Alexander Neitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lucchi_A/0/1/0/all/0/1\">Aurelien Lucchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parascandolo_G/0/1/0/all/0/1\">Giambattista Parascandolo</a>",
          "description": "Symbolic equations are at the core of scientific discovery. The task of\ndiscovering the underlying equation from a set of input-output pairs is called\nsymbolic regression. Traditionally, symbolic regression methods use\nhand-designed strategies that do not improve with experience. In this paper, we\nintroduce the first symbolic regression method that leverages large scale\npre-training. We procedurally generate an unbounded set of equations, and\nsimultaneously pre-train a Transformer to predict the symbolic equation from a\ncorresponding set of input-output-pairs. At test time, we query the model on a\nnew set of points and use its output to guide the search for the equation. We\nshow empirically that this approach can re-discover a set of well-known\nphysical equations, and that it improves over time with more data and compute.",
          "link": "http://arxiv.org/abs/2106.06427",
          "publishedOn": "2021-06-14T01:38:54.470Z",
          "wordCount": 559,
          "title": "Neural Symbolic Regression that Scales. (arXiv:2106.06427v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2010.04157",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Sitan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koehler_F/0/1/0/all/0/1\">Frederic Koehler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moitra_A/0/1/0/all/0/1\">Ankur Moitra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yau_M/0/1/0/all/0/1\">Morris Yau</a>",
          "description": "In this work we revisit two classic high-dimensional online learning\nproblems, namely linear regression and contextual bandits, from the perspective\nof adversarial robustness. Existing works in algorithmic robust statistics make\nstrong distributional assumptions that ensure that the input data is evenly\nspread out or comes from a nice generative model. Is it possible to achieve\nstrong robustness guarantees even without distributional assumptions\naltogether, where the sequence of tasks we are asked to solve is adaptively and\nadversarially chosen?\n\nWe answer this question in the affirmative for both linear regression and\ncontextual bandits. In fact our algorithms succeed where conventional methods\nfail. In particular we show strong lower bounds against Huber regression and\nmore generally any convex M-estimator. Our approach is based on a novel\nalternating minimization scheme that interleaves ordinary least-squares with a\nsimple convex program that finds the optimal reweighting of the distribution\nunder a spectral constraint. Our results obtain essentially optimal dependence\non the contamination level $\\eta$, reach the optimal breakdown point, and\nnaturally apply to infinite dimensional settings where the feature vectors are\nrepresented implicitly via a kernel map.",
          "link": "http://arxiv.org/abs/2010.04157",
          "publishedOn": "2021-06-14T01:38:54.453Z",
          "wordCount": 672,
          "title": "Online and Distribution-Free Robustness: Regression and Contextual Bandits with Huber Contamination. (arXiv:2010.04157v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06445",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dinh_T/0/1/0/all/0/1\">Tuan Dinh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Kangwook Lee</a>",
          "description": "Inspired by a new coded computation algorithm for invertible functions, we\npropose Coded-InvNet a new approach to design resilient prediction serving\nsystems that can gracefully handle stragglers or node failures. Coded-InvNet\nleverages recent findings in the deep learning literature such as invertible\nneural networks, Manifold Mixup, and domain translation algorithms, identifying\ninteresting research directions that span across machine learning and systems.\nOur experimental results show that Coded-InvNet can outperform existing\napproaches, especially when the compute resource overhead is as low as 10%. For\ninstance, without knowing which of the ten workers is going to fail, our\nalgorithm can design a backup task so that it can correctly recover the missing\nprediction result with an accuracy of 85.9%, significantly outperforming the\nprevious SOTA by 32.5%.",
          "link": "http://arxiv.org/abs/2106.06445",
          "publishedOn": "2021-06-14T01:38:54.446Z",
          "wordCount": 546,
          "title": "Coded-InvNet for Resilient Prediction Serving Systems. (arXiv:2106.06445v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2006.15327",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bar_A/0/1/0/all/0/1\">Amir Bar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Herzig_R/0/1/0/all/0/1\">Roei Herzig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaolong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rohrbach_A/0/1/0/all/0/1\">Anna Rohrbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chechik_G/0/1/0/all/0/1\">Gal Chechik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Darrell_T/0/1/0/all/0/1\">Trevor Darrell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Globerson_A/0/1/0/all/0/1\">Amir Globerson</a>",
          "description": "Videos of actions are complex signals containing rich compositional structure\nin space and time. Current video generation methods lack the ability to\ncondition the generation on multiple coordinated and potentially simultaneous\ntimed actions. To address this challenge, we propose to represent the actions\nin a graph structure called Action Graph and present the new ``Action Graph To\nVideo'' synthesis task. Our generative model for this task (AG2Vid)\ndisentangles motion and appearance features, and by incorporating a scheduling\nmechanism for actions facilitates a timely and coordinated video generation. We\ntrain and evaluate AG2Vid on the CATER and Something-Something V2 datasets, and\nshow that the resulting videos have better visual quality and semantic\nconsistency compared to baselines. Finally, our model demonstrates zero-shot\nabilities by synthesizing novel compositions of the learned actions. For code\nand pretrained models, see the project page https://roeiherz.github.io/AG2Video",
          "link": "http://arxiv.org/abs/2006.15327",
          "publishedOn": "2021-06-14T01:38:54.436Z",
          "wordCount": 631,
          "title": "Compositional Video Synthesis with Action Graphs. (arXiv:2006.15327v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.10618",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_S/0/1/0/all/0/1\">Sushant Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jabbari_S/0/1/0/all/0/1\">Shahin Jabbari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_C/0/1/0/all/0/1\">Chirag Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Upadhyay_S/0/1/0/all/0/1\">Sohini Upadhyay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhiwei Steven Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lakkaraju_H/0/1/0/all/0/1\">Himabindu Lakkaraju</a>",
          "description": "As machine learning black boxes are increasingly being deployed in critical\ndomains such as healthcare and criminal justice, there has been a growing\nemphasis on developing techniques for explaining these black boxes in a post\nhoc manner. In this work, we analyze two popular post hoc interpretation\ntechniques: SmoothGrad which is a gradient based method, and a variant of LIME\nwhich is a perturbation based method. More specifically, we derive explicit\nclosed form expressions for the explanations output by these two methods and\nshow that they both converge to the same explanation in expectation, i.e., when\nthe number of perturbed samples used by these methods is large. We then\nleverage this connection to establish other desirable properties, such as\nrobustness, for these techniques. We also derive finite sample complexity\nbounds for the number of perturbations required for these methods to converge\nto their expected explanation. Finally, we empirically validate our theory\nusing extensive experimentation on both synthetic and real world datasets.",
          "link": "http://arxiv.org/abs/2102.10618",
          "publishedOn": "2021-06-14T01:38:54.429Z",
          "wordCount": 649,
          "title": "Towards the Unification and Robustness of Perturbation and Gradient Based Explanations. (arXiv:2102.10618v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.08085",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yucheng Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sa_C/0/1/0/all/0/1\">Christopher De Sa</a>",
          "description": "Decentralization is a promising method of scaling up parallel machine\nlearning systems. In this paper, we provide a tight lower bound on the\niteration complexity for such methods in a stochastic non-convex setting. Our\nlower bound reveals a theoretical gap in known convergence rates of many\nexisting decentralized training algorithms, such as D-PSGD. We prove by\nconstruction this lower bound is tight and achievable. Motivated by our\ninsights, we further propose DeTAG, a practical gossip-style decentralized\nalgorithm that achieves the lower bound with only a logarithm gap. Empirically,\nwe compare DeTAG with other decentralized algorithms on image classification\ntasks, and we show DeTAG enjoys faster convergence compared to baselines,\nespecially on unshuffled data and in sparse networks.",
          "link": "http://arxiv.org/abs/2006.08085",
          "publishedOn": "2021-06-14T01:38:54.408Z",
          "wordCount": 574,
          "title": "Optimal Complexity in Decentralized Training. (arXiv:2006.08085v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06524",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Serie_E/0/1/0/all/0/1\">Emmanuel S&#xe9;ri&#xe9;</a>",
          "description": "Wax is what you put on a surfboard to avoid slipping. It is an essential tool\nto go surfing... We introduce WAX-ML a research-oriented Python library\nproviding tools to design powerful machine learning algorithms and feedback\nloops working on streaming data. It strives to complement JAX with tools\ndedicated to time series. WAX-ML makes JAX-based programs easy to use for\nend-users working with pandas and xarray for data manipulation. It provides a\nsimple mechanism for implementing feedback loops, allows the implementation of\nonline learning and reinforcement learning algorithms with functions, and makes\nthem easy to integrate by end-users working with the object-oriented\nreinforcement learning framework from the Gym library. It is released with an\nApache open-source license on GitHub at https://github.com/eserie/wax-ml.",
          "link": "http://arxiv.org/abs/2106.06524",
          "publishedOn": "2021-06-14T01:38:54.386Z",
          "wordCount": 560,
          "title": "WAX-ML: A Python library for machine learning and feedback loops on streaming data. (arXiv:2106.06524v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2002.04137",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zifan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jongho Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rekatsinas_T/0/1/0/all/0/1\">Theodoros Rekatsinas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tzamos_C/0/1/0/all/0/1\">Christos Tzamos</a>",
          "description": "We study the problem of robust mean estimation and introduce a novel Hamming\ndistance-based measure of distribution shift for coordinate-level corruptions.\nWe show that this measure yields adversary models that capture more realistic\ncorruptions than those used in prior works, and present an\ninformation-theoretic analysis of robust mean estimation in these settings. We\nshow that for structured distributions, methods that leverage the structure\nyield information theoretically more accurate mean estimation. We also focus on\npractical algorithms for robust mean estimation and study when data\ncleaning-inspired approaches that first fix corruptions in the input data and\nthen perform robust mean estimation can match the information theoretic bounds\nof our analysis. We finally demonstrate experimentally that this two-step\napproach outperforms structure-agnostic robust estimation and provides accurate\nmean estimation even for high-magnitude corruption.",
          "link": "http://arxiv.org/abs/2002.04137",
          "publishedOn": "2021-06-14T01:38:54.378Z",
          "wordCount": 624,
          "title": "On Robust Mean Estimation under Coordinate-level Corruption. (arXiv:2002.04137v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06401",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Belilovsky_E/0/1/0/all/0/1\">Eugene Belilovsky</a> (MILA), <a href=\"http://arxiv.org/find/cs/1/au:+Leconte_L/0/1/0/all/0/1\">Louis Leconte</a> (MLIA, CMAP), <a href=\"http://arxiv.org/find/cs/1/au:+Caccia_L/0/1/0/all/0/1\">Lucas Caccia</a> (MILA), <a href=\"http://arxiv.org/find/cs/1/au:+Eickenberg_M/0/1/0/all/0/1\">Michael Eickenberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oyallon_E/0/1/0/all/0/1\">Edouard Oyallon</a> (MLIA)",
          "description": "A commonly cited inefficiency of neural network training using\nback-propagation is the update locking problem: each layer must wait for the\nsignal to propagate through the full network before updating. Several\nalternatives that can alleviate this issue have been proposed. In this context,\nwe consider a simple alternative based on minimal feedback, which we call\nDecoupled Greedy Learning (DGL). It is based on a classic greedy relaxation of\nthe joint training objective, recently shown to be effective in the context of\nConvolutional Neural Networks (CNNs) on large-scale image classification. We\nconsider an optimization of this objective that permits us to decouple the\nlayer training, allowing for layers or modules in networks to be trained with a\npotentially linear parallelization. With the use of a replay buffer we show\nthat this approach can be extended to asynchronous settings, where modules can\noperate and continue to update with possibly large communication delays. To\naddress bandwidth and memory issues we propose an approach based on online\nvector quantization. This allows to drastically reduce the communication\nbandwidth between modules and required memory for replay buffers. We show\ntheoretically and empirically that this approach converges and compare it to\nthe sequential solvers. We demonstrate the effectiveness of DGL against\nalternative approaches on the CIFAR-10 dataset and on the large-scale ImageNet\ndataset.",
          "link": "http://arxiv.org/abs/2106.06401",
          "publishedOn": "2021-06-14T01:38:54.371Z",
          "wordCount": 672,
          "title": "Decoupled Greedy Learning of CNNs for Synchronous and Asynchronous Distributed Learning. (arXiv:2106.06401v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06510",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Stephenson_W/0/1/0/all/0/1\">William T. Stephenson</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ghosh_S/0/1/0/all/0/1\">Soumya Ghosh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nguyen_T/0/1/0/all/0/1\">Tin D. Nguyen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yurochkin_M/0/1/0/all/0/1\">Mikhail Yurochkin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Deshpande_S/0/1/0/all/0/1\">Sameer K. Deshpande</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Broderick_T/0/1/0/all/0/1\">Tamara Broderick</a>",
          "description": "Gaussian processes (GPs) are used to make medical and scientific decisions,\nincluding in cardiac care and monitoring of carbon dioxide emissions. But the\nchoice of GP kernel is often somewhat arbitrary. In particular, uncountably\nmany kernels typically align with qualitative prior knowledge (e.g. function\nsmoothness or stationarity). But in practice, data analysts choose among a\nhandful of convenient standard kernels (e.g. squared exponential). In the\npresent work, we ask: Would decisions made with a GP differ under other,\nqualitatively interchangeable kernels? We show how to formulate this\nsensitivity analysis as a constrained optimization problem over a\nfinite-dimensional space. We can then use standard optimizers to identify\nsubstantive changes in relevant decisions made with a GP. We demonstrate in\nboth synthetic and real-world examples that decisions made with a GP can\nexhibit substantial sensitivity to kernel choice, even when prior draws are\nqualitatively interchangeable to a user.",
          "link": "http://arxiv.org/abs/2106.06510",
          "publishedOn": "2021-06-14T01:38:54.364Z",
          "wordCount": 585,
          "title": "Measuring the sensitivity of Gaussian processes to kernel choice. (arXiv:2106.06510v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2006.12297",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Nitanda_A/0/1/0/all/0/1\">Atsushi Nitanda</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Suzuki_T/0/1/0/all/0/1\">Taiji Suzuki</a>",
          "description": "We analyze the convergence of the averaged stochastic gradient descent for\noverparameterized two-layer neural networks for regression problems. It was\nrecently found that a neural tangent kernel (NTK) plays an important role in\nshowing the global convergence of gradient-based methods under the NTK regime,\nwhere the learning dynamics for overparameterized neural networks can be almost\ncharacterized by that for the associated reproducing kernel Hilbert space\n(RKHS). However, there is still room for a convergence rate analysis in the NTK\nregime. In this study, we show that the averaged stochastic gradient descent\ncan achieve the minimax optimal convergence rate, with the global convergence\nguarantee, by exploiting the complexities of the target function and the RKHS\nassociated with the NTK. Moreover, we show that the target function specified\nby the NTK of a ReLU network can be learned at the optimal convergence rate\nthrough a smooth approximation of a ReLU network under certain conditions.",
          "link": "http://arxiv.org/abs/2006.12297",
          "publishedOn": "2021-06-14T01:38:54.357Z",
          "wordCount": 604,
          "title": "Optimal Rates for Averaged Stochastic Gradient Descent under Neural Tangent Kernel Regime. (arXiv:2006.12297v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1904.03116",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Souri_Y/0/1/0/all/0/1\">Yaser Souri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fayyaz_M/0/1/0/all/0/1\">Mohsen Fayyaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Minciullo_L/0/1/0/all/0/1\">Luca Minciullo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Francesca_G/0/1/0/all/0/1\">Gianpiero Francesca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gall_J/0/1/0/all/0/1\">Juergen Gall</a>",
          "description": "Action segmentation is the task of predicting the actions for each frame of a\nvideo. As obtaining the full annotation of videos for action segmentation is\nexpensive, weakly supervised approaches that can learn only from transcripts\nare appealing. In this paper, we propose a novel end-to-end approach for weakly\nsupervised action segmentation based on a two-branch neural network. The two\nbranches of our network predict two redundant but different representations for\naction segmentation and we propose a novel mutual consistency (MuCon) loss that\nenforces the consistency of the two redundant representations. Using the MuCon\nloss together with a loss for transcript prediction, our proposed approach\nachieves the accuracy of state-of-the-art approaches while being $14$ times\nfaster to train and $20$ times faster during inference. The MuCon loss proves\nbeneficial even in the fully supervised setting.",
          "link": "http://arxiv.org/abs/1904.03116",
          "publishedOn": "2021-06-14T01:38:54.351Z",
          "wordCount": 638,
          "title": "Fast Weakly Supervised Action Segmentation Using Mutual Consistency. (arXiv:1904.03116v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.03573",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_Y/0/1/0/all/0/1\">Yizi Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liu_M/0/1/0/all/0/1\">Meimei Liu</a>",
          "description": "Recent years have witnessed rapid developments on collaborative filtering\ntechniques for improving the performance of recommender systems due to the\ngrowing need of companies to help users discover new and relevant items.\nHowever, the majority of existing literature focuses on delivering items which\nmatch the user model learned from users' past preferences. A good\nrecommendation model is expected to recommend items that are known to enjoy and\nitems that are novel to try. In this work, we introduce an\nexploitation-exploration motivated variational auto-encoder (XploVAE) to\ncollaborative filtering. To facilitate personalized recommendations, we\nconstruct user-specific subgraphs, which contain the first-order proximity\ncapturing observed user-item interactions for exploitation and the high-order\nproximity for exploration. A hierarchical latent space model is utilized to\nlearn the personalized item embedding for a given user, along with the\npopulation distribution of all user subgraphs. Finally, experimental results on\nvarious real-world datasets clearly demonstrate the effectiveness of our\nproposed model on leveraging the exploitation and exploration recommendation\ntasks.",
          "link": "http://arxiv.org/abs/2006.03573",
          "publishedOn": "2021-06-14T01:38:54.335Z",
          "wordCount": 623,
          "title": "Exploration-Exploitation Motivated Variational Auto-Encoder for Recommender Systems. (arXiv:2006.03573v4 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06536",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jarboui_F/0/1/0/all/0/1\">Firas Jarboui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perchet_V/0/1/0/all/0/1\">Vianney Perchet</a>",
          "description": "We introduce a new procedure to neuralize unsupervised Hidden Markov Models\nin the continuous case. This provides higher flexibility to solve problems with\nunderlying latent variables. This approach is evaluated on both synthetic and\nreal data. On top of generating likely model parameters with comparable\nperformances to off-the-shelf neural architecture (LSTMs, GRUs,..), the\nobtained results are easily interpretable.",
          "link": "http://arxiv.org/abs/2106.06536",
          "publishedOn": "2021-06-14T01:38:54.329Z",
          "wordCount": 484,
          "title": "Unsupervised Neural Hidden Markov Models with a Continuous latent state space. (arXiv:2106.06536v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06515",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhiyuan/0/1/0/all/0/1\">Zhiyuan</a> (Jerry)Lin, <a href=\"http://arxiv.org/find/cs/1/au:+Sheng_H/0/1/0/all/0/1\">Hao Sheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goel_S/0/1/0/all/0/1\">Sharad Goel</a>",
          "description": "In settings ranging from weather forecasts to political prognostications to\nfinancial projections, probability estimates of future binary outcomes often\nevolve over time. For example, the estimated likelihood of rain on a specific\nday changes by the hour as new information becomes available. Given a\ncollection of such probability paths, we introduce a Bayesian framework --\nwhich we call the Gaussian latent information martingale, or GLIM -- for\nmodeling the structure of dynamic predictions over time. Suppose, for example,\nthat the likelihood of rain in a week is 50%, and consider two hypothetical\nscenarios. In the first, one expects the forecast is equally likely to become\neither 25% or 75% tomorrow; in the second, one expects the forecast to stay\nconstant for the next several days. A time-sensitive decision-maker might\nselect a course of action immediately in the latter scenario, but may postpone\ntheir decision in the former, knowing that new information is imminent. We\nmodel these trajectories by assuming predictions update according to a latent\nprocess of information flow, which is inferred from historical data. In\ncontrast to general methods for time series analysis, this approach preserves\nthe martingale structure of probability paths and better quantifies future\nuncertainties around probability paths. We show that GLIM outperforms three\npopular baseline methods, producing better estimated posterior probability path\ndistributions measured by three different metrics. By elucidating the dynamic\nstructure of predictions over time, we hope to help individuals make more\ninformed choices.",
          "link": "http://arxiv.org/abs/2106.06515",
          "publishedOn": "2021-06-14T01:38:54.322Z",
          "wordCount": 671,
          "title": "Probability Paths and the Structure of Predictions over Time. (arXiv:2106.06515v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06498",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Scrugli_M/0/1/0/all/0/1\">Matteo Antonio Scrugli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Loi_D/0/1/0/all/0/1\">Daniela Loi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raffo_L/0/1/0/all/0/1\">Luigi Raffo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meloni_P/0/1/0/all/0/1\">Paolo Meloni</a>",
          "description": "The Internet of Medical Things (IoMT) paradigm is becoming mainstream in\nmultiple clinical trials and healthcare procedures. It relies on novel very\naccurate and compact sensing devices and communication infrastructures, opening\npreviously unmatched possibilities of implementing data collection and\ncontinuous patient monitoring. Nevertheless, to fully exploit the potential of\nthis technology, some steps forwards are needed. First, the edge-computing\nparadigm must be added to the picture. A certain level of near-sensor\nprocessing has to be enabled, to improve the scalability, portability,\nreliability, responsiveness of the IoMT nodes. Second, novel, increasingly\naccurate, data analysis algorithms, such as those based on artificial\nintelligence and Deep Learning, must be exploited. To reach these objectives,\ndesigners, programmers of IoMT nodes, have to face challenging optimization\ntasks, in order to execute fairly complex computing tasks on low-power wearable\nand portable processing systems, with tight power and battery lifetime budgets.\nIn this work, we explore the implementation of cognitive data analysis\nalgorithm on resource-constrained computing platforms. To minimize power\nconsumption, we add an adaptivity layer that dynamically manages the hardware\nand software configuration of the device to adapt it at runtime to the required\noperating mode. We have assessed our approach on a use-case using a\nconvolutional neural network to classify electrocardiogram (ECG) traces on a\nlow-power microcontroller. Our experimental results show that adapting the node\nsetup to the workload at runtime can save up to 50% power consumption and a\nquantized neural network reaches an accuracy value higher than 98% for\narrhythmia disorders detection on MIT-BIH Arrhythmia dataset.",
          "link": "http://arxiv.org/abs/2106.06498",
          "publishedOn": "2021-06-14T01:38:54.306Z",
          "wordCount": 700,
          "title": "An adaptive cognitive sensor node for ECG monitoring in the Internet of Medical Things. (arXiv:2106.06498v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2006.04988",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Voynov_A/0/1/0/all/0/1\">Andrey Voynov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morozov_S/0/1/0/all/0/1\">Stanislav Morozov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Babenko_A/0/1/0/all/0/1\">Artem Babenko</a>",
          "description": "The recent rise of unsupervised and self-supervised learning has dramatically\nreduced the dependency on labeled data, providing effective image\nrepresentations for transfer to downstream vision tasks. Furthermore, recent\nworks employed these representations in a fully unsupervised setup for image\nclassification, reducing the need for human labels on the fine-tuning stage as\nwell. This work demonstrates that large-scale unsupervised models can also\nperform a more challenging object segmentation task, requiring neither\npixel-level nor image-level labeling. Namely, we show that recent unsupervised\nGANs allow to differentiate between foreground/background pixels, providing\nhigh-quality saliency masks. By extensive comparison on standard benchmarks, we\noutperform existing unsupervised alternatives for object segmentation,\nachieving new state-of-the-art.",
          "link": "http://arxiv.org/abs/2006.04988",
          "publishedOn": "2021-06-14T01:38:54.298Z",
          "wordCount": 568,
          "title": "Object Segmentation Without Labels with Large-Scale Generative Models. (arXiv:2006.04988v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06523",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Citron_R/0/1/0/all/0/1\">Robert I. Citron</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Jenniskens_P/0/1/0/all/0/1\">Peter Jenniskens</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Watkins_C/0/1/0/all/0/1\">Christopher Watkins</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Sinha_S/0/1/0/all/0/1\">Sravanthi Sinha</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Shah_A/0/1/0/all/0/1\">Amar Shah</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Raissi_C/0/1/0/all/0/1\">Chedy Raissi</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Devillepoix_H/0/1/0/all/0/1\">Hadrien Devillepoix</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Albers_J/0/1/0/all/0/1\">Jim Albers</a>",
          "description": "The recovery of freshly fallen meteorites from tracked and triangulated\nmeteors is critical to determining their source asteroid families. However,\nlocating meteorite fragments in strewn fields remains a challenge with very few\nmeteorites being recovered from the meteors triangulated in past and ongoing\nmeteor camera networks. We examined if locating meteorites can be automated\nusing machine learning and an autonomous drone. Drones can be programmed to fly\na grid search pattern and take systematic pictures of the ground over a large\nsurvey area. Those images can be analyzed using a machine learning classifier\nto identify meteorites in the field among many other features. Here, we\ndescribe a proof-of-concept meteorite classifier that deploys off-line a\ncombination of different convolution neural networks to recognize meteorites\nfrom images taken by drones in the field. The system was implemented in a\nconceptual drone setup and tested in the suspected strewn field of a recent\nmeteorite fall near Walker Lake, Nevada.",
          "link": "http://arxiv.org/abs/2106.06523",
          "publishedOn": "2021-06-14T01:38:54.290Z",
          "wordCount": 620,
          "title": "Recovery of Meteorites Using an Autonomous Drone and Machine Learning. (arXiv:2106.06523v1 [astro-ph.EP])"
        },
        {
          "id": "http://arxiv.org/abs/1909.11294",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Luo_S/0/1/0/all/0/1\">Simon Luo</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Azizi_L/0/1/0/all/0/1\">Lamiae Azizi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sugiyama_M/0/1/0/all/0/1\">Mahito Sugiyama</a>",
          "description": "We present a novel blind source separation (BSS) method, called information\ngeometric blind source separation (IGBSS). Our formulation is based on the\nlog-linear model equipped with a hierarchically structured sample space, which\nhas theoretical guarantees to uniquely recover a set of source signals by\nminimizing the KL divergence from a set of mixed signals. Source signals,\nreceived signals, and mixing matrices are realized as different layers in our\nhierarchical sample space. Our empirical results have demonstrated on images\nand time series data that our approach is superior to well established\ntechniques and is able to separate signals with complex interactions.",
          "link": "http://arxiv.org/abs/1909.11294",
          "publishedOn": "2021-06-14T01:38:54.282Z",
          "wordCount": 575,
          "title": "Hierarchical Probabilistic Model for Blind Source Separation via Legendre Transformation. (arXiv:1909.11294v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.13300",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ryou_W/0/1/0/all/0/1\">Wonryong Ryou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiayu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balunovic_M/0/1/0/all/0/1\">Mislav Balunovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_G/0/1/0/all/0/1\">Gagandeep Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dan_A/0/1/0/all/0/1\">Andrei Dan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vechev_M/0/1/0/all/0/1\">Martin Vechev</a>",
          "description": "We present a scalable and precise verifier for recurrent neural networks,\ncalled Prover based on two novel ideas: (i) a method to compute a set of\npolyhedral abstractions for the non-convex and nonlinear recurrent update\nfunctions by combining sampling, optimization, and Fermat's theorem, and (ii) a\ngradient descent based algorithm for abstraction refinement guided by the\ncertification problem that combines multiple abstractions for each neuron.\nUsing Prover, we present the first study of certifying a non-trivial use case\nof recurrent neural networks, namely speech classification. To achieve this, we\nadditionally develop custom abstractions for the non-linear speech\npreprocessing pipeline. Our evaluation shows that Prover successfully verifies\nseveral challenging recurrent models in computer vision, speech, and motion\nsensor data classification beyond the reach of prior work.",
          "link": "http://arxiv.org/abs/2005.13300",
          "publishedOn": "2021-06-14T01:38:54.275Z",
          "wordCount": 609,
          "title": "Scalable Polyhedral Verification of Recurrent Neural Networks. (arXiv:2005.13300v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06499",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Javed_Z/0/1/0/all/0/1\">Zaynah Javed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brown_D/0/1/0/all/0/1\">Daniel S. Brown</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1\">Satvik Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jerry Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balakrishna_A/0/1/0/all/0/1\">Ashwin Balakrishna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petrik_M/0/1/0/all/0/1\">Marek Petrik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dragan_A/0/1/0/all/0/1\">Anca D. Dragan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldberg_K/0/1/0/all/0/1\">Ken Goldberg</a>",
          "description": "The difficulty in specifying rewards for many real-world problems has led to\nan increased focus on learning rewards from human feedback, such as\ndemonstrations. However, there are often many different reward functions that\nexplain the human feedback, leaving agents with uncertainty over what the true\nreward function is. While most policy optimization approaches handle this\nuncertainty by optimizing for expected performance, many applications demand\nrisk-averse behavior. We derive a novel policy gradient-style robust\noptimization approach, PG-BROIL, that optimizes a soft-robust objective that\nbalances expected performance and risk. To the best of our knowledge, PG-BROIL\nis the first policy optimization algorithm robust to a distribution of reward\nhypotheses which can scale to continuous MDPs. Results suggest that PG-BROIL\ncan produce a family of behaviors ranging from risk-neutral to risk-averse and\noutperforms state-of-the-art imitation learning algorithms when learning from\nambiguous demonstrations by hedging against uncertainty, rather than seeking to\nuniquely identify the demonstrator's reward function.",
          "link": "http://arxiv.org/abs/2106.06499",
          "publishedOn": "2021-06-14T01:38:54.267Z",
          "wordCount": 601,
          "title": "Policy Gradient Bayesian Robust Optimization for Imitation Learning. (arXiv:2106.06499v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06468",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Junchen Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lindenbaum_O/0/1/0/all/0/1\">Ofir Lindenbaum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kluger_Y/0/1/0/all/0/1\">Yuval Kluger</a>",
          "description": "Despite the enormous success of neural networks, they are still hard to\ninterpret and often overfit when applied to low-sample-size (LSS) datasets. To\ntackle these obstacles, we propose a framework for training locally sparse\nneural networks where the local sparsity is learned via a sample-specific\ngating mechanism that identifies the subset of most relevant features for each\nmeasurement. The sample-specific sparsity is predicted via a \\textit{gating}\nnetwork, which is trained in tandem with the \\textit{prediction} network. By\nlearning these subsets and weights of a prediction model, we obtain an\ninterpretable neural network that can handle LSS data and can remove nuisance\nvariables, which are irrelevant for the supervised learning task. Using both\nsynthetic and real-world datasets, we demonstrate that our method outperforms\nstate-of-the-art models when predicting the target function with far fewer\nfeatures per instance.",
          "link": "http://arxiv.org/abs/2106.06468",
          "publishedOn": "2021-06-14T01:38:54.260Z",
          "wordCount": 557,
          "title": "Locally Sparse Networks for Interpretable Predictions. (arXiv:2106.06468v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06333",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yifei Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yezhen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">Wenzhen Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reed_C/0/1/0/all/0/1\">Colorado J. Reed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Che_T/0/1/0/all/0/1\">Tong Che</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dongsheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keutzer_K/0/1/0/all/0/1\">Kurt Keutzer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Han Zhao</a>",
          "description": "The main challenge for domain generalization (DG) is to overcome the\npotential distributional shift between multiple training domains and unseen\ntest domains. One popular class of DG algorithms aims to learn representations\nthat have an invariant causal relation across the training domains. However,\ncertain features, called \\emph{pseudo-invariant features}, may be invariant in\nthe training domain but not the test domain and can substantially decreases the\nperformance of existing algorithms. To address this issue, we propose a novel\nalgorithm, called Invariant Information Bottleneck (IIB), that learns a\nminimally sufficient representation that is invariant across training and\ntesting domains. By minimizing the mutual information between the\nrepresentation and inputs, IIB alleviates its reliance on pseudo-invariant\nfeatures, which is desirable for DG. To verify the effectiveness of the IIB\nprinciple, we conduct extensive experiments on large-scale DG benchmarks. The\nresults show that IIB outperforms invariant learning baseline (e.g. IRM) by an\naverage of 2.8\\% and 3.8\\% accuracy over two evaluation metrics.",
          "link": "http://arxiv.org/abs/2106.06333",
          "publishedOn": "2021-06-14T01:38:54.253Z",
          "wordCount": 596,
          "title": "Invariant Information Bottleneck for Domain Generalization. (arXiv:2106.06333v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06338",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Malezieux_B/0/1/0/all/0/1\">Beno&#xee;t Mal&#xe9;zieux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moreau_T/0/1/0/all/0/1\">Thomas Moreau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kowalski_M/0/1/0/all/0/1\">Matthieu Kowalski</a>",
          "description": "Inverse problems consist in recovering a signal given noisy observations. One\nclassical resolution approach is to leverage sparsity and integrate prior\nknowledge of the signal to the reconstruction algorithm to get a plausible\nsolution. Still, this prior might not be sufficiently adapted to the data. In\nthis work, we study Dictionary and Prior learning from degraded measurements as\na bi-level problem, and we take advantage of unrolled algorithms to solve\napproximate formulations of Synthesis and Analysis. We provide an empirical and\ntheoretical analysis of automatic differentiation for Dictionary Learning to\nunderstand better the pros and cons of unrolling in this context. We find that\nunrolled algorithms speed up the recovery process for a small number of\niterations by improving the gradient estimation. Then we compare Analysis and\nSynthesis by evaluating the performance of unrolled algorithms for inverse\nproblems, without access to any ground truth data for several classes of\ndictionaries and priors. While Analysis can achieve good results,Synthesis is\nmore robust and performs better. Finally, we illustrate our method on pattern\nand structure learning tasks from degraded measurements.",
          "link": "http://arxiv.org/abs/2106.06338",
          "publishedOn": "2021-06-14T01:38:54.244Z",
          "wordCount": 617,
          "title": "Dictionary and prior learning with unrolled algorithms for unsupervised inverse problems. (arXiv:2106.06338v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06430",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wolf_L/0/1/0/all/0/1\">Laura M. Wolf</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Baum_M/0/1/0/all/0/1\">Marcus Baum</a>",
          "description": "Herding is a technique to sequentially generate deterministic samples from a\nprobability distribution. In this work, we propose a continuous herded Gibbs\nsampler, that combines kernel herding on continuous densities with Gibbs\nsampling. Our algorithm allows for deterministically sampling from\nhigh-dimensional multivariate probability densities, without directly sampling\nfrom the joint density. Experiments with Gaussian mixture densities indicate\nthat the L2 error decreases similarly to kernel herding, while the computation\ntime is significantly lower, i.e., linear in the number of dimensions.",
          "link": "http://arxiv.org/abs/2106.06430",
          "publishedOn": "2021-06-14T01:38:54.214Z",
          "wordCount": 512,
          "title": "Continuous Herded Gibbs Sampling. (arXiv:2106.06430v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06469",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1\">Songzhu Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yikai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wagner_H/0/1/0/all/0/1\">Hubert Wagner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goswami_M/0/1/0/all/0/1\">Mayank Goswami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chao Chen</a>",
          "description": "Deep neural networks are known to have security issues. One particular threat\nis the Trojan attack. It occurs when the attackers stealthily manipulate the\nmodel's behavior through Trojaned training samples, which can later be\nexploited.\n\nGuided by basic neuroscientific principles we discover subtle -- yet critical\n-- structural deviation characterizing Trojaned models. In our analysis we use\ntopological tools. They allow us to model high-order dependencies in the\nnetworks, robustly compare different networks, and localize structural\nabnormalities. One interesting observation is that Trojaned models develop\nshort-cuts from input to output layers.\n\nInspired by these observations, we devise a strategy for robust detection of\nTrojaned models. Compared to standard baselines it displays better performance\non multiple benchmarks.",
          "link": "http://arxiv.org/abs/2106.06469",
          "publishedOn": "2021-06-14T01:38:54.194Z",
          "wordCount": 542,
          "title": "Topological Detection of Trojaned Neural Networks. (arXiv:2106.06469v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06406",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lee_S/0/1/0/all/0/1\">Sang-gil Lee</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kim_H/0/1/0/all/0/1\">Heeseung Kim</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shin_C/0/1/0/all/0/1\">Chaehun Shin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tan_X/0/1/0/all/0/1\">Xu Tan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liu_C/0/1/0/all/0/1\">Chang Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Meng_Q/0/1/0/all/0/1\">Qi Meng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Qin_T/0/1/0/all/0/1\">Tao Qin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chen_W/0/1/0/all/0/1\">Wei Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yoon_S/0/1/0/all/0/1\">Sungroh Yoon</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liu_T/0/1/0/all/0/1\">Tie-Yan Liu</a>",
          "description": "Denoising diffusion probabilistic models have been recently proposed to\ngenerate high-quality samples by estimating the gradient of the data density.\nThe framework assumes the prior noise as a standard Gaussian distribution,\nwhereas the corresponding data distribution may be more complicated than the\nstandard Gaussian distribution, which potentially introduces inefficiency in\ndenoising the prior noise into the data sample because of the discrepancy\nbetween the data and the prior. In this paper, we propose PriorGrad to improve\nthe efficiency of the conditional diffusion model (for example, a vocoder using\na mel-spectrogram as the condition) by applying an adaptive prior derived from\nthe data statistics based on the conditional information. We formulate the\ntraining and sampling procedures of PriorGrad and demonstrate the advantages of\nan adaptive prior through a theoretical analysis. Focusing on the audio domain,\nwe consider the recently proposed diffusion-based audio generative models based\non both the spectral and time domains and show that PriorGrad achieves a faster\nconvergence leading to data and parameter efficiency and improved quality, and\nthereby demonstrating the efficiency of a data-driven adaptive prior.",
          "link": "http://arxiv.org/abs/2106.06406",
          "publishedOn": "2021-06-14T01:38:54.165Z",
          "wordCount": 644,
          "title": "PriorGrad: Improving Conditional Denoising Diffusion Models with Data-Driven Adaptive Prior. (arXiv:2106.06406v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06431",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rezaeifar_S/0/1/0/all/0/1\">Shideh Rezaeifar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dadashi_R/0/1/0/all/0/1\">Robert Dadashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vieillard_N/0/1/0/all/0/1\">Nino Vieillard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hussenot_L/0/1/0/all/0/1\">L&#xe9;onard Hussenot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bachem_O/0/1/0/all/0/1\">Olivier Bachem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pietquin_O/0/1/0/all/0/1\">Olivier Pietquin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geist_M/0/1/0/all/0/1\">Matthieu Geist</a>",
          "description": "Offline Reinforcement Learning (RL) aims at learning an optimal control from\na fixed dataset, without interactions with the system. An agent in this setting\nshould avoid selecting actions whose consequences cannot be predicted from the\ndata. This is the converse of exploration in RL, which favors such actions. We\nthus take inspiration from the literature on bonus-based exploration to design\na new offline RL agent. The core idea is to subtract a prediction-based\nexploration bonus from the reward, instead of adding it for exploration. This\nallows the policy to stay close to the support of the dataset. We connect this\napproach to a more common regularization of the learned policy towards the\ndata. Instantiated with a bonus based on the prediction error of a variational\nautoencoder, we show that our agent is competitive with the state of the art on\na set of continuous control locomotion and manipulation tasks.",
          "link": "http://arxiv.org/abs/2106.06431",
          "publishedOn": "2021-06-14T01:38:54.158Z",
          "wordCount": 574,
          "title": "Offline Reinforcement Learning as Anti-Exploration. (arXiv:2106.06431v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06345",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bunne_C/0/1/0/all/0/1\">Charlotte Bunne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Papaxanthos_L/0/1/0/all/0/1\">Laetitia Meng-Papaxanthos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krause_A/0/1/0/all/0/1\">Andreas Krause</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cuturi_M/0/1/0/all/0/1\">Marco Cuturi</a>",
          "description": "Consider a heterogeneous population of points evolving with time. While the\npopulation evolves, both in size and nature, we can observe it periodically,\nthrough snapshots taken at different timestamps. Each of these snapshots is\nformed by sampling points from the population at that time, and then creating\nfeatures to recover point clouds. While these snapshots describe the\npopulation's evolution on aggregate, they do not provide directly insights on\nindividual trajectories. This scenario is encountered in several applications,\nnotably single-cell genomics experiments, tracking of particles, or when\nstudying crowd motion. In this paper, we propose to model that dynamic as\nresulting from the celebrated Jordan-Kinderlehrer-Otto (JKO) proximal scheme.\nThe JKO scheme posits that the configuration taken by a population at time $t$\nis one that trades off a decrease w.r.t. an energy (the model we seek to learn)\npenalized by an optimal transport distance w.r.t. the previous configuration.\nTo that end, we propose JKOnet, a neural architecture that combines an energy\nmodel on measures, with (small) optimal displacements solved with input convex\nneural networks (ICNN). We demonstrate the applicability of our model to\nexplain and predict population dynamics.",
          "link": "http://arxiv.org/abs/2106.06345",
          "publishedOn": "2021-06-14T01:38:54.151Z",
          "wordCount": 610,
          "title": "JKOnet: Proximal Optimal Transport Modeling of Population Dynamics. (arXiv:2106.06345v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06153",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Teng_J/0/1/0/all/0/1\">Jiaye Teng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jianhao Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1\">Yang Yuan</a>",
          "description": "Generalization is one of the critical issues in machine learning. However,\ntraditional methods like uniform convergence are not powerful enough to fully\nexplain generalization because they may yield vacuous bounds even in\noverparameterized linear regression regimes. An alternative solution is to\nanalyze the generalization dynamics to derive algorithm-dependent bounds, e.g.,\nstability. Unfortunately, the stability-based bound is still far from\nexplaining the remarkable generalization ability of neural networks due to the\ncoarse-grained analysis of the signal and noise. Inspired by the observation\nthat neural networks show a slow convergence rate when fitting noise, we\npropose decomposing the excess risk dynamics and applying stability-based bound\nonly on the variance part (which measures how the model performs on pure\nnoise). We provide two applications for the framework, including a linear case\n(overparameterized linear regression with gradient descent) and a non-linear\ncase (matrix recovery with gradient flow). Under the decomposition framework,\nthe new bound accords better with the theoretical and empirical evidence\ncompared to the stability-based bound and uniform convergence bound.",
          "link": "http://arxiv.org/abs/2106.06153",
          "publishedOn": "2021-06-14T01:38:54.144Z",
          "wordCount": 598,
          "title": "Towards Understanding Generalization via Decomposing Excess Risk Dynamics. (arXiv:2106.06153v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06508",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Anand_N/0/1/0/all/0/1\">Nishanth Anand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Precup_D/0/1/0/all/0/1\">Doina Precup</a>",
          "description": "Temporal-Difference (TD) learning is a general and very useful tool for\nestimating the value function of a given policy, which in turn is required to\nfind good policies. Generally speaking, TD learning updates states whenever\nthey are visited. When the agent lands in a state, its value can be used to\ncompute the TD-error, which is then propagated to other states. However, it may\nbe interesting, when computing updates, to take into account other information\nthan whether a state is visited or not. For example, some states might be more\nimportant than others (such as states which are frequently seen in a successful\ntrajectory). Or, some states might have unreliable value estimates (for\nexample, due to partial observability or lack of data), making their values\nless desirable as targets. We propose an approach to re-weighting states used\nin TD updates, both when they are the input and when they provide the target\nfor the update. We prove that our approach converges with linear function\napproximation and illustrate its desirable empirical behaviour compared to\nother TD-style methods.",
          "link": "http://arxiv.org/abs/2106.06508",
          "publishedOn": "2021-06-14T01:38:54.137Z",
          "wordCount": 603,
          "title": "Preferential Temporal Difference Learning. (arXiv:2106.06508v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06530",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Damian_A/0/1/0/all/0/1\">Alex Damian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1\">Tengyu Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jason Lee</a>",
          "description": "In overparametrized models, the noise in stochastic gradient descent (SGD)\nimplicitly regularizes the optimization trajectory and determines which local\nminimum SGD converges to. Motivated by empirical studies that demonstrate that\ntraining with noisy labels improves generalization, we study the implicit\nregularization effect of SGD with label noise. We show that SGD with label\nnoise converges to a stationary point of a regularized loss $L(\\theta) +\\lambda\nR(\\theta)$, where $L(\\theta)$ is the training loss, $\\lambda$ is an effective\nregularization parameter depending on the step size, strength of the label\nnoise, and the batch size, and $R(\\theta)$ is an explicit regularizer that\npenalizes sharp minimizers. Our analysis uncovers an additional regularization\neffect of large learning rates beyond the linear scaling rule that penalizes\nlarge eigenvalues of the Hessian more than small ones. We also prove extensions\nto classification with general loss functions, SGD with momentum, and SGD with\ngeneral noise covariance, significantly strengthening the prior work of Blanc\net al. to global convergence and large learning rates and of HaoChen et al. to\ngeneral models.",
          "link": "http://arxiv.org/abs/2106.06530",
          "publishedOn": "2021-06-14T01:38:54.117Z",
          "wordCount": 620,
          "title": "Label Noise SGD Provably Prefers Flat Global Minimizers. (arXiv:2106.06530v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06307",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nazir_U/0/1/0/all/0/1\">Usman Nazir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">He Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taj_M/0/1/0/all/0/1\">Murtaza Taj</a>",
          "description": "In this survey paper, we analyze image based graph neural networks and\npropose a three-step classification approach. We first convert the image into\nsuperpixels using the Quickshift algorithm so as to reduce 30% of the input\ndata. The superpixels are subsequently used to generate a region adjacency\ngraph. Finally, the graph is passed through a state-of-art graph convolutional\nneural network to get classification scores. We also analyze the spatial and\nspectral convolution filtering techniques in graph neural networks.\nSpectral-based models perform better than spatial-based models and classical\nCNN with lesser compute cost.",
          "link": "http://arxiv.org/abs/2106.06307",
          "publishedOn": "2021-06-14T01:38:54.108Z",
          "wordCount": 522,
          "title": "Survey of Image Based Graph Neural Networks. (arXiv:2106.06307v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06410",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chapman_A/0/1/0/all/0/1\">Adriane Chapman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_G/0/1/0/all/0/1\">Guihua Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hall_D/0/1/0/all/0/1\">Dame Wendy Hall</a>",
          "description": "Supervised machine learning has several drawbacks that make it difficult to\nuse in many situations. Drawbacks include: heavy reliance on massive training\ndata, limited generalizability and poor expressiveness of high-level semantics.\nLow-shot Learning attempts to address these drawbacks. Low-shot learning allows\nthe model to obtain good predictive power with very little or no training data,\nwhere structured knowledge plays a key role as a high-level semantic\nrepresentation of human. This article will review the fundamental factors of\nlow-shot learning technologies, with a focus on the operation of structured\nknowledge under different low-shot conditions. We also introduce other\ntechniques relevant to low-shot learning. Finally, we point out the limitations\nof low-shot learning, the prospects and gaps of industrial applications, and\nfuture research directions.",
          "link": "http://arxiv.org/abs/2106.06410",
          "publishedOn": "2021-06-14T01:38:54.102Z",
          "wordCount": 573,
          "title": "What Can Knowledge Bring to Machine Learning? -- A Survey of Low-shot Learning for Structured Data. (arXiv:2106.06410v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06356",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_Q/0/1/0/all/0/1\">Quan Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Modiri_A/0/1/0/all/0/1\">Arghavan Modiri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garnett_R/0/1/0/all/0/1\">Roman Garnett</a>",
          "description": "Active search is a learning paradigm where we seek to identify as many\nmembers of a rare, valuable class as possible given a labeling budget. Previous\nwork on active search has assumed access to a faithful (and expensive) oracle\nreporting experimental results. However, some settings offer access to cheaper\nsurrogates such as computational simulation that may aid in the search. We\npropose a model of multifidelity active search, as well as a novel,\ncomputationally efficient policy for this setting that is motivated by\nstate-of-the-art classical policies. Our policy is nonmyopic and budget aware,\nallowing for a dynamic tradeoff between exploration and exploitation. We\nevaluate the performance of our solution on real-world datasets and demonstrate\nsignificantly better performance than natural benchmarks.",
          "link": "http://arxiv.org/abs/2106.06356",
          "publishedOn": "2021-06-14T01:38:54.095Z",
          "wordCount": 539,
          "title": "Nonmyopic Multifidelity Active Search. (arXiv:2106.06356v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06189",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chen_X/0/1/0/all/0/1\">Xiaohui Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Han_X/0/1/0/all/0/1\">Xu Han</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hu_J/0/1/0/all/0/1\">Jiajing Hu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ruiz_F/0/1/0/all/0/1\">Francisco J. R. Ruiz</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liu_L/0/1/0/all/0/1\">Liping Liu</a>",
          "description": "A graph generative model defines a distribution over graphs. One type of\ngenerative model is constructed by autoregressive neural networks, which\nsequentially add nodes and edges to generate a graph. However, the likelihood\nof a graph under the autoregressive model is intractable, as there are numerous\nsequences leading to the given graph; this makes maximum likelihood estimation\nchallenging. Instead, in this work we derive the exact joint probability over\nthe graph and the node ordering of the sequential process. From the joint, we\napproximately marginalize out the node orderings and compute a lower bound on\nthe log-likelihood using variational inference. We train graph generative\nmodels by maximizing this bound, without using the ad-hoc node orderings of\nprevious methods. Our experiments show that the log-likelihood bound is\nsignificantly tighter than the bound of previous schemes. Moreover, the models\nfitted with the proposed algorithm can generate high-quality graphs that match\nthe structures of target graphs not seen during training. We have made our code\npublicly available at\n\\hyperref[https://github.com/tufts-ml/graph-generation-vi]{https://github.com/tufts-ml/graph-generation-vi}.",
          "link": "http://arxiv.org/abs/2106.06189",
          "publishedOn": "2021-06-14T01:38:54.088Z",
          "wordCount": 614,
          "title": "Order Matters: Probabilistic Modeling of Node Sequence for Graph Generation. (arXiv:2106.06189v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06312",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhaomin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qinbin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_B/0/1/0/all/0/1\">Bingsheng He</a>",
          "description": "As the privacy of machine learning has drawn increasing attention, federated\nlearning is introduced to enable collaborative learning without revealing raw\ndata. Notably, \\textit{vertical federated learning} (VFL), where parties share\nthe same set of samples but only hold partial features, has a wide range of\nreal-world applications. However, existing studies in VFL rarely study the\n``record linkage'' process. They either design algorithms assuming the data\nfrom different parties have been linked or use simple linkage methods like\nexact-linkage or top1-linkage. These approaches are unsuitable for many\napplications, such as the GPS location and noisy titles requiring fuzzy\nmatching. In this paper, we design a novel similarity-based VFL framework,\nFedSim, which is suitable for more real-world applications and achieves higher\nperformance on traditional VFL tasks. Moreover, we theoretically analyze the\nprivacy risk caused by sharing similarities. Our experiments on three synthetic\ndatasets and five real-world datasets with various similarity metrics show that\nFedSim consistently outperforms other state-of-the-art baselines.",
          "link": "http://arxiv.org/abs/2106.06312",
          "publishedOn": "2021-06-14T01:38:54.068Z",
          "wordCount": 584,
          "title": "Exploiting Record Similarity for Practical Vertical Federated Learning. (arXiv:2106.06312v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06452",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wen_C/0/1/0/all/0/1\">Chuan Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jierui Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_J/0/1/0/all/0/1\">Jianing Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yang Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jayaraman_D/0/1/0/all/0/1\">Dinesh Jayaraman</a>",
          "description": "Imitation learning trains control policies by mimicking pre-recorded expert\ndemonstrations. In partially observable settings, imitation policies must rely\non observation histories, but many seemingly paradoxical results show better\nperformance for policies that only access the most recent observation. Recent\nsolutions ranging from causal graph learning to deep information bottlenecks\nhave shown promising results, but failed to scale to realistic settings such as\nvisual imitation. We propose a solution that outperforms these prior approaches\nby upweighting demonstration keyframes corresponding to expert action\nchangepoints. This simple approach easily scales to complex visual imitation\nsettings. Our experimental results demonstrate consistent performance\nimprovements over all baselines on image-based Gym MuJoCo continuous control\ntasks. Finally, on the CARLA photorealistic vision-based urban driving\nsimulator, we resolve a long-standing issue in behavioral cloning for driving\nby demonstrating effective imitation from observation histories. Supplementary\nmaterials and code at: \\url{https://tinyurl.com/imitation-keyframes}.",
          "link": "http://arxiv.org/abs/2106.06452",
          "publishedOn": "2021-06-14T01:38:54.061Z",
          "wordCount": 570,
          "title": "Keyframe-Focused Visual Imitation Learning. (arXiv:2106.06452v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06012",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Laakom_F/0/1/0/all/0/1\">Firas Laakom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raitoharju_J/0/1/0/all/0/1\">Jenni Raitoharju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iosifidis_A/0/1/0/all/0/1\">Alexandros Iosifidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gabbouj_M/0/1/0/all/0/1\">Moncef Gabbouj</a>",
          "description": "Neural networks are composed of multiple layers arranged in a hierarchical\nstructure jointly trained with a gradient-based optimization, where the errors\nare back-propagated from the last layer back to the first one. At each\noptimization step, neurons at a given layer receive feedback from neurons\nbelonging to higher layers of the hierarchy. In this paper, we propose to\ncomplement this traditional 'between-layer' feedback with additional\n'within-layer' feedback to encourage diversity of the activations within the\nsame layer. To this end, we measure the pairwise similarity between the outputs\nof the neurons and use it to model the layer's overall diversity. By penalizing\nsimilarities and promoting diversity, we encourage each neuron to learn a\ndistinctive representation and, thus, to enrich the data representation learned\nwithin the layer and to increase the total capacity of the model. We\ntheoretically study how the within-layer activation diversity affects the\ngeneralization performance of a neural network and prove that increasing the\ndiversity of hidden activations reduces the estimation error. In addition to\nthe theoretical guarantees, we present an empirical study on three datasets\nconfirming that the proposed approach enhances the performance of\nstate-of-the-art neural network models and decreases the generalization gap.",
          "link": "http://arxiv.org/abs/2106.06012",
          "publishedOn": "2021-06-14T01:38:54.054Z",
          "wordCount": 628,
          "title": "Within-layer Diversity Reduces Generalization Gap. (arXiv:2106.06012v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06297",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hombaiah_S/0/1/0/all/0/1\">Spurthi Amba Hombaiah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mingyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bendersky_M/0/1/0/all/0/1\">Michael Bendersky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Najork_M/0/1/0/all/0/1\">Marc Najork</a>",
          "description": "The content on the web is in a constant state of flux. New entities, issues,\nand ideas continuously emerge, while the semantics of the existing conversation\ntopics gradually shift. In recent years, pre-trained language models like BERT\ngreatly improved the state-of-the-art for a large spectrum of content\nunderstanding tasks. Therefore, in this paper, we aim to study how these\nlanguage models can be adapted to better handle continuously evolving web\ncontent. In our study, we first analyze the evolution of 2013 - 2019 Twitter\ndata, and unequivocally confirm that a BERT model trained on past tweets would\nheavily deteriorate when directly applied to data from later years. Then, we\ninvestigate two possible sources of the deterioration: the semantic shift of\nexisting tokens and the sub-optimal or failed understanding of new tokens. To\nthis end, we both explore two different vocabulary composition methods, as well\nas propose three sampling methods which help in efficient incremental training\nfor BERT-like models. Compared to a new model trained from scratch offline, our\nincremental training (a) reduces the training costs, (b) achieves better\nperformance on evolving content, and (c) is suitable for online deployment. The\nsuperiority of our methods is validated using two downstream tasks. We\ndemonstrate significant improvements when incrementally evolving the model from\na particular base year, on the task of Country Hashtag Prediction, as well as\non the OffensEval 2019 task.",
          "link": "http://arxiv.org/abs/2106.06297",
          "publishedOn": "2021-06-14T01:38:54.047Z",
          "wordCount": 666,
          "title": "Dynamic Language Models for Continuously Evolving Content. (arXiv:2106.06297v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06321",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bana_T/0/1/0/all/0/1\">Tejas Bana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Loya_J/0/1/0/all/0/1\">Jatan Loya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulkarni_S/0/1/0/all/0/1\">Siddhant Kulkarni</a>",
          "description": "Studies involving colourising images has been garnering researchers' keen\nattention over time, assisted by significant advances in various Machine\nLearning techniques and compute power availability. Traditionally, colourising\nimages have been an intricate task that gave a substantial degree of freedom\nduring the assignment of chromatic information. In our proposed method, we\nattempt to colourise images using Vision Transformer - Inception - Generative\nAdversarial Network (ViT-I-GAN), which has an Inception-v3 fusion embedding in\nthe generator. For a stable and robust network, we have used Vision Transformer\n(ViT) as the discriminator. We trained the model on the Unsplash and the COCO\ndataset for demonstrating the improvement made by the Inception-v3 embedding.\nWe have compared the results between ViT-GANs with and without Inception-v3\nembedding.",
          "link": "http://arxiv.org/abs/2106.06321",
          "publishedOn": "2021-06-14T01:38:54.040Z",
          "wordCount": 547,
          "title": "ViT-Inception-GAN for Image Colourising. (arXiv:2106.06321v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06218",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yun_S/0/1/0/all/0/1\">Seongjun Yun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeong_M/0/1/0/all/0/1\">Minbyul Jeong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoo_S/0/1/0/all/0/1\">Sungdong Yoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Seunghun Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_S/0/1/0/all/0/1\">Sean S. Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_R/0/1/0/all/0/1\">Raehyun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_J/0/1/0/all/0/1\">Jaewoo Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyunwoo J. Kim</a>",
          "description": "Graph Neural Networks (GNNs) have been widely applied to various fields due\nto their powerful representations of graph-structured data. Despite the success\nof GNNs, most existing GNNs are designed to learn node representations on the\nfixed and homogeneous graphs. The limitations especially become problematic\nwhen learning representations on a misspecified graph or a heterogeneous graph\nthat consists of various types of nodes and edges. To address this limitations,\nwe propose Graph Transformer Networks (GTNs) that are capable of generating new\ngraph structures, which preclude noisy connections and include useful\nconnections (e.g., meta-paths) for tasks, while learning effective node\nrepresentations on the new graphs in an end-to-end fashion. We further propose\nenhanced version of GTNs, Fast Graph Transformer Networks (FastGTNs), that\nimprove scalability of graph transformations. Compared to GTNs, FastGTNs are\n230x faster and use 100x less memory while allowing the identical graph\ntransformations as GTNs. In addition, we extend graph transformations to the\nsemantic proximity of nodes allowing non-local operations beyond meta-paths.\nExtensive experiments on both homogeneous graphs and heterogeneous graphs show\nthat GTNs and FastGTNs with non-local operations achieve the state-of-the-art\nperformance for node classification tasks. The code is available:\nhttps://github.com/seongjunyun/Graph_Transformer_Networks",
          "link": "http://arxiv.org/abs/2106.06218",
          "publishedOn": "2021-06-14T01:38:54.033Z",
          "wordCount": 647,
          "title": "Graph Transformer Networks: Learning Meta-path Graphs to Improve GNNs. (arXiv:2106.06218v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06261",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hosp_B/0/1/0/all/0/1\">Benedikt Hosp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_M/0/1/0/all/0/1\">Myat Su Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haddawy_p/0/1/0/all/0/1\">peter Haddawy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watcharporas_R/0/1/0/all/0/1\">Ratthapoom Watcharporas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sa_ngasoonsong_p/0/1/0/all/0/1\">paphon Sa-ngasoonsong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kasneci_E/0/1/0/all/0/1\">Enkelejda Kasneci</a>",
          "description": "During arthroscopic surgeries, surgeons are faced with challenges like\ncognitive re-projection of the 2D screen output into the 3D operating site or\nnavigation through highly similar tissue. Training of these cognitive processes\ntakes much time and effort for young surgeons, but is necessary and crucial for\ntheir education. In this study we want to show how to recognize states of\nconfusion of young surgeons during an arthroscopic surgery, by looking at their\neye and head movements and feeding them to a machine learning model. With an\naccuracy of over 94\\% and detection speed of 0.039 seconds, our model is a step\ntowards online diagnostic and training systems for the perceptual-cognitive\nprocesses of surgeons during arthroscopic surgeries.",
          "link": "http://arxiv.org/abs/2106.06261",
          "publishedOn": "2021-06-14T01:38:54.010Z",
          "wordCount": 558,
          "title": "States of confusion: Eye and Head tracking reveal surgeons' confusion during arthroscopic surgery. (arXiv:2106.06261v1 [cs.HC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06385",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Manduchi_L/0/1/0/all/0/1\">Laura Manduchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chin_Cheong_K/0/1/0/all/0/1\">Kieran Chin-Cheong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Michel_H/0/1/0/all/0/1\">Holger Michel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wellmann_S/0/1/0/all/0/1\">Sven Wellmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogt_J/0/1/0/all/0/1\">Julia E. Vogt</a>",
          "description": "Constrained clustering has gained significant attention in the field of\nmachine learning as it can leverage prior information on a growing amount of\nonly partially labeled data. Following recent advances in deep generative\nmodels, we propose a novel framework for constrained clustering that is\nintuitive, interpretable, and can be trained efficiently in the framework of\nstochastic gradient variational inference. By explicitly integrating domain\nknowledge in the form of probabilistic relations, our proposed model (DC-GMM)\nuncovers the underlying distribution of data conditioned on prior clustering\npreferences, expressed as pairwise constraints. These constraints guide the\nclustering process towards a desirable partition of the data by indicating\nwhich samples should or should not belong to the same cluster. We provide\nextensive experiments to demonstrate that DC-GMM shows superior clustering\nperformances and robustness compared to state-of-the-art deep constrained\nclustering methods on a wide range of data sets. We further demonstrate the\nusefulness of our approach on two challenging real-world applications.",
          "link": "http://arxiv.org/abs/2106.06385",
          "publishedOn": "2021-06-14T01:38:54.003Z",
          "wordCount": 582,
          "title": "Deep Conditional Gaussian Mixture Model for Constrained Clustering. (arXiv:2106.06385v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06257",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Arango_S/0/1/0/all/0/1\">Sebastian Pineda Arango</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jomaa_H/0/1/0/all/0/1\">Hadi S. Jomaa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wistuba_M/0/1/0/all/0/1\">Martin Wistuba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grabocka_J/0/1/0/all/0/1\">Josif Grabocka</a>",
          "description": "Hyperparameter optimization (HPO) is a core problem for the machine learning\ncommunity and remains largely unsolved due to the significant computational\nresources required to evaluate hyperparameter configurations. As a result, a\nseries of recent related works have focused on the direction of transfer\nlearning for quickly fine-tuning hyperparameters on a dataset. Unfortunately,\nthe community does not have a common large-scale benchmark for comparing HPO\nalgorithms. Instead, the de facto practice consists of empirical protocols on\narbitrary small-scale meta-datasets that vary inconsistently across\npublications, making reproducibility a challenge. To resolve this major\nbottleneck and enable a fair and fast comparison of black-box HPO methods on a\nlevel playing field, we propose HPO-B, a new large-scale benchmark in the form\nof a collection of meta-datasets. Our benchmark is assembled and preprocessed\nfrom the OpenML repository and consists of 176 search spaces (algorithms)\nevaluated sparsely on 196 datasets with a total of 6.4 million hyperparameter\nevaluations. For ensuring reproducibility on our benchmark, we detail explicit\nexperimental protocols, splits, and evaluation measures for comparing methods\nfor both non-transfer, as well as, transfer learning HPO.",
          "link": "http://arxiv.org/abs/2106.06257",
          "publishedOn": "2021-06-14T01:38:53.995Z",
          "wordCount": 612,
          "title": "HPO-B: A Large-Scale Reproducible Benchmark for Black-Box HPO based on OpenML. (arXiv:2106.06257v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06251",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Akiyama_S/0/1/0/all/0/1\">Shunta Akiyama</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Suzuki_T/0/1/0/all/0/1\">Taiji Suzuki</a>",
          "description": "Deep learning empirically achieves high performance in many applications, but\nits training dynamics has not been fully understood theoretically. In this\npaper, we explore theoretical analysis on training two-layer ReLU neural\nnetworks in a teacher-student regression model, in which a student network\nlearns an unknown teacher network through its outputs. We show that with a\nspecific regularization and sufficient over-parameterization, the student\nnetwork can identify the parameters of the teacher network with high\nprobability via gradient descent with a norm dependent stepsize even though the\nobjective function is highly non-convex. The key theoretical tool is the\nmeasure representation of the neural networks and a novel application of a dual\ncertificate argument for sparse estimation on a measure space. We analyze the\nglobal minima and global convergence property in the measure space.",
          "link": "http://arxiv.org/abs/2106.06251",
          "publishedOn": "2021-06-14T01:38:53.985Z",
          "wordCount": 570,
          "title": "On Learnability via Gradient Method for Two-Layer ReLU Neural Networks in Teacher-Student Setting. (arXiv:2106.06251v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06235",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gurel_N/0/1/0/all/0/1\">Nezihe Merve G&#xfc;rel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_X/0/1/0/all/0/1\">Xiangyu Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rimanic_L/0/1/0/all/0/1\">Luka Rimanic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Ce Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>",
          "description": "Despite the great successes achieved by deep neural networks (DNNs), recent\nstudies show that they are vulnerable against adversarial examples, which aim\nto mislead DNNs by adding small adversarial perturbations. Several defenses\nhave been proposed against such attacks, while many of them have been\nadaptively attacked. In this work, we aim to enhance the ML robustness from a\ndifferent perspective by leveraging domain knowledge: We propose a Knowledge\nEnhanced Machine Learning Pipeline (KEMLP) to integrate domain knowledge (i.e.,\nlogic relationships among different predictions) into a probabilistic graphical\nmodel via first-order logic rules. In particular, we develop KEMLP by\nintegrating a diverse set of weak auxiliary models based on their logical\nrelationships to the main DNN model that performs the target task.\nTheoretically, we provide convergence results and prove that, under mild\nconditions, the prediction of KEMLP is more robust than that of the main DNN\nmodel. Empirically, we take road sign recognition as an example and leverage\nthe relationships between road signs and their shapes and contents as domain\nknowledge. We show that compared with adversarial training and other baselines,\nKEMLP achieves higher robustness against physical attacks, $\\mathcal{L}_p$\nbounded attacks, unforeseen attacks, and natural corruptions under both\nwhitebox and blackbox settings, while still maintaining high clean accuracy.",
          "link": "http://arxiv.org/abs/2106.06235",
          "publishedOn": "2021-06-14T01:38:53.979Z",
          "wordCount": 649,
          "title": "Knowledge Enhanced Machine Learning Pipeline against Diverse Adversarial Attacks. (arXiv:2106.06235v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06216",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Waldis_A/0/1/0/all/0/1\">Andreas Waldis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mazzola_L/0/1/0/all/0/1\">Luca Mazzola</a>",
          "description": "Entity Recognition (ER) within a text is a fundamental exercise in Natural\nLanguage Processing, enabling further depending tasks such as Knowledge\nExtraction, Text Summarisation, or Keyphrase Extraction. An entity consists of\nsingle words or of a consecutive sequence of terms, constituting the basic\nbuilding blocks for communication. Mainstream ER approaches are mainly limited\nto flat structures, concentrating on the outermost entities while ignoring the\ninner ones. This paper introduces a partly-layered network architecture that\ndeals with the complexity of overlapping and nested cases. The proposed\narchitecture consists of two parts: (1) a shared Sequence Layer and (2) a\nstacked component with multiple Tagging Layers. The adoption of such an\narchitecture has the advantage of preventing overfit to a specific word-length,\nthus maintaining performance for longer entities despite their lower frequency.\nTo verify the proposed architecture's effectiveness, we train and evaluate this\narchitecture to recognise two kinds of entities - Concepts (CR) and Named\nEntities (NER). Our approach achieves state-of-the-art NER performances, while\nit outperforms previous CR approaches. Considering these promising results, we\nsee the possibility to evolve the architecture for other cases such as the\nextraction of events or the detection of argumentative components.",
          "link": "http://arxiv.org/abs/2106.06216",
          "publishedOn": "2021-06-14T01:38:53.958Z",
          "wordCount": 635,
          "title": "Nested and Balanced Entity Recognition using Multi-Task Learning. (arXiv:2106.06216v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06308",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Choo_D/0/1/0/all/0/1\">Davin Choo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+dOrsi_T/0/1/0/all/0/1\">Tommaso d&#x27;Orsi</a>",
          "description": "We study the problem of sparse tensor principal component analysis: given a\ntensor $\\pmb Y = \\pmb W + \\lambda x^{\\otimes p}$ with $\\pmb W \\in\n\\otimes^p\\mathbb{R}^n$ having i.i.d. Gaussian entries, the goal is to recover\nthe $k$-sparse unit vector $x \\in \\mathbb{R}^n$. The model captures both sparse\nPCA (in its Wigner form) and tensor PCA.\n\nFor the highly sparse regime of $k \\leq \\sqrt{n}$, we present a family of\nalgorithms that smoothly interpolates between a simple polynomial-time\nalgorithm and the exponential-time exhaustive search algorithm. For any $1 \\leq\nt \\leq k$, our algorithms recovers the sparse vector for signal-to-noise ratio\n$\\lambda \\geq \\tilde{\\mathcal{O}} (\\sqrt{t} \\cdot (k/t)^{p/2})$ in time\n$\\tilde{\\mathcal{O}}(n^{p+t})$, capturing the state-of-the-art guarantees for\nthe matrix settings (in both the polynomial-time and sub-exponential time\nregimes).\n\nOur results naturally extend to the case of $r$ distinct $k$-sparse signals\nwith disjoint supports, with guarantees that are independent of the number of\nspikes. Even in the restricted case of sparse PCA, known algorithms only\nrecover the sparse vectors for $\\lambda \\geq \\tilde{\\mathcal{O}}(k \\cdot r)$\nwhile our algorithms require $\\lambda \\geq \\tilde{\\mathcal{O}}(k)$.\n\nFinally, by analyzing the low-degree likelihood ratio, we complement these\nalgorithmic results with rigorous evidence illustrating the trade-offs between\nsignal-to-noise ratio and running time. This lower bound captures the known\nlower bounds for both sparse PCA and tensor PCA. In this general model, we\nobserve a more intricate three-way trade-off between the number of samples $n$,\nthe sparsity $k$, and the tensor power $p$.",
          "link": "http://arxiv.org/abs/2106.06308",
          "publishedOn": "2021-06-14T01:38:53.951Z",
          "wordCount": 680,
          "title": "The Complexity of Sparse Tensor PCA. (arXiv:2106.06308v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06237",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zhou_C/0/1/0/all/0/1\">Chenhong Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_F/0/1/0/all/0/1\">Feng Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gong_C/0/1/0/all/0/1\">Chen Gong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_T/0/1/0/all/0/1\">Tongliang Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Han_B/0/1/0/all/0/1\">Bo Han</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cheung_W/0/1/0/all/0/1\">William Cheung</a>",
          "description": "In semantic segmentation, we aim to train a pixel-level classifier to assign\ncategory labels to all pixels in an image, where labeled training images and\nunlabeled test images are from the same distribution and share the same label\nset. However, in an open world, the unlabeled test images probably contain\nunknown categories and have different distributions from the labeled images.\nHence, in this paper, we consider a new, more realistic, and more challenging\nproblem setting where the pixel-level classifier has to be trained with labeled\nimages and unlabeled open-world images -- we name it open world semantic\nsegmentation (OSS). In OSS, the trained classifier is expected to identify\nunknown-class pixels and classify known-class pixels well. To solve OSS, we\nfirst investigate which distribution that unknown-class pixels obey. Then,\nmotivated by the goodness-of-fit test, we use statistical measurements to show\nhow a pixel fits the distribution of an unknown class and select highly-fitted\npixels to form the unknown region in each image. Eventually, we propose an\nend-to-end learning framework, known-region-aware domain alignment (KRADA), to\ndistinguish unknown classes while aligning distributions of known classes in\nlabeled and unlabeled open-world images. The effectiveness of KRADA has been\nverified on two synthetic tasks and one COVID-19 segmentation task.",
          "link": "http://arxiv.org/abs/2106.06237",
          "publishedOn": "2021-06-14T01:38:53.944Z",
          "wordCount": 698,
          "title": "KRADA: Known-region-aware Domain Alignment for Open World Semantic Segmentation. (arXiv:2106.06237v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06298",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kanaan_G/0/1/0/all/0/1\">Georges Kanaan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_K/0/1/0/all/0/1\">Kai Wen Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fenaux_L/0/1/0/all/0/1\">Lucas Fenaux</a>",
          "description": "We propose a novel approach to lifelong learning, introducing a compact\nencapsulated support structure which endows a network with the capability to\nexpand its capacity as needed to learn new tasks while preventing the loss of\nlearned tasks. This is achieved by splitting neurons with high semantic drift\nand constructing an adjacent network to encode the new tasks at hand. We call\nthis the Plastic Support Structure (PSS), it is a compact structure to learn\nnew tasks that cannot be efficiently encoded in the existing structure of the\nnetwork. We validate the PSS on public datasets against existing lifelong\nlearning architectures, showing it performs similarly to them but without prior\nknowledge of the task and in some cases with fewer parameters and in a more\nunderstandable fashion where the PSS is an encapsulated container for specific\nfeatures related to specific tasks, thus making it an ideal \"add-on\" solution\nfor endowing a network to learn more tasks.",
          "link": "http://arxiv.org/abs/2106.06298",
          "publishedOn": "2021-06-14T01:38:53.937Z",
          "wordCount": 583,
          "title": "A Novel Approach to Lifelong Learning: The Plastic Support Structure. (arXiv:2106.06298v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06369",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yan_S/0/1/0/all/0/1\">Shengchao Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Welschehold_T/0/1/0/all/0/1\">Tim Welschehold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buscher_D/0/1/0/all/0/1\">Daniel B&#xfc;scher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burgard_W/0/1/0/all/0/1\">Wolfram Burgard</a>",
          "description": "The transition from today's mostly human-driven traffic to a purely automated\none will be a gradual evolution, with the effect that we will likely experience\nmixed traffic in the near future. Connected and automated vehicles can benefit\nhuman-driven ones and the whole traffic system in different ways, for example\nby improving collision avoidance and reducing traffic waves. Many studies have\nbeen carried out to improve intersection management, a significant bottleneck\nin traffic, with intelligent traffic signals or exclusively automated vehicles.\nHowever, the problem of how to improve mixed traffic at unsignalized\nintersections has received less attention. In this paper, we propose a novel\napproach to optimizing traffic flow at intersections in mixed traffic\nsituations using deep reinforcement learning. Our reinforcement learning agent\nlearns a policy for a centralized controller to let connected autonomous\nvehicles at unsignalized intersections give up their right of way and yield to\nother vehicles to optimize traffic flow. We implemented our approach and tested\nit in the traffic simulator SUMO based on simulated and real traffic data. The\nexperimental evaluation demonstrates that our method significantly improves\ntraffic flow through unsignalized intersections in mixed traffic settings and\nalso provides better performance on a wide range of traffic situations compared\nto the state-of-the-art traffic signal controller for the corresponding\nsignalized intersection.",
          "link": "http://arxiv.org/abs/2106.06369",
          "publishedOn": "2021-06-14T01:38:53.931Z",
          "wordCount": 646,
          "title": "Courteous Behavior of Automated Vehicles at Unsignalized Intersections via Reinforcement Learning. (arXiv:2106.06369v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06420",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Al_Kaabi_K/0/1/0/all/0/1\">Karrar Al-Kaabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monsefi_R/0/1/0/all/0/1\">Reza Monsefi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zabihzadeh_D/0/1/0/all/0/1\">Davood Zabihzadeh</a>",
          "description": "Metric learning algorithms aim to learn a distance function that brings the\nsemantically similar data items together and keeps dissimilar ones at a\ndistance. The traditional Mahalanobis distance learning is equivalent to find a\nlinear projection. In contrast, Deep Metric Learning (DML) methods are proposed\nthat automatically extract features from data and learn a non-linear\ntransformation from input space to a semantically embedding space. Recently,\nmany DML methods are proposed focused to enhance the discrimination power of\nthe learned metric by providing novel sampling strategies or loss functions.\nThis approach is very helpful when both the training and test examples are\ncoming from the same set of categories. However, it is less effective in many\napplications of DML such as image retrieval and person-reidentification. Here,\nthe DML should learn general semantic concepts from observed classes and employ\nthem to rank or identify objects from unseen categories. Neglecting the\ngeneralization ability of the learned representation and just emphasizing to\nlearn a more discriminative embedding on the observed classes may lead to the\noverfitting problem. To address this limitation, we propose a framework to\nenhance the generalization power of existing DML methods in a Zero-Shot\nLearning (ZSL) setting by general yet discriminative representation learning\nand employing a class adversarial neural network. To learn a more general\nrepresentation, we propose to employ feature maps of intermediate layers in a\ndeep neural network and enhance their discrimination power through an attention\nmechanism. Besides, a class adversarial network is utilized to enforce the deep\nmodel to seek class invariant features for the DML task. We evaluate our work\non widely used machine vision datasets in a ZSL setting.",
          "link": "http://arxiv.org/abs/2106.06420",
          "publishedOn": "2021-06-14T01:38:53.913Z",
          "wordCount": 744,
          "title": "A Framework to Enhance Generalization of Deep Metric Learning methods using General Discriminative Feature Learning and Class Adversarial Neural Networks. (arXiv:2106.06420v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06326",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chi_H/0/1/0/all/0/1\">Haoang Chi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Feng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1\">Wenjing Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_L/0/1/0/all/0/1\">Long Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tongliang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1\">Bo Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheung_W/0/1/0/all/0/1\">William K. Cheung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwok_J/0/1/0/all/0/1\">James T. Kwok</a>",
          "description": "In few-shot domain adaptation (FDA), classifiers for the target domain are\ntrained with accessible labeled data in the source domain (SD) and few labeled\ndata in the target domain (TD). However, data usually contain private\ninformation in the current era, e.g., data distributed on personal phones.\nThus, the private information will be leaked if we directly access data in SD\nto train a target-domain classifier (required by FDA methods). In this paper,\nto thoroughly prevent the privacy leakage in SD, we consider a very challenging\nproblem setting, where the classifier for the TD has to be trained using few\nlabeled target data and a well-trained SD classifier, named few-shot hypothesis\nadaptation (FHA). In FHA, we cannot access data in SD, as a result, the private\ninformation in SD will be protected well. To this end, we propose a target\norientated hypothesis adaptation network (TOHAN) to solve the FHA problem,\nwhere we generate highly-compatible unlabeled data (i.e., an intermediate\ndomain) to help train a target-domain classifier. TOHAN maintains two deep\nnetworks simultaneously, where one focuses on learning an intermediate domain\nand the other takes care of the intermediate-to-target distributional\nadaptation and the target-risk minimization. Experimental results show that\nTOHAN outperforms competitive baselines significantly.",
          "link": "http://arxiv.org/abs/2106.06326",
          "publishedOn": "2021-06-14T01:38:53.904Z",
          "wordCount": 635,
          "title": "TOHAN: A One-step Approach towards Few-shot Hypothesis Adaptation. (arXiv:2106.06326v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06317",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schubert_F/0/1/0/all/0/1\">Frederik Schubert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eimer_T/0/1/0/all/0/1\">Theresa Eimer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosenhahn_B/0/1/0/all/0/1\">Bodo Rosenhahn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lindauer_M/0/1/0/all/0/1\">Marius Lindauer</a>",
          "description": "The use of Reinforcement Learning (RL) agents in practical applications\nrequires the consideration of suboptimal outcomes, depending on the familiarity\nof the agent with its environment. This is especially important in\nsafety-critical environments, where errors can lead to high costs or damage. In\ndistributional RL, the risk-sensitivity can be controlled via different\ndistortion measures of the estimated return distribution. However, these\ndistortion functions require an estimate of the risk level, which is difficult\nto obtain and depends on the current state. In this work, we demonstrate the\nsuboptimality of a static risk level estimation and propose a method to\ndynamically select risk levels at each environment step. Our method ARA\n(Automatic Risk Adaptation) estimates the appropriate risk level in both known\nand unknown environments using a Random Network Distillation error. We show\nreduced failure rates by up to a factor of 7 and improved generalization\nperformance by up to 14% compared to both risk-aware and risk-agnostic agents\nin several locomotion environments.",
          "link": "http://arxiv.org/abs/2106.06317",
          "publishedOn": "2021-06-14T01:38:53.898Z",
          "wordCount": 583,
          "title": "Automatic Risk Adaptation in Distributional Reinforcement Learning. (arXiv:2106.06317v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06232",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_J/0/1/0/all/0/1\">Jiajun Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1\">Changnan Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yue Huang</a>",
          "description": "Deep Q Network (DQN) firstly kicked the door of deep reinforcement learning\n(DRL) via combining deep learning (DL) with reinforcement learning (RL), which\nhas noticed that the distribution of the acquired data would change during the\ntraining process. DQN found this property might cause instability for training,\nso it proposed effective methods to handle the downside of the property.\nInstead of focusing on the unfavourable aspects, we find it critical for RL to\nease the gap between the estimated data distribution and the ground truth data\ndistribution while supervised learning (SL) fails to do so. From this new\nperspective, we extend the basic paradigm of RL called the Generalized Policy\nIteration (GPI) into a more generalized version, which is called the\nGeneralized Data Distribution Iteration (GDI). We see massive RL algorithms and\ntechniques can be unified into the GDI paradigm, which can be considered as one\nof the special cases of GDI. We provide theoretical proof of why GDI is better\nthan GPI and how it works. Several practical algorithms based on GDI have been\nproposed to verify the effectiveness and extensiveness of it. Empirical\nexperiments prove our state-of-the-art (SOTA) performance on Arcade Learning\nEnvironment (ALE), wherein our algorithm has achieved 9620.98% mean human\nnormalized score (HNS), 1146.39% median HNS and 22 human world record\nbreakthroughs (HWRB) using only 200 training frames. Our work aims to lead the\nRL research to step into the journey of conquering the human world records and\nseek real superhuman agents on both performance and efficiency.",
          "link": "http://arxiv.org/abs/2106.06232",
          "publishedOn": "2021-06-14T01:38:53.890Z",
          "wordCount": 687,
          "title": "GDI: Rethinking What Makes Reinforcement Learning Different From Supervised Learning. (arXiv:2106.06232v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06245",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Tran_B/0/1/0/all/0/1\">Ba-Hien Tran</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rossi_S/0/1/0/all/0/1\">Simone Rossi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Milios_D/0/1/0/all/0/1\">Dimitrios Milios</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Michiardi_P/0/1/0/all/0/1\">Pietro Michiardi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bonilla_E/0/1/0/all/0/1\">Edwin V. Bonilla</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Filippone_M/0/1/0/all/0/1\">Maurizio Filippone</a>",
          "description": "We develop a novel method for carrying out model selection for Bayesian\nautoencoders (BAEs) by means of prior hyper-parameter optimization. Inspired by\nthe common practice of type-II maximum likelihood optimization and its\nequivalence to Kullback-Leibler divergence minimization, we propose to optimize\nthe distributional sliced-Wasserstein distance (DSWD) between the output of the\nautoencoder and the empirical data distribution. The advantages of this\nformulation are that we can estimate the DSWD based on samples and handle\nhigh-dimensional problems. We carry out posterior estimation of the BAE\nparameters via stochastic gradient Hamiltonian Monte Carlo and turn our BAE\ninto a generative model by fitting a flexible Dirichlet mixture model in the\nlatent space. Consequently, we obtain a powerful alternative to variational\nautoencoders, which are the preferred choice in modern applications of\nautoencoders for representation learning with uncertainty. We evaluate our\napproach qualitatively and quantitatively using a vast experimental campaign on\na number of unsupervised learning tasks and show that, in small-data regimes\nwhere priors matter, our approach provides state-of-the-art results,\noutperforming multiple competitive baselines.",
          "link": "http://arxiv.org/abs/2106.06245",
          "publishedOn": "2021-06-14T01:38:53.884Z",
          "wordCount": 597,
          "title": "Model Selection for Bayesian Autoencoders. (arXiv:2106.06245v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06300",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Plassier_V/0/1/0/all/0/1\">Vincent Plassier</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vono_M/0/1/0/all/0/1\">Maxime Vono</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Durmus_A/0/1/0/all/0/1\">Alain Durmus</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Moulines_E/0/1/0/all/0/1\">Eric Moulines</a>",
          "description": "Performing reliable Bayesian inference on a big data scale is becoming a\nkeystone in the modern era of machine learning. A workhorse class of methods to\nachieve this task are Markov chain Monte Carlo (MCMC) algorithms and their\ndesign to handle distributed datasets has been the subject of many works.\nHowever, existing methods are not completely either reliable or computationally\nefficient. In this paper, we propose to fill this gap in the case where the\ndataset is partitioned and stored on computing nodes within a cluster under a\nmaster/slaves architecture. We derive a user-friendly centralised distributed\nMCMC algorithm with provable scaling in high-dimensional settings. We\nillustrate the relevance of the proposed methodology on both synthetic and real\ndata experiments.",
          "link": "http://arxiv.org/abs/2106.06300",
          "publishedOn": "2021-06-14T01:38:53.866Z",
          "wordCount": 564,
          "title": "DG-LMC: A Turn-key and Scalable Synchronous Distributed MCMC Algorithm. (arXiv:2106.06300v1 [stat.ME])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06239",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Amani_S/0/1/0/all/0/1\">Sanae Amani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thrampoulidis_C/0/1/0/all/0/1\">Christos Thrampoulidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Lin F. Yang</a>",
          "description": "Safety in reinforcement learning has become increasingly important in recent\nyears. Yet, existing solutions either fail to strictly avoid choosing unsafe\nactions, which may lead to catastrophic results in safety-critical systems, or\nfail to provide regret guarantees for settings where safety constraints need to\nbe learned. In this paper, we address both problems by first modeling safety as\nan unknown linear cost function of states and actions, which must always fall\nbelow a certain threshold. We then present algorithms, termed SLUCB-QVI and\nRSLUCB-QVI, for episodic Markov decision processes (MDPs) with linear function\napproximation. We show that SLUCB-QVI and RSLUCB-QVI, while with \\emph{no\nsafety violation}, achieve a\n$\\tilde{\\mathcal{O}}\\left(\\kappa\\sqrt{d^3H^3T}\\right)$ regret, nearly matching\nthat of state-of-the-art unsafe algorithms, where $H$ is the duration of each\nepisode, $d$ is the dimension of the feature mapping, $\\kappa$ is a constant\ncharacterizing the safety constraints, and $T$ is the total number of action\nplays. We further present numerical simulations that corroborate our\ntheoretical findings.",
          "link": "http://arxiv.org/abs/2106.06239",
          "publishedOn": "2021-06-14T01:38:53.859Z",
          "wordCount": 585,
          "title": "Safe Reinforcement Learning with Linear Function Approximation. (arXiv:2106.06239v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06273",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Junshan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_K/0/1/0/all/0/1\">Kunqing Xie</a>",
          "description": "With the rapid growth of traffic sensors deployed, a massive amount of\ntraffic flow data are collected, revealing the long-term evolution of traffic\nflows and the gradual expansion of traffic networks. How to accurately\nforecasting these traffic flow attracts the attention of researchers as it is\nof great significance for improving the efficiency of transportation systems.\nHowever, existing methods mainly focus on the spatial-temporal correlation of\nstatic networks, leaving the problem of efficiently learning models on networks\nwith expansion and evolving patterns less studied. To tackle this problem, we\npropose a Streaming Traffic Flow Forecasting Framework, TrafficStream, based on\nGraph Neural Networks (GNNs) and Continual Learning (CL), achieving accurate\npredictions and high efficiency. Firstly, we design a traffic pattern fusion\nmethod, cleverly integrating the new patterns that emerged during the long-term\nperiod into the model. A JS-divergence-based algorithm is proposed to mine new\ntraffic patterns. Secondly, we introduce CL to consolidate the knowledge\nlearned previously and transfer them to the current model. Specifically, we\nadopt two strategies: historical data replay and parameter smoothing. We\nconstruct a streaming traffic dataset to verify the efficiency and\neffectiveness of our model. Extensive experiments demonstrate its excellent\npotential to extract traffic patterns with high efficiency on long-term\nstreaming network scene. The source code is available at\nhttps://github.com/AprLie/TrafficStream.",
          "link": "http://arxiv.org/abs/2106.06273",
          "publishedOn": "2021-06-14T01:38:53.853Z",
          "wordCount": 653,
          "title": "TrafficStream: A Streaming Traffic Flow Forecasting Framework Based on Graph Neural Networks and Continual Learning. (arXiv:2106.06273v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06199",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Amid_E/0/1/0/all/0/1\">Ehsan Amid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anil_R/0/1/0/all/0/1\">Rohan Anil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Warmuth_M/0/1/0/all/0/1\">Manfred K. Warmuth</a>",
          "description": "We study a local loss construction approach for optimizing neural networks.\nWe start by motivating the problem as minimizing a squared loss between the\npre-activations of each layer and a local target, plus a regularizer term on\nthe weights. The targets are chosen so that the first gradient descent step on\nthe local objectives recovers vanilla BackProp, while the exact solution to\neach problem results in a preconditioned gradient update. We improve the local\nloss construction by forming a Bregman divergence in each layer tailored to the\ntransfer function which keeps the local problem convex w.r.t. the weights. The\ngeneralized local problem is again solved iteratively by taking small gradient\ndescent steps on the weights, for which the first step recovers BackProp. We\nrun several ablations and show that our construction consistently improves\nconvergence, reducing the gap between first-order and second-order methods.",
          "link": "http://arxiv.org/abs/2106.06199",
          "publishedOn": "2021-06-14T01:38:53.845Z",
          "wordCount": 563,
          "title": "LocoProp: Enhancing BackProp via Local Loss Optimization. (arXiv:2106.06199v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06033",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mallen_A/0/1/0/all/0/1\">Alex Mallen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lange_H/0/1/0/all/0/1\">Henning Lange</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kutz_J/0/1/0/all/0/1\">J. Nathan Kutz</a>",
          "description": "Probabilistic forecasting of complex phenomena is paramount to various\nscientific disciplines and applications. Despite the generality and importance\nof the problem, general mathematical techniques that allow for stable long-term\nforecasts with calibrated uncertainty measures are lacking. For most time\nseries models, the difficulty of obtaining accurate probabilistic future time\nstep predictions increases with the prediction horizon. In this paper, we\nintroduce a surprisingly simple approach that characterizes time-varying\ndistributions and enables reasonably accurate predictions thousands of\ntimesteps into the future. This technique, which we call Deep Probabilistic\nKoopman (DPK), is based on recent advances in linear Koopman operator theory,\nand does not require time stepping for future time predictions. Koopman models\nalso tend to have a small parameter footprint (often less than 10,000\nparameters). We demonstrate the long-term forecasting performance of these\nmodels on a diversity of domains, including electricity demand forecasting,\natmospheric chemistry, and neuroscience. For electricity demand modeling, our\ndomain-agnostic technique outperforms all of 177 domain-specific competitors in\nthe most recent Global Energy Forecasting Competition.",
          "link": "http://arxiv.org/abs/2106.06033",
          "publishedOn": "2021-06-14T01:38:53.839Z",
          "wordCount": 601,
          "title": "Deep Probabilistic Koopman: Long-term time-series forecasting under periodic uncertainties. (arXiv:2106.06033v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06210",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ko_J/0/1/0/all/0/1\">Jihoon Ko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwon_T/0/1/0/all/0/1\">Taehyung Kwon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_K/0/1/0/all/0/1\">Kijung Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Juho Lee</a>",
          "description": "Graph neural networks (GNNs) are one of the most popular approaches to using\ndeep learning on graph-structured data, and they have shown state-of-the-art\nperformances on a variety of tasks. However, according to a recent study, a\ncareful choice of pooling functions, which are used for the aggregation or\nreadout operation in GNNs, is crucial for enabling GNNs to extrapolate. Without\nthe ideal combination of pooling functions, which varies across tasks, GNNs\ncompletely fail to generalize to out-of-distribution data, while the number of\npossible combinations grows exponentially with the number of layers. In this\npaper, we present GNP, a $L^p$ norm-like pooling function that is trainable\nend-to-end for any given task. Notably, GNP generalizes most of the widely-used\npooling functions. We verify experimentally that simply replacing all pooling\nfunctions with GNP enables GNNs to extrapolate well on many node-level,\ngraph-level, and set-related tasks; and GNP sometimes performs even better than\noptimal combinations of existing pooling functions.",
          "link": "http://arxiv.org/abs/2106.06210",
          "publishedOn": "2021-06-14T01:38:53.832Z",
          "wordCount": 580,
          "title": "Learning to Pool in Graph Neural Networks for Extrapolation. (arXiv:2106.06210v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06170",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1\">Yunhao Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rowland_M/0/1/0/all/0/1\">Mark Rowland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Munos_R/0/1/0/all/0/1\">R&#xe9;mi Munos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valko_M/0/1/0/all/0/1\">Michal Valko</a>",
          "description": "In practical reinforcement learning (RL), the discount factor used for\nestimating value functions often differs from that used for defining the\nevaluation objective. In this work, we study the effect that this discrepancy\nof discount factors has during learning, and discover a family of objectives\nthat interpolate value functions of two distinct discount factors. Our analysis\nsuggests new ways for estimating value functions and performing policy\noptimization updates, which demonstrate empirical performance gains. This\nframework also leads to new insights on commonly-used deep RL heuristic\nmodifications to policy optimization algorithms.",
          "link": "http://arxiv.org/abs/2106.06170",
          "publishedOn": "2021-06-14T01:38:53.813Z",
          "wordCount": 518,
          "title": "Taylor Expansion of Discount Factors. (arXiv:2106.06170v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06041",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yoon_J/0/1/0/all/0/1\">Jongmin Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1\">Sung Ju Hwang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Juho Lee</a>",
          "description": "While adversarial training is considered as a standard defense method against\nadversarial attacks for image classifiers, adversarial purification, which\npurifies attacked images into clean images with a standalone purification\nmodel, has shown promises as an alternative defense method. Recently, an\nEnergy-Based Model (EBM) trained with Markov-Chain Monte-Carlo (MCMC) has been\nhighlighted as a purification model, where an attacked image is purified by\nrunning a long Markov-chain using the gradients of the EBM. Yet, the\npracticality of the adversarial purification using an EBM remains questionable\nbecause the number of MCMC steps required for such purification is too large.\nIn this paper, we propose a novel adversarial purification method based on an\nEBM trained with Denoising Score-Matching (DSM). We show that an EBM trained\nwith DSM can quickly purify attacked images within a few steps. We further\nintroduce a simple yet effective randomized purification scheme that injects\nrandom noises into images before purification. This process screens the\nadversarial perturbations imposed on images by the random noises and brings the\nimages to the regime where the EBM can denoise well. We show that our\npurification method is robust against various attacks and demonstrate its\nstate-of-the-art performances.",
          "link": "http://arxiv.org/abs/2106.06041",
          "publishedOn": "2021-06-14T01:38:53.806Z",
          "wordCount": 620,
          "title": "Adversarial purification with Score-based generative models. (arXiv:2106.06041v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06110",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qureshi_S/0/1/0/all/0/1\">Syed Arbaaz Qureshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehta_S/0/1/0/all/0/1\">Sonu Mehta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhagwan_R/0/1/0/all/0/1\">Ranjita Bhagwan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_R/0/1/0/all/0/1\">Rahul Kumar</a>",
          "description": "In recent times, it has been shown that one can use code as data to aid\nvarious applications such as automatic commit message generation, automatic\ngeneration of pull request descriptions and automatic program repair. Take for\ninstance the problem of commit message generation. Treating source code as a\nsequence of tokens, state of the art techniques generate commit messages using\nneural machine translation models. However, they tend to ignore the syntactic\nstructure of programming languages.\n\nPrevious work, i.e., code2seq has used structural information from Abstract\nSyntax Tree (AST) to represent source code and they use it to automatically\ngenerate method names. In this paper, we elaborate upon this state of the art\napproach and modify it to represent source code edits. We determine the effect\nof using such syntactic structure for the problem of classifying code edits.\nInspired by the code2seq approach, we evaluate how using structural information\nfrom AST, i.e., paths between AST leaf nodes can help with the task of code\nedit classification on two datasets of fine-grained syntactic edits.\n\nOur experiments shows that attempts of adding syntactic structure does not\nresult in any improvements over less sophisticated methods. The results suggest\nthat techniques such as code2seq, while promising, have a long way to go before\nthey can be generically applied to learning code edit representations. We hope\nthat these results will benefit other researchers and inspire them to work\nfurther on this problem.",
          "link": "http://arxiv.org/abs/2106.06110",
          "publishedOn": "2021-06-14T01:38:53.684Z",
          "wordCount": 666,
          "title": "Assessing the Effectiveness of Syntactic Structure to Learn Code Edit Representations. (arXiv:2106.06110v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06097",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lyu_Y/0/1/0/all/0/1\">Yueming Lyu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tsang_I/0/1/0/all/0/1\">Ivor Tsang</a>",
          "description": "Recent studies show a close connection between neural networks (NN) and\nkernel methods. However, most of these analyses (e.g., NTK) focus on the\ninfluence of (infinite) width instead of the depth of NN models. There remains\na gap between theory and practical network designs that benefit from the depth.\nThis paper first proposes a novel kernel family named Neural Optimization\nKernel (NOK). Our kernel is defined as the inner product between two $T$-step\nupdated functionals in RKHS w.r.t. a regularized optimization problem.\nTheoretically, we proved the monotonic descent property of our update rule for\nboth convex and non-convex problems, and a $O(1/T)$ convergence rate of our\nupdates for convex problems. Moreover, we propose a data-dependent structured\napproximation of our NOK, which builds the connection between training deep NNs\nand kernel methods associated with NOK. The resultant computational graph is a\nResNet-type finite width NN. Our structured approximation preserved the\nmonotonic descent property and $O(1/T)$ convergence rate. Namely, a $T$-layer\nNN performs $T$-step monotonic descent updates. Notably, we show our\n$T$-layered structured NN with ReLU maintains a $O(1/T)$ convergence rate\nw.r.t. a convex regularized problem, which explains the success of ReLU on\ntraining deep NN from a NN architecture optimization perspective. For the\nunsupervised learning and the shared parameter case, we show the equivalence of\ntraining structured NN with GD and performing functional gradient descent in\nRKHS associated with a fixed (data-dependent) NOK at an infinity-width regime.\nFor finite NOKs, we prove generalization bounds. Remarkably, we show that\noverparameterized deep NN (NOK) can increase the expressive power to reduce\nempirical risk and reduce the generalization bound at the same time. Extensive\nexperiments verify the robustness of our structured NOK blocks.",
          "link": "http://arxiv.org/abs/2106.06097",
          "publishedOn": "2021-06-14T01:38:53.677Z",
          "wordCount": 713,
          "title": "Neural Optimization Kernel: Towards Robust Deep Learning. (arXiv:2106.06097v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06167",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_L/0/1/0/all/0/1\">Liwei Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xuanhao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yan Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_K/0/1/0/all/0/1\">Kai Zheng</a>",
          "description": "Monitoring complex systems results in massive multivariate time series data,\nand anomaly detection of these data is very important to maintain the normal\noperation of the systems. Despite the recent emergence of a large number of\nanomaly detection algorithms for multivariate time series, most of them ignore\nthe correlation modeling among multivariate, which can often lead to poor\nanomaly detection results. In this work, we propose a novel anomaly detection\nmodel for multivariate time series with \\underline{HI}gh-order\n\\underline{F}eature \\underline{I}nteractions (HIFI). More specifically, HIFI\nbuilds multivariate feature interaction graph automatically and uses the graph\nconvolutional neural network to achieve high-order feature interactions, in\nwhich the long-term temporal dependencies are modeled by attention mechanisms\nand a variational encoding technique is utilized to improve the model\nperformance and robustness. Extensive experiments on three publicly available\ndatasets demonstrate the superiority of our framework compared with\nstate-of-the-art approaches.",
          "link": "http://arxiv.org/abs/2106.06167",
          "publishedOn": "2021-06-14T01:38:53.651Z",
          "wordCount": 577,
          "title": "HIFI: Anomaly Detection for Multivariate Time Series with High-order Feature Interactions. (arXiv:2106.06167v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06159",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gan_Y/0/1/0/all/0/1\">Yanhai Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1\">Xinghui Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Huiyu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_F/0/1/0/all/0/1\">Feng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1\">Junyu Dong</a>",
          "description": "Clustering is one of the fundamental tasks in computer vision and pattern\nrecognition. Recently, deep clustering methods (algorithms based on deep\nlearning) have attracted wide attention with their impressive performance. Most\nof these algorithms combine deep unsupervised representation learning and\nstandard clustering together. However, the separation of representation\nlearning and clustering will lead to suboptimal solutions because the two-stage\nstrategy prevents representation learning from adapting to subsequent tasks\n(e.g., clustering according to specific cues). To overcome this issue, efforts\nhave been made in the dynamic adaption of representation and cluster\nassignment, whereas current state-of-the-art methods suffer from heuristically\nconstructed objectives with representation and cluster assignment alternatively\noptimized. To further standardize the clustering problem, we audaciously\nformulate the objective of clustering as finding a precise feature as the cue\nfor cluster assignment. Based on this, we propose a general-purpose deep\nclustering framework which radically integrates representation learning and\nclustering into a single pipeline for the first time. The proposed framework\nexploits the powerful ability of recently developed generative models for\nlearning intrinsic features, and imposes an entropy minimization on the\ndistribution of the cluster assignment by a dedicated variational algorithm.\nExperimental results show that the performance of the proposed method is\nsuperior, or at least comparable to, the state-of-the-art methods on the\nhandwritten digit recognition, fashion recognition, face recognition and object\nrecognition benchmark datasets.",
          "link": "http://arxiv.org/abs/2106.06159",
          "publishedOn": "2021-06-14T01:38:53.629Z",
          "wordCount": 659,
          "title": "Learning the Precise Feature for Cluster Assignment. (arXiv:2106.06159v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06162",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Saehoon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sungwoong Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Juho Lee</a>",
          "description": "Unsupervised representation learning has recently received lots of interest\ndue to its powerful generalizability through effectively leveraging large-scale\nunlabeled data. There are two prevalent approaches for this, contrastive\nlearning and generative pre-training, where the former learns representations\nfrom instance-wise discrimination tasks and the latter learns them from\nestimating the likelihood. These seemingly orthogonal approaches have their own\nstrengths and weaknesses. Contrastive learning tends to extract semantic\ninformation and discards details irrelevant for classifying objects, making the\nrepresentations effective for discriminative tasks while degrading robustness\nto out-of-distribution data. On the other hand, the generative pre-training\ndirectly estimates the data distribution, so the representations tend to be\nrobust but not optimal for discriminative tasks. In this paper, we show that we\ncould achieve the best of both worlds by a hybrid training scheme.\nSpecifically, we demonstrated that a transformer-based encoder-decoder\narchitecture trained with both contrastive and generative losses can learn\nhighly discriminative and robust representations without hurting the generative\nperformance. We extensively validate our approach on various tasks.",
          "link": "http://arxiv.org/abs/2106.06162",
          "publishedOn": "2021-06-14T01:38:53.620Z",
          "wordCount": 589,
          "title": "Hybrid Generative-Contrastive Representation Learning. (arXiv:2106.06162v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06134",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yao Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaorui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_N/0/1/0/all/0/1\">Neil Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jiliang Tang</a>",
          "description": "Graph neural networks (GNNs) have shown great prowess in learning\nrepresentations suitable for numerous graph-based machine learning tasks. When\napplied to semi-supervised node classification, GNNs are widely believed to\nwork well due to the homophily assumption (``like attracts like''), and fail to\ngeneralize to heterophilous graphs where dissimilar nodes connect. Recent works\ndesign new architectures to overcome such heterophily-related limitations,\nciting poor baseline performance and new architecture improvements on a few\nheterophilous graph benchmark datasets as evidence for this notion. In our\nexperiments, we empirically find that standard graph convolutional networks\n(GCNs) can actually achieve better performance than such carefully designed\nmethods on some commonly used heterophilous graphs. This motivates us to\nreconsider whether homophily is truly necessary for good GNN performance. We\nfind that this claim is not quite true, and in fact, GCNs can achieve strong\nperformance on heterophilous graphs under certain conditions. Our work\ncarefully characterizes these conditions, and provides supporting theoretical\nunderstanding and empirical observations. Finally, we examine existing\nheterophilous graphs benchmarks and reconcile how the GCN (under)performs on\nthem based on this understanding.",
          "link": "http://arxiv.org/abs/2106.06134",
          "publishedOn": "2021-06-14T01:38:53.614Z",
          "wordCount": 606,
          "title": "Is Homophily a Necessity for Graph Neural Networks?. (arXiv:2106.06134v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06147",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abdelnour_J/0/1/0/all/0/1\">Jerome Abdelnour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rouat_J/0/1/0/all/0/1\">Jean Rouat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salvi_G/0/1/0/all/0/1\">Giampiero Salvi</a>",
          "description": "The goal of the Acoustic Question Answering (AQA) task is to answer a\nfree-form text question about the content of an acoustic scene. It was inspired\nby the Visual Question Answering (VQA) task. In this paper, based on the\npreviously introduced CLEAR dataset, we propose a new benchmark for AQA that\nemphasizes the specific challenges of acoustic inputs, e.g. variable duration\nscenes. We also introduce NAAQA, a neural architecture that leverages specific\nproperties of acoustic inputs. The usage of time and frequency 1D convolutions\nto process 2D spectro-temporal representations of acoustic content shows\npromising results and enables reductions in model complexity. NAAQA achieves\n91.6% of accuracy on the AQA task with about 7 times fewer parameters than the\npreviously explored VQA model. We provide a detailed analysis of the results\nfor the different question types. The effectiveness of coordinate maps in this\nacoustic context was also studied and we show that time coordinate maps augment\ntemporal localization capabilities which enhance performance of the network by\nabout 17 percentage points.",
          "link": "http://arxiv.org/abs/2106.06147",
          "publishedOn": "2021-06-14T01:38:53.607Z",
          "wordCount": 622,
          "title": "NAAQA: A Neural Architecture for Acoustic Question Answering. (arXiv:2106.06147v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06168",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xuanli He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nassar_I/0/1/0/all/0/1\">Islam Nassar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiros_J/0/1/0/all/0/1\">Jamie Kiros</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haffari_G/0/1/0/all/0/1\">Gholamreza Haffari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Norouzi_M/0/1/0/all/0/1\">Mohammad Norouzi</a>",
          "description": "Semi-Supervised Learning (SSL) has seen success in many application domains,\nbut this success often hinges on the availability of task-specific unlabeled\ndata. Knowledge distillation (KD) has enabled compressing deep networks and\nensembles, achieving the best results when distilling knowledge on fresh\ntask-specific unlabeled examples. However, task-specific unlabeled data can be\nchallenging to find. We present a general framework called \"generate, annotate,\nand learn (GAL)\" that uses unconditional generative models to synthesize\nin-domain unlabeled data, helping advance SSL and KD on different tasks. To\nobtain strong task-specific generative models, we adopt generic generative\nmodels, pretrained on open-domain data, and fine-tune them on inputs from\nspecific tasks. Then, we use existing classifiers to annotate generated\nunlabeled examples with soft pseudo labels, which are used for additional\ntraining. When self-training is combined with samples generated from\nGPT2-large, fine-tuned on the inputs of each GLUE task, we outperform a strong\nRoBERTa-large baseline on the GLUE benchmark. Moreover, KD on GPT-2 samples\nyields a new state-of-the-art for 6-layer transformers on the GLUE leaderboard.\nFinally, self-training with GAL offers significant gains on image\nclassification on CIFAR-10 and four tabular tasks from the UCI repository",
          "link": "http://arxiv.org/abs/2106.06168",
          "publishedOn": "2021-06-14T01:38:53.601Z",
          "wordCount": 625,
          "title": "Generate, Annotate, and Learn: Generative Models Advance Self-Training and Knowledge Distillation. (arXiv:2106.06168v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06135",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zha_D/0/1/0/all/0/1\">Daochen Zha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1\">Jingru Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1\">Wenye Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Sheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lian_X/0/1/0/all/0/1\">Xiangru Lian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xia Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Ji Liu</a>",
          "description": "Games are abstractions of the real world, where artificial agents learn to\ncompete and cooperate with other agents. While significant achievements have\nbeen made in various perfect- and imperfect-information games, DouDizhu (a.k.a.\nFighting the Landlord), a three-player card game, is still unsolved. DouDizhu\nis a very challenging domain with competition, collaboration, imperfect\ninformation, large state space, and particularly a massive set of possible\nactions where the legal actions vary significantly from turn to turn.\nUnfortunately, modern reinforcement learning algorithms mainly focus on simple\nand small action spaces, and not surprisingly, are shown not to make\nsatisfactory progress in DouDizhu. In this work, we propose a conceptually\nsimple yet effective DouDizhu AI system, namely DouZero, which enhances\ntraditional Monte-Carlo methods with deep neural networks, action encoding, and\nparallel actors. Starting from scratch in a single server with four GPUs,\nDouZero outperformed all the existing DouDizhu AI programs in days of training\nand was ranked the first in the Botzone leaderboard among 344 AI agents.\nThrough building DouZero, we show that classic Monte-Carlo methods can be made\nto deliver strong results in a hard domain with a complex action space. The\ncode and an online demo are released at https://github.com/kwai/DouZero with\nthe hope that this insight could motivate future work.",
          "link": "http://arxiv.org/abs/2106.06135",
          "publishedOn": "2021-06-14T01:38:53.582Z",
          "wordCount": 649,
          "title": "DouZero: Mastering DouDizhu with Self-Play Deep Reinforcement Learning. (arXiv:2106.06135v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06151",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kuroyanagi_I/0/1/0/all/0/1\">Ibuki Kuroyanagi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hayashi_T/0/1/0/all/0/1\">Tomoki Hayashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takeda_K/0/1/0/all/0/1\">Kazuya Takeda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Toda_T/0/1/0/all/0/1\">Tomoki Toda</a>",
          "description": "An anomalous sound detection system to detect unknown anomalous sounds\nusually needs to be built using only normal sound data. Moreover, it is\ndesirable to improve the system by effectively using a small amount of\nanomalous sound data, which will be accumulated through the system's operation.\nAs one of the methods to meet these requirements, we focus on a binary\nclassification model that is developed by using not only normal data but also\noutlier data in the other domains as pseudo-anomalous sound data, which can be\neasily updated by using anomalous data. In this paper, we implement a new loss\nfunction based on metric learning to learn the distance relationship from each\nclass centroid in feature space for the binary classification model. The\nproposed multi-task learning of the binary classification and the metric\nlearning makes it possible to build the feature space where the within-class\nvariance is minimized and the between-class variance is maximized while keeping\nnormal and anomalous classes linearly separable. We also investigate the\neffectiveness of additionally using anomalous sound data for further improving\nthe binary classification model. Our results showed that multi-task learning\nusing binary classification and metric learning to consider the distance from\neach class centroid in the feature space is effective, and performance can be\nsignificantly improved by using even a small amount of anomalous data during\ntraining.",
          "link": "http://arxiv.org/abs/2106.06151",
          "publishedOn": "2021-06-14T01:38:53.576Z",
          "wordCount": 670,
          "title": "Anomalous Sound Detection Using a Binary Classification Model and Class Centroids. (arXiv:2106.06151v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06158",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gad_A/0/1/0/all/0/1\">Ahmed Fawzy Gad</a>",
          "description": "This paper introduces PyGAD, an open-source easy-to-use Python library for\nbuilding the genetic algorithm. PyGAD supports a wide range of parameters to\ngive the user control over everything in its life cycle. This includes, but is\nnot limited to, population, gene value range, gene data type, parent selection,\ncrossover, and mutation. PyGAD is designed as a general-purpose optimization\nlibrary that allows the user to customize the fitness function. Its usage\nconsists of 3 main steps: build the fitness function, create an instance of the\npygad.GA class, and calling the pygad.GA.run() method. The library supports\ntraining deep learning models created either with PyGAD itself or with\nframeworks like Keras and PyTorch. Given its stable state, PyGAD is also in\nactive development to respond to the user's requested features and enhancement\nreceived on GitHub https://github.com/ahmedfgad/GeneticAlgorithmPython. PyGAD\ncomes with documentation https://pygad.readthedocs.io for further details and\nexamples.",
          "link": "http://arxiv.org/abs/2106.06158",
          "publishedOn": "2021-06-14T01:38:53.569Z",
          "wordCount": 587,
          "title": "PyGAD: An Intuitive Genetic Algorithm Python Library. (arXiv:2106.06158v1 [cs.NE])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06139",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moore_K/0/1/0/all/0/1\">Kristen Moore</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_S/0/1/0/all/0/1\">Shenjun Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1\">Zhen He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rudolf_T/0/1/0/all/0/1\">Torsten Rudolf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fisher_N/0/1/0/all/0/1\">Nils Fisher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Victor_B/0/1/0/all/0/1\">Brandon Victor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jindal_N/0/1/0/all/0/1\">Neha Jindal</a>",
          "description": "In this paper we present the results of our experiments in training and\ndeploying a self-supervised retrieval-based chatbot trained with contrastive\nlearning for assisting customer support agents. In contrast to most existing\nresearch papers in this area where the focus is on solving just one component\nof a deployable chatbot, we present an end-to-end set of solutions to take the\nreader from an unlabelled chatlogs to a deployed chatbot. This set of solutions\nincludes creating a self-supervised dataset and a weakly labelled dataset from\nchatlogs, as well as a systematic approach to selecting a fixed list of canned\nresponses. We present a hierarchical-based RNN architecture for the response\nselection model, chosen for its ability to cache intermediate utterance\nembeddings, which helped to meet deployment inference speed requirements. We\ncompare the performance of this architecture across 3 different learning\nobjectives: self-supervised contrastive learning, binary classification, and\nmulti-class classification. We find that using a self-supervised contrastive\nlearning model outperforms training the binary and multi-class classification\nmodels on a weakly labelled dataset. Our results validate that the\nself-supervised contrastive learning approach can be effectively used for a\nreal-world chatbot scenario.",
          "link": "http://arxiv.org/abs/2106.06139",
          "publishedOn": "2021-06-14T01:38:53.562Z",
          "wordCount": 624,
          "title": "A comprehensive solution to retrieval-based chatbot construction. (arXiv:2106.06139v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06142",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhai_R/0/1/0/all/0/1\">Runtian Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dan_C/0/1/0/all/0/1\">Chen Dan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolter_J/0/1/0/all/0/1\">J. Zico Kolter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ravikumar_P/0/1/0/all/0/1\">Pradeep Ravikumar</a>",
          "description": "Many machine learning tasks involve subpopulation shift where the testing\ndata distribution is a subpopulation of the training distribution. For such\nsettings, a line of recent work has proposed the use of a variant of empirical\nrisk minimization(ERM) known as distributionally robust optimization (DRO). In\nthis work, we apply DRO to real, large-scale tasks with subpopulation shift,\nand observe that DRO performs relatively poorly, and moreover has severe\ninstability. We identify one direct cause of this phenomenon: sensitivity of\nDRO to outliers in the datasets. To resolve this issue, we propose the\nframework of DORO, for Distributional and Outlier Robust Optimization. At the\ncore of this approach is a refined risk function which prevents DRO from\noverfitting to potential outliers. We instantiate DORO for the Cressie-Read\nfamily of R\\'enyi divergence, and delve into two specific instances of this\nfamily: CVaR and $\\chi^2$-DRO. We theoretically prove the effectiveness of the\nproposed method, and empirically show that DORO improves the performance and\nstability of DRO with experiments on large modern datasets, thereby positively\naddressing the open question raised by Hashimoto et al., 2018.",
          "link": "http://arxiv.org/abs/2106.06142",
          "publishedOn": "2021-06-14T01:38:53.554Z",
          "wordCount": 614,
          "title": "DORO: Distributional and Outlier Robust Optimization. (arXiv:2106.06142v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06095",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ament_S/0/1/0/all/0/1\">Sebastian Ament</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gomes_C/0/1/0/all/0/1\">Carla Gomes</a>",
          "description": "Sparse Bayesian Learning (SBL) is a powerful framework for attaining sparsity\nin probabilistic models. Herein, we propose a coordinate ascent algorithm for\nSBL termed Relevance Matching Pursuit (RMP) and show that, as its noise\nvariance parameter goes to zero, RMP exhibits a surprising connection to\nStepwise Regression. Further, we derive novel guarantees for Stepwise\nRegression algorithms, which also shed light on RMP. Our guarantees for Forward\nRegression improve on deterministic and probabilistic results for Orthogonal\nMatching Pursuit with noise. Our analysis of Backward Regression on determined\nsystems culminates in a bound on the residual of the optimal solution to the\nsubset selection problem that, if satisfied, guarantees the optimality of the\nresult. To our knowledge, this bound is the first that can be computed in\npolynomial time and depends chiefly on the smallest singular value of the\nmatrix. We report numerical experiments using a variety of feature selection\nalgorithms. Notably, RMP and its limiting variant are both efficient and\nmaintain strong performance with correlated features.",
          "link": "http://arxiv.org/abs/2106.06095",
          "publishedOn": "2021-06-14T01:38:53.536Z",
          "wordCount": 600,
          "title": "Sparse Bayesian Learning via Stepwise Regression. (arXiv:2106.06095v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06048",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ferianc_M/0/1/0/all/0/1\">Martin Ferianc</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Que_Z/0/1/0/all/0/1\">Zhiqiang Que</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_H/0/1/0/all/0/1\">Hongxiang Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luk_W/0/1/0/all/0/1\">Wayne Luk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodrigues_M/0/1/0/all/0/1\">Miguel Rodrigues</a>",
          "description": "Neural networks have demonstrated their great performance in a wide range of\ntasks. Especially in time-series analysis, recurrent architectures based on\nlong-short term memory (LSTM) cells have manifested excellent capability to\nmodel time dependencies in real-world data. However, standard recurrent\narchitectures cannot estimate their uncertainty which is essential for\nsafety-critical applications such as in medicine. In contrast, Bayesian\nrecurrent neural networks (RNNs) are able to provide uncertainty estimation\nwith improved accuracy. Nonetheless, Bayesian RNNs are computationally and\nmemory demanding, which limits their practicality despite their advantages. To\naddress this issue, we propose an FPGA-based hardware design to accelerate\nBayesian LSTM-based RNNs. To further improve the overall algorithmic-hardware\nperformance, a co-design framework is proposed to explore the most optimal\nalgorithmic-hardware configurations for Bayesian RNNs. We conduct extensive\nexperiments on health-related tasks to demonstrate the improvement of our\ndesign and the effectiveness of our framework. Compared with GPU\nimplementation, our FPGA-based design can achieve up to 10 times speedup with\nnearly 106 times higher energy efficiency. To the best of our knowledge, this\nis the first work targeting the acceleration of Bayesian RNNs on FPGAs.",
          "link": "http://arxiv.org/abs/2106.06048",
          "publishedOn": "2021-06-14T01:38:53.529Z",
          "wordCount": 621,
          "title": "High-Performance FPGA-based Accelerator for Bayesian Recurrent Neural Networks. (arXiv:2106.06048v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06129",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vasu_P/0/1/0/all/0/1\">Pavan Kumar Anasosalu Vasu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saxena_S/0/1/0/all/0/1\">Shreyas Saxena</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuzel_O/0/1/0/all/0/1\">Oncel Tuzel</a>",
          "description": "Recent works have shown that deep neural networks benefit from multi-task\nlearning by learning a shared representation across several related tasks.\nHowever, performance of such systems depend on relative weighting between\nvarious losses involved during training. Prior works on loss weighting schemes\nassume that instances are equally easy or hard for all tasks. In order to break\nthis assumption, we let the training process dictate the optimal weighting of\ntasks for every instance in the dataset. More specifically, we equip every\ninstance in the dataset with a set of learnable parameters (instance-level task\nparameters) where the cardinality is equal to the number of tasks learned by\nthe model. These parameters model the weighting of each task for an instance.\nThey are updated by gradient descent and do not require hand-crafted rules. We\nconduct extensive experiments on SURREAL and CityScapes datasets, for human\nshape and pose estimation, depth estimation and semantic segmentation tasks. In\nthese tasks, our approach outperforms recent dynamic loss weighting approaches,\ne.g. reducing surface estimation errors by 8.97% on SURREAL. When applied to\ndatasets where one or more tasks can have noisy annotations, the proposed\nmethod learns to prioritize learning from clean labels for a given task, e.g.\nreducing surface estimation errors by up to 60%. We also show that we can\nreliably detect corrupt labels for a given task as a by-product from learned\ninstance-level task parameters.",
          "link": "http://arxiv.org/abs/2106.06129",
          "publishedOn": "2021-06-14T01:38:53.522Z",
          "wordCount": 665,
          "title": "Instance-Level Task Parameters: A Robust Multi-task Weighting Framework. (arXiv:2106.06129v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06098",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_G/0/1/0/all/0/1\">Guanya Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azizzadenesheli_K/0/1/0/all/0/1\">Kamyar Azizzadenesheli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chung_S/0/1/0/all/0/1\">Soon-Jo Chung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yue_Y/0/1/0/all/0/1\">Yisong Yue</a>",
          "description": "We present an online multi-task learning approach for adaptive nonlinear\ncontrol, which we call Online Meta-Adaptive Control (OMAC). The goal is to\ncontrol a nonlinear system subject to adversarial disturbance and unknown\n$\\textit{environment-dependent}$ nonlinear dynamics, under the assumption that\nthe environment-dependent dynamics can be well captured with some shared\nrepresentation. Our approach is motivated by robot control, where a robotic\nsystem encounters a sequence of new environmental conditions that it must\nquickly adapt to. A key emphasis is to integrate online representation learning\nwith established methods from control theory, in order to arrive at a unified\nframework that yields both control-theoretic and learning-theoretic guarantees.\nWe provide instantiations of our approach under varying conditions, leading to\nthe first non-asymptotic end-to-end convergence guarantee for multi-task\nadaptive nonlinear control. OMAC can also be integrated with deep\nrepresentation learning. Experiments show that OMAC significantly outperforms\nconventional adaptive control approaches which do not learn the shared\nrepresentation.",
          "link": "http://arxiv.org/abs/2106.06098",
          "publishedOn": "2021-06-14T01:38:53.516Z",
          "wordCount": 586,
          "title": "Meta-Adaptive Nonlinear Control: Theory and Algorithms. (arXiv:2106.06098v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06127",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ryu_M/0/1/0/all/0/1\">Minseok Ryu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1\">Kibaek Kim</a>",
          "description": "Differential privacy (DP) techniques can be applied to the federated learning\nmodel to protect data privacy against inference attacks to communication among\nthe learning agents. The DP techniques, however, hinder achieving a greater\nlearning performance while ensuring strong data privacy. In this paper we\ndevelop a DP inexact alternating direction method of multipliers algorithm that\nsolves a sequence of trust-region subproblems with the objective perturbation\nby random noises generated from a Laplace distribution. We show that our\nalgorithm provides $\\bar{\\epsilon}$-DP for every iteration and\n$\\mathcal{O}(1/T)$ rate of convergence in expectation, where $T$ is the number\nof iterations. Using MNIST and FEMNIST datasets for the image classification,\nwe demonstrate that our algorithm reduces the testing error by at most $22\\%$\ncompared with the existing DP algorithm, while achieving the same level of data\nprivacy. The numerical experiment also shows that our algorithm converges\nfaster than the existing algorithm.",
          "link": "http://arxiv.org/abs/2106.06127",
          "publishedOn": "2021-06-14T01:38:53.509Z",
          "wordCount": 571,
          "title": "Differentially Private Federated Learning via Inexact ADMM. (arXiv:2106.06127v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06143",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ma_F/0/1/0/all/0/1\">Fanhe Ma</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_F/0/1/0/all/0/1\">Faen Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ben_S/0/1/0/all/0/1\">Shenglan Ben</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Qin_S/0/1/0/all/0/1\">Shuxin Qin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhou_P/0/1/0/all/0/1\">Pengcheng Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhou_C/0/1/0/all/0/1\">Changsheng Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_F/0/1/0/all/0/1\">Fengyi Xu</a>",
          "description": "In this paper, we are interested in building a domain knowledge based deep\nlearning framework to solve the chiller plants energy optimization problems.\nCompared to the hotspot applications of deep learning (e.g. image\nclassification and NLP), it is difficult to collect enormous data for deep\nnetwork training in real-world physical systems. Most existing methods reduce\nthe complex systems into linear model to facilitate the training on small\nsamples. To tackle the small sample size problem, this paper considers domain\nknowledge in the structure and loss design of deep network to build a nonlinear\nmodel with lower redundancy function space. Specifically, the energy\nconsumption estimation of most chillers can be physically viewed as an\ninput-output monotonic problem. Thus, we can design a Neural Network with\nmonotonic constraints to mimic the physical behavior of the system. We verify\nthe proposed method in a cooling system of a data center, experimental results\nshow the superiority of our framework in energy optimization compared to the\nexisting ones.",
          "link": "http://arxiv.org/abs/2106.06143",
          "publishedOn": "2021-06-14T01:38:53.487Z",
          "wordCount": 613,
          "title": "Monotonic Neural Network: combining Deep Learning with Domain Knowledge for Chiller Plants Energy Optimization. (arXiv:2106.06143v1 [eess.SP])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06126",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swaminathan_R/0/1/0/all/0/1\">Rupak Vignesh Swaminathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parthasarathi_S/0/1/0/all/0/1\">Sree Hari Krishnan Parthasarathi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_C/0/1/0/all/0/1\">Chunchuan Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mouchtaris_A/0/1/0/all/0/1\">Athanasios Mouchtaris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kunzmann_S/0/1/0/all/0/1\">Siegfried Kunzmann</a>",
          "description": "We present results from Alexa speech teams on semi-supervised learning (SSL)\nof acoustic models (AM) with experiments spanning over 3000 hours of GPU time,\nmaking our study one of the largest of its kind. We discuss SSL for AMs in a\nsmall footprint setting, showing that a smaller capacity model trained with 1\nmillion hours of unsupervised data can outperform a baseline supervised system\nby 14.3% word error rate reduction (WERR). When increasing the supervised data\nto seven-fold, our gains diminish to 7.1% WERR; to improve SSL efficiency at\nlarger supervised data regimes, we employ a step-wise distillation into a\nsmaller model, obtaining a WERR of 14.4%. We then switch to SSL using larger\nstudent models in low data regimes; while learning efficiency with unsupervised\ndata is higher, student models may outperform teacher models in such a setting.\nWe develop a theoretical sketch to explain this behavior.",
          "link": "http://arxiv.org/abs/2106.06126",
          "publishedOn": "2021-06-14T01:38:53.478Z",
          "wordCount": 588,
          "title": "Exploiting Large-scale Teacher-Student Training for On-device Acoustic Models. (arXiv:2106.06126v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06056",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiawei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Linyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Huichen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaolu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shuang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>",
          "description": "Boundary based blackbox attack has been recognized as practical and\neffective, given that an attacker only needs to access the final model\nprediction. However, the query efficiency of it is in general high especially\nfor high dimensional image data. In this paper, we show that such efficiency\nhighly depends on the scale at which the attack is applied, and attacking at\nthe optimal scale significantly improves the efficiency. In particular, we\npropose a theoretical framework to analyze and show three key characteristics\nto improve the query efficiency. We prove that there exists an optimal scale\nfor projective gradient estimation. Our framework also explains the\nsatisfactory performance achieved by existing boundary black-box attacks. Based\non our theoretical framework, we propose Progressive-Scale enabled projective\nBoundary Attack (PSBA) to improve the query efficiency via progressive scaling\ntechniques. In particular, we employ Progressive-GAN to optimize the scale of\nprojections, which we call PSBA-PGAN. We evaluate our approach on both spatial\nand frequency scales. Extensive experiments on MNIST, CIFAR-10, CelebA, and\nImageNet against different models including a real-world face recognition API\nshow that PSBA-PGAN significantly outperforms existing baseline attacks in\nterms of query efficiency and attack success rate. We also observe relatively\nstable optimal scales for different models and datasets. The code is publicly\navailable at https://github.com/AI-secure/PSBA.",
          "link": "http://arxiv.org/abs/2106.06056",
          "publishedOn": "2021-06-14T01:38:53.470Z",
          "wordCount": 656,
          "title": "Progressive-Scale Boundary Blackbox Attack via Projective Gradient Estimation. (arXiv:2106.06056v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06080",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abnar_S/0/1/0/all/0/1\">Samira Abnar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berg_R/0/1/0/all/0/1\">Rianne van den Berg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghiasi_G/0/1/0/all/0/1\">Golnaz Ghiasi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dehghani_M/0/1/0/all/0/1\">Mostafa Dehghani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalchbrenner_N/0/1/0/all/0/1\">Nal Kalchbrenner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sedghi_H/0/1/0/all/0/1\">Hanie Sedghi</a>",
          "description": "We focus on the problem of domain adaptation when the goal is shifting the\nmodel towards the target distribution, rather than learning domain invariant\nrepresentations. It has been shown that under the following two assumptions:\n(a) access to samples from intermediate distributions, and (b) samples being\nannotated with the amount of change from the source distribution, self-training\ncan be successfully applied on gradually shifted samples to adapt the model\ntoward the target distribution. We hypothesize having (a) is enough to enable\niterative self-training to slowly adapt the model to the target distribution,\nby making use of an implicit curriculum. In the case where (a) does not hold,\nwe observe that iterative self-training falls short. We propose GIFT, a method\nthat creates virtual samples from intermediate distributions by interpolating\nrepresentations of examples from source and target domains. We evaluate an\niterative-self-training method on datasets with natural distribution shifts,\nand show that when applied on top of other domain adaptation methods, it\nimproves the performance of the model on the target dataset. We run an analysis\non a synthetic dataset to show that in the presence of (a)\niterative-self-training naturally forms a curriculum of samples. Furthermore,\nwe show that when (a) does not hold, GIFT performs better than iterative\nself-training.",
          "link": "http://arxiv.org/abs/2106.06080",
          "publishedOn": "2021-06-14T01:38:53.460Z",
          "wordCount": 646,
          "title": "Gradual Domain Adaptation in the Wild:When Intermediate Distributions are Absent. (arXiv:2106.06080v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06044",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Song_G/0/1/0/all/0/1\">Ganlin Song</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Xu_R/0/1/0/all/0/1\">Ruitu Xu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lafferty_J/0/1/0/all/0/1\">John Lafferty</a>",
          "description": "Stochastic gradient descent with backpropagation is the workhorse of\nartificial neural networks. It has long been recognized that backpropagation\nfails to be a biologically plausible algorithm. Fundamentally, it is a\nnon-local procedure -- updating one neuron's synaptic weights requires\nknowledge of synaptic weights or receptive fields of downstream neurons. This\nlimits the use of artificial neural networks as a tool for understanding the\nbiological principles of information processing in the brain. Lillicrap et al.\n(2016) propose a more biologically plausible \"feedback alignment\" algorithm\nthat uses random and fixed backpropagation weights, and show promising\nsimulations. In this paper we study the mathematical properties of the feedback\nalignment procedure by analyzing convergence and alignment for two-layer\nnetworks under squared error loss. In the overparameterized setting, we prove\nthat the error converges to zero exponentially fast, and also that\nregularization is necessary in order for the parameters to become aligned with\nthe random backpropagation weights. Simulations are given that are consistent\nwith this analysis and suggest further generalizations. These results\ncontribute to our understanding of how biologically plausible algorithms might\ncarry out weight learning in a manner different from Hebbian learning, with\nperformance that is comparable with the full non-local backpropagation\nalgorithm.",
          "link": "http://arxiv.org/abs/2106.06044",
          "publishedOn": "2021-06-14T01:38:53.451Z",
          "wordCount": 632,
          "title": "Convergence and Alignment of Gradient Descentwith Random Back propagation Weights. (arXiv:2106.06044v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06067",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brausse_F/0/1/0/all/0/1\">Franz Brau&#xdf;e</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khasidashvili_Z/0/1/0/all/0/1\">Zurab Khasidashvili</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korovin_K/0/1/0/all/0/1\">Konstantin Korovin</a>",
          "description": "Application domains of Bayesian optimization include optimizing black-box\n\nfunctions or very complex functions. The functions we are interested in\ndescribe\n\ncomplex real-world systems applied in industrial settings. Even though\n\nthey do have explicit representations, standard optimization\n\ntechniques fail to provide validated solutions and correctness\n\nguarantees for them.\n\nIn this paper we present a combination of Bayesian optimisation and SMT-based\nconstraint solving to achieve safe and stable solutions with optimality\nguarantees.",
          "link": "http://arxiv.org/abs/2106.06067",
          "publishedOn": "2021-06-14T01:38:53.444Z",
          "wordCount": 495,
          "title": "Bayesian Optimisation with Formal Guarantees. (arXiv:2106.06067v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05997",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sena_L/0/1/0/all/0/1\">Luiz Sena</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xidan Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alves_E/0/1/0/all/0/1\">Erickson Alves</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bessa_I/0/1/0/all/0/1\">Iury Bessa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manino_E/0/1/0/all/0/1\">Edoardo Manino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cordeiro_L/0/1/0/all/0/1\">Lucas Cordeiro</a>",
          "description": "Artificial Neural Networks (ANNs) are being deployed on an increasing number\nof safety-critical applications, including autonomous cars and medical\ndiagnosis. However, concerns about their reliability have been raised due to\ntheir black-box nature and apparent fragility to adversarial attacks. Here, we\ndevelop and evaluate a symbolic verification framework using incremental model\nchecking (IMC) and satisfiability modulo theories (SMT) to check for\nvulnerabilities in ANNs. More specifically, we propose several ANN-related\noptimizations for IMC, including invariant inference via interval analysis and\nthe discretization of non-linear activation functions. With this, we can\nprovide guarantees on the safe behavior of ANNs implemented both in\nfloating-point and fixed-point (quantized) arithmetic. In this regard, our\nverification approach was able to verify and produce adversarial examples for\n52 test cases spanning image classification and general machine learning\napplications. For small- to medium-sized ANN, our approach completes most of\nits verification runs in minutes. Moreover, in contrast to most\nstate-of-the-art methods, our approach is not restricted to specific choices of\nactivation functions or non-quantized representations.",
          "link": "http://arxiv.org/abs/2106.05997",
          "publishedOn": "2021-06-14T01:38:53.425Z",
          "wordCount": 605,
          "title": "Verifying Quantized Neural Networks using SMT-Based Model Checking. (arXiv:2106.05997v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06123",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhou_Z/0/1/0/all/0/1\">Zhiyong Zhou</a>",
          "description": "Over the past decades, many individual nonconvex methods have been proposed\nto achieve better sparse recovery performance in various scenarios. However,\nhow to construct a valid nonconvex regularization function remains open in\npractice. In this paper, we fill in this gap by presenting a unified framework\nfor constructing the nonconvex regularization based on the probability density\nfunction. Meanwhile, a new nonconvex sparse recovery method constructed via the\nWeibull distribution is studied.",
          "link": "http://arxiv.org/abs/2106.06123",
          "publishedOn": "2021-06-14T01:38:53.417Z",
          "wordCount": 496,
          "title": "A Unified Framework for Constructing Nonconvex Regularizations. (arXiv:2106.06123v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06042",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Oh_J/0/1/0/all/0/1\">Jaehoon Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sangmook Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yun_S/0/1/0/all/0/1\">Se-Young Yun</a>",
          "description": "Federated learning has evolved to improve a single global model under data\nheterogeneity (as a curse) or to develop multiple personalized models using\ndata heterogeneity (as a blessing). However, there has been little research\nconsidering both directions simultaneously. In this paper, we first investigate\nthe relationship between them by analyzing Federated Averaging at the client\nlevel and determine that a better federated global model performance does not\nconstantly improve personalization. To elucidate the cause of this\npersonalization performance degradation problem, we decompose the entire\nnetwork into the body (i.e., extractor), related to universality, and the head\n(i.e., classifier), related to personalization. We then point out that this\nproblem stems from training the head. Based on this observation, we propose a\nnovel federated learning algorithm, coined as FedBABU, which updates only the\nbody of the model during federated training (i.e., the head is randomly\ninitialized and never updated), and the head is fine-tuned for personalization\nduring the evaluation process. Extensive experiments show consistent\nperformance improvements and an efficient personalization of FedBABU.",
          "link": "http://arxiv.org/abs/2106.06042",
          "publishedOn": "2021-06-14T01:38:53.411Z",
          "wordCount": 603,
          "title": "FedBABU: Towards Enhanced Representation for Federated Image Classification. (arXiv:2106.06042v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06092",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Becdelievre_J/0/1/0/all/0/1\">Jean de Becdelievre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kroo_I/0/1/0/all/0/1\">Ilan Kroo</a>",
          "description": "The design of complex engineering systems leads to solving very large\noptimization problems involving different disciplines. Strategies allowing\ndisciplines to optimize in parallel by providing sub-objectives and splitting\nthe problem into smaller parts, such as Collaborative Optimization, are\npromising solutions.However, most of them have slow convergence which reduces\ntheir practical use. Earlier efforts to fasten convergence by learning\nsurrogate models have not yet succeeded at sufficiently improving the\ncompetitiveness of these strategies.This paper shows that, in the case of\nCollaborative Optimization, faster and more reliable convergence can be\nobtained by solving an interesting instance of binary classification: on top of\nthe target label, the training data of one of the two classes contains the\ndistance to the decision boundary and its derivative. Leveraging this\ninformation, we propose to train a neural network with an asymmetric loss\nfunction, a structure that guarantees Lipshitz continuity, and a regularization\ntowards respecting basic distance function properties. The approach is\ndemonstrated on a toy learning example, and then applied to a multidisciplinary\naircraft design problem.",
          "link": "http://arxiv.org/abs/2106.06092",
          "publishedOn": "2021-06-14T01:38:53.405Z",
          "wordCount": 607,
          "title": "Collaborative Multidisciplinary Design Optimization with Neural Networks. (arXiv:2106.06092v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06124",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wetzel_S/0/1/0/all/0/1\">Sebastian J. Wetzel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Melko_R/0/1/0/all/0/1\">Roger G. Melko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tamblyn_I/0/1/0/all/0/1\">Isaac Tamblyn</a>",
          "description": "Twin neural network regression (TNNR) is a semi-supervised regression\nalgorithm, it can be trained on unlabelled data points as long as other,\nlabelled anchor data points, are present. TNNR is trained to predict\ndifferences between the target values of two different data points rather than\nthe targets themselves. By ensembling predicted differences between the targets\nof an unseen data point and all training data points, it is possible to obtain\na very accurate prediction for the original regression problem. Since any loop\nof predicted differences should sum to zero, loops can be supplied to the\ntraining data, even if the data points themselves within loops are unlabelled.\nSemi-supervised training improves TNNR performance, which is already state of\nthe art, significantly.",
          "link": "http://arxiv.org/abs/2106.06124",
          "publishedOn": "2021-06-14T01:38:53.397Z",
          "wordCount": 546,
          "title": "Twin Neural Network Regression is a Semi-Supervised Regression Algorithm. (arXiv:2106.06124v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06054",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Biswas_S/0/1/0/all/0/1\">Sumon Biswas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajan_H/0/1/0/all/0/1\">Hridesh Rajan</a>",
          "description": "In recent years, many incidents have been reported where machine learning\nmodels exhibited discrimination among people based on race, sex, age, etc.\nResearch has been conducted to measure and mitigate unfairness in machine\nlearning models. For a machine learning task, it is a common practice to build\na pipeline that includes an ordered set of data preprocessing stages followed\nby a classifier. However, most of the research on fairness has considered a\nsingle classifier based prediction task. What are the fairness impacts of the\npreprocessing stages in machine learning pipeline? Furthermore, studies showed\nthat often the root cause of unfairness is ingrained in the data itself, rather\nthan the model. But no research has been conducted to measure the unfairness\ncaused by a specific transformation made in the data preprocessing stage. In\nthis paper, we introduced the causal method of fairness to reason about the\nfairness impact of data preprocessing stages in ML pipeline. We leveraged\nexisting metrics to define the fairness measures of the stages. Then we\nconducted a detailed fairness evaluation of the preprocessing stages in 37\npipelines collected from three different sources. Our results show that certain\ndata transformers are causing the model to exhibit unfairness. We identified a\nnumber of fairness patterns in several categories of data transformers.\nFinally, we showed how the local fairness of a preprocessing stage composes in\nthe global fairness of the pipeline. We used the fairness composition to choose\nappropriate downstream transformer that mitigates unfairness in the machine\nlearning pipeline.",
          "link": "http://arxiv.org/abs/2106.06054",
          "publishedOn": "2021-06-14T01:38:53.376Z",
          "wordCount": 714,
          "title": "Fair Preprocessing: Towards Understanding Compositional Fairness of Data Transformers in Machine Learning Pipeline. (arXiv:2106.06054v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06057",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schneider_J/0/1/0/all/0/1\">Johannes Schneider</a>",
          "description": "The data distribution commonly evolves over time leading to problems such as\nconcept drift that often decrease classifier performance. We seek to predict\nunseen data (and their labels) allowing us to tackle challenges due to a\nnon-constant data distribution in a \\emph{proactive} manner rather than\ndetecting and reacting to already existing changes that might already have led\nto errors. To this end, we learn a domain transformer in an unsupervised manner\nthat allows generating data of unseen domains. Our approach first matches\nindependently learned latent representations of two given domains obtained from\nan auto-encoder using a Cycle-GAN. In turn, a transformation of the original\nsamples can be learned that can be applied iteratively to extrapolate to unseen\ndomains. Our evaluation on CNNs on image data confirms the usefulness of the\napproach. It also achieves very good results on the well-known problem of\nunsupervised domain adaption, where labels but not samples have to be\npredicted.",
          "link": "http://arxiv.org/abs/2106.06057",
          "publishedOn": "2021-06-14T01:38:53.369Z",
          "wordCount": 576,
          "title": "Domain Transformer: Predicting Samples of Unseen, Future Domains. (arXiv:2106.06057v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06079",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_E/0/1/0/all/0/1\">Eric Hans Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eriksson_D/0/1/0/all/0/1\">David Eriksson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perrone_V/0/1/0/all/0/1\">Valerio Perrone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seeger_M/0/1/0/all/0/1\">Matthias Seeger</a>",
          "description": "Bayesian optimization (BO) is a popular method for optimizing\nexpensive-to-evaluate black-box functions. BO budgets are typically given in\niterations, which implicitly assumes each evaluation has the same cost. In\nfact, in many BO applications, evaluation costs vary significantly in different\nregions of the search space. In hyperparameter optimization, the time spent on\nneural network training increases with layer size; in clinical trials, the\nmonetary cost of drug compounds vary; and in optimal control, control actions\nhave differing complexities. Cost-constrained BO measures convergence with\nalternative cost metrics such as time, money, or energy, for which the sample\nefficiency of standard BO methods is ill-suited. For cost-constrained BO, cost\nefficiency is far more important than sample efficiency. In this paper, we\nformulate cost-constrained BO as a constrained Markov decision process (CMDP),\nand develop an efficient rollout approximation to the optimal CMDP policy that\ntakes both the cost and future iterations into account. We validate our method\non a collection of hyperparameter optimization problems as well as a sensor set\nselection application.",
          "link": "http://arxiv.org/abs/2106.06079",
          "publishedOn": "2021-06-14T01:38:53.361Z",
          "wordCount": 603,
          "title": "A Nonmyopic Approach to Cost-Constrained Bayesian Optimization. (arXiv:2106.06079v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06114",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tjandrasuwita_M/0/1/0/all/0/1\">Megan Tjandrasuwita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jennifer J. Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kennedy_A/0/1/0/all/0/1\">Ann Kennedy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhuri_S/0/1/0/all/0/1\">Swarat Chaudhuri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yue_Y/0/1/0/all/0/1\">Yisong Yue</a>",
          "description": "Hand-annotated data can vary due to factors such as subjective differences,\nintra-rater variability, and differing annotator expertise. We study\nannotations from different experts who labelled the same behavior classes on a\nset of animal behavior videos, and observe a variation in annotation styles. We\npropose a new method using program synthesis to help interpret annotation\ndifferences for behavior analysis. Our model selects relevant trajectory\nfeatures and learns a temporal filter as part of a program, which corresponds\nto estimated importance an annotator places on that feature at each timestamp.\nOur experiments on a dataset from behavioral neuroscience demonstrate that\ncompared to baseline approaches, our method is more accurate at capturing\nannotator labels and learns interpretable temporal filters. We believe that our\nmethod can lead to greater reproducibility of behavior annotations used in\nscientific studies. We plan to release our code.",
          "link": "http://arxiv.org/abs/2106.06114",
          "publishedOn": "2021-06-14T01:38:53.354Z",
          "wordCount": 583,
          "title": "Interpreting Expert Annotation Differences in Animal Behavior. (arXiv:2106.06114v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06049",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+P_D/0/1/0/all/0/1\">Deepak P</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sundaram_S/0/1/0/all/0/1\">Sowmya S Sundaram</a>",
          "description": "Pervasiveness of tracking devices and enhanced availability of spatially\nlocated data has deepened interest in using them for various policy\ninterventions, through computational data analysis tasks such as spatial hot\nspot detection. In this paper, we consider, for the first time to our best\nknowledge, fairness in detecting spatial hot spots. We motivate the need for\nensuring fairness through statistical parity over the collective population\ncovered across chosen hot spots. We then characterize the task of identifying a\ndiverse set of solutions in the noteworthiness-fairness trade-off spectrum, to\nempower the user to choose a trade-off justified by the policy domain. Being a\nnovel task formulation, we also develop a suite of evaluation metrics for fair\nhot spots, motivated by the need to evaluate pertinent aspects of the task. We\nillustrate the computational infeasibility of identifying fair hot spots using\nnaive and/or direct approaches and devise a method, codenamed {\\it FiSH}, for\nefficiently identifying high-quality, fair and diverse sets of spatial hot\nspots. FiSH traverses the tree-structured search space using heuristics that\nguide it towards identifying effective and fair sets of spatial hot spots.\nThrough an extensive empirical analysis over a real-world dataset from the\ndomain of human development, we illustrate that FiSH generates high-quality\nsolutions at fast response times.",
          "link": "http://arxiv.org/abs/2106.06049",
          "publishedOn": "2021-06-14T01:38:53.347Z",
          "wordCount": 626,
          "title": "FiSH: Fair Spatial Hotspots. (arXiv:2106.06049v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06061",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Harrold_D/0/1/0/all/0/1\">Daniel J. B. Harrold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1\">Jun Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1\">Zhong Fan</a>",
          "description": "As the world seeks to become more sustainable, intelligent solutions are\nneeded to increase the penetration of renewable energy. In this paper, the\nmodel-free deep reinforcement learning algorithm Rainbow Deep Q-Networks is\nused to control a battery in a small microgrid to perform energy arbitrage and\nmore efficiently utilise solar and wind energy sources. The grid operates with\nits own demand and renewable generation based on a dataset collected at Keele\nUniversity, as well as using dynamic energy pricing from a real wholesale\nenergy market. Four scenarios are tested including using demand and price\nforecasting produced with local weather data. The algorithm and its\nsubcomponents are evaluated against two continuous control benchmarks with\nRainbow able to outperform all other method. This research shows the importance\nof using the distributional approach for reinforcement learning when working\nwith complex environments and reward functions, as well as how it can be used\nto visualise and contextualise the agent's behaviour for real-world\napplications.",
          "link": "http://arxiv.org/abs/2106.06061",
          "publishedOn": "2021-06-14T01:38:53.339Z",
          "wordCount": 607,
          "title": "Data-driven battery operation for energy arbitrage using rainbow deep reinforcement learning. (arXiv:2106.06061v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06075",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Barazandeh_B/0/1/0/all/0/1\">Babak Barazandeh</a>, <a href=\"http://arxiv.org/find/math/1/au:+Huang_T/0/1/0/all/0/1\">Tianjian Huang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Michailidis_G/0/1/0/all/0/1\">George Michailidis</a>",
          "description": "Min-max saddle point games have recently been intensely studied, due to their\nwide range of applications, including training Generative Adversarial\nNetworks~(GANs). However, most of the recent efforts for solving them are\nlimited to special regimes such as convex-concave games. Further, it is\ncustomarily assumed that the underlying optimization problem is solved either\nby a single machine or in the case of multiple machines connected in\ncentralized fashion, wherein each one communicates with a central node. The\nlatter approach becomes challenging, when the underlying communications network\nhas low bandwidth. In addition, privacy considerations may dictate that certain\nnodes can communicate with a subset of other nodes. Hence, it is of interest to\ndevelop methods that solve min-max games in a decentralized manner. To that\nend, we develop a decentralized adaptive momentum (ADAM)-type algorithm for\nsolving min-max optimization problem under the condition that the objective\nfunction satisfies a Minty Variational Inequality condition, which is a\ngeneralization to convex-concave case. The proposed method overcomes\nshortcomings of recent non-adaptive gradient-based decentralized algorithms for\nmin-max optimization problems that do not perform well in practice and require\ncareful tuning. In this paper, we obtain non-asymptotic rates of convergence of\nthe proposed algorithm (coined DADAM$^3$) for finding a (stochastic)\nfirst-order Nash equilibrium point and subsequently evaluate its performance on\ntraining GANs. The extensive empirical evaluation shows that DADAM$^3$\noutperforms recently developed methods, including decentralized optimistic\nstochastic gradient for solving such min-max problems.",
          "link": "http://arxiv.org/abs/2106.06075",
          "publishedOn": "2021-06-14T01:38:53.331Z",
          "wordCount": 678,
          "title": "A Decentralized Adaptive Momentum Method for Solving a Class of Min-Max Optimization Problems. (arXiv:2106.06075v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05996",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qian_H/0/1/0/all/0/1\">Haifeng Qian</a>",
          "description": "It is a known phenomenon that adversarial robustness comes at a cost to\nnatural accuracy. To improve this trade-off, this paper proposes an ensemble\napproach that divides a complex robust-classification task into simpler\nsubtasks. Specifically, fractal divide derives multiple training sets from the\ntraining data, and fractal aggregation combines inference outputs from multiple\nclassifiers that are trained on those sets. The resulting ensemble classifiers\nhave a unique property that ensures robustness for an input if certain\ndon't-care conditions are met. The new techniques are evaluated on MNIST and\nFashion-MNIST, with no adversarial training. The MNIST classifier has 99%\nnatural accuracy, 70% measured robustness and 36.9% provable robustness, within\nL2 distance of 2. The Fashion-MNIST classifier has 90% natural accuracy, 54.5%\nmeasured robustness and 28.2% provable robustness, within L2 distance of 1.5.\nBoth results are new state of the art, and we also present new state-of-the-art\nbinary results on challenging label-pairs.",
          "link": "http://arxiv.org/abs/2106.05996",
          "publishedOn": "2021-06-14T01:38:53.306Z",
          "wordCount": 568,
          "title": "An Ensemble Approach Towards Adversarial Robustness. (arXiv:2106.05996v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06038",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chowdhury_J/0/1/0/all/0/1\">Jishnu Ray Chowdhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caragea_C/0/1/0/all/0/1\">Cornelia Caragea</a>",
          "description": "Recursive Neural Networks (RvNNs), which compose sequences according to their\nunderlying hierarchical syntactic structure, have performed well in several\nnatural language processing tasks compared to similar models without structural\nbiases. However, traditional RvNNs are incapable of inducing the latent\nstructure in a plain text sequence on their own. Several extensions have been\nproposed to overcome this limitation. Nevertheless, these extensions tend to\nrely on surrogate gradients or reinforcement learning at the cost of higher\nbias or variance. In this work, we propose Continuous Recursive Neural Network\n(CRvNN) as a backpropagation-friendly alternative to address the aforementioned\nlimitations. This is done by incorporating a continuous relaxation to the\ninduced structure. We demonstrate that CRvNN achieves strong performance in\nchallenging synthetic tasks such as logical inference and ListOps. We also show\nthat CRvNN performs comparably or better than prior latent structure models on\nreal-world tasks such as sentiment analysis and natural language inference.",
          "link": "http://arxiv.org/abs/2106.06038",
          "publishedOn": "2021-06-14T01:38:53.299Z",
          "wordCount": 589,
          "title": "Modeling Hierarchical Structures with Continuous Recursive Neural Networks. (arXiv:2106.06038v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06047",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qu_L/0/1/0/all/0/1\">Liangqiong Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yuyin Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1\">Paul Pu Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1\">Yingda Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Feifei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1\">Li Fei-Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adeli_E/0/1/0/all/0/1\">Ehsan Adeli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubin_D/0/1/0/all/0/1\">Daniel Rubin</a>",
          "description": "Federated learning is an emerging research paradigm enabling collaborative\ntraining of machine learning models among different organizations while keeping\ndata private at each institution. Despite recent progress, there remain\nfundamental challenges such as lack of convergence and potential for\ncatastrophic forgetting in federated learning across real-world heterogeneous\ndevices. In this paper, we demonstrate that attention-based architectures\n(e.g., Transformers) are fairly robust to distribution shifts and hence improve\nfederated learning over heterogeneous data. Concretely, we conduct the first\nrigorous empirical investigation of different neural architectures across a\nrange of federated algorithms, real-world benchmarks, and heterogeneous data\nsplits. Our experiments show that simply replacing convolutional networks with\nTransformers can greatly reduce catastrophic forgetting of previous devices,\naccelerate convergence, and reach a better global model, especially when\ndealing with heterogeneous data. We will release our code and pretrained models\nat https://github.com/Liangqiong/ViT-FL-main to encourage future exploration in\nrobust architectures as an alternative to current research efforts on the\noptimization front.",
          "link": "http://arxiv.org/abs/2106.06047",
          "publishedOn": "2021-06-14T01:38:53.293Z",
          "wordCount": 602,
          "title": "Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning. (arXiv:2106.06047v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05992",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1\">Shengyang Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1\">Jiaxin Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilson_A/0/1/0/all/0/1\">Andrew Gordon Wilson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grosse_R/0/1/0/all/0/1\">Roger Grosse</a>",
          "description": "We introduce a new scalable variational Gaussian process approximation which\nprovides a high fidelity approximation while retaining general applicability.\nWe propose the harmonic kernel decomposition (HKD), which uses Fourier series\nto decompose a kernel as a sum of orthogonal kernels. Our variational\napproximation exploits this orthogonality to enable a large number of inducing\npoints at a low computational cost. We demonstrate that, on a range of\nregression and classification problems, our approach can exploit input space\nsymmetries such as translations and reflections, and it significantly\noutperforms standard variational methods in scalability and accuracy. Notably,\nour approach achieves state-of-the-art results on CIFAR-10 among pure GP\nmodels.",
          "link": "http://arxiv.org/abs/2106.05992",
          "publishedOn": "2021-06-14T01:38:53.275Z",
          "wordCount": 539,
          "title": "Scalable Variational Gaussian Processes via Harmonic Kernel Decomposition. (arXiv:2106.05992v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06009",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Coppens_Y/0/1/0/all/0/1\">Youri Coppens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steckelmacher_D/0/1/0/all/0/1\">Denis Steckelmacher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jonker_C/0/1/0/all/0/1\">Catholijn M. Jonker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nowe_A/0/1/0/all/0/1\">Ann Now&#xe9;</a>",
          "description": "Today's advanced Reinforcement Learning algorithms produce black-box\npolicies, that are often difficult to interpret and trust for a person. We\nintroduce a policy distilling algorithm, building on the CN2 rule mining\nalgorithm, that distills the policy into a rule-based decision system. At the\ncore of our approach is the fact that an RL process does not just learn a\npolicy, a mapping from states to actions, but also produces extra\nmeta-information, such as action values indicating the quality of alternative\nactions. This meta-information can indicate whether more than one action is\nnear-optimal for a certain state. We extend CN2 to make it able to leverage\nknowledge about equally-good actions to distill the policy into fewer rules,\nincreasing its interpretability by a person. Then, to ensure that the rules\nexplain a valid, non-degenerate policy, we introduce a refinement algorithm\nthat fine-tunes the rules to obtain good performance when executed in the\nenvironment. We demonstrate the applicability of our algorithm on the Mario AI\nbenchmark, a complex task that requires modern reinforcement learning\nalgorithms including neural networks. The explanations we produce capture the\nlearned policy in only a few rules, that allow a person to understand what the\nblack-box agent learned. Source code:\nhttps://gitlab.ai.vub.ac.be/yocoppen/svcn2",
          "link": "http://arxiv.org/abs/2106.06009",
          "publishedOn": "2021-06-14T01:38:53.269Z",
          "wordCount": 672,
          "title": "Synthesising Reinforcement Learning Policies through Set-Valued Inductive Rule Learning. (arXiv:2106.06009v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06046",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kumar_M/0/1/0/all/0/1\">Mohit Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moser_B/0/1/0/all/0/1\">Bernhard A. Moser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fischer_L/0/1/0/all/0/1\">Lukas Fischer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freudenthaler_B/0/1/0/all/0/1\">Bernhard Freudenthaler</a>",
          "description": "Guidelines and principles of trustworthy AI should be adhered to in practice\nduring the development of AI systems. This work suggests a novel information\ntheoretic trustworthy AI framework based on the hypothesis that information\ntheory enables taking into account the ethical AI principles during the\ndevelopment of machine learning and deep learning models via providing a way to\nstudy and optimize the inherent tradeoffs between trustworthy AI principles. A\nunified approach to \"privacy-preserving interpretable and transferable\nlearning\" is presented via introducing the information theoretic measures for\nprivacy-leakage, interpretability, and transferability. A technique based on\nvariational optimization, employing conditionally deep autoencoders, is\ndeveloped for practically calculating the defined information theoretic\nmeasures for privacy-leakage, interpretability, and transferability.",
          "link": "http://arxiv.org/abs/2106.06046",
          "publishedOn": "2021-06-14T01:38:53.262Z",
          "wordCount": 570,
          "title": "Information Theoretic Evaluation of Privacy-Leakage, Interpretability, and Transferability for a Novel Trustworthy AI Framework. (arXiv:2106.06046v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06010",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Homssi_B/0/1/0/all/0/1\">Bassel Al Homssi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Al_Hourani_A/0/1/0/all/0/1\">Akram Al-Hourani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krusevac_Z/0/1/0/all/0/1\">Zarko Krusevac</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rowe_W/0/1/0/all/0/1\">Wayne S T Rowe</a>",
          "description": "Spectrum scarcity has surfaced as a prominent concern in wireless radio\ncommunications with the emergence of new technologies over the past few years.\nAs a result, there is growing need for better understanding of the spectrum\noccupancy with newly emerging access technologies supporting the Internet of\nThings. In this paper, we present a framework to capture and model the traffic\nbehavior of short-time spectrum occupancy for IoT applications in the shared\nbands to determine the existing interference. The proposed capturing method\nutilizes a software defined radio to monitor the short bursts of IoT\ntransmissions by capturing the time series data which is converted to power\nspectral density to extract the observed occupancy. Furthermore, we propose the\nuse of an unsupervised machine learning technique to enhance conventionally\nimplemented energy detection methods. Our experimental results show that the\ntemporal and frequency behavior of the spectrum can be well-captured using the\ncombination of two models, namely, semi-Markov chains and a\nPoisson-distribution arrival rate. We conduct an extensive measurement campaign\nin different urban environments and incorporate the spatial effect on the IoT\nshared spectrum.",
          "link": "http://arxiv.org/abs/2106.06010",
          "publishedOn": "2021-06-14T01:38:53.255Z",
          "wordCount": 617,
          "title": "Machine Learning Framework for Sensing and Modeling Interference in IoT Frequency Bands. (arXiv:2106.06010v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06027",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1\">Mingkang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tianlong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhangyang Wang</a>",
          "description": "Sparse adversarial attacks can fool deep neural networks (DNNs) by only\nperturbing a few pixels (regularized by l_0 norm). Recent efforts combine it\nwith another l_infty imperceptible on the perturbation magnitudes. The\nresultant sparse and imperceptible attacks are practically relevant, and\nindicate an even higher vulnerability of DNNs that we usually imagined.\nHowever, such attacks are more challenging to generate due to the optimization\ndifficulty by coupling the l_0 regularizer and box constraints with a\nnon-convex objective. In this paper, we address this challenge by proposing a\nhomotopy algorithm, to jointly tackle the sparsity and the perturbation bound\nin one unified framework. Each iteration, the main step of our algorithm is to\noptimize an l_0-regularized adversarial loss, by leveraging the nonmonotone\nAccelerated Proximal Gradient Method (nmAPG) for nonconvex programming; it is\nfollowed by an l_0 change control step, and an optional post-attack step\ndesigned to escape bad local minima. We also extend the algorithm to handling\nthe structural sparsity regularizer. We extensively examine the effectiveness\nof our proposed homotopy attack for both targeted and non-targeted attack\nscenarios, on CIFAR-10 and ImageNet datasets. Compared to state-of-the-art\nmethods, our homotopy attack leads to significantly fewer perturbations, e.g.,\nreducing 42.91% on CIFAR-10 and 75.03% on ImageNet (average case, targeted\nattack), at similar maximal perturbation magnitudes, when still achieving 100%\nattack success rates. Our codes are available at:\nhttps://github.com/VITA-Group/SparseADV_Homotopy.",
          "link": "http://arxiv.org/abs/2106.06027",
          "publishedOn": "2021-06-14T01:38:53.248Z",
          "wordCount": 662,
          "title": "Sparse and Imperceptible Adversarial Attack via a Homotopy Algorithm. (arXiv:2106.06027v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06011",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yibo Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haidi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1\">Yiming Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shunyao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1\">Mingliang Xu</a>",
          "description": "With the development of deep learning, the single super-resolution image\nreconstruction network models are becoming more and more complex. Small changes\nin hyperparameters of the models have a greater impact on model performance. In\nthe existing works, experts have gradually explored a set of optimal model\nparameters based on empirical values or performing brute-force search. In this\npaper, we introduce a new super-resolution image reconstruction generative\nadversarial network framework, and a Bayesian optimization method used to\noptimizing the hyperparameters of the generator and discriminator. The\ngenerator is made by self-calibrated convolution, and discriminator is made by\nconvolution lays. We have defined the hyperparameters such as the number of\nnetwork layers and the number of neurons. Our method adopts Bayesian\noptimization as a optimization policy of GAN in our model. Not only can find\nthe optimal hyperparameter solution automatically, but also can construct a\nsuper-resolution image reconstruction network, reducing the manual workload.\nExperiments show that Bayesian optimization can search the optimal solution\nearlier than the other two optimization algorithms.",
          "link": "http://arxiv.org/abs/2106.06011",
          "publishedOn": "2021-06-14T01:38:53.238Z",
          "wordCount": 619,
          "title": "A self-adapting super-resolution structures framework for automatic design of GAN. (arXiv:2106.06011v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06020",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weiler_M/0/1/0/all/0/1\">Maurice Weiler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Forre_P/0/1/0/all/0/1\">Patrick Forr&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verlinde_E/0/1/0/all/0/1\">Erik Verlinde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1\">Max Welling</a>",
          "description": "Motivated by the vast success of deep convolutional networks, there is a\ngreat interest in generalizing convolutions to non-Euclidean manifolds. A major\ncomplication in comparison to flat spaces is that it is unclear in which\nalignment a convolution kernel should be applied on a manifold. The underlying\nreason for this ambiguity is that general manifolds do not come with a\ncanonical choice of reference frames (gauge). Kernels and features therefore\nhave to be expressed relative to arbitrary coordinates. We argue that the\nparticular choice of coordinatization should not affect a network's inference\n-- it should be coordinate independent. A simultaneous demand for coordinate\nindependence and weight sharing is shown to result in a requirement on the\nnetwork to be equivariant under local gauge transformations (changes of local\nreference frames). The ambiguity of reference frames depends thereby on the\nG-structure of the manifold, such that the necessary level of gauge\nequivariance is prescribed by the corresponding structure group G. Coordinate\nindependent convolutions are proven to be equivariant w.r.t. those isometries\nthat are symmetries of the G-structure. The resulting theory is formulated in a\ncoordinate free fashion in terms of fiber bundles. To exemplify the design of\ncoordinate independent convolutions, we implement a convolutional network on\nthe M\\\"obius strip. The generality of our differential geometric formulation of\nconvolutional networks is demonstrated by an extensive literature review which\nexplains a large number of Euclidean CNNs, spherical CNNs and CNNs on general\nsurfaces as specific instances of coordinate independent convolutions.",
          "link": "http://arxiv.org/abs/2106.06020",
          "publishedOn": "2021-06-14T01:38:53.228Z",
          "wordCount": 710,
          "title": "Coordinate Independent Convolutional Networks -- Isometry and Gauge Equivariant Convolutions on Riemannian Manifolds. (arXiv:2106.06020v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06091",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alwani_M/0/1/0/all/0/1\">Manoj Alwani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madhavan_V/0/1/0/all/0/1\">Vashisht Madhavan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yang Wang</a>",
          "description": "Deep learning has become an increasingly popular and powerful option for\nmodern pattern recognition systems. However, many deep neural networks have\nmillions to billions of parameters, making them untenable for real-world\napplications with constraints on memory or latency. As a result, powerful\nnetwork compression techniques are a must for the widespread adoption of deep\nlearning. We present DECORE, a reinforcement learning approach to automate the\nnetwork compression process. Using a simple policy gradient method to learn\nwhich neurons or channels to keep or remove, we are able to achieve compression\nrates 3x to 5x greater than contemporary approaches. In contrast with other\narchitecture search methods, DECORE is simple and quick to train, requiring\nonly a few hours of training on 1 GPU. When applied to standard network\narchitectures on different datasets, our approach achieves 11x to 103x\ncompression on different architectures while maintaining accuracies similar to\nthose of the original, large networks.",
          "link": "http://arxiv.org/abs/2106.06091",
          "publishedOn": "2021-06-14T01:38:53.217Z",
          "wordCount": 574,
          "title": "DECORE: Deep Compression with Reinforcement Learning. (arXiv:2106.06091v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05974",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Riquelme_C/0/1/0/all/0/1\">Carlos Riquelme</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Puigcerver_J/0/1/0/all/0/1\">Joan Puigcerver</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mustafa_B/0/1/0/all/0/1\">Basil Mustafa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neumann_M/0/1/0/all/0/1\">Maxim Neumann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jenatton_R/0/1/0/all/0/1\">Rodolphe Jenatton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pinto_A/0/1/0/all/0/1\">Andr&#xe9; Susano Pinto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keysers_D/0/1/0/all/0/1\">Daniel Keysers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Houlsby_N/0/1/0/all/0/1\">Neil Houlsby</a>",
          "description": "Sparsely-gated Mixture of Experts networks (MoEs) have demonstrated excellent\nscalability in Natural Language Processing. In Computer Vision, however, almost\nall performant networks are \"dense\", that is, every input is processed by every\nparameter. We present a Vision MoE (V-MoE), a sparse version of the Vision\nTransformer, that is scalable and competitive with the largest dense networks.\nWhen applied to image recognition, V-MoE matches the performance of\nstate-of-the-art networks, while requiring as little as half of the compute at\ninference time. Further, we propose an extension to the routing algorithm that\ncan prioritize subsets of each input across the entire batch, leading to\nadaptive per-image compute. This allows V-MoE to trade-off performance and\ncompute smoothly at test-time. Finally, we demonstrate the potential of V-MoE\nto scale vision models, and train a 15B parameter model that attains 90.35% on\nImageNet.",
          "link": "http://arxiv.org/abs/2106.05974",
          "publishedOn": "2021-06-14T01:38:53.189Z",
          "wordCount": 589,
          "title": "Scaling Vision with Sparse Mixture of Experts. (arXiv:2106.05974v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06130",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fang_X/0/1/0/all/0/1\">Xiaomin Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lihang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_J/0/1/0/all/0/1\">Jieqiong Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1\">Donglong He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shanzhuo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jingbo Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Fan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Hua Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haifeng Wang</a>",
          "description": "Effective molecular representation learning is of great importance to\nfacilitate molecular property prediction, which is a fundamental task for the\ndrug and material industry. Recent advances in graph neural networks (GNNs)\nhave shown great promise in applying GNNs for molecular representation\nlearning. Moreover, a few recent studies have also demonstrated successful\napplications of self-supervised learning methods to pre-train the GNNs to\novercome the problem of insufficient labeled molecules. However, existing GNNs\nand pre-training strategies usually treat molecules as topological graph data\nwithout fully utilizing the molecular geometry information. Whereas, the\nthree-dimensional (3D) spatial structure of a molecule, a.k.a molecular\ngeometry, is one of the most critical factors for determining molecular\nphysical, chemical, and biological properties. To this end, we propose a novel\nGeometry Enhanced Molecular representation learning method (GEM) for Chemical\nRepresentation Learning (ChemRL). At first, we design a geometry-based GNN\narchitecture that simultaneously models atoms, bonds, and bond angles in a\nmolecule. To be specific, we devised double graphs for a molecule: The first\none encodes the atom-bond relations; The second one encodes bond-angle\nrelations. Moreover, on top of the devised GNN architecture, we propose several\nnovel geometry-level self-supervised learning strategies to learn spatial\nknowledge by utilizing the local and global molecular 3D structures. We compare\nChemRL-GEM with various state-of-the-art (SOTA) baselines on different\nmolecular benchmarks and exhibit that ChemRL-GEM can significantly outperform\nall baselines in both regression and classification tasks. For example, the\nexperimental results show an overall improvement of $8.8\\%$ on average compared\nto SOTA baselines on the regression tasks, demonstrating the superiority of the\nproposed method.",
          "link": "http://arxiv.org/abs/2106.06130",
          "publishedOn": "2021-06-14T01:38:53.181Z",
          "wordCount": 705,
          "title": "ChemRL-GEM: Geometry Enhanced Molecular Representation Learning for Property Prediction. (arXiv:2106.06130v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06090",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1\">Lingfei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_K/0/1/0/all/0/1\">Kai Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1\">Xiaojie Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_H/0/1/0/all/0/1\">Hanning Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shucheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pei_J/0/1/0/all/0/1\">Jian Pei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_B/0/1/0/all/0/1\">Bo Long</a>",
          "description": "Deep learning has become the dominant approach in coping with various tasks\nin Natural LanguageProcessing (NLP). Although text inputs are typically\nrepresented as a sequence of tokens, there isa rich variety of NLP problems\nthat can be best expressed with a graph structure. As a result, thereis a surge\nof interests in developing new deep learning techniques on graphs for a large\nnumberof NLP tasks. In this survey, we present a comprehensive overview onGraph\nNeural Networks(GNNs) for Natural Language Processing. We propose a new\ntaxonomy of GNNs for NLP, whichsystematically organizes existing research of\nGNNs for NLP along three axes: graph construction,graph representation\nlearning, and graph based encoder-decoder models. We further introducea large\nnumber of NLP applications that are exploiting the power of GNNs and summarize\nthecorresponding benchmark datasets, evaluation metrics, and open-source codes.\nFinally, we discussvarious outstanding challenges for making the full use of\nGNNs for NLP as well as future researchdirections. To the best of our\nknowledge, this is the first comprehensive overview of Graph NeuralNetworks for\nNatural Language Processing.",
          "link": "http://arxiv.org/abs/2106.06090",
          "publishedOn": "2021-06-14T01:38:53.155Z",
          "wordCount": 614,
          "title": "Graph Neural Networks for Natural Language Processing: A Survey. (arXiv:2106.06090v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.06165",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1\">Ziwei Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiwei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1\">Lei Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Philip S. Yu</a>",
          "description": "The sequential patterns within the user interactions are pivotal for\nrepresenting the user's preference and capturing latent relationships among\nitems. The recent advancements of sequence modeling by Transformers advocate\nthe community to devise more effective encoders for the sequential\nrecommendation. Most existing sequential methods assume users are\ndeterministic. However, item-item transitions might fluctuate significantly in\nseveral item aspects and exhibit randomness of user interests. This\n\\textit{stochastic characteristics} brings up a solid demand to include\nuncertainties in representing sequences and items. Additionally, modeling\nsequences and items with uncertainties expands users' and items' interaction\nspaces, thus further alleviating cold-start problems.\n\nIn this work, we propose a Distribution-based Transformer for Sequential\nRecommendation (DT4SR), which injects uncertainties into sequential modeling.\nWe use Elliptical Gaussian distributions to describe items and sequences with\nuncertainty. We describe the uncertainty in items and sequences as Elliptical\nGaussian distribution. And we adopt Wasserstein distance to measure the\nsimilarity between distributions. We devise two novel Trans-formers for\nmodeling mean and covariance, which guarantees the positive-definite property\nof distributions. The proposed method significantly outperforms the\nstate-of-the-art methods. The experiments on three benchmark datasets also\ndemonstrate its effectiveness in alleviating cold-start issues. The code is\navailable inhttps://github.com/DyGRec/DT4SR.",
          "link": "http://arxiv.org/abs/2106.06165",
          "publishedOn": "2021-06-14T01:38:53.118Z",
          "wordCount": 631,
          "title": "Modeling Sequences as Distributions with Uncertainty for Sequential Recommendation. (arXiv:2106.06165v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05545",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Guo_Y/0/1/0/all/0/1\">Yibo Guo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_H/0/1/0/all/0/1\">Haidi Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fan_Y/0/1/0/all/0/1\">Yiming Fan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_S/0/1/0/all/0/1\">Shunyao Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_M/0/1/0/all/0/1\">Mingliang Xu</a>",
          "description": "With the effective application of deep learning in computer vision,\nbreakthroughs have been made in the research of super-resolution images\nreconstruction. However, many researches have pointed out that the\ninsufficiency of the neural network extraction on image features may bring the\ndeteriorating of newly reconstructed image. On the other hand, the generated\npictures are sometimes too artificial because of over-smoothing. In order to\nsolve the above problems, we propose a novel self-calibrated convolutional\ngenerative adversarial networks. The generator consists of feature extraction\nand image reconstruction. Feature extraction uses self-calibrated convolutions,\nwhich contains four portions, and each portion has specific functions. It can\nnot only expand the range of receptive fields, but also obtain long-range\nspatial and inter-channel dependencies. Then image reconstruction is performed,\nand finally a super-resolution image is reconstructed. We have conducted\nthorough experiments on different datasets including set5, set14 and BSD100\nunder the SSIM evaluation method. The experimental results prove the\neffectiveness of the proposed network.",
          "link": "http://arxiv.org/abs/2106.05545",
          "publishedOn": "2021-06-11T22:07:42.030Z",
          "wordCount": 607,
          "title": "Super-Resolution Image Reconstruction Based on Self-Calibrated Convolutional GAN. (arXiv:2106.05545v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05915",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Kamal_U/0/1/0/all/0/1\">Uday Kamal</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zunaed_M/0/1/0/all/0/1\">Mohammad Zunaed</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nizam_N/0/1/0/all/0/1\">Nusrat Binta Nizam</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hasan_T/0/1/0/all/0/1\">Taufiq Hasan</a>",
          "description": "Thoracic disease detection from chest radiographs using deep learning methods\nhas been an active area of research in the last decade. Most previous methods\nattempt to focus on the diseased organs of the image by identifying spatial\nregions responsible for significant contributions to the model's prediction. In\ncontrast, expert radiologists first locate the prominent anatomical structures\nbefore determining if those regions are anomalous. Therefore, integrating\nanatomical knowledge within deep learning models could bring substantial\nimprovement in automatic disease classification. This work proposes an\nanatomy-aware attention-based architecture named Anatomy X-Net, that\nprioritizes the spatial features guided by the pre-identified anatomy regions.\nWe leverage a semi-supervised learning method using the JSRT dataset containing\norgan-level annotation to obtain the anatomical segmentation masks (for lungs\nand heart) for the NIH and CheXpert datasets. The proposed Anatomy X-Net uses\nthe pre-trained DenseNet-121 as the backbone network with two corresponding\nstructured modules, the Anatomy Aware Attention (AAA) and Probabilistic\nWeighted Average Pooling (PWAP), in a cohesive framework for anatomical\nattention learning. Our proposed method sets new state-of-the-art performance\non the official NIH test set with an AUC score of 0.8439, proving the efficacy\nof utilizing the anatomy segmentation knowledge to improve the thoracic disease\nclassification. Furthermore, the Anatomy X-Net yields an averaged AUC of 0.9020\non the Stanford CheXpert dataset, improving on existing methods that\ndemonstrate the generalizability of the proposed framework.",
          "link": "http://arxiv.org/abs/2106.05915",
          "publishedOn": "2021-06-11T22:07:42.006Z",
          "wordCount": 679,
          "title": "Anatomy X-Net: A Semi-Supervised Anatomy Aware Convolutional Neural Network for Thoracic Disease Classification. (arXiv:2106.05915v1 [eess.IV])"
        }
      ]
    }
  ],
  "cliVersion": "1.10.2"
}