{
  "sources": [
    {
      "title": "cs.CL updates on arXiv.org",
      "feedUrl": "http://export.arxiv.org/rss/cs.CL",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2106.10132",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Wang_D/0/1/0/all/0/1\">Disong Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Deng_L/0/1/0/all/0/1\">Liqun Deng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yeung_Y/0/1/0/all/0/1\">Yu Ting Yeung</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_X/0/1/0/all/0/1\">Xiao Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_X/0/1/0/all/0/1\">Xunying Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Meng_H/0/1/0/all/0/1\">Helen Meng</a>",
          "description": "One-shot voice conversion (VC), which performs conversion across arbitrary\nspeakers with only a single target-speaker utterance for reference, can be\neffectively achieved by speech representation disentanglement. Existing work\ngenerally ignores the correlation between different speech representations\nduring training, which causes leakage of content information into the speaker\nrepresentation and thus degrades VC performance. To alleviate this issue, we\nemploy vector quantization (VQ) for content encoding and introduce mutual\ninformation (MI) as the correlation metric during training, to achieve proper\ndisentanglement of content, speaker and pitch representations, by reducing\ntheir inter-dependencies in an unsupervised manner. Experimental results\nreflect the superiority of the proposed method in learning effective\ndisentangled speech representations for retaining source linguistic content and\nintonation variations, while capturing target speaker characteristics. In doing\nso, the proposed approach achieves higher speech naturalness and speaker\nsimilarity than current state-of-the-art one-shot VC systems. Our code,\npre-trained models and demo are available at\nhttps://github.com/Wendison/VQMIVC.",
          "link": "http://arxiv.org/abs/2106.10132",
          "publishedOn": "2021-07-22T02:03:10.551Z",
          "wordCount": 639,
          "title": "VQMIVC: Vector Quantization and Mutual Information-Based Unsupervised Speech Representation Disentanglement for One-shot Voice Conversion. (arXiv:2106.10132v1 [eess.AS] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.10204",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Phadke_S/0/1/0/all/0/1\">Shruti Phadke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samory_M/0/1/0/all/0/1\">Mattia Samory</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitra_T/0/1/0/all/0/1\">Tanushree Mitra</a>",
          "description": "Online discussion platforms offer a forum to strengthen and propagate belief\nin misinformed conspiracy theories. Yet, they also offer avenues for conspiracy\ntheorists to express their doubts and experiences of cognitive dissonance. Such\nexpressions of dissonance may shed light on who abandons misguided beliefs and\nunder which circumstances. This paper characterizes self-disclosures of\ndissonance about QAnon, a conspiracy theory initiated by a mysterious leader Q\nand popularized by their followers, anons in conspiracy theory subreddits. To\nunderstand what dissonance and disbelief mean within conspiracy communities, we\nfirst characterize their social imaginaries, a broad understanding of how\npeople collectively imagine their social existence. Focusing on 2K posts from\ntwo image boards, 4chan and 8chan, and 1.2 M comments and posts from 12\nsubreddits dedicated to QAnon, we adopt a mixed methods approach to uncover the\nsymbolic language representing the movement, expectations, practices, heroes\nand foes of the QAnon community. We use these social imaginaries to create a\ncomputational framework for distinguishing belief and dissonance from general\ndiscussion about QAnon. Further, analyzing user engagement with QAnon\nconspiracy subreddits, we find that self-disclosures of dissonance correlate\nwith a significant decrease in user contributions and ultimately with their\ndeparture from the community. We contribute a computational framework for\nidentifying dissonance self-disclosures and measuring the changes in user\nengagement surrounding dissonance. Our work can provide insights into designing\ndissonance-based interventions that can potentially dissuade conspiracists from\nonline conspiracy discussion communities.",
          "link": "http://arxiv.org/abs/2107.10204",
          "publishedOn": "2021-07-22T02:03:10.542Z",
          "wordCount": 693,
          "title": "Characterizing Social Imaginaries and Self-Disclosures of Dissonance in Online Conspiracy Discussion Communities. (arXiv:2107.10204v1 [cs.SI])"
        },
        {
          "id": "http://arxiv.org/abs/2002.01335",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Slowik_A/0/1/0/all/0/1\">Agnieszka S&#x142;owik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Abhinav Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamilton_W/0/1/0/all/0/1\">William L. Hamilton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jamnik_M/0/1/0/all/0/1\">Mateja Jamnik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holden_S/0/1/0/all/0/1\">Sean B. Holden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pal_C/0/1/0/all/0/1\">Christopher Pal</a>",
          "description": "In order to communicate, humans flatten a complex representation of ideas and\ntheir attributes into a single word or a sentence. We investigate the impact of\nrepresentation learning in artificial agents by developing graph referential\ngames. We empirically show that agents parametrized by graph neural networks\ndevelop a more compositional language compared to bag-of-words and sequence\nmodels, which allows them to systematically generalize to new combinations of\nfamiliar features.",
          "link": "http://arxiv.org/abs/2002.01335",
          "publishedOn": "2021-07-22T02:03:10.534Z",
          "wordCount": 570,
          "title": "Structural Inductive Biases in Emergent Communication. (arXiv:2002.01335v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.09846",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhongyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_X/0/1/0/all/0/1\">Xiao Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Ting Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1\">J. Edward Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durme_B/0/1/0/all/0/1\">Benjamin Van Durme</a>",
          "description": "We present a conditional text generation framework that posits sentential\nexpressions of possible causes and effects. This framework depends on two novel\nresources we develop in the course of this work: a very large-scale collection\nof English sentences expressing causal patterns CausalBank; and a refinement\nover previous work on constructing large lexical causal knowledge graphs Cause\nEffect Graph. Further, we extend prior work in lexically-constrained decoding\nto support disjunctive positive constraints. Human assessment confirms that our\napproach gives high-quality and diverse outputs. Finally, we use CausalBank to\nperform continued training of an encoder supporting a recent state-of-the-art\nmodel for causal reasoning, leading to a 3-point improvement on the COPA\nchallenge set, with no change in model architecture.",
          "link": "http://arxiv.org/abs/2107.09846",
          "publishedOn": "2021-07-22T02:03:10.464Z",
          "wordCount": 557,
          "title": "Guided Generation of Cause and Effect. (arXiv:2107.09846v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.05426",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Antonello_R/0/1/0/all/0/1\">Richard Antonello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turek_J/0/1/0/all/0/1\">Javier Turek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vo_V/0/1/0/all/0/1\">Vy Vo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huth_A/0/1/0/all/0/1\">Alexander Huth</a>",
          "description": "How related are the representations learned by neural language models,\ntranslation models, and language tagging tasks? We answer this question by\nadapting an encoder-decoder transfer learning method from computer vision to\ninvestigate the structure among 100 different feature spaces extracted from\nhidden representations of various networks trained on language tasks. This\nmethod reveals a low-dimensional structure where language models and\ntranslation models smoothly interpolate between word embeddings, syntactic and\nsemantic tasks, and future word embeddings. We call this low-dimensional\nstructure a language representation embedding because it encodes the\nrelationships between representations needed to process language for a variety\nof NLP tasks. We find that this representation embedding can predict how well\neach individual feature space maps to human brain responses to natural language\nstimuli recorded using fMRI. Additionally, we find that the principal dimension\nof this structure can be used to create a metric which highlights the brain's\nnatural language processing hierarchy. This suggests that the embedding\ncaptures some part of the brain's natural language representation structure.",
          "link": "http://arxiv.org/abs/2106.05426",
          "publishedOn": "2021-07-22T02:03:10.435Z",
          "wordCount": 653,
          "title": "Low-Dimensional Structure in the Space of Language Representations is Reflected in Brain Responses. (arXiv:2106.05426v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2004.11142",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1\">Hongxuan Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hongyu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_Y/0/1/0/all/0/1\">Yu Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Hua Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haifeng Wang</a>",
          "description": "Machine reading comprehension (MRC) is a crucial task in natural language\nprocessing and has achieved remarkable advancements. However, most of the\nneural MRC models are still far from robust and fail to generalize well in\nreal-world applications. In order to comprehensively verify the robustness and\ngeneralization of MRC models, we introduce a real-world Chinese dataset --\nDuReader_robust. It is designed to evaluate the MRC models from three aspects:\nover-sensitivity, over-stability and generalization. Comparing to previous\nwork, the instances in DuReader_robust are natural texts, rather than the\naltered unnatural texts. It presents the challenges when applying MRC models to\nreal-world applications. The experimental results show that MRC models do not\nperform well on the challenge test set. Moreover, we analyze the behavior of\nexisting models on the challenge test set, which may provide suggestions for\nfuture model development. The dataset and codes are publicly available at\nhttps://github.com/baidu/DuReader.",
          "link": "http://arxiv.org/abs/2004.11142",
          "publishedOn": "2021-07-22T02:03:10.410Z",
          "wordCount": 629,
          "title": "DuReader_robust: A Chinese Dataset Towards Evaluating Robustness and Generalization of Machine Reading Comprehension in Real-World Applications. (arXiv:2004.11142v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.10042",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lehecka_J/0/1/0/all/0/1\">Jan Lehe&#x10d;ka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Svec_J/0/1/0/all/0/1\">Jan &#x160;vec</a>",
          "description": "In this paper, we present our progress in pre-training monolingual\nTransformers for Czech and contribute to the research community by releasing\nour models for public. The need for such models emerged from our effort to\nemploy Transformers in our language-specific tasks, but we found the\nperformance of the published multilingual models to be very limited. Since the\nmultilingual models are usually pre-trained from 100+ languages, most of\nlow-resourced languages (including Czech) are under-represented in these\nmodels. At the same time, there is a huge amount of monolingual training data\navailable in web archives like Common Crawl. We have pre-trained and publicly\nreleased two monolingual Czech Transformers and compared them with relevant\npublic models, trained (at least partially) for Czech. The paper presents the\nTransformers pre-training procedure as well as a comparison of pre-trained\nmodels on text classification task from various domains.",
          "link": "http://arxiv.org/abs/2107.10042",
          "publishedOn": "2021-07-22T02:03:10.355Z",
          "wordCount": 573,
          "title": "Comparison of Czech Transformers on Text Classification Tasks. (arXiv:2107.10042v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.10023",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jadallah_N/0/1/0/all/0/1\">Noah Jadallah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fischbach_J/0/1/0/all/0/1\">Jannik Fischbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frattini_J/0/1/0/all/0/1\">Julian Frattini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogelsang_A/0/1/0/all/0/1\">Andreas Vogelsang</a>",
          "description": "Causal relations (If A, then B) are prevalent in requirements artifacts.\nAutomatically extracting causal relations from requirements holds great\npotential for various RE activities (e.g., automatic derivation of suitable\ntest cases). However, we lack an approach capable of extracting causal\nrelations from natural language with reasonable performance. In this paper, we\npresent our tool CATE (CAusality Tree Extractor), which is able to parse the\ncomposition of a causal relation as a tree structure. CATE does not only\nprovide an overview of causes and effects in a sentence, but also reveals their\nsemantic coherence by translating the causal relation into a binary tree. We\nencourage fellow researchers and practitioners to use CATE at\nhttps://causalitytreeextractor.com/",
          "link": "http://arxiv.org/abs/2107.10023",
          "publishedOn": "2021-07-22T02:03:10.343Z",
          "wordCount": 551,
          "title": "CATE: CAusality Tree Extractor from Natural Language Requirements. (arXiv:2107.10023v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09710",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sarkar_T/0/1/0/all/0/1\">Tushar Sarkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajadhyaksha_N/0/1/0/all/0/1\">Nishant Rajadhyaksha</a>",
          "description": "Linguistics has been instrumental in developing a deeper understanding of\nhuman nature. Words are indispensable to bequeath the thoughts, emotions, and\npurpose of any human interaction, and critically analyzing these words can\nelucidate the social and psychological behavior and characteristics of these\nsocial animals. Social media has become a platform for human interaction on a\nlarge scale and thus gives us scope for collecting and using that data for our\nstudy. However, this entire process of collecting, labeling, and analyzing this\ndata iteratively makes the entire procedure cumbersome. To make this entire\nprocess easier and structured, we would like to introduce TLA(Twitter\nLinguistic Analysis). In this paper, we describe TLA and provide a basic\nunderstanding of the framework and discuss the process of collecting, labeling,\nand analyzing data from Twitter for a corpus of languages while providing\ndetailed labeled datasets for all the languages and the models are trained on\nthese datasets. The analysis provided by TLA will also go a long way in\nunderstanding the sentiments of different linguistic communities and come up\nwith new and innovative solutions for their problems based on the analysis.",
          "link": "http://arxiv.org/abs/2107.09710",
          "publishedOn": "2021-07-22T02:03:10.335Z",
          "wordCount": 606,
          "title": "TLA: Twitter Linguistic Analysis. (arXiv:2107.09710v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09931",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Prasad_A/0/1/0/all/0/1\">Archiki Prasad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rehan_M/0/1/0/all/0/1\">Mohammad Ali Rehan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pathak_S/0/1/0/all/0/1\">Shreya Pathak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jyothi_P/0/1/0/all/0/1\">Preethi Jyothi</a>",
          "description": "While recent benchmarks have spurred a lot of new work on improving the\ngeneralization of pretrained multilingual language models on multilingual\ntasks, techniques to improve code-switched natural language understanding tasks\nhave been far less explored. In this work, we propose the use of bilingual\nintermediate pretraining as a reliable technique to derive large and consistent\nperformance gains on three different NLP tasks using code-switched text. We\nachieve substantial absolute improvements of 7.87%, 20.15%, and 10.99%, on the\nmean accuracies and F1 scores over previous state-of-the-art systems for\nHindi-English Natural Language Inference (NLI), Question Answering (QA) tasks,\nand Spanish-English Sentiment Analysis (SA) respectively. We show consistent\nperformance gains on four different code-switched language-pairs\n(Hindi-English, Spanish-English, Tamil-English and Malayalam-English) for SA.\nWe also present a code-switched masked language modelling (MLM) pretraining\ntechnique that consistently benefits SA compared to standard MLM pretraining\nusing real code-switched text.",
          "link": "http://arxiv.org/abs/2107.09931",
          "publishedOn": "2021-07-22T02:03:10.314Z",
          "wordCount": 583,
          "title": "The Effectiveness of Intermediate-Task Training for Code-Switched Natural Language Understanding. (arXiv:2107.09931v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09948",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Quijano_A/0/1/0/all/0/1\">Alex John Quijano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dale_R/0/1/0/all/0/1\">Rick Dale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sindi_S/0/1/0/all/0/1\">Suzanne Sindi</a>",
          "description": "The availability of large linguistic data sets enables data-driven approaches\nto study linguistic change. This work explores the word rank dynamics of eight\nlanguages by investigating the Google Books corpus unigram frequency data set.\nWe observed the rank changes of the unigrams from 1900 to 2008 and compared it\nto a Wright-Fisher inspired model that we developed for our analysis. The model\nsimulates a neutral evolutionary process with the restriction of having no\ndisappearing words. This work explains the mathematical framework of the model\n- written as a Markov Chain with multinomial transition probabilities - to show\nhow frequencies of words change in time. From our observations in the data and\nour model, word rank stability shows two types of characteristics: (1) the\nincrease/decrease in ranks are monotonic, or (2) the average rank stays the\nsame. Based on our model, high-ranked words tend to be more stable while\nlow-ranked words tend to be more volatile. Some words change in ranks in two\nways: (a) by an accumulation of small increasing/decreasing rank changes in\ntime and (b) by shocks of increase/decrease in ranks. Most of the stopwords and\nSwadesh words are observed to be stable in ranks across eight languages. These\nsignatures suggest unigram frequencies in all languages have changed in a\nmanner inconsistent with a purely neutral evolutionary process.",
          "link": "http://arxiv.org/abs/2107.09948",
          "publishedOn": "2021-07-22T02:03:10.303Z",
          "wordCount": 672,
          "title": "A Statistical Model of Word Rank Evolution. (arXiv:2107.09948v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.10251",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kenna_D/0/1/0/all/0/1\">Dana Kenna</a>",
          "description": "Word Embeddings have been shown to contain the societal biases present in the\noriginal corpora.Existing methods to deal with this problem have been shown to\nonly remove superficial biases. Themethod ofAdversarial Debiasingwas presumed\nto be similarly superficial, but this is was not verifiedin previous works.\nUsing the experiments that demonstrated the shallow removal in other methods,\nIshow results that suggestAdversarial Debiasingis more effective at removing\nbias and thus motivatefurther investigation on the utility ofAdversarial\nDebiasing.",
          "link": "http://arxiv.org/abs/2107.10251",
          "publishedOn": "2021-07-22T02:03:10.281Z",
          "wordCount": 513,
          "title": "Using Adversarial Debiasing to Remove Bias from Word Embeddings. (arXiv:2107.10251v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09840",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Weijia Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haider_B/0/1/0/all/0/1\">Batool Haider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krone_J/0/1/0/all/0/1\">Jason Krone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mansour_S/0/1/0/all/0/1\">Saab Mansour</a>",
          "description": "Multilingual pre-trained contextual embedding models (Devlin et al., 2019)\nhave achieved impressive performance on zero-shot cross-lingual transfer tasks.\nFinding the most effective fine-tuning strategy to fine-tune these models on\nhigh-resource languages so that it transfers well to the zero-shot languages is\na non-trivial task. In this paper, we propose a novel meta-optimizer to\nsoft-select which layers of the pre-trained model to freeze during fine-tuning.\nWe train the meta-optimizer by simulating the zero-shot transfer scenario.\nResults on cross-lingual natural language inference show that our approach\nimproves over the simple fine-tuning baseline and X-MAML (Nooralahzadeh et al.,\n2020).",
          "link": "http://arxiv.org/abs/2107.09840",
          "publishedOn": "2021-07-22T02:03:10.264Z",
          "wordCount": 535,
          "title": "Soft Layer Selection with Meta-Learning for Zero-Shot Cross-Lingual Transfer. (arXiv:2107.09840v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09980",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fischbach_J/0/1/0/all/0/1\">Jannik Fischbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Springer_T/0/1/0/all/0/1\">Tobias Springer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frattini_J/0/1/0/all/0/1\">Julian Frattini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Femmer_H/0/1/0/all/0/1\">Henning Femmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogelsang_A/0/1/0/all/0/1\">Andreas Vogelsang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mendez_D/0/1/0/all/0/1\">Daniel Mendez</a>",
          "description": "[Context:] Causal relations (e.g., If A, then B) are prevalent in functional\nrequirements. For various applications of AI4RE, e.g., the automatic derivation\nof suitable test cases from requirements, automatically extracting such causal\nstatements are a basic necessity. [Problem:] We lack an approach that is able\nto extract causal relations from natural language requirements in fine-grained\nform. Specifically, existing approaches do not consider the combinatorics\nbetween causes and effects. They also do not allow to split causes and effects\ninto more granular text fragments (e.g., variable and condition), making the\nextracted relations unsuitable for automatic test case derivation. [Objective &\nContributions:] We address this research gap and make the following\ncontributions: First, we present the Causality Treebank, which is the first\ncorpus of fully labeled binary parse trees representing the composition of\n1,571 causal requirements. Second, we propose a fine-grained causality\nextractor based on Recursive Neural Tensor Networks. Our approach is capable of\nrecovering the composition of causal statements written in natural language and\nachieves a F1 score of 74 % in the evaluation on the Causality Treebank. Third,\nwe disclose our open data sets as well as our code to foster the discourse on\nthe automatic extraction of causality in the RE community.",
          "link": "http://arxiv.org/abs/2107.09980",
          "publishedOn": "2021-07-22T02:03:10.242Z",
          "wordCount": 651,
          "title": "Fine-Grained Causality Extraction From Natural Language Requirements Using Recursive Neural Tensor Networks. (arXiv:2107.09980v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.10188",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qingxiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaliszyk_C/0/1/0/all/0/1\">Cezary Kaliszyk</a>",
          "description": "The heterogeneous nature of the logical foundations used in different\ninteractive proof assistant libraries has rendered discovery of similar\nmathematical concepts among them difficult. In this paper, we compare a\npreviously proposed algorithm for matching concepts across libraries with our\nunsupervised embedding approach that can help us retrieve similar concepts. Our\napproach is based on the fasttext implementation of Word2Vec, on top of which a\ntree traversal module is added to adapt its algorithm to the representation\nformat of our data export pipeline. We compare the explainability,\ncustomizability, and online-servability of the approaches and argue that the\nneural embedding approach has more potential to be integrated into an\ninteractive proof assistant.",
          "link": "http://arxiv.org/abs/2107.10188",
          "publishedOn": "2021-07-22T02:03:10.232Z",
          "wordCount": 553,
          "title": "JEFL: Joint Embedding of Formal Proof Libraries. (arXiv:2107.10188v1 [cs.LO])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09881",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Imperial_J/0/1/0/all/0/1\">Joseph Marvin Imperial</a>",
          "description": "One of the most important humanitarian responsibility of every individual is\nto protect the future of our children. This entails not only protection of\nphysical welfare but also from ill events that can potentially affect the\nmental well-being of a child such as sexual coercion and abuse which, in\nworst-case scenarios, can result to lifelong trauma. In this study, we perform\na preliminary investigation of how child sex peddlers spread illegal\npornographic content and target minors for sexual activities on Twitter in the\nPhilippines using Natural Language Processing techniques. Results of our\nstudies show frequently used and co-occurring words that traffickers use to\nspread content as well as four main roles played by these entities that\ncontribute to the proliferation of child pornography in the country.",
          "link": "http://arxiv.org/abs/2107.09881",
          "publishedOn": "2021-07-22T02:03:10.159Z",
          "wordCount": 582,
          "title": "How Do Pedophiles Tweet? Investigating the Writing Styles and Online Personas of Child Cybersex Traffickers in the Philippines. (arXiv:2107.09881v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09852",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhongyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_X/0/1/0/all/0/1\">Xiao Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_K/0/1/0/all/0/1\">Kuo Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Ting Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_B/0/1/0/all/0/1\">Bing Qin</a>",
          "description": "Recent work has shown success in incorporating pre-trained models like BERT\nto improve NLP systems. However, existing pre-trained models lack of causal\nknowledge which prevents today's NLP systems from thinking like humans. In this\npaper, we investigate the problem of injecting causal knowledge into\npre-trained models. There are two fundamental problems: 1) how to collect a\nlarge-scale causal resource from unstructured texts; 2) how to effectively\ninject causal knowledge into pre-trained models. To address these issues, we\npropose CausalBERT, which collects the largest scale of causal resource using\nprecise causal patterns and causal embedding techniques. In addition, we adopt\na regularization-based method to preserve the already learned knowledge with an\nextra regularization term while injecting causal knowledge. Extensive\nexperiments on 7 datasets, including four causal pair classification tasks, two\ncausal QA tasks and a causal inference task, demonstrate that CausalBERT\ncaptures rich causal knowledge and outperforms all pre-trained models-based\nstate-of-the-art methods, achieving a new causal inference benchmark.",
          "link": "http://arxiv.org/abs/2107.09852",
          "publishedOn": "2021-07-22T02:03:10.136Z",
          "wordCount": 594,
          "title": "CausalBERT: Injecting Causal Knowledge Into Pre-trained Models with Minimal Supervision. (arXiv:2107.09852v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.10181",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bansal_S/0/1/0/all/0/1\">Srijan Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garimella_V/0/1/0/all/0/1\">Vishal Garimella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suhane_A/0/1/0/all/0/1\">Ayush Suhane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_A/0/1/0/all/0/1\">Animesh Mukherjee</a>",
          "description": "In this paper, we advance the current state-of-the-art method for debiasing\nmonolingual word embeddings so as to generalize well in a multilingual setting.\nWe consider different methods to quantify bias and different debiasing\napproaches for monolingual as well as multilingual settings. We demonstrate the\nsignificance of our bias-mitigation approach on downstream NLP applications.\nOur proposed methods establish the state-of-the-art performance for debiasing\nmultilingual embeddings for three Indian languages - Hindi, Bengali, and Telugu\nin addition to English. We believe that our work will open up new opportunities\nin building unbiased downstream NLP applications that are inherently dependent\non the quality of the word embeddings used.",
          "link": "http://arxiv.org/abs/2107.10181",
          "publishedOn": "2021-07-22T02:03:10.125Z",
          "wordCount": 559,
          "title": "Debiasing Multilingual Word Embeddings: A Case Study of Three Indian Languages. (arXiv:2107.10181v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.10021",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Watkins_H/0/1/0/all/0/1\">Henry Watkins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gray_R/0/1/0/all/0/1\">Robert Gray</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jha_A/0/1/0/all/0/1\">Ashwani Jha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nachev_P/0/1/0/all/0/1\">Parashkev Nachev</a>",
          "description": "The use of electronic health records in medical research is difficult because\nof the unstructured format. Extracting information within reports and\nsummarising patient presentations in a way amenable to downstream analysis\nwould be enormously beneficial for operational and clinical research. In this\nwork we present a natural language processing pipeline for information\nextraction of radiological reports in neurology. Our pipeline uses a hybrid\nsequence of rule-based and artificial intelligence models to accurately extract\nand summarise neurological reports. We train and evaluate a custom language\nmodel on a corpus of 150000 radiological reports from National Hospital for\nNeurology and Neurosurgery, London MRI imaging. We also present results for\nstandard NLP tasks on domain-specific neuroradiology datasets. We show our\npipeline, called `neuroNLP', can reliably extract clinically relevant\ninformation from these reports, enabling downstream modelling of reports and\nassociated imaging on a heretofore unprecedented scale.",
          "link": "http://arxiv.org/abs/2107.10021",
          "publishedOn": "2021-07-22T02:03:10.105Z",
          "wordCount": 592,
          "title": "An artificial intelligence natural language processing pipeline for information extraction in neuroradiology. (arXiv:2107.10021v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.04165",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_P/0/1/0/all/0/1\">Pan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_R/0/1/0/all/0/1\">Ran Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1\">Shibiao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_L/0/1/0/all/0/1\">Liang Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Siyuan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1\">Xiaodan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1\">Song-Chun Zhu</a>",
          "description": "Geometry problem solving has attracted much attention in the NLP community\nrecently. The task is challenging as it requires abstract problem understanding\nand symbolic reasoning with axiomatic knowledge. However, current datasets are\neither small in scale or not publicly available. Thus, we construct a new\nlarge-scale benchmark, Geometry3K, consisting of 3,002 geometry problems with\ndense annotation in formal language. We further propose a novel geometry\nsolving approach with formal language and symbolic reasoning, called\nInterpretable Geometry Problem Solver (Inter-GPS). Inter-GPS first parses the\nproblem text and diagram into formal language automatically via rule-based text\nparsing and neural object detecting, respectively. Unlike implicit learning in\nexisting methods, Inter-GPS incorporates theorem knowledge as conditional rules\nand performs symbolic reasoning step by step. Also, a theorem predictor is\ndesigned to infer the theorem application sequence fed to the symbolic solver\nfor the more efficient and reasonable searching path. Extensive experiments on\nthe Geometry3K and GEOS datasets demonstrate that Inter-GPS achieves\nsignificant improvements over existing methods. The project with code and data\nis available at https://lupantech.github.io/inter-gps.",
          "link": "http://arxiv.org/abs/2105.04165",
          "publishedOn": "2021-07-22T02:03:10.088Z",
          "wordCount": 684,
          "title": "Inter-GPS: Interpretable Geometry Problem Solving with Formal Language and Symbolic Reasoning. (arXiv:2105.04165v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.10137",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pan_L/0/1/0/all/0/1\">Lin Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hang_C/0/1/0/all/0/1\">Chung-Wei Hang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sil_A/0/1/0/all/0/1\">Avirup Sil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potdar_S/0/1/0/all/0/1\">Saloni Potdar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_M/0/1/0/all/0/1\">Mo Yu</a>",
          "description": "We propose a simple and general method to regularize the fine-tuning of\nTransformer-based encoders for text classification tasks. Specifically, during\nfine-tuning we generate adversarial examples by perturbing the word embeddings\nof the model and perform contrastive learning on clean and adversarial examples\nin order to teach the model to learn noise-invariant representations. By\ntraining on both clean and adversarial examples along with the additional\ncontrastive objective, we observe consistent improvement over standard\nfine-tuning on clean examples. On several GLUE benchmark tasks, our fine-tuned\nBERT Large model outperforms BERT Large baseline by 1.7% on average, and our\nfine-tuned RoBERTa Large improves over RoBERTa Large baseline by 1.3%. We\nadditionally validate our method in different domains using three intent\nclassification datasets, where our fine-tuned RoBERTa Large outperforms RoBERTa\nLarge baseline by 1-2% on average.",
          "link": "http://arxiv.org/abs/2107.10137",
          "publishedOn": "2021-07-22T02:03:10.075Z",
          "wordCount": 563,
          "title": "Improved Text Classification via Contrastive Adversarial Training. (arXiv:2107.10137v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09729",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shaham_U/0/1/0/all/0/1\">Uri Shaham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levy_O/0/1/0/all/0/1\">Omer Levy</a>",
          "description": "We combine beam search with the probabilistic pruning technique of nucleus\nsampling to create two deterministic nucleus search algorithms for natural\nlanguage generation. The first algorithm, p-exact search, locally prunes the\nnext-token distribution and performs an exact search over the remaining space.\nThe second algorithm, dynamic beam search, shrinks and expands the beam size\naccording to the entropy of the candidate's probability distribution. Despite\nthe probabilistic intuition behind nucleus search, experiments on machine\ntranslation and summarization benchmarks show that both algorithms reach the\nsame performance levels as standard beam search.",
          "link": "http://arxiv.org/abs/2107.09729",
          "publishedOn": "2021-07-22T02:03:10.063Z",
          "wordCount": 534,
          "title": "What Do You Get When You Cross Beam Search with Nucleus Sampling?. (arXiv:2107.09729v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09768",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dadgar_S/0/1/0/all/0/1\">Sajad Dadgar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghatee_M/0/1/0/all/0/1\">Mehdi Ghatee</a>",
          "description": "During the COVID-19 pandemic, social media platforms were ideal for\ncommunicating due to social isolation and quarantine. Also, it was the primary\nsource of misinformation dissemination on a large scale, referred to as the\ninfodemic. Therefore, automatic debunking misinformation is a crucial problem.\nTo tackle this problem, we present two COVID-19 related misinformation datasets\non Twitter and propose a misinformation detection system comprising\nnetwork-based and content-based processes based on machine learning algorithms\nand NLP techniques. In the network-based process, we focus on social\nproperties, network characteristics, and users. On the other hand, we classify\nmisinformation using the content of the tweets directly in the content-based\nprocess, which contains text classification models (paragraph-level and\nsentence-level) and similarity models. The evaluation results on the\nnetwork-based process show the best results for the artificial neural network\nmodel with an F1 score of 88.68%. In the content-based process, our novel\nsimilarity models, which obtained an F1 score of 90.26%, show an improvement in\nthe misinformation classification results compared to the network-based models.\nIn addition, in the text classification models, the best result was achieved\nusing the stacking ensemble-learning model by obtaining an F1 score of 95.18%.\nFurthermore, we test our content-based models on the Constraint@AAAI2021\ndataset, and by getting an F1 score of 94.38%, we improve the baseline results.\nFinally, we develop a fact-checking website called Checkovid that uses each\nprocess to detect misinformative and informative claims in the domain of\nCOVID-19 from different perspectives.",
          "link": "http://arxiv.org/abs/2107.09768",
          "publishedOn": "2021-07-22T02:03:10.013Z",
          "wordCount": 756,
          "title": "Checkovid: A COVID-19 misinformation detection system on Twitter using network and content mining perspectives. (arXiv:2107.09768v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2103.11528",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luu_S/0/1/0/all/0/1\">Son T. Luu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1\">Kiet Van Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1\">Ngan Luu-Thuy Nguyen</a>",
          "description": "In recent years, Vietnam witnesses the mass development of social network\nusers on different social platforms such as Facebook, Youtube, Instagram, and\nTiktok. On social medias, hate speech has become a critical problem for social\nnetwork users. To solve this problem, we introduce the ViHSD - a\nhuman-annotated dataset for automatically detecting hate speech on the social\nnetwork. This dataset contains over 30,000 comments, each comment in the\ndataset has one of three labels: CLEAN, OFFENSIVE, or HATE. Besides, we\nintroduce the data creation process for annotating and evaluating the quality\nof the dataset. Finally, we evaluated the dataset by deep learning models and\ntransformer models.",
          "link": "http://arxiv.org/abs/2103.11528",
          "publishedOn": "2021-07-21T02:01:34.365Z",
          "wordCount": 605,
          "title": "A Large-scale Dataset for Hate Speech Detection on Vietnamese Social Media Texts. (arXiv:2103.11528v4 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.09009",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Saxon_M/0/1/0/all/0/1\">Michael Saxon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choudhary_S/0/1/0/all/0/1\">Samridhi Choudhary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McKenna_J/0/1/0/all/0/1\">Joseph P. McKenna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mouchtaris_A/0/1/0/all/0/1\">Athanasios Mouchtaris</a>",
          "description": "End-to-end (E2E) spoken language understanding (SLU) systems predict\nutterance semantics directly from speech using a single model. Previous work in\nthis area has focused on targeted tasks in fixed domains, where the output\nsemantic structure is assumed a priori and the input speech is of limited\ncomplexity. In this work we present our approach to developing an E2E model for\ngeneralized SLU in commercial voice assistants (VAs). We propose a fully\ndifferentiable, transformer-based, hierarchical system that can be pretrained\nat both the ASR and NLU levels. This is then fine-tuned on both transcription\nand semantic classification losses to handle a diverse set of intent and\nargument combinations. This leads to an SLU system that achieves significant\nimprovements over baselines on a complex internal generalized VA dataset with a\n43% improvement in accuracy, while still meeting the 99% accuracy benchmark on\nthe popular Fluent Speech Commands dataset. We further evaluate our model on a\nhard test set, exclusively containing slot arguments unseen in training, and\ndemonstrate a nearly 20% improvement, showing the efficacy of our approach in\ntruly demanding VA scenarios.",
          "link": "http://arxiv.org/abs/2106.09009",
          "publishedOn": "2021-07-21T02:01:34.309Z",
          "wordCount": 665,
          "title": "End-to-End Spoken Language Understanding for Generalized Voice Assistants. (arXiv:2106.09009v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.08001",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hatua_A/0/1/0/all/0/1\">Amartya Hatua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_A/0/1/0/all/0/1\">Arjun Mukherjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verma_R/0/1/0/all/0/1\">Rakesh M. Verma</a>",
          "description": "This article describes research on claim verification carried out using a\nmultiple GAN-based model. The proposed model consists of three pairs of\ngenerators and discriminators. The generator and discriminator pairs are\nresponsible for generating synthetic data for supported and refuted claims and\nclaim labels. A theoretical discussion about the proposed model is provided to\nvalidate the equilibrium state of the model. The proposed model is applied to\nthe FEVER dataset, and a pre-trained language model is used for the input text\ndata. The synthetically generated data helps to gain information which helps\nthe model to perform better than state of the art models and other standard\nclassifiers.",
          "link": "http://arxiv.org/abs/2103.08001",
          "publishedOn": "2021-07-21T02:01:33.929Z",
          "wordCount": 598,
          "title": "Claim Verification using a Multi-GAN based Model. (arXiv:2103.08001v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.11077",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Heidarysafa_M/0/1/0/all/0/1\">Mojtaba Heidarysafa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kowsari_K/0/1/0/all/0/1\">Kamran Kowsari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bashiri_M/0/1/0/all/0/1\">Masoud Bashiri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brown_D/0/1/0/all/0/1\">Donald E. Brown</a>",
          "description": "The growth of the data science field requires better tools to understand such\na fast-paced growing domain. Moreover, individuals from different backgrounds\nbecame interested in following a career as data scientists. Therefore,\nproviding a quantitative guide for individuals and organizations to understand\nthe skills required in the job market would be crucial. This paper introduces a\nframework to analyze the job market for data science-related jobs within the US\nwhile providing an interface to access insights in this market. The proposed\nframework includes three sub-modules allowing continuous data collection,\ninformation extraction, and a web-based dashboard visualization to investigate\nthe spatial and temporal distribution of data science-related jobs and skills.\nThe result of this work shows important skills for the main branches of data\nscience jobs and attempts to provide a skill-based definition of these data\nscience branches. The current version of this application is deployed on the\nweb and allows individuals and institutes to investigate skills required for\ndata science positions through the industry lens.",
          "link": "http://arxiv.org/abs/2106.11077",
          "publishedOn": "2021-07-21T02:01:33.913Z",
          "wordCount": 645,
          "title": "Toward a Knowledge Discovery Framework for Data Science Job Market in the United States. (arXiv:2106.11077v2 [cs.CY] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.09356",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Eloff_K/0/1/0/all/0/1\">Kevin Eloff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Engelbrecht_H/0/1/0/all/0/1\">Herman Engelbrecht</a>",
          "description": "Communication between agents in collaborative multi-agent settings is in\ngeneral implicit or a direct data stream. This paper considers text-based\nnatural language as a novel form of communication between multiple agents\ntrained with reinforcement learning. This could be considered first steps\ntoward a truly autonomous communication without the need to define a limited\nset of instructions, and natural collaboration between humans and robots.\nInspired by the game of Blind Leads, we propose an environment where one agent\nuses natural language instructions to guide another through a maze. We test the\nability of reinforcement learning agents to effectively communicate through\ndiscrete word-level symbols and show that the agents are able to sufficiently\ncommunicate through natural language with a limited vocabulary. Although the\ncommunication is not always perfect English, the agents are still able to\nnavigate the maze. We achieve a BLEU score of 0.85, which is an improvement of\n0.61 over randomly generated sequences while maintaining a 100% maze completion\nrate. This is a 3.5 times the performance of the random baseline using our\nreference set.",
          "link": "http://arxiv.org/abs/2107.09356",
          "publishedOn": "2021-07-21T02:01:33.868Z",
          "wordCount": 665,
          "title": "Toward Collaborative Reinforcement Learning Agents that Communicate Through Text-Based Natural Language. (arXiv:2107.09356v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09622",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khan_Z/0/1/0/all/0/1\">Zeeshan Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akella_K/0/1/0/all/0/1\">Kartheek Akella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Namboodiri_V/0/1/0/all/0/1\">Vinay P. Namboodiri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jawahar_C/0/1/0/all/0/1\">C V Jawahar</a>",
          "description": "This work studies the long-standing problems of model capacity and negative\ninterference in multilingual neural machine translation MNMT. We use network\npruning techniques and observe that pruning 50-70% of the parameters from a\ntrained MNMT model results only in a 0.29-1.98 drop in the BLEU score.\nSuggesting that there exist large redundancies even in MNMT models. These\nobservations motivate us to use the redundant parameters and counter the\ninterference problem efficiently. We propose a novel adaptation strategy, where\nwe iteratively prune and retrain the redundant parameters of an MNMT to improve\nbilingual representations while retaining the multilinguality. Negative\ninterference severely affects high resource languages, and our method\nalleviates it without any additional adapter modules. Hence, we call it\nparameter-free adaptation strategy, paving way for the efficient adaptation of\nMNMT. We demonstrate the effectiveness of our method on a 9 language MNMT\ntrained on TED talks, and report an average improvement of +1.36 BLEU on high\nresource pairs. Code will be released here.",
          "link": "http://arxiv.org/abs/2107.09622",
          "publishedOn": "2021-07-21T02:01:33.837Z",
          "wordCount": 587,
          "title": "More Parameters? No Thanks!. (arXiv:2107.09622v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2106.14610",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Arruda_H/0/1/0/all/0/1\">Henrique Ferraz de Arruda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Costa_L/0/1/0/all/0/1\">Luciano da Fontoura Costa</a>",
          "description": "To a good extent, words can be understood as corresponding to patterns or\ncategories that appeared in order to represent concepts and structures that are\nparticularly important or useful in a given time and space. Words are\ncharacterized by not being completely general nor specific, in the sense that\nthe same word can be instantiated or related to several different contexts,\ndepending on specific situations. Indeed, the way in which words are\ninstantiated and associated represents a particularly interesting aspect that\ncan substantially help to better understand the context in which they are\nemployed. Scientific words are no exception to that. In the present work, we\napproach the associations between a set of particularly relevant words in the\nsense of being not only frequently used in several areas, but also representing\nconcepts that are currently related to some of the main standing challenges in\nscience. More specifically, the study reported here takes into account the\nwords \"prediction\", \"model\", \"optimization\", \"complex\", \"entropy\", \"random\",\n\"deterministic\", \"pattern\", and \"database\". In order to complement the\nanalysis, we also obtain a network representing the relationship between the\nadopted areas. Many interesting results were found. First and foremost, several\nof the words were observed to have markedly distinct associations in different\nareas. Biology was found to be related to computer science, sharing\nassociations with databases. Furthermore, for most of the cases, the words\n\"complex\", \"model\", and \"prediction\" were observed to have several strong\nassociations.",
          "link": "http://arxiv.org/abs/2106.14610",
          "publishedOn": "2021-07-21T02:01:33.805Z",
          "wordCount": 696,
          "title": "A keyword-driven approach to science. (arXiv:2106.14610v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.08898",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fisch_A/0/1/0/all/0/1\">Adam Fisch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schuster_T/0/1/0/all/0/1\">Tal Schuster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaakkola_T/0/1/0/all/0/1\">Tommi Jaakkola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barzilay_R/0/1/0/all/0/1\">Regina Barzilay</a>",
          "description": "We develop a novel approach to conformal prediction when the target task has\nlimited data available for training. Conformal prediction identifies a small\nset of promising output candidates in place of a single prediction, with\nguarantees that the set contains the correct answer with high probability. When\ntraining data is limited, however, the predicted set can easily become unusably\nlarge. In this work, we obtain substantially tighter prediction sets while\nmaintaining desirable marginal guarantees by casting conformal prediction as a\nmeta-learning paradigm over exchangeable collections of auxiliary tasks. Our\nconformalization algorithm is simple, fast, and agnostic to the choice of\nunderlying model, learning algorithm, or dataset. We demonstrate the\neffectiveness of this approach across a number of few-shot classification and\nregression tasks in natural language processing, computer vision, and\ncomputational chemistry for drug discovery.",
          "link": "http://arxiv.org/abs/2102.08898",
          "publishedOn": "2021-07-21T02:01:33.797Z",
          "wordCount": 603,
          "title": "Few-shot Conformal Prediction with Auxiliary Tasks. (arXiv:2102.08898v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.11820",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Poria_S/0/1/0/all/0/1\">Soujanya Poria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Majumder_N/0/1/0/all/0/1\">Navonil Majumder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hazarika_D/0/1/0/all/0/1\">Devamanyu Hazarika</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosal_D/0/1/0/all/0/1\">Deepanway Ghosal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhardwaj_R/0/1/0/all/0/1\">Rishabh Bhardwaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jian_S/0/1/0/all/0/1\">Samson Yu Bai Jian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_P/0/1/0/all/0/1\">Pengfei Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_R/0/1/0/all/0/1\">Romila Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_A/0/1/0/all/0/1\">Abhinaba Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chhaya_N/0/1/0/all/0/1\">Niyati Chhaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gelbukh_A/0/1/0/all/0/1\">Alexander Gelbukh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mihalcea_R/0/1/0/all/0/1\">Rada Mihalcea</a>",
          "description": "We address the problem of recognizing emotion cause in conversations, define\ntwo novel sub-tasks of this problem, and provide a corresponding dialogue-level\ndataset, along with strong Transformer-based baselines. The dataset is\navailable at https://github.com/declare-lab/RECCON.\n\nIntroduction: Recognizing the cause behind emotions in text is a fundamental\nyet under-explored area of research in NLP. Advances in this area hold the\npotential to improve interpretability and performance in affect-based models.\nIdentifying emotion causes at the utterance level in conversations is\nparticularly challenging due to the intermingling dynamics among the\ninterlocutors.\n\nMethod: We introduce the task of Recognizing Emotion Cause in CONversations\nwith an accompanying dataset named \\RECCONDA, containing over 1,000 dialogues\nand 10,000 utterance cause-effect pairs. Furthermore, we define different cause\ntypes based on the source of the causes, and establish strong Transformer-based\nbaselines to address two different sub-tasks on this dataset: causal span\nextraction and causal emotion entailment.\n\nResult: Our Transformer-based baselines, which leverage contextual\npre-trained embeddings, such as RoBERTa, outperform the state-of-the-art\nemotion cause extraction approaches\n\nConclusion: We introduce a new task highly relevant for (explainable)\nemotion-aware artificial intelligence: recognizing emotion cause in\nconversations, provide a new highly challenging publicly available\ndialogue-level dataset for this task, and give strong baseline results on this\ndataset.",
          "link": "http://arxiv.org/abs/2012.11820",
          "publishedOn": "2021-07-21T02:01:33.787Z",
          "wordCount": 692,
          "title": "Recognizing Emotion Cause in Conversations. (arXiv:2012.11820v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.14610",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Oguz_B/0/1/0/all/0/1\">Barlas Oguz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xilun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karpukhin_V/0/1/0/all/0/1\">Vladimir Karpukhin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peshterliev_S/0/1/0/all/0/1\">Stan Peshterliev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Okhonko_D/0/1/0/all/0/1\">Dmytro Okhonko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schlichtkrull_M/0/1/0/all/0/1\">Michael Schlichtkrull</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1\">Sonal Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehdad_Y/0/1/0/all/0/1\">Yashar Mehdad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yih_S/0/1/0/all/0/1\">Scott Yih</a>",
          "description": "We study open-domain question answering with structured, unstructured and\nsemi-structured knowledge sources, including text, tables, lists and knowledge\nbases. Departing from prior work, we propose a unifying approach that\nhomogenizes all sources by reducing them to text and applies the\nretriever-reader model which has so far been limited to text sources only. Our\napproach greatly improves the results on knowledge-base QA tasks by 11 points,\ncompared to latest graph-based methods. More importantly, we demonstrate that\nour unified knowledge (UniK-QA) model is a simple and yet effective way to\ncombine heterogeneous sources of knowledge, advancing the state-of-the-art\nresults on two popular question answering benchmarks, NaturalQuestions and\nWebQuestions, by 3.5 and 2.6 points, respectively.",
          "link": "http://arxiv.org/abs/2012.14610",
          "publishedOn": "2021-07-21T02:01:33.780Z",
          "wordCount": 593,
          "title": "UniK-QA: Unified Representations of Structured and Unstructured Knowledge for Open-Domain Question Answering. (arXiv:2012.14610v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.01131",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chopra_H/0/1/0/all/0/1\">Harshita Chopra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vashishtha_A/0/1/0/all/0/1\">Aniket Vashishtha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pal_R/0/1/0/all/0/1\">Ridam Pal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ashima/0/1/0/all/0/1\">Ashima</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tyagi_A/0/1/0/all/0/1\">Ananya Tyagi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sethi_T/0/1/0/all/0/1\">Tavpritesh Sethi</a>",
          "description": "Social media plays a pivotal role in disseminating news globally and acts as\na platform for people to express their opinions on various topics. A wide\nvariety of views accompanies COVID-19 vaccination drives across the globe,\noften colored by emotions, which change along with rising cases, approval of\nvaccines, and multiple factors discussed online. This study aims at analyzing\nthe temporal evolution of different Emotion categories: Hesitation, Rage,\nSorrow, Anticipation, Faith, and Contentment with Influencing Factors: Vaccine\nRollout, Misinformation, Health Effects, and Inequities as lexical categories\ncreated from Tweets belonging to five countries with vital vaccine roll-out\nprograms, namely, India, United States of America, Brazil, United Kingdom, and\nAustralia. We extracted a corpus of nearly 1.8 million Twitter posts related to\nCOVID-19 vaccination. Using cosine distance from selected seed words, we\nexpanded the vocabulary of each category and tracked the longitudinal change in\ntheir strength from June 2020 to April 2021. We used community detection\nalgorithms to find modules in positive correlation networks. Our findings\nsuggest that tweets expressing hesitancy towards vaccines contain the highest\nmentions of health-related effects in all countries. Our results indicated that\nthe patterns of hesitancy were variable across geographies and can help us\nlearn targeted interventions. We also observed a significant change in the\nlinear trends of categories like hesitation and contentment before and after\napproval of vaccines. Negative emotions like rage and sorrow gained the highest\nimportance in the alluvial diagram. They formed a significant module with all\nthe influencing factors in April 2021, when India observed the second wave of\nCOVID-19 cases. The relationship between Emotions and Influencing Factors was\nfound to be variable across the countries.",
          "link": "http://arxiv.org/abs/2104.01131",
          "publishedOn": "2021-07-21T02:01:33.773Z",
          "wordCount": 790,
          "title": "Mining Trends of COVID-19 Vaccine Beliefs on Twitter with Lexical Embeddings. (arXiv:2104.01131v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04426",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roller_S/0/1/0/all/0/1\">Stephen Roller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sukhbaatar_S/0/1/0/all/0/1\">Sainbayar Sukhbaatar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szlam_A/0/1/0/all/0/1\">Arthur Szlam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weston_J/0/1/0/all/0/1\">Jason Weston</a>",
          "description": "We investigate the training of sparse layers that use different parameters\nfor different inputs based on hashing in large Transformer models.\nSpecifically, we modify the feedforward layer to hash to different sets of\nweights depending on the current token, over all tokens in the sequence. We\nshow that this procedure either outperforms or is competitive with\nlearning-to-route mixture-of-expert methods such as Switch Transformers and\nBASE Layers, while requiring no routing parameters or extra terms in the\nobjective function such as a load balancing loss, and no sophisticated\nassignment algorithm. We study the performance of different hashing techniques,\nhash sizes and input features, and show that balanced and random hashes focused\non the most local features work best, compared to either learning clusters or\nusing longer-range context. We show our approach works well both on large\nlanguage modeling and dialogue tasks, and on downstream fine-tuning tasks.",
          "link": "http://arxiv.org/abs/2106.04426",
          "publishedOn": "2021-07-21T02:01:33.752Z",
          "wordCount": 614,
          "title": "Hash Layers For Large Sparse Models. (arXiv:2106.04426v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.11519",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Carrera_Casado_D/0/1/0/all/0/1\">David Carrera-Casado</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferrer_i_Cancho_R/0/1/0/all/0/1\">Ramon Ferrer-i-Cancho</a>",
          "description": "Biosemiosis is a process of choice-making between simultaneously alternative\noptions. It is well-known that, when sufficiently young children encounter a\nnew word, they tend to interpret it as pointing to a meaning that does not have\na word yet in their lexicon rather than to a meaning that already has a word\nattached. In previous research, the strategy was shown to be optimal from an\ninformation theoretic standpoint. In that framework, interpretation is\nhypothesized to be driven by the minimization of a cost function: the option of\nleast communication cost is chosen. However, the information theoretic model\nemployed in that research neither explains the weakening of that vocabulary\nlearning bias in older children or polylinguals nor reproduces Zipf's\nmeaning-frequency law, namely the non-linear relationship between the number of\nmeanings of a word and its frequency. Here we consider a generalization of the\nmodel that is channeled to reproduce that law. The analysis of the new model\nreveals regions of the phase space where the bias disappears consistently with\nthe weakening or loss of the bias in older children or polylinguals. The model\nis abstract enough to support future research on other levels of life that are\nrelevant to biosemiotics. In the deep learning era, the model is a transparent\nlow-dimensional tool for future experimental research and illustrates the\npredictive power of a theoretical framework originally designed to shed light\non the origins of Zipf's rank-frequency law.",
          "link": "http://arxiv.org/abs/2105.11519",
          "publishedOn": "2021-07-21T02:01:33.745Z",
          "wordCount": 731,
          "title": "The advent and fall of a vocabulary learning bias from communicative efficiency. (arXiv:2105.11519v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14686",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Weize Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yankai Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hexu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Peng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>",
          "description": "Hyperbolic neural networks have shown great potential for modeling complex\ndata. However, existing hyperbolic networks are not completely hyperbolic, as\nthey encode features in a hyperbolic space yet formalize most of their\noperations in the tangent space (a Euclidean subspace) at the origin of the\nhyperbolic space. This hybrid method greatly limits the modeling ability of\nnetworks. In this paper, we propose a fully hyperbolic framework to build\nhyperbolic networks based on the Lorentz model by adapting the Lorentz\ntransformations (including boost and rotation) to formalize essential\noperations of neural networks. Moreover, we also prove that linear\ntransformation in tangent spaces used by existing hyperbolic networks is a\nrelaxation of the Lorentz rotation and does not include the boost, implicitly\nlimiting the capabilities of existing hyperbolic networks. The experimental\nresults on four NLP tasks show that our method has better performance for\nbuilding both shallow and deep networks. Our code will be released to\nfacilitate follow-up research.",
          "link": "http://arxiv.org/abs/2105.14686",
          "publishedOn": "2021-07-21T02:01:33.737Z",
          "wordCount": 624,
          "title": "Fully Hyperbolic Neural Networks. (arXiv:2105.14686v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.09648",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Michaelov_J/0/1/0/all/0/1\">James A. Michaelov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bardolph_M/0/1/0/all/0/1\">Megan D. Bardolph</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Coulson_S/0/1/0/all/0/1\">Seana Coulson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bergen_B/0/1/0/all/0/1\">Benjamin K. Bergen</a>",
          "description": "Despite being designed for performance rather than cognitive plausibility,\ntransformer language models have been found to be better at predicting metrics\nused to assess human language comprehension than language models with other\narchitectures, such as recurrent neural networks. Based on how well they\npredict the N400, a neural signal associated with processing difficulty, we\npropose and provide evidence for one possible explanation - their predictions\nare affected by the preceding context in a way analogous to the effect of\nsemantic facilitation in humans.",
          "link": "http://arxiv.org/abs/2107.09648",
          "publishedOn": "2021-07-21T02:01:33.727Z",
          "wordCount": 554,
          "title": "Different kinds of cognitive plausibility: why are transformers better than RNNs at predicting N400 amplitude?. (arXiv:2107.09648v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09625",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ao_S/0/1/0/all/0/1\">Shuang Ao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Acharya_X/0/1/0/all/0/1\">Xeno Acharya</a>",
          "description": "A medical dialogue system is essential for healthcare service as providing\nprimary clinical advice and diagnoses. It has been gradually adopted and\npracticed in medical organizations in the form of a conversational bot, largely\ndue to the advancement of NLP. In recent years, the introduction of\nstate-of-the-art deep learning models and transfer learning techniques like\nUniversal Language Model Fine Tuning (ULMFiT) and Knowledge Distillation (KD)\nlargely contributes to the performance of NLP tasks. However, some deep neural\nnetworks are poorly calibrated and wrongly estimate the uncertainty. Hence the\nmodel is not trustworthy, especially in sensitive medical decision-making\nsystems and safety tasks. In this paper, we investigate the well-calibrated\nmodel for ULMFiT and self-distillation (SD) in a medical dialogue system. The\ncalibrated ULMFiT (CULMFiT) is obtained by incorporating label smoothing (LS),\na commonly used regularization technique to achieve a well-calibrated model.\nMoreover, we apply the technique to recalibrate the confidence score called\ntemperature scaling (TS) with KD to observe its correlation with network\ncalibration. To further understand the relation between SD and calibration, we\nuse both fixed and optimal temperatures to fine-tune the whole model. All\nexperiments are conducted on the consultation backpain dataset collected by\nexperts then further validated using a large publicly medial dialogue corpus.\nWe empirically show that our proposed methodologies outperform conventional\nmethods in terms of accuracy and robustness.",
          "link": "http://arxiv.org/abs/2107.09625",
          "publishedOn": "2021-07-21T02:01:33.710Z",
          "wordCount": 657,
          "title": "Learning ULMFiT and Self-Distillation with Calibration for Medical Dialogue System. (arXiv:2107.09625v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09333",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bezati_E/0/1/0/all/0/1\">Endri Bezati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Emami_M/0/1/0/all/0/1\">Mahyar Emami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Janneck_J/0/1/0/all/0/1\">J&#xf6;rn Janneck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Larus_J/0/1/0/all/0/1\">James Larus</a>",
          "description": "To increase performance and efficiency, systems use FPGAs as reconfigurable\naccelerators. A key challenge in designing these systems is partitioning\ncomputation between processors and an FPGA. An appropriate division of labor\nmay be difficult to predict in advance and require experiments and\nmeasurements. When an investigation requires rewriting part of the system in a\nnew language or with a new programming model, its high cost can retard the\nstudy of different configurations. A single-language system with an appropriate\nprogramming model and compiler that targets both platforms simplifies this\nexploration to a simple recompile with new compiler directives.\n\nThis work introduces StreamBlocks, an open-source compiler and runtime that\nuses the CAL dataflow programming language to partition computations across\nheterogeneous (CPU/accelerator) platforms. Because of the dataflow model's\nsemantics and the CAL language, StreamBlocks can exploit both thread\nparallelism in multi-core CPUs and the inherent parallelism of FPGAs.\nStreamBlocks supports exploring the design space with a profile-guided tool\nthat helps identify the best hardware-software partitions.",
          "link": "http://arxiv.org/abs/2107.09333",
          "publishedOn": "2021-07-21T02:01:33.687Z",
          "wordCount": 610,
          "title": "StreamBlocks: A compiler for heterogeneous dataflow computing (technical report). (arXiv:2107.09333v1 [cs.AR])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09609",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lei_J/0/1/0/all/0/1\">Jie Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berg_T/0/1/0/all/0/1\">Tamara L. Berg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>",
          "description": "Detecting customized moments and highlights from videos given natural\nlanguage (NL) user queries is an important but under-studied topic. One of the\nchallenges in pursuing this direction is the lack of annotated data. To address\nthis issue, we present the Query-based Video Highlights (QVHighlights) dataset.\nIt consists of over 10,000 YouTube videos, covering a wide range of topics,\nfrom everyday activities and travel in lifestyle vlog videos to social and\npolitical activities in news videos. Each video in the dataset is annotated\nwith: (1) a human-written free-form NL query, (2) relevant moments in the video\nw.r.t. the query, and (3) five-point scale saliency scores for all\nquery-relevant clips. This comprehensive annotation enables us to develop and\nevaluate systems that detect relevant moments as well as salient highlights for\ndiverse, flexible user queries. We also present a strong baseline for this\ntask, Moment-DETR, a transformer encoder-decoder model that views moment\nretrieval as a direct set prediction problem, taking extracted video and query\nrepresentations as inputs and predicting moment coordinates and saliency scores\nend-to-end. While our model does not utilize any human prior, we show that it\nperforms competitively when compared to well-engineered architectures. With\nweakly supervised pretraining using ASR captions, Moment-DETR substantially\noutperforms previous methods. Lastly, we present several ablations and\nvisualizations of Moment-DETR. Data and code is publicly available at\nhttps://github.com/jayleicn/moment_detr",
          "link": "http://arxiv.org/abs/2107.09609",
          "publishedOn": "2021-07-21T02:01:33.677Z",
          "wordCount": 680,
          "title": "QVHighlights: Detecting Moments and Highlights in Videos via Natural Language Queries. (arXiv:2107.09609v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09429",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Huiqiang Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Guoxin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Weile Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chengxi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karlsson_B/0/1/0/all/0/1\">B&#xf6;rje F. Karlsson</a>",
          "description": "While named entity recognition (NER) is a key task in natural language\nprocessing, most approaches only target flat entities, ignoring nested\nstructures which are common in many scenarios. Most existing nested NER methods\ntraverse all sub-sequences which is both expensive and inefficient, and also\ndon't well consider boundary knowledge which is significant for nested\nentities. In this paper, we propose a joint entity mention detection and typing\nmodel via prior boundary knowledge (BoningKnife) to better handle nested NER\nextraction and recognition tasks. BoningKnife consists of two modules,\nMentionTagger and TypeClassifier. MentionTagger better leverages boundary\nknowledge beyond just entity start/end to improve the handling of nesting\nlevels and longer spans, while generating high quality mention candidates.\nTypeClassifier utilizes a two-level attention mechanism to decouple different\nnested level representations and better distinguish entity types. We jointly\ntrain both modules sharing a common representation and a new dual-info\nattention layer, which leads to improved representation focus on entity-related\ninformation. Experiments over different datasets show that our approach\noutperforms previous state of the art methods and achieves 86.41, 85.46, and\n94.2 F1 scores on ACE2004, ACE2005, and NNE, respectively.",
          "link": "http://arxiv.org/abs/2107.09429",
          "publishedOn": "2021-07-21T02:01:33.660Z",
          "wordCount": 641,
          "title": "BoningKnife: Joint Entity Mention Detection and Typing for Nested NER via prior Boundary Knowledge. (arXiv:2107.09429v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09433",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gretter_R/0/1/0/all/0/1\">Roberto Gretter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matassoni_M/0/1/0/all/0/1\">Marco Matassoni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Falavigna_D/0/1/0/all/0/1\">Daniele Falavigna</a>",
          "description": "We address the problem of language model customization in applications where\nthe ASR component needs to manage domain-specific terminology; although current\nstate-of-the-art speech recognition technology provides excellent results for\ngeneric domains, the adaptation to specialized dictionaries or glossaries is\nstill an open issue. In this work we present an approach for automatically\nselecting sentences, from a text corpus, that match, both semantically and\nmorphologically, a glossary of terms (words or composite words) furnished by\nthe user. The final goal is to rapidly adapt the language model of an hybrid\nASR system with a limited amount of in-domain text data in order to\nsuccessfully cope with the linguistic domain at hand; the vocabulary of the\nbaseline model is expanded and tailored, reducing the resulting OOV rate. Data\nselection strategies based on shallow morphological seeds and semantic\nsimilarity viaword2vec are introduced and discussed; the experimental setting\nconsists in a simultaneous interpreting scenario, where ASRs in three languages\nare designed to recognize the domain-specific terms (i.e. dentistry). Results\nusing different metrics (OOV rate, WER, precision and recall) show the\neffectiveness of the proposed techniques.",
          "link": "http://arxiv.org/abs/2107.09433",
          "publishedOn": "2021-07-21T02:01:33.651Z",
          "wordCount": 615,
          "title": "Seed Words Based Data Selection for Language Model Adaptation. (arXiv:2107.09433v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09477",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Wen-Chin Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hayashi_T/0/1/0/all/0/1\">Tomoki Hayashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xinjian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watanabe_S/0/1/0/all/0/1\">Shinji Watanabe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Toda_T/0/1/0/all/0/1\">Tomoki Toda</a>",
          "description": "In voice conversion (VC), an approach showing promising results in the latest\nvoice conversion challenge (VCC) 2020 is to first use an automatic speech\nrecognition (ASR) model to transcribe the source speech into the underlying\nlinguistic contents; these are then used as input by a text-to-speech (TTS)\nsystem to generate the converted speech. Such a paradigm, referred to as\nASR+TTS, overlooks the modeling of prosody, which plays an important role in\nspeech naturalness and conversion similarity. Although some researchers have\nconsidered transferring prosodic clues from the source speech, there arises a\nspeaker mismatch during training and conversion. To address this issue, in this\nwork, we propose to directly predict prosody from the linguistic representation\nin a target-speaker-dependent manner, referred to as target text prediction\n(TTP). We evaluate both methods on the VCC2020 benchmark and consider different\nlinguistic representations. The results demonstrate the effectiveness of TTP in\nboth objective and subjective evaluations.",
          "link": "http://arxiv.org/abs/2107.09477",
          "publishedOn": "2021-07-21T02:01:33.628Z",
          "wordCount": 598,
          "title": "On Prosody Modeling for ASR+TTS based Voice Conversion. (arXiv:2107.09477v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09556",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Luyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yujia Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aslan_O/0/1/0/all/0/1\">Ozlem Aslan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vinyals_O/0/1/0/all/0/1\">Oriol Vinyals</a>",
          "description": "We present a new dataset of Wikipedia articles each paired with a knowledge\ngraph, to facilitate the research in conditional text generation, graph\ngeneration and graph representation learning. Existing graph-text paired\ndatasets typically contain small graphs and short text (1 or few sentences),\nthus limiting the capabilities of the models that can be learned on the data.\nOur new dataset WikiGraphs is collected by pairing each Wikipedia article from\nthe established WikiText-103 benchmark (Merity et al., 2016) with a subgraph\nfrom the Freebase knowledge graph (Bollacker et al., 2008). This makes it easy\nto benchmark against other state-of-the-art text generative models that are\ncapable of generating long paragraphs of coherent text. Both the graphs and the\ntext data are of significantly larger scale compared to prior graph-text paired\ndatasets. We present baseline graph neural network and transformer model\nresults on our dataset for 3 tasks: graph -> text generation, graph -> text\nretrieval and text -> graph retrieval. We show that better conditioning on the\ngraph provides gains in generation and retrieval quality but there is still\nlarge room for improvement.",
          "link": "http://arxiv.org/abs/2107.09556",
          "publishedOn": "2021-07-21T02:01:33.596Z",
          "wordCount": 618,
          "title": "WikiGraphs: A Wikipedia Text - Knowledge Graph Paired Dataset. (arXiv:2107.09556v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09332",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Seongsik Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Harksoo Kim</a>",
          "description": "The sentence-level relation extraction mainly aims to classify the relation\nbetween two entities in a sentence. The sentence-level relation extraction\ncorpus is often containing data of difficulty for the model to infer or noise\ndata. In this paper, we propose a curriculum learning-based relation extraction\nmodel that split data by difficulty and utilize it for learning. In the\nexperiments with the representative sentence-level relation extraction\ndatasets, TACRED and Re-TACRED, the proposed method showed good performances.",
          "link": "http://arxiv.org/abs/2107.09332",
          "publishedOn": "2021-07-21T02:01:33.587Z",
          "wordCount": 503,
          "title": "Improving Sentence-Level Relation Extraction through Curriculum Learning. (arXiv:2107.09332v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09274",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Joosung Lee</a>",
          "description": "We present a simple and effective way to generate a variety of paraphrases\nand find a good quality paraphrase among them. As in previous studies, it is\ndifficult to ensure that one generation method always generates the best\nparaphrase in various domains. Therefore, we focus on finding the best\ncandidate from multiple candidates, rather than assuming that there is only one\ncombination of generative models and decoding options. Our approach shows that\nit is easy to apply in various domains and has sufficiently good performance\ncompared to previous methods. In addition, our approach can be used for data\nagumentation that extends the downstream corpus, showing that it can help\nimprove performance in English and Korean datasets.",
          "link": "http://arxiv.org/abs/2107.09274",
          "publishedOn": "2021-07-21T02:01:33.251Z",
          "wordCount": 538,
          "title": "Paraphrasing via Ranking Many Candidates. (arXiv:2107.09274v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09293",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Suzhen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lincheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1\">Yu Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1\">Changjie Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1\">Xin Yu</a>",
          "description": "We propose an audio-driven talking-head method to generate photo-realistic\ntalking-head videos from a single reference image. In this work, we tackle two\nkey challenges: (i) producing natural head motions that match speech prosody,\nand (ii) maintaining the appearance of a speaker in a large head motion while\nstabilizing the non-face regions. We first design a head pose predictor by\nmodeling rigid 6D head movements with a motion-aware recurrent neural network\n(RNN). In this way, the predicted head poses act as the low-frequency holistic\nmovements of a talking head, thus allowing our latter network to focus on\ndetailed facial movement generation. To depict the entire image motions arising\nfrom audio, we exploit a keypoint based dense motion field representation.\nThen, we develop a motion field generator to produce the dense motion fields\nfrom input audio, head poses, and a reference image. As this keypoint based\nrepresentation models the motions of facial regions, head, and backgrounds\nintegrally, our method can better constrain the spatial and temporal\nconsistency of the generated videos. Finally, an image generation network is\nemployed to render photo-realistic talking-head videos from the estimated\nkeypoint based motion fields and the input reference image. Extensive\nexperiments demonstrate that our method produces videos with plausible head\nmotions, synchronized facial expressions, and stable backgrounds and\noutperforms the state-of-the-art.",
          "link": "http://arxiv.org/abs/2107.09293",
          "publishedOn": "2021-07-21T02:01:33.170Z",
          "wordCount": 663,
          "title": "Audio2Head: Audio-driven One-shot Talking-head Generation with Natural Head Motion. (arXiv:2107.09293v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09278",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qinglin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qian Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yali Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiaqing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wen Wang</a>",
          "description": "Transcripts generated by automatic speech recognition (ASR) systems for\nspoken documents lack structural annotations such as paragraphs, significantly\nreducing their readability. Automatically predicting paragraph segmentation for\nspoken documents may both improve readability and downstream NLP performance\nsuch as summarization and machine reading comprehension. We propose a sequence\nmodel with self-adaptive sliding window for accurate and efficient paragraph\nsegmentation. We also propose an approach to exploit phonetic information,\nwhich significantly improves robustness of spoken document segmentation to ASR\nerrors. Evaluations are conducted on the English Wiki-727K document\nsegmentation benchmark, a Chinese Wikipedia-based document segmentation dataset\nwe created, and an in-house Chinese spoken document dataset. Our proposed model\noutperforms the state-of-the-art (SOTA) model based on the same BERT-Base,\nincreasing segmentation F1 on the English benchmark by 4.2 points and on\nChinese datasets by 4.3-10.1 points, while reducing inference time to less than\n1/6 of inference time of the current SOTA.",
          "link": "http://arxiv.org/abs/2107.09278",
          "publishedOn": "2021-07-21T02:01:33.158Z",
          "wordCount": 593,
          "title": "Sequence Model with Self-Adaptive Sliding Window for Efficient Spoken Document Segmentation. (arXiv:2107.09278v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09055",
          "author": "<a href=\"http://arxiv.org/find/q-fin/1/au:+Sonkiya_P/0/1/0/all/0/1\">Priyank Sonkiya</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Bajpai_V/0/1/0/all/0/1\">Vikas Bajpai</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Bansal_A/0/1/0/all/0/1\">Anukriti Bansal</a>",
          "description": "The stock market has been a popular topic of interest in the recent past. The\ngrowth in the inflation rate has compelled people to invest in the stock and\ncommodity markets and other areas rather than saving. Further, the ability of\nDeep Learning models to make predictions on the time series data has been\nproven time and again. Technical analysis on the stock market with the help of\ntechnical indicators has been the most common practice among traders and\ninvestors. One more aspect is the sentiment analysis - the emotion of the\ninvestors that shows the willingness to invest. A variety of techniques have\nbeen used by people around the globe involving basic Machine Learning and\nNeural Networks. Ranging from the basic linear regression to the advanced\nneural networks people have experimented with all possible techniques to\npredict the stock market. It's evident from recent events how news and\nheadlines affect the stock markets and cryptocurrencies. This paper proposes an\nensemble of state-of-the-art methods for predicting stock prices. Firstly\nsentiment analysis of the news and the headlines for the company Apple Inc,\nlisted on the NASDAQ is performed using a version of BERT, which is a\npre-trained transformer model by Google for Natural Language Processing (NLP).\nAfterward, a Generative Adversarial Network (GAN) predicts the stock price for\nApple Inc using the technical indicators, stock indexes of various countries,\nsome commodities, and historical prices along with the sentiment scores.\nComparison is done with baseline models like - Long Short Term Memory (LSTM),\nGated Recurrent Units (GRU), vanilla GAN, and Auto-Regressive Integrated Moving\nAverage (ARIMA) model.",
          "link": "http://arxiv.org/abs/2107.09055",
          "publishedOn": "2021-07-21T02:01:33.143Z",
          "wordCount": 699,
          "title": "Stock price prediction using BERT and GAN. (arXiv:2107.09055v1 [q-fin.ST])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09106",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Whitehead_S/0/1/0/all/0/1\">Spencer Whitehead</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Hui Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feris_R/0/1/0/all/0/1\">Rogerio Feris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saenko_K/0/1/0/all/0/1\">Kate Saenko</a>",
          "description": "Generalization to out-of-distribution data has been a problem for Visual\nQuestion Answering (VQA) models. To measure generalization to novel questions,\nwe propose to separate them into \"skills\" and \"concepts\". \"Skills\" are visual\ntasks, such as counting or attribute recognition, and are applied to \"concepts\"\nmentioned in the question, such as objects and people. VQA methods should be\nable to compose skills and concepts in novel ways, regardless of whether the\nspecific composition has been seen in training, yet we demonstrate that\nexisting models have much to improve upon towards handling new compositions. We\npresent a novel method for learning to compose skills and concepts that\nseparates these two factors implicitly within a model by learning grounded\nconcept representations and disentangling the encoding of skills from that of\nconcepts. We enforce these properties with a novel contrastive learning\nprocedure that does not rely on external annotations and can be learned from\nunlabeled image-question pairs. Experiments demonstrate the effectiveness of\nour approach for improving compositional and grounding performance.",
          "link": "http://arxiv.org/abs/2107.09106",
          "publishedOn": "2021-07-21T02:01:33.123Z",
          "wordCount": 624,
          "title": "Separating Skills and Concepts for Novel Visual Question Answering. (arXiv:2107.09106v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09186",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haoran Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koehn_P/0/1/0/all/0/1\">Philipp Koehn</a>",
          "description": "Typically, a linearly orthogonal transformation mapping is learned by\naligning static type-level embeddings to build a shared semantic space. In view\nof the analysis that contextual embeddings contain richer semantic features, we\ninvestigate a context-aware and dictionary-free mapping approach by leveraging\nparallel corpora. We illustrate that our contextual embedding space mapping\nsignificantly outperforms previous multilingual word embedding methods on the\nbilingual dictionary induction (BDI) task by providing a higher degree of\nisomorphism. To improve the quality of mapping, we also explore sense-level\nembeddings that are split from type-level representations, which can align\nspaces in a finer resolution and yield more precise mapping. Moreover, we\nreveal that contextual embedding spaces suffer from their natural properties --\nanisotropy and anisometry. To mitigate these two problems, we introduce the\niterative normalization algorithm as an imperative preprocessing step. Our\nfindings unfold the tight relationship between isotropy, isometry, and\nisomorphism in normalized contextual embedding spaces.",
          "link": "http://arxiv.org/abs/2107.09186",
          "publishedOn": "2021-07-21T02:01:33.080Z",
          "wordCount": 584,
          "title": "Cross-Lingual BERT Contextual Embedding Space Mapping with Isotropic and Isometric Conditions. (arXiv:2107.09186v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09240",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yi-Fu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_J/0/1/0/all/0/1\">Jaesik Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahn_S/0/1/0/all/0/1\">Sungjin Ahn</a>",
          "description": "Transformers have been successful for many natural language processing tasks.\nHowever, applying transformers to the video domain for tasks such as long-term\nvideo generation and scene understanding has remained elusive due to the high\ncomputational complexity and the lack of natural tokenization. In this paper,\nwe propose the Object-Centric Video Transformer (OCVT) which utilizes an\nobject-centric approach for decomposing scenes into tokens suitable for use in\na generative video transformer. By factoring the video into objects, our fully\nunsupervised model is able to learn complex spatio-temporal dynamics of\nmultiple interacting objects in a scene and generate future frames of the\nvideo. Our model is also significantly more memory-efficient than pixel-based\nmodels and thus able to train on videos of length up to 70 frames with a single\n48GB GPU. We compare our model with previous RNN-based approaches as well as\nother possible video transformer baselines. We demonstrate OCVT performs well\nwhen compared to baselines in generating future frames. OCVT also develops\nuseful representations for video reasoning, achieving start-of-the-art\nperformance on the CATER task.",
          "link": "http://arxiv.org/abs/2107.09240",
          "publishedOn": "2021-07-21T02:01:33.069Z",
          "wordCount": 618,
          "title": "Generative Video Transformer: Can Objects be the Words?. (arXiv:2107.09240v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09285",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Burns_K/0/1/0/all/0/1\">Kaylee Burns</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manning_C/0/1/0/all/0/1\">Christopher D. Manning</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1\">Li Fei-Fei</a>",
          "description": "Although virtual agents are increasingly situated in environments where\nnatural language is the most effective mode of interaction with humans, these\nexchanges are rarely used as an opportunity for learning. Leveraging language\ninteractions effectively requires addressing limitations in the two most common\napproaches to language grounding: semantic parsers built on top of fixed object\ncategories are precise but inflexible and end-to-end models are maximally\nexpressive, but fickle and opaque. Our goal is to develop a system that\nbalances the strengths of each approach so that users can teach agents new\ninstructions that generalize broadly from a single example. We introduce the\nidea of neural abstructions: a set of constraints on the inference procedure of\na label-conditioned generative model that can affect the meaning of the label\nin context. Starting from a core programming language that operates over\nabstructions, users can define increasingly complex mappings from natural\nlanguage to actions. We show that with this method a user population is able to\nbuild a semantic parser for an open-ended house modification task in Minecraft.\nThe semantic parser that results is both flexible and expressive: the\npercentage of utterances sourced from redefinitions increases steadily over the\ncourse of 191 total exchanges, achieving a final value of 28%.",
          "link": "http://arxiv.org/abs/2107.09285",
          "publishedOn": "2021-07-21T02:01:33.033Z",
          "wordCount": 651,
          "title": "Neural Abstructions: Abstractions that Support Construction for Grounded Language Learning. (arXiv:2107.09285v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09099",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1\">Qiushi Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ko_T/0/1/0/all/0/1\">Tom Ko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1\">H Lilian Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xubo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1\">Bo Wu</a>",
          "description": "Punctuation is critical in understanding natural language text. Currently,\nmost automatic speech recognition (ASR) systems do not generate punctuation,\nwhich affects the performance of downstream tasks, such as intent detection and\nslot filling. This gives rise to the need for punctuation restoration. Recent\nwork in punctuation restoration heavily utilizes pre-trained language models\nwithout considering data imbalance when predicting punctuation classes. In this\nwork, we address this problem by proposing a token-level supervised contrastive\nlearning method that aims at maximizing the distance of representation of\ndifferent punctuation marks in the embedding space. The result shows that\ntraining with token-level supervised contrastive learning obtains up to 3.2%\nabsolute F1 improvement on the test set.",
          "link": "http://arxiv.org/abs/2107.09099",
          "publishedOn": "2021-07-21T02:01:33.001Z",
          "wordCount": 554,
          "title": "Token-Level Supervised Contrastive Learning for Punctuation Restoration. (arXiv:2107.09099v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.01198",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Abheesht Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chhablani_G/0/1/0/all/0/1\">Gunjan Chhablani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pandey_H/0/1/0/all/0/1\">Harshit Pandey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patil_R/0/1/0/all/0/1\">Rajaswa Patil</a>",
          "description": "In this work, we present to the NLP community, and to the wider research\ncommunity as a whole, an application for the diachronic analysis of research\ncorpora. We open source an easy-to-use tool coined: DRIFT, which allows\nresearchers to track research trends and development over the years. The\nanalysis methods are collated from well-cited research works, with a few of our\nown methods added for good measure. Succinctly put, some of the analysis\nmethods are: keyword extraction, word clouds, predicting\ndeclining/stagnant/growing trends using Productivity, tracking bi-grams using\nAcceleration plots, finding the Semantic Drift of words, tracking trends using\nsimilarity, etc. To demonstrate the utility and efficacy of our tool, we\nperform a case study on the cs.CL corpus of the arXiv repository and draw\ninferences from the analysis methods. The toolkit and the associated code are\navailable here: https://github.com/rajaswa/DRIFT.",
          "link": "http://arxiv.org/abs/2107.01198",
          "publishedOn": "2021-07-20T02:04:41.716Z",
          "wordCount": 602,
          "title": "DRIFT: A Toolkit for Diachronic Analysis of Scientific Literature. (arXiv:2107.01198v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.15728",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1\">Hang Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suarez_Paniagua_V/0/1/0/all/0/1\">V&#xed;ctor Su&#xe1;rez-Paniagua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Whiteley_W/0/1/0/all/0/1\">William Whiteley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Honghan Wu</a>",
          "description": "Diagnostic or procedural coding of clinical notes aims to derive a coded\nsummary of disease-related information about patients. Such coding is usually\ndone manually in hospitals but could potentially be automated to improve the\nefficiency and accuracy of medical coding. Recent studies on deep learning for\nautomated medical coding achieved promising performances. However, the\nexplainability of these models is usually poor, preventing them to be used\nconfidently in supporting clinical practice. Another limitation is that these\nmodels mostly assume independence among labels, ignoring the complex\ncorrelation among medical codes which can potentially be exploited to improve\nthe performance. We propose a Hierarchical Label-wise Attention Network (HLAN),\nwhich aimed to interpret the model by quantifying importance (as attention\nweights) of words and sentences related to each of the labels. Secondly, we\npropose to enhance the major deep learning models with a label embedding (LE)\ninitialisation approach, which learns a dense, continuous vector representation\nand then injects the representation into the final layers and the label-wise\nattention layers in the models. We evaluated the methods using three settings\non the MIMIC-III discharge summaries: full codes, top-50 codes, and the UK NHS\nCOVID-19 shielding codes. Experiments were conducted to compare HLAN and LE\ninitialisation to the state-of-the-art neural network based methods. HLAN\nachieved the best Micro-level AUC and $F_1$ on the top-50 code prediction and\ncomparable results on the NHS COVID-19 shielding code prediction to other\nmodels. By highlighting the most salient words and sentences for each label,\nHLAN showed more meaningful and comprehensive model interpretation compared to\nits downgraded baselines and the CNN-based models. LE initialisation\nconsistently boosted most deep learning models for automated medical coding.",
          "link": "http://arxiv.org/abs/2010.15728",
          "publishedOn": "2021-07-20T02:04:41.578Z",
          "wordCount": 846,
          "title": "Explainable Automated Coding of Clinical Notes using Hierarchical Label-wise Attention Networks and Label Embedding Initialisation. (arXiv:2010.15728v4 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06981",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weiss_G/0/1/0/all/0/1\">Gail Weiss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldberg_Y/0/1/0/all/0/1\">Yoav Goldberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yahav_E/0/1/0/all/0/1\">Eran Yahav</a>",
          "description": "What is the computational model behind a Transformer? Where recurrent neural\nnetworks have direct parallels in finite state machines, allowing clear\ndiscussion and thought around architecture variants or trained models,\nTransformers have no such familiar parallel. In this paper we aim to change\nthat, proposing a computational model for the transformer-encoder in the form\nof a programming language. We map the basic components of a transformer-encoder\n-- attention and feed-forward computation -- into simple primitives, around\nwhich we form a programming language: the Restricted Access Sequence Processing\nLanguage (RASP). We show how RASP can be used to program solutions to tasks\nthat could conceivably be learned by a Transformer, and how a Transformer can\nbe trained to mimic a RASP solution. In particular, we provide RASP programs\nfor histograms, sorting, and Dyck-languages. We further use our model to relate\ntheir difficulty in terms of the number of required layers and attention heads:\nanalyzing a RASP program implies a maximum number of heads and layers necessary\nto encode a task in a transformer. Finally, we see how insights gained from our\nabstraction might be used to explain phenomena seen in recent works.",
          "link": "http://arxiv.org/abs/2106.06981",
          "publishedOn": "2021-07-20T02:04:41.119Z",
          "wordCount": 651,
          "title": "Thinking Like Transformers. (arXiv:2106.06981v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10042",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Potdar_N/0/1/0/all/0/1\">Nihal Potdar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Avila_A/0/1/0/all/0/1\">Anderson R. Avila</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_C/0/1/0/all/0/1\">Chao Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Dong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yiran Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiao Chen</a>",
          "description": "End-to-end spoken language understanding (SLU) has recently attracted\nincreasing interest. Compared to the conventional tandem-based approach that\ncombines speech recognition and language understanding as separate modules, the\nnew approach extracts users' intentions directly from the speech signals,\nresulting in joint optimization and low latency. Such an approach, however, is\ntypically designed to process one intention at a time, which leads users to\ntake multiple rounds to fulfill their requirements while interacting with a\ndialogue system. In this paper, we propose a streaming end-to-end framework\nthat can process multiple intentions in an online and incremental way. The\nbackbone of our framework is a unidirectional RNN trained with the\nconnectionist temporal classification (CTC) criterion. By this design, an\nintention can be identified when sufficient evidence has been accumulated, and\nmultiple intentions can be identified sequentially. We evaluate our solution on\nthe Fluent Speech Commands (FSC) dataset and the intent detection accuracy is\nabout 97 % on all multi-intent settings. This result is comparable to the\nperformance of the state-of-the-art non-streaming models, but is achieved in an\nonline and incremental way. We also employ our model to a keyword spotting task\nusing the Google Speech Commands dataset and the results are also highly\npromising.",
          "link": "http://arxiv.org/abs/2105.10042",
          "publishedOn": "2021-07-20T02:04:41.090Z",
          "wordCount": 701,
          "title": "A Streaming End-to-End Framework For Spoken Language Understanding. (arXiv:2105.10042v4 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08902",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bhatia_B/0/1/0/all/0/1\">Bhumika Bhatia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verma_A/0/1/0/all/0/1\">Anuj Verma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anjum/0/1/0/all/0/1\">Anjum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Katarya_R/0/1/0/all/0/1\">Rahul Katarya</a>",
          "description": "Cyberbullying is of extreme prevalence today. Online-hate comments, toxicity,\ncyberbullying amongst children and other vulnerable groups are only growing\nover online classes, and increased access to social platforms, especially post\nCOVID-19. It is paramount to detect and ensure minors' safety across social\nplatforms so that any violence or hate-crime is automatically detected and\nstrict action is taken against it. In our work, we explore binary\nclassification by using a combination of datasets from various social media\nplatforms that cover a wide range of cyberbullying such as sexism, racism,\nabusive, and hate-speech. We experiment through multiple models such as\nBi-LSTM, GloVe, state-of-the-art models like BERT, and apply a unique\npreprocessing technique by introducing a slang-abusive corpus, achieving a\nhigher precision in comparison to models without slang preprocessing.",
          "link": "http://arxiv.org/abs/2107.08902",
          "publishedOn": "2021-07-20T02:04:41.071Z",
          "wordCount": 626,
          "title": "Analysing Cyberbullying using Natural Language Processing by Understanding Jargon in Social Media. (arXiv:2107.08902v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2009.06110",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Begus_G/0/1/0/all/0/1\">Ga&#x161;per Begu&#x161;</a>",
          "description": "This paper models unsupervised learning of an identity-based pattern (or\ncopying) in speech called reduplication from raw continuous data with deep\nconvolutional neural networks. We use the ciwGAN architecture Begu\\v{s} (2021a;\narXiv:2006.02951) in which learning of meaningful representations in speech\nemerges from a requirement that the CNNs generate informative data. We propose\na technique to wug-test CNNs trained on speech and, based on four generative\ntests, argue that the network learns to represent an identity-based pattern in\nits latent space. By manipulating only two categorical variables in the latent\nspace, we can actively turn an unreduplicated form into a reduplicated form\nwith no other substantial changes to the output in the majority of cases. We\nalso argue that the network extends the identity-based pattern to unobserved\ndata. Exploration of how meaningful representations of identity-based patterns\nemerge in CNNs and how the latent space variables outside of the training range\ncorrelate with identity-based patterns in the output has general implications\nfor neural network interpretability.",
          "link": "http://arxiv.org/abs/2009.06110",
          "publishedOn": "2021-07-20T02:04:41.052Z",
          "wordCount": 628,
          "title": "Identity-Based Patterns in Deep Convolutional Networks: Generative Adversarial Phonology and Reduplication. (arXiv:2009.06110v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.12804",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fajcik_M/0/1/0/all/0/1\">Martin Fajcik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jon_J/0/1/0/all/0/1\">Josef Jon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smrz_P/0/1/0/all/0/1\">Pavel Smrz</a>",
          "description": "This work demonstrates that, contrary to a common belief, using the objective\nwith independence assumption for modelling the span probability $P(a_s,a_e) =\nP(a_s)P(a_e)$ of span starting at position $a_s$ and ending at position $a_e$\nhas adverse effects. Therefore we propose multiple approaches to modelling\njoint probability $P(a_s,a_e)$ directly. Among those, we propose a compound\nobjective, composed from the joint probability while still keeping the\nobjective with independence assumption as an auxiliary objective. We find that\nthe compound objective is consistently superior or equal to other assumptions\nin exact match. Additionally, we identified common errors caused by the\nassumption of independence and manually checked the counterpart predictions,\ndemonstrating the impact of the compound objective on the real examples. Our\nfindings are supported via experiments with three extractive QA models (BIDAF,\nBERT, ALBERT) over six datasets and our code, individual results and manual\nanalysis are available online.",
          "link": "http://arxiv.org/abs/2008.12804",
          "publishedOn": "2021-07-20T02:04:41.021Z",
          "wordCount": 635,
          "title": "Rethinking the Objectives of Extractive Question Answering. (arXiv:2008.12804v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.09152",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Ye Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yanyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Ziyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_Q/0/1/0/all/0/1\">Quan Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_T/0/1/0/all/0/1\">Tong Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jingbo Zhu</a>",
          "description": "Knowledge distillation has been proven to be effective in model acceleration\nand compression. It allows a small network to learn to generalize in the same\nway as a large network. Recent successes in pre-training suggest the\neffectiveness of transferring model parameters. Inspired by this, we\ninvestigate methods of model acceleration and compression in another line of\nresearch. We propose Weight Distillation to transfer the knowledge in the large\nnetwork parameters through a parameter generator. Our experiments on WMT16\nEn-Ro, NIST12 Zh-En, and WMT14 En-De machine translation tasks show that weight\ndistillation can train a small network that is 1.88~2.94x faster than the large\nnetwork but with competitive performance. With the same sized small network,\nweight distillation can outperform knowledge distillation by 0.51~1.82 BLEU\npoints.",
          "link": "http://arxiv.org/abs/2009.09152",
          "publishedOn": "2021-07-20T02:04:40.957Z",
          "wordCount": 606,
          "title": "Weight Distillation: Transferring the Knowledge in Neural Network Parameters. (arXiv:2009.09152v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.00542",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yanyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Ye Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_T/0/1/0/all/0/1\">Tong Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jingbo Zhu</a>",
          "description": "The large attention-based encoder-decoder network (Transformer) has become\nprevailing recently due to its effectiveness. But the high computation\ncomplexity of its decoder raises the inefficiency issue. By examining the\nmathematic formulation of the decoder, we show that under some mild conditions,\nthe architecture could be simplified by compressing its sub-layers, the basic\nbuilding block of Transformer, and achieves a higher parallelism. We thereby\npropose Compressed Attention Network, whose decoder layer consists of only one\nsub-layer instead of three. Extensive experiments on 14 WMT machine translation\ntasks show that our model is 1.42x faster with performance on par with a strong\nbaseline. This strong baseline is already 2x faster than the widely used\nstandard baseline without loss in performance.",
          "link": "http://arxiv.org/abs/2101.00542",
          "publishedOn": "2021-07-20T02:04:40.927Z",
          "wordCount": 580,
          "title": "An Efficient Transformer Decoder with Compressed Sub-layers. (arXiv:2101.00542v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.09132",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jieh-Sheng Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsiang_J/0/1/0/all/0/1\">Jieh Hsiang</a>",
          "description": "Generative models, such as GPT-2, have demonstrated impressive results\nrecently. A fundamental question we'd like to address is: where did the\ngenerated text come from? This work is our initial effort toward answering the\nquestion by using prior art search. The purpose of the prior art search is to\nfind the most similar prior text in the training data of GPT-2. We take a\nreranking approach and apply it to the patent domain. Specifically, we\npre-train GPT-2 models from scratch by using the patent data from the USPTO.\nThe input for the prior art search is the patent text generated by the GPT-2\nmodel. We also pre-trained BERT models from scratch for converting patent text\nto embeddings. The steps of reranking are: (1) search the most similar text in\nthe training data of GPT-2 by taking a bag-of-word ranking approach (BM25), (2)\nconvert the search results in text format to BERT embeddings, and (3) provide\nthe final result by ranking the BERT embeddings based on their similarities\nwith the patent text generated by GPT-2. The experiments in this work show that\nsuch reranking is better than ranking with embeddings alone. However, our mixed\nresults also indicate that calculating the semantic similarities among long\ntext spans is still challenging. To our knowledge, this work is the first to\nimplement a reranking system to identify retrospectively the most similar\ninputs to a GPT model based on its output.",
          "link": "http://arxiv.org/abs/2009.09132",
          "publishedOn": "2021-07-20T02:04:40.905Z",
          "wordCount": 728,
          "title": "Prior Art Search and Reranking for Generated Patent Text. (arXiv:2009.09132v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.00858",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zhao_R/0/1/0/all/0/1\">Rui Zhao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xue_J/0/1/0/all/0/1\">Jian Xue</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_J/0/1/0/all/0/1\">Jinyu Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wei_W/0/1/0/all/0/1\">Wenning Wei</a>, <a href=\"http://arxiv.org/find/eess/1/au:+He_L/0/1/0/all/0/1\">Lei He</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gong_Y/0/1/0/all/0/1\">Yifan Gong</a>",
          "description": "In this paper, several works are proposed to address practical challenges for\ndeploying RNN Transducer (RNN-T) based speech recognition system. These\nchallenges are adapting a well-trained RNN-T model to a new domain without\ncollecting the audio data, obtaining time stamps and confidence scores at word\nlevel. The first challenge is solved with a splicing data method which\nconcatenates the speech segments extracted from the source domain data. To get\nthe time stamp, a phone prediction branch is added to the RNN-T model by\nsharing the encoder for the purpose of force alignment. Finally, we obtain\nword-level confidence scores by utilizing several types of features calculated\nduring decoding and from confusion network. Evaluated with Microsoft production\ndata, the splicing data adaptation method improves the baseline and adaptation\nwith the text to speech method by 58.03% and 15.25% relative word error rate\nreduction, respectively. The proposed time stamping method can get less than\n50ms word timing difference from the ground truth alignment on average while\nmaintaining the recognition accuracy of the RNN-T model. We also obtain high\nconfidence annotation performance with limited computation cost.",
          "link": "http://arxiv.org/abs/2105.00858",
          "publishedOn": "2021-07-20T02:04:40.886Z",
          "wordCount": 657,
          "title": "On Addressing Practical Challenges for RNN-Transducer. (arXiv:2105.00858v3 [eess.AS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1906.00908",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chesi_C/0/1/0/all/0/1\">Cristiano Chesi</a>",
          "description": "A cognitively plausible parsing algorithm should perform like the human\nparser in critical contexts. Here I propose an adaptation of Earley's parsing\nalgorithm, suitable for Phase-based Minimalist Grammars (PMG, Chesi 2012), that\nis able to predict complexity effects in performance. Focusing on self-paced\nreading experiments of object clefts sentences (Warren & Gibson 2005) I will\nassociate to parsing a complexity metric based on cued features to be retrieved\nat the verb segment (Feature Retrieval & Encoding Cost, FREC). FREC is\ncrucially based on the usage of memory predicted by the discussed parsing\nalgorithm and it correctly fits with the reading time revealed.",
          "link": "http://arxiv.org/abs/1906.00908",
          "publishedOn": "2021-07-20T02:04:40.864Z",
          "wordCount": 580,
          "title": "Phase-based Minimalist Parsing and complexity in non-local dependencies. (arXiv:1906.00908v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.03969",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Le_T/0/1/0/all/0/1\">Thanh-Dung Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noumeir_R/0/1/0/all/0/1\">Rita Noumeir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rambaud_J/0/1/0/all/0/1\">Jerome Rambaud</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sans_G/0/1/0/all/0/1\">Guillaume Sans</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jouvet_P/0/1/0/all/0/1\">Philippe Jouvet</a>",
          "description": "The rapid progress in clinical data management systems and artificial\nintelligence approaches enable the era of personalized medicine. Intensive care\nunits (ICUs) are the ideal clinical research environment for such development\nbecause they collect many clinical data and are highly computerized\nenvironments. We designed a retrospective clinical study on a prospective ICU\ndatabase using clinical natural language to help in the early diagnosis of\nheart failure in critically ill children. The methodology consisted of\nempirical experiments of a learning algorithm to learn the hidden\ninterpretation and presentation of the French clinical note data. This study\nincluded 1386 patients' clinical notes with 5444 single lines of notes. There\nwere 1941 positive cases (36 % of total) and 3503 negative cases classified by\ntwo independent physicians using a standardized approach. The multilayer\nperceptron neural network outperforms other discriminative and generative\nclassifiers. Consequently, the proposed framework yields an overall\nclassification performance with 89 % accuracy, 88 % recall, and 89 % precision.\nFurthermore, a generative autoencoder learning algorithm was proposed to\nleverage the sparsity reduction that achieved 91% accuracy, 91% recall, and 91%\nprecision. This study successfully applied learning representation and machine\nlearning algorithms to detect heart failure from clinical natural language in a\nsingle French institution. Further work is needed to use the same methodology\nin other institutions and other languages.",
          "link": "http://arxiv.org/abs/2104.03969",
          "publishedOn": "2021-07-20T02:04:40.806Z",
          "wordCount": 716,
          "title": "Detecting of a Patient's Condition From Clinical Narratives Using Natural Language Representation. (arXiv:2104.03969v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08484",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Papangelis_A/0/1/0/all/0/1\">Alexandros Papangelis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gopalakrishnan_K/0/1/0/all/0/1\">Karthik Gopalakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Padmakumar_A/0/1/0/all/0/1\">Aishwarya Padmakumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Seokhwan Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tur_G/0/1/0/all/0/1\">Gokhan Tur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hakkani_Tur_D/0/1/0/all/0/1\">Dilek Hakkani-Tur</a>",
          "description": "Inspired by recent work in meta-learning and generative teaching networks, we\npropose a framework called Generative Conversational Networks, in which\nconversational agents learn to generate their own labelled training data (given\nsome seed data) and then train themselves from that data to perform a given\ntask. We use reinforcement learning to optimize the data generation process\nwhere the reward signal is the agent's performance on the task. The task can be\nany language-related task, from intent detection to full task-oriented\nconversations. In this work, we show that our approach is able to generalise\nfrom seed data and performs well in limited data and limited computation\nsettings, with significant gains for intent detection and slot tagging across\nmultiple datasets: ATIS, TOD, SNIPS, and Restaurants8k. We show an average\nimprovement of 35% in intent detection and 21% in slot tagging over a baseline\nmodel trained from the seed data. We also conduct an analysis of the novelty of\nthe generated data and provide generated examples for intent detection, slot\ntagging, and non-goal oriented conversations.",
          "link": "http://arxiv.org/abs/2106.08484",
          "publishedOn": "2021-07-20T02:04:40.786Z",
          "wordCount": 636,
          "title": "Generative Conversational Networks. (arXiv:2106.08484v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.09410",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Park_D/0/1/0/all/0/1\">Deokgun Park</a>",
          "description": "Despite recent advances in many application-specific domains, we do not know\nhow to build a human-level artificial intelligence (HLAI). We conjecture that\nlearning from others' experience with the language is the essential\ncharacteristic that distinguishes human intelligence from the rest. Humans can\nupdate the action-value function with the verbal description as if they\nexperience states, actions, and corresponding rewards sequences firsthand. In\nthis paper, we present a classification of intelligence according to how\nindividual agents learn and propose a definition and a test for HLAI. The main\nidea is that language acquisition without explicit rewards can be a sufficient\ntest for HLAI.",
          "link": "http://arxiv.org/abs/2011.09410",
          "publishedOn": "2021-07-20T02:04:40.762Z",
          "wordCount": 575,
          "title": "A Definition and a Test for Human-Level Artificial Intelligence. (arXiv:2011.09410v4 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08807",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Karakanta_A/0/1/0/all/0/1\">Alina Karakanta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papi_S/0/1/0/all/0/1\">Sara Papi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Negri_M/0/1/0/all/0/1\">Matteo Negri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turchi_M/0/1/0/all/0/1\">Marco Turchi</a>",
          "description": "With the increased audiovisualisation of communication, the need for live\nsubtitles in multilingual events is more relevant than ever. In an attempt to\nautomatise the process, we aim at exploring the feasibility of simultaneous\nspeech translation (SimulST) for live subtitling. However, the word-for-word\nrate of generation of SimulST systems is not optimal for displaying the\nsubtitles in a comprehensible and readable way. In this work, we adapt SimulST\nsystems to predict subtitle breaks along with the translation. We then propose\na display mode that exploits the predicted break structure by presenting the\nsubtitles in scrolling lines. We compare our proposed mode with a display 1)\nword-for-word and 2) in blocks, in terms of reading speed and delay.\nExperiments on three language pairs (en$\\rightarrow$it, de, fr) show that\nscrolling lines is the only mode achieving an acceptable reading speed while\nkeeping delay close to a 4-second threshold. We argue that simultaneous\ntranslation for readable live subtitles still faces challenges, the main one\nbeing poor translation quality, and propose directions for steering future\nresearch.",
          "link": "http://arxiv.org/abs/2107.08807",
          "publishedOn": "2021-07-20T02:04:40.743Z",
          "wordCount": 622,
          "title": "Simultaneous Speech Translation for Live Subtitling: from Delay to Display. (arXiv:2107.08807v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08264",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xingbo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jianben He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1\">Zhihua Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Muqiao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_H/0/1/0/all/0/1\">Huamin Qu</a>",
          "description": "Multimodal sentiment analysis aims to recognize people's attitudes from\nmultiple communication channels such as verbal content (i.e., text), voice, and\nfacial expressions. It has become a vibrant and important research topic in\nnatural language processing. Much research focuses on modeling the complex\nintra- and inter-modal interactions between different communication channels.\nHowever, current multimodal models with strong performance are often\ndeep-learning-based techniques and work like black boxes. It is not clear how\nmodels utilize multimodal information for sentiment predictions. Despite recent\nadvances in techniques for enhancing the explainability of machine learning\nmodels, they often target unimodal scenarios (e.g., images, sentences), and\nlittle research has been done on explaining multimodal models. In this paper,\nwe present an interactive visual analytics system, M2Lens, to visualize and\nexplain multimodal models for sentiment analysis. M2Lens provides explanations\non intra- and inter-modal interactions at the global, subset, and local levels.\nSpecifically, it summarizes the influence of three typical interaction types\n(i.e., dominance, complement, and conflict) on the model predictions. Moreover,\nM2Lens identifies frequent and influential multimodal features and supports the\nmulti-faceted exploration of model behaviors from language, acoustic, and\nvisual modalities. Through two case studies and expert interviews, we\ndemonstrate our system can help users gain deep insights into the multimodal\nmodels for sentiment analysis.",
          "link": "http://arxiv.org/abs/2107.08264",
          "publishedOn": "2021-07-20T02:04:40.723Z",
          "wordCount": 685,
          "title": "M2Lens: Visualizing and Explaining Multimodal Models for Sentiment Analysis. (arXiv:2107.08264v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.12700",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jie_C/0/1/0/all/0/1\">Cheng Jie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1\">Da Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zigeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_W/0/1/0/all/0/1\">Wei Shen</a>",
          "description": "With the increasing scale of search engine marketing, designing an efficient\nbidding system is becoming paramount for the success of e-commerce companies.\nThe critical challenges faced by a modern industrial-level bidding system\ninclude: 1. the catalog is enormous, and the relevant bidding features are of\nhigh sparsity; 2. the large volume of bidding requests induces significant\ncomputation burden to both the offline and online serving. Leveraging\nextraneous user-item information proves essential to mitigate the sparsity\nissue, for which we exploit the natural language signals from the users' query\nand the contextual knowledge from the products. In particular, we extract the\nvector representations of ads via the Transformer model and leverage their\ngeometric relation to building collaborative bidding predictions via\nclustering. The two-step procedure also significantly reduces the computation\nstress of bid evaluation and optimization. In this paper, we introduce the\nend-to-end structure of the bidding system for search engine marketing for\nWalmart e-commerce, which successfully handles tens of millions of bids each\nday. We analyze the online and offline performances of our approach and discuss\nhow we find it as a production-efficient solution.",
          "link": "http://arxiv.org/abs/2106.12700",
          "publishedOn": "2021-07-20T02:04:40.640Z",
          "wordCount": 657,
          "title": "An Efficient Group-based Search Engine Marketing System for E-Commerce. (arXiv:2106.12700v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.13155",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Anderson_M/0/1/0/all/0/1\">Mark Anderson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gomez_Rodriguez_C/0/1/0/all/0/1\">Carlos G&#xf3;mez-Rodr&#xed;guez</a>",
          "description": "We present the system submission from the FASTPARSE team for the EUD Shared\nTask at IWPT 2021. We engaged in the task last year by focusing on efficiency.\nThis year we have focused on experimenting with new ideas on a limited time\nbudget. Our system is based on splitting the EUD graph into several trees,\nbased on linguistic criteria. We predict these trees using a sequence-labelling\nparser and combine them into an EUD graph. The results were relatively poor,\nalthough not a total disaster and could probably be improved with some\npolishing of the system's rough edges.",
          "link": "http://arxiv.org/abs/2106.13155",
          "publishedOn": "2021-07-20T02:04:40.621Z",
          "wordCount": 575,
          "title": "Splitting EUD graphs into trees: A quick and clatty approach. (arXiv:2106.13155v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08772",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ruiter_D/0/1/0/all/0/1\">Dana Ruiter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klakow_D/0/1/0/all/0/1\">Dietrich Klakow</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Genabith_J/0/1/0/all/0/1\">Josef van Genabith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Espana_Bonet_C/0/1/0/all/0/1\">Cristina Espa&#xf1;a-Bonet</a>",
          "description": "For most language combinations, parallel data is either scarce or simply\nunavailable. To address this, unsupervised machine translation (UMT) exploits\nlarge amounts of monolingual data by using synthetic data generation techniques\nsuch as back-translation and noising, while self-supervised NMT (SSNMT)\nidentifies parallel sentences in smaller comparable data and trains on them. To\ndate, the inclusion of UMT data generation techniques in SSNMT has not been\ninvestigated. We show that including UMT techniques into SSNMT significantly\noutperforms SSNMT and UMT on all tested language pairs, with improvements of up\nto +4.3 BLEU, +50.8 BLEU, +51.5 over SSNMT, statistical UMT and hybrid UMT,\nrespectively, on Afrikaans to English. We further show that the combination of\nmultilingual denoising autoencoding, SSNMT with backtranslation and bilingual\nfinetuning enables us to learn machine translation even for distant language\npairs for which only small amounts of monolingual data are available, e.g.\nyielding BLEU scores of 11.6 (English to Swahili).",
          "link": "http://arxiv.org/abs/2107.08772",
          "publishedOn": "2021-07-20T02:04:40.442Z",
          "wordCount": 604,
          "title": "Integrating Unsupervised Data Generation into Self-Supervised Neural Machine Translation for Low-Resource Languages. (arXiv:2107.08772v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2004.01670",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vidgen_B/0/1/0/all/0/1\">Bertie Vidgen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Derczynski_L/0/1/0/all/0/1\">Leon Derczynski</a>",
          "description": "Data-driven analysis and detection of abusive online content covers many\ndifferent tasks, phenomena, contexts, and methodologies. This paper\nsystematically reviews abusive language dataset creation and content in\nconjunction with an open website for cataloguing abusive language data. This\ncollection of knowledge leads to a synthesis providing evidence-based\nrecommendations for practitioners working with this complex and highly diverse\ndata.",
          "link": "http://arxiv.org/abs/2004.01670",
          "publishedOn": "2021-07-20T02:04:40.423Z",
          "wordCount": 533,
          "title": "Directions in Abusive Language Training Data: Garbage In, Garbage Out. (arXiv:2004.01670v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08728",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Slavnov_S/0/1/0/all/0/1\">Sergey Slavnov</a>",
          "description": "We propose a concrete surface representation of abstract categorial grammars\nin the category of word cobordisms or cowordisms for short, which are certain\nbipartite graphs decorated with words in a given alphabet, generalizing linear\nlogic proof-nets. We also introduce and study linear logic grammars, directly\nbased on cobordisms and using classical multiplicative linear logic as a typing\nsystem.",
          "link": "http://arxiv.org/abs/2107.08728",
          "publishedOn": "2021-07-20T02:04:40.362Z",
          "wordCount": 519,
          "title": "Cobordisms and commutative categorial grammars. (arXiv:2107.08728v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2007.12988",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alshaabi_T/0/1/0/all/0/1\">Thayer Alshaabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adams_J/0/1/0/all/0/1\">Jane L. Adams</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arnold_M/0/1/0/all/0/1\">Michael V. Arnold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Minot_J/0/1/0/all/0/1\">Joshua R. Minot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dewhurst_D/0/1/0/all/0/1\">David R. Dewhurst</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reagan_A/0/1/0/all/0/1\">Andrew J. Reagan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Danforth_C/0/1/0/all/0/1\">Christopher M. Danforth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dodds_P/0/1/0/all/0/1\">Peter Sheridan Dodds</a>",
          "description": "In real-time, social media data strongly imprints world events, popular\nculture, and day-to-day conversations by millions of ordinary people at a scale\nthat is scarcely conventionalized and recorded. Vitally, and absent from many\nstandard corpora such as books and news archives, sharing and commenting\nmechanisms are native to social media platforms, enabling us to quantify social\namplification (i.e., popularity) of trending storylines and contemporary\ncultural phenomena. Here, we describe Storywrangler, a natural language\nprocessing instrument designed to carry out an ongoing, day-scale curation of\nover 100 billion tweets containing roughly 1 trillion 1-grams from 2008 to\n2021. For each day, we break tweets into unigrams, bigrams, and trigrams\nspanning over 100 languages. We track n-gram usage frequencies, and generate\nZipf distributions, for words, hashtags, handles, numerals, symbols, and\nemojis. We make the data set available through an interactive time series\nviewer, and as downloadable time series and daily distributions. Although\nStorywrangler leverages Twitter data, our method of extracting and tracking\ndynamic changes of n-grams can be extended to any similar social media\nplatform. We showcase a few examples of the many possible avenues of study we\naim to enable including how social amplification can be visualized through\n'contagiograms'. We also present some example case studies that bridge n-gram\ntime series with disparate data sources to explore sociotechnical dynamics of\nfamous individuals, box office success, and social unrest.",
          "link": "http://arxiv.org/abs/2007.12988",
          "publishedOn": "2021-07-20T02:04:40.344Z",
          "wordCount": 786,
          "title": "Storywrangler: A massive exploratorium for sociolinguistic, cultural, socioeconomic, and political timelines using Twitter. (arXiv:2007.12988v5 [cs.SI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08929",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gu_N/0/1/0/all/0/1\">Nianlong Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ash_E/0/1/0/all/0/1\">Elliott Ash</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hahnloser_R/0/1/0/all/0/1\">Richard H.R. Hahnloser</a>",
          "description": "We introduce MemSum (Multi-step Episodic Markov decision process extractive\nSUMmarizer), a reinforcement-learning-based extractive summarizer enriched at\nany given time step with information on the current extraction history. Similar\nto previous models in this vein, MemSum iteratively selects sentences into the\nsummary. Our innovation is in considering a broader information set when\nsummarizing that would intuitively also be used by humans in this task: 1) the\ntext content of the sentence, 2) the global text context of the rest of the\ndocument, and 3) the extraction history consisting of the set of sentences that\nhave already been extracted. With a lightweight architecture, MemSum\nnonetheless obtains state-of-the-art test-set performance (ROUGE score) on long\ndocument datasets (PubMed, arXiv, and GovReport). Supporting analysis\ndemonstrates that the added awareness of extraction history gives MemSum\nrobustness against redundancy in the source document.",
          "link": "http://arxiv.org/abs/2107.08929",
          "publishedOn": "2021-07-20T02:04:40.322Z",
          "wordCount": 575,
          "title": "MemSum: Extractive Summarization of Long Documents using Multi-step Episodic Markov Decision Processes. (arXiv:2107.08929v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08721",
          "author": "<a href=\"http://arxiv.org/find/q-fin/1/au:+Chen_Q/0/1/0/all/0/1\">Qinkai Chen</a>",
          "description": "News events can greatly influence equity markets. In this paper, we are\ninterested in predicting the short-term movement of stock prices after\nfinancial news events using only the headlines of the news. To achieve this\ngoal, we introduce a new text mining method called Fine-Tuned\nContextualized-Embedding Recurrent Neural Network (FT-CE-RNN). Compared with\nprevious approaches which use static vector representations of the news (static\nembedding), our model uses contextualized vector representations of the\nheadlines (contextualized embeddings) generated from Bidirectional Encoder\nRepresentations from Transformers (BERT). Our model obtains the\nstate-of-the-art result on this stock movement prediction task. It shows\nsignificant improvement compared with other baseline models, in both accuracy\nand trading simulations. Through various trading simulations based on millions\nof headlines from Bloomberg News, we demonstrate the ability of this model in\nreal scenarios.",
          "link": "http://arxiv.org/abs/2107.08721",
          "publishedOn": "2021-07-20T02:04:40.303Z",
          "wordCount": 590,
          "title": "Stock Movement Prediction with Financial News using Contextualized Embedding from BERT. (arXiv:2107.08721v1 [q-fin.ST])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08739",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fabiano_F/0/1/0/all/0/1\">Francesco Fabiano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_B/0/1/0/all/0/1\">Biplav Srivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lenchner_J/0/1/0/all/0/1\">Jonathan Lenchner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Horesh_L/0/1/0/all/0/1\">Lior Horesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rossi_F/0/1/0/all/0/1\">Francesca Rossi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganapini_M/0/1/0/all/0/1\">Marianna Bergamaschi Ganapini</a>",
          "description": "Epistemic Planning (EP) refers to an automated planning setting where the\nagent reasons in the space of knowledge states and tries to find a plan to\nreach a desirable state from the current state. Its general form, the\nMulti-agent Epistemic Planning (MEP) problem involves multiple agents who need\nto reason about both the state of the world and the information flow between\nagents. In a MEP problem, multiple approaches have been developed recently with\nvarying restrictions, such as considering only the concept of knowledge while\nnot allowing the idea of belief, or not allowing for ``complex\" modal operators\nsuch as those needed to handle dynamic common knowledge. While the diversity of\napproaches has led to a deeper understanding of the problem space, the lack of\na standardized way to specify MEP problems independently of solution approaches\nhas created difficulties in comparing performance of planners, identifying\npromising techniques, exploring new strategies like ensemble methods, and\nmaking it easy for new researchers to contribute to this research area. To\naddress the situation, we propose a unified way of specifying EP problems - the\nEpistemic Planning Domain Definition Language, E-PDDL. We show that E-PPDL can\nbe supported by leading MEP planners and provide corresponding parser code that\ntranslates EP problems specified in E-PDDL into (M)EP problems that can be\nhandled by several planners. This work is also useful in building more general\nepistemic planning environments where we envision a meta-cognitive module that\ntakes a planning problem in E-PDDL, identifies and assesses some of its\nfeatures, and autonomously decides which planner is the best one to solve it.",
          "link": "http://arxiv.org/abs/2107.08739",
          "publishedOn": "2021-07-20T02:04:40.282Z",
          "wordCount": 718,
          "title": "E-PDDL: A Standardized Way of Defining Epistemic Planning Problems. (arXiv:2107.08739v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08329",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yutao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_J/0/1/0/all/0/1\">Jian-Yun Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1\">Kun Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_P/0/1/0/all/0/1\">Pan Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Hao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dou_Z/0/1/0/all/0/1\">Zhicheng Dou</a>",
          "description": "A proactive dialogue system has the ability to proactively lead the\nconversation. Different from the general chatbots which only react to the user,\nproactive dialogue systems can be used to achieve some goals, e.g., to\nrecommend some items to the user. Background knowledge is essential to enable\nsmooth and natural transitions in dialogue. In this paper, we propose a new\nmulti-task learning framework for retrieval-based knowledge-grounded proactive\ndialogue. To determine the relevant knowledge to be used, we frame knowledge\nprediction as a complementary task and use explicit signals to supervise its\nlearning. The final response is selected according to the predicted knowledge,\nthe goal to achieve, and the context. Experimental results show that explicit\nmodeling of knowledge prediction and goal selection can greatly improve the\nfinal response selection. Our code is available at\nhttps://github.com/DaoD/KPN/.",
          "link": "http://arxiv.org/abs/2107.08329",
          "publishedOn": "2021-07-20T02:04:40.260Z",
          "wordCount": 581,
          "title": "Proactive Retrieval-based Chatbots based on Relevant Knowledge and Goals. (arXiv:2107.08329v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08128",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hegel_A/0/1/0/all/0/1\">Allison Hegel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1\">Marina Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peaslee_G/0/1/0/all/0/1\">Genevieve Peaslee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roof_B/0/1/0/all/0/1\">Brendan Roof</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elwany_E/0/1/0/all/0/1\">Emad Elwany</a>",
          "description": "Large, pre-trained transformer models like BERT have achieved\nstate-of-the-art results on document understanding tasks, but most\nimplementations can only consider 512 tokens at a time. For many real-world\napplications, documents can be much longer, and the segmentation strategies\ntypically used on longer documents miss out on document structure and\ncontextual information, hurting their results on downstream tasks. In our work\non legal agreements, we find that visual cues such as layout, style, and\nplacement of text in a document are strong features that are crucial to\nachieving an acceptable level of accuracy on long documents. We measure the\nimpact of incorporating such visual cues, obtained via computer vision methods,\non the accuracy of document understanding tasks including document\nsegmentation, entity extraction, and attribute classification. Our method of\nsegmenting documents based on structural metadata out-performs existing methods\non four long-document understanding tasks as measured on the Contract\nUnderstanding Atticus Dataset.",
          "link": "http://arxiv.org/abs/2107.08128",
          "publishedOn": "2021-07-20T02:04:40.191Z",
          "wordCount": 602,
          "title": "The Law of Large Documents: Understanding the Structure of Legal Contracts Using Visual Cues. (arXiv:2107.08128v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08091",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Braun_R/0/1/0/all/0/1\">Rudolf A. Braun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madikeri_S/0/1/0/all/0/1\">Srikanth Madikeri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Motlicek_P/0/1/0/all/0/1\">Petr Motlicek</a>",
          "description": "A common problem for automatic speech recognition systems is how to recognize\nwords that they did not see during training. Currently there is no established\nmethod of evaluating different techniques for tackling this problem. We propose\nusing the CommonVoice dataset to create test sets for multiple languages which\nhave a high out-of-vocabulary (OOV) ratio relative to a training set and\nrelease a new tool for calculating relevant performance metrics. We then\nevaluate, within the context of a hybrid ASR system, how much better subword\nmodels are at recognizing OOVs, and how much benefit one can get from\nincorporating OOV-word information into an existing system by modifying WFSTs.\nAdditionally, we propose a new method for modifying a subword-based language\nmodel so as to better recognize OOV-words. We showcase very large improvements\nin OOV-word recognition and make both the data and code available.",
          "link": "http://arxiv.org/abs/2107.08091",
          "publishedOn": "2021-07-20T02:04:40.151Z",
          "wordCount": 592,
          "title": "A Comparison of Methods for OOV-word Recognition on a New Public Dataset. (arXiv:2107.08091v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2010.05357",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiahua Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuai Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mazumder_S/0/1/0/all/0/1\">Sahisnu Mazumder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bing Liu</a>",
          "description": "Classifying and resolving coreferences of objects (e.g., product names) and\nattributes (e.g., product aspects) in opinionated reviews is crucial for\nimproving the opinion mining performance. However, the task is challenging as\none often needs to consider domain-specific knowledge (e.g., iPad is a tablet\nand has aspect resolution) to identify coreferences in opinionated reviews.\nAlso, compiling a handcrafted and curated domain-specific knowledge base for\neach domain is very time consuming and arduous. This paper proposes an approach\nto automatically mine and leverage domain-specific knowledge for classifying\nobjects and attribute coreferences. The approach extracts domain-specific\nknowledge from unlabeled review data and trains a knowledgeaware neural\ncoreference classification model to leverage (useful) domain knowledge together\nwith general commonsense knowledge for the task. Experimental evaluation on\nrealworld datasets involving five domains (product types) shows the\neffectiveness of the approach.",
          "link": "http://arxiv.org/abs/2010.05357",
          "publishedOn": "2021-07-20T02:04:40.129Z",
          "wordCount": 615,
          "title": "A Knowledge-Driven Approach to Classifying Object and Attribute Coreferences in Opinion Mining. (arXiv:2010.05357v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08720",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fanton_M/0/1/0/all/0/1\">Margherita Fanton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bonaldi_H/0/1/0/all/0/1\">Helena Bonaldi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tekiroglu_S/0/1/0/all/0/1\">Serra Sinem Tekiroglu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guerini_M/0/1/0/all/0/1\">Marco Guerini</a>",
          "description": "Undermining the impact of hateful content with informed and non-aggressive\nresponses, called counter narratives, has emerged as a possible solution for\nhaving healthier online communities. Thus, some NLP studies have started\naddressing the task of counter narrative generation. Although such studies have\nmade an effort to build hate speech / counter narrative (HS/CN) datasets for\nneural generation, they fall short in reaching either high-quality and/or\nhigh-quantity. In this paper, we propose a novel human-in-the-loop data\ncollection methodology in which a generative language model is refined\niteratively by using its own data from the previous loops to generate new\ntraining samples that experts review and/or post-edit. Our experiments\ncomprised several loops including dynamic variations. Results show that the\nmethodology is scalable and facilitates diverse, novel, and cost-effective data\ncollection. To our knowledge, the resulting dataset is the only expert-based\nmulti-target HS/CN dataset available to the community.",
          "link": "http://arxiv.org/abs/2107.08720",
          "publishedOn": "2021-07-20T02:04:40.103Z",
          "wordCount": 603,
          "title": "Human-in-the-Loop for Data Collection: a Multi-Target Counter Narrative Dataset to Fight Online Hate Speech. (arXiv:2107.08720v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08661",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1\">Ye Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramanovich_M/0/1/0/all/0/1\">Michelle Tadmor Ramanovich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Remez_T/0/1/0/all/0/1\">Tal Remez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pomerantz_R/0/1/0/all/0/1\">Roi Pomerantz</a>",
          "description": "We present Translatotron 2, a neural direct speech-to-speech translation\nmodel that can be trained end-to-end. Translatotron 2 consists of a speech\nencoder, a phoneme decoder, a mel-spectrogram synthesizer, and an attention\nmodule that connects all the previous three components. Experimental results\nsuggest that Translatotron 2 outperforms the original Translatotron by a large\nmargin in terms of translation quality and predicted speech naturalness, and\ndrastically improves the robustness of the predicted speech by mitigating\nover-generation, such as babbling or long pause. We also propose a new method\nfor retaining the source speaker's voice in the translated speech. The trained\nmodel is restricted to retain the source speaker's voice, and unlike the\noriginal Translatotron, it is not able to generate speech in a different\nspeaker's voice, making the model more robust for production deployment, by\nmitigating potential misuse for creating spoofing audio artifacts. When the new\nmethod is used together with a simple concatenation-based data augmentation,\nthe trained Translatotron 2 model is able to retain each speaker's voice for\ninput with speaker turns.",
          "link": "http://arxiv.org/abs/2107.08661",
          "publishedOn": "2021-07-20T02:04:40.071Z",
          "wordCount": 614,
          "title": "Translatotron 2: Robust direct speech-to-speech translation. (arXiv:2107.08661v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08685",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_N/0/1/0/all/0/1\">Nyoungwoo Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_S/0/1/0/all/0/1\">Suwon Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choo_J/0/1/0/all/0/1\">Jaegul Choo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_H/0/1/0/all/0/1\">Ho-Jin Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Myaeng_S/0/1/0/all/0/1\">Sung-Hyun Myaeng</a>",
          "description": "In multi-modal dialogue systems, it is important to allow the use of images\nas part of a multi-turn conversation. Training such dialogue systems generally\nrequires a large-scale dataset consisting of multi-turn dialogues that involve\nimages, but such datasets rarely exist. In response, this paper proposes a 45k\nmulti-modal dialogue dataset created with minimal human intervention. Our\nmethod to create such a dataset consists of (1) preparing and pre-processing\ntext dialogue datasets, (2) creating image-mixed dialogues by using a\ntext-to-image replacement technique, and (3) employing a\ncontextual-similarity-based filtering step to ensure the contextual coherence\nof the dataset. To evaluate the validity of our dataset, we devise a simple\nretrieval model for dialogue sentence prediction tasks. Automatic metrics and\nhuman evaluation results on such tasks show that our dataset can be effectively\nused as training data for multi-modal dialogue systems which require an\nunderstanding of images and text in a context-aware manner. Our dataset and\ngeneration code is available at\nhttps://github.com/shh1574/multi-modal-dialogue-dataset.",
          "link": "http://arxiv.org/abs/2107.08685",
          "publishedOn": "2021-07-20T02:04:40.007Z",
          "wordCount": 606,
          "title": "Constructing Multi-Modal Dialogue Dataset by Replacing Text with Semantically Relevant Images. (arXiv:2107.08685v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08408",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singh_I/0/1/0/all/0/1\">Ishika Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_G/0/1/0/all/0/1\">Gargi Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Modi_A/0/1/0/all/0/1\">Ashutosh Modi</a>",
          "description": "Recently, text world games have been proposed to enable artificial agents to\nunderstand and reason about real-world scenarios. These text-based games are\nchallenging for artificial agents, as it requires understanding and interaction\nusing natural language in a partially observable environment. In this paper, we\nimprove the semantic understanding of the agent by proposing a simple RL with\nLM framework where we use transformer-based language models with Deep RL\nmodels. We perform a detailed study of our framework to demonstrate how our\nmodel outperforms all existing agents on the popular game, Zork1, to achieve a\nscore of 44.7, which is 1.6 higher than the state-of-the-art model. Our\nproposed approach also performs comparably to the state-of-the-art models on\nthe other set of text games.",
          "link": "http://arxiv.org/abs/2107.08408",
          "publishedOn": "2021-07-20T02:04:39.987Z",
          "wordCount": 581,
          "title": "Pre-trained Language Models as Prior Knowledge for Playing Text-based Games. (arXiv:2107.08408v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08523",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gantt_W/0/1/0/all/0/1\">William Gantt</a>",
          "description": "Semantic role labeling (SRL) -- identifying the semantic relationships\nbetween a predicate and other constituents in the same sentence -- is a\nwell-studied task in natural language understanding (NLU). However, many of\nthese relationships are evident only at the level of the document, as a role\nfor a predicate in one sentence may often be filled by an argument in a\ndifferent one. This more general task, known as implicit semantic role labeling\nor argument linking, has received increased attention in recent years, as\nresearchers have recognized its centrality to information extraction and NLU.\nThis paper surveys the literature on argument linking and identifies several\nnotable shortcomings of existing approaches that indicate the paths along which\nfuture research effort could most profitably be spent.",
          "link": "http://arxiv.org/abs/2107.08523",
          "publishedOn": "2021-07-20T02:04:39.968Z",
          "wordCount": 549,
          "title": "Argument Linking: A Survey and Forecast. (arXiv:2107.08523v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08173",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Geng_B/0/1/0/all/0/1\">Binzong Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_F/0/1/0/all/0/1\">Fajie Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1\">Qiancheng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Ying Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">Ruifeng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Min Yang</a>",
          "description": "This ability to learn consecutive tasks without forgetting how to perform\npreviously trained problems is essential for developing an online dialogue\nsystem. This paper proposes an effective continual learning for the\ntask-oriented dialogue system with iterative network pruning, expanding and\nmasking (TPEM), which preserves performance on previously encountered tasks\nwhile accelerating learning progress on subsequent tasks. Specifically, TPEM\n(i) leverages network pruning to keep the knowledge for old tasks, (ii) adopts\nnetwork expanding to create free weights for new tasks, and (iii) introduces\ntask-specific network masking to alleviate the negative impact of fixed weights\nof old tasks on new tasks. We conduct extensive experiments on seven different\ntasks from three benchmark datasets and show empirically that TPEM leads to\nsignificantly improved results over the strong competitors. For\nreproducibility, we submit the code and data at:\nhttps://github.com/siat-nlp/TPEM",
          "link": "http://arxiv.org/abs/2107.08173",
          "publishedOn": "2021-07-20T02:04:39.940Z",
          "wordCount": 598,
          "title": "Continual Learning for Task-oriented Dialogue System with Iterative Network Pruning, Expanding and Masking. (arXiv:2107.08173v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08582",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bian_N/0/1/0/all/0/1\">Ning Bian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xianpei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Bo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Hongyu Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_B/0/1/0/all/0/1\">Ben He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Le Sun</a>",
          "description": "Despite recent success in machine reading comprehension (MRC), learning\nhigh-quality MRC models still requires large-scale labeled training data, even\nusing strong pre-trained language models (PLMs). The pre-training tasks for\nPLMs are not question-answering or MRC-based tasks, making existing PLMs unable\nto be directly used for unsupervised MRC. Specifically, MRC aims to spot an\naccurate answer span from the given document, but PLMs focus on token filling\nin sentences. In this paper, we propose a new framework for unsupervised MRC.\nFirstly, we propose to learn to spot answer spans in documents via\nself-supervised learning, by designing a self-supervision pretext task for MRC\n- Spotting-MLM. Solving this task requires capturing deep interactions between\nsentences in documents. Secondly, we apply a simple sentence rewriting strategy\nin the inference stage to alleviate the expression mismatch between questions\nand documents. Experiments show that our method achieves a new state-of-the-art\nperformance for unsupervised MRC.",
          "link": "http://arxiv.org/abs/2107.08582",
          "publishedOn": "2021-07-20T02:04:39.921Z",
          "wordCount": 593,
          "title": "Bridging the Gap between Language Model and Reading Comprehension: Unsupervised MRC via Self-Supervision. (arXiv:2107.08582v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08251",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weston_J/0/1/0/all/0/1\">Jack Weston</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lenain_R/0/1/0/all/0/1\">Raphael Lenain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meepegama_U/0/1/0/all/0/1\">Udeepa Meepegama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fristed_E/0/1/0/all/0/1\">Emil Fristed</a>",
          "description": "We introduce ParaBLEU, a paraphrase representation learning model and\nevaluation metric for text generation. Unlike previous approaches, ParaBLEU\nlearns to understand paraphrasis using generative conditioning as a pretraining\nobjective. ParaBLEU correlates more strongly with human judgements than\nexisting metrics, obtaining new state-of-the-art results on the 2017 WMT\nMetrics Shared Task. We show that our model is robust to data scarcity,\nexceeding previous state-of-the-art performance using only $50\\%$ of the\navailable training data and surpassing BLEU, ROUGE and METEOR with only $40$\nlabelled examples. Finally, we demonstrate that ParaBLEU can be used to\nconditionally generate novel paraphrases from a single demonstration, which we\nuse to confirm our hypothesis that it learns abstract, generalized paraphrase\nrepresentations.",
          "link": "http://arxiv.org/abs/2107.08251",
          "publishedOn": "2021-07-20T02:04:39.649Z",
          "wordCount": 546,
          "title": "Generative Pretraining for Paraphrase Evaluation. (arXiv:2107.08251v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08356",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xingbo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ming_Y/0/1/0/all/0/1\">Yao Ming</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1\">Tongshuang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_H/0/1/0/all/0/1\">Haipeng Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_H/0/1/0/all/0/1\">Huamin Qu</a>",
          "description": "Despite being a critical communication skill, grasping humor is challenging\n-- a successful use of humor requires a mixture of both engaging content\nbuild-up and an appropriate vocal delivery (e.g., pause). Prior studies on\ncomputational humor emphasize the textual and audio features immediately next\nto the punchline, yet overlooking longer-term context setup. Moreover, the\ntheories are usually too abstract for understanding each concrete humor\nsnippet. To fill in the gap, we develop DeHumor, a visual analytical system for\nanalyzing humorous behaviors in public speaking. To intuitively reveal the\nbuilding blocks of each concrete example, DeHumor decomposes each humorous\nvideo into multimodal features and provides inline annotations of them on the\nvideo script. In particular, to better capture the build-ups, we introduce\ncontent repetition as a complement to features introduced in theories of\ncomputational humor and visualize them in a context linking graph. To help\nusers locate the punchlines that have the desired features to learn, we\nsummarize the content (with keywords) and humor feature statistics on an\naugmented time matrix. With case studies on stand-up comedy shows and TED\ntalks, we show that DeHumor is able to highlight various building blocks of\nhumor examples. In addition, expert interviews with communication coaches and\nhumor researchers demonstrate the effectiveness of DeHumor for multimodal humor\nanalysis of speech content and vocal delivery.",
          "link": "http://arxiv.org/abs/2107.08356",
          "publishedOn": "2021-07-20T02:04:39.589Z",
          "wordCount": 689,
          "title": "DeHumor: Visual Analytics for Decomposing Humor. (arXiv:2107.08356v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08512",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Arruda_H/0/1/0/all/0/1\">Henrique F. de Arruda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reia_S/0/1/0/all/0/1\">Sandro M. Reia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silva_F/0/1/0/all/0/1\">Filipi N. Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amancio_D/0/1/0/all/0/1\">Diego R. Amancio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Costa_L/0/1/0/all/0/1\">Luciano da F. Costa</a>",
          "description": "Poetry and prose are written artistic expressions that help us to appreciate\nthe reality we live. Each of these styles has its own set of subjective\nproperties, such as rhyme and rhythm, which are easily caught by a human\nreader's eye and ear. With the recent advances in artificial intelligence, the\ngap between humans and machines may have decreased, and today we observe\nalgorithms mastering tasks that were once exclusively performed by humans. In\nthis paper, we propose an automated method to distinguish between poetry and\nprose based solely on aural and rhythmic properties. In other to compare prose\nand poetry rhythms, we represent the rhymes and phones as temporal sequences\nand thus we propose a procedure for extracting rhythmic features from these\nsequences. The classification of the considered texts using the set of features\nextracted resulted in a best accuracy of 0.78, obtained with a neural network.\nInterestingly, by using an approach based on complex networks to visualize the\nsimilarities between the different texts considered, we found that the patterns\nof poetry vary much more than prose. Consequently, a much richer and complex\nset of rhythmic possibilities tends to be found in that modality.",
          "link": "http://arxiv.org/abs/2107.08512",
          "publishedOn": "2021-07-20T02:04:39.557Z",
          "wordCount": 646,
          "title": "A pattern recognition approach for distinguishing between prose and poetry. (arXiv:2107.08512v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08357",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guzman_F/0/1/0/all/0/1\">Francisco Guzman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+El_Kishky_A/0/1/0/all/0/1\">Ahmed El-Kishky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubinstein_B/0/1/0/all/0/1\">Benjamin I. P. Rubinstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohn_T/0/1/0/all/0/1\">Trevor Cohn</a>",
          "description": "Mistranslated numbers have the potential to cause serious effects, such as\nfinancial loss or medical misinformation. In this work we develop comprehensive\nassessments of the robustness of neural machine translation systems to\nnumerical text via behavioural testing. We explore a variety of numerical\ntranslation capabilities a system is expected to exhibit and design effective\ntest examples to expose system underperformance. We find that numerical\nmistranslation is a general issue: major commercial systems and\nstate-of-the-art research models fail on many of our test examples, for high-\nand low-resource languages. Our tests reveal novel errors that have not\npreviously been reported in NMT systems, to the best of our knowledge. Lastly,\nwe discuss strategies to mitigate numerical mistranslation.",
          "link": "http://arxiv.org/abs/2107.08357",
          "publishedOn": "2021-07-20T02:04:39.369Z",
          "wordCount": 577,
          "title": "As Easy as 1, 2, 3: Behavioural Testing of NMT Systems for Numerical Translation. (arXiv:2107.08357v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08199",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Parry_H/0/1/0/all/0/1\">Hishan Parry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xun_L/0/1/0/all/0/1\">Lei Xun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabet_A/0/1/0/all/0/1\">Amin Sabet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bi_J/0/1/0/all/0/1\">Jia Bi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hare_J/0/1/0/all/0/1\">Jonathon Hare</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Merrett_G/0/1/0/all/0/1\">Geoff V. Merrett</a>",
          "description": "The Transformer architecture is widely used for machine translation tasks.\nHowever, its resource-intensive nature makes it challenging to implement on\nconstrained embedded devices, particularly where available hardware resources\ncan vary at run-time. We propose a dynamic machine translation model that\nscales the Transformer architecture based on the available resources at any\nparticular time. The proposed approach, 'Dynamic-HAT', uses a HAT\nSuperTransformer as the backbone to search for SubTransformers with different\naccuracy-latency trade-offs at design time. The optimal SubTransformers are\nsampled from the SuperTransformer at run-time, depending on latency\nconstraints. The Dynamic-HAT is tested on the Jetson Nano and the approach uses\ninherited SubTransformers sampled directly from the SuperTransformer with a\nswitching time of <1s. Using inherited SubTransformers results in a BLEU score\nloss of <1.5% because the SubTransformer configuration is not retrained from\nscratch after sampling. However, to recover this loss in performance, the\ndimensions of the design space can be reduced to tailor it to a family of\ntarget hardware. The new reduced design space results in a BLEU score increase\nof approximately 1% for sub-optimal models from the original design space, with\na wide range for performance scaling between 0.356s - 1.526s for the GPU and\n2.9s - 7.31s for the CPU.",
          "link": "http://arxiv.org/abs/2107.08199",
          "publishedOn": "2021-07-20T02:04:39.289Z",
          "wordCount": 651,
          "title": "Dynamic Transformer for Efficient Machine Translation on Embedded Devices. (arXiv:2107.08199v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08337",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chingacham_A/0/1/0/all/0/1\">Anupama Chingacham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Demberg_V/0/1/0/all/0/1\">Vera Demberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klakow_D/0/1/0/all/0/1\">Dietrich Klakow</a>",
          "description": "Listening in noisy environments can be difficult even for individuals with a\nnormal hearing thresholds. The speech signal can be masked by noise, which may\nlead to word misperceptions on the side of the listener, and overall difficulty\nto understand the message. To mitigate hearing difficulties on listeners, a\nco-operative speaker utilizes voice modulation strategies like Lombard speech\nto generate noise-robust utterances, and similar solutions have been developed\nfor speech synthesis systems. In this work, we propose an alternate solution of\nchoosing noise-robust lexical paraphrases to represent an intended meaning. Our\nresults show that lexical paraphrases differ in their intelligibility in noise.\nWe evaluate the intelligibility of synonyms in context and find that choosing a\nlexical unit that is less risky to be misheard than its synonym introduced an\naverage gain in comprehension of 37% at SNR -5 dB and 21% at SNR 0 dB for\nbabble noise.",
          "link": "http://arxiv.org/abs/2107.08337",
          "publishedOn": "2021-07-20T02:04:39.266Z",
          "wordCount": 598,
          "title": "Exploring the Potential of Lexical Paraphrases for Mitigating Noise-Induced Comprehension Errors. (arXiv:2107.08337v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08212",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xuebo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Longyue Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_D/0/1/0/all/0/1\">Derek F. Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_L/0/1/0/all/0/1\">Liang Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chao_L/0/1/0/all/0/1\">Lidia S. Chao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1\">Shuming Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1\">Zhaopeng Tu</a>",
          "description": "Previous studies have shown that initializing neural machine translation\n(NMT) models with the pre-trained language models (LM) can speed up the model\ntraining and boost the model performance. In this work, we identify a critical\nside-effect of pre-training for NMT, which is due to the discrepancy between\nthe training objectives of LM-based pre-training and NMT. Since the LM\nobjective learns to reconstruct a few source tokens and copy most of them, the\npre-training initialization would affect the copying behaviors of NMT models.\nWe provide a quantitative analysis of copying behaviors by introducing a metric\ncalled copying ratio, which empirically shows that pre-training based NMT\nmodels have a larger copying ratio than the standard one. In response to this\nproblem, we propose a simple and effective method named copying penalty to\ncontrol the copying behaviors in decoding. Extensive experiments on both\nin-domain and out-of-domain benchmarks show that the copying penalty method\nconsistently improves translation performance by controlling copying behaviors\nfor pre-training based NMT models. Source code is freely available at\nhttps://github.com/SunbowLiu/CopyingPenalty.",
          "link": "http://arxiv.org/abs/2107.08212",
          "publishedOn": "2021-07-20T02:04:39.238Z",
          "wordCount": 626,
          "title": "On the Copying Behaviors of Pre-Training for Neural Machine Translation. (arXiv:2107.08212v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08248",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weston_J/0/1/0/all/0/1\">Jack Weston</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lenain_R/0/1/0/all/0/1\">Raphael Lenain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meepegama_U/0/1/0/all/0/1\">Udeepa Meepegama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fristed_E/0/1/0/all/0/1\">Emil Fristed</a>",
          "description": "We propose a method for learning de-identified prosody representations from\nraw audio using a contrastive self-supervised signal. Whereas prior work has\nrelied on conditioning models on bottlenecks, we introduce a set of inductive\nbiases that exploit the natural structure of prosody to minimize timbral\ninformation and decouple prosody from speaker representations. Despite\naggressive downsampling of the input and having no access to linguistic\ninformation, our model performs comparably to state-of-the-art speech\nrepresentations on DAMMP, a new benchmark we introduce for spoken language\nunderstanding. We use minimum description length probing to show that our\nrepresentations have selectively learned the subcomponents of non-timbral\nprosody, and that the product quantizer naturally disentangles them without\nusing bottlenecks. We derive an information-theoretic definition of speech\nde-identifiability and use it to demonstrate that our prosody representations\nare less identifiable than other speech representations.",
          "link": "http://arxiv.org/abs/2107.08248",
          "publishedOn": "2021-07-20T02:04:39.186Z",
          "wordCount": 611,
          "title": "Learning De-identified Representations of Prosody from Raw Audio. (arXiv:2107.08248v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08347",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pei_X/0/1/0/all/0/1\">Xin Pei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehta_D/0/1/0/all/0/1\">Deval Mehta</a>",
          "description": "Transcending the binary categorization of racist and xenophobic texts, this\nresearch takes cues from social science theories to develop a four dimensional\ncategory for racism and xenophobia detection, namely stigmatization,\noffensiveness, blame, and exclusion. With the aid of deep learning techniques,\nthis categorical detection enables insights into the nuances of emergent topics\nreflected in racist and xenophobic expression on Twitter. Moreover, a stage\nwise analysis is applied to capture the dynamic changes of the topics across\nthe stages of early development of Covid-19 from a domestic epidemic to an\ninternational public health emergency, and later to a global pandemic. The main\ncontributions of this research include, first the methodological advancement.\nBy bridging the state-of-the-art computational methods with social science\nperspective, this research provides a meaningful approach for future research\nto gain insight into the underlying subtlety of racist and xenophobic\ndiscussion on digital platforms. Second, by enabling a more accurate\ncomprehension and even prediction of public opinions and actions, this research\npaves the way for the enactment of effective intervention policies to combat\nracist crimes and social exclusion under Covid-19.",
          "link": "http://arxiv.org/abs/2107.08347",
          "publishedOn": "2021-07-20T02:04:39.148Z",
          "wordCount": 688,
          "title": "Beyond a binary of (non)racist tweets: A four-dimensional categorical detection and analysis of racist and xenophobic opinions on Twitter in early Covid-19. (arXiv:2107.08347v1 [cs.SI])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08188",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wadden_D/0/1/0/all/0/1\">David Wadden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lo_K/0/1/0/all/0/1\">Kyle Lo</a>",
          "description": "We present an overview of the SciVer shared task, presented at the 2nd\nScholarly Document Processing (SDP) workshop at NAACL 2021. In this shared\ntask, systems were provided a scientific claim and a corpus of research\nabstracts, and asked to identify which articles SUPPORT or REFUTE the claim as\nwell as provide evidentiary sentences justifying those labels. 11 teams made a\ntotal of 14 submissions to the shared task leaderboard, leading to an\nimprovement of more than +23 F1 on the primary task evaluation metric. In\naddition to surveying the participating systems, we provide several insights\ninto modeling approaches to support continued progress and future research on\nthe important and challenging task of scientific claim verification.",
          "link": "http://arxiv.org/abs/2107.08188",
          "publishedOn": "2021-07-20T02:04:39.083Z",
          "wordCount": 567,
          "title": "Overview and Insights from the SciVer Shared Task on Scientific Claim Verification. (arXiv:2107.08188v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08146",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jansen_P/0/1/0/all/0/1\">Peter Jansen</a>",
          "description": "Tamarian, a fictional language introduced in the Star Trek episode Darmok,\ncommunicates meaning through utterances of metaphorical references, such as\n\"Darmok and Jalad at Tanagra\" instead of \"We should work together.\" This work\nassembles a Tamarian-English dictionary of utterances from the original episode\nand several follow-on novels, and uses this to construct a parallel corpus of\n456 English-Tamarian utterances. A machine translation system based on a large\nlanguage model (T5) is trained using this parallel corpus, and is shown to\nproduce an accuracy of 76% when translating from English to Tamarian on known\nutterances.",
          "link": "http://arxiv.org/abs/2107.08146",
          "publishedOn": "2021-07-20T02:04:39.061Z",
          "wordCount": 527,
          "title": "Darmok and Jalad at Tanagra: A Dataset and Model for English-to-Tamarian Translation. (arXiv:2107.08146v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08124",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wysocki_O/0/1/0/all/0/1\">Oskar Wysocki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Florea_M/0/1/0/all/0/1\">Malina Florea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Landers_D/0/1/0/all/0/1\">Donal Landers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freitas_A/0/1/0/all/0/1\">Andre Freitas</a>",
          "description": "This paper proposes a novel statistical corpus analysis framework targeted\ntowards the interpretation of Natural Language Processing (NLP) architectural\npatterns at scale. The proposed approach combines saturation-based lexicon\nconstruction, statistical corpus analysis methods and graph collocations to\ninduce a synthesis representation of NLP architectural patterns from corpora.\nThe framework is validated in the full corpus of Semeval tasks and demonstrated\ncoherent architectural patterns which can be used to answer architectural\nquestions on a data-driven fashion, providing a systematic mechanism to\ninterpret a largely dynamic and exponentially growing field.",
          "link": "http://arxiv.org/abs/2107.08124",
          "publishedOn": "2021-07-20T02:04:39.034Z",
          "wordCount": 546,
          "title": "Architectures of Meaning, A Systematic Corpus Analysis of NLP Systems. (arXiv:2107.08124v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2012.14094",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Montero_I/0/1/0/all/0/1\">Ivan Montero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Longpre_S/0/1/0/all/0/1\">Shayne Longpre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lao_N/0/1/0/all/0/1\">Ni Lao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frank_A/0/1/0/all/0/1\">Andrew J. Frank</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DuBois_C/0/1/0/all/0/1\">Christopher DuBois</a>",
          "description": "Existing methods for open-retrieval question answering in lower resource\nlanguages (LRLs) lag significantly behind English. They not only suffer from\nthe shortcomings of non-English document retrieval, but are reliant on\nlanguage-specific supervision for either the task or translation. We formulate\na task setup more realistic to available resources, that circumvents document\nretrieval to reliably transfer knowledge from English to lower resource\nlanguages. Assuming a strong English question answering model or database, we\ncompare and analyze methods that pivot through English: to map foreign queries\nto English and then English answers back to target language answers. Within\nthis task setup we propose Reranked Multilingual Maximal Inner Product Search\n(RM-MIPS), akin to semantic similarity retrieval over the English training set\nwith reranking, which outperforms the strongest baselines by 2.7% on XQuAD and\n6.2% on MKQA. Analysis demonstrates the particular efficacy of this strategy\nover state-of-the-art alternatives in challenging settings: low-resource\nlanguages, with extensive distractor data and query distribution misalignment.\nCircumventing retrieval, our analysis shows this approach offers rapid answer\ngeneration to almost any language off-the-shelf, without the need for any\nadditional training data in the target language.",
          "link": "http://arxiv.org/abs/2012.14094",
          "publishedOn": "2021-07-19T00:49:05.908Z",
          "wordCount": 651,
          "title": "Pivot Through English: Reliably Answering Multilingual Questions without Document Retrieval. (arXiv:2012.14094v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.00419",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xing_Y/0/1/0/all/0/1\">Yiran Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1\">Zai Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Z/0/1/0/all/0/1\">Zhao Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lakemeyer_G/0/1/0/all/0/1\">Gerhard Lakemeyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yunpu Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wattenhofer_R/0/1/0/all/0/1\">Roger Wattenhofer</a>",
          "description": "We present Knowledge Enhanced Multimodal BART (KM-BART), which is a\nTransformer-based sequence-to-sequence model capable of reasoning about\ncommonsense knowledge from multimodal inputs of images and texts. We adapt the\ngenerative BART architecture to a multimodal model with visual and textual\ninputs. We further develop novel pretraining tasks to improve the model\nperformance on the Visual Commonsense Generation (VCG) task. In particular, our\npretraining task of Knowledge-based Commonsense Generation (KCG) boosts model\nperformance on the VCG task by leveraging commonsense knowledge from a large\nlanguage model pretrained on external commonsense knowledge graphs. To the best\nof our knowledge, we are the first to propose a dedicated task for improving\nmodel performance on the VCG task. Experimental results show that our model\nreaches state-of-the-art performance on the VCG task by applying these novel\npretraining tasks.",
          "link": "http://arxiv.org/abs/2101.00419",
          "publishedOn": "2021-07-19T00:49:05.844Z",
          "wordCount": 612,
          "title": "KM-BART: Knowledge Enhanced Multimodal BART for Visual Commonsense Generation. (arXiv:2101.00419v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.11524",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Likhomanenko_T/0/1/0/all/0/1\">Tatiana Likhomanenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1\">Qiantong Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kahn_J/0/1/0/all/0/1\">Jacob Kahn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Synnaeve_G/0/1/0/all/0/1\">Gabriel Synnaeve</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Collobert_R/0/1/0/all/0/1\">Ronan Collobert</a>",
          "description": "Recent results in end-to-end automatic speech recognition have demonstrated\nthe efficacy of pseudo-labeling for semi-supervised models trained both with\nConnectionist Temporal Classification (CTC) and Sequence-to-Sequence (seq2seq)\nlosses. Iterative Pseudo-Labeling (IPL), which continuously trains a single\nmodel using pseudo-labels iteratively re-generated as the model learns, has\nbeen shown to further improve performance in ASR. We improve upon the IPL\nalgorithm: as the model learns, we propose to iteratively re-generate\ntranscriptions with hard labels (the most probable tokens), that is, without a\nlanguage model. We call this approach Language-Model-Free IPL (slimIPL) and\ngive a resultant training setup for low-resource settings with CTC-based\nmodels. slimIPL features a dynamic cache for pseudo-labels which reduces\nsensitivity to changes in relabeling hyperparameters and results in improves\ntraining stability. slimIPL is also highly-efficient and requires 3.5-4x fewer\ncomputational resources to converge than other state-of-the-art\nsemi/self-supervised approaches. With only 10 hours of labeled audio, slimIPL\nis competitive with self-supervised approaches, and is state-of-the-art with\n100 hours of labeled audio without the use of a language model both at test\ntime and during pseudo-label generation.",
          "link": "http://arxiv.org/abs/2010.11524",
          "publishedOn": "2021-07-19T00:49:05.837Z",
          "wordCount": 654,
          "title": "SlimIPL: Language-Model-Free Iterative Pseudo-Labeling. (arXiv:2010.11524v4 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.11410",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Field_A/0/1/0/all/0/1\">Anjalie Field</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blodgett_S/0/1/0/all/0/1\">Su Lin Blodgett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Waseem_Z/0/1/0/all/0/1\">Zeerak Waseem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsvetkov_Y/0/1/0/all/0/1\">Yulia Tsvetkov</a>",
          "description": "Despite inextricable ties between race and language, little work has\nconsidered race in NLP research and development. In this work, we survey 79\npapers from the ACL anthology that mention race. These papers reveal various\ntypes of race-related bias in all stages of NLP model development, highlighting\nthe need for proactive consideration of how NLP systems can uphold racial\nhierarchies. However, persistent gaps in research on race and NLP remain: race\nhas been siloed as a niche topic and remains ignored in many NLP tasks; most\nwork operationalizes race as a fixed single-dimensional variable with a\nground-truth label, which risks reinforcing differences produced by historical\nracism; and the voices of historically marginalized people are nearly absent in\nNLP literature. By identifying where and how NLP literature has and has not\nconsidered race, especially in comparison to related fields, our work calls for\ninclusion and racial justice in NLP research practices.",
          "link": "http://arxiv.org/abs/2106.11410",
          "publishedOn": "2021-07-19T00:49:05.830Z",
          "wordCount": 620,
          "title": "A Survey of Race, Racism, and Anti-Racism in NLP. (arXiv:2106.11410v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.07958",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hao_Y/0/1/0/all/0/1\">Yang Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_X/0/1/0/all/0/1\">Xiao Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_W/0/1/0/all/0/1\">Wenbiao Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zitao Liu</a>",
          "description": "Learning effective language representations from crowdsourced labels is\ncrucial for many real-world machine learning tasks. A challenging aspect of\nthis problem is that the quality of crowdsourced labels suffer high intra- and\ninter-observer variability. Since the high-capacity deep neural networks can\neasily memorize all disagreements among crowdsourced labels, directly applying\nexisting supervised language representation learning algorithms may yield\nsuboptimal solutions. In this paper, we propose \\emph{TACMA}, a\n\\underline{t}emporal-\\underline{a}ware language representation learning\nheuristic for \\underline{c}rowdsourced labels with \\underline{m}ultiple\n\\underline{a}nnotators. The proposed approach (1) explicitly models the\nintra-observer variability with attention mechanism; (2) computes and\naggregates per-sample confidence scores from multiple workers to address the\ninter-observer disagreements. The proposed heuristic is extremely easy to\nimplement in around 5 lines of code. The proposed heuristic is evaluated on\nfour synthetic and four real-world data sets. The results show that our\napproach outperforms a wide range of state-of-the-art baselines in terms of\nprediction accuracy and AUC. To encourage the reproducible results, we make our\ncode publicly available at \\url{https://github.com/CrowdsourcingMining/TACMA}.",
          "link": "http://arxiv.org/abs/2107.07958",
          "publishedOn": "2021-07-19T00:49:05.801Z",
          "wordCount": 621,
          "title": "Temporal-aware Language Representation Learning From Crowdsourced Labels. (arXiv:2107.07958v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07974",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Heeringa_W/0/1/0/all/0/1\">Wilbert Heeringa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bouma_G/0/1/0/all/0/1\">Gosse Bouma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hofman_M/0/1/0/all/0/1\">Martha Hofman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drenth_E/0/1/0/all/0/1\">Eduard Drenth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wijffels_J/0/1/0/all/0/1\">Jan Wijffels</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Velde_H/0/1/0/all/0/1\">Hans Van de Velde</a>",
          "description": "We present a lemmatizer/POS-tagger/dependency parser for West Frisian using a\ncorpus of 44,714 words in 3,126 sentences that were annotated according to the\nguidelines of Universal Dependency version 2. POS tags were assigned to words\nby using a Dutch POS tagger that was applied to a literal word-by-word\ntranslation, or to sentences of a Dutch parallel text. Best results were\nobtained when using literal translations that were created by using the Frisian\ntranslation program Oersetter. Morphologic and syntactic annotations were\ngenerated on the basis of a literal Dutch translation as well. The performance\nof the lemmatizer/tagger/annotator when it was trained using default parameters\nwas compared to the performance that was obtained when using the parameter\nvalues that were used for training the LassySmall UD 2.5 corpus. A significant\nimprovement was found for `lemma'. The Frisian lemmatizer/PoS tagger/dependency\nparser is released as a web app and as a web service.",
          "link": "http://arxiv.org/abs/2107.07974",
          "publishedOn": "2021-07-19T00:49:05.794Z",
          "wordCount": 606,
          "title": "POS tagging, lemmatization and dependency parsing of West Frisian. (arXiv:2107.07974v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07771",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yajing Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yue Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_L/0/1/0/all/0/1\">Luxi Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yuqiang Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1\">Xiangpeng Wei</a>",
          "description": "End-to-End intelligent neural dialogue systems suffer from the problems of\ngenerating inconsistent and repetitive responses. Existing dialogue models pay\nattention to unilaterally incorporating personal knowledge into the dialog\nwhile ignoring the fact that incorporating the personality-related conversation\ninformation into personal knowledge taken as the bilateral information flow\nboosts the quality of the subsequent conversation. Besides, it is indispensable\nto control personal knowledge utilization over the conversation level. In this\npaper, we propose a conversation-adaption multi-view persona aware response\ngeneration model that aims at enhancing conversation consistency and\nalleviating the repetition from two folds. First, we consider conversation\nconsistency from multiple views. From the view of the persona profile, we\ndesign a novel interaction module that not only iteratively incorporates\npersonalized knowledge into each turn conversation but also captures the\npersonality-related information from conversation to enhance personalized\nknowledge semantic representation. From the view of speaking style, we\nintroduce the speaking style vector and feed it into the decoder to keep the\nspeaking style consistency. To avoid conversation repetition, we devise a\ncoverage mechanism to keep track of the activation of personal knowledge\nutilization. Experiments on both automatic and human evaluation verify the\nsuperiority of our model over previous models.",
          "link": "http://arxiv.org/abs/2107.07771",
          "publishedOn": "2021-07-19T00:49:05.774Z",
          "wordCount": 639,
          "title": "Know Deeper: Knowledge-Conversation Cyclic Utilization Mechanism for Open-domain Dialogue Generation. (arXiv:2107.07771v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07970",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Koenders_C/0/1/0/all/0/1\">Camille Koenders</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Filla_J/0/1/0/all/0/1\">Johannes Filla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schneider_N/0/1/0/all/0/1\">Nicolai Schneider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woloszyn_V/0/1/0/all/0/1\">Vinicius Woloszyn</a>",
          "description": "As the spread of false information on the internet has increased dramatically\nin recent years, more and more attention is being paid to automated fake news\ndetection. Some fake news detection methods are already quite successful.\nNevertheless, there are still many vulnerabilities in the detection algorithms.\nThe reason for this is that fake news publishers can structure and formulate\ntheir texts in such a way that a detection algorithm does not expose this text\nas fake news. This paper shows that it is possible to automatically attack\nstate-of-the-art models that have been trained to detect Fake News, making\nthese vulnerable. For this purpose, corresponding models were first trained\nbased on a dataset. Then, using Text-Attack, an attempt was made to manipulate\nthe trained models in such a way that previously correctly identified fake news\nwas classified as true news. The results show that it is possible to\nautomatically bypass Fake News detection mechanisms, leading to implications\nconcerning existing policy initiatives.",
          "link": "http://arxiv.org/abs/2107.07970",
          "publishedOn": "2021-07-19T00:49:05.715Z",
          "wordCount": 604,
          "title": "How Vulnerable Are Automatic Fake News Detection Methods to Adversarial Attacks?. (arXiv:2107.07970v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07940",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Pengju Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1\">Yonghui Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1\">Muhua Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wenliang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Min Zhang</a>",
          "description": "Recent studies on Knowledge Base Question Answering (KBQA) have shown great\nprogress on this task via better question understanding. Previous works for\nencoding questions mainly focus on the word sequences, but seldom consider the\ninformation from syntactic trees.In this paper, we propose an approach to learn\nsyntax-based representations for KBQA. First, we encode path-based syntax by\nconsidering the shortest dependency paths between keywords. Then, we propose\ntwo encoding strategies to mode the information of whole syntactic trees to\nobtain tree-based syntax. Finally, we combine both path-based and tree-based\nsyntax representations for KBQA. We conduct extensive experiments on a widely\nused benchmark dataset and the experimental results show that our syntax-aware\nsystems can make full use of syntax information in different settings and\nachieve state-of-the-art performance of KBQA.",
          "link": "http://arxiv.org/abs/2107.07940",
          "publishedOn": "2021-07-19T00:49:05.695Z",
          "wordCount": 565,
          "title": "Exploiting Rich Syntax for Better Knowledge Base Question Answering. (arXiv:2107.07940v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07705",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ruan_Q/0/1/0/all/0/1\">Qin Ruan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Namee_B/0/1/0/all/0/1\">Brian Mac Namee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_R/0/1/0/all/0/1\">Ruihai Dong</a>",
          "description": "Leveraging unlabelled data through weak or distant supervision is a\ncompelling approach to developing more effective text classification models.\nThis paper proposes a simple but effective data augmentation method, which\nleverages the idea of pseudo-labelling to select samples from noisy distant\nsupervision annotation datasets. The result shows that the proposed method\nimproves the accuracy of biased news detection models.",
          "link": "http://arxiv.org/abs/2107.07705",
          "publishedOn": "2021-07-19T00:49:05.680Z",
          "wordCount": 491,
          "title": "Pseudo-labelling Enhanced Media Bias Detection. (arXiv:2107.07705v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07002",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dehghani_M/0/1/0/all/0/1\">Mostafa Dehghani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tay_Y/0/1/0/all/0/1\">Yi Tay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gritsenko_A/0/1/0/all/0/1\">Alexey A. Gritsenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1\">Zhe Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Houlsby_N/0/1/0/all/0/1\">Neil Houlsby</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diaz_F/0/1/0/all/0/1\">Fernando Diaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Metzler_D/0/1/0/all/0/1\">Donald Metzler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vinyals_O/0/1/0/all/0/1\">Oriol Vinyals</a>",
          "description": "The world of empirical machine learning (ML) strongly relies on benchmarks in\norder to determine the relative effectiveness of different algorithms and\nmethods. This paper proposes the notion of \"a benchmark lottery\" that describes\nthe overall fragility of the ML benchmarking process. The benchmark lottery\npostulates that many factors, other than fundamental algorithmic superiority,\nmay lead to a method being perceived as superior. On multiple benchmark setups\nthat are prevalent in the ML community, we show that the relative performance\nof algorithms may be altered significantly simply by choosing different\nbenchmark tasks, highlighting the fragility of the current paradigms and\npotential fallacious interpretation derived from benchmarking ML methods. Given\nthat every benchmark makes a statement about what it perceives to be important,\nwe argue that this might lead to biased progress in the community. We discuss\nthe implications of the observed phenomena and provide recommendations on\nmitigating them using multiple machine learning domains and communities as use\ncases, including natural language processing, computer vision, information\nretrieval, recommender systems, and reinforcement learning.",
          "link": "http://arxiv.org/abs/2107.07002",
          "publishedOn": "2021-07-19T00:49:05.656Z",
          "wordCount": 620,
          "title": "The Benchmark Lottery. (arXiv:2107.07002v1 [cs.LG] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.07903",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Armengol_Estape_J/0/1/0/all/0/1\">Jordi Armengol-Estap&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carrino_C/0/1/0/all/0/1\">Casimiro Pio Carrino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_Penagos_C/0/1/0/all/0/1\">Carlos Rodriguez-Penagos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bonet_O/0/1/0/all/0/1\">Ona de Gibert Bonet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Armentano_Oller_C/0/1/0/all/0/1\">Carme Armentano-Oller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_Agirre_A/0/1/0/all/0/1\">Aitor Gonzalez-Agirre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Melero_M/0/1/0/all/0/1\">Maite Melero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Villegas_M/0/1/0/all/0/1\">Marta Villegas</a>",
          "description": "Multilingual language models have been a crucial breakthrough as they\nconsiderably reduce the need of data for under-resourced languages.\nNevertheless, the superiority of language-specific models has already been\nproven for languages having access to large amounts of data. In this work, we\nfocus on Catalan with the aim to explore to what extent a medium-sized\nmonolingual language model is competitive with state-of-the-art large\nmultilingual models. For this, we: (1) build a clean, high-quality textual\nCatalan corpus (CaText), the largest to date (but only a fraction of the usual\nsize of the previous work in monolingual language models), (2) train a\nTransformer-based language model for Catalan (BERTa), and (3) devise a thorough\nevaluation in a diversity of settings, comprising a complete array of\ndownstream tasks, namely, Part of Speech Tagging, Named Entity Recognition and\nClassification, Text Classification, Question Answering, and Semantic Textual\nSimilarity, with most of the corresponding datasets being created ex novo. The\nresult is a new benchmark, the Catalan Language Understanding Benchmark (CLUB),\nwhich we publish as an open resource, together with the clean textual corpus,\nthe language model, and the cleaning pipeline. Using state-of-the-art\nmultilingual models and a monolingual model trained only on Wikipedia as\nbaselines, we consistently observe the superiority of our model across tasks\nand settings.",
          "link": "http://arxiv.org/abs/2107.07903",
          "publishedOn": "2021-07-19T00:49:05.605Z",
          "wordCount": 674,
          "title": "Are Multilingual Models the Best Choice for Moderately Under-resourced Languages? A Comprehensive Assessment for Catalan. (arXiv:2107.07903v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2005.02721",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gelderloos_L/0/1/0/all/0/1\">Lieke Gelderloos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chrupala_G/0/1/0/all/0/1\">Grzegorz Chrupa&#x142;a</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alishahi_A/0/1/0/all/0/1\">Afra Alishahi</a>",
          "description": "Speech directed to children differs from adult-directed speech in linguistic\naspects such as repetition, word choice, and sentence length, as well as in\naspects of the speech signal itself, such as prosodic and phonemic variation.\nHuman language acquisition research indicates that child-directed speech helps\nlanguage learners. This study explores the effect of child-directed speech when\nlearning to extract semantic information from speech directly. We compare the\ntask performance of models trained on adult-directed speech (ADS) and\nchild-directed speech (CDS). We find indications that CDS helps in the initial\nstages of learning, but eventually, models trained on ADS reach comparable task\nperformance, and generalize better. The results suggest that this is at least\npartially due to linguistic rather than acoustic properties of the two\nregisters, as we see the same pattern when looking at models trained on\nacoustically comparable synthetic speech.",
          "link": "http://arxiv.org/abs/2005.02721",
          "publishedOn": "2021-07-19T00:49:05.581Z",
          "wordCount": 671,
          "title": "Learning to Understand Child-directed and Adult-directed Speech. (arXiv:2005.02721v4 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.07956",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_Y/0/1/0/all/0/1\">Yu Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_Y/0/1/0/all/0/1\">Yang Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_W/0/1/0/all/0/1\">Wenbiao Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhongqin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zitao Liu</a>",
          "description": "The quality of vocal delivery is one of the key indicators for evaluating\nteacher enthusiasm, which has been widely accepted to be connected to the\noverall course qualities. However, existing evaluation for vocal delivery is\nmainly conducted with manual ratings, which faces two core challenges:\nsubjectivity and time-consuming. In this paper, we present a novel machine\nlearning approach that utilizes pairwise comparisons and a multimodal\northogonal fusing algorithm to generate large-scale objective evaluation\nresults of the teacher vocal delivery in terms of fluency and passion. We\ncollect two datasets from real-world education scenarios and the experiment\nresults demonstrate the effectiveness of our algorithm. To encourage\nreproducible results, we make our code public available at\n\\url{https://github.com/tal-ai/ML4VocalDelivery.git}.",
          "link": "http://arxiv.org/abs/2107.07956",
          "publishedOn": "2021-07-19T00:49:05.566Z",
          "wordCount": 577,
          "title": "A Multimodal Machine Learning Framework for Teacher Vocal Delivery Evaluation. (arXiv:2107.07956v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07957",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shiting Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_G/0/1/0/all/0/1\">Guowei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_P/0/1/0/all/0/1\">Peilei Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_W/0/1/0/all/0/1\">Wenbiao Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhongqin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zitao Liu</a>",
          "description": "Task requirements (TRs) writing is an important question type in Key English\nTest and Preliminary English Test. A TR writing question may include multiple\nrequirements and a high-quality essay must respond to each requirement\nthoroughly and accurately. However, the limited teacher resources prevent\nstudents from getting detailed grading instantly. The majority of existing\nautomatic essay scoring systems focus on giving a holistic score but rarely\nprovide reasons to support it. In this paper, we proposed an end-to-end\nframework based on machine reading comprehension (MRC) to address this problem\nto some extent. The framework not only detects whether an essay responds to a\nrequirement question, but clearly marks where the essay answers the question.\nOur framework consists of three modules: question normalization module, ELECTRA\nbased MRC module and response locating module. We extensively explore\nstate-of-the-art MRC methods. Our approach achieves 0.93 accuracy score and\n0.85 F1 score on a real-world educational dataset. To encourage reproducible\nresults, we make our code publicly available at\n\\url{https://github.com/aied2021TRMRC/AIED_2021_TRMRC_code}.",
          "link": "http://arxiv.org/abs/2107.07957",
          "publishedOn": "2021-07-19T00:49:05.545Z",
          "wordCount": 619,
          "title": "Automatic Task Requirements Writing Evaluation via Machine Reading Comprehension. (arXiv:2107.07957v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07682",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yukun Jiang</a>",
          "description": "Active learning is a state-of-art machine learning approach to deal with an\nabundance of unlabeled data. In the field of Natural Language Processing,\ntypically it is costly and time-consuming to have all the data annotated. This\ninefficiency inspires out our application of active learning in text\nclassification. Traditional unsupervised k-means clustering is first modified\ninto a semi-supervised version in this research. Then, a novel attempt is\napplied to further extend the algorithm into active learning scenario with\nPenalized Min-Max-selection, so as to make limited queries that yield more\nstable initial centroids. This method utilizes both the interactive query\nresults from users and the underlying distance representation. After tested on\na Chinese news dataset, it shows a consistent increase in accuracy while\nlowering the cost in training.",
          "link": "http://arxiv.org/abs/2107.07682",
          "publishedOn": "2021-07-19T00:49:05.525Z",
          "wordCount": 600,
          "title": "The Application of Active Query K-Means in Text Classification. (arXiv:2107.07682v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07691",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Magee_L/0/1/0/all/0/1\">Liam Magee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghahremanlou_L/0/1/0/all/0/1\">Lida Ghahremanlou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soldatic_K/0/1/0/all/0/1\">Karen Soldatic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Robertson_S/0/1/0/all/0/1\">Shanthi Robertson</a>",
          "description": "To examine whether intersectional bias can be observed in language\ngeneration, we examine \\emph{GPT-2} and \\emph{GPT-NEO} models, ranging in size\nfrom 124 million to ~2.7 billion parameters. We conduct an experiment combining\nup to three social categories - gender, religion and disability - into\nunconditional or zero-shot prompts used to generate sentences that are then\nanalysed for sentiment. Our results confirm earlier tests conducted with\nauto-regressive causal models, including the \\emph{GPT} family of models. We\nalso illustrate why bias may be resistant to techniques that target single\ncategories (e.g. gender, religion and race), as it can also manifest, in often\nsubtle ways, in texts prompted by concatenated social categories. To address\nthese difficulties, we suggest technical and community-based approaches need to\ncombine to acknowledge and address complex and intersectional language model\nbias.",
          "link": "http://arxiv.org/abs/2107.07691",
          "publishedOn": "2021-07-19T00:49:05.500Z",
          "wordCount": 568,
          "title": "Intersectional Bias in Causal Language Models. (arXiv:2107.07691v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07634",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Higuchi_T/0/1/0/all/0/1\">Takuya Higuchi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gupta_A/0/1/0/all/0/1\">Anmol Gupta</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dhir_C/0/1/0/all/0/1\">Chandra Dhir</a>",
          "description": "Keyword spotting (KWS) is an important technique for speech applications,\nwhich enables users to activate devices by speaking a keyword phrase. Although\na phoneme classifier can be used for KWS, exploiting a large amount of\ntranscribed data for automatic speech recognition (ASR), there is a mismatch\nbetween the training criterion (phoneme recognition) and the target task (KWS).\nRecently, multi-task learning has been applied to KWS to exploit both ASR and\nKWS training data. In this approach, an output of an acoustic model is split\ninto two branches for the two tasks, one for phoneme transcription trained with\nthe ASR data and one for keyword classification trained with the KWS data. In\nthis paper, we introduce a cross attention decoder in the multi-task learning\nframework. Unlike the conventional multi-task learning approach with the simple\nsplit of the output layer, the cross attention decoder summarizes information\nfrom a phonetic encoder by performing cross attention between the encoder\noutputs and a trainable query sequence to predict a confidence score for the\nKWS task. Experimental results on KWS tasks show that the proposed approach\noutperformed the conventional multi-task learning with split branches and a\nbi-directional long short-team memory decoder by 12% on average.",
          "link": "http://arxiv.org/abs/2107.07634",
          "publishedOn": "2021-07-19T00:49:05.441Z",
          "wordCount": 652,
          "title": "Multi-task Learning with Cross Attention for Keyword Spotting. (arXiv:2107.07634v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07567",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jing Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szlam_A/0/1/0/all/0/1\">Arthur Szlam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weston_J/0/1/0/all/0/1\">Jason Weston</a>",
          "description": "Despite recent improvements in open-domain dialogue models, state of the art\nmodels are trained and evaluated on short conversations with little context. In\ncontrast, the long-term conversation setting has hardly been studied. In this\nwork we collect and release a human-human dataset consisting of multiple chat\nsessions whereby the speaking partners learn about each other's interests and\ndiscuss the things they have learnt from past sessions. We show how existing\nmodels trained on existing datasets perform poorly in this long-term\nconversation setting in both automatic and human evaluations, and we study\nlong-context models that can perform much better. In particular, we find\nretrieval-augmented methods and methods with an ability to summarize and recall\nprevious conversations outperform the standard encoder-decoder architectures\ncurrently considered state of the art.",
          "link": "http://arxiv.org/abs/2107.07567",
          "publishedOn": "2021-07-19T00:49:05.430Z",
          "wordCount": 556,
          "title": "Beyond Goldfish Memory: Long-Term Open-Domain Conversation. (arXiv:2107.07567v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07610",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meng_Z/0/1/0/all/0/1\">Zhao Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1\">Yihan Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sachan_M/0/1/0/all/0/1\">Mrinmaya Sachan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wattenhofer_R/0/1/0/all/0/1\">Roger Wattenhofer</a>",
          "description": "This paper improves the robustness of the pretrained language model BERT\nagainst word substitution-based adversarial attacks by leveraging\nself-supervised contrastive learning with adversarial perturbations. One\nadvantage of our method compared to previous works is that it is capable of\nimproving model robustness without using any labels. Additionally, we also\ncreate an adversarial attack for word-level adversarial training on BERT. The\nattack is efficient, allowing adversarial training for BERT on adversarial\nexamples generated on the fly during training. Experimental results on four\ndatasets show that our method improves the robustness of BERT against four\ndifferent word substitution-based adversarial attacks. Furthermore, to\nunderstand why our method can improve the model robustness against adversarial\nattacks, we study vector representations of clean examples and their\ncorresponding adversarial examples before and after applying our method. As our\nmethod improves model robustness with unlabeled raw data, it opens up the\npossibility of using large text datasets to train robust language models.",
          "link": "http://arxiv.org/abs/2107.07610",
          "publishedOn": "2021-07-19T00:49:05.402Z",
          "wordCount": 596,
          "title": "Self-Supervised Contrastive Learning with Adversarial Perturbations for Robust Pretrained Language Models. (arXiv:2107.07610v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07653",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qian Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Bei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1\">Jiaqi Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zeqi Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lou_J/0/1/0/all/0/1\">Jian-guang Lou</a>",
          "description": "Recent years pre-trained language models hit a success on modeling natural\nlanguage sentences and (semi-)structured tables. However, existing table\npre-training techniques always suffer from low data quality and low\npre-training efficiency. In this paper, we show that table pre-training can be\nrealized by learning a neural SQL executor over a synthetic corpus, which is\nobtained by automatically synthesizing executable SQL queries. By pre-training\non the synthetic corpus, our approach TAPEX dramatically improves the\nperformance on downstream tasks, boosting existing language models by at most\n19.5%. Meanwhile, TAPEX has remarkably high pre-training efficiency and yields\nstrong results when using a small pre-trained corpus. Experimental results\ndemonstrate that TAPEX outperforms previous table pre-training approaches by a\nlarge margin, and our model achieves new state-of-the-art results on four\nwell-known datasets, including improving the WikiSQL denotation accuracy to\n89.6% (+4.9%), the WikiTableQuestions denotation accuracy to 57.5% (+4.8%), the\nSQA denotation accuracy to 74.5% (+3.5%), and the TabFact accuracy to 84.6%\n(+3.6%). Our work opens the way to reason over structured data by pre-training\non synthetic executable programs.",
          "link": "http://arxiv.org/abs/2107.07653",
          "publishedOn": "2021-07-19T00:49:05.328Z",
          "wordCount": 624,
          "title": "TAPEX: Table Pre-training via Learning a Neural SQL Executor. (arXiv:2107.07653v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07566",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Komeili_M/0/1/0/all/0/1\">Mojtaba Komeili</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shuster_K/0/1/0/all/0/1\">Kurt Shuster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weston_J/0/1/0/all/0/1\">Jason Weston</a>",
          "description": "The largest store of continually updating knowledge on our planet can be\naccessed via internet search. In this work we study giving access to this\ninformation to conversational agents. Large language models, even though they\nstore an impressive amount of knowledge within their weights, are known to\nhallucinate facts when generating dialogue (Shuster et al., 2021); moreover,\nthose facts are frozen in time at the point of model training. In contrast, we\npropose an approach that learns to generate an internet search query based on\nthe context, and then conditions on the search results to finally generate a\nresponse, a method that can employ up-to-the-minute relevant information. We\ntrain and evaluate such models on a newly collected dataset of human-human\nconversations whereby one of the speakers is given access to internet search\nduring knowledgedriven discussions in order to ground their responses. We find\nthat search-query based access of the internet in conversation provides\nsuperior performance compared to existing approaches that either use no\naugmentation or FAISS-based retrieval (Lewis et al., 2020).",
          "link": "http://arxiv.org/abs/2107.07566",
          "publishedOn": "2021-07-19T00:49:05.279Z",
          "wordCount": 594,
          "title": "Internet-Augmented Dialogue Generation. (arXiv:2107.07566v1 [cs.AI])"
        }
      ]
    },
    {
      "title": "cs.IR updates on arXiv.org",
      "feedUrl": "http://export.arxiv.org/rss/cs.IR",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2104.09036",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jinghao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yanqiao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qiang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuhui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Liang Wang</a>",
          "description": "Multimedia content is of predominance in the modern Web era. Investigating\nhow users interact with multimodal items is a continuing concern within the\nrapid development of recommender systems. The majority of previous work focuses\non modeling user-item interactions with multimodal features included as side\ninformation. However, this scheme is not well-designed for multimedia\nrecommendation. Specifically, only collaborative item-item relationships are\nimplicitly modeled through high-order item-user-item relations. Considering\nthat items are associated with rich contents in multiple modalities, we argue\nthat the latent semantic item-item structures underlying these multimodal\ncontents could be beneficial for learning better item representations and\nfurther boosting recommendation. To this end, we propose a LATent sTructure\nmining method for multImodal reCommEndation, which we term LATTICE for brevity.\nTo be specific, in the proposed LATTICE model, we devise a novel modality-aware\nstructure learning layer, which learns item-item structures for each modality\nand aggregates multiple modalities to obtain latent item graphs. Based on the\nlearned latent graphs, we perform graph convolutions to explicitly inject\nhigh-order item affinities into item representations. These enriched item\nrepresentations can then be plugged into existing collaborative filtering\nmethods to make more accurate recommendations. Extensive experiments on three\nreal-world datasets demonstrate the superiority of our method over\nstate-of-the-art multimedia recommendation methods and validate the efficacy of\nmining latent item-item relationships from multimodal features.",
          "link": "http://arxiv.org/abs/2104.09036",
          "publishedOn": "2021-07-22T02:03:10.377Z",
          "wordCount": 695,
          "title": "Mining Latent Structures for Multimedia Recommendation. (arXiv:2104.09036v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09829",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yunqi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hanxiong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shuyuan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1\">Yingqiang Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongfeng Zhang</a>",
          "description": "Recommender systems are gaining increasing and critical impacts on human and\nsociety since a growing number of users use them for information seeking and\ndecision making. Therefore, it is crucial to address the potential unfairness\nproblems in recommendations. Just like users have personalized preferences on\nitems, users' demands for fairness are also personalized in many scenarios.\nTherefore, it is important to provide personalized fair recommendations for\nusers to satisfy their personalized fairness demands. Besides, previous works\non fair recommendation mainly focus on association-based fairness. However, it\nis important to advance from associative fairness notions to causal fairness\nnotions for assessing fairness more properly in recommender systems. Based on\nthe above considerations, this paper focuses on achieving personalized\ncounterfactual fairness for users in recommender systems. To this end, we\nintroduce a framework for achieving counterfactually fair recommendations\nthrough adversary learning by generating feature-independent user embeddings\nfor recommendation. The framework allows recommender systems to achieve\npersonalized fairness for users while also covering non-personalized\nsituations. Experiments on two real-world datasets with shallow and deep\nrecommendation algorithms show that our method can generate fairer\nrecommendations for users with a desirable recommendation performance.",
          "link": "http://arxiv.org/abs/2105.09829",
          "publishedOn": "2021-07-22T02:03:10.199Z",
          "wordCount": 659,
          "title": "Personalized Counterfactual Fairness in Recommendation. (arXiv:2105.09829v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.09980",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fischbach_J/0/1/0/all/0/1\">Jannik Fischbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Springer_T/0/1/0/all/0/1\">Tobias Springer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frattini_J/0/1/0/all/0/1\">Julian Frattini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Femmer_H/0/1/0/all/0/1\">Henning Femmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogelsang_A/0/1/0/all/0/1\">Andreas Vogelsang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mendez_D/0/1/0/all/0/1\">Daniel Mendez</a>",
          "description": "[Context:] Causal relations (e.g., If A, then B) are prevalent in functional\nrequirements. For various applications of AI4RE, e.g., the automatic derivation\nof suitable test cases from requirements, automatically extracting such causal\nstatements are a basic necessity. [Problem:] We lack an approach that is able\nto extract causal relations from natural language requirements in fine-grained\nform. Specifically, existing approaches do not consider the combinatorics\nbetween causes and effects. They also do not allow to split causes and effects\ninto more granular text fragments (e.g., variable and condition), making the\nextracted relations unsuitable for automatic test case derivation. [Objective &\nContributions:] We address this research gap and make the following\ncontributions: First, we present the Causality Treebank, which is the first\ncorpus of fully labeled binary parse trees representing the composition of\n1,571 causal requirements. Second, we propose a fine-grained causality\nextractor based on Recursive Neural Tensor Networks. Our approach is capable of\nrecovering the composition of causal statements written in natural language and\nachieves a F1 score of 74 % in the evaluation on the Causality Treebank. Third,\nwe disclose our open data sets as well as our code to foster the discourse on\nthe automatic extraction of causality in the RE community.",
          "link": "http://arxiv.org/abs/2107.09980",
          "publishedOn": "2021-07-22T02:03:10.035Z",
          "wordCount": 651,
          "title": "Fine-Grained Causality Extraction From Natural Language Requirements Using Recursive Neural Tensor Networks. (arXiv:2107.09980v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.10023",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jadallah_N/0/1/0/all/0/1\">Noah Jadallah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fischbach_J/0/1/0/all/0/1\">Jannik Fischbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frattini_J/0/1/0/all/0/1\">Julian Frattini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogelsang_A/0/1/0/all/0/1\">Andreas Vogelsang</a>",
          "description": "Causal relations (If A, then B) are prevalent in requirements artifacts.\nAutomatically extracting causal relations from requirements holds great\npotential for various RE activities (e.g., automatic derivation of suitable\ntest cases). However, we lack an approach capable of extracting causal\nrelations from natural language with reasonable performance. In this paper, we\npresent our tool CATE (CAusality Tree Extractor), which is able to parse the\ncomposition of a causal relation as a tree structure. CATE does not only\nprovide an overview of causes and effects in a sentence, but also reveals their\nsemantic coherence by translating the causal relation into a binary tree. We\nencourage fellow researchers and practitioners to use CATE at\nhttps://causalitytreeextractor.com/",
          "link": "http://arxiv.org/abs/2107.10023",
          "publishedOn": "2021-07-22T02:03:09.971Z",
          "wordCount": 551,
          "title": "CATE: CAusality Tree Extractor from Natural Language Requirements. (arXiv:2107.10023v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09966",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jarwar_M/0/1/0/all/0/1\">Muhammad Aslam Jarwar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chapman_A/0/1/0/all/0/1\">Adriane Chapman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elliot_M/0/1/0/all/0/1\">Mark Elliot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raji_F/0/1/0/all/0/1\">Fatemeh Raji</a>",
          "description": "The Anonymisation Decision-making Framework (ADF) operationalizes the risk\nmanagement of data exchange between organizations, referred to as \"data\nenvironments\". The second edition of ADF has increased its emphasis on modeling\ndata flows, highlighting a potential new use of provenance information to\nsupport anonymisation decision-making. In this paper, we provide a use case\nthat showcases this functionality more. Based on this use case, we identify how\nprovenance information could be utilized within the ADF framework, and identify\na currently un-met requirement which is the modeling of \\textit{data\nenvironments}. We show how data environments can be implemented within the W3C\nPROV in four different ways. We analyze the costs and benefits of each\napproach, and consider another use case as a partial check for completeness. We\nthen summarize our findings and suggest ways forward.",
          "link": "http://arxiv.org/abs/2107.09966",
          "publishedOn": "2021-07-22T02:03:09.935Z",
          "wordCount": 566,
          "title": "Provenance, Anonymisation and Data Environments: a Unifying Construction. (arXiv:2107.09966v1 [cs.DB])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09558",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tran_H/0/1/0/all/0/1\">Hieu Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_S/0/1/0/all/0/1\">Son Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yen_I/0/1/0/all/0/1\">I-Ling Yen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bastani_F/0/1/0/all/0/1\">Farokh Bastani</a>",
          "description": "In this paper, we consider the IoT data discovery data objects to specific\nnodes in the network. They are very problem in very large and growing scale\nnetworks. Specifically, we investigate in depth the routing table summarization\ntechniques to support effective and space-efficient IoT data discovery routing.\nNovel summarization algorithms, including alphabetical based, hash based, and\nmeaning based summarization and their corresponding coding schemes are\nproposed. The issue of potentially misleading routing due to summarization is\nalso investigated. Subsequently, we analyze the strategy of when to summarize\nin order to balance the tradeoff especially in handling MAA based lookups.\nbetween the routing table compression rate and the chance of Unstructured\ndiscovery routing approaches, such as [4] [5], causing misleading routing. For\nexperimental study, we have collected 100K IoT data streams from various IoT\ndatabases as the input dataset. Experimental results show that our\nsummarization solution can reduce the routing table size by 20 to 30 folds with\n2-5% increase in latency when compared with similar peer-to-peer discovery\nrouting algorithms without summarization. Also, our approach outperforms DHT\nbased approaches by 2 to 6 folds in terms of latency and traffic.",
          "link": "http://arxiv.org/abs/2107.09558",
          "publishedOn": "2021-07-21T02:01:33.669Z",
          "wordCount": 658,
          "title": "Into Summarization Techniques for IoT Data Discovery Routing. (arXiv:2107.09558v1 [cs.NI])"
        },
        {
          "id": "http://arxiv.org/abs/2010.12537",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhiruo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1\">Haoyu Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1\">Ran Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jia Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Z/0/1/0/all/0/1\">Zhiyi Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Shi Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dongmei Zhang</a>",
          "description": "Tables are widely used with various structures to organize and present data.\nRecent attempts on table understanding mainly focus on relational tables, yet\noverlook to other common table structures. In this paper, we propose TUTA, a\nunified pre-training architecture for understanding generally structured\ntables. Noticing that understanding a table requires spatial, hierarchical, and\nsemantic information, we enhance transformers with three novel structure-aware\nmechanisms. First, we devise a unified tree-based structure, called a\nbi-dimensional coordinate tree, to describe both the spatial and hierarchical\ninformation of generally structured tables. Upon this, we propose tree-based\nattention and position embedding to better capture the spatial and hierarchical\ninformation. Moreover, we devise three progressive pre-training objectives to\nenable representations at the token, cell, and table levels. We pre-train TUTA\non a wide range of unlabeled web and spreadsheet tables and fine-tune it on two\ncritical tasks in the field of table structure understanding: cell type\nclassification and table type classification. Experiments show that TUTA is\nhighly effective, achieving state-of-the-art on five widely-studied datasets.",
          "link": "http://arxiv.org/abs/2010.12537",
          "publishedOn": "2021-07-21T02:01:32.983Z",
          "wordCount": 662,
          "title": "TUTA: Tree-based Transformers for Generally Structured Table Pre-training. (arXiv:2010.12537v4 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.09480",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Amato_D/0/1/0/all/0/1\">Domenico Amato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giancarlo_R/0/1/0/all/0/1\">Raffaele Giancarlo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bosco_G/0/1/0/all/0/1\">Giosu&#xe8; Lo Bosco</a>",
          "description": "Sorted Table Search Procedures are the quintessential query-answering tool,\nstill very useful, e.g, Search Engines (Google Chrome). Speeding them up, in\nsmall additional space with respect to the table being searched into, is still\na quite significant achievement. Static Learned Indexes have been very\nsuccessful in achieving such a speed-up, but leave open a major question: To\nwhat extent one can enjoy the speed-up of Learned Indexes while using constant\nor nearly constant additional space. By generalizing the experimental\nmethodology of a recent benchmarking study on Learned Indexes, we shed light on\nthis question, by considering two scenarios. The first, quite elementary, i.e.,\ntextbook code, and the second using advanced Learned Indexing algorithms and\nthe supporting sophisticated software platforms. Although in both cases one\nwould expect a positive answer, its achievement is not as simple as it seems.\nIndeed, our extensive set of experiments reveal a complex relationship between\nquery time and model space. The findings regarding this relationship and the\ncorresponding quantitative estimates, across memory levels, can be of interest\nto algorithm designers and of use to practitioners as well. As an essential\npart of our research, we introduce two new models that are of interest in their\nown right. The first is a constant space model that can be seen as a\ngeneralization of $k$-ary search, while the second is a synoptic {\\bf RMI}, in\nwhich we can control model space usage.",
          "link": "http://arxiv.org/abs/2107.09480",
          "publishedOn": "2021-07-21T02:01:32.669Z",
          "wordCount": 696,
          "title": "Learned Sorted Table Search and Static Indexes in Small Space: Methodological and Practical Insights via an Experimental Study. (arXiv:2107.09480v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2104.11783",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yanci Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_T/0/1/0/all/0/1\">Tianming Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yujie Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Donohue_L/0/1/0/all/0/1\">Lawrence Donohue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_R/0/1/0/all/0/1\">Rui Dai</a>",
          "description": "The quarterly financial statement, or Form 10-Q, is one of the most\nfrequently required filings for US public companies to disclose financial and\nother important business information. Due to the massive volume of 10-Q filings\nand the enormous variations in the reporting format, it has been a\nlong-standing challenge to retrieve item-specific information from 10-Q filings\nthat lack machine-readable hierarchy. This paper presents a solution for\nitemizing 10-Q files by complementing a rule-based algorithm with a\nConvolutional Neural Network (CNN) image classifier. This solution demonstrates\na pipeline that can be generalized to a rapid data retrieval solution among a\nlarge volume of textual data using only typographic items. The extracted\ntextual data can be used as unlabeled content-specific data to train\ntransformer models (e.g., BERT) or fit into various field-focus natural\nlanguage processing (NLP) applications.",
          "link": "http://arxiv.org/abs/2104.11783",
          "publishedOn": "2021-07-20T02:04:39.008Z",
          "wordCount": 601,
          "title": "Form 10-Q Itemization. (arXiv:2104.11783v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08868",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yazdani_N/0/1/0/all/0/1\">Niloofar Yazdani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kouvelas_N/0/1/0/all/0/1\">Nikolaos Kouvelas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prasad_R/0/1/0/all/0/1\">R Venkatesha Prasad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lucani_D/0/1/0/all/0/1\">Daniel E. Lucani</a>",
          "description": "High frame-corruption is widely observed in Long Range Wide Area Networks\n(LoRaWAN) due to the coexistence with other networks in ISM bands and an\nAloha-like MAC layer. LoRa's Forward Error Correction (FEC) mechanism is often\ninsufficient to retrieve corrupted data. In fact, real-life measurements show\nthat at least one-fourth of received transmissions are corrupted. When more\nframes are dropped, LoRa nodes usually switch over to higher spreading factors\n(SF), thus increasing transmission times and increasing the required energy.\nThis paper introduces ReDCoS, a novel coding technique at the application layer\nthat improves recovery of corrupted LoRa frames, thus reducing the overall\ntransmission time and energy invested by LoRa nodes by several-fold. ReDCoS\nutilizes lightweight coding techniques to pre-encode the transmitted data.\nTherefore, the inbuilt Cyclic Redundancy Check (CRC) that follows is computed\nbased on an already encoded data. At the receiver, we use both the CRC and the\ncoded data to recover data from a corrupted frame beyond the built-in Error\nCorrecting Code (ECC). We compare the performance of ReDCoS to (I) the standard\nFEC of vanilla-LoRaWAN, and to (ii) RS coding applied as ECC to the data of\nLoRaWAN. The results indicated a 54x and 13.5x improvement of decoding ratio,\nrespectively, when 20 data symbols were sent. Furthermore, we evaluated ReDCoS\non-field using LoRa SX1261 transceivers showing that it outperformed RS-coding\nby factor of at least 2x (and up to 6x) in terms of the decoding ratio while\nconsuming 38.5% less energy per correctly received transmission.",
          "link": "http://arxiv.org/abs/2107.08868",
          "publishedOn": "2021-07-20T02:04:38.982Z",
          "wordCount": 688,
          "title": "Energy Efficient Data Recovery from Corrupted LoRa Frames. (arXiv:2107.08868v1 [cs.IT])"
        },
        {
          "id": "http://arxiv.org/abs/2008.08899",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mathew_M/0/1/0/all/0/1\">Minesh Mathew</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tito_R/0/1/0/all/0/1\">Ruben Tito</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karatzas_D/0/1/0/all/0/1\">Dimosthenis Karatzas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manmatha_R/0/1/0/all/0/1\">R. Manmatha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jawahar_C/0/1/0/all/0/1\">C.V. Jawahar</a>",
          "description": "This paper presents results of Document Visual Question Answering Challenge\norganized as part of \"Text and Documents in the Deep Learning Era\" workshop, in\nCVPR 2020. The challenge introduces a new problem - Visual Question Answering\non document images. The challenge comprised two tasks. The first task concerns\nwith asking questions on a single document image. On the other hand, the second\ntask is set as a retrieval task where the question is posed over a collection\nof images. For the task 1 a new dataset is introduced comprising 50,000\nquestions-answer(s) pairs defined over 12,767 document images. For task 2\nanother dataset has been created comprising 20 questions over 14,362 document\nimages which share the same document template.",
          "link": "http://arxiv.org/abs/2008.08899",
          "publishedOn": "2021-07-20T02:04:38.396Z",
          "wordCount": 597,
          "title": "Document Visual Question Answering Challenge 2020. (arXiv:2008.08899v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08927",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pourkamali_F/0/1/0/all/0/1\">Farzad Pourkamali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Macris_N/0/1/0/all/0/1\">Nicolas Macris</a>",
          "description": "We consider the estimation of an n-dimensional vector s from the noisy\nelement-wise measurements of $\\mathbf{s}\\mathbf{s}^T$, a generic problem that\narises in statistics and machine learning. We study a mismatched Bayesian\ninference setting, where some of the parameters are not known to the\nstatistician. We derive the full exact analytic expression of the asymptotic\nmean squared error (MSE) in the large system size limit for the particular case\nof Gaussian priors and additive noise. From our formulas, we see that\nestimation is still possible in the mismatched case; and also that the minimum\nMSE (MMSE) can be achieved if the statistician chooses suitable parameters. Our\ntechnique relies on the asymptotics of the spherical integrals and can be\napplied as long as the statistician chooses a rotationally invariant prior.",
          "link": "http://arxiv.org/abs/2107.08927",
          "publishedOn": "2021-07-20T02:04:38.368Z",
          "wordCount": 562,
          "title": "Mismatched Estimation of rank-one symmetric matrices under Gaussian noise. (arXiv:2107.08927v1 [cs.IT])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08383",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pan_F/0/1/0/all/0/1\">Feiyang Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haoming Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ao_X/0/1/0/all/0/1\">Xiang Ao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_Y/0/1/0/all/0/1\">Yanrong Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_A/0/1/0/all/0/1\">Ao Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Q/0/1/0/all/0/1\">Qing He</a>",
          "description": "The exploration/exploitation (E&E) dilemma lies at the core of interactive\nsystems such as online advertising, for which contextual bandit algorithms have\nbeen proposed. Bayesian approaches provide guided exploration with principled\nuncertainty estimation, but the applicability is often limited due to\nover-simplified assumptions. Non-Bayesian bootstrap methods, on the other hand,\ncan apply to complex problems by using deep reward models, but lacks clear\nguidance to the exploration behavior. It still remains largely unsolved to\ndevelop a practical method for complex deep contextual bandits.\n\nIn this paper, we introduce Guided Bootstrap (GuideBoot for short), combining\nthe best of both worlds. GuideBoot provides explicit guidance to the\nexploration behavior by training multiple models over both real samples and\nnoisy samples with fake labels, where the noise is added according to the\npredictive uncertainty. The proposed method is efficient as it can make\ndecisions on-the-fly by utilizing only one randomly chosen model, but is also\neffective as we show that it can be viewed as a non-Bayesian approximation of\nThompson sampling. Moreover, we extend it to an online version that can learn\nsolely from streaming data, which is favored in real applications. Extensive\nexperiments on both synthetic task and large-scale advertising environments\nshow that GuideBoot achieves significant improvements against previous\nstate-of-the-art methods.",
          "link": "http://arxiv.org/abs/2107.08383",
          "publishedOn": "2021-07-20T02:04:38.289Z",
          "wordCount": 649,
          "title": "GuideBoot: Guided Bootstrap for Deep Contextual Bandits. (arXiv:2107.08383v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08096",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shanmugam_D/0/1/0/all/0/1\">Divya Shanmugam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shabanian_S/0/1/0/all/0/1\">Samira Shabanian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diaz_F/0/1/0/all/0/1\">Fernando Diaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Finck_M/0/1/0/all/0/1\">Mich&#xe8;le Finck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biega_A/0/1/0/all/0/1\">Asia Biega</a>",
          "description": "Data minimization is a legal obligation defined in the European Union's\nGeneral Data Protection Regulation (GDPR) as the responsibility to process an\nadequate, relevant, and limited amount of personal data in relation to a\nprocessing purpose. However, unlike fairness or transparency, the principle has\nnot seen wide adoption for machine learning systems due to a lack of\ncomputational interpretation. In this paper, we build on literature in machine\nlearning and law to propose the first learning framework for limiting data\ncollection based on an interpretation that ties the data collection purpose to\nsystem performance. We formalize a data minimization criterion based on\nperformance curve derivatives and provide an effective and interpretable\npiecewise power law technique that models distinct stages of an algorithm's\nperformance throughout data collection. Results from our empirical\ninvestigation offer deeper insights into the relevant considerations when\ndesigning a data minimization framework, including the choice of feature\nacquisition algorithm, initialization conditions, as well as impacts on\nindividuals that hint at tensions between data minimization and fairness.",
          "link": "http://arxiv.org/abs/2107.08096",
          "publishedOn": "2021-07-20T02:04:38.147Z",
          "wordCount": 618,
          "title": "Learning to Limit Data Collection via Scaling Laws: Data Minimization Compliance in Practice. (arXiv:2107.08096v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08291",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kumar_L/0/1/0/all/0/1\">Lakshya Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarkar_S/0/1/0/all/0/1\">Sagnik Sarkar</a>",
          "description": "Typical e-commerce platforms contain millions of products in the catalog.\nUsers visit these platforms and enter search queries to retrieve their desired\nproducts. Therefore, showing the relevant products at the top is essential for\nthe success of e-commerce platforms. We approach this problem by learning low\ndimension representations for queries and product descriptions by leveraging\nuser click-stream data as our main source of signal for product relevance.\nStarting from GRU-based architectures as our baseline model, we move towards a\nmore advanced transformer-based architecture. This helps the model to learn\ncontextual representations of queries and products to serve better search\nresults and understand the user intent in an efficient manner. We perform\nexperiments related to pre-training of the Transformer based RoBERTa model\nusing a fashion corpus and fine-tuning it over the triplet loss. Our\nexperiments on the product ranking task show that the RoBERTa model is able to\ngive an improvement of 7.8% in Mean Reciprocal Rank(MRR), 15.8% in Mean Average\nPrecision(MAP) and 8.8% in Normalized Discounted Cumulative Gain(NDCG), thus\noutperforming our GRU based baselines. For the product retrieval task, RoBERTa\nmodel is able to outperform other two models with an improvement of 164.7% in\nPrecision@50 and 145.3% in Recall@50. In order to highlight the importance of\npre-training RoBERTa for fashion domain, we qualitatively compare already\npre-trained RoBERTa on standard datasets with our custom pre-trained RoBERTa\nover a fashion corpus for the query token prediction task. Finally, we also\nshow a qualitative comparison between GRU and RoBERTa results for product\nretrieval task for some test queries.",
          "link": "http://arxiv.org/abs/2107.08291",
          "publishedOn": "2021-07-20T02:04:38.103Z",
          "wordCount": 692,
          "title": "Neural Search: Learning Query and Product Representations in Fashion E-commerce. (arXiv:2107.08291v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08345",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1\">Yinqiong Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1\">Yixing Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1\">Jiafeng Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ruqing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_Y/0/1/0/all/0/1\">Yanyan Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1\">Xueqi Cheng</a>",
          "description": "Similar question retrieval is a core task in community-based question\nanswering (CQA) services. To balance the effectiveness and efficiency, the\nquestion retrieval system is typically implemented as multi-stage rankers: The\nfirst-stage ranker aims to recall potentially relevant questions from a large\nrepository, and the latter stages attempt to re-rank the retrieved results.\nMost existing works on question retrieval mainly focused on the re-ranking\nstages, leaving the first-stage ranker to some traditional term-based methods.\nHowever, term-based methods often suffer from the vocabulary mismatch problem,\nespecially on short texts, which may block the re-rankers from relevant\nquestions at the very beginning. An alternative is to employ embedding-based\nmethods for the first-stage ranker, which compress texts into dense vectors to\nenhance the semantic matching. However, these methods often lose the\ndiscriminative power as term-based methods, thus introduce noise during\nretrieval and hurt the recall performance. In this work, we aim to tackle the\ndilemma of the first-stage ranker, and propose a discriminative semantic\nranker, namely DenseTrans, for high-recall retrieval. Specifically, DenseTrans\nis a densely connected Transformer, which learns semantic embeddings for texts\nbased on Transformer layers. Meanwhile, DenseTrans promotes low-level features\nthrough dense connections to keep the discriminative power of the learned\nrepresentations. DenseTrans is inspired by DenseNet in computer vision (CV),\nbut poses a new way to use the dense connectivity which is totally different\nfrom its original design purpose. Experimental results over two question\nretrieval benchmark datasets show that our model can obtain significant gain on\nrecall against strong term-based methods as well as state-of-the-art\nembedding-based methods.",
          "link": "http://arxiv.org/abs/2107.08345",
          "publishedOn": "2021-07-20T02:04:38.062Z",
          "wordCount": 691,
          "title": "A Discriminative Semantic Ranker for Question Retrieval. (arXiv:2107.08345v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07002",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dehghani_M/0/1/0/all/0/1\">Mostafa Dehghani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tay_Y/0/1/0/all/0/1\">Yi Tay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gritsenko_A/0/1/0/all/0/1\">Alexey A. Gritsenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1\">Zhe Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Houlsby_N/0/1/0/all/0/1\">Neil Houlsby</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diaz_F/0/1/0/all/0/1\">Fernando Diaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Metzler_D/0/1/0/all/0/1\">Donald Metzler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vinyals_O/0/1/0/all/0/1\">Oriol Vinyals</a>",
          "description": "The world of empirical machine learning (ML) strongly relies on benchmarks in\norder to determine the relative effectiveness of different algorithms and\nmethods. This paper proposes the notion of \"a benchmark lottery\" that describes\nthe overall fragility of the ML benchmarking process. The benchmark lottery\npostulates that many factors, other than fundamental algorithmic superiority,\nmay lead to a method being perceived as superior. On multiple benchmark setups\nthat are prevalent in the ML community, we show that the relative performance\nof algorithms may be altered significantly simply by choosing different\nbenchmark tasks, highlighting the fragility of the current paradigms and\npotential fallacious interpretation derived from benchmarking ML methods. Given\nthat every benchmark makes a statement about what it perceives to be important,\nwe argue that this might lead to biased progress in the community. We discuss\nthe implications of the observed phenomena and provide recommendations on\nmitigating them using multiple machine learning domains and communities as use\ncases, including natural language processing, computer vision, information\nretrieval, recommender systems, and reinforcement learning.",
          "link": "http://arxiv.org/abs/2107.07002",
          "publishedOn": "2021-07-19T00:49:05.316Z",
          "wordCount": 620,
          "title": "The Benchmark Lottery. (arXiv:2107.07002v1 [cs.LG] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.09423",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tagliabue_J/0/1/0/all/0/1\">Jacopo Tagliabue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Greco_C/0/1/0/all/0/1\">Ciro Greco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_J/0/1/0/all/0/1\">Jean-Francis Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1\">Bingqing Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chia_P/0/1/0/all/0/1\">Patrick John Chia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bianchi_F/0/1/0/all/0/1\">Federico Bianchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cassani_G/0/1/0/all/0/1\">Giovanni Cassani</a>",
          "description": "The 2021 SIGIR workshop on eCommerce is hosting the Coveo Data Challenge for\n\"In-session prediction for purchase intent and recommendations\". The challenge\naddresses the growing need for reliable predictions within the boundaries of a\nshopping session, as customer intentions can be different depending on the\noccasion. The need for efficient procedures for personalization is even clearer\nif we consider the e-commerce landscape more broadly: outside of giant digital\nretailers, the constraints of the problem are stricter, due to smaller user\nbases and the realization that most users are not frequently returning\ncustomers. We release a new session-based dataset including more than 30M\nfine-grained browsing events (product detail, add, purchase), enriched by\nlinguistic behavior (queries made by shoppers, with items clicked and items not\nclicked after the query) and catalog meta-data (images, text, pricing\ninformation). On this dataset, we ask participants to showcase innovative\nsolutions for two open problems: a recommendation task (where a model is shown\nsome events at the start of a session, and it is asked to predict future\nproduct interactions); an intent prediction task, where a model is shown a\nsession containing an add-to-cart event, and it is asked to predict whether the\nitem will be bought before the end of the session.",
          "link": "http://arxiv.org/abs/2104.09423",
          "publishedOn": "2021-07-19T00:49:05.195Z",
          "wordCount": 695,
          "title": "SIGIR 2021 E-Commerce Workshop Data Challenge. (arXiv:2104.09423v4 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.07831",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chaudhuri_A/0/1/0/all/0/1\">Arpita Chaudhuri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samanta_D/0/1/0/all/0/1\">Debasis Samanta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarma_M/0/1/0/all/0/1\">Monalisa Sarma</a>",
          "description": "User intention which often changes dynamically is considered to be an\nimportant factor for modeling users in the design of recommendation systems.\nRecent studies are starting to focus on predicting user intention (what users\nwant) beyond user preference (what users like). In this work, a user intention\nmodel is proposed based on deep sequential topic analysis. The model predicts a\nuser's intention in terms of the topic of interest. The Hybrid Topic Model\n(HTM) comprising Latent Dirichlet Allocation (LDA) and Word2Vec is proposed to\nderive the topic of interest of users and the history of preferences. HTM finds\nthe true topics of papers estimating word-topic distribution which includes\nsyntactic and semantic correlations among words. Next, to model user intention,\na Long Short Term Memory (LSTM) based sequential deep learning model is\nproposed. This model takes into account temporal context, namely the time\ndifference between clicks of two consecutive papers seen by a user. Extensive\nexperiments with the real-world research paper dataset indicate that the\nproposed approach significantly outperforms the state-of-the-art methods.\nFurther, the proposed approach introduces a new road map to model a user\nactivity suitable for the design of a research paper recommendation system.",
          "link": "http://arxiv.org/abs/2107.07831",
          "publishedOn": "2021-07-19T00:49:05.156Z",
          "wordCount": 630,
          "title": "Modeling User Behaviour in Research Paper Recommendation System. (arXiv:2107.07831v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07842",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Choudhary_S/0/1/0/all/0/1\">Shivani Choudhary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luthra_T/0/1/0/all/0/1\">Tarun Luthra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mittal_A/0/1/0/all/0/1\">Ashima Mittal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1\">Rajat Singh</a>",
          "description": "Knowledge Graph embedding provides a versatile technique for representing\nknowledge. These techniques can be used in a variety of applications such as\ncompletion of knowledge graph to predict missing information, recommender\nsystems, question answering, query expansion, etc. The information embedded in\nKnowledge graph though being structured is challenging to consume in a\nreal-world application. Knowledge graph embedding enables the real-world\napplication to consume information to improve performance. Knowledge graph\nembedding is an active research area. Most of the embedding methods focus on\nstructure-based information. Recent research has extended the boundary to\ninclude text-based information and image-based information in entity embedding.\nEfforts have been made to enhance the representation with context information.\nThis paper introduces growth in the field of KG embedding from simple\ntranslation-based models to enrichment-based models. This paper includes the\nutility of the Knowledge graph in real-world applications.",
          "link": "http://arxiv.org/abs/2107.07842",
          "publishedOn": "2021-07-19T00:49:05.141Z",
          "wordCount": 580,
          "title": "A Survey of Knowledge Graph Embedding and Their Applications. (arXiv:2107.07842v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07786",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shatri_E/0/1/0/all/0/1\">Elona Shatri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fazekas_G/0/1/0/all/0/1\">Gy&#xf6;rgy Fazekas</a>",
          "description": "The main challenges of Optical Music Recognition (OMR) come from the nature\nof written music, its complexity and the difficulty of finding an appropriate\ndata representation. This paper provides a first look at DoReMi, an OMR dataset\nthat addresses these challenges, and a baseline object detection model to\nassess its utility. Researchers often approach OMR following a set of small\nstages, given that existing data often do not satisfy broader research. We\nexamine the possibility of changing this tendency by presenting more metadata.\nOur approach complements existing research; hence DoReMi allows harmonisation\nwith two existing datasets, DeepScores and MUSCIMA++. DoReMi was generated\nusing a music notation software and includes over 6400 printed sheet music\nimages with accompanying metadata useful in OMR research. Our dataset provides\nOMR metadata, MIDI, MEI, MusicXML and PNG files, each aiding a different stage\nof OMR. We obtain 64% mean average precision (mAP) in object detection using\nhalf of the data. Further work includes re-iterating through the creation\nprocess to satisfy custom OMR models. While we do not assume to have solved the\nmain challenges in OMR, this dataset opens a new course of discussions that\nwould ultimately aid that goal.",
          "link": "http://arxiv.org/abs/2107.07786",
          "publishedOn": "2021-07-19T00:49:05.131Z",
          "wordCount": 651,
          "title": "DoReMi: First glance at a universal OMR dataset. (arXiv:2107.07786v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07705",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ruan_Q/0/1/0/all/0/1\">Qin Ruan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Namee_B/0/1/0/all/0/1\">Brian Mac Namee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_R/0/1/0/all/0/1\">Ruihai Dong</a>",
          "description": "Leveraging unlabelled data through weak or distant supervision is a\ncompelling approach to developing more effective text classification models.\nThis paper proposes a simple but effective data augmentation method, which\nleverages the idea of pseudo-labelling to select samples from noisy distant\nsupervision annotation datasets. The result shows that the proposed method\nimproves the accuracy of biased news detection models.",
          "link": "http://arxiv.org/abs/2107.07705",
          "publishedOn": "2021-07-19T00:49:04.905Z",
          "wordCount": 491,
          "title": "Pseudo-labelling Enhanced Media Bias Detection. (arXiv:2107.07705v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07773",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yizhi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhenghao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1\">Chenyan Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>",
          "description": "Dense retrieval conducts text retrieval in the embedding space and has shown\nmany advantages compared to sparse retrieval. Existing dense retrievers\noptimize representations of queries and documents with contrastive training and\nmap them to the embedding space. The embedding space is optimized by aligning\nthe matched query-document pairs and pushing the negative documents away from\nthe query. However, in such training paradigm, the queries are only optimized\nto align to the documents and are coarsely positioned, leading to an\nanisotropic query embedding space. In this paper, we analyze the embedding\nspace distributions and propose an effective training paradigm, Contrastive\nDual Learning for Approximate Nearest Neighbor (DANCE) to learn fine-grained\nquery representations for dense retrieval. DANCE incorporates an additional\ndual training object of query retrieval, inspired by the classic information\nretrieval training axiom, query likelihood. With contrastive learning, the dual\ntraining object of DANCE learns more tailored representations for queries and\ndocuments to keep the embedding space smooth and uniform, thriving on the\nranking performance of DANCE on the MS MARCO document retrieval task. Different\nfrom ANCE that only optimized with the document retrieval task, DANCE\nconcentrates the query embeddings closer to document representations while\nmaking the document distribution more discriminative. Such concentrated query\nembedding distribution assigns more uniform negative sampling probabilities to\nqueries and helps to sufficiently optimize query representations in the query\nretrieval task. Our codes are released at https://github.com/thunlp/DANCE.",
          "link": "http://arxiv.org/abs/2107.07773",
          "publishedOn": "2021-07-19T00:49:04.885Z",
          "wordCount": 669,
          "title": "More Robust Dense Retrieval with Contrastive Dual Learning. (arXiv:2107.07773v1 [cs.IR])"
        }
      ]
    },
    {
      "title": "cs.MM updates on arXiv.org",
      "feedUrl": "http://export.arxiv.org/rss/cs.MM",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2104.09036",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jinghao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yanqiao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qiang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuhui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Liang Wang</a>",
          "description": "Multimedia content is of predominance in the modern Web era. Investigating\nhow users interact with multimodal items is a continuing concern within the\nrapid development of recommender systems. The majority of previous work focuses\non modeling user-item interactions with multimodal features included as side\ninformation. However, this scheme is not well-designed for multimedia\nrecommendation. Specifically, only collaborative item-item relationships are\nimplicitly modeled through high-order item-user-item relations. Considering\nthat items are associated with rich contents in multiple modalities, we argue\nthat the latent semantic item-item structures underlying these multimodal\ncontents could be beneficial for learning better item representations and\nfurther boosting recommendation. To this end, we propose a LATent sTructure\nmining method for multImodal reCommEndation, which we term LATTICE for brevity.\nTo be specific, in the proposed LATTICE model, we devise a novel modality-aware\nstructure learning layer, which learns item-item structures for each modality\nand aggregates multiple modalities to obtain latent item graphs. Based on the\nlearned latent graphs, we perform graph convolutions to explicitly inject\nhigh-order item affinities into item representations. These enriched item\nrepresentations can then be plugged into existing collaborative filtering\nmethods to make more accurate recommendations. Extensive experiments on three\nreal-world datasets demonstrate the superiority of our method over\nstate-of-the-art multimedia recommendation methods and validate the efficacy of\nmining latent item-item relationships from multimodal features.",
          "link": "http://arxiv.org/abs/2104.09036",
          "publishedOn": "2021-07-22T02:03:11.029Z",
          "wordCount": 695,
          "title": "Mining Latent Structures for Multimedia Recommendation. (arXiv:2104.09036v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.09877",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ning Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Junchi Yan</a>",
          "description": "Symbolic music generation has attracted increasing attention, while most\nmethods focus on generating short piece (mostly less than 8 bars, and up to 32\nbars). Generating long music calls for effective expression of the coherent\nmusic structure. Despite their success on long sequences, self-attention\narchitectures still have challenge in dealing with long-term music as it\nrequires additional care on the subtle music structure. In this paper, we\npropose to transfer the structure of training samples for new music generation,\nand develop a novel separable self-attention based model which enable the\nlearning and transferring of the structure embedding. We show that our transfer\nmodel can generate music sequences (up to 100 bars) with interpretable\nstructures, which bears similar structures and composition techniques with the\ntemplate music from training set. Extensive experiments show its ability of\ngenerating music with target structure and well diversity. The generated 3,000\nsets of music is uploaded as supplemental material.",
          "link": "http://arxiv.org/abs/2107.09877",
          "publishedOn": "2021-07-22T02:03:10.522Z",
          "wordCount": 588,
          "title": "Melody Structure Transfer Network: Generating Music with Separable Self-Attention. (arXiv:2107.09877v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09889",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+He_T/0/1/0/all/0/1\">Tianyao He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wenxuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_C/0/1/0/all/0/1\">Chen Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Junchi Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ning Zhang</a>",
          "description": "Nowadays, with the prevalence of social media and music creation tools,\nmusical pieces are spreading much quickly, and music creation is getting much\neasier. The increasing number of musical pieces have made the problem of music\nplagiarism prominent. There is an urgent need for a tool that can detect music\nplagiarism automatically. Researchers have proposed various methods to extract\nlow-level and high-level features of music and compute their similarities.\nHowever, low-level features such as cepstrum coefficients have weak relation\nwith the copyright protection of musical pieces. Existing algorithms\nconsidering high-level features fail to detect the case in which two musical\npieces are not quite similar overall, but have some highly similar regions.\nThis paper proposes a new method named MESMF, which innovatively converts the\nmusic plagiarism detection problem into the bipartite graph matching task. It\ncan be solved via the maximum weight matching and edit distances model. We\ndesign several kinds of melody representations and the similarity computation\nmethods according to the music theory. The proposed method can deal with the\nshift, swapping, transposition, and tempo variance problems in music\nplagiarism. It can also effectively pick out the local similar regions from two\nmusical pieces with relatively low global similarity. We collect a new music\nplagiarism dataset from real legally-judged music plagiarism cases and conduct\ndetailed ablation studies. Experimental results prove the excellent performance\nof the proposed algorithm. The source code and our dataset are available at\nhttps://anonymous.4open.science/r/a41b8fb4-64cf-4190-a1e1-09b7499a15f5/",
          "link": "http://arxiv.org/abs/2107.09889",
          "publishedOn": "2021-07-22T02:03:10.425Z",
          "wordCount": 675,
          "title": "Music Plagiarism Detection via Bipartite Graph Matching. (arXiv:2107.09889v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2107.10220",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Antsiferova_A/0/1/0/all/0/1\">Anastasia Antsiferova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yakovenko_A/0/1/0/all/0/1\">Alexander Yakovenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Safonov_N/0/1/0/all/0/1\">Nickolay Safonov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulikov_D/0/1/0/all/0/1\">Dmitriy Kulikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gushin_A/0/1/0/all/0/1\">Alexander Gushin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vatolin_D/0/1/0/all/0/1\">Dmitriy Vatolin</a>",
          "description": "Quality assessment plays a key role in creating and comparing video\ncompression algorithms. Despite the development of a large number of new\nmethods for assessing quality, generally accepted and well-known codecs\ncomparisons mainly use the classical methods like PSNR, SSIM and new method\nVMAF. These methods can be calculated following different rules: they can use\ndifferent frame-by-frame averaging techniques or different summation of color\ncomponents. In this paper, a fundamental comparison of various versions of\ngenerally accepted metrics is carried out to find the most relevant and\nrecommended versions of video quality metrics to be used in codecs comparisons.\nFor comparison, we used a set of videos encoded with video codecs of different\nstandards, and visual quality scores collected for the resulting set of streams\nsince 2018 until 2021",
          "link": "http://arxiv.org/abs/2107.10220",
          "publishedOn": "2021-07-22T02:03:10.401Z",
          "wordCount": 584,
          "title": "Objective video quality metrics application to video codecs comparisons: choosing the best for subjective quality estimation. (arXiv:2107.10220v1 [cs.MM])"
        },
        {
          "id": "http://arxiv.org/abs/2106.10132",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Wang_D/0/1/0/all/0/1\">Disong Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Deng_L/0/1/0/all/0/1\">Liqun Deng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yeung_Y/0/1/0/all/0/1\">Yu Ting Yeung</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_X/0/1/0/all/0/1\">Xiao Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_X/0/1/0/all/0/1\">Xunying Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Meng_H/0/1/0/all/0/1\">Helen Meng</a>",
          "description": "One-shot voice conversion (VC), which performs conversion across arbitrary\nspeakers with only a single target-speaker utterance for reference, can be\neffectively achieved by speech representation disentanglement. Existing work\ngenerally ignores the correlation between different speech representations\nduring training, which causes leakage of content information into the speaker\nrepresentation and thus degrades VC performance. To alleviate this issue, we\nemploy vector quantization (VQ) for content encoding and introduce mutual\ninformation (MI) as the correlation metric during training, to achieve proper\ndisentanglement of content, speaker and pitch representations, by reducing\ntheir inter-dependencies in an unsupervised manner. Experimental results\nreflect the superiority of the proposed method in learning effective\ndisentangled speech representations for retaining source linguistic content and\nintonation variations, while capturing target speaker characteristics. In doing\nso, the proposed approach achieves higher speech naturalness and speaker\nsimilarity than current state-of-the-art one-shot VC systems. Our code,\npre-trained models and demo are available at\nhttps://github.com/Wendison/VQMIVC.",
          "link": "http://arxiv.org/abs/2106.10132",
          "publishedOn": "2021-07-22T02:03:10.188Z",
          "wordCount": 639,
          "title": "VQMIVC: Vector Quantization and Mutual Information-Based Unsupervised Speech Representation Disentanglement for One-shot Voice Conversion. (arXiv:2106.10132v1 [eess.AS] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.09262",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghose_S/0/1/0/all/0/1\">Sanchita Ghose</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prevost_J/0/1/0/all/0/1\">John J. Prevost</a>",
          "description": "Deep learning based visual to sound generation systems essentially need to be\ndeveloped particularly considering the synchronicity aspects of visual and\naudio features with time. In this research we introduce a novel task of guiding\na class conditioned generative adversarial network with the temporal visual\ninformation of a video input for visual to sound generation task adapting the\nsynchronicity traits between audio-visual modalities. Our proposed FoleyGAN\nmodel is capable of conditioning action sequences of visual events leading\ntowards generating visually aligned realistic sound tracks. We expand our\npreviously proposed Automatic Foley dataset to train with FoleyGAN and evaluate\nour synthesized sound through human survey that shows noteworthy (on average\n81\\%) audio-visual synchronicity performance. Our approach also outperforms in\nstatistical experiments compared with other baseline models and audio-visual\ndatasets.",
          "link": "http://arxiv.org/abs/2107.09262",
          "publishedOn": "2021-07-21T02:01:33.208Z",
          "wordCount": 610,
          "title": "FoleyGAN: Visually Guided Generative Adversarial Network-Based Synchronous Sound Generation in Silent Videos. (arXiv:2107.09262v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09491",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1\">Lingzhi Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_Y/0/1/0/all/0/1\">Ying Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yunfei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Sheng Yang</a>",
          "description": "This paper investigates adaptive streaming of one or multiple tiled 360\nvideos from a multi-antenna base station (BS) to one or multiple single-antenna\nusers, respectively, in a multi-carrier wireless system. We aim to maximize the\nvideo quality while keeping rebuffering time small via encoding rate adaptation\nat each group of pictures (GOP) and transmission adaptation at each\n(transmission) slot. To capture the impact of field-of-view (FoV) prediction,\nwe consider three cases of FoV viewing probability distributions, i.e.,\nperfect, imperfect, and unknown FoV viewing probability distributions, and use\nthe average total utility, worst average total utility, and worst total utility\nas the respective performance metrics. In the single-user scenario, we optimize\nthe encoding rates of the tiles, encoding rates of the FoVs, and transmission\nbeamforming vectors for all subcarriers to maximize the total utility in each\ncase. In the multi-user scenario, we adopt rate splitting with successive\ndecoding and optimize the encoding rates of the tiles, encoding rates of the\nFoVs, rates of the common and private messages, and transmission beamforming\nvectors for all subcarriers to maximize the total utility in each case. Then,\nwe separate the challenging optimization problem into multiple tractable\nproblems in each scenario. In the single-user scenario, we obtain a globally\noptimal solution of each problem using transformation techniques and the\nKarush-Kuhn-Tucker (KKT) conditions. In the multi-user scenario, we obtain a\nKKT point of each problem using the concave-convex procedure (CCCP). Finally,\nnumerical results demonstrate that the proposed solutions achieve notable gains\nover existing schemes in all three cases. To the best of our knowledge, this is\nthe first work revealing the impact of FoV prediction on the performance of\nadaptive streaming of tiled 360 videos.",
          "link": "http://arxiv.org/abs/2107.09491",
          "publishedOn": "2021-07-21T02:01:33.193Z",
          "wordCount": 744,
          "title": "Adaptive Streaming of 360 Videos with Perfect, Imperfect, and Unknown FoV Viewing Probabilities in Wireless Networks. (arXiv:2107.09491v1 [cs.MM])"
        },
        {
          "id": "http://arxiv.org/abs/2107.06252",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aggarwal_G/0/1/0/all/0/1\">Gunjan Aggarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parikh_D/0/1/0/all/0/1\">Devi Parikh</a>",
          "description": "Dance and music typically go hand in hand. The complexities in dance, music,\nand their synchronisation make them fascinating to study from a computational\ncreativity perspective. While several works have looked at generating dance for\na given music, automatically generating music for a given dance remains\nunder-explored. This capability could have several creative expression and\nentertainment applications. We present some early explorations in this\ndirection. We present a search-based offline approach that generates music\nafter processing the entire dance video and an online approach that uses a deep\nneural network to generate music on-the-fly as the video proceeds. We compare\nthese approaches to a strong heuristic baseline via human studies and present\nour findings. We have integrated our online approach in a live demo! A video of\nthe demo can be found here:\nhttps://sites.google.com/view/dance2music/live-demo.",
          "link": "http://arxiv.org/abs/2107.06252",
          "publishedOn": "2021-07-21T02:01:33.048Z",
          "wordCount": 581,
          "title": "Dance2Music: Automatic Dance-driven Music Generation. (arXiv:2107.06252v2 [cs.SD] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08688",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xiangyu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yinzhe Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Hanzhou Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xinpeng Zhang</a>",
          "description": "In order to protect the intellectual property (IP) of deep neural networks\n(DNNs), many existing DNN watermarking techniques either embed watermarks\ndirectly into the DNN parameters or insert backdoor watermarks by fine-tuning\nthe DNN parameters, which, however, cannot resist against various attack\nmethods that remove watermarks by altering DNN parameters. In this paper, we\nbypass such attacks by introducing a structural watermarking scheme that\nutilizes channel pruning to embed the watermark into the host DNN architecture\ninstead of crafting the DNN parameters. To be specific, during watermark\nembedding, we prune the internal channels of the host DNN with the channel\npruning rates controlled by the watermark. During watermark extraction, the\nwatermark is retrieved by identifying the channel pruning rates from the\narchitecture of the target DNN model. Due to the superiority of pruning\nmechanism, the performance of the DNN model on its original task is reserved\nduring watermark embedding. Experimental results have shown that, the proposed\nwork enables the embedded watermark to be reliably recovered and provides a\nhigh watermark capacity, without sacrificing the usability of the DNN model. It\nis also demonstrated that the work is robust against common transforms and\nattacks designed for conventional watermarking approaches.",
          "link": "http://arxiv.org/abs/2107.08688",
          "publishedOn": "2021-07-20T02:04:38.180Z",
          "wordCount": 640,
          "title": "Structural Watermarking to Deep Neural Networks via Network Channel Pruning. (arXiv:2107.08688v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08621",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qingzhong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Pengfei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1\">Haoyi Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jian Zhao</a>",
          "description": "In this paper, we develop face.evoLVe -- a comprehensive library that\ncollects and implements a wide range of popular deep learning-based methods for\nface recognition. First of all, face.evoLVe is composed of key components that\ncover the full process of face analytics, including face alignment, data\nprocessing, various backbones, losses, and alternatives with bags of tricks for\nimproving performance. Later, face.evoLVe supports multi-GPU training on top of\ndifferent deep learning platforms, such as PyTorch and PaddlePaddle, which\nfacilitates researchers to work on both large-scale datasets with millions of\nimages and low-shot counterparts with limited well-annotated data. More\nimportantly, along with face.evoLVe, images before & after alignment in the\ncommon benchmark datasets are released with source codes and trained models\nprovided. All these efforts lower the technical burdens in reproducing the\nexisting methods for comparison, while users of our library could focus on\ndeveloping advanced approaches more efficiently. Last but not least,\nface.evoLVe is well designed and vibrantly evolving, so that new face\nrecognition approaches can be easily plugged into our framework. Note that we\nhave used face.evoLVe to participate in a number of face recognition\ncompetitions and secured the first place. The version that supports PyTorch is\npublicly available at https://github.com/ZhaoJ9014/face.evoLVe.PyTorch and the\nPaddlePaddle version is available at\nhttps://github.com/ZhaoJ9014/face.evoLVe.PyTorch/tree/master/paddle.\nFace.evoLVe has been widely used for face analytics, receiving 2.4K stars and\n622 forks.",
          "link": "http://arxiv.org/abs/2107.08621",
          "publishedOn": "2021-07-20T02:04:37.964Z",
          "wordCount": 668,
          "title": "Face.evoLVe: A High-Performance Face Recognition Library. (arXiv:2107.08621v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08264",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xingbo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jianben He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1\">Zhihua Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Muqiao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_H/0/1/0/all/0/1\">Huamin Qu</a>",
          "description": "Multimodal sentiment analysis aims to recognize people's attitudes from\nmultiple communication channels such as verbal content (i.e., text), voice, and\nfacial expressions. It has become a vibrant and important research topic in\nnatural language processing. Much research focuses on modeling the complex\nintra- and inter-modal interactions between different communication channels.\nHowever, current multimodal models with strong performance are often\ndeep-learning-based techniques and work like black boxes. It is not clear how\nmodels utilize multimodal information for sentiment predictions. Despite recent\nadvances in techniques for enhancing the explainability of machine learning\nmodels, they often target unimodal scenarios (e.g., images, sentences), and\nlittle research has been done on explaining multimodal models. In this paper,\nwe present an interactive visual analytics system, M2Lens, to visualize and\nexplain multimodal models for sentiment analysis. M2Lens provides explanations\non intra- and inter-modal interactions at the global, subset, and local levels.\nSpecifically, it summarizes the influence of three typical interaction types\n(i.e., dominance, complement, and conflict) on the model predictions. Moreover,\nM2Lens identifies frequent and influential multimodal features and supports the\nmulti-faceted exploration of model behaviors from language, acoustic, and\nvisual modalities. Through two case studies and expert interviews, we\ndemonstrate our system can help users gain deep insights into the multimodal\nmodels for sentiment analysis.",
          "link": "http://arxiv.org/abs/2107.08264",
          "publishedOn": "2021-07-20T02:04:37.888Z",
          "wordCount": 685,
          "title": "M2Lens: Visualizing and Explaining Multimodal Models for Sentiment Analysis. (arXiv:2107.08264v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08356",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xingbo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ming_Y/0/1/0/all/0/1\">Yao Ming</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1\">Tongshuang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_H/0/1/0/all/0/1\">Haipeng Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_H/0/1/0/all/0/1\">Huamin Qu</a>",
          "description": "Despite being a critical communication skill, grasping humor is challenging\n-- a successful use of humor requires a mixture of both engaging content\nbuild-up and an appropriate vocal delivery (e.g., pause). Prior studies on\ncomputational humor emphasize the textual and audio features immediately next\nto the punchline, yet overlooking longer-term context setup. Moreover, the\ntheories are usually too abstract for understanding each concrete humor\nsnippet. To fill in the gap, we develop DeHumor, a visual analytical system for\nanalyzing humorous behaviors in public speaking. To intuitively reveal the\nbuilding blocks of each concrete example, DeHumor decomposes each humorous\nvideo into multimodal features and provides inline annotations of them on the\nvideo script. In particular, to better capture the build-ups, we introduce\ncontent repetition as a complement to features introduced in theories of\ncomputational humor and visualize them in a context linking graph. To help\nusers locate the punchlines that have the desired features to learn, we\nsummarize the content (with keywords) and humor feature statistics on an\naugmented time matrix. With case studies on stand-up comedy shows and TED\ntalks, we show that DeHumor is able to highlight various building blocks of\nhumor examples. In addition, expert interviews with communication coaches and\nhumor researchers demonstrate the effectiveness of DeHumor for multimodal humor\nanalysis of speech content and vocal delivery.",
          "link": "http://arxiv.org/abs/2107.08356",
          "publishedOn": "2021-07-20T02:04:37.706Z",
          "wordCount": 689,
          "title": "DeHumor: Visual Analytics for Decomposing Humor. (arXiv:2107.08356v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07907",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Liu_K/0/1/0/all/0/1\">Kanglin Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cao_G/0/1/0/all/0/1\">Gaofeng Cao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Duan_J/0/1/0/all/0/1\">Jiang Duan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Qiu_G/0/1/0/all/0/1\">Guoping Qiu</a>",
          "description": "Single-image HDR reconstruction or inverse tone mapping (iTM) is a\nchallenging task. In particular, recovering information in over-exposed regions\nis extremely difficult because details in such regions are almost completely\nlost. In this paper, we present a deep learning based iTM method that takes\nadvantage of the feature extraction and mapping power of deep convolutional\nneural networks (CNNs) and uses a lightness prior to modulate the CNN to better\nexploit observations in the surrounding areas of the over-exposed regions to\nenhance the quality of HDR image reconstruction. Specifically, we introduce a\nHierarchical Synthesis Network (HiSN) for inferring a HDR image from a LDR\ninput and a Lightness Adpative Modulation Network (LAMN) to incorporate the the\nlightness prior knowledge in the inferring process. The HiSN hierarchically\nsynthesizes the high-brightness component and the low-brightness component of\nthe HDR image whilst the LAMN uses a lightness adaptive mask that separates\ndetail-less saturated bright pixels from well-exposed lower light pixels to\nenable HiSN to better infer the missing information, particularly in the\ndifficult over-exposed detail-less areas. We present experimental results to\ndemonstrate the effectiveness of the new technique based on quantitative\nmeasures and visual comparisons. In addition, we present ablation studies of\nHiSN and visualization of the activation maps inside LAMN to help gain a deeper\nunderstanding of the internal working of the new iTM algorithm and explain why\nit can achieve much improved performance over state-of-the-art algorithms.",
          "link": "http://arxiv.org/abs/2107.07907",
          "publishedOn": "2021-07-19T00:49:04.940Z",
          "wordCount": 683,
          "title": "Lightness Modulated Deep Inverse Tone Mapping. (arXiv:2107.07907v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07786",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shatri_E/0/1/0/all/0/1\">Elona Shatri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fazekas_G/0/1/0/all/0/1\">Gy&#xf6;rgy Fazekas</a>",
          "description": "The main challenges of Optical Music Recognition (OMR) come from the nature\nof written music, its complexity and the difficulty of finding an appropriate\ndata representation. This paper provides a first look at DoReMi, an OMR dataset\nthat addresses these challenges, and a baseline object detection model to\nassess its utility. Researchers often approach OMR following a set of small\nstages, given that existing data often do not satisfy broader research. We\nexamine the possibility of changing this tendency by presenting more metadata.\nOur approach complements existing research; hence DoReMi allows harmonisation\nwith two existing datasets, DeepScores and MUSCIMA++. DoReMi was generated\nusing a music notation software and includes over 6400 printed sheet music\nimages with accompanying metadata useful in OMR research. Our dataset provides\nOMR metadata, MIDI, MEI, MusicXML and PNG files, each aiding a different stage\nof OMR. We obtain 64% mean average precision (mAP) in object detection using\nhalf of the data. Further work includes re-iterating through the creation\nprocess to satisfy custom OMR models. While we do not assume to have solved the\nmain challenges in OMR, this dataset opens a new course of discussions that\nwould ultimately aid that goal.",
          "link": "http://arxiv.org/abs/2107.07786",
          "publishedOn": "2021-07-19T00:49:04.774Z",
          "wordCount": 651,
          "title": "DoReMi: First glance at a universal OMR dataset. (arXiv:2107.07786v1 [cs.IR])"
        }
      ]
    },
    {
      "title": "cs.CV updates on arXiv.org",
      "feedUrl": "http://export.arxiv.org/rss/cs.CV",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2106.11582",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hechen Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jinghua Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1\">Peng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1\">Ao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_T/0/1/0/all/0/1\">Tao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grzegorzek_M/0/1/0/all/0/1\">Marcin Grzegorzek</a>",
          "description": "Nowadays, analysis of Transparent Environmental Microorganism Images (T-EM\nimages) in the field of computer vision has gradually become a new and\ninteresting spot. This paper compares different deep learning classification\nperformance for the problem that T-EM images are challenging to analyze. We\ncrop the T-EM images into 8 * 8 and 224 * 224 pixel patches in the same\nproportion and then divide the two different pixel patches into foreground and\nbackground according to ground truth. We also use four convolutional neural\nnetworks and a novel ViT network model to compare the foreground and background\nclassification experiments. We conclude that ViT performs the worst in\nclassifying 8 * 8 pixel patches, but it outperforms most convolutional neural\nnetworks in classifying 224 * 224 pixel patches.",
          "link": "http://arxiv.org/abs/2106.11582",
          "publishedOn": "2021-07-22T02:03:12.537Z",
          "wordCount": 623,
          "title": "A Comparison for Patch-level Classification of Deep Learning Methods on Transparent Environmental Microorganism Images: from Convolutional Neural Networks to Visual Transformers. (arXiv:2106.11582v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.10050",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dana_A/0/1/0/all/0/1\">Alexandra Dana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shutman_M/0/1/0/all/0/1\">Maor Shutman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perlitz_Y/0/1/0/all/0/1\">Yotam Perlitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vitek_R/0/1/0/all/0/1\">Ran Vitek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peleg_T/0/1/0/all/0/1\">Tomer Peleg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jevnisek_R/0/1/0/all/0/1\">Roy Jevnisek</a>",
          "description": "General object detectors use powerful backbones that uniformly extract\nfeatures from images for enabling detection of a vast amount of object types.\nHowever, utilization of such backbones in object detection applications\ndeveloped for specific object types can unnecessarily over-process an extensive\namount of background. In addition, they are agnostic to object scales, thus\nredundantly process all image regions at the same resolution. In this work we\nintroduce BLT-net, a new low-computation two-stage object detection\narchitecture designed to process images with a significant amount of background\nand objects of variate scales. BLT-net reduces computations by separating\nobjects from background using a very lite first-stage. BLT-net then efficiently\nmerges obtained proposals to further decrease processed background and then\ndynamically reduces their resolution to minimize computations. Resulting image\nproposals are then processed in the second-stage by a highly accurate model. We\ndemonstrate our architecture on the pedestrian detection problem, where objects\nare of different sizes, images are of high resolution and object detection is\nrequired to run in real-time. We show that our design reduces computations by a\nfactor of x4-x7 on the Citypersons and Caltech datasets with respect to leading\npedestrian detectors, on account of a small accuracy degradation. This method\ncan be applied on other object detection applications in scenes with a\nconsiderable amount of background and variate object sizes to reduce\ncomputations.",
          "link": "http://arxiv.org/abs/2107.10050",
          "publishedOn": "2021-07-22T02:03:12.410Z",
          "wordCount": 674,
          "title": "You Better Look Twice: a new perspective for designing accurate detectors with reduced computations. (arXiv:2107.10050v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.10140",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Prabhu_V/0/1/0/all/0/1\">Viraj Prabhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khare_S/0/1/0/all/0/1\">Shivam Khare</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kartik_D/0/1/0/all/0/1\">Deeksha Kartik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoffman_J/0/1/0/all/0/1\">Judy Hoffman</a>",
          "description": "Most modern approaches for domain adaptive semantic segmentation rely on\ncontinued access to source data during adaptation, which may be infeasible due\nto computational or privacy constraints. We focus on source-free domain\nadaptation for semantic segmentation, wherein a source model must adapt itself\nto a new target domain given only unlabeled target data. We propose\nSelf-Supervised Selective Self-Training (S4T), a source-free adaptation\nalgorithm that first uses the model's pixel-level predictive consistency across\ndiverse views of each target image along with model confidence to classify\npixel predictions as either reliable or unreliable. Next, the model is\nself-trained, using predicted pseudolabels for reliable predictions and\npseudolabels inferred via a selective interpolation strategy for unreliable\nones. S4T matches or improves upon the state-of-the-art in source-free\nadaptation on 3 standard benchmarks for semantic segmentation within a single\nepoch of adaptation.",
          "link": "http://arxiv.org/abs/2107.10140",
          "publishedOn": "2021-07-22T02:03:12.404Z",
          "wordCount": 581,
          "title": "S4T: Source-free domain adaptation for semantic segmentation via self-supervised selective self-training. (arXiv:2107.10140v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2103.10492",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fuad_M/0/1/0/all/0/1\">Md. Tahmid Hasan Fuad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fime_A/0/1/0/all/0/1\">Awal Ahmed Fime</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sikder_D/0/1/0/all/0/1\">Delowar Sikder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iftee_M/0/1/0/all/0/1\">Md. Akil Raihan Iftee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rabbi_J/0/1/0/all/0/1\">Jakaria Rabbi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Al_rakhami_M/0/1/0/all/0/1\">Mabrook S. Al-rakhami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gumae_A/0/1/0/all/0/1\">Abdu Gumae</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sen_O/0/1/0/all/0/1\">Ovishake Sen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fuad_M/0/1/0/all/0/1\">Mohtasim Fuad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Islam_M/0/1/0/all/0/1\">Md. Nazrul Islam</a>",
          "description": "In recent years, researchers have proposed many deep learning (DL) methods\nfor various tasks, and particularly face recognition (FR) made an enormous leap\nusing these techniques. Deep FR systems benefit from the hierarchical\narchitecture of the DL methods to learn discriminative face representation.\nTherefore, DL techniques significantly improve state-of-the-art performance on\nFR systems and encourage diverse and efficient real-world applications. In this\npaper, we present a comprehensive analysis of various FR systems that leverage\nthe different types of DL techniques, and for the study, we summarize 168\nrecent contributions from this area. We discuss the papers related to different\nalgorithms, architectures, loss functions, activation functions, datasets,\nchallenges, improvement ideas, current and future trends of DL-based FR\nsystems. We provide a detailed discussion of various DL methods to understand\nthe current state-of-the-art, and then we discuss various activation and loss\nfunctions for the methods. Additionally, we summarize different datasets used\nwidely for FR tasks and discuss challenges related to illumination, expression,\npose variations, and occlusion. Finally, we discuss improvement ideas, current\nand future trends of FR tasks.",
          "link": "http://arxiv.org/abs/2103.10492",
          "publishedOn": "2021-07-22T02:03:12.388Z",
          "wordCount": 710,
          "title": "Recent Advances in Deep Learning Techniques for Face Recognition. (arXiv:2103.10492v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.14808",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jun Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_S/0/1/0/all/0/1\">Song Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1\">Cheng Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_C/0/1/0/all/0/1\">Cheng Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yichi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+An_X/0/1/0/all/0/1\">Xingle An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Congcong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qiyuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_S/0/1/0/all/0/1\">Shucheng Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shangqing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yunpeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuhui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jian He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiaoping Yang</a>",
          "description": "With the unprecedented developments in deep learning, automatic segmentation\nof main abdominal organs seems to be a solved problem as state-of-the-art\n(SOTA) methods have achieved comparable results with inter-rater variability on\nmany benchmark datasets. However, most of the existing abdominal datasets only\ncontain single-center, single-phase, single-vendor, or single-disease cases,\nand it is unclear whether the excellent performance can generalize on diverse\ndatasets. This paper presents a large and diverse abdominal CT organ\nsegmentation dataset, termed AbdomenCT-1K, with more than 1000 (1K) CT scans\nfrom 12 medical centers, including multi-phase, multi-vendor, and multi-disease\ncases. Furthermore, we conduct a large-scale study for liver, kidney, spleen,\nand pancreas segmentation and reveal the unsolved segmentation problems of the\nSOTA methods, such as the limited generalization ability on distinct medical\ncenters, phases, and unseen diseases. To advance the unsolved problems, we\nfurther build four organ segmentation benchmarks for fully supervised,\nsemi-supervised, weakly supervised, and continual learning, which are currently\nchallenging and active research topics. Accordingly, we develop a simple and\neffective method for each benchmark, which can be used as out-of-the-box\nmethods and strong baselines. We believe the AbdomenCT-1K dataset will promote\nfuture in-depth research towards clinical applicable abdominal organ\nsegmentation methods. The datasets, codes, and trained models are publicly\navailable at https://github.com/JunMa11/AbdomenCT-1K.",
          "link": "http://arxiv.org/abs/2010.14808",
          "publishedOn": "2021-07-22T02:03:12.356Z",
          "wordCount": 705,
          "title": "AbdomenCT-1K: Is Abdominal Organ Segmentation A Solved Problem?. (arXiv:2010.14808v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.03367",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Prabhudesai_M/0/1/0/all/0/1\">Mihir Prabhudesai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lal_S/0/1/0/all/0/1\">Shamit Lal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patil_D/0/1/0/all/0/1\">Darshan Patil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tung_H/0/1/0/all/0/1\">Hsiao-Yu Tung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harley_A/0/1/0/all/0/1\">Adam W Harley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fragkiadaki_K/0/1/0/all/0/1\">Katerina Fragkiadaki</a>",
          "description": "We present neural architectures that disentangle RGB-D images into objects'\nshapes and styles and a map of the background scene, and explore their\napplications for few-shot 3D object detection and few-shot concept\nclassification. Our networks incorporate architectural biases that reflect the\nimage formation process, 3D geometry of the world scene, and shape-style\ninterplay. They are trained end-to-end self-supervised by predicting views in\nstatic scenes, alongside a small number of 3D object boxes. Objects and scenes\nare represented in terms of 3D feature grids in the bottleneck of the network.\nWe show that the proposed 3D neural representations are compositional: they can\ngenerate novel 3D scene feature maps by mixing object shapes and styles,\nresizing and adding the resulting object 3D feature maps over background scene\nfeature maps. We show that classifiers for object categories, color, materials,\nand spatial relationships trained over the disentangled 3D feature sub-spaces\ngeneralize better with dramatically fewer examples than the current\nstate-of-the-art, and enable a visual question answering system that uses them\nas its modules to generalize one-shot to novel objects in the scene.",
          "link": "http://arxiv.org/abs/2011.03367",
          "publishedOn": "2021-07-22T02:03:12.337Z",
          "wordCount": 657,
          "title": "Disentangling 3D Prototypical Networks For Few-Shot Concept Learning. (arXiv:2011.03367v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.10224",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Shoufa Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_E/0/1/0/all/0/1\">Enze Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_C/0/1/0/all/0/1\">Chongjian Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_D/0/1/0/all/0/1\">Ding Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_P/0/1/0/all/0/1\">Ping Luo</a>",
          "description": "This paper presents a simple MLP-like architecture, CycleMLP, which is a\nversatile backbone for visual recognition and dense predictions, unlike modern\nMLP architectures, e.g., MLP-Mixer, ResMLP, and gMLP, whose architectures are\ncorrelated to image size and thus are infeasible in object detection and\nsegmentation. CycleMLP has two advantages compared to modern approaches. (1) It\ncan cope with various image sizes. (2) It achieves linear computational\ncomplexity to image size by using local windows. In contrast, previous MLPs\nhave quadratic computations because of their fully spatial connections. We\nbuild a family of models that surpass existing MLPs and achieve a comparable\naccuracy (83.2%) on ImageNet-1K classification compared to the state-of-the-art\nTransformer such as Swin Transformer (83.3%) but using fewer parameters and\nFLOPs. We expand the MLP-like models' applicability, making them a versatile\nbackbone for dense prediction tasks. CycleMLP aims to provide a competitive\nbaseline on object detection, instance segmentation, and semantic segmentation\nfor MLP models. In particular, CycleMLP achieves 45.1 mIoU on ADE20K val,\ncomparable to Swin (45.2 mIOU). Code is available at\n\\url{https://github.com/ShoufaChen/CycleMLP}.",
          "link": "http://arxiv.org/abs/2107.10224",
          "publishedOn": "2021-07-22T02:03:12.330Z",
          "wordCount": 618,
          "title": "CycleMLP: A MLP-like Architecture for Dense Prediction. (arXiv:2107.10224v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.10006",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nordmark_N/0/1/0/all/0/1\">Nils Nordmark</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ayenew_M/0/1/0/all/0/1\">Mola Ayenew</a>",
          "description": "The parsing of windows in building facades is a long-desired but challenging\ntask in computer vision. It is crucial to urban analysis, semantic\nreconstruction, lifecycle analysis, digital twins, and scene parsing amongst\nother building-related tasks that require high-quality semantic data. This\narticle investigates the usage of the mask R-CNN framework to be used for\nwindow detection of facade imagery input. We utilize transfer learning to train\nour proposed method on COCO weights with our own collected dataset of street\nview images of facades to produce instance segmentations of our new window\nclass. Experimental results show that our suggested approach with a relatively\nsmall dataset trains the network only with transfer learning and augmentation\nachieves results on par with prior state-of-the-art window detection\napproaches, even without post-optimization techniques.",
          "link": "http://arxiv.org/abs/2107.10006",
          "publishedOn": "2021-07-22T02:03:11.699Z",
          "wordCount": 577,
          "title": "Window Detection In Facade Imagery: A Deep Learning Approach Using Mask R-CNN. (arXiv:2107.10006v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.10064",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Souibgui_M/0/1/0/all/0/1\">Mohamed Ali Souibgui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fornes_A/0/1/0/all/0/1\">Alicia Forn&#xe9;s</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kessentini_Y/0/1/0/all/0/1\">Yousri Kessentini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Megyesi_B/0/1/0/all/0/1\">Be&#xe1;ta Megyesi</a>",
          "description": "Handwritten text recognition in low resource scenarios, such as manuscripts\nwith rare alphabets, is a challenging problem. The main difficulty comes from\nthe very few annotated data and the limited linguistic information (e.g.\ndictionaries and language models). Thus, we propose a few-shot learning-based\nhandwriting recognition approach that significantly reduces the human labor\nannotation process, requiring only few images of each alphabet symbol. First,\nour model detects all symbols of a given alphabet in a textline image, then a\ndecoding step maps the symbol similarity scores to the final sequence of\ntranscribed symbols. Our model is first pretrained on synthetic line images\ngenerated from any alphabet, even though different from the target domain. A\nsecond training step is then applied to diminish the gap between the source and\ntarget data. Since this retraining would require annotation of thousands of\nhandwritten symbols together with their bounding boxes, we propose to avoid\nsuch human effort through an unsupervised progressive learning approach that\nautomatically assigns pseudo-labels to the non-annotated data. The evaluation\non different manuscript datasets show that our model can lead to competitive\nresults with a significant reduction in human effort.",
          "link": "http://arxiv.org/abs/2107.10064",
          "publishedOn": "2021-07-22T02:03:11.664Z",
          "wordCount": 650,
          "title": "Few Shots Is All You Need: A Progressive Few Shot Learning Approach for Low Resource Handwriting Recognition. (arXiv:2107.10064v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2010.00806",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Thai_P/0/1/0/all/0/1\">Phat Thai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alam_S/0/1/0/all/0/1\">Sameer Alam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lilith_N/0/1/0/all/0/1\">Nimrod Lilith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_P/0/1/0/all/0/1\">Phu N. Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thanh_B/0/1/0/all/0/1\">Binh Nguyen Thanh</a>",
          "description": "An airport runway and taxiway (airside) area is a highly dynamic and complex\nenvironment featuring interactions between different types of vehicles (speed\nand dimension), under varying visibility and traffic conditions. Airport ground\nmovements are deemed safety-critical activities, and safe-separation procedures\nmust be maintained by Air Traffic Controllers (ATCs). Large airports with\ncomplicated runway-taxiway systems use advanced ground surveillance systems.\nHowever, these systems have inherent limitations and a lack of real-time\nanalytics. In this paper, we propose a novel computer-vision based framework,\nnamely \"Deep4Air\", which can not only augment the ground surveillance systems\nvia the automated visual monitoring of runways and taxiways for aircraft\nlocation, but also provide real-time speed and distance analytics for aircraft\non runways and taxiways. The proposed framework includes an adaptive deep\nneural network for efficiently detecting and tracking aircraft. The\nexperimental results show an average precision of detection and tracking of up\nto 99.8% on simulated data with validations on surveillance videos from the\ndigital tower at George Bush Intercontinental Airport. The results also\ndemonstrate that \"Deep4Air\" can locate aircraft positions relative to the\nairport runway and taxiway infrastructure with high accuracy. Furthermore,\naircraft speed and separation distance are monitored in real-time, providing\nenhanced safety management.",
          "link": "http://arxiv.org/abs/2010.00806",
          "publishedOn": "2021-07-22T02:03:11.332Z",
          "wordCount": 670,
          "title": "Deep4Air: A Novel Deep Learning Framework for Airport Airside Surveillance. (arXiv:2010.00806v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.05489",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yichuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+James_H/0/1/0/all/0/1\">Hailey James</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_O/0/1/0/all/0/1\">Otkrist Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raviv_D/0/1/0/all/0/1\">Dan Raviv</a>",
          "description": "Detecting and extracting information from Machine-Readable Zone (MRZ) on\npassports and visas is becoming increasingly important for verifying document\nauthenticity. However, computer vision methods for performing similar tasks,\nsuch as optical character recognition (OCR), fail to extract the MRZ given\ndigital images of passports with reasonable accuracy. We present a specially\ndesigned model based on convolutional neural networks that is able to\nsuccessfully extract MRZ information from digital images of passports of\narbitrary orientation and size. Our model achieved 100% MRZ detection rate and\n98.36% character recognition macro-f1 score on a passport and visa dataset.",
          "link": "http://arxiv.org/abs/2009.05489",
          "publishedOn": "2021-07-22T02:03:11.288Z",
          "wordCount": 577,
          "title": "MRZ code extraction from visa and passport documents using convolutional neural networks. (arXiv:2009.05489v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.09842",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zhang_Y/0/1/0/all/0/1\">Yao Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_J/0/1/0/all/0/1\">Jiawei Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tian_J/0/1/0/all/0/1\">Jiang Tian</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shi_Z/0/1/0/all/0/1\">Zhongchao Shi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhong_C/0/1/0/all/0/1\">Cheng Zhong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_Y/0/1/0/all/0/1\">Yang Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+He_Z/0/1/0/all/0/1\">Zhiqiang He</a>",
          "description": "Liver cancer is one of the most common cancers worldwide. Due to\ninconspicuous texture changes of liver tumor, contrast-enhanced computed\ntomography (CT) imaging is effective for the diagnosis of liver cancer. In this\npaper, we focus on improving automated liver tumor segmentation by integrating\nmulti-modal CT images. To this end, we propose a novel mutual learning (ML)\nstrategy for effective and robust multi-modal liver tumor segmentation.\nDifferent from existing multi-modal methods that fuse information from\ndifferent modalities by a single model, with ML, an ensemble of\nmodality-specific models learn collaboratively and teach each other to distill\nboth the characteristics and the commonality between high-level representations\nof different modalities. The proposed ML not only enables the superiority for\nmulti-modal learning but can also handle missing modalities by transferring\nknowledge from existing modalities to missing ones. Additionally, we present a\nmodality-aware (MA) module, where the modality-specific models are\ninterconnected and calibrated with attention weights for adaptive information\nexchange. The proposed modality-aware mutual learning (MAML) method achieves\npromising results for liver tumor segmentation on a large-scale clinical\ndataset. Moreover, we show the efficacy and robustness of MAML for handling\nmissing modalities on both the liver tumor and public brain tumor (BRATS 2018)\ndatasets. Our code is available at https://github.com/YaoZhang93/MAML.",
          "link": "http://arxiv.org/abs/2107.09842",
          "publishedOn": "2021-07-22T02:03:11.280Z",
          "wordCount": 658,
          "title": "Modality-aware Mutual Learning for Multi-modal Medical Image Segmentation. (arXiv:2107.09842v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2004.06193",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Koner_R/0/1/0/all/0/1\">Rajat Koner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shit_S/0/1/0/all/0/1\">Suprosanna Shit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tresp_V/0/1/0/all/0/1\">Volker Tresp</a>",
          "description": "The extraction of a scene graph with objects as nodes and mutual\nrelationships as edges is the basis for a deep understanding of image content.\nDespite recent advances, such as message passing and joint classification, the\ndetection of visual relationships remains a challenging task due to sub-optimal\nexploration of the mutual interaction among the visual objects. In this work,\nwe propose a novel transformer formulation for scene graph generation and\nrelation prediction. We leverage the encoder-decoder architecture of the\ntransformer for rich feature embedding of nodes and edges. Specifically, we\nmodel the node-to-node interaction with the self-attention of the transformer\nencoder and the edge-to-node interaction with the cross-attention of the\ntransformer decoder. Further, we introduce a novel positional embedding\nsuitable to handle edges in the decoder. Finally, our relation prediction\nmodule classifies the directed relation from the learned node and edge\nembedding. We name this architecture as Relation Transformer Network (RTN). On\nthe Visual Genome and GQA dataset, we have achieved an overall mean of 4.85%\nand 3.1% point improvement in comparison with state-of-the-art methods. Our\nexperiments show that Relation Transformer can efficiently model context across\nvarious datasets with small, medium, and large-scale relation classification.",
          "link": "http://arxiv.org/abs/2004.06193",
          "publishedOn": "2021-07-22T02:03:11.273Z",
          "wordCount": 644,
          "title": "Relation Transformer Network. (arXiv:2004.06193v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.09923",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Hu_B/0/1/0/all/0/1\">Bowen Hu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lei_B/0/1/0/all/0/1\">Baiying Lei</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shen_Y/0/1/0/all/0/1\">Yanyan Shen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_Y/0/1/0/all/0/1\">Yong Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_S/0/1/0/all/0/1\">Shuqiang Wang</a>",
          "description": "Fusing medical images and the corresponding 3D shape representation can\nprovide complementary information and microstructure details to improve the\noperational performance and accuracy in brain surgery. However, compared to the\nsubstantial image data, it is almost impossible to obtain the intraoperative 3D\nshape information by using physical methods such as sensor scanning, especially\nin minimally invasive surgery and robot-guided surgery. In this paper, a\ngeneral generative adversarial network (GAN) architecture based on graph\nconvolutional networks is proposed to reconstruct the 3D point clouds (PCs) of\nbrains by using one single 2D image, thus relieving the limitation of acquiring\n3D shape data during surgery. Specifically, a tree-structured generative\nmechanism is constructed to use the latent vector effectively and transfer\nfeatures between hidden layers accurately. With the proposed generative model,\na spontaneous image-to-PC conversion is finished in real-time. Competitive\nqualitative and quantitative experimental results have been achieved on our\nmodel. In multiple evaluation methods, the proposed model outperforms another\ncommon point cloud generative model PointOutNet.",
          "link": "http://arxiv.org/abs/2107.09923",
          "publishedOn": "2021-07-22T02:03:11.266Z",
          "wordCount": 622,
          "title": "A Point Cloud Generative Model via Tree-Structured Graph Convolutions for 3D Brain Shape Reconstruction. (arXiv:2107.09923v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/1905.08616",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wong_A/0/1/0/all/0/1\">Alex Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_X/0/1/0/all/0/1\">Xiaohan Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsuei_S/0/1/0/all/0/1\">Stephanie Tsuei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1\">Stefano Soatto</a>",
          "description": "We describe a method to infer dense depth from camera motion and sparse depth\nas estimated using a visual-inertial odometry system. Unlike other scenarios\nusing point clouds from lidar or structured light sensors, we have few hundreds\nto few thousand points, insufficient to inform the topology of the scene. Our\nmethod first constructs a piecewise planar scaffolding of the scene, and then\nuses it to infer dense depth using the image along with the sparse points. We\nuse a predictive cross-modal criterion, akin to `self-supervision,' measuring\nphotometric consistency across time, forward-backward pose consistency, and\ngeometric compatibility with the sparse point cloud. We also launch the first\nvisual-inertial + depth dataset, which we hope will foster additional\nexploration into combining the complementary strengths of visual and inertial\nsensors. To compare our method to prior work, we adopt the unsupervised KITTI\ndepth completion benchmark, and show state-of-the-art performance on it. Code\navailable at:\nhttps://github.com/alexklwong/unsupervised-depth-completion-visual-inertial-odometry.",
          "link": "http://arxiv.org/abs/1905.08616",
          "publishedOn": "2021-07-22T02:03:11.245Z",
          "wordCount": 646,
          "title": "Unsupervised Depth Completion from Visual Inertial Odometry. (arXiv:1905.08616v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.10161",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bao_W/0/1/0/all/0/1\">Wentao Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Q/0/1/0/all/0/1\">Qi Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_Y/0/1/0/all/0/1\">Yu Kong</a>",
          "description": "In a real-world scenario, human actions are typically out of the distribution\nfrom training data, which requires a model to both recognize the known actions\nand reject the unknown. Different from image data, video actions are more\nchallenging to be recognized in an open-set setting due to the uncertain\ntemporal dynamics and static bias of human actions. In this paper, we propose a\nDeep Evidential Action Recognition (DEAR) method to recognize actions in an\nopen testing set. Specifically, we formulate the action recognition problem\nfrom the evidential deep learning (EDL) perspective and propose a novel model\ncalibration method to regularize the EDL training. Besides, to mitigate the\nstatic bias of video representation, we propose a plug-and-play module to\ndebias the learned representation through contrastive learning. Experimental\nresults show that our DEAR method achieves consistent performance gain on\nmultiple mainstream action recognition models and benchmarks. Codes and\npre-trained weights will be made available upon paper acceptance.",
          "link": "http://arxiv.org/abs/2107.10161",
          "publishedOn": "2021-07-22T02:03:11.226Z",
          "wordCount": 589,
          "title": "Evidential Deep Learning for Open Set Action Recognition. (arXiv:2107.10161v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2104.01542",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1\">Zhenyu Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yifeng Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Svetlik_M/0/1/0/all/0/1\">Maxwell Svetlik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_K/0/1/0/all/0/1\">Kuan Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yuke Zhu</a>",
          "description": "Grasp detection in clutter requires the robot to reason about the 3D scene\nfrom incomplete and noisy perception. In this work, we draw insight that 3D\nreconstruction and grasp learning are two intimately connected tasks, both of\nwhich require a fine-grained understanding of local geometry details. We thus\npropose to utilize the synergies between grasp affordance and 3D reconstruction\nthrough multi-task learning of a shared representation. Our model takes\nadvantage of deep implicit functions, a continuous and memory-efficient\nrepresentation, to enable differentiable training of both tasks. We train the\nmodel on self-supervised grasp trials data in simulation. Evaluation is\nconducted on a clutter removal task, where the robot clears cluttered objects\nby grasping them one at a time. The experimental results in simulation and on\nthe real robot have demonstrated that the use of implicit neural\nrepresentations and joint learning of grasp affordance and 3D reconstruction\nhave led to state-of-the-art grasping results. Our method outperforms baselines\nby over 10% in terms of grasp success rate. Additional results and videos can\nbe found at https://sites.google.com/view/rpl-giga2021",
          "link": "http://arxiv.org/abs/2104.01542",
          "publishedOn": "2021-07-22T02:03:11.182Z",
          "wordCount": 650,
          "title": "Synergies Between Affordance and Geometry: 6-DoF Grasp Detection via Implicit Representations. (arXiv:2104.01542v2 [cs.RO] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.09754",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hoque_R/0/1/0/all/0/1\">Ryan Hoque</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seita_D/0/1/0/all/0/1\">Daniel Seita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balakrishna_A/0/1/0/all/0/1\">Ashwin Balakrishna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganapathi_A/0/1/0/all/0/1\">Aditya Ganapathi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tanwani_A/0/1/0/all/0/1\">Ajay Kumar Tanwani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jamali_N/0/1/0/all/0/1\">Nawid Jamali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamane_K/0/1/0/all/0/1\">Katsu Yamane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iba_S/0/1/0/all/0/1\">Soshi Iba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldberg_K/0/1/0/all/0/1\">Ken Goldberg</a>",
          "description": "Robotic fabric manipulation has applications in home robotics, textiles,\nsenior care and surgery. Existing fabric manipulation techniques, however, are\ndesigned for specific tasks, making it difficult to generalize across different\nbut related tasks. We build upon the Visual Foresight framework to learn fabric\ndynamics that can be efficiently reused to accomplish different sequential\nfabric manipulation tasks with a single goal-conditioned policy. We extend our\nearlier work on VisuoSpatial Foresight (VSF), which learns visual dynamics on\ndomain randomized RGB images and depth maps simultaneously and completely in\nsimulation. In this earlier work, we evaluated VSF on multi-step fabric\nsmoothing and folding tasks against 5 baseline methods in simulation and on the\nda Vinci Research Kit (dVRK) surgical robot without any demonstrations at train\nor test time. A key finding was that depth sensing significantly improves\nperformance: RGBD data yields an 80% improvement in fabric folding success rate\nin simulation over pure RGB data. In this work, we vary 4 components of VSF,\nincluding data generation, visual dynamics model, cost function, and\noptimization procedure. Results suggest that training visual dynamics models\nusing longer, corner-based actions can improve the efficiency of fabric folding\nby 76% and enable a physical sequential fabric folding task that VSF could not\npreviously perform with 90% reliability. Code, data, videos, and supplementary\nmaterial are available at https://sites.google.com/view/fabric-vsf/.",
          "link": "http://arxiv.org/abs/2102.09754",
          "publishedOn": "2021-07-22T02:03:11.173Z",
          "wordCount": 723,
          "title": "VisuoSpatial Foresight for Physical Sequential Fabric Manipulation. (arXiv:2102.09754v2 [cs.RO] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.12741",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Renshen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fujii_Y/0/1/0/all/0/1\">Yasuhisa Fujii</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Popat_A/0/1/0/all/0/1\">Ashok C. Popat</a>",
          "description": "Paragraphs are an important class of document entities. We propose a new\napproach for paragraph identification by spatial graph convolutional neural\nnetworks (GCN) applied on OCR text boxes. Two steps, namely line splitting and\nline clustering, are performed to extract paragraphs from the lines in OCR\nresults. Each step uses a beta-skeleton graph constructed from bounding boxes,\nwhere the graph edges provide efficient support for graph convolution\noperations. With only pure layout input features, the GCN model size is 3~4\norders of magnitude smaller compared to R-CNN based models, while achieving\ncomparable or better accuracies on PubLayNet and other datasets. Furthermore,\nthe GCN models show good generalization from synthetic training data to\nreal-world images, and good adaptivity for variable document styles.",
          "link": "http://arxiv.org/abs/2101.12741",
          "publishedOn": "2021-07-22T02:03:11.166Z",
          "wordCount": 603,
          "title": "Post-OCR Paragraph Recognition by Graph Convolutional Networks. (arXiv:2101.12741v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1701.02123",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Je_C/0/1/0/all/0/1\">Changsoo Je</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_K/0/1/0/all/0/1\">Kyuhyoung Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sang Wook Lee</a>",
          "description": "In this paper, we present a novel method for rapid high-resolution range\nsensing using green-blue stripe pattern. We use green and blue for designing\nhigh-frequency stripe projection pattern. For accurate and reliable range\nrecovery, we identify the stripe patterns by our color-stripe segmentation and\nunwrapping algorithms. The experimental result for a naked human face shows the\neffectiveness of our method.",
          "link": "http://arxiv.org/abs/1701.02123",
          "publishedOn": "2021-07-22T02:03:11.158Z",
          "wordCount": 565,
          "title": "Green-Blue Stripe Pattern for Range Sensing from a Single Image. (arXiv:1701.02123v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.05653",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Perez_M/0/1/0/all/0/1\">Mauricio Perez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kot_A/0/1/0/all/0/1\">Alex C. Kot</a>",
          "description": "Research on group activity recognition mostly leans on the standard\ntwo-stream approach (RGB and Optical Flow) as their input features. Few have\nexplored explicit pose information, with none using it directly to reason about\nthe persons interactions. In this paper, we leverage the skeleton information\nto learn the interactions between the individuals straight from it. With our\nproposed method GIRN, multiple relationship types are inferred from independent\nmodules, that describe the relations between the body joints pair-by-pair.\nAdditionally to the joints relations, we also experiment with the previously\nunexplored relationship between individuals and relevant objects (e.g.\nvolleyball). The individuals distinct relations are then merged through an\nattention mechanism, that gives more importance to those individuals more\nrelevant for distinguishing the group activity. We evaluate our method in the\nVolleyball dataset, obtaining competitive results to the state-of-the-art. Our\nexperiments demonstrate the potential of skeleton-based approaches for modeling\nmulti-person interactions.",
          "link": "http://arxiv.org/abs/2011.05653",
          "publishedOn": "2021-07-22T02:03:11.136Z",
          "wordCount": 621,
          "title": "Skeleton-based Relational Reasoning for Group Activity Analysis. (arXiv:2011.05653v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.04165",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_P/0/1/0/all/0/1\">Pan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_R/0/1/0/all/0/1\">Ran Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1\">Shibiao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_L/0/1/0/all/0/1\">Liang Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Siyuan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1\">Xiaodan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1\">Song-Chun Zhu</a>",
          "description": "Geometry problem solving has attracted much attention in the NLP community\nrecently. The task is challenging as it requires abstract problem understanding\nand symbolic reasoning with axiomatic knowledge. However, current datasets are\neither small in scale or not publicly available. Thus, we construct a new\nlarge-scale benchmark, Geometry3K, consisting of 3,002 geometry problems with\ndense annotation in formal language. We further propose a novel geometry\nsolving approach with formal language and symbolic reasoning, called\nInterpretable Geometry Problem Solver (Inter-GPS). Inter-GPS first parses the\nproblem text and diagram into formal language automatically via rule-based text\nparsing and neural object detecting, respectively. Unlike implicit learning in\nexisting methods, Inter-GPS incorporates theorem knowledge as conditional rules\nand performs symbolic reasoning step by step. Also, a theorem predictor is\ndesigned to infer the theorem application sequence fed to the symbolic solver\nfor the more efficient and reasonable searching path. Extensive experiments on\nthe Geometry3K and GEOS datasets demonstrate that Inter-GPS achieves\nsignificant improvements over existing methods. The project with code and data\nis available at https://lupantech.github.io/inter-gps.",
          "link": "http://arxiv.org/abs/2105.04165",
          "publishedOn": "2021-07-22T02:03:11.129Z",
          "wordCount": 684,
          "title": "Inter-GPS: Interpretable Geometry Problem Solving with Formal Language and Symbolic Reasoning. (arXiv:2105.04165v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.06154",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1\">Shuhao Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuhui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuo_J/0/1/0/all/0/1\">Junbao Zhuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Liang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1\">Qingming Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Q/0/1/0/all/0/1\">Qi Tian</a>",
          "description": "Due to the domain discrepancy in visual domain adaptation, the performance of\nsource model degrades when bumping into the high data density near decision\nboundary in target domain. A common solution is to minimize the Shannon Entropy\nto push the decision boundary away from the high density area. However, entropy\nminimization also leads to severe reduction of prediction diversity, and\nunfortunately brings harm to the domain adaptation. In this paper, we\ninvestigate the prediction discriminability and diversity by studying the\nstructure of the classification output matrix of a randomly selected data\nbatch. We find by theoretical analysis that the prediction discriminability and\ndiversity could be separately measured by the Frobenius-norm and rank of the\nbatch output matrix. The nuclear-norm is an upperbound of the former, and a\nconvex approximation of the latter. Accordingly, we propose Batch Nuclear-norm\nMaximization and Minimization, which performs nuclear-norm maximization on the\ntarget output matrix to enhance the target prediction ability, and nuclear-norm\nminimization on the source batch output matrix to increase applicability of the\nsource domain knowledge. We further approximate the nuclear-norm by\nL_{1,2}-norm, and design multi-batch optimization for stable solution on large\nnumber of categories. The fast approximation method achieves O(n^2)\ncomputational complexity and better convergence property. Experiments show that\nour method could boost the adaptation accuracy and robustness under three\ntypical domain adaptation scenarios. The code is available at\nhttps://github.com/cuishuhao/BNM.",
          "link": "http://arxiv.org/abs/2107.06154",
          "publishedOn": "2021-07-22T02:03:11.110Z",
          "wordCount": 709,
          "title": "Fast Batch Nuclear-norm Maximization and Minimization for Robust Domain Adaptation. (arXiv:2107.06154v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.10073",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Jaume_G/0/1/0/all/0/1\">Guillaume Jaume</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pati_P/0/1/0/all/0/1\">Pushpak Pati</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Anklin_V/0/1/0/all/0/1\">Valentin Anklin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Foncubierta_A/0/1/0/all/0/1\">Antonio Foncubierta</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gabrani_M/0/1/0/all/0/1\">Maria Gabrani</a>",
          "description": "Advances in entity-graph based analysis of histopathology images have brought\nin a new paradigm to describe tissue composition, and learn the tissue\nstructure-to-function relationship. Entity-graphs offer flexible and scalable\nrepresentations to characterize tissue organization, while allowing the\nincorporation of prior pathological knowledge to further support model\ninterpretability and explainability. However, entity-graph analysis requires\nprerequisites for image-to-graph translation and knowledge of state-of-the-art\nmachine learning algorithms applied to graph-structured data, which can\npotentially hinder their adoption. In this work, we aim to alleviate these\nissues by developing HistoCartography, a standardized python API with necessary\npreprocessing, machine learning and explainability tools to facilitate\ngraph-analytics in computational pathology. Further, we have benchmarked the\ncomputational time and performance on multiple datasets across different\nimaging types and histopathology tasks to highlight the applicability of the\nAPI for building computational pathology workflows.",
          "link": "http://arxiv.org/abs/2107.10073",
          "publishedOn": "2021-07-22T02:03:11.100Z",
          "wordCount": 583,
          "title": "HistoCartography: A Toolkit for Graph Analytics in Digital Pathology. (arXiv:2107.10073v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.10220",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Antsiferova_A/0/1/0/all/0/1\">Anastasia Antsiferova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yakovenko_A/0/1/0/all/0/1\">Alexander Yakovenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Safonov_N/0/1/0/all/0/1\">Nickolay Safonov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulikov_D/0/1/0/all/0/1\">Dmitriy Kulikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gushin_A/0/1/0/all/0/1\">Alexander Gushin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vatolin_D/0/1/0/all/0/1\">Dmitriy Vatolin</a>",
          "description": "Quality assessment plays a key role in creating and comparing video\ncompression algorithms. Despite the development of a large number of new\nmethods for assessing quality, generally accepted and well-known codecs\ncomparisons mainly use the classical methods like PSNR, SSIM and new method\nVMAF. These methods can be calculated following different rules: they can use\ndifferent frame-by-frame averaging techniques or different summation of color\ncomponents. In this paper, a fundamental comparison of various versions of\ngenerally accepted metrics is carried out to find the most relevant and\nrecommended versions of video quality metrics to be used in codecs comparisons.\nFor comparison, we used a set of videos encoded with video codecs of different\nstandards, and visual quality scores collected for the resulting set of streams\nsince 2018 until 2021",
          "link": "http://arxiv.org/abs/2107.10220",
          "publishedOn": "2021-07-22T02:03:11.092Z",
          "wordCount": 584,
          "title": "Objective video quality metrics application to video codecs comparisons: choosing the best for subjective quality estimation. (arXiv:2107.10220v1 [cs.MM])"
        },
        {
          "id": "http://arxiv.org/abs/2005.02356",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Chen_S/0/1/0/all/0/1\">Shixiang Chen</a>, <a href=\"http://arxiv.org/find/math/1/au:+Deng_Z/0/1/0/all/0/1\">Zengde Deng</a>, <a href=\"http://arxiv.org/find/math/1/au:+Ma_S/0/1/0/all/0/1\">Shiqian Ma</a>, <a href=\"http://arxiv.org/find/math/1/au:+So_A/0/1/0/all/0/1\">Anthony Man-Cho So</a>",
          "description": "We consider the problem of maximizing the $\\ell_1$ norm of a linear map over\nthe sphere, which arises in various machine learning applications such as\northogonal dictionary learning (ODL) and robust subspace recovery (RSR). The\nproblem is numerically challenging due to its nonsmooth objective and nonconvex\nconstraint, and its algorithmic aspects have not been well explored. In this\npaper, we show how the manifold structure of the sphere can be exploited to\ndesign fast algorithms for tackling this problem. Specifically, our\ncontribution is threefold. First, we present a manifold proximal point\nalgorithm (ManPPA) for the problem and show that it converges at a sublinear\nrate. Furthermore, we show that ManPPA can achieve a quadratic convergence rate\nwhen applied to the ODL and RSR problems. Second, we propose a stochastic\nvariant of ManPPA called StManPPA, which is well suited for large-scale\ncomputation, and establish its sublinear convergence rate. Both ManPPA and\nStManPPA have provably faster convergence rates than existing subgradient-type\nmethods. Third, using ManPPA as a building block, we propose a new approach to\nsolving a matrix analog of the problem, in which the sphere is replaced by the\nStiefel manifold. The results from our extensive numerical experiments on the\nODL and RSR problems demonstrate the efficiency and efficacy of our proposed\nmethods.",
          "link": "http://arxiv.org/abs/2005.02356",
          "publishedOn": "2021-07-22T02:03:11.069Z",
          "wordCount": 701,
          "title": "Manifold Proximal Point Algorithms for Dual Principal Component Pursuit and Orthogonal Dictionary Learning. (arXiv:2005.02356v2 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.10180",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Eschweiler_D/0/1/0/all/0/1\">Dennis Eschweiler</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rethwisch_M/0/1/0/all/0/1\">Malte Rethwisch</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jarchow_M/0/1/0/all/0/1\">Mareike Jarchow</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Koppers_S/0/1/0/all/0/1\">Simon Koppers</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Stegmaier_J/0/1/0/all/0/1\">Johannes Stegmaier</a>",
          "description": "Automated image processing approaches are indispensable for many biomedical\nexperiments and help to cope with the increasing amount of microscopy image\ndata in a fast and reproducible way. Especially state-of-the-art deep\nlearning-based approaches most often require large amounts of annotated\ntraining data to produce accurate and generalist outputs, but they are often\ncompromised by the general lack of those annotated data sets. In this work, we\npropose how conditional generative adversarial networks can be utilized to\ngenerate realistic image data for 3D fluorescence microscopy from annotation\nmasks of 3D cellular structures. In combination with mask simulation\napproaches, we demonstrate the generation of fully-annotated 3D microscopy data\nsets that we make publicly available for training or benchmarking. An\nadditional positional conditioning of the cellular structures enables the\nreconstruction of position-dependent intensity characteristics and allows to\ngenerate image data of different quality levels. A patch-wise working principle\nand a subsequent full-size reassemble strategy is used to generate image data\nof arbitrary size and different organisms. We present this as a\nproof-of-concept for the automated generation of fully-annotated training data\nsets requiring only a minimum of manual interaction to alleviate the need of\nmanual annotations.",
          "link": "http://arxiv.org/abs/2107.10180",
          "publishedOn": "2021-07-22T02:03:11.051Z",
          "wordCount": 642,
          "title": "3D fluorescence microscopy data synthesis for segmentation and benchmarking. (arXiv:2107.10180v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.10189",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bao_W/0/1/0/all/0/1\">Wentao Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Q/0/1/0/all/0/1\">Qi Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_Y/0/1/0/all/0/1\">Yu Kong</a>",
          "description": "Traffic accident anticipation aims to accurately and promptly predict the\noccurrence of a future accident from dashcam videos, which is vital for a\nsafety-guaranteed self-driving system. To encourage an early and accurate\ndecision, existing approaches typically focus on capturing the cues of spatial\nand temporal context before a future accident occurs. However, their\ndecision-making lacks visual explanation and ignores the dynamic interaction\nwith the environment. In this paper, we propose Deep ReInforced accident\nanticipation with Visual Explanation, named DRIVE. The method simulates both\nthe bottom-up and top-down visual attention mechanism in a dashcam observation\nenvironment so that the decision from the proposed stochastic multi-task agent\ncan be visually explained by attentive regions. Moreover, the proposed dense\nanticipation reward and sparse fixation reward are effective in training the\nDRIVE model with our improved reinforcement learning algorithm. Experimental\nresults show that the DRIVE model achieves state-of-the-art performance on\nmultiple real-world traffic accident datasets. The code and pre-trained model\nwill be available upon paper acceptance.",
          "link": "http://arxiv.org/abs/2107.10189",
          "publishedOn": "2021-07-22T02:03:11.042Z",
          "wordCount": 596,
          "title": "DRIVE: Deep Reinforced Accident Anticipation with Visual Explanation. (arXiv:2107.10189v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.10100",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shuailin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1\">Zhitong Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xuming He</a>",
          "description": "Learning segmentation from noisy labels is an important task for medical\nimage analysis due to the difficulty in acquiring highquality annotations. Most\nexisting methods neglect the pixel correlation and structural prior in\nsegmentation, often producing noisy predictions around object boundaries. To\naddress this, we adopt a superpixel representation and develop a robust\niterative learning strategy that combines noise-aware training of segmentation\nnetwork and noisy label refinement, both guided by the superpixels. This design\nenables us to exploit the structural constraints in segmentation labels and\neffectively mitigate the impact of label noise in learning. Experiments on two\nbenchmarks show that our method outperforms recent state-of-the-art approaches,\nand achieves superior robustness in a wide range of label noises. Code is\navailable at https://github.com/gaozhitong/SP_guided_Noisy_Label_Seg.",
          "link": "http://arxiv.org/abs/2107.10100",
          "publishedOn": "2021-07-22T02:03:10.973Z",
          "wordCount": 567,
          "title": "Superpixel-guided Iterative Learning from Noisy Labels for Medical Image Segmentation. (arXiv:2107.10100v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.10068",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lan_M/0/1/0/all/0/1\">Mengcheng Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ning_S/0/1/0/all/0/1\">Shuliang Ning</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yanran Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qian Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xunlai Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xiaoguang Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1\">Shuguang Cui</a>",
          "description": "Despite video forecasting has been a widely explored topic in recent years,\nthe mainstream of the existing work still limits their models with a single\nprediction space but completely neglects the way to leverage their model with\nmulti-prediction spaces. This work fills this gap. For the first time, we\ndeeply study numerous strategies to perform video forecasting in\nmulti-prediction spaces and fuse their results together to boost performance.\nThe prediction in the pixel space usually lacks the ability to preserve the\nsemantic and structure content of the video however the prediction in the\nhigh-level feature space is prone to generate errors in the reduction and\nrecovering process. Therefore, we build a recurrent connection between\ndifferent feature spaces and incorporate their generations in the upsampling\nprocess. Rather surprisingly, this simple idea yields a much more significant\nperformance boost than PhyDNet (performance improved by 32.1% MAE on MNIST-2\ndataset, and 21.4% MAE on KTH dataset). Both qualitative and quantitative\nevaluations on four datasets demonstrate the generalization ability and\neffectiveness of our approach. We show that our model significantly reduces the\ntroublesome distortions and blurry artifacts and brings remarkable improvements\nto the accuracy in long term video prediction. The code will be released soon.",
          "link": "http://arxiv.org/abs/2107.10068",
          "publishedOn": "2021-07-22T02:03:10.966Z",
          "wordCount": 649,
          "title": "From Single to Multiple: Leveraging Multi-level Prediction Spaces for Video Forecasting. (arXiv:2107.10068v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.10060",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hou_L/0/1/0/all/0/1\">Liang Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Q/0/1/0/all/0/1\">Qi Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1\">Huawei Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1\">Xueqi Cheng</a>",
          "description": "Conditional generative models aim to learn the underlying joint distribution\nof data and labels, and thus realize conditional generation. Among them,\nauxiliary classifier generative adversarial networks (AC-GAN) have been widely\nused, but suffer from the issue of low intra-class diversity on generated\nsamples. In this paper, we point out that the fundamental reason is that the\nclassifier of AC-GAN is generator-agnostic, and thus cannot provide informative\nguidance to the generator to approximate the target joint distribution, leading\nto a minimization of conditional entropy that decreases the intra-class\ndiversity. Based on this finding, we propose novel cGANs with auxiliary\ndiscriminative classifier (ADC-GAN) to address the issue of AC-GAN.\nSpecifically, the auxiliary discriminative classifier becomes generator-aware\nby distinguishing between the real and fake data while recognizing their\nlabels. We then optimize the generator based on the auxiliary classifier along\nwith the original discriminator to match the joint and marginal distributions\nof the generated samples with those of the real samples. We provide theoretical\nanalysis and empirical evidence on synthetic and real-world datasets to\ndemonstrate the superiority of the proposed ADC-GAN compared to competitive\ncGANs.",
          "link": "http://arxiv.org/abs/2107.10060",
          "publishedOn": "2021-07-22T02:03:10.958Z",
          "wordCount": 613,
          "title": "CGANs with Auxiliary Discriminative Classifier. (arXiv:2107.10060v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09989",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Li_G/0/1/0/all/0/1\">Guangyuan Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lv_J/0/1/0/all/0/1\">Jun Lv</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tong_X/0/1/0/all/0/1\">Xiangrong Tong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_C/0/1/0/all/0/1\">Chengyan Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_G/0/1/0/all/0/1\">Guang Yang</a>",
          "description": "Magnetic resonance imaging (MRI) is an important medical imaging modality,\nbut its acquisition speed is quite slow due to the physiological limitations.\nRecently, super-resolution methods have shown excellent performance in\naccelerating MRI. In some circumstances, it is difficult to obtain\nhigh-resolution images even with prolonged scan time. Therefore, we proposed a\nnovel super-resolution method that uses a generative adversarial network (GAN)\nwith cyclic loss and attention mechanism to generate high-resolution MR images\nfrom low-resolution MR images by a factor of 2. We implemented our model on\npelvic images from healthy subjects as training and validation data, while\nthose data from patients were used for testing. The MR dataset was obtained\nusing different imaging sequences, including T2, T2W SPAIR, and mDIXON-W. Four\nmethods, i.e., BICUBIC, SRCNN, SRGAN, and EDSR were used for comparison.\nStructural similarity, peak signal to noise ratio, root mean square error, and\nvariance inflation factor were used as calculation indicators to evaluate the\nperformances of the proposed method. Various experimental results showed that\nour method can better restore the details of the high-resolution MR image as\ncompared to the other methods. In addition, the reconstructed high-resolution\nMR image can provide better lesion textures in the tumor patients, which is\npromising to be used in clinical diagnosis.",
          "link": "http://arxiv.org/abs/2107.09989",
          "publishedOn": "2021-07-22T02:03:10.941Z",
          "wordCount": 677,
          "title": "High-Resolution Pelvic MRI Reconstruction Using a Generative Adversarial Network with Attention and Cyclic Loss. (arXiv:2107.09989v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.10004",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jaganathan_S/0/1/0/all/0/1\">Srikrishna Jaganathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jian Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borsdorf_A/0/1/0/all/0/1\">Anja Borsdorf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shetty_K/0/1/0/all/0/1\">Karthik Shetty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maier_A/0/1/0/all/0/1\">Andreas Maier</a>",
          "description": "Deep Learning-based 2D/3D registration methods are highly robust but often\nlack the necessary registration accuracy for clinical application. A refinement\nstep using the classical optimization-based 2D/3D registration method applied\nin combination with Deep Learning-based techniques can provide the required\naccuracy. However, it also increases the runtime. In this work, we propose a\nnovel Deep Learning driven 2D/3D registration framework that can be used\nend-to-end for iterative registration tasks without relying on any further\nrefinement step. We accomplish this by learning the update step of the 2D/3D\nregistration framework using Point-to-Plane Correspondences. The update step is\nlearned using iterative residual refinement-based optical flow estimation, in\ncombination with the Point-to-Plane correspondence solver embedded as a known\noperator. Our proposed method achieves an average runtime of around 8s, a mean\nre-projection distance error of 0.60 $\\pm$ 0.40 mm with a success ratio of 97\npercent and a capture range of 60 mm. The combination of high registration\naccuracy, high robustness, and fast runtime makes our solution ideal for\nclinical applications.",
          "link": "http://arxiv.org/abs/2107.10004",
          "publishedOn": "2021-07-22T02:03:10.805Z",
          "wordCount": 616,
          "title": "Deep Iterative 2D/3D Registration. (arXiv:2107.10004v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09957",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Patel_D/0/1/0/all/0/1\">Deep Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sastry_P/0/1/0/all/0/1\">P.S. Sastry</a>",
          "description": "Deep Neural Networks, often owing to the overparameterization, are shown to\nbe capable of exactly memorizing even randomly labelled data. Empirical studies\nhave also shown that none of the standard regularization techniques mitigate\nsuch overfitting. We investigate whether the choice of the loss function can\naffect this memorization. We empirically show, with benchmark data sets MNIST\nand CIFAR-10, that a symmetric loss function, as opposed to either\ncross-entropy or squared error loss, results in significant improvement in the\nability of the network to resist such overfitting. We then provide a formal\ndefinition for robustness to memorization and provide a theoretical explanation\nas to why the symmetric losses provide this robustness. Our results clearly\nbring out the role loss functions alone can play in this phenomenon of\nmemorization.",
          "link": "http://arxiv.org/abs/2107.09957",
          "publishedOn": "2021-07-22T02:03:10.645Z",
          "wordCount": 579,
          "title": "Memorization in Deep Neural Networks: Does the Loss Function matter?. (arXiv:2107.09957v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09965",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Noeckel_J/0/1/0/all/0/1\">James Noeckel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Haisen Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Curless_B/0/1/0/all/0/1\">Brian Curless</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schulz_A/0/1/0/all/0/1\">Adriana Schulz</a>",
          "description": "We propose a novel method to generate fabrication blueprints from images of\ncarpentered items. While 3D reconstruction from images is a well-studied\nproblem, typical approaches produce representations that are ill-suited for\ncomputer-aided design and fabrication applications. Our key insight is that\nfabrication processes define and constrain the design space for carpentered\nobjects, and can be leveraged to develop novel reconstruction methods. Our\nmethod makes use of domain-specific constraints to recover not just valid\ngeometry, but a semantically valid assembly of parts, using a combination of\nimage-based and geometric optimization techniques.\n\nWe demonstrate our method on a variety of wooden objects and furniture, and\nshow that we can automatically obtain designs that are both easy to edit and\naccurate recreations of the ground truth. We further illustrate how our method\ncan be used to fabricate a physical replica of the captured object as well as a\ncustomized version, which can be produced by directly editing the reconstructed\nmodel in CAD software.",
          "link": "http://arxiv.org/abs/2107.09965",
          "publishedOn": "2021-07-22T02:03:10.621Z",
          "wordCount": 618,
          "title": "Fabrication-Aware Reverse Engineering for Carpentry. (arXiv:2107.09965v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09903",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_N/0/1/0/all/0/1\">Ning Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_K/0/1/0/all/0/1\">Kaitao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1\">Zhiheng Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1\">Xing Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_X/0/1/0/all/0/1\">Xiaopeng Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1\">Yihong Gong</a>",
          "description": "Anomaly detection plays a key role in industrial manufacturing for product\nquality control. Traditional methods for anomaly detection are rule-based with\nlimited generalization ability. Recent methods based on supervised deep\nlearning are more powerful but require large-scale annotated datasets for\ntraining. In practice, abnormal products are rare thus it is very difficult to\ntrain a deep model in a fully supervised way. In this paper, we propose a novel\nunsupervised anomaly detection approach based on Self-organizing Map (SOM). Our\nmethod, Self-organizing Map for Anomaly Detection (SOMAD) maintains normal\ncharacteristics by using topological memory based on multi-scale features.\nSOMAD achieves state-of the-art performance on unsupervised anomaly detection\nand localization on the MVTec dataset.",
          "link": "http://arxiv.org/abs/2107.09903",
          "publishedOn": "2021-07-22T02:03:10.614Z",
          "wordCount": 553,
          "title": "Anomaly Detection via Self-organizing Map. (arXiv:2107.09903v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09847",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shin_M/0/1/0/all/0/1\">Minjung Shin</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jeonghoon Kim</a> (1 and 2), <a href=\"http://arxiv.org/find/cs/1/au:+Choi_S/0/1/0/all/0/1\">Seongho Choi</a> (3), <a href=\"http://arxiv.org/find/cs/1/au:+Heo_Y/0/1/0/all/0/1\">Yu-Jung Heo</a> (3), <a href=\"http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1\">Donghyun Kim</a> (1 and 4), <a href=\"http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1\">Minsu Lee</a> (3 and 5), <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Byoung-Tak Zhang</a> (3 and 5), <a href=\"http://arxiv.org/find/cs/1/au:+Ryu_J/0/1/0/all/0/1\">Jeh-Kwang Ryu</a> (1 and 4) ((1) Laboratory for Natural and Artificial Kin&#xe4;sthese, Convergence Research Center for Artificial Intelligence (CRC4AI), Dongguk University, Seoul, South Korea, (2) Department of Artificial Intelligence, Dongguk University, Seoul, South Korea, (3) Biointelligence Laboratory, Department of Computer Science and Engineering, Seoul National University, Seoul, South Korea, (4) Department of Physical Education, College of Education, Dongguk University, Seoul, South Korea, (5) AI Institute of Seoul National University (AIIS), Seoul, South Korea)",
          "description": "Developing video understanding intelligence is quite challenging because it\nrequires holistic integration of images, scripts, and sounds based on natural\nlanguage processing, temporal dependency, and reasoning. Recently, substantial\nattempts have been made on several video datasets with associated question\nanswering (QA) on a large scale. However, existing evaluation metrics for video\nquestion answering (VideoQA) do not provide meaningful analysis. To make\nprogress, we argue that a well-made framework, established on the way humans\nunderstand, is required to explain and evaluate the performance of\nunderstanding in detail. Then we propose a top-down evaluation system for\nVideoQA, based on the cognitive process of humans and story elements: Cognitive\nModules for Evaluation (CogME). CogME is composed of three cognitive modules:\ntargets, contents, and thinking. The interaction among the modules in the\nunderstanding procedure can be expressed in one sentence as follows: \"I\nunderstand the CONTENT of the TARGET through a way of THINKING.\" Each module\nhas sub-components derived from the story elements. We can specify the required\naspects of understanding by annotating the sub-components to individual\nquestions. CogME thus provides a framework for an elaborated specification of\nVideoQA datasets. To examine the suitability of a VideoQA dataset for\nvalidating video understanding intelligence, we evaluated the baseline model of\nthe DramaQA dataset by applying CogME. The evaluation reveals that story\nelements are unevenly reflected in the existing dataset, and the model based on\nthe dataset may cause biased predictions. Although this study has only been\nable to grasp a narrow range of stories, we expect that it offers the first\nstep in considering the cognitive process of humans on the video understanding\nintelligence of humans and AI.",
          "link": "http://arxiv.org/abs/2107.09847",
          "publishedOn": "2021-07-22T02:03:10.603Z",
          "wordCount": 818,
          "title": "CogME: A Novel Evaluation Metric for Video Understanding Intelligence. (arXiv:2107.09847v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09953",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1\">Junren Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_B/0/1/0/all/0/1\">Baiying Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yanyan Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1\">Zhiguang Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuqiang Wang</a>",
          "description": "Using multimodal neuroimaging data to characterize brain network is currently\nan advanced technique for Alzheimer's disease(AD) Analysis. Over recent years\nthe neuroimaging community has made tremendous progress in the study of\nresting-state functional magnetic resonance imaging (rs-fMRI) derived from\nblood-oxygen-level-dependent (BOLD) signals and Diffusion Tensor Imaging (DTI)\nderived from white matter fiber tractography. However, Due to the heterogeneity\nand complexity between BOLD signals and fiber tractography, Most existing\nmultimodal data fusion algorithms can not sufficiently take advantage of the\ncomplementary information between rs-fMRI and DTI. To overcome this problem, a\nnovel Hypergraph Generative Adversarial Networks(HGGAN) is proposed in this\npaper, which utilizes Interactive Hyperedge Neurons module (IHEN) and Optimal\nHypergraph Homomorphism algorithm(OHGH) to generate multimodal connectivity of\nBrain Network from rs-fMRI combination with DTI. To evaluate the performance of\nthis model, We use publicly available data from the ADNI database to\ndemonstrate that the proposed model not only can identify discriminative brain\nregions of AD but also can effectively improve classification performance.",
          "link": "http://arxiv.org/abs/2107.09953",
          "publishedOn": "2021-07-22T02:03:10.595Z",
          "wordCount": 612,
          "title": "Characterization Multimodal Connectivity of Brain Network by Hypergraph GAN for Alzheimer's Disease Analysis. (arXiv:2107.09953v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09909",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hong_H/0/1/0/all/0/1\">Haiwen Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1\">Xuan Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yunqing Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jingfeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yuan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_H/0/1/0/all/0/1\">Hui Xue</a>",
          "description": "In multimodal tasks, we find that the importance of text and image modal\ninformation is different for different input cases, and for this motivation, we\npropose a high-performance and highly general Dual-Router Dynamic Framework\n(DRDF), consisting of Dual-Router, MWF-Layer, experts and expert fusion unit.\nThe text router and image router in Dual-Router accept text modal information\nand image modal information, and use MWF-Layer to determine the importance of\nmodal information. Based on the result of the determination, MWF-Layer\ngenerates fused weights for the fusion of experts. Experts are model backbones\nthat match the current task. DRDF has high performance and high generality, and\nwe have tested 12 backbones such as Visual BERT on multimodal dataset Hateful\nmemes, unimodal dataset CIFAR10, CIFAR100, and TinyImagenet. Our DRDF\noutperforms all the baselines. We also verified the components of DRDF in\ndetail by ablations, compared and discussed the reasons and ideas of DRDF\ndesign.",
          "link": "http://arxiv.org/abs/2107.09909",
          "publishedOn": "2021-07-22T02:03:10.586Z",
          "wordCount": 600,
          "title": "DRDF: Determining the Importance of Different Multimodal Information with Dual-Router Dynamic Framework. (arXiv:2107.09909v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09928",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zuo_Q/0/1/0/all/0/1\">Qiankun Zuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_B/0/1/0/all/0/1\">Baiying Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yanyan Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1\">Zhiguang Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuqiang Wang</a>",
          "description": "Multimodal neuroimage can provide complementary information about the\ndementia, but small size of complete multimodal data limits the ability in\nrepresentation learning. Moreover, the data distribution inconsistency from\ndifferent modalities may lead to ineffective fusion, which fails to\nsufficiently explore the intra-modal and inter-modal interactions and\ncompromises the disease diagnosis performance. To solve these problems, we\nproposed a novel multimodal representation learning and adversarial hypergraph\nfusion (MRL-AHF) framework for Alzheimer's disease diagnosis using complete\ntrimodal images. First, adversarial strategy and pre-trained model are\nincorporated into the MRL to extract latent representations from multimodal\ndata. Then two hypergraphs are constructed from the latent representations and\nthe adversarial network based on graph convolution is employed to narrow the\ndistribution difference of hyperedge features. Finally, the hyperedge-invariant\nfeatures are fused for disease prediction by hyperedge convolution. Experiments\non the public Alzheimer's Disease Neuroimaging Initiative(ADNI) database\ndemonstrate that our model achieves superior performance on Alzheimer's disease\ndetection compared with other related models and provides a possible way to\nunderstand the underlying mechanisms of disorder's progression by analyzing the\nabnormal brain connections.",
          "link": "http://arxiv.org/abs/2107.09928",
          "publishedOn": "2021-07-22T02:03:10.561Z",
          "wordCount": 630,
          "title": "Multimodal Representations Learning and Adversarial Hypergraph Fusion for Early Alzheimer's Disease Prediction. (arXiv:2107.09928v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09725",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singandhupe_A/0/1/0/all/0/1\">Ashutosh Singandhupe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+La_H/0/1/0/all/0/1\">Hung La</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ngo_T/0/1/0/all/0/1\">Trung Dung Ngo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ho_V/0/1/0/all/0/1\">Van Ho</a>",
          "description": "This work focuses on Registration or Alignment of 3D point sets. Although the\nRegistration problem is a well established problem and it's solved using\nmultiple variants of Iterative Closest Point (ICP) Algorithm, most of the\napproaches in the current state of the art still suffers from misalignment when\nthe \\textit{Source} and the \\textit{Target} point sets are separated by large\nrotations and translation. In this work, we propose a variant of the Standard\nICP algorithm, where we introduce a Correntropy Relationship Matrix in the\ncomputation of rotation and translation component which attempts to solve the\nlarge rotation and translation problem between \\textit{Source} and\n\\textit{Target} point sets. This matrix is created through correntropy\ncriterion which is updated in every iteration. The correntropy criterion\ndefined in this approach maintains the relationship between the points in the\n\\textit{Source} dataset and the \\textit{Target} dataset. Through our\nexperiments and validation we verify that our approach has performed well under\nvarious rotation and translation in comparison to the other well-known state of\nthe art methods available in the Point Cloud Library (PCL) as well as other\nmethods available as open source. We have uploaded our code in the github\nrepository for the readers to validate and verify our approach\nhttps://github.com/aralab-unr/CoSM-ICP.",
          "link": "http://arxiv.org/abs/2107.09725",
          "publishedOn": "2021-07-22T02:03:10.487Z",
          "wordCount": 644,
          "title": "Registration of 3D Point Sets Using Correntropy Similarity Matrix. (arXiv:2107.09725v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09899",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1\">Runnan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yuexin Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1\">Nenglun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lingjie Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_Z/0/1/0/all/0/1\">Zhiming Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yanhong Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenping Wang</a>",
          "description": "Detecting 3D landmarks on cone-beam computed tomography (CBCT) is crucial to\nassessing and quantifying the anatomical abnormalities in 3D cephalometric\nanalysis. However, the current methods are time-consuming and suffer from large\nbiases in landmark localization, leading to unreliable diagnosis results. In\nthis work, we propose a novel Structure-Aware Long Short-Term Memory framework\n(SA-LSTM) for efficient and accurate 3D landmark detection. To reduce the\ncomputational burden, SA-LSTM is designed in two stages. It first locates the\ncoarse landmarks via heatmap regression on a down-sampled CBCT volume and then\nprogressively refines landmarks by attentive offset regression using\nhigh-resolution cropped patches. To boost accuracy, SA-LSTM captures\nglobal-local dependence among the cropping patches via self-attention.\nSpecifically, a graph attention module implicitly encodes the landmark's global\nstructure to rationalize the predicted position. Furthermore, a novel\nattention-gated module recursively filters irrelevant local features and\nmaintains high-confident local predictions for aggregating the final result.\nExperiments show that our method significantly outperforms state-of-the-art\nmethods in terms of efficiency and accuracy on an in-house dataset and a public\ndataset, achieving 1.64 mm and 2.37 mm average errors, respectively, and using\nonly 0.5 seconds for inferring the whole CBCT volume of resolution 768*768*576.\nMoreover, all predicted landmarks are within 8 mm error, which is vital for\nacceptable cephalometric analysis.",
          "link": "http://arxiv.org/abs/2107.09899",
          "publishedOn": "2021-07-22T02:03:10.480Z",
          "wordCount": 655,
          "title": "Structure-Aware Long Short-Term Memory Network for 3D Cephalometric Landmark Detection. (arXiv:2107.09899v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09843",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jiawei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yuan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1\">Lei He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1\">Zhiqiang He</a>",
          "description": "Deep learning models are notoriously data-hungry. Thus, there is an urging\nneed for data-efficient techniques in medical image analysis, where\nwell-annotated data are costly and time consuming to collect. Motivated by the\nrecently revived \"Copy-Paste\" augmentation, we propose TumorCP, a simple but\neffective object-level data augmentation method tailored for tumor\nsegmentation. TumorCP is online and stochastic, providing unlimited\naugmentation possibilities for tumors' subjects, locations, appearances, as\nwell as morphologies. Experiments on kidney tumor segmentation task demonstrate\nthat TumorCP surpasses the strong baseline by a remarkable margin of 7.12% on\ntumor Dice. Moreover, together with image-level data augmentation, it beats the\ncurrent state-of-the-art by 2.32% on tumor Dice. Comprehensive ablation studies\nare performed to validate the effectiveness of TumorCP. Meanwhile, we show that\nTumorCP can lead to striking improvements in extremely low-data regimes.\nEvaluated with only 10% labeled data, TumorCP significantly boosts tumor Dice\nby 21.87%. To the best of our knowledge, this is the very first work exploring\nand extending the \"Copy-Paste\" design in medical imaging domain. Code is\navailable at: https://github.com/YaoZhang93/TumorCP.",
          "link": "http://arxiv.org/abs/2107.09843",
          "publishedOn": "2021-07-22T02:03:10.472Z",
          "wordCount": 619,
          "title": "TumorCP: A Simple but Effective Object-Level Data Augmentation for Tumor Segmentation. (arXiv:2107.09843v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09887",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lewy_D/0/1/0/all/0/1\">Dominik Lewy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mandziuk_J/0/1/0/all/0/1\">Jacek Ma&#x144;dziuk</a>",
          "description": "Deep Convolutional Neural Networks have made an incredible progress in many\nComputer Vision tasks. This progress, however, often relies on the availability\nof large amounts of the training data, required to prevent over-fitting, which\nin many domains entails significant cost of manual data labeling. An\nalternative approach is application of data augmentation (DA) techniques that\naim at model regularization by creating additional observations from the\navailable ones. This survey focuses on two DA research streams: image mixing\nand automated selection of augmentation strategies. First, the presented\nmethods are briefly described, and then qualitatively compared with respect to\ntheir key characteristics. Various quantitative comparisons are also included\nbased on the results reported in recent DA literature. This review mainly\ncovers the methods published in the materials of top-tier conferences and in\nleading journals in the years 2017-2021.",
          "link": "http://arxiv.org/abs/2107.09887",
          "publishedOn": "2021-07-22T02:03:10.455Z",
          "wordCount": 570,
          "title": "An overview of mixing augmentation methods and augmentation strategies. (arXiv:2107.09887v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09892",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sudarshan_V/0/1/0/all/0/1\">Viswanath P. Sudarshan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Upadhyay_U/0/1/0/all/0/1\">Uddeshya Upadhyay</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Egan_G/0/1/0/all/0/1\">Gary F. Egan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_Z/0/1/0/all/0/1\">Zhaolin Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Awate_S/0/1/0/all/0/1\">Suyash P. Awate</a>",
          "description": "Radiation exposure in positron emission tomography (PET) imaging limits its\nusage in the studies of radiation-sensitive populations, e.g., pregnant women,\nchildren, and adults that require longitudinal imaging. Reducing the PET\nradiotracer dose or acquisition time reduces photon counts, which can\ndeteriorate image quality. Recent deep-neural-network (DNN) based methods for\nimage-to-image translation enable the mapping of low-quality PET images\n(acquired using substantially reduced dose), coupled with the associated\nmagnetic resonance imaging (MRI) images, to high-quality PET images. However,\nsuch DNN methods focus on applications involving test data that match the\nstatistical characteristics of the training data very closely and give little\nattention to evaluating the performance of these DNNs on new\nout-of-distribution (OOD) acquisitions. We propose a novel DNN formulation that\nmodels the (i) underlying sinogram-based physics of the PET imaging system and\n(ii) the uncertainty in the DNN output through the per-voxel heteroscedasticity\nof the residuals between the predicted and the high-quality reference images.\nOur sinogram-based uncertainty-aware DNN framework, namely, suDNN, estimates a\nstandard-dose PET image using multimodal input in the form of (i) a\nlow-dose/low-count PET image and (ii) the corresponding multi-contrast MRI\nimages, leading to improved robustness of suDNN to OOD acquisitions. Results on\nin vivo simultaneous PET-MRI, and various forms of OOD data in PET-MRI, show\nthe benefits of suDNN over the current state of the art, quantitatively and\nqualitatively.",
          "link": "http://arxiv.org/abs/2107.09892",
          "publishedOn": "2021-07-22T02:03:10.273Z",
          "wordCount": 699,
          "title": "Towards Lower-Dose PET using Physics-Based Uncertainty-Aware Multimodal Learning with Robustness to Out-of-Distribution Data. (arXiv:2107.09892v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09700",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Hong_S/0/1/0/all/0/1\">Sungmin Hong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Marinescu_R/0/1/0/all/0/1\">Razvan Marinescu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dalca_A/0/1/0/all/0/1\">Adrian V. Dalca</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bonkhoff_A/0/1/0/all/0/1\">Anna K. Bonkhoff</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bretzner_M/0/1/0/all/0/1\">Martin Bretzner</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rost_N/0/1/0/all/0/1\">Natalia S. Rost</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Golland_P/0/1/0/all/0/1\">Polina Golland</a>",
          "description": "Image synthesis via Generative Adversarial Networks (GANs) of\nthree-dimensional (3D) medical images has great potential that can be extended\nto many medical applications, such as, image enhancement and disease\nprogression modeling. However, current GAN technologies for 3D medical image\nsynthesis need to be significantly improved to be readily adapted to real-world\nmedical problems. In this paper, we extend the state-of-the-art StyleGAN2\nmodel, which natively works with two-dimensional images, to enable 3D image\nsynthesis. In addition to the image synthesis, we investigate the\ncontrollability and interpretability of the 3D-StyleGAN via style vectors\ninherited form the original StyleGAN2 that are highly suitable for medical\napplications: (i) the latent space projection and reconstruction of unseen real\nimages, and (ii) style mixing. We demonstrate the 3D-StyleGAN's performance and\nfeasibility with ~12,000 three-dimensional full brain MR T1 images, although it\ncan be applied to any 3D volumetric images. Furthermore, we explore different\nconfigurations of hyperparameters to investigate potential improvement of the\nimage synthesis with larger networks. The codes and pre-trained networks are\navailable online: https://github.com/sh4174/3DStyleGAN.",
          "link": "http://arxiv.org/abs/2107.09700",
          "publishedOn": "2021-07-22T02:03:10.256Z",
          "wordCount": 664,
          "title": "3D-StyleGAN: A Style-Based Generative Adversarial Network for Generative Modeling of Three-Dimensional Medical Images. (arXiv:2107.09700v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09858",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cho_Y/0/1/0/all/0/1\">Yeong-Jun Cho</a>",
          "description": "In this paper, we propose a novel evaluation metric for performance\nevaluation of semantic segmentation. In recent years, many studies have tried\nto train pixel-level classifiers on large-scale image datasets to perform\naccurate semantic segmentation. The goal of semantic segmentation is to assign\na class label of each pixel in the scene. It has various potential applications\nin computer vision fields e.g., object detection, classification, scene\nunderstanding and Etc. To validate the proposed wIoU evaluation metric, we\ntested state-of-the art methods on public benchmark datasets (e.g., KITTI)\nbased on the proposed wIoU metric and compared with other conventional\nevaluation metrics.",
          "link": "http://arxiv.org/abs/2107.09858",
          "publishedOn": "2021-07-22T02:03:10.210Z",
          "wordCount": 537,
          "title": "Weighted Intersection over Union (wIoU): A New Evaluation Metric for Image Segmentation. (arXiv:2107.09858v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09783",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rochan_M/0/1/0/all/0/1\">Mrigank Rochan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aich_S/0/1/0/all/0/1\">Shubhra Aich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Corral_Soto_E/0/1/0/all/0/1\">Eduardo R. Corral-Soto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nabatchian_A/0/1/0/all/0/1\">Amir Nabatchian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bingbing Liu</a>",
          "description": "In this paper, we focus on a less explored, but more realistic and complex\nproblem of domain adaptation in LiDAR semantic segmentation. There is a\nsignificant drop in performance of an existing segmentation model when training\n(source domain) and testing (target domain) data originate from different LiDAR\nsensors. To overcome this shortcoming, we propose an unsupervised domain\nadaptation framework that leverages unlabeled target domain data for\nself-supervision, coupled with an unpaired mask transfer strategy to mitigate\nthe impact of domain shifts. Furthermore, we introduce gated adapter modules\nwith a small number of parameters into the network to account for target\ndomain-specific information. Experiments adapting from both real-to-real and\nsynthetic-to-real LiDAR semantic segmentation benchmarks demonstrate the\nsignificant improvement over prior arts.",
          "link": "http://arxiv.org/abs/2107.09783",
          "publishedOn": "2021-07-22T02:03:10.176Z",
          "wordCount": 567,
          "title": "Unsupervised Domain Adaptation in LiDAR Semantic Segmentation with Self-Supervision and Gated Adapters. (arXiv:2107.09783v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09609",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lei_J/0/1/0/all/0/1\">Jie Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berg_T/0/1/0/all/0/1\">Tamara L. Berg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>",
          "description": "Detecting customized moments and highlights from videos given natural\nlanguage (NL) user queries is an important but under-studied topic. One of the\nchallenges in pursuing this direction is the lack of annotated data. To address\nthis issue, we present the Query-based Video Highlights (QVHighlights) dataset.\nIt consists of over 10,000 YouTube videos, covering a wide range of topics,\nfrom everyday activities and travel in lifestyle vlog videos to social and\npolitical activities in news videos. Each video in the dataset is annotated\nwith: (1) a human-written free-form NL query, (2) relevant moments in the video\nw.r.t. the query, and (3) five-point scale saliency scores for all\nquery-relevant clips. This comprehensive annotation enables us to develop and\nevaluate systems that detect relevant moments as well as salient highlights for\ndiverse, flexible user queries. We also present a strong baseline for this\ntask, Moment-DETR, a transformer encoder-decoder model that views moment\nretrieval as a direct set prediction problem, taking extracted video and query\nrepresentations as inputs and predicting moment coordinates and saliency scores\nend-to-end. While our model does not utilize any human prior, we show that it\nperforms competitively when compared to well-engineered architectures. With\nweakly supervised pretraining using ASR captions, Moment-DETR substantially\noutperforms previous methods. Lastly, we present several ablations and\nvisualizations of Moment-DETR. Data and code is publicly available at\nhttps://github.com/jayleicn/moment_detr",
          "link": "http://arxiv.org/abs/2107.09609",
          "publishedOn": "2021-07-21T02:01:37.296Z",
          "wordCount": 680,
          "title": "QVHighlights: Detecting Moments and Highlights in Videos via Natural Language Queries. (arXiv:2107.09609v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09391",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gulshad_S/0/1/0/all/0/1\">Sadaf Gulshad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sosnovik_I/0/1/0/all/0/1\">Ivan Sosnovik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smeulders_A/0/1/0/all/0/1\">Arnold Smeulders</a>",
          "description": "We focus on building robustness in the convolutions of neural visual\nclassifiers, especially against natural perturbations like elastic\ndeformations, occlusions and Gaussian noise. Existing CNNs show outstanding\nperformance on clean images, but fail to tackle naturally occurring\nperturbations. In this paper, we start from elastic perturbations, which\napproximate (local) view-point changes of the object. We present\nelastically-augmented convolutions (EAConv) by parameterizing filters as a\ncombination of fixed elastically-perturbed bases functions and trainable\nweights for the purpose of integrating unseen viewpoints in the CNN. We show on\nCIFAR-10 and STL-10 datasets that the general robustness of our method on\nunseen occlusion and Gaussian perturbations improves, while even improving the\nperformance on clean images slightly without performing any data augmentation.",
          "link": "http://arxiv.org/abs/2107.09391",
          "publishedOn": "2021-07-21T02:01:37.289Z",
          "wordCount": 556,
          "title": "Built-in Elastic Transformations for Improved Robustness. (arXiv:2107.09391v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2006.14435",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1\">Wenbin Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teng_Q/0/1/0/all/0/1\">Qi Teng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Hao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jun He</a>",
          "description": "Human activity recognition (HAR) in ubiquitous computing has been beginning\nto incorporate attention into the context of deep neural networks (DNNs), in\nwhich the rich sensing data from multimodal sensors such as accelerometer and\ngyroscope is used to infer human activities. Recently, two attention methods\nare proposed via combining with Gated Recurrent Units (GRU) and Long Short-Term\nMemory (LSTM) network, which can capture the dependencies of sensing signals in\nboth spatial and temporal domains simultaneously. However, recurrent networks\noften have a weak feature representing power compared with convolutional neural\nnetworks (CNNs). On the other hand, two attention, i.e., hard attention and\nsoft attention, are applied in temporal domains via combining with CNN, which\npay more attention to the target activity from a long sequence. However, they\ncan only tell where to focus and miss channel information, which plays an\nimportant role in deciding what to focus. As a result, they fail to address the\nspatial-temporal dependencies of multimodal sensing signals, compared with\nattention-based GRU or LSTM. In the paper, we propose a novel dual attention\nmethod called DanHAR, which introduces the framework of blending channel\nattention and temporal attention on a CNN, demonstrating superiority in\nimproving the comprehensibility for multimodal HAR. Extensive experiments on\nfour public HAR datasets and weakly labeled dataset show that DanHAR achieves\nstate-of-the-art performance with negligible overhead of parameters.\nFurthermore, visualizing analysis is provided to show that our attention can\namplifies more important sensor modalities and timesteps during classification,\nwhich agrees well with human common intuition.",
          "link": "http://arxiv.org/abs/2006.14435",
          "publishedOn": "2021-07-21T02:01:36.612Z",
          "wordCount": 734,
          "title": "DanHAR: Dual Attention Network For Multimodal Human Activity Recognition Using Wearable Sensors. (arXiv:2006.14435v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.09652",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Montenegro_H/0/1/0/all/0/1\">H. Montenegro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silva_W/0/1/0/all/0/1\">W. Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cardoso_J/0/1/0/all/0/1\">J. S. Cardoso</a>",
          "description": "The use of Deep Learning in the medical field is hindered by the lack of\ninterpretability. Case-based interpretability strategies can provide intuitive\nexplanations for deep learning models' decisions, thus, enhancing trust.\nHowever, the resulting explanations threaten patient privacy, motivating the\ndevelopment of privacy-preserving methods compatible with the specifics of\nmedical data. In this work, we analyze existing privacy-preserving methods and\ntheir respective capacity to anonymize medical data while preserving\ndisease-related semantic features. We find that the PPRL-VGAN deep learning\nmethod was the best at preserving the disease-related semantic features while\nguaranteeing a high level of privacy among the compared state-of-the-art\nmethods. Nevertheless, we emphasize the need to improve privacy-preserving\nmethods for medical imaging, as we identified relevant drawbacks in all\nexisting privacy-preserving approaches.",
          "link": "http://arxiv.org/abs/2107.09652",
          "publishedOn": "2021-07-21T02:01:36.586Z",
          "wordCount": 571,
          "title": "Towards Privacy-preserving Explanations in Medical Image Analysis. (arXiv:2107.09652v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.03620",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yuliang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1\">Chunhua Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_L/0/1/0/all/0/1\">Lianwen Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_T/0/1/0/all/0/1\">Tong He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1\">Peng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chongyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hao Chen</a>",
          "description": "End-to-end text-spotting, which aims to integrate detection and recognition\nin a unified framework, has attracted increasing attention due to its\nsimplicity of the two complimentary tasks. It remains an open problem\nespecially when processing arbitrarily-shaped text instances. Previous methods\ncan be roughly categorized into two groups: character-based and\nsegmentation-based, which often require character-level annotations and/or\ncomplex post-processing due to the unstructured output. Here, we tackle\nend-to-end text spotting by presenting Adaptive Bezier Curve Network v2 (ABCNet\nv2). Our main contributions are four-fold: 1) For the first time, we adaptively\nfit arbitrarily-shaped text by a parameterized Bezier curve, which, compared\nwith segmentation-based methods, can not only provide structured output but\nalso controllable representation. 2) We design a novel BezierAlign layer for\nextracting accurate convolution features of a text instance of arbitrary\nshapes, significantly improving the precision of recognition over previous\nmethods. 3) Different from previous methods, which often suffer from complex\npost-processing and sensitive hyper-parameters, our ABCNet v2 maintains a\nsimple pipeline with the only post-processing non-maximum suppression (NMS). 4)\nAs the performance of text recognition closely depends on feature alignment,\nABCNet v2 further adopts a simple yet effective coordinate convolution to\nencode the position of the convolutional filters, which leads to a considerable\nimprovement with negligible computation overhead. Comprehensive experiments\nconducted on various bilingual (English and Chinese) benchmark datasets\ndemonstrate that ABCNet v2 can achieve state-of-the-art performance while\nmaintaining very high efficiency.",
          "link": "http://arxiv.org/abs/2105.03620",
          "publishedOn": "2021-07-21T02:01:36.398Z",
          "wordCount": 728,
          "title": "ABCNet v2: Adaptive Bezier-Curve Network for Real-time End-to-end Text Spotting. (arXiv:2105.03620v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08982",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_D/0/1/0/all/0/1\">Dahu Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1\">Xing Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1\">Xiaodong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_W/0/1/0/all/0/1\">Wenming Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_Y/0/1/0/all/0/1\">Ye Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pu_S/0/1/0/all/0/1\">Shiliang Pu</a>",
          "description": "Multi-person pose estimation is an attractive and challenging task. Existing\nmethods are mostly based on two-stage frameworks, which include top-down and\nbottom-up methods. Two-stage methods either suffer from high computational\nredundancy for additional person detectors or they need to group keypoints\nheuristically after predicting all the instance-agnostic keypoints. The\nsingle-stage paradigm aims to simplify the multi-person pose estimation\npipeline and receives a lot of attention. However, recent single-stage methods\nhave the limitation of low performance due to the difficulty of regressing\nvarious full-body poses from a single feature vector. Different from previous\nsolutions that involve complex heuristic designs, we present a simple yet\neffective solution by employing instance-aware dynamic networks. Specifically,\nwe propose an instance-aware module to adaptively adjust (part of) the network\nparameters for each instance. Our solution can significantly increase the\ncapacity and adaptive-ability of the network for recognizing various poses,\nwhile maintaining a compact end-to-end trainable pipeline. Extensive\nexperiments on the MS-COCO dataset demonstrate that our method achieves\nsignificant improvement over existing single-stage methods, and makes a better\nbalance of accuracy and efficiency compared to the state-of-the-art two-stage\napproaches.",
          "link": "http://arxiv.org/abs/2107.08982",
          "publishedOn": "2021-07-21T02:01:36.213Z",
          "wordCount": 662,
          "title": "InsPose: Instance-Aware Networks for Single-Stage Multi-Person Pose Estimation. (arXiv:2107.08982v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.04259",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Borkman_S/0/1/0/all/0/1\">Steve Borkman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crespi_A/0/1/0/all/0/1\">Adam Crespi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dhakad_S/0/1/0/all/0/1\">Saurav Dhakad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganguly_S/0/1/0/all/0/1\">Sujoy Ganguly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hogins_J/0/1/0/all/0/1\">Jonathan Hogins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jhang_Y/0/1/0/all/0/1\">You-Cyuan Jhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamalzadeh_M/0/1/0/all/0/1\">Mohsen Kamalzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bowen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leal_S/0/1/0/all/0/1\">Steven Leal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parisi_P/0/1/0/all/0/1\">Pete Parisi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Romero_C/0/1/0/all/0/1\">Cesar Romero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_W/0/1/0/all/0/1\">Wesley Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thaman_A/0/1/0/all/0/1\">Alex Thaman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Warren_S/0/1/0/all/0/1\">Samuel Warren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yadav_N/0/1/0/all/0/1\">Nupur Yadav</a>",
          "description": "We introduce the Unity Perception package which aims to simplify and\naccelerate the process of generating synthetic datasets for computer vision\ntasks by offering an easy-to-use and highly customizable toolset. This\nopen-source package extends the Unity Editor and engine components to generate\nperfectly annotated examples for several common computer vision tasks.\nAdditionally, it offers an extensible Randomization framework that lets the\nuser quickly construct and configure randomized simulation parameters in order\nto introduce variation into the generated datasets. We provide an overview of\nthe provided tools and how they work, and demonstrate the value of the\ngenerated synthetic datasets by training a 2D object detection model. The model\ntrained with mostly synthetic data outperforms the model trained using only\nreal data.",
          "link": "http://arxiv.org/abs/2107.04259",
          "publishedOn": "2021-07-21T02:01:36.164Z",
          "wordCount": 613,
          "title": "Unity Perception: Generate Synthetic Data for Computer Vision. (arXiv:2107.04259v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.04570",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Eiras_F/0/1/0/all/0/1\">Francisco Eiras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alfarra_M/0/1/0/all/0/1\">Motasem Alfarra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_M/0/1/0/all/0/1\">M. Pawan Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1\">Philip H. S. Torr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dokania_P/0/1/0/all/0/1\">Puneet K. Dokania</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghanem_B/0/1/0/all/0/1\">Bernard Ghanem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bibi_A/0/1/0/all/0/1\">Adel Bibi</a>",
          "description": "Randomized smoothing has recently emerged as an effective tool that enables\ncertification of deep neural network classifiers at scale. All prior art on\nrandomized smoothing has focused on isotropic $\\ell_p$ certification, which has\nthe advantage of yielding certificates that can be easily compared among\nisotropic methods via $\\ell_p$-norm radius. However, isotropic certification\nlimits the region that can be certified around an input to worst-case\nadversaries, i.e., it cannot reason about other \"close\", potentially large,\nconstant prediction safe regions. To alleviate this issue, (i) we theoretically\nextend the isotropic randomized smoothing $\\ell_1$ and $\\ell_2$ certificates to\ntheir generalized anisotropic counterparts following a simplified analysis.\nMoreover, (ii) we propose evaluation metrics allowing for the comparison of\ngeneral certificates - a certificate is superior to another if it certifies a\nsuperset region - with the quantification of each certificate through the\nvolume of the certified region. We introduce ANCER, a practical framework for\nobtaining anisotropic certificates for a given test set sample via volume\nmaximization. Our empirical results demonstrate that ANCER achieves\nstate-of-the-art $\\ell_1$ and $\\ell_2$ certified accuracy on both CIFAR-10 and\nImageNet at multiple radii, while certifying substantially larger regions in\nterms of volume, thus highlighting the benefits of moving away from isotropic\nanalysis. Code used in our experiments is available in\nhttps://github.com/MotasemAlfarra/ANCER.",
          "link": "http://arxiv.org/abs/2107.04570",
          "publishedOn": "2021-07-21T02:01:36.138Z",
          "wordCount": 687,
          "title": "ANCER: Anisotropic Certification via Sample-wise Volume Maximization. (arXiv:2107.04570v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1912.00384",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhaohui Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_M/0/1/0/all/0/1\">Miaojing Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chao Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferrari_V/0/1/0/all/0/1\">Vittorio Ferrari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Avrithis_Y/0/1/0/all/0/1\">Yannis Avrithis</a>",
          "description": "Weakly-supervised object detection attempts to limit the amount of\nsupervision by dispensing the need for bounding boxes, but still assumes\nimage-level labels on the entire training set. In this work, we study the\nproblem of training an object detector from one or few images with image-level\nlabels and a larger set of completely unlabeled images. This is an extreme case\nof semi-supervised learning where the labeled data are not enough to bootstrap\nthe learning of a detector. Our solution is to train a weakly-supervised\nstudent detector model from image-level pseudo-labels generated on the\nunlabeled set by a teacher classifier model, bootstrapped by region-level\nsimilarities to labeled images. Building upon the recent representative\nweakly-supervised pipeline PCL, our method can use more unlabeled images to\nachieve performance competitive or superior to many recent weakly-supervised\ndetection solutions.",
          "link": "http://arxiv.org/abs/1912.00384",
          "publishedOn": "2021-07-21T02:01:35.994Z",
          "wordCount": 633,
          "title": "Training Object Detectors from Few Weakly-Labeled and Many Unlabeled Images. (arXiv:1912.00384v5 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.10567",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lyu_Y/0/1/0/all/0/1\">Yueming Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1\">Jing Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1\">Bo Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_T/0/1/0/all/0/1\">Tieniu Tan</a>",
          "description": "In recent years, virtual makeup applications have become more and more\npopular. However, it is still challenging to propose a robust makeup transfer\nmethod in the real-world environment. Current makeup transfer methods mostly\nwork well on good-conditioned clean makeup images, but transferring makeup that\nexhibits shadow and occlusion is not satisfying. To alleviate it, we propose a\nnovel makeup transfer method, called 3D-Aware Shadow and Occlusion Robust GAN\n(SOGAN). Given the source and the reference faces, we first fit a 3D face model\nand then disentangle the faces into shape and texture. In the texture branch,\nwe map the texture to the UV space and design a UV texture generator to\ntransfer the makeup. Since human faces are symmetrical in the UV space, we can\nconveniently remove the undesired shadow and occlusion from the reference image\nby carefully designing a Flip Attention Module (FAM). After obtaining cleaner\nmakeup features from the reference image, a Makeup Transfer Module (MTM) is\nintroduced to perform accurate makeup transfer. The qualitative and\nquantitative experiments demonstrate that our SOGAN not only achieves superior\nresults in shadow and occlusion situations but also performs well in large pose\nand expression variations.",
          "link": "http://arxiv.org/abs/2104.10567",
          "publishedOn": "2021-07-21T02:01:35.279Z",
          "wordCount": 676,
          "title": "SOGAN: 3D-Aware Shadow and Occlusion Robust GAN for Makeup Transfer. (arXiv:2104.10567v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.10122",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yuxing Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_S/0/1/0/all/0/1\">Shaodi You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1\">Ying Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Q/0/1/0/all/0/1\">Qiu Shen</a>",
          "description": "High-resolution hyperspectral images (HSIs) contain the response of each\npixel in different spectral bands, which can be used to effectively distinguish\nvarious objects in complex scenes. While HSI cameras have become low cost,\nalgorithms based on it have not been well exploited. In this paper, we focus on\na novel topic, weakly-supervised semantic segmentation in cityscape via HSIs.\nIt is based on the idea that high-resolution HSIs in city scenes contain rich\nspectral information, which can be easily associated to semantics without\nmanual labeling. Therefore, it enables low cost, highly reliable semantic\nsegmentation in complex scenes. Specifically, in this paper, we theoretically\nanalyze the HSIs and introduce a weakly-supervised HSI semantic segmentation\nframework, which utilizes spectral information to improve the coarse labels to\na finer degree. The experimental results show that our method can obtain highly\ncompetitive labels and even have higher edge fineness than artificial fine\nlabels in some classes. At the same time, the results also show that the\nrefined labels can effectively improve the effect of semantic segmentation. The\ncombination of HSIs and semantic segmentation proves that HSIs have great\npotential in high-level visual tasks.",
          "link": "http://arxiv.org/abs/2012.10122",
          "publishedOn": "2021-07-21T02:01:35.265Z",
          "wordCount": 652,
          "title": "Weakly-supervised Semantic Segmentation in Cityscape via Hyperspectral Image. (arXiv:2012.10122v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.15599",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xingming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jinzhao Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yante Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_G/0/1/0/all/0/1\">Guoying Zhao</a>",
          "description": "Facial affect analysis (FAA) using visual signals is important in\nhuman-computer interaction. Early methods focus on extracting appearance and\ngeometry features associated with human affects, while ignoring the latent\nsemantic information among individual facial changes, leading to limited\nperformance and generalization. Recent work attempts to establish a graph-based\nrepresentation to model these semantic relationships and develop frameworks to\nleverage them for various FAA tasks. In this paper, we provide a comprehensive\nreview of graph-based FAA, including the evolution of algorithms and their\napplications. First, the FAA background knowledge is introduced, especially on\nthe role of the graph. We then discuss approaches that are widely used for\ngraph-based affective representation in literature and show a trend towards\ngraph construction. For the relational reasoning in graph-based FAA, existing\nstudies are categorized according to their usage of traditional methods or deep\nmodels, with a special emphasis on the latest graph neural networks.\nPerformance comparisons of the state-of-the-art graph-based FAA methods are\nalso summarized. Finally, we discuss the challenges and potential directions.\nAs far as we know, this is the first survey of graph-based FAA methods. Our\nfindings can serve as a reference for future research in this field.",
          "link": "http://arxiv.org/abs/2103.15599",
          "publishedOn": "2021-07-21T02:01:35.259Z",
          "wordCount": 707,
          "title": "Graph-based Facial Affect Analysis: A Review of Methods, Applications and Challenges. (arXiv:2103.15599v5 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.08285",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Reich_C/0/1/0/all/0/1\">Christoph Reich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prangemeier_T/0/1/0/all/0/1\">Tim Prangemeier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wildner_C/0/1/0/all/0/1\">Christian Wildner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koeppl_H/0/1/0/all/0/1\">Heinz Koeppl</a>",
          "description": "Time-lapse fluorescent microscopy (TLFM) combined with predictive\nmathematical modelling is a powerful tool to study the inherently dynamic\nprocesses of life on the single-cell level. Such experiments are costly,\ncomplex and labour intensive. A complimentary approach and a step towards in\nsilico experimentation, is to synthesise the imagery itself. Here, we propose\nMulti-StyleGAN as a descriptive approach to simulate time-lapse fluorescence\nmicroscopy imagery of living cells, based on a past experiment. This novel\ngenerative adversarial network synthesises a multi-domain sequence of\nconsecutive timesteps. We showcase Multi-StyleGAN on imagery of multiple live\nyeast cells in microstructured environments and train on a dataset recorded in\nour laboratory. The simulation captures underlying biophysical factors and time\ndependencies, such as cell morphology, growth, physical interactions, as well\nas the intensity of a fluorescent reporter protein. An immediate application is\nto generate additional training and validation data for feature extraction\nalgorithms or to aid and expedite development of advanced experimental\ntechniques such as online monitoring or control of cells.\n\nCode and dataset is available at\nhttps://git.rwth-aachen.de/bcs/projects/tp/multi-stylegan.",
          "link": "http://arxiv.org/abs/2106.08285",
          "publishedOn": "2021-07-21T02:01:35.229Z",
          "wordCount": 674,
          "title": "Multi-StyleGAN: Towards Image-Based Simulation of Time-Lapse Live-Cell Microscopy. (arXiv:2106.08285v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.11858",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sreenivasaiah_D/0/1/0/all/0/1\">Deepthi Sreenivasaiah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Otterbach_J/0/1/0/all/0/1\">Johannes Otterbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wollmann_T/0/1/0/all/0/1\">Thomas Wollmann</a>",
          "description": "Image segmentation is a common and challenging task in autonomous driving.\nAvailability of sufficient pixel-level annotations for the training data is a\nhurdle. Active learning helps learning from small amounts of data by suggesting\nthe most promising samples for labeling. In this work, we propose a new\npool-based method for active learning, which proposes promising patches\nextracted from full image, in each acquisition step. The problem is framed in\nan exploration-exploitation framework by combining an embedding based on\nUniform Manifold Approximation to model representativeness with entropy as\nuncertainty measure to model informativeness. We applied our proposed method to\nthe autonomous driving datasets CamVid and Cityscapes and performed a\nquantitative comparison with state-of-the-art baselines. We find that our\nactive learning method achieves better performance compared to previous\nmethods.",
          "link": "http://arxiv.org/abs/2106.11858",
          "publishedOn": "2021-07-21T02:01:35.220Z",
          "wordCount": 584,
          "title": "MEAL: Manifold Embedding-based Active Learning. (arXiv:2106.11858v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.02924",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shen_B/0/1/0/all/0/1\">Bokui Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_F/0/1/0/all/0/1\">Fei Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chengshu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_Martin_R/0/1/0/all/0/1\">Roberto Mart&#xed;n-Mart&#xed;n</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1\">Linxi Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Guanzhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perez_DArpino_C/0/1/0/all/0/1\">Claudia P&#xe9;rez-D&#x27;Arpino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buch_S/0/1/0/all/0/1\">Shyamal Buch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_S/0/1/0/all/0/1\">Sanjana Srivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tchapmi_L/0/1/0/all/0/1\">Lyne P. Tchapmi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tchapmi_M/0/1/0/all/0/1\">Micael E. Tchapmi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vainio_K/0/1/0/all/0/1\">Kent Vainio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1\">Li Fei-Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Savarese_S/0/1/0/all/0/1\">Silvio Savarese</a>",
          "description": "We present iGibson 1.0, a novel simulation environment to develop robotic\nsolutions for interactive tasks in large-scale realistic scenes. Our\nenvironment contains 15 fully interactive home-sized scenes with 108 rooms\npopulated with rigid and articulated objects. The scenes are replicas of\nreal-world homes, with distribution and the layout of objects aligned to those\nof the real world. iGibson 1.0 integrates several key features to facilitate\nthe study of interactive tasks: i) generation of high-quality virtual sensor\nsignals (RGB, depth, segmentation, LiDAR, flow and so on), ii) domain\nrandomization to change the materials of the objects (both visual and physical)\nand/or their shapes, iii) integrated sampling-based motion planners to generate\ncollision-free trajectories for robot bases and arms, and iv) intuitive\nhuman-iGibson interface that enables efficient collection of human\ndemonstrations. Through experiments, we show that the full interactivity of the\nscenes enables agents to learn useful visual representations that accelerate\nthe training of downstream manipulation tasks. We also show that iGibson 1.0\nfeatures enable the generalization of navigation agents, and that the\nhuman-iGibson interface and integrated motion planners facilitate efficient\nimitation learning of human demonstrated (mobile) manipulation behaviors.\niGibson 1.0 is open-source, equipped with comprehensive examples and\ndocumentation. For more information, visit our project website:\nthis http URL",
          "link": "http://arxiv.org/abs/2012.02924",
          "publishedOn": "2021-07-21T02:01:35.206Z",
          "wordCount": 737,
          "title": "iGibson 1.0: a Simulation Environment for Interactive Tasks in Large Realistic Scenes. (arXiv:2012.02924v4 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.09321",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dang_V/0/1/0/all/0/1\">Vien Ngoc Dang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galati_F/0/1/0/all/0/1\">Francesco Galati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cortese_R/0/1/0/all/0/1\">Rosa Cortese</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giacomo_G/0/1/0/all/0/1\">Giuseppe Di Giacomo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marconetto_V/0/1/0/all/0/1\">Viola Marconetto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mathur_P/0/1/0/all/0/1\">Prateek Mathur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lekadir_K/0/1/0/all/0/1\">Karim Lekadir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lorenzi_M/0/1/0/all/0/1\">Marco Lorenzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prados_F/0/1/0/all/0/1\">Ferran Prados</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zuluaga_M/0/1/0/all/0/1\">Maria A. Zuluaga</a>",
          "description": "Deep learning techniques for 3D brain vessel image segmentation have not been\nas successful as in the segmentation of other organs and tissues. This can be\nexplained by two factors. First, deep learning techniques tend to show poor\nperformances at the segmentation of relatively small objects compared to the\nsize of the full image. Second, due to the complexity of vascular trees and the\nsmall size of vessels, it is challenging to obtain the amount of annotated\ntraining data typically needed by deep learning methods. To address these\nproblems, we propose a novel annotation-efficient deep learning vessel\nsegmentation framework. The framework avoids pixel-wise annotations, only\nrequiring weak patch-level labels to discriminate between vessel and non-vessel\n2D patches in the training set, in a setup similar to the CAPTCHAs used to\ndifferentiate humans from bots in web applications. The user-provided weak\nannotations are used for two tasks: 1) to synthesize pixel-wise pseudo-labels\nfor vessels and background in each patch, which are used to train a\nsegmentation network, and 2) to train a classifier network. The classifier\nnetwork allows to generate additional weak patch labels, further reducing the\nannotation burden, and it acts as a noise filter for poor quality images. We\nuse this framework for the segmentation of the cerebrovascular tree in\nTime-of-Flight angiography (TOF) and Susceptibility-Weighted Images (SWI). The\nresults show that the framework achieves state-of-the-art accuracy, while\nreducing the annotation time by ~77% w.r.t. learning-based segmentation methods\nusing pixel-wise labels for training.",
          "link": "http://arxiv.org/abs/2101.09321",
          "publishedOn": "2021-07-21T02:01:35.199Z",
          "wordCount": 746,
          "title": "Vessel-CAPTCHA: an efficient learning framework for vessel annotation and segmentation. (arXiv:2101.09321v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.09584",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Smith_E/0/1/0/all/0/1\">Edward J. Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meger_D/0/1/0/all/0/1\">David Meger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pineda_L/0/1/0/all/0/1\">Luis Pineda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Calandra_R/0/1/0/all/0/1\">Roberto Calandra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malik_J/0/1/0/all/0/1\">Jitendra Malik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Romero_A/0/1/0/all/0/1\">Adriana Romero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drozdzal_M/0/1/0/all/0/1\">Michal Drozdzal</a>",
          "description": "Humans build 3D understandings of the world through active object\nexploration, using jointly their senses of vision and touch. However, in 3D\nshape reconstruction, most recent progress has relied on static datasets of\nlimited sensory data such as RGB images, depth maps or haptic readings, leaving\nthe active exploration of the shape largely unexplored. In active touch sensing\nfor 3D reconstruction, the goal is to actively select the tactile readings that\nmaximize the improvement in shape reconstruction accuracy. However, the\ndevelopment of deep learning-based active touch models is largely limited by\nthe lack of frameworks for shape exploration. In this paper, we focus on this\nproblem and introduce a system composed of: 1) a haptic simulator leveraging\nhigh spatial resolution vision-based tactile sensors for active touching of 3D\nobjects; 2) a mesh-based 3D shape reconstruction model that relies on tactile\nor visuotactile signals; and 3) a set of data-driven solutions with either\ntactile or visuotactile priors to guide the shape exploration. Our framework\nenables the development of the first fully data-driven solutions to active\ntouch on top of learned models for object understanding. Our experiments show\nthe benefits of such solutions in the task of 3D shape understanding where our\nmodels consistently outperform natural baselines. We provide our framework as a\ntool to foster future research in this direction.",
          "link": "http://arxiv.org/abs/2107.09584",
          "publishedOn": "2021-07-21T02:01:35.174Z",
          "wordCount": 664,
          "title": "Active 3D Shape Reconstruction from Vision and Touch. (arXiv:2107.09584v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2103.09957",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_E/0/1/0/all/0/1\">Emma Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_A/0/1/0/all/0/1\">Andy Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krishnan_R/0/1/0/all/0/1\">Rayan Krishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_J/0/1/0/all/0/1\">Jin Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ng_A/0/1/0/all/0/1\">Andrew Y. Ng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajpurkar_P/0/1/0/all/0/1\">Pranav Rajpurkar</a>",
          "description": "A major obstacle to the integration of deep learning models for chest x-ray\ninterpretation into clinical settings is the lack of understanding of their\nfailure modes. In this work, we first investigate whether there are patient\nsubgroups that chest x-ray models are likely to misclassify. We find that\npatient age and the radiographic finding of lung lesion, pneumothorax or\nsupport devices are statistically relevant features for predicting\nmisclassification for some chest x-ray models. Second, we develop\nmisclassification predictors on chest x-ray models using their outputs and\nclinical features. We find that our best performing misclassification\nidentifier achieves an AUROC close to 0.9 for most diseases. Third, employing\nour misclassification identifiers, we develop a corrective algorithm to\nselectively flip model predictions that have high likelihood of\nmisclassification at inference time. We observe F1 improvement on the\nprediction of Consolidation (0.008 [95% CI 0.005, 0.010]) and Edema (0.003,\n[95% CI 0.001, 0.006]). By carrying out our investigation on ten distinct and\nhigh-performing chest x-ray models, we are able to derive insights across model\narchitectures and offer a generalizable framework applicable to other medical\nimaging tasks.",
          "link": "http://arxiv.org/abs/2103.09957",
          "publishedOn": "2021-07-21T02:01:35.167Z",
          "wordCount": 697,
          "title": "CheXbreak: Misclassification Identification for Deep Learning Models Interpreting Chest X-rays. (arXiv:2103.09957v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.00182",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Klein_L/0/1/0/all/0/1\">Levente J. Klein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Wang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Albrecht_C/0/1/0/all/0/1\">Conrad M. Albrecht</a>",
          "description": "Vegetation, trees in particular, sequester carbon by absorbing carbon dioxide\nfrom the atmosphere. However, the lack of efficient quantification methods of\ncarbon stored in trees renders it difficult to track the process. We present an\napproach to estimate the carbon storage in trees based on fusing multi-spectral\naerial imagery and LiDAR data to identify tree coverage, geometric shape, and\ntree species -- key attributes to carbon storage quantification. We demonstrate\nthat tree species information and their three-dimensional geometric shapes can\nbe estimated from aerial imagery in order to determine the tree's biomass.\nSpecifically, we estimate a total of $52,000$ tons of carbon sequestered in\ntrees for New York City's borough Manhattan.",
          "link": "http://arxiv.org/abs/2106.00182",
          "publishedOn": "2021-07-21T02:01:35.159Z",
          "wordCount": 587,
          "title": "Quantification of Carbon Sequestration in Urban Forests. (arXiv:2106.00182v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.05108",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cooper_J/0/1/0/all/0/1\">Jessica Cooper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arandjelovic_O/0/1/0/all/0/1\">Ognjen Arandjelovi&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harrison_D/0/1/0/all/0/1\">David J Harrison</a>",
          "description": "Understanding the predictions made by Artificial Intelligence (AI) systems is\nbecoming more and more important as deep learning models are used for\nincreasingly complex and high-stakes tasks. Saliency mapping - an easily\ninterpretable visual attribution method - is one important tool for this, but\nexisting formulations are limited by either computational cost or architectural\nconstraints. We therefore propose Hierarchical Perturbation, a very fast and\ncompletely model-agnostic method for explaining model predictions with robust\nsaliency maps. Using standard benchmarks and datasets, we show that our\nsaliency maps are of competitive or superior quality to those generated by\nexisting model-agnostic methods - and are over 20X faster to compute.",
          "link": "http://arxiv.org/abs/2103.05108",
          "publishedOn": "2021-07-21T02:01:35.152Z",
          "wordCount": 587,
          "title": "Believe The HiPe: Hierarchical Perturbation for Fast, Robust and Model-Agnostic Explanations. (arXiv:2103.05108v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.03308",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiangtai Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xia Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_A/0/1/0/all/0/1\">Ansheng You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Li Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_G/0/1/0/all/0/1\">Guangliang Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1\">Kuiyuan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_Y/0/1/0/all/0/1\">Yunhai Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhouchen Lin</a>",
          "description": "Graph-based convolutional model such as non-local block has shown to be\neffective for strengthening the context modeling ability in convolutional\nneural networks (CNNs). However, its pixel-wise computational overhead is\nprohibitive which renders it unsuitable for high resolution imagery. In this\npaper, we explore the efficiency of context graph reasoning and propose a novel\nframework called Squeeze Reasoning. Instead of propagating information on the\nspatial map, we first learn to squeeze the input feature into a channel-wise\nglobal vector and perform reasoning within the single vector where the\ncomputation cost can be significantly reduced. Specifically, we build the node\ngraph in the vector where each node represents an abstract semantic concept.\nThe refined feature within the same semantic category results to be consistent,\nwhich is thus beneficial for downstream tasks. We show that our approach can be\nmodularized as an end-to-end trained block and can be easily plugged into\nexisting networks. {Despite its simplicity and being lightweight, the proposed\nstrategy allows us to establish the considerable results on different semantic\nsegmentation datasets and shows significant improvements with respect to strong\nbaselines on various other scene understanding tasks including object\ndetection, instance segmentation and panoptic segmentation.} Code is available\nat \\url{https://github.com/lxtGH/SFSegNets}.",
          "link": "http://arxiv.org/abs/2011.03308",
          "publishedOn": "2021-07-21T02:01:35.132Z",
          "wordCount": 687,
          "title": "Towards Efficient Scene Understanding via Squeeze Reasoning. (arXiv:2011.03308v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.00926",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jaunet_T/0/1/0/all/0/1\">Theo Jaunet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kervadec_C/0/1/0/all/0/1\">Corentin Kervadec</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vuillemot_R/0/1/0/all/0/1\">Romain Vuillemot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Antipov_G/0/1/0/all/0/1\">Grigory Antipov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baccouche_M/0/1/0/all/0/1\">Moez Baccouche</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolf_C/0/1/0/all/0/1\">Christian Wolf</a>",
          "description": "Visual Question Answering systems target answering open-ended textual\nquestions given input images. They are a testbed for learning high-level\nreasoning with a primary use in HCI, for instance assistance for the visually\nimpaired. Recent research has shown that state-of-the-art models tend to\nproduce answers exploiting biases and shortcuts in the training data, and\nsometimes do not even look at the input image, instead of performing the\nrequired reasoning steps. We present VisQA, a visual analytics tool that\nexplores this question of reasoning vs. bias exploitation. It exposes the key\nelement of state-of-the-art neural models -- attention maps in transformers.\nOur working hypothesis is that reasoning steps leading to model predictions are\nobservable from attention distributions, which are particularly useful for\nvisualization. The design process of VisQA was motivated by well-known bias\nexamples from the fields of deep learning and vision-language reasoning and\nevaluated in two ways. First, as a result of a collaboration of three fields,\nmachine learning, vision and language reasoning, and data analytics, the work\nlead to a better understanding of bias exploitation of neural models for VQA,\nwhich eventually resulted in an impact on its design and training through the\nproposition of a method for the transfer of reasoning patterns from an oracle\nmodel. Second, we also report on the design of VisQA, and a goal-oriented\nevaluation of VisQA targeting the analysis of a model decision process from\nmultiple experts, providing evidence that it makes the inner workings of models\naccessible to users.",
          "link": "http://arxiv.org/abs/2104.00926",
          "publishedOn": "2021-07-21T02:01:35.119Z",
          "wordCount": 720,
          "title": "VisQA: X-raying Vision and Language Reasoning in Transformers. (arXiv:2104.00926v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.00337",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_K/0/1/0/all/0/1\">Kishor Datta Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akhtar_Z/0/1/0/all/0/1\">Zahid Akhtar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dasgupta_D/0/1/0/all/0/1\">Dipankar Dasgupta</a>",
          "description": "Developing secure machine learning models from adversarial examples is\nchallenging as various methods are continually being developed to generate\nadversarial attacks. In this work, we propose an evolutionary approach to\nautomatically determine Image Processing Techniques Sequence (IPTS) for\ndetecting malicious inputs. Accordingly, we first used a diverse set of attack\nmethods including adaptive attack methods (on our defense) to generate\nadversarial samples from the clean dataset. A detection framework based on a\ngenetic algorithm (GA) is developed to find the optimal IPTS, where the\noptimality is estimated by different fitness measures such as Euclidean\ndistance, entropy loss, average histogram, local binary pattern and loss\nfunctions. The \"image difference\" between the original and processed images is\nused to extract the features, which are then fed to a classification scheme in\norder to determine whether the input sample is adversarial or clean. This paper\ndescribed our methodology and performed experiments using multiple data-sets\ntested with several adversarial attacks. For each attack-type and dataset, it\ngenerates unique IPTS. A set of IPTS selected dynamically in testing time which\nworks as a filter for the adversarial attack. Our empirical experiments\nexhibited promising results indicating the approach can efficiently be used as\nprocessing for any AI model.",
          "link": "http://arxiv.org/abs/2007.00337",
          "publishedOn": "2021-07-21T02:01:35.112Z",
          "wordCount": 675,
          "title": "Determining Sequence of Image Processing Technique (IPT) to Detect Adversarial Attacks. (arXiv:2007.00337v2 [cs.CV] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.09305",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1\">Wenxian Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yuxuan Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Hao Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bohan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>",
          "description": "Deep neural networks often have a huge number of parameters, which posts\nchallenges in deployment in application scenarios with limited memory and\ncomputation capacity. Knowledge distillation is one approach to derive compact\nmodels from bigger ones. However, it has been observed that a converged heavy\nteacher model is strongly constrained for learning a compact student network\nand could make the optimization subject to poor local optima. In this paper, we\npropose ProKT, a new model-agnostic method by projecting the supervision\nsignals of a teacher model into the student's parameter space. Such projection\nis implemented by decomposing the training objective into local intermediate\ntargets with an approximate mirror descent technique. The proposed method could\nbe less sensitive with the quirks during optimization which could result in a\nbetter local optimum. Experiments on both image and text datasets show that our\nproposed ProKT consistently achieves superior performance compared to other\nexisting knowledge distillation methods.",
          "link": "http://arxiv.org/abs/2107.09305",
          "publishedOn": "2021-07-21T02:01:35.104Z",
          "wordCount": 597,
          "title": "Follow Your Path: a Progressive Method for Knowledge Distillation. (arXiv:2107.09305v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2010.13677",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Huang_W/0/1/0/all/0/1\">Wenqi Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ke_Z/0/1/0/all/0/1\">Ziwen Ke</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cui_Z/0/1/0/all/0/1\">Zhuo-Xu Cui</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cheng_J/0/1/0/all/0/1\">Jing Cheng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Qiu_Z/0/1/0/all/0/1\">Zhilang Qiu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jia_S/0/1/0/all/0/1\">Sen Jia</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ying_L/0/1/0/all/0/1\">Leslie Ying</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhu_Y/0/1/0/all/0/1\">Yanjie Zhu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liang_D/0/1/0/all/0/1\">Dong Liang</a>",
          "description": "In dynamic magnetic resonance (MR) imaging, low-rank plus sparse (L+S)\ndecomposition, or robust principal component analysis (PCA), has achieved\nstunning performance. However, the selection of the parameters of L+S is\nempirical, and the acceleration rate is limited, which are common failings of\niterative compressed sensing MR imaging (CS-MRI) reconstruction methods. Many\ndeep learning approaches have been proposed to address these issues, but few of\nthem use a low-rank prior. In this paper, a model-based low-rank plus sparse\nnetwork, dubbed L+S-Net, is proposed for dynamic MR reconstruction. In\nparticular, we use an alternating linearized minimization method to solve the\noptimization problem with low-rank and sparse regularization. Learned soft\nsingular value thresholding is introduced to ensure the clear separation of the\nL component and S component. Then, the iterative steps are unrolled into a\nnetwork in which the regularization parameters are learnable. We prove that the\nproposed L+S-Net achieves global convergence under two standard assumptions.\nExperiments on retrospective and prospective cardiac cine datasets show that\nthe proposed model outperforms state-of-the-art CS and existing deep learning\nmethods and has great potential for extremely high acceleration factors (up to\n24x).",
          "link": "http://arxiv.org/abs/2010.13677",
          "publishedOn": "2021-07-21T02:01:35.085Z",
          "wordCount": 677,
          "title": "Deep Low-rank plus Sparse Network for Dynamic MR Imaging. (arXiv:2010.13677v3 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.09562",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Milbich_T/0/1/0/all/0/1\">Timo Milbich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_K/0/1/0/all/0/1\">Karsten Roth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sinha_S/0/1/0/all/0/1\">Samarth Sinha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidt_L/0/1/0/all/0/1\">Ludwig Schmidt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghassemi_M/0/1/0/all/0/1\">Marzyeh Ghassemi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ommer_B/0/1/0/all/0/1\">Bj&#xf6;rn Ommer</a>",
          "description": "Deep Metric Learning (DML) aims to find representations suitable for\nzero-shot transfer to a priori unknown test distributions. However, common\nevaluation protocols only test a single, fixed data split in which train and\ntest classes are assigned randomly. More realistic evaluations should consider\na broad spectrum of distribution shifts with potentially varying degree and\ndifficulty. In this work, we systematically construct train-test splits of\nincreasing difficulty and present the ooDML benchmark to characterize\ngeneralization under out-of-distribution shifts in DML. ooDML is designed to\nprobe the generalization performance on much more challenging, diverse\ntrain-to-test distribution shifts. Based on our new benchmark, we conduct a\nthorough empirical analysis of state-of-the-art DML methods. We find that while\ngeneralization tends to consistently degrade with difficulty, some methods are\nbetter at retaining performance as the distribution shift increases. Finally,\nwe propose few-shot DML as an efficient way to consistently improve\ngeneralization in response to unknown test shifts presented in ooDML. Code\navailable here:\nhttps://github.com/Confusezius/Characterizing_Generalization_in_DeepMetricLearning.",
          "link": "http://arxiv.org/abs/2107.09562",
          "publishedOn": "2021-07-21T02:01:35.078Z",
          "wordCount": 604,
          "title": "Characterizing Generalization under Out-Of-Distribution Shifts in Deep Metric Learning. (arXiv:2107.09562v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.01151",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haiyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenguan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xizhou Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1\">Jifeng Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Liwei Wang</a>",
          "description": "As a fundamental problem for Artificial Intelligence, multi-agent system\n(MAS) is making rapid progress, mainly driven by multi-agent reinforcement\nlearning (MARL) techniques. However, previous MARL methods largely focused on\ngrid-world like or game environments; MAS in visually rich environments has\nremained less explored. To narrow this gap and emphasize the crucial role of\nperception in MAS, we propose a large-scale 3D dataset, CollaVN, for\nmulti-agent visual navigation (MAVN). In CollaVN, multiple agents are entailed\nto cooperatively navigate across photo-realistic environments to reach target\nlocations. Diverse MAVN variants are explored to make our problem more general.\nMoreover, a memory-augmented communication framework is proposed. Each agent is\nequipped with a private, external memory to persistently store communication\ninformation. This allows agents to make better use of their past communication\ninformation, enabling more efficient collaboration and robust long-term\nplanning. In our experiments, several baselines and evaluation metrics are\ndesigned. We also empirically verify the efficacy of our proposed MARL approach\nacross different MAVN task settings.",
          "link": "http://arxiv.org/abs/2107.01151",
          "publishedOn": "2021-07-21T02:01:35.071Z",
          "wordCount": 613,
          "title": "Collaborative Visual Navigation. (arXiv:2107.01151v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.00432",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bonnaerens_M/0/1/0/all/0/1\">Maxim Bonnaerens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freiberger_M/0/1/0/all/0/1\">Matthias Freiberger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dambre_J/0/1/0/all/0/1\">Joni Dambre</a>",
          "description": "This paper proposes anchor pruning for object detection in one-stage\nanchor-based detectors. While pruning techniques are widely used to reduce the\ncomputational cost of convolutional neural networks, they tend to focus on\noptimizing the backbone networks where often most computations are. In this\nwork we demonstrate an additional pruning technique, specifically for object\ndetection: anchor pruning. With more efficient backbone networks and a growing\ntrend of deploying object detectors on embedded systems where post-processing\nsteps such as non-maximum suppression can be a bottleneck, the impact of the\nanchors used in the detection head is becoming increasingly more important. In\nthis work, we show that many anchors in the object detection head can be\nremoved without any loss in accuracy. With additional retraining, anchor\npruning can even lead to improved accuracy. Extensive experiments on SSD and MS\nCOCO show that the detection head can be made up to 44% more efficient while\nsimultaneously increasing accuracy. Further experiments on RetinaNet and PASCAL\nVOC show the general effectiveness of our approach. We also introduce\n`overanchorized' models that can be used together with anchor pruning to\neliminate hyperparameters related to the initial shape of anchors.",
          "link": "http://arxiv.org/abs/2104.00432",
          "publishedOn": "2021-07-21T02:01:35.063Z",
          "wordCount": 645,
          "title": "Anchor Pruning for Object Detection. (arXiv:2104.00432v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.00329",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1\">Zihao Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_Z/0/1/0/all/0/1\">Zimu Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_R/0/1/0/all/0/1\">Ruizhen Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitra_N/0/1/0/all/0/1\">Niloy J. Mitra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_Or_D/0/1/0/all/0/1\">Daniel Cohen-Or</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Hui Huang</a>",
          "description": "Rigid registration of partial observations is a fundamental problem in\nvarious applied fields. In computer graphics, special attention has been given\nto the registration between two partial point clouds generated by scanning\ndevices. State-of-the-art registration techniques still struggle when the\noverlap region between the two point clouds is small, and completely fail if\nthere is no overlap between the scan pairs. In this paper, we present a\nlearning-based technique that alleviates this problem, and allows registration\nbetween point clouds, presented in arbitrary poses, and having little or even\nno overlap, a setting that has been referred to as tele-registration. Our\ntechnique is based on a novel neural network design that learns a prior of a\nclass of shapes and can complete a partial shape. The key idea is combining the\nregistration and completion tasks in a way that reinforces each other. In\nparticular, we simultaneously train the registration network and completion\nnetwork using two coupled flows, one that register-and-complete, and one that\ncomplete-and-register, and encourage the two flows to produce a consistent\nresult. We show that, compared with each separate flow, this two-flow training\nleads to robust and reliable tele-registration, and hence to a better point\ncloud prediction that completes the registered scans. It is also worth\nmentioning that each of the components in our neural network outperforms\nstate-of-the-art methods in both completion and registration. We further\nanalyze our network with several ablation studies and demonstrate its\nperformance on a large number of partial point clouds, both synthetic and\nreal-world, that have only small or no overlap.",
          "link": "http://arxiv.org/abs/2106.00329",
          "publishedOn": "2021-07-21T02:01:35.054Z",
          "wordCount": 736,
          "title": "Consistent Two-Flow Network for Tele-Registration of Point Clouds. (arXiv:2106.00329v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.02850",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1\">Qi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Siheng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yiling Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jun Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asif_M/0/1/0/all/0/1\">M. Salman Asif</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1\">Zhan Ma</a>",
          "description": "Distortion quantification of point clouds plays a stealth, yet vital role in\na wide range of human and machine perception tasks. For human perception tasks,\na distortion quantification can substitute subjective experiments to guide 3D\nvisualization; while for machine perception tasks, a distortion quantification\ncan work as a loss function to guide the training of deep neural networks for\nunsupervised learning tasks. To handle a variety of demands in many\napplications, a distortion quantification needs to be distortion discriminable,\ndifferentiable, and have a low computational complexity. Currently, however,\nthere is a lack of a general distortion quantification that can satisfy all\nthree conditions. To fill this gap, this work proposes multiscale potential\nenergy discrepancy (MPED), a distortion quantification to measure point cloud\ngeometry and color difference. By evaluating at various neighborhood sizes, the\nproposed MPED achieves global-local tradeoffs, capturing distortion in a\nmultiscale fashion. Extensive experimental studies validate MPED's superiority\nfor both human and machine perception tasks.",
          "link": "http://arxiv.org/abs/2103.02850",
          "publishedOn": "2021-07-21T02:01:35.036Z",
          "wordCount": 647,
          "title": "Point Cloud Distortion Quantification based on Potential Energy for Human and Machine Perception. (arXiv:2103.02850v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.09600",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1\">Li Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lefei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>",
          "description": "Unsupervised domain adaptation (UDA) for semantic segmentation aims to adapt\na segmentation model trained on the labeled source domain to the unlabeled\ntarget domain. Existing methods try to learn domain invariant features while\nsuffering from large domain gaps that make it difficult to correctly align\ndiscrepant features, especially in the initial training phase. To address this\nissue, we propose a novel Dual Soft-Paste (DSP) method in this paper.\nSpecifically, DSP selects some classes from a source domain image using a\nlong-tail class first sampling strategy and softly pastes the corresponding\nimage patch on both the source and target training images with a fusion weight.\nTechnically, we adopt the mean teacher framework for domain adaptation, where\nthe pasted source and target images go through the student network while the\noriginal target image goes through the teacher network. Output-level alignment\nis carried out by aligning the probability maps of the target fused image from\nboth networks using a weighted cross-entropy loss. In addition, feature-level\nalignment is carried out by aligning the feature maps of the source and target\nimages from student network using a weighted maximum mean discrepancy loss. DSP\nfacilitates the model learning domain-invariant features from the intermediate\ndomains, leading to faster convergence and better performance. Experiments on\ntwo challenging benchmarks demonstrate the superiority of DSP over\nstate-of-the-art methods. Code is available at\n\\url{https://github.com/GaoLii/DSP}.",
          "link": "http://arxiv.org/abs/2107.09600",
          "publishedOn": "2021-07-21T02:01:35.029Z",
          "wordCount": 674,
          "title": "DSP: Dual Soft-Paste for Unsupervised Domain Adaptive Semantic Segmentation. (arXiv:2107.09600v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09011",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+VS_V/0/1/0/all/0/1\">Vibashan VS</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valanarasu_J/0/1/0/all/0/1\">Jeya Maria Jose Valanarasu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oza_P/0/1/0/all/0/1\">Poojan Oza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patel_V/0/1/0/all/0/1\">Vishal M. Patel</a>",
          "description": "In image fusion, images obtained from different sensors are fused to generate\na single image with enhanced information. In recent years, state-of-the-art\nmethods have adopted Convolution Neural Networks (CNNs) to encode meaningful\nfeatures for image fusion. Specifically, CNN-based methods perform image fusion\nby fusing local features. However, they do not consider long-range dependencies\nthat are present in the image. Transformer-based models are designed to\novercome this by modeling the long-range dependencies with the help of\nself-attention mechanism. This motivates us to propose a novel Image Fusion\nTransformer (IFT) where we develop a transformer-based multi-scale fusion\nstrategy that attends to both local and long-range information (or global\ncontext). The proposed method follows a two-stage training approach. In the\nfirst stage, we train an auto-encoder to extract deep features at multiple\nscales. In the second stage, multi-scale features are fused using a\nSpatio-Transformer (ST) fusion strategy. The ST fusion blocks are comprised of\na CNN and a transformer branch which capture local and long-range features,\nrespectively. Extensive experiments on multiple benchmark datasets show that\nthe proposed method performs better than many competitive fusion algorithms.\nFurthermore, we show the effectiveness of the proposed ST fusion strategy with\nan ablation analysis. The source code is available at:\nhttps://github.com/Vibashan/Image-Fusion-Transformer.",
          "link": "http://arxiv.org/abs/2107.09011",
          "publishedOn": "2021-07-21T02:01:35.018Z",
          "wordCount": 653,
          "title": "Image Fusion Transformer. (arXiv:2107.09011v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.09602",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Bharati_S/0/1/0/all/0/1\">Subrato Bharati</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Podder_P/0/1/0/all/0/1\">Prajoy Podder</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mondal_M/0/1/0/all/0/1\">M. Rubaiyat Hossain Mondal</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Prasath_V/0/1/0/all/0/1\">V.B. Surya Prasath</a>",
          "description": "The outbreak of novel coronavirus disease (COVID- 19) has claimed millions of\nlives and has affected all aspects of human life. This paper focuses on the\napplication of deep learning (DL) models to medical imaging and drug discovery\nfor managing COVID-19 disease. In this article, we detail various medical\nimaging-based studies such as X-rays and computed tomography (CT) images along\nwith DL methods for classifying COVID-19 affected versus pneumonia. The\napplications of DL techniques to medical images are further described in terms\nof image localization, segmentation, registration, and classification leading\nto COVID-19 detection. The reviews of recent papers indicate that the highest\nclassification accuracy of 99.80% is obtained when InstaCovNet-19 DL method is\napplied to an X-ray dataset of 361 COVID-19 patients, 362 pneumonia patients\nand 365 normal people. Furthermore, it can be seen that the best classification\naccuracy of 99.054% can be achieved when EDL_COVID DL method is applied to a CT\nimage dataset of 7500 samples where COVID-19 patients, lung tumor patients and\nnormal people are equal in number. Moreover, we illustrate the potential DL\ntechniques in drug or vaccine discovery in combating the coronavirus. Finally,\nwe address a number of problems, concerns and future research directions\nrelevant to DL applications for COVID-19.",
          "link": "http://arxiv.org/abs/2107.09602",
          "publishedOn": "2021-07-21T02:01:35.002Z",
          "wordCount": 729,
          "title": "Medical Imaging with Deep Learning for COVID- 19 Diagnosis: A Comprehensive Review. (arXiv:2107.09602v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.03008",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaodong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuo_J/0/1/0/all/0/1\">Junbao Zhuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1\">Shuhao Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuhui Wang</a>",
          "description": "Semi-supervised domain adaptation (SSDA) aims to solve tasks in target domain\nby utilizing transferable information learned from the available source domain\nand a few labeled target data. However, source data is not always accessible in\npractical scenarios, which restricts the application of SSDA in real world\ncircumstances. In this paper, we propose a novel task named Semi-supervised\nSource Hypothesis Transfer (SSHT), which performs domain adaptation based on\nsource trained model, to generalize well in target domain with a few\nsupervisions. In SSHT, we are facing two challenges: (1) The insufficient\nlabeled target data may result in target features near the decision boundary,\nwith the increased risk of mis-classification; (2) The data are usually\nimbalanced in source domain, so the model trained with these data is biased.\nThe biased model is prone to categorize samples of minority categories into\nmajority ones, resulting in low prediction diversity. To tackle the above\nissues, we propose Consistency and Diversity Learning (CDL), a simple but\neffective framework for SSHT by facilitating prediction consistency between two\nrandomly augmented unlabeled data and maintaining the prediction diversity when\nadapting model to target domain. Encouraging consistency regularization brings\ndifficulty to memorize the few labeled target data and thus enhances the\ngeneralization ability of the learned model. We further integrate Batch\nNuclear-norm Maximization into our method to enhance the discriminability and\ndiversity. Experimental results show that our method outperforms existing SSDA\nmethods and unsupervised model adaptation methods on DomainNet, Office-Home and\nOffice-31 datasets. The code is available at\nhttps://github.com/Wang-xd1899/SSHT.",
          "link": "http://arxiv.org/abs/2107.03008",
          "publishedOn": "2021-07-21T02:01:34.994Z",
          "wordCount": 717,
          "title": "Learning Invariant Representation with Consistency and Diversity for Semi-supervised Source Hypothesis Transfer. (arXiv:2107.03008v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.13201",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Raju_A/0/1/0/all/0/1\">Ashwin Raju</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cheng_C/0/1/0/all/0/1\">Chi-Tung Cheng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huo_Y/0/1/0/all/0/1\">Yunakai Huo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cai_J/0/1/0/all/0/1\">Jinzheng Cai</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huang_J/0/1/0/all/0/1\">Junzhou Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xiao_J/0/1/0/all/0/1\">Jing Xiao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lu_L/0/1/0/all/0/1\">Le Lu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liao_C/0/1/0/all/0/1\">ChienHuang Liao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Harrison_A/0/1/0/all/0/1\">Adam P Harrison</a>",
          "description": "In medical imaging, organ/pathology segmentation models trained on current\npublicly available and fully-annotated datasets usually do not well-represent\nthe heterogeneous modalities, phases, pathologies, and clinical scenarios\nencountered in real environments. On the other hand, there are tremendous\namounts of unlabelled patient imaging scans stored by many modern clinical\ncenters. In this work, we present a novel segmentation strategy,\nco-heterogenous and adaptive segmentation (CHASe), which only requires a small\nlabeled cohort of single phase imaging data to adapt to any unlabeled cohort of\nheterogenous multi-phase data with possibly new clinical scenarios and\npathologies. To do this, we propose a versatile framework that fuses appearance\nbased semi-supervision, mask based adversarial domain adaptation, and\npseudo-labeling. We also introduce co-heterogeneous training, which is a novel\nintegration of co-training and hetero modality learning. We have evaluated\nCHASe using a clinically comprehensive and challenging dataset of multi-phase\ncomputed tomography (CT) imaging studies (1147 patients and 4577 3D volumes).\nCompared to previous state-of-the-art baselines, CHASe can further improve\npathological liver mask Dice-Sorensen coefficients by ranges of $4.2\\% \\sim\n9.4\\%$, depending on the phase combinations: e.g., from $84.6\\%$ to $94.0\\%$ on\nnon-contrast CTs.",
          "link": "http://arxiv.org/abs/2005.13201",
          "publishedOn": "2021-07-21T02:01:34.976Z",
          "wordCount": 703,
          "title": "Co-Heterogeneous and Adaptive Segmentation from Multi-Source and Multi-Phase CT Imaging Data: A Study on Pathological Liver and Lesion Segmentation. (arXiv:2005.13201v4 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.09282",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_M/0/1/0/all/0/1\">Mingkai Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_S/0/1/0/all/0/1\">Shan You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Fei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_C/0/1/0/all/0/1\">Chen Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Changshui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaogang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chang Xu</a>",
          "description": "Self-supervised Learning (SSL) including the mainstream contrastive learning\nhas achieved great success in learning visual representations without data\nannotations. However, most of methods mainly focus on the instance level\ninformation (\\ie, the different augmented images of the same instance should\nhave the same feature or cluster into the same class), but there is a lack of\nattention on the relationships between different instances. In this paper, we\nintroduced a novel SSL paradigm, which we term as relational self-supervised\nlearning (ReSSL) framework that learns representations by modeling the\nrelationship between different instances. Specifically, our proposed method\nemploys sharpened distribution of pairwise similarities among different\ninstances as \\textit{relation} metric, which is thus utilized to match the\nfeature embeddings of different augmentations. Moreover, to boost the\nperformance, we argue that weak augmentations matter to represent a more\nreliable relation, and leverage momentum strategy for practical efficiency.\nExperimental results show that our proposed ReSSL significantly outperforms the\nprevious state-of-the-art algorithms in terms of both performance and training\nefficiency. Code is available at \\url{https://github.com/KyleZheng1997/ReSSL}.",
          "link": "http://arxiv.org/abs/2107.09282",
          "publishedOn": "2021-07-21T02:01:34.957Z",
          "wordCount": 615,
          "title": "ReSSL: Relational Self-Supervised Learning with Weak Augmentation. (arXiv:2107.09282v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2007.05675",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jinhai Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hua Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lin Chen</a>",
          "description": "Few-shot learning aims at rapidly adapting to novel categories with only a\nhandful of samples at test time, which has been predominantly tackled with the\nidea of meta-learning. However, meta-learning approaches essentially learn\nacross a variety of few-shot tasks and thus still require large-scale training\ndata with fine-grained supervision to derive a generalized model, thereby\ninvolving prohibitive annotation cost. In this paper, we advance the few-shot\nclassification paradigm towards a more challenging scenario, i.e.,\ncross-granularity few-shot classification, where the model observes only coarse\nlabels during training while is expected to perform fine-grained classification\nduring testing. This task largely relieves the annotation cost since\nfine-grained labeling usually requires strong domain-specific expertise. To\nbridge the cross-granularity gap, we approximate the fine-grained data\ndistribution by greedy clustering of each coarse-class into pseudo-fine-classes\naccording to the similarity of image embeddings. We then propose a\nmeta-embedder that jointly optimizes the visual- and semantic-discrimination,\nin both instance-wise and coarse class-wise, to obtain a good feature space for\nthis coarse-to-fine pseudo-labeling process. Extensive experiments and ablation\nstudies are conducted to demonstrate the effectiveness and robustness of our\napproach on three representative datasets.",
          "link": "http://arxiv.org/abs/2007.05675",
          "publishedOn": "2021-07-21T02:01:34.947Z",
          "wordCount": 674,
          "title": "Towards Cross-Granularity Few-Shot Learning: Coarse-to-Fine Pseudo-Labeling with Visual-Semantic Meta-Embedding. (arXiv:2007.05675v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.09628",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Figueroa_Flores_C/0/1/0/all/0/1\">Carola Figueroa-Flores</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berga_D/0/1/0/all/0/1\">David Berga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weijer_J/0/1/0/all/0/1\">Joost van der Weijer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raducanu_B/0/1/0/all/0/1\">Bogdan Raducanu</a>",
          "description": "Saliency is the perceptual capacity of our visual system to focus our\nattention (i.e. gaze) on relevant objects. Neural networks for saliency\nestimation require ground truth saliency maps for training which are usually\nachieved via eyetracking experiments. In the current paper, we demonstrate that\nsaliency maps can be generated as a side-effect of training an object\nrecognition deep neural network that is endowed with a saliency branch. Such a\nnetwork does not require any ground-truth saliency maps for training.Extensive\nexperiments carried out on both real and synthetic saliency datasets\ndemonstrate that our approach is able to generate accurate saliency maps,\nachieving competitive results on both synthetic and real datasets when compared\nto methods that do require ground truth data.",
          "link": "http://arxiv.org/abs/2107.09628",
          "publishedOn": "2021-07-21T02:01:34.925Z",
          "wordCount": 575,
          "title": "Saliency for free: Saliency prediction as a side-effect of object recognition. (arXiv:2107.09628v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.05214",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhenrong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jianshu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_J/0/1/0/all/0/1\">Jun Du</a>",
          "description": "Table structure recognition is an essential part for making machines\nunderstand tables. Its main task is to recognize the internal structure of a\ntable. However, due to the complexity and diversity in their structure and\nstyle, it is very difficult to parse the tabular data into the structured\nformat which machines can understand easily, especially for complex tables. In\nthis paper, we introduce Split, Embed and Merge (SEM), an accurate table\nstructure recognizer. Our model takes table images as input and can correctly\nrecognize the structure of tables, whether they are simple or a complex tables.\nSEM is mainly composed of three parts, splitter, embedder and merger. In the\nfirst stage, we apply the splitter to predict the potential regions of the\ntable row (column) separators, and obtain the fine grid structure of the table.\nIn the second stage, by taking a full consideration of the textual information\nin the table, we fuse the output features for each table grid from both vision\nand language modalities. Moreover, we achieve a higher precision in our\nexperiments through adding additional semantic features. Finally, we process\nthe merging of these basic table grids in a self-regression manner. The\ncorrespondent merging results is learned through the attention mechanism. In\nour experiments, SEM achieves an average F1-Measure of 97.11% on the SciTSR\ndataset which outperforms other methods by a large margin. We also won the\nfirst place in the complex table and third place in all tables in ICDAR 2021\nCompetition on Scientific Literature Parsing, Task-B. Extensive experiments on\nother publicly available datasets demonstrate that our model achieves\nstate-of-the-art.",
          "link": "http://arxiv.org/abs/2107.05214",
          "publishedOn": "2021-07-21T02:01:34.907Z",
          "wordCount": 716,
          "title": "Split, embed and merge: An accurate table structure recognizer. (arXiv:2107.05214v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.03876",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yuecong Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jianfei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_H/0/1/0/all/0/1\">Haozhi Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_K/0/1/0/all/0/1\">Kezhi Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_J/0/1/0/all/0/1\">Jianxiong Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+See_S/0/1/0/all/0/1\">Simon See</a>",
          "description": "The task of action recognition in dark videos is useful in various scenarios,\ne.g., night surveillance and self-driving at night. Though progress has been\nmade in the action recognition task for videos in normal illumination, few have\nstudied action recognition in the dark. This is partly due to the lack of\nsufficient datasets for such a task. In this paper, we explored the task of\naction recognition in dark videos. We bridge the gap of the lack of data for\nthis task by collecting a new dataset: the Action Recognition in the Dark\n(ARID) dataset. It consists of over 3,780 video clips with 11 action\ncategories. To the best of our knowledge, it is the first dataset focused on\nhuman actions in dark videos. To gain further understandings of our ARID\ndataset, we analyze the ARID dataset in detail and exhibited its necessity over\nsynthetic dark videos. Additionally, we benchmarked the performance of several\ncurrent action recognition models on our dataset and explored potential methods\nfor increasing their performances. Our results show that current action\nrecognition models and frame enhancement methods may not be effective solutions\nfor the task of action recognition in dark videos.",
          "link": "http://arxiv.org/abs/2006.03876",
          "publishedOn": "2021-07-21T02:01:34.849Z",
          "wordCount": 697,
          "title": "ARID: A Comprehensive Study on Recognizing Actions in the Dark and A New Benchmark Dataset. (arXiv:2006.03876v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.06212",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Manda_B/0/1/0/all/0/1\">Bharadwaj Manda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dhayarkar_S/0/1/0/all/0/1\">Shubham Dhayarkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitheran_S/0/1/0/all/0/1\">Sai Mitheran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Viekash_V/0/1/0/all/0/1\">V.K. Viekash</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muthuganapathy_R/0/1/0/all/0/1\">Ramanathan Muthuganapathy</a>",
          "description": "Ongoing advancements in the fields of 3D modelling and digital archiving have\nled to an outburst in the amount of data stored digitally. Consequently,\nseveral retrieval systems have been developed depending on the type of data\nstored in these databases. However, unlike text data or images, performing a\nsearch for 3D models is non-trivial. Among 3D models, retrieving 3D\nEngineering/CAD models or mechanical components is even more challenging due to\nthe presence of holes, volumetric features, presence of sharp edges etc., which\nmake CAD a domain unto itself. The research work presented in this paper aims\nat developing a dataset suitable for building a retrieval system for 3D CAD\nmodels based on deep learning. 3D CAD models from the available CAD databases\nare collected, and a dataset of computer-generated sketch data, termed\n'CADSketchNet', has been prepared. Additionally, hand-drawn sketches of the\ncomponents are also added to CADSketchNet. Using the sketch images from this\ndataset, the paper also aims at evaluating the performance of various retrieval\nsystem or a search engine for 3D CAD models that accepts a sketch image as the\ninput query. Many experimental models are constructed and tested on\nCADSketchNet. These experiments, along with the model architecture, choice of\nsimilarity metrics are reported along with the search results.",
          "link": "http://arxiv.org/abs/2107.06212",
          "publishedOn": "2021-07-21T02:01:34.842Z",
          "wordCount": 713,
          "title": "'CADSketchNet' -- An Annotated Sketch dataset for 3D CAD Model Retrieval with Deep Neural Networks. (arXiv:2107.06212v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.09442",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Bortsova_G/0/1/0/all/0/1\">Gerda Bortsova</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bos_D/0/1/0/all/0/1\">Daniel Bos</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dubost_F/0/1/0/all/0/1\">Florian Dubost</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Vernooij_M/0/1/0/all/0/1\">Meike W. Vernooij</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ikram_M/0/1/0/all/0/1\">M. Kamran Ikram</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tulder_G/0/1/0/all/0/1\">Gijs van Tulder</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bruijne_M/0/1/0/all/0/1\">Marleen de Bruijne</a>",
          "description": "Purpose: To evaluate a fully-automated deep-learning-based method for\nassessment of intracranial carotid artery calcification (ICAC). Methods: Two\nobservers manually delineated ICAC in non-contrast CT scans of 2,319\nparticipants (mean age 69 (SD 7) years; 1154 women) of the Rotterdam Study,\nprospectively collected between 2003 and 2006. These data were used to\nretrospectively develop and validate a deep-learning-based method for automated\nICAC delineation and volume measurement. To evaluate the method, we compared\nmanual and automatic assessment (computed using ten-fold cross-validation) with\nrespect to 1) the agreement with an independent observer's assessment\n(available in a random subset of 47 scans); 2) the accuracy in delineating ICAC\nas judged via blinded visual comparison by an expert; 3) the association with\nfirst stroke incidence from the scan date until 2012. All method performance\nmetrics were computed using 10-fold cross-validation. Results: The automated\ndelineation of ICAC reached sensitivity of 83.8% and positive predictive value\n(PPV) of 88%. The intraclass correlation between automatic and manual ICAC\nvolume measures was 0.98 (95% CI: 0.97, 0.98; computed in the entire dataset).\nMeasured between the assessments of independent observers, sensitivity was\n73.9%, PPV was 89.5%, and intraclass correlation was 0.91 (95% CI: 0.84, 0.95;\ncomputed in the 47-scan subset). In the blinded visual comparisons, automatic\ndelineations were more accurate than manual ones (p-value = 0.01). The\nassociation of ICAC volume with incident stroke was similarly strong for both\nautomated (hazard ratio, 1.38 (95% CI: 1.12, 1.75) and manually measured\nvolumes (hazard ratio, 1.48 (95% CI: 1.20, 1.87)). Conclusions: The developed\nmodel was capable of automated segmentation and volume quantification of ICAC\nwith accuracy comparable to human experts.",
          "link": "http://arxiv.org/abs/2107.09442",
          "publishedOn": "2021-07-21T02:01:34.809Z",
          "wordCount": 756,
          "title": "Automated Segmentation and Volume Measurement of Intracranial Carotid Artery Calcification on Non-Contrast CT. (arXiv:2107.09442v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09289",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fujii_K/0/1/0/all/0/1\">Kazuma Fujii</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daiki_S/0/1/0/all/0/1\">Suehiro Daiki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kazuya_N/0/1/0/all/0/1\">Nishimura Kazuya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ryoma_B/0/1/0/all/0/1\">Bise Ryoma</a>",
          "description": "Cell detection is an essential task in cell image analysis. Recent deep\nlearning-based detection methods have achieved very promising results. In\ngeneral, these methods require exhaustively annotating the cells in an entire\nimage. If some of the cells are not annotated (imperfect annotation), the\ndetection performance significantly degrades due to noisy labels. This often\noccurs in real collaborations with biologists and even in public data-sets. Our\nproposed method takes a pseudo labeling approach for cell detection from\nimperfect annotated data. A detection convolutional neural network (CNN)\ntrained using such missing labeled data often produces over-detection. We treat\npartially labeled cells as positive samples and the detected positions except\nfor the labeled cell as unlabeled samples. Then we select reliable pseudo\nlabels from unlabeled data using recent machine learning techniques;\npositive-and-unlabeled (PU) learning and P-classification. Experiments using\nmicroscopy images for five different conditions demonstrate the effectiveness\nof the proposed method.",
          "link": "http://arxiv.org/abs/2107.09289",
          "publishedOn": "2021-07-21T02:01:34.802Z",
          "wordCount": 599,
          "title": "Cell Detection from Imperfect Annotation by Pseudo Label Selection Using P-classification. (arXiv:2107.09289v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09126",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Spetter_Goldstein_B/0/1/0/all/0/1\">Benjamin Spetter-Goldstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruiz_N/0/1/0/all/0/1\">Nataniel Ruiz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bargal_S/0/1/0/all/0/1\">Sarah Adel Bargal</a>",
          "description": "The modern open internet contains billions of public images of human faces\nacross the web, especially on social media websites used by half the world's\npopulation. In this context, Face Recognition (FR) systems have the potential\nto match faces to specific names and identities, creating glaring privacy\nconcerns. Adversarial attacks are a promising way to grant users privacy from\nFR systems by disrupting their capability to recognize faces. Yet, such attacks\ncan be perceptible to human observers, especially under the more challenging\nblack-box threat model. In the literature, the justification for the\nimperceptibility of such attacks hinges on bounding metrics such as $\\ell_p$\nnorms. However, there is not much research on how these norms match up with\nhuman perception. Through examining and measuring both the effectiveness of\nrecent black-box attacks in the face recognition setting and their\ncorresponding human perceptibility through survey data, we demonstrate the\ntrade-offs in perceptibility that occur as attacks become more aggressive. We\nalso show how the $\\ell_2$ norm and other metrics do not correlate with human\nperceptibility in a linear fashion, thus making these norms suboptimal at\nmeasuring adversarial attack perceptibility.",
          "link": "http://arxiv.org/abs/2107.09126",
          "publishedOn": "2021-07-21T02:01:34.606Z",
          "wordCount": 638,
          "title": "Examining the Human Perceptibility of Black-Box Adversarial Attacks on Face Recognition. (arXiv:2107.09126v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09225",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1\">Shaohao Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xian_Y/0/1/0/all/0/1\">Yuqiao Xian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_K/0/1/0/all/0/1\">Ke Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yi Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xing Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1\">Xiaowei Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Feiyue Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_W/0/1/0/all/0/1\">Wei-Shi Zheng</a>",
          "description": "The Deep Neural Networks are vulnerable toadversarial exam-ples(Figure 1),\nmaking the DNNs-based systems collapsed byadding the inconspicuous\nperturbations to the images. Most of the existing works for adversarial attack\nare gradient-based and suf-fer from the latency efficiencies and the load on\nGPU memory. Thegenerative-based adversarial attacks can get rid of this\nlimitation,and some relative works propose the approaches based on GAN.However,\nsuffering from the difficulty of the convergence of train-ing a GAN, the\nadversarial examples have either bad attack abilityor bad visual quality. In\nthis work, we find that the discriminatorcould be not necessary for\ngenerative-based adversarial attack, andpropose theSymmetric Saliency-based\nAuto-Encoder (SSAE)to generate the perturbations, which is composed of the\nsaliencymap module and the angle-norm disentanglement of the featuresmodule.\nThe advantage of our proposed method lies in that it is notdepending on\ndiscriminator, and uses the generative saliency map to pay more attention to\nlabel-relevant regions. The extensive exper-iments among the various tasks,\ndatasets, and models demonstratethat the adversarial examples generated by SSAE\nnot only make thewidely-used models collapse, but also achieves good visual\nquality.The code is available at https://github.com/BravoLu/SSAE.",
          "link": "http://arxiv.org/abs/2107.09225",
          "publishedOn": "2021-07-21T02:01:34.599Z",
          "wordCount": 627,
          "title": "Discriminator-Free Generative Adversarial Attack. (arXiv:2107.09225v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09262",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghose_S/0/1/0/all/0/1\">Sanchita Ghose</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prevost_J/0/1/0/all/0/1\">John J. Prevost</a>",
          "description": "Deep learning based visual to sound generation systems essentially need to be\ndeveloped particularly considering the synchronicity aspects of visual and\naudio features with time. In this research we introduce a novel task of guiding\na class conditioned generative adversarial network with the temporal visual\ninformation of a video input for visual to sound generation task adapting the\nsynchronicity traits between audio-visual modalities. Our proposed FoleyGAN\nmodel is capable of conditioning action sequences of visual events leading\ntowards generating visually aligned realistic sound tracks. We expand our\npreviously proposed Automatic Foley dataset to train with FoleyGAN and evaluate\nour synthesized sound through human survey that shows noteworthy (on average\n81\\%) audio-visual synchronicity performance. Our approach also outperforms in\nstatistical experiments compared with other baseline models and audio-visual\ndatasets.",
          "link": "http://arxiv.org/abs/2107.09262",
          "publishedOn": "2021-07-21T02:01:34.592Z",
          "wordCount": 610,
          "title": "FoleyGAN: Visually Guided Generative Adversarial Network-Based Synchronous Sound Generation in Silent Videos. (arXiv:2107.09262v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09373",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yaqub_W/0/1/0/all/0/1\">Waheeb Yaqub</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohanty_M/0/1/0/all/0/1\">Manoranjan Mohanty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suleiman_B/0/1/0/all/0/1\">Basem Suleiman</a>",
          "description": "Online proctoring has become a necessity in online teaching. Video-based\ncrowd-sourced online proctoring solutions are being used, where an exam-taking\nstudent's video is monitored by third parties, leading to privacy concerns. In\nthis paper, we propose a privacy-preserving online proctoring system. The\nproposed image-hashing-based system can detect the student's excessive face and\nbody movement (i.e., anomalies) that is resulted when the student tries to\ncheat in the exam. The detection can be done even if the student's face is\nblurred or masked in video frames. Experiment with an in-house dataset shows\nthe usability of the proposed system.",
          "link": "http://arxiv.org/abs/2107.09373",
          "publishedOn": "2021-07-21T02:01:34.586Z",
          "wordCount": 535,
          "title": "Image-Hashing-Based Anomaly Detection for Privacy-Preserving Online Proctoring. (arXiv:2107.09373v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09372",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1\">Duy M. H. Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mai_T/0/1/0/all/0/1\">Truong T. N. Mai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Than_N/0/1/0/all/0/1\">Ngoc T. T. Than</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prange_A/0/1/0/all/0/1\">Alexander Prange</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sonntag_D/0/1/0/all/0/1\">Daniel Sonntag</a>",
          "description": "This paper investigates the problem of domain adaptation for diabetic\nretinopathy (DR) grading. We learn invariant target-domain features by defining\na novel self-supervised task based on retinal vessel image reconstructions,\ninspired by medical domain knowledge. Then, a benchmark of current\nstate-of-the-art unsupervised domain adaptation methods on the DR problem is\nprovided. It can be shown that our approach outperforms existing domain\nadaption strategies. Furthermore, when utilizing entire training data in the\ntarget domain, we are able to compete with several state-of-the-art approaches\nin final classification accuracy just by applying standard network\narchitectures and using image-level labels.",
          "link": "http://arxiv.org/abs/2107.09372",
          "publishedOn": "2021-07-21T02:01:34.567Z",
          "wordCount": 547,
          "title": "Self-Supervised Domain Adaptation for Diabetic Retinopathy Grading using Vessel Image Reconstruction. (arXiv:2107.09372v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/1805.01760",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mahpod_S/0/1/0/all/0/1\">Shahar Mahpod</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_R/0/1/0/all/0/1\">Rig Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maiorana_E/0/1/0/all/0/1\">Emanuele Maiorana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keller_Y/0/1/0/all/0/1\">Yosi Keller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Campisi_P/0/1/0/all/0/1\">Patrizio Campisi</a>",
          "description": "The accurate localization of facial landmarks is at the core of face analysis\ntasks, such as face recognition and facial expression analysis, to name a few.\nIn this work, we propose a novel localization approach based on a deep learning\narchitecture that utilizes cascaded subnetworks with convolutional neural\nnetwork units. The cascaded units of the first subnetwork estimate\nheatmap-based encodings of the landmarks locations, while the cascaded units of\nthe second subnetwork receive as input the output of the corresponding heatmap\nestimation units, and refine them through regression. The proposed scheme is\nexperimentally shown to compare favorably with contemporary state-of-the-art\nschemes, especially when applied to images depicting challenging localization\nconditions.",
          "link": "http://arxiv.org/abs/1805.01760",
          "publishedOn": "2021-07-21T02:01:34.559Z",
          "wordCount": 587,
          "title": "Facial Landmarks Localization using Cascaded Neural Networks. (arXiv:1805.01760v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1906.00184",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jianxin Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1\">Yingce Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Sen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Shuqin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhibo Chen</a>",
          "description": "Image-to-image translation models have shown remarkable ability on\ntransferring images among different domains. Most of existing work follows the\nsetting that the source domain and target domain keep the same at training and\ninference phases, which cannot be generalized to the scenarios for translating\nan image from an unseen domain to another unseen domain. In this work, we\npropose the Unsupervised Zero-Shot Image-to-image Translation (UZSIT) problem,\nwhich aims to learn a model that can translate samples from image domains that\nare not observed during training. Accordingly, we propose a framework called\nZstGAN: By introducing an adversarial training scheme, ZstGAN learns to model\neach domain with domain-specific feature distribution that is semantically\nconsistent on vision and attribute modalities. Then the domain-invariant\nfeatures are disentangled with an shared encoder for image generation. We carry\nout extensive experiments on CUB and FLO datasets, and the results demonstrate\nthe effectiveness of proposed method on UZSIT task. Moreover, ZstGAN shows\nsignificant accuracy improvements over state-of-the-art zero-shot learning\nmethods on CUB and FLO.",
          "link": "http://arxiv.org/abs/1906.00184",
          "publishedOn": "2021-07-21T02:01:34.552Z",
          "wordCount": 641,
          "title": "ZstGAN: An Adversarial Approach for Unsupervised Zero-Shot Image-to-Image Translation. (arXiv:1906.00184v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.09211",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mahadev_R/0/1/0/all/0/1\">Rohan Mahadev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakravarti_A/0/1/0/all/0/1\">Anindya Chakravarti</a>",
          "description": "Large scale image classification models trained on top of popular datasets\nsuch as Imagenet have shown to have a distributional skew which leads to\ndisparities in prediction accuracies across different subsections of population\ndemographics. A lot of approaches have been made to solve for this\ndistributional skew using methods that alter the model pre, post and during\ntraining. We investigate one such approach - which uses a multi-label softmax\nloss with cross-entropy as the loss function instead of a binary cross-entropy\non a multi-label classification problem on the Inclusive Images dataset which\nis a subset of the OpenImages V6 dataset. We use the MR2 dataset, which\ncontains images of people with self-identified gender and race attributes to\nevaluate the fairness in the model outcomes and try to interpret the mistakes\nby looking at model activations and suggest possible fixes.",
          "link": "http://arxiv.org/abs/2107.09211",
          "publishedOn": "2021-07-21T02:01:34.545Z",
          "wordCount": 572,
          "title": "Understanding Gender and Racial Disparities in Image Recognition Models. (arXiv:2107.09211v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09255",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuanzhou Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_S/0/1/0/all/0/1\">Shaobo Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuxin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Junchi Yan</a>",
          "description": "Electronic Line Calling is an auxiliary referee system used for tennis\nmatches based on binocular vision technology. While ELC has been widely used,\nthere are still many problems, such as complex installation and maintenance,\nhigh cost and etc. We propose a monocular vision technology based ELC method.\nThe method has the following steps. First, locate the tennis ball's trajectory.\nWe propose a multistage tennis ball positioning approach combining background\nsubtraction and color area filtering. Then we propose a bouncing point\nprediction method by minimizing the fitting loss of the uncertain point.\nFinally, we find out whether the bouncing point of the ball is out of bounds or\nnot according to the relative position between the bouncing point and the court\nside line in the two dimensional image. We collected and tagged 394 samples\nwith an accuracy rate of 99.4%, and 81.8% of the 11 samples with bouncing\npoints.The experimental results show that our method is feasible to judge if a\nball is out of the court with monocular vision and significantly reduce complex\ninstallation and costs of ELC system with binocular vision.",
          "link": "http://arxiv.org/abs/2107.09255",
          "publishedOn": "2021-07-21T02:01:34.539Z",
          "wordCount": 625,
          "title": "Monocular Visual Analysis for Electronic Line Calling of Tennis Games. (arXiv:2107.09255v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09313",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yim_M/0/1/0/all/0/1\">Moonbin Yim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Yoonsik Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_H/0/1/0/all/0/1\">Han-Cheol Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Sungrae Park</a>",
          "description": "For successful scene text recognition (STR) models, synthetic text image\ngenerators have alleviated the lack of annotated text images from the real\nworld. Specifically, they generate multiple text images with diverse\nbackgrounds, font styles, and text shapes and enable STR models to learn visual\npatterns that might not be accessible from manually annotated data. In this\npaper, we introduce a new synthetic text image generator, SynthTIGER, by\nanalyzing techniques used for text image synthesis and integrating effective\nones under a single algorithm. Moreover, we propose two techniques that\nalleviate the long-tail problem in length and character distributions of\ntraining data. In our experiments, SynthTIGER achieves better STR performance\nthan the combination of synthetic datasets, MJSynth (MJ) and SynthText (ST).\nOur ablation study demonstrates the benefits of using sub-components of\nSynthTIGER and the guideline on generating synthetic text images for STR\nmodels. Our implementation is publicly available at\nhttps://github.com/clovaai/synthtiger.",
          "link": "http://arxiv.org/abs/2107.09313",
          "publishedOn": "2021-07-21T02:01:34.521Z",
          "wordCount": 599,
          "title": "SynthTIGER: Synthetic Text Image GEneratoR Towards Better Text Recognition Models. (arXiv:2107.09313v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09249",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yifan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hooi_B/0/1/0/all/0/1\">Bryan Hooi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_L/0/1/0/all/0/1\">Lanqing Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jiashi Feng</a>",
          "description": "Existing long-tailed recognition methods, aiming to train class-balance\nmodels from long-tailed data, generally assume the models would be evaluated on\nthe uniform test class distribution. However, the practical test class\ndistribution often violates such an assumption (e.g., being long-tailed or even\ninversely long-tailed), which would lead existing methods to fail in real-world\napplications. In this work, we study a more practical task setting, called\ntest-agnostic long-tailed recognition, where the training class distribution is\nlong-tailed while the test class distribution is unknown and can be skewed\narbitrarily. In addition to the issue of class imbalance, this task poses\nanother challenge: the class distribution shift between the training and test\nsamples is unidentified. To address this task, we propose a new method, called\nTest-time Aggregating Diverse Experts (TADE), that presents two solution\nstrategies: (1) a novel skill-diverse expert learning strategy that trains\ndiverse experts to excel at handling different test distributions from a single\nlong-tailed training distribution; (2) a novel test-time expert aggregation\nstrategy that leverages self-supervision to aggregate multiple experts for\nhandling various test distributions. Moreover, we theoretically show that our\nmethod has provable ability to simulate unknown test class distributions.\nPromising results on both vanilla and test-agnostic long-tailed recognition\nverify the effectiveness of TADE. Code is available at\nhttps://github.com/Vanint/TADE-AgnosticLT.",
          "link": "http://arxiv.org/abs/2107.09249",
          "publishedOn": "2021-07-21T02:01:34.514Z",
          "wordCount": 651,
          "title": "Test-Agnostic Long-Tailed Recognition by Test-Time Aggregating Diverse Experts with Self-Supervision. (arXiv:2107.09249v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09405",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Schirris_Y/0/1/0/all/0/1\">Yoni Schirris</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gavves_E/0/1/0/all/0/1\">Efstratios Gavves</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nederlof_I/0/1/0/all/0/1\">Iris Nederlof</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Horlings_H/0/1/0/all/0/1\">Hugo Mark Horlings</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Teuwen_J/0/1/0/all/0/1\">Jonas Teuwen</a>",
          "description": "We propose a Deep learning-based weak label learning method for analysing\nwhole slide images (WSIs) of Hematoxylin and Eosin (H&E) stained tumorcells not\nrequiring pixel-level or tile-level annotations using Self-supervised\npre-training and heterogeneity-aware deep Multiple Instance LEarning\n(DeepSMILE). We apply DeepSMILE to the task of Homologous recombination\ndeficiency (HRD) and microsatellite instability (MSI) prediction. We utilize\ncontrastive self-supervised learning to pre-train a feature extractor on\nhistopathology tiles of cancer tissue. Additionally, we use variability-aware\ndeep multiple instance learning to learn the tile feature aggregation function\nwhile modeling tumor heterogeneity. Compared to state-of-the-art genomic label\nclassification methods, DeepSMILE improves classification performance for HRD\nfrom $70.43\\pm4.10\\%$ to $83.79\\pm1.25\\%$ AUC and MSI from $78.56\\pm6.24\\%$ to\n$90.32\\pm3.58\\%$ AUC in a multi-center breast and colorectal cancer dataset,\nrespectively. These improvements suggest we can improve genomic label\nclassification performance without collecting larger datasets. In the future,\nthis may reduce the need for expensive genome sequencing techniques, provide\npersonalized therapy recommendations based on widely available WSIs of cancer\ntissue, and improve patient care with quicker treatment decisions - also in\nmedical centers without access to genome sequencing resources.",
          "link": "http://arxiv.org/abs/2107.09405",
          "publishedOn": "2021-07-21T02:01:34.507Z",
          "wordCount": 654,
          "title": "DeepSMILE: Self-supervised heterogeneity-aware multiple instance learning for DNA damage response defect classification directly from H&E whole-slide images. (arXiv:2107.09405v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09362",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ito_H/0/1/0/all/0/1\">Hiroki Ito</a>, <a href=\"http://arxiv.org/find/eess/1/au:+AprilPyone_M/0/1/0/all/0/1\">MaungMaung AprilPyone</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kiya_H/0/1/0/all/0/1\">Hitoshi Kiya</a>",
          "description": "Since production-level trained deep neural networks (DNNs) are of a great\nbusiness value, protecting such DNN models against copyright infringement and\nunauthorized access is in a rising demand. However, conventional model\nprotection methods focused only the image classification task, and these\nprotection methods were never applied to semantic segmentation although it has\nan increasing number of applications. In this paper, we propose to protect\nsemantic segmentation models from unauthorized access by utilizing block-wise\ntransformation with a secret key for the first time. Protected models are\ntrained by using transformed images. Experiment results show that the proposed\nprotection method allows rightful users with the correct key to access the\nmodel to full capacity and deteriorate the performance for unauthorized users.\nHowever, protected models slightly drop the segmentation performance compared\nto non-protected models.",
          "link": "http://arxiv.org/abs/2107.09362",
          "publishedOn": "2021-07-21T02:01:34.500Z",
          "wordCount": 606,
          "title": "Protecting Semantic Segmentation Models by Using Block-wise Image Encryption with Secret Key from Unauthorized Access. (arXiv:2107.09362v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09427",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenlong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yihao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_C/0/1/0/all/0/1\">Chao Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1\">Yu Qiao</a>",
          "description": "Generative Adversarial Networks (GAN) have demonstrated the potential to\nrecover realistic details for single image super-resolution (SISR). To further\nimprove the visual quality of super-resolved results, PIRM2018-SR Challenge\nemployed perceptual metrics to assess the perceptual quality, such as PI, NIQE,\nand Ma. However, existing methods cannot directly optimize these\nindifferentiable perceptual metrics, which are shown to be highly correlated\nwith human ratings. To address the problem, we propose Super-Resolution\nGenerative Adversarial Networks with Ranker (RankSRGAN) to optimize generator\nin the direction of different perceptual metrics. Specifically, we first train\na Ranker which can learn the behaviour of perceptual metrics and then introduce\na novel rank-content loss to optimize the perceptual quality. The most\nappealing part is that the proposed method can combine the strengths of\ndifferent SR methods to generate better results. Furthermore, we extend our\nmethod to multiple Rankers to provide multi-dimension constraints for the\ngenerator. Extensive experiments show that RankSRGAN achieves visually pleasing\nresults and reaches state-of-the-art performance in perceptual metrics and\nquality. Project page: https://wenlongzhang0517.github.io/Projects/RankSRGAN",
          "link": "http://arxiv.org/abs/2107.09427",
          "publishedOn": "2021-07-21T02:01:34.493Z",
          "wordCount": 621,
          "title": "RankSRGAN: Super Resolution Generative Adversarial Networks with Learning to Rank. (arXiv:2107.09427v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09244",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Li Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yao Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_H/0/1/0/all/0/1\">Hao Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_D/0/1/0/all/0/1\">Donghai Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yue_J/0/1/0/all/0/1\">Jiabao Yue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1\">Rui Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1\">Ao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_S/0/1/0/all/0/1\">Shouye Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_B/0/1/0/all/0/1\">Bitao Jiang</a>",
          "description": "Collecting large-scale annotated satellite imagery datasets is essential for\ndeep-learning-based global building change surveillance. In particular, the\nscroll imaging mode of optical satellites enables larger observation ranges and\nshorter revisit periods, facilitating efficient global surveillance. However,\nthe images in recent satellite change detection datasets are mainly captured at\nnear-nadir viewing angles. In this paper, we introduce S2Looking, a building\nchange detection dataset that contains large-scale side-looking satellite\nimages captured at varying off-nadir angles. Our S2Looking dataset consists of\n5000 registered bitemporal image pairs (size of 1024*1024, 0.5 ~ 0.8 m/pixel)\nof rural areas throughout the world and more than 65,920 annotated change\ninstances. We provide two label maps to separately indicate the newly built and\ndemolished building regions for each sample in the dataset. We establish a\nbenchmark task based on this dataset, i.e., identifying the pixel-level\nbuilding changes in the bi-temporal images. We test several state-of-the-art\nmethods on both the S2Looking dataset and the (near-nadir) LEVIR-CD+ dataset.\nThe experimental results show that recent change detection methods exhibit much\npoorer performance on the S2Looking than on LEVIR-CD+. The proposed S2Looking\ndataset presents three main challenges: 1) large viewing angle changes, 2)\nlarge illumination variances and 3) various complex scene characteristics\nencountered in rural areas. Our proposed dataset may promote the development of\nalgorithms for satellite image change detection and registration under\nconditions of large off-nadir angles. The dataset is available at\nhttps://github.com/AnonymousForACMMM/.",
          "link": "http://arxiv.org/abs/2107.09244",
          "publishedOn": "2021-07-21T02:01:34.485Z",
          "wordCount": 696,
          "title": "S2Looking: A Satellite Side-Looking Dataset for Building Change Detection. (arXiv:2107.09244v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09270",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+He_M/0/1/0/all/0/1\">Mingjie He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jie Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shan_S/0/1/0/all/0/1\">Shiguang Shan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhongqin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xilin Chen</a>",
          "description": "Face recognition remains a challenging task in unconstrained scenarios,\nespecially when faces are partially occluded. To improve the robustness against\nocclusion, augmenting the training images with artificial occlusions has been\nproved as a useful approach. However, these artificial occlusions are commonly\ngenerated by adding a black rectangle or several object templates including\nsunglasses, scarfs and phones, which cannot well simulate the realistic\nocclusions. In this paper, based on the argument that the occlusion essentially\ndamages a group of neurons, we propose a novel and elegant occlusion-simulation\nmethod via dropping the activations of a group of neurons in some elaborately\nselected channel. Specifically, we first employ a spatial regularization to\nencourage each feature channel to respond to local and different face regions.\nIn this way, the activations affected by an occlusion in a local region are\nmore likely to be located in a single feature channel. Then, the locality-aware\nchannel-wise dropout (LCD) is designed to simulate the occlusion by dropping\nout the entire feature channel. Furthermore, by randomly dropping out several\nfeature channels, our method can well simulate the occlusion of larger area.\nThe proposed LCD can encourage its succeeding layers to minimize the\nintra-class feature variance caused by occlusions, thus leading to improved\nrobustness against occlusion. In addition, we design an auxiliary spatial\nattention module by learning a channel-wise attention vector to reweight the\nfeature channels, which improves the contributions of non-occluded regions.\nExtensive experiments on various benchmarks show that the proposed method\noutperforms state-of-the-art methods with a remarkable improvement.",
          "link": "http://arxiv.org/abs/2107.09270",
          "publishedOn": "2021-07-21T02:01:34.462Z",
          "wordCount": 688,
          "title": "Locality-aware Channel-wise Dropout for Occluded Face Recognition. (arXiv:2107.09270v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09240",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yi-Fu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_J/0/1/0/all/0/1\">Jaesik Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahn_S/0/1/0/all/0/1\">Sungjin Ahn</a>",
          "description": "Transformers have been successful for many natural language processing tasks.\nHowever, applying transformers to the video domain for tasks such as long-term\nvideo generation and scene understanding has remained elusive due to the high\ncomputational complexity and the lack of natural tokenization. In this paper,\nwe propose the Object-Centric Video Transformer (OCVT) which utilizes an\nobject-centric approach for decomposing scenes into tokens suitable for use in\na generative video transformer. By factoring the video into objects, our fully\nunsupervised model is able to learn complex spatio-temporal dynamics of\nmultiple interacting objects in a scene and generate future frames of the\nvideo. Our model is also significantly more memory-efficient than pixel-based\nmodels and thus able to train on videos of length up to 70 frames with a single\n48GB GPU. We compare our model with previous RNN-based approaches as well as\nother possible video transformer baselines. We demonstrate OCVT performs well\nwhen compared to baselines in generating future frames. OCVT also develops\nuseful representations for video reasoning, achieving start-of-the-art\nperformance on the CATER task.",
          "link": "http://arxiv.org/abs/2107.09240",
          "publishedOn": "2021-07-21T02:01:34.453Z",
          "wordCount": 618,
          "title": "Generative Video Transformer: Can Objects be the Words?. (arXiv:2107.09240v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09543",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Osuala_R/0/1/0/all/0/1\">Richard Osuala</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kushibar_K/0/1/0/all/0/1\">Kaisar Kushibar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Garrucho_L/0/1/0/all/0/1\">Lidia Garrucho</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Linardos_A/0/1/0/all/0/1\">Akis Linardos</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Szafranowska_Z/0/1/0/all/0/1\">Zuzanna Szafranowska</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Klein_S/0/1/0/all/0/1\">Stefan Klein</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Glocker_B/0/1/0/all/0/1\">Ben Glocker</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Diaz_O/0/1/0/all/0/1\">Oliver Diaz</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lekadir_K/0/1/0/all/0/1\">Karim Lekadir</a>",
          "description": "Despite technological and medical advances, the detection, interpretation,\nand treatment of cancer based on imaging data continue to pose significant\nchallenges. These include high inter-observer variability, difficulty of\nsmall-sized lesion detection, nodule interpretation and malignancy\ndetermination, inter- and intra-tumour heterogeneity, class imbalance,\nsegmentation inaccuracies, and treatment effect uncertainty. The recent\nadvancements in Generative Adversarial Networks (GANs) in computer vision as\nwell as in medical imaging may provide a basis for enhanced capabilities in\ncancer detection and analysis. In this review, we assess the potential of GANs\nto address a number of key challenges of cancer imaging, including data\nscarcity and imbalance, domain and dataset shifts, data access and privacy,\ndata annotation and quantification, as well as cancer detection, tumour\nprofiling and treatment planning. We provide a critical appraisal of the\nexisting literature of GANs applied to cancer imagery, together with\nsuggestions on future research directions to address these challenges. We\nanalyse and discuss 163 papers that apply adversarial training techniques in\nthe context of cancer imaging and elaborate their methodologies, advantages and\nlimitations. With this work, we strive to bridge the gap between the needs of\nthe clinical cancer imaging community and the current and prospective research\non GANs in the artificial intelligence community.",
          "link": "http://arxiv.org/abs/2107.09543",
          "publishedOn": "2021-07-21T02:01:34.445Z",
          "wordCount": 691,
          "title": "A Review of Generative Adversarial Networks in Cancer Imaging: New Applications, New Solutions. (arXiv:2107.09543v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09287",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Byrnes_O/0/1/0/all/0/1\">Olivia Byrnes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+La_W/0/1/0/all/0/1\">Wendy La</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1\">Congbo Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_M/0/1/0/all/0/1\">Minhui Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qi Wu</a>",
          "description": "Data hiding is the process of embedding information into a noise-tolerant\nsignal such as a piece of audio, video, or image. Digital watermarking is a\nform of data hiding where identifying data is robustly embedded so that it can\nresist tampering and be used to identify the original owners of the media.\nSteganography, another form of data hiding, embeds data for the purpose of\nsecure and secret communication. This survey summarises recent developments in\ndeep learning techniques for data hiding for the purposes of watermarking and\nsteganography, categorising them based on model architectures and noise\ninjection methods. The objective functions, evaluation metrics, and datasets\nused for training these data hiding models are comprehensively summarised.\nFinally, we propose and discuss possible future directions for research into\ndeep data hiding techniques.",
          "link": "http://arxiv.org/abs/2107.09287",
          "publishedOn": "2021-07-21T02:01:34.418Z",
          "wordCount": 577,
          "title": "Data Hiding with Deep Learning: A Survey Unifying Digital Watermarking and Steganography. (arXiv:2107.09287v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09101",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nousias_S/0/1/0/all/0/1\">Stavros Nousias</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pikoulis_E/0/1/0/all/0/1\">Erion-Vasilis Pikoulis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mavrokefalidis_C/0/1/0/all/0/1\">Christos Mavrokefalidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lalos_A/0/1/0/all/0/1\">Aris S. Lalos</a>",
          "description": "Automotive Cyber-Physical Systems (ACPS) have attracted a significant amount\nof interest in the past few decades, while one of the most critical operations\nin these systems is the perception of the environment. Deep learning and,\nespecially, the use of Deep Neural Networks (DNNs) provides impressive results\nin analyzing and understanding complex and dynamic scenes from visual data. The\nprediction horizons for those perception systems are very short and inference\nmust often be performed in real time, stressing the need of transforming the\noriginal large pre-trained networks into new smaller models, by utilizing Model\nCompression and Acceleration (MCA) techniques. Our goal in this work is to\ninvestigate best practices for appropriately applying novel weight sharing\ntechniques, optimizing the available variables and the training procedures\ntowards the significant acceleration of widely adopted DNNs. Extensive\nevaluation studies carried out using various state-of-the-art DNN models in\nobject detection and tracking experiments, provide details about the type of\nerrors that manifest after the application of weight sharing techniques,\nresulting in significant acceleration gains with negligible accuracy losses.",
          "link": "http://arxiv.org/abs/2107.09101",
          "publishedOn": "2021-07-21T02:01:34.411Z",
          "wordCount": 620,
          "title": "Accelerating deep neural networks for efficient scene understanding in automotive cyber-physical systems. (arXiv:2107.09101v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09559",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Billot_B/0/1/0/all/0/1\">Benjamin Billot</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Greve_D/0/1/0/all/0/1\">Douglas N. Greve</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Puonti_O/0/1/0/all/0/1\">Oula Puonti</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Thielscher_A/0/1/0/all/0/1\">Axel Thielscher</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Leemput_K/0/1/0/all/0/1\">Koen Van Leemput</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fischl_B/0/1/0/all/0/1\">Bruce Fischl</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dalca_A/0/1/0/all/0/1\">Adrian V. Dalca</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Iglesias_J/0/1/0/all/0/1\">Juan Eugenio Iglesias</a>",
          "description": "Despite advances in data augmentation and transfer learning, convolutional\nneural networks (CNNs) have difficulties generalising to unseen target domains.\nWhen applied to segmentation of brain MRI scans, CNNs are highly sensitive to\nchanges in resolution and contrast: even within the same MR modality, decreases\nin performance can be observed across datasets. We introduce SynthSeg, the\nfirst segmentation CNN agnostic to brain MRI scans of any contrast and\nresolution. SynthSeg is trained with synthetic data sampled from a generative\nmodel inspired by Bayesian segmentation. Crucially, we adopt a \\textit{domain\nrandomisation} strategy where we fully randomise the generation parameters to\nmaximise the variability of the training data. Consequently, SynthSeg can\nsegment preprocessed and unpreprocessed real scans of any target domain,\nwithout retraining or fine-tuning. Because SynthSeg only requires segmentations\nto be trained (no images), it can learn from label maps obtained automatically\nfrom existing datasets of different populations (e.g., with atrophy and\nlesions), thus achieving robustness to a wide range of morphological\nvariability. We demonstrate SynthSeg on 5,500 scans of 6 modalities and 10\nresolutions, where it exhibits unparalleled generalisation compared to\nsupervised CNNs, test time adaptation, and Bayesian segmentation. The code and\ntrained model are available at https://github.com/BBillot/SynthSeg.",
          "link": "http://arxiv.org/abs/2107.09559",
          "publishedOn": "2021-07-21T02:01:34.386Z",
          "wordCount": 676,
          "title": "SynthSeg: Domain Randomisation for Segmentation of Brain MRI Scans of any Contrast and Resolution. (arXiv:2107.09559v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09204",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wilmet_V/0/1/0/all/0/1\">Vincent Wilmet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verma_S/0/1/0/all/0/1\">Sauraj Verma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Redl_T/0/1/0/all/0/1\">Tabea Redl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sandaker_H/0/1/0/all/0/1\">H&#xe5;kon Sandaker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhenning Li</a>",
          "description": "Anomaly detection in images plays a significant role for many applications\nacross all industries, such as disease diagnosis in healthcare or quality\nassurance in manufacturing. Manual inspection of images, when extended over a\nmonotonously repetitive period of time is very time consuming and can lead to\nanomalies being overlooked.Artificial neural networks have proven themselves\nvery successful on simple, repetitive tasks, in some cases even outperforming\nhumans. Therefore, in this paper we investigate different methods of deep\nlearning, including supervised and unsupervised learning, for anomaly detection\napplied to a quality assurance use case. We utilize the MVTec anomaly dataset\nand develop three different models, a CNN for supervised anomaly detection,\nKD-CAE for autoencoder anomaly detection, NI-CAE for noise induced anomaly\ndetection and a DCGAN for generating reconstructed images. By experiments, we\nfound that KD-CAE performs better on the anomaly datasets compared to CNN and\nNI-CAE, with NI-CAE performing the best on the Transistor dataset. We also\nimplemented a DCGAN for the creation of new training data but due to\ncomputational limitation and lack of extrapolating the mechanics of AnoGAN, we\nrestricted ourselves just to the generation of GAN based images. We conclude\nthat unsupervised methods are more powerful for anomaly detection in images,\nespecially in a setting where only a small amount of anomalous data is\navailable, or the data is unlabeled.",
          "link": "http://arxiv.org/abs/2107.09204",
          "publishedOn": "2021-07-21T02:01:34.379Z",
          "wordCount": 686,
          "title": "A Comparison of Supervised and Unsupervised Deep Learning Methods for Anomaly Detection in Images. (arXiv:2107.09204v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09504",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zatsarynna_O/0/1/0/all/0/1\">Olga Zatsarynna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farha_Y/0/1/0/all/0/1\">Yazan Abu Farha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gall_J/0/1/0/all/0/1\">Juergen Gall</a>",
          "description": "Anticipating human actions is an important task that needs to be addressed\nfor the development of reliable intelligent agents, such as self-driving cars\nor robot assistants. While the ability to make future predictions with high\naccuracy is crucial for designing the anticipation approaches, the speed at\nwhich the inference is performed is not less important. Methods that are\naccurate but not sufficiently fast would introduce a high latency into the\ndecision process. Thus, this will increase the reaction time of the underlying\nsystem. This poses a problem for domains such as autonomous driving, where the\nreaction time is crucial. In this work, we propose a simple and effective\nmulti-modal architecture based on temporal convolutions. Our approach stacks a\nhierarchy of temporal convolutional layers and does not rely on recurrent\nlayers to ensure a fast prediction. We further introduce a multi-modal fusion\nmechanism that captures the pairwise interactions between RGB, flow, and object\nmodalities. Results on two large-scale datasets of egocentric videos,\nEPIC-Kitchens-55 and EPIC-Kitchens-100, show that our approach achieves\ncomparable performance to the state-of-the-art approaches while being\nsignificantly faster.",
          "link": "http://arxiv.org/abs/2107.09504",
          "publishedOn": "2021-07-21T02:01:34.357Z",
          "wordCount": 622,
          "title": "Multi-Modal Temporal Convolutional Network for Anticipating Actions in Egocentric Videos. (arXiv:2107.09504v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09293",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Suzhen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lincheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1\">Yu Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1\">Changjie Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1\">Xin Yu</a>",
          "description": "We propose an audio-driven talking-head method to generate photo-realistic\ntalking-head videos from a single reference image. In this work, we tackle two\nkey challenges: (i) producing natural head motions that match speech prosody,\nand (ii) maintaining the appearance of a speaker in a large head motion while\nstabilizing the non-face regions. We first design a head pose predictor by\nmodeling rigid 6D head movements with a motion-aware recurrent neural network\n(RNN). In this way, the predicted head poses act as the low-frequency holistic\nmovements of a talking head, thus allowing our latter network to focus on\ndetailed facial movement generation. To depict the entire image motions arising\nfrom audio, we exploit a keypoint based dense motion field representation.\nThen, we develop a motion field generator to produce the dense motion fields\nfrom input audio, head poses, and a reference image. As this keypoint based\nrepresentation models the motions of facial regions, head, and backgrounds\nintegrally, our method can better constrain the spatial and temporal\nconsistency of the generated videos. Finally, an image generation network is\nemployed to render photo-realistic talking-head videos from the estimated\nkeypoint based motion fields and the input reference image. Extensive\nexperiments demonstrate that our method produces videos with plausible head\nmotions, synchronized facial expressions, and stable backgrounds and\noutperforms the state-of-the-art.",
          "link": "http://arxiv.org/abs/2107.09293",
          "publishedOn": "2021-07-21T02:01:34.351Z",
          "wordCount": 663,
          "title": "Audio2Head: Audio-driven One-shot Talking-head Generation with Natural Head Motion. (arXiv:2107.09293v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09242",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1\">Xu Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuxuan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_L/0/1/0/all/0/1\">Liangjian Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_L/0/1/0/all/0/1\">Lili Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zenglin Xu</a>",
          "description": "The goal of few-shot classification is to classify new categories with few\nlabeled examples within each class. Nowadays, the excellent performance in\nhandling few-shot classification problems is shown by metric-based\nmeta-learning methods. However, it is very hard for previous methods to\ndiscriminate the fine-grained sub-categories in the embedding space without\nfine-grained labels. This may lead to unsatisfactory generalization to\nfine-grained subcategories, and thus affects model interpretation. To tackle\nthis problem, we introduce the contrastive loss into few-shot classification\nfor learning latent fine-grained structure in the embedding space. Furthermore,\nto overcome the drawbacks of random image transformation used in current\ncontrastive learning in producing noisy and inaccurate image pairs (i.e.,\nviews), we develop a learning-to-learn algorithm to automatically generate\ndifferent views of the same image. Extensive experiments on standard few-shot\nlearning benchmarks demonstrate the superiority of our method.",
          "link": "http://arxiv.org/abs/2107.09242",
          "publishedOn": "2021-07-21T02:01:34.331Z",
          "wordCount": 578,
          "title": "Boosting few-shot classification with view-learnable contrastive learning. (arXiv:2107.09242v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09540",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Melnik_A/0/1/0/all/0/1\">Andrew Melnik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harter_A/0/1/0/all/0/1\">Augustin Harter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Limberg_C/0/1/0/all/0/1\">Christian Limberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rana_K/0/1/0/all/0/1\">Krishan Rana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suenderhauf_N/0/1/0/all/0/1\">Niko Suenderhauf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ritter_H/0/1/0/all/0/1\">Helge Ritter</a>",
          "description": "This work discusses a learning approach to mask rewarding objects in images\nusing sparse reward signals from an imitation learning dataset. For that, we\ntrain an Hourglass network using only feedback from a critic model. The\nHourglass network learns to produce a mask to decrease the critic's score of a\nhigh score image and increase the critic's score of a low score image by\nswapping the masked areas between these two images. We trained the model on an\nimitation learning dataset from the NeurIPS 2020 MineRL Competition Track,\nwhere our model learned to mask rewarding objects in a complex interactive 3D\nenvironment with a sparse reward signal. This approach was part of the 1st\nplace winning solution in this competition. Video demonstration and code:\nhttps://rebrand.ly/critic-guided-segmentation",
          "link": "http://arxiv.org/abs/2107.09540",
          "publishedOn": "2021-07-21T02:01:34.324Z",
          "wordCount": 572,
          "title": "Critic Guided Segmentation of Rewarding Objects in First-Person Views. (arXiv:2107.09540v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09237",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xingxing Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jie Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zaifeng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhenghua Chen</a>",
          "description": "Near infrared (NIR) imaging has been widely applied in low-light imaging\nscenarios; however, it is difficult for human and algorithms to perceive the\nreal scene in the colorless NIR domain. While Generative Adversarial Network\n(GAN) has been widely employed in various image colorization tasks, it is\nchallenging for a direct mapping mechanism, such as a conventional GAN, to\ntransform an image from the NIR to the RGB domain with correct semantic\nreasoning, well-preserved textures, and vivid color combinations concurrently.\nIn this work, we propose a novel Attention-based NIR image colorization\nframework via Adaptive Fusion of Semantic and Texture clues, aiming at\nachieving these goals within the same framework. The tasks of texture transfer\nand semantic reasoning are carried out in two separate network blocks.\nSpecifically, the Texture Transfer Block (TTB) aims at extracting texture\nfeatures from the NIR image's Laplacian component and transferring them for\nsubsequent color fusion. The Semantic Reasoning Block (SRB) extracts semantic\nclues and maps the NIR pixel values to the RGB domain. Finally, a Fusion\nAttention Block (FAB) is proposed to adaptively fuse the features from the two\nbranches and generate an optimized colorization result. In order to enhance the\nnetwork's learning capacity in semantic reasoning as well as mapping precision\nin texture transfer, we have proposed the Residual Coordinate Attention Block\n(RCAB), which incorporates coordinate attention into a residual learning\nframework, enabling the network to capture long-range dependencies along the\nchannel direction and meanwhile precise positional information can be preserved\nalong spatial directions. RCAB is also incorporated into FAB to facilitate\naccurate texture alignment during fusion. Both quantitative and qualitative\nevaluations show that the proposed method outperforms state-of-the-art NIR\nimage colorization methods.",
          "link": "http://arxiv.org/abs/2107.09237",
          "publishedOn": "2021-07-21T02:01:34.317Z",
          "wordCount": 721,
          "title": "Attention-Guided NIR Image Colorization via Adaptive Fusion of Semantic and Texture Clues. (arXiv:2107.09237v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09170",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vicente_J/0/1/0/all/0/1\">Juan Pablo de Vicente</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soto_A/0/1/0/all/0/1\">Alvaro Soto</a>",
          "description": "Current datasets to train social behaviors are usually borrowed from\nsurveillance applications that capture visual data from a bird's-eye\nperspective. This leaves aside precious relationships and visual cues that\ncould be captured through a first-person view of a scene. In this work, we\npropose a strategy to exploit the power of current game engines, such as Unity,\nto transform pre-existing bird's-eye view datasets into a first-person view, in\nparticular, a depth view. Using this strategy, we are able to generate large\nvolumes of synthetic data that can be used to pre-train a social navigation\nmodel. To test our ideas, we present DeepSocNav, a deep learning based model\nthat takes advantage of the proposed approach to generate synthetic data.\nFurthermore, DeepSocNav includes a self-supervised strategy that is included as\nan auxiliary task. This consists of predicting the next depth frame that the\nagent will face. Our experiments show the benefits of the proposed model that\nis able to outperform relevant baselines in terms of social navigation scores.",
          "link": "http://arxiv.org/abs/2107.09170",
          "publishedOn": "2021-07-21T02:01:34.291Z",
          "wordCount": 624,
          "title": "DeepSocNav: Social Navigation by Imitating Human Behaviors. (arXiv:2107.09170v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09179",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Bidgoli_N/0/1/0/all/0/1\">Navid Mahmoudian Bidgoli</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Azevedo_R/0/1/0/all/0/1\">Roberto G. de A. Azevedo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Maugey_T/0/1/0/all/0/1\">Thomas Maugey</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Roumy_A/0/1/0/all/0/1\">Aline Roumy</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Frossard_P/0/1/0/all/0/1\">Pascal Frossard</a>",
          "description": "State-of-the-art 2D image compression schemes rely on the power of\nconvolutional neural networks (CNNs). Although CNNs offer promising\nperspectives for 2D image compression, extending such models to omnidirectional\nimages is not straightforward. First, omnidirectional images have specific\nspatial and statistical properties that can not be fully captured by current\nCNN models. Second, basic mathematical operations composing a CNN architecture,\ne.g., translation and sampling, are not well-defined on the sphere. In this\npaper, we study the learning of representation models for omnidirectional\nimages and propose to use the properties of HEALPix uniform sampling of the\nsphere to redefine the mathematical tools used in deep learning models for\nomnidirectional images. In particular, we: i) propose the definition of a new\nconvolution operation on the sphere that keeps the high expressiveness and the\nlow complexity of a classical 2D convolution; ii) adapt standard CNN techniques\nsuch as stride, iterative aggregation, and pixel shuffling to the spherical\ndomain; and then iii) apply our new framework to the task of omnidirectional\nimage compression. Our experiments show that our proposed on-the-sphere\nsolution leads to a better compression gain that can save 13.7% of the bit rate\ncompared to similar learned models applied to equirectangular images. Also,\ncompared to learning models based on graph convolutional networks, our solution\nsupports more expressive filters that can preserve high frequencies and provide\na better perceptual quality of the compressed images. Such results demonstrate\nthe efficiency of the proposed framework, which opens new research venues for\nother omnidirectional vision tasks to be effectively implemented on the sphere\nmanifold.",
          "link": "http://arxiv.org/abs/2107.09179",
          "publishedOn": "2021-07-21T02:01:34.082Z",
          "wordCount": 719,
          "title": "OSLO: On-the-Sphere Learning for Omnidirectional images and its application to 360-degree image compression. (arXiv:2107.09179v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09136",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Dick_J/0/1/0/all/0/1\">Jo&#xe3;o Dick</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Abreu_B/0/1/0/all/0/1\">Brunno Abreu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Grellert_M/0/1/0/all/0/1\">Mateus Grellert</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bampi_S/0/1/0/all/0/1\">Sergio Bampi</a>",
          "description": "This work presents an analysis of state-of-the-art learning-based image\ncompression techniques. We compare 8 models available in the Tensorflow\nCompression package in terms of visual quality metrics and processing time,\nusing the KODAK data set. The results are compared with the Better Portable\nGraphics (BPG) and the JPEG2000 codecs. Results show that JPEG2000 has the\nlowest execution times compared with the fastest learning-based model, with a\nspeedup of 1.46x in compression and 30x in decompression. However, the\nlearning-based models achieved improvements over JPEG2000 in terms of quality,\nspecially for lower bitrates. Our findings also show that BPG is more efficient\nin terms of PSNR, but the learning models are better for other quality metrics,\nand sometimes even faster. The results indicate that learning-based techniques\nare promising solutions towards a future mainstream compression method.",
          "link": "http://arxiv.org/abs/2107.09136",
          "publishedOn": "2021-07-21T02:01:33.936Z",
          "wordCount": 584,
          "title": "Quality and Complexity Assessment of Learning-Based Image Compression Solutions. (arXiv:2107.09136v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09106",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Whitehead_S/0/1/0/all/0/1\">Spencer Whitehead</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Hui Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feris_R/0/1/0/all/0/1\">Rogerio Feris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saenko_K/0/1/0/all/0/1\">Kate Saenko</a>",
          "description": "Generalization to out-of-distribution data has been a problem for Visual\nQuestion Answering (VQA) models. To measure generalization to novel questions,\nwe propose to separate them into \"skills\" and \"concepts\". \"Skills\" are visual\ntasks, such as counting or attribute recognition, and are applied to \"concepts\"\nmentioned in the question, such as objects and people. VQA methods should be\nable to compose skills and concepts in novel ways, regardless of whether the\nspecific composition has been seen in training, yet we demonstrate that\nexisting models have much to improve upon towards handling new compositions. We\npresent a novel method for learning to compose skills and concepts that\nseparates these two factors implicitly within a model by learning grounded\nconcept representations and disentangling the encoding of skills from that of\nconcepts. We enforce these properties with a novel contrastive learning\nprocedure that does not rely on external annotations and can be learned from\nunlabeled image-question pairs. Experiments demonstrate the effectiveness of\nour approach for improving compositional and grounding performance.",
          "link": "http://arxiv.org/abs/2107.09106",
          "publishedOn": "2021-07-21T02:01:33.922Z",
          "wordCount": 624,
          "title": "Separating Skills and Concepts for Novel Visual Question Answering. (arXiv:2107.09106v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09134",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Lima_D/0/1/0/all/0/1\">Daniel Lima</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Graves_C/0/1/0/all/0/1\">Catharine Graves</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gutierrez_M/0/1/0/all/0/1\">Marco Gutierrez</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Brandoli_B/0/1/0/all/0/1\">Bruno Brandoli</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jose_J/0/1/0/all/0/1\">Jose Rodrigues-Jr</a>",
          "description": "Magnetic resonance imaging (MRI) is a widely known medical imaging technique\nused to assess the heart function. Deep learning (DL) models perform several\ntasks in cardiac MRI (CMR) images with good efficacy, such as segmentation,\nestimation, and detection of diseases. Many DL models based on convolutional\nneural networks (CNN) were improved by detecting regions-of-interest (ROI)\neither automatically or by hand. In this paper we describe Visual-Motion-Focus\n(VMF), a module that detects the heart motion in the 4D MRI sequence, and\nhighlights ROIs by focusing a Radial Basis Function (RBF) on the estimated\nmotion field. We experimented and evaluated VMF on three CMR datasets,\nobserving that the proposed ROIs cover 99.7% of data labels (Recall score),\nimproved the CNN segmentation (mean Dice score) by 1.7 (p < .001) after the ROI\nextraction, and improved the overall training speed by 2.5 times (+150%).",
          "link": "http://arxiv.org/abs/2107.09134",
          "publishedOn": "2021-07-21T02:01:33.906Z",
          "wordCount": 609,
          "title": "Convolutional module for heart localization and segmentation in MRI. (arXiv:2107.09134v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09060",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Kustner_T/0/1/0/all/0/1\">Thomas K&#xfc;stner</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pan_J/0/1/0/all/0/1\">Jiazhen Pan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Qi_H/0/1/0/all/0/1\">Haikun Qi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cruz_G/0/1/0/all/0/1\">Gastao Cruz</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gilliam_C/0/1/0/all/0/1\">Christopher Gilliam</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Blu_T/0/1/0/all/0/1\">Thierry Blu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_B/0/1/0/all/0/1\">Bin Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gatidis_S/0/1/0/all/0/1\">Sergios Gatidis</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Botnar_R/0/1/0/all/0/1\">Ren&#xe9; Botnar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Prieto_C/0/1/0/all/0/1\">Claudia Prieto</a>",
          "description": "Physiological motion, such as cardiac and respiratory motion, during Magnetic\nResonance (MR) image acquisition can cause image artifacts. Motion correction\ntechniques have been proposed to compensate for these types of motion during\nthoracic scans, relying on accurate motion estimation from undersampled\nmotion-resolved reconstruction. A particular interest and challenge lie in the\nderivation of reliable non-rigid motion fields from the undersampled\nmotion-resolved data. Motion estimation is usually formulated in image space\nvia diffusion, parametric-spline, or optical flow methods. However, image-based\nregistration can be impaired by remaining aliasing artifacts due to the\nundersampled motion-resolved reconstruction. In this work, we describe a\nformalism to perform non-rigid registration directly in the sampled Fourier\nspace, i.e. k-space. We propose a deep-learning based approach to perform fast\nand accurate non-rigid registration from the undersampled k-space data. The\nbasic working principle originates from the Local All-Pass (LAP) technique, a\nrecently introduced optical flow-based registration. The proposed LAPNet is\ncompared against traditional and deep learning image-based registrations and\ntested on fully-sampled and highly-accelerated (with two undersampling\nstrategies) 3D respiratory motion-resolved MR images in a cohort of 40 patients\nwith suspected liver or lung metastases and 25 healthy subjects. The proposed\nLAPNet provided consistent and superior performance to image-based approaches\nthroughout different sampling trajectories and acceleration factors.",
          "link": "http://arxiv.org/abs/2107.09060",
          "publishedOn": "2021-07-21T02:01:33.895Z",
          "wordCount": 677,
          "title": "LAPNet: Non-rigid Registration derived in k-space for Magnetic Resonance Imaging. (arXiv:2107.09060v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09118",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Khaledyan_D/0/1/0/all/0/1\">Donya Khaledyan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tajally_A/0/1/0/all/0/1\">AmirReza Tajally</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sarkhosh_R/0/1/0/all/0/1\">Reza Sarkhosh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shamsi_A/0/1/0/all/0/1\">Afshar Shamsi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Asgharnezhad_H/0/1/0/all/0/1\">Hamzeh Asgharnezhad</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Khosravi_A/0/1/0/all/0/1\">Abbas Khosravi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nahavandi_S/0/1/0/all/0/1\">Saeid Nahavandi</a>",
          "description": "Deep learning (DL) models have received particular attention in medical\nimaging due to their promising pattern recognition capabilities. However, Deep\nNeural Networks (DNNs) require a huge amount of data, and because of the lack\nof sufficient data in this field, transfer learning can be a great solution.\nDNNs used for disease diagnosis meticulously concentrate on improving the\naccuracy of predictions without providing a figure about their confidence of\npredictions. Knowing how much a DNN model is confident in a computer-aided\ndiagnosis model is necessary for gaining clinicians' confidence and trust in\nDL-based solutions. To address this issue, this work presents three different\nmethods for quantifying uncertainties for skin cancer detection from images. It\nalso comprehensively evaluates and compares performance of these DNNs using\nnovel uncertainty-related metrics. The obtained results reveal that the\npredictive uncertainty estimation methods are capable of flagging risky and\nerroneous predictions with a high uncertainty estimate. We also demonstrate\nthat ensemble approaches are more reliable in capturing uncertainties through\ninference.",
          "link": "http://arxiv.org/abs/2107.09118",
          "publishedOn": "2021-07-21T02:01:33.852Z",
          "wordCount": 625,
          "title": "Confidence Aware Neural Networks for Skin Cancer Detection. (arXiv:2107.09118v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09092",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tom_M/0/1/0/all/0/1\">Manu Tom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yuchang Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baltsavias_E/0/1/0/all/0/1\">Emmanuel Baltsavias</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schindler_K/0/1/0/all/0/1\">Konrad Schindler</a>",
          "description": "Fusing satellite imagery acquired with different sensors has been a\nlong-standing challenge of Earth observation, particularly across different\nmodalities such as optical and Synthetic Aperture Radar (SAR) images. Here, we\nexplore the joint analysis of imagery from different sensors in the light of\nrepresentation learning: we propose to learn a joint, sensor-invariant\nembedding (feature representation) within a deep neural network. Our\napplication problem is the monitoring of lake ice on Alpine lakes. To reach the\ntemporal resolution requirement of the Swiss Global Climate Observing System\n(GCOS) office, we combine three image sources: Sentinel-1 SAR (S1-SAR), Terra\nMODIS and Suomi-NPP VIIRS. The large gaps between the optical and SAR domains\nand between the sensor resolutions make this a challenging instance of the\nsensor fusion problem. Our approach can be classified as a feature-level fusion\nthat is learnt in a data-driven manner. The proposed network architecture has\nseparate encoding branches for each image sensor, which feed into a single\nlatent embedding. I.e., a common feature representation shared by all inputs,\nsuch that subsequent processing steps deliver comparable output irrespective of\nwhich sort of input image was used. By fusing satellite data, we map lake ice\nat a temporal resolution of <1.5 days. The network produces spatially explicit\nlake ice maps with pixel-wise accuracies >91.3% (respectively, mIoU scores\n>60.7%) and generalises well across different lakes and winters. Moreover, it\nsets a new state-of-the-art for determining the important ice-on and ice-off\ndates for the target lakes, in many cases meeting the GCOS requirement.",
          "link": "http://arxiv.org/abs/2107.09092",
          "publishedOn": "2021-07-21T02:01:33.823Z",
          "wordCount": 703,
          "title": "Learning a Sensor-invariant Embedding of Satellite Data: A Case Study for Lake Ice Monitoring. (arXiv:2107.09092v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08211",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1\">Soumyadeep Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Sanjay Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verma_J/0/1/0/all/0/1\">Janu Verma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1\">Awanish Kumar</a>",
          "description": "In order to train robust deep learning models, large amounts of labelled data\nis required. However, in the absence of such large repositories of labelled\ndata, unlabeled data can be exploited for the same. Semi-Supervised learning\naims to utilize such unlabeled data for training classification models. Recent\nprogress of self-training based approaches have shown promise in this area,\nwhich leads to this study where we utilize an ensemble approach for the same. A\nby-product of any semi-supervised approach may be loss of calibration of the\ntrained model especially in scenarios where unlabeled data may contain\nout-of-distribution samples, which leads to this investigation on how to adapt\nto such effects. Our proposed algorithm carefully avoids common pitfalls in\nutilizing unlabeled data and leads to a more accurate and calibrated supervised\nmodel compared to vanilla self-training based student-teacher algorithms. We\nperform several experiments on the popular STL-10 database followed by an\nextensive analysis of our approach and study its effects on model accuracy and\ncalibration.",
          "link": "http://arxiv.org/abs/2107.08211",
          "publishedOn": "2021-07-20T02:04:48.562Z",
          "wordCount": 607,
          "title": "Self Training with Ensemble of Teacher Models. (arXiv:2107.08211v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08421",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1\">Tianshu Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1\">Xuan Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaomin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Minghui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1\">Jiali Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Ming Liu</a>",
          "description": "In this paper, we propose a novel training strategy for convolutional neural\nnetwork(CNN) named Feature Mining, that aims to strengthen the network's\nlearning of the local feature. Through experiments, we find that semantic\ncontained in different parts of the feature is different, while the network\nwill inevitably lose the local information during feedforward propagation. In\norder to enhance the learning of local feature, Feature Mining divides the\ncomplete feature into two complementary parts and reuse these divided feature\nto make the network learn more local information, we call the two steps as\nfeature segmentation and feature reusing. Feature Mining is a parameter-free\nmethod and has plug-and-play nature, and can be applied to any CNN models.\nExtensive experiments demonstrate the wide applicability, versatility, and\ncompatibility of our method.",
          "link": "http://arxiv.org/abs/2107.08421",
          "publishedOn": "2021-07-20T02:04:48.428Z",
          "wordCount": 571,
          "title": "Feature Mining: A Novel Training Strategy for Convolutional Neural Network. (arXiv:2107.08421v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08311",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Di_X/0/1/0/all/0/1\">Xing Di</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1\">Shuowen Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patel_V/0/1/0/all/0/1\">Vishal M. Patel</a>",
          "description": "Recent advances in deep convolutional neural networks (DCNNs) have shown\nimpressive performance improvements on thermal to visible face synthesis and\nmatching problems. However, current DCNN-based synthesis models do not perform\nwell on thermal faces with large pose variations. In order to deal with this\nproblem, heterogeneous face frontalization methods are needed in which a model\ntakes a thermal profile face image and generates a frontal visible face. This\nis an extremely difficult problem due to the large domain as well as large pose\ndiscrepancies between the two modalities. Despite its applications in\nbiometrics and surveillance, this problem is relatively unexplored in the\nliterature. We propose a domain agnostic learning-based generative adversarial\nnetwork (DAL-GAN) which can synthesize frontal views in the visible domain from\nthermal faces with pose variations. DAL-GAN consists of a generator with an\nauxiliary classifier and two discriminators which capture both local and global\ntexture discriminations for better synthesis. A contrastive constraint is\nenforced in the latent space of the generator with the help of a dual-path\ntraining strategy, which improves the feature vector discrimination. Finally, a\nmulti-purpose loss function is utilized to guide the network in synthesizing\nidentity preserving cross-domain frontalization. Extensive experimental results\ndemonstrate that DAL-GAN can generate better quality frontal views compared to\nthe other baseline methods.",
          "link": "http://arxiv.org/abs/2107.08311",
          "publishedOn": "2021-07-20T02:04:48.375Z",
          "wordCount": 661,
          "title": "Heterogeneous Face Frontalization via Domain Agnostic Learning. (arXiv:2107.08311v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2008.08899",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mathew_M/0/1/0/all/0/1\">Minesh Mathew</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tito_R/0/1/0/all/0/1\">Ruben Tito</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karatzas_D/0/1/0/all/0/1\">Dimosthenis Karatzas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manmatha_R/0/1/0/all/0/1\">R. Manmatha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jawahar_C/0/1/0/all/0/1\">C.V. Jawahar</a>",
          "description": "This paper presents results of Document Visual Question Answering Challenge\norganized as part of \"Text and Documents in the Deep Learning Era\" workshop, in\nCVPR 2020. The challenge introduces a new problem - Visual Question Answering\non document images. The challenge comprised two tasks. The first task concerns\nwith asking questions on a single document image. On the other hand, the second\ntask is set as a retrieval task where the question is posed over a collection\nof images. For the task 1 a new dataset is introduced comprising 50,000\nquestions-answer(s) pairs defined over 12,767 document images. For task 2\nanother dataset has been created comprising 20 questions over 14,362 document\nimages which share the same document template.",
          "link": "http://arxiv.org/abs/2008.08899",
          "publishedOn": "2021-07-20T02:04:47.750Z",
          "wordCount": 597,
          "title": "Document Visual Question Answering Challenge 2020. (arXiv:2008.08899v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08766",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Du_D/0/1/0/all/0/1\">Dawei Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_L/0/1/0/all/0/1\">Longyin Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_P/0/1/0/all/0/1\">Pengfei Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_H/0/1/0/all/0/1\">Heng Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Q/0/1/0/all/0/1\">Qinghua Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_H/0/1/0/all/0/1\">Haibin Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1\">Mubarak Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1\">Junwen Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Al_Ali_A/0/1/0/all/0/1\">Ali Al-Ali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohamed_A/0/1/0/all/0/1\">Amr Mohamed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Imene_B/0/1/0/all/0/1\">Bakour Imene</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_B/0/1/0/all/0/1\">Bin Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Binyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nesma_B/0/1/0/all/0/1\">Bouchali Hadia Nesma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chenfeng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_C/0/1/0/all/0/1\">Chenzhen Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Castiello_C/0/1/0/all/0/1\">Ciro Castiello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mencar_C/0/1/0/all/0/1\">Corrado Mencar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_D/0/1/0/all/0/1\">Dingkang Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kruger_F/0/1/0/all/0/1\">Florian Kr&#xfc;ger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vessio_G/0/1/0/all/0/1\">Gennaro Vessio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Castellano_G/0/1/0/all/0/1\">Giovanna Castellano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jieru Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Junyu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abualsaud_K/0/1/0/all/0/1\">Khalid Abualsaud</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_L/0/1/0/all/0/1\">Laihui Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1\">Lei Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cianciotta_M/0/1/0/all/0/1\">Marco Cianciotta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saqib_M/0/1/0/all/0/1\">Muhammad Saqib</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Almaadeed_N/0/1/0/all/0/1\">Noor Almaadeed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elharrouss_O/0/1/0/all/0/1\">Omar Elharrouss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_P/0/1/0/all/0/1\">Pei Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shidong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_S/0/1/0/all/0/1\">Shuang Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1\">Siyang Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Al_Maadeed_S/0/1/0/all/0/1\">Somaya Al-Maadeed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1\">Sultan Daud Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khattab_T/0/1/0/all/0/1\">Tamer Khattab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_T/0/1/0/all/0/1\">Tao Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Golda_T/0/1/0/all/0/1\">Thomas Golda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Wei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_X/0/1/0/all/0/1\">Xiang Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xiaoqing Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xuelong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yanyun Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Ye Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yingnan Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yongchao Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yuehan Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zhenyu Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1\">Zhijian Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1\">Zhipeng Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1\">Zhiwei Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1\">Zhiyuan Zhao</a>",
          "description": "Crowd counting on the drone platform is an interesting topic in computer\nvision, which brings new challenges such as small object inference, background\nclutter and wide viewpoint. However, there are few algorithms focusing on crowd\ncounting on the drone-captured data due to the lack of comprehensive datasets.\nTo this end, we collect a large-scale dataset and organize the Vision Meets\nDrone Crowd Counting Challenge (VisDrone-CC2020) in conjunction with the 16th\nEuropean Conference on Computer Vision (ECCV 2020) to promote the developments\nin the related fields. The collected dataset is formed by $3,360$ images,\nincluding $2,460$ images for training, and $900$ images for testing.\nSpecifically, we manually annotate persons with points in each video frame.\nThere are $14$ algorithms from $15$ institutes submitted to the VisDrone-CC2020\nChallenge. We provide a detailed analysis of the evaluation results and\nconclude the challenge. More information can be found at the website:\n\\url{this http URL}.",
          "link": "http://arxiv.org/abs/2107.08766",
          "publishedOn": "2021-07-20T02:04:47.020Z",
          "wordCount": null,
          "title": "VisDrone-CC2020: The Vision Meets Drone Crowd Counting Challenge Results. (arXiv:2107.08766v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08770",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_G/0/1/0/all/0/1\">Gun-Hee Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ko_H/0/1/0/all/0/1\">Han-Bin Ko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Seong-Whan Lee</a>",
          "description": "Deep learning has played a major role in the interpretation of dermoscopic\nimages for detecting skin defects and abnormalities. However, current deep\nlearning solutions for dermatological lesion analysis are typically limited in\nproviding probabilistic predictions which highlights the importance of\nconcerning uncertainties. This concept of uncertainty can provide a confidence\nlevel for each feature which prevents overconfident predictions with poor\ngeneralization on unseen data. In this paper, we propose an overall framework\nthat jointly considers dermatological classification and uncertainty estimation\ntogether. The estimated confidence of each feature to avoid uncertain feature\nand undesirable shift, which are caused by environmental difference of input\nimage, in the latent space is pooled from confidence network. Our qualitative\nresults show that modeling uncertainties not only helps to quantify model\nconfidence for each prediction but also helps classification layers to focus on\nconfident features, therefore, improving the accuracy for dermatological lesion\nclassification. We demonstrate the potential of the proposed approach in two\nstate-of-the-art dermoscopic datasets (ISIC 2018 and ISIC 2019).",
          "link": "http://arxiv.org/abs/2107.08770",
          "publishedOn": "2021-07-20T02:04:47.020Z",
          "wordCount": null,
          "title": "Joint Dermatological Lesion Classification and Confidence Modeling with Uncertainty Estimation. (arXiv:2107.08770v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08440",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Thuy_H/0/1/0/all/0/1\">Hang Duong Thi Thuy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Minh_T/0/1/0/all/0/1\">Tuan Nguyen Minh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Van_P/0/1/0/all/0/1\">Phi Nguyen Van</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quoc_L/0/1/0/all/0/1\">Long Tran Quoc</a>",
          "description": "Nowadays, cardiac diagnosis largely depends on left ventricular function\nassessment. With the help of the segmentation deep learning model, the\nassessment of the left ventricle becomes more accessible and accurate. However,\ndeep learning technique still faces two main obstacles: the difficulty in\nacquiring sufficient training data and time-consuming in developing quality\nmodels. In the ordinary data acquisition process, the dataset was selected\nrandomly from a large pool of unlabeled images for labeling, leading to massive\nlabor time to annotate those images. Besides that, hand-designed model\ndevelopment is laborious and also costly. This paper introduces a pipeline that\nrelies on Active Learning to ease the labeling work and utilizes Neural\nArchitecture Search's idea to design the adequate deep learning model\nautomatically. We called this Fully automated machine learning pipeline for\nechocardiogram segmentation. The experiment results show that our method\nobtained the same IOU accuracy with only two-fifths of the original training\ndataset, and the searched model got the same accuracy as the hand-designed\nmodel given the same training dataset.",
          "link": "http://arxiv.org/abs/2107.08440",
          "publishedOn": "2021-07-20T02:04:46.794Z",
          "wordCount": null,
          "title": "Fully Automated Machine Learning Pipeline for Echocardiogram Segmentation. (arXiv:2107.08440v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08371",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qu_L/0/1/0/all/0/1\">Liangqiong Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balachandar_N/0/1/0/all/0/1\">Niranjan Balachandar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubin_D/0/1/0/all/0/1\">Daniel L Rubin</a>",
          "description": "Federated learning enables multiple institutions to collaboratively train\nmachine learning models on their local data in a privacy-preserving way.\nHowever, its distributed nature often leads to significant heterogeneity in\ndata distributions across institutions. In this paper, we investigate the\ndeleterious impact of a taxonomy of data heterogeneity regimes on federated\nlearning methods, including quantity skew, label distribution skew, and imaging\nacquisition skew. We show that the performance degrades with the increasing\ndegrees of data heterogeneity. We present several mitigation strategies to\novercome performance drops from data heterogeneity, including weighted average\nfor data quantity skew, weighted loss and batch normalization averaging for\nlabel distribution skew. The proposed optimizations to federated learning\nmethods improve their capability of handling heterogeneity across institutions,\nwhich provides valuable guidance for the deployment of federated learning in\nreal clinical applications.",
          "link": "http://arxiv.org/abs/2107.08371",
          "publishedOn": "2021-07-20T02:04:46.772Z",
          "wordCount": null,
          "title": "An Experimental Study of Data Heterogeneity in Federated Learning Methods for Medical Imaging. (arXiv:2107.08371v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.11237",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Peng_J/0/1/0/all/0/1\">Jinlong Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1\">Zhengkai Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1\">Yueyang Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yabiao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tai_Y/0/1/0/all/0/1\">Ying Tai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chengjie Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1\">Weiyao Lin</a>",
          "description": "Recently, most siamese network based trackers locate targets via object\nclassification and bounding-box regression. Generally, they select the\nbounding-box with maximum classification confidence as the final prediction.\nThis strategy may miss the right result due to the accuracy misalignment\nbetween classification and regression. In this paper, we propose a novel\nsiamese tracking algorithm called SiamRCR, addressing this problem with a\nsimple, light and effective solution. It builds reciprocal links between\nclassification and regression branches, which can dynamically re-weight their\nlosses for each positive sample. In addition, we add a localization branch to\npredict the localization accuracy, so that it can work as the replacement of\nthe regression assistance link during inference. This branch makes the training\nand inference more consistent. Extensive experimental results demonstrate the\neffectiveness of SiamRCR and its superiority over the state-of-the-art\ncompetitors on GOT-10k, LaSOT, TrackingNet, OTB-2015, VOT-2018 and VOT-2019.\nMoreover, our SiamRCR runs at 65 FPS, far above the real-time requirement.",
          "link": "http://arxiv.org/abs/2105.11237",
          "publishedOn": "2021-07-20T02:04:46.771Z",
          "wordCount": null,
          "title": "SiamRCR: Reciprocal Classification and Regression for Visual Object Tracking. (arXiv:2105.11237v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.05528",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cosma_A/0/1/0/all/0/1\">Adrian Cosma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radoi_E/0/1/0/all/0/1\">Emilian Radoi</a>",
          "description": "The use of gait for person identification has important advantages such as\nbeing non-invasive, unobtrusive, not requiring cooperation and being less\nlikely to be obscured compared to other biometrics. Existing methods for gait\nrecognition require cooperative gait scenarios, in which a single person is\nwalking multiple times in a straight line in front of a camera. We aim to\naddress the hard challenges of real-world scenarios in which camera feeds\ncapture multiple people, who in most cases pass in front of the camera only\nonce. We address privacy concerns by using only the motion information of\nwalking individuals, with no identifiable appearance-based information. As\nsuch, we propose a novel weakly supervised learning framework, WildGait, which\nconsists of training a Spatio-Temporal Graph Convolutional Network on a large\nnumber of automatically annotated skeleton sequences obtained from raw,\nreal-world, surveillance streams to learn useful gait signatures. Our results\nshow that, with fine-tuning, we surpass in terms of recognition accuracy the\ncurrent state-of-the-art pose-based gait recognition solutions. Our proposed\nmethod is reliable in training gait recognition methods in unconstrained\nenvironments, especially in settings with scarce amounts of annotated data.",
          "link": "http://arxiv.org/abs/2105.05528",
          "publishedOn": "2021-07-20T02:04:46.705Z",
          "wordCount": null,
          "title": "WildGait: Learning Gait Representations from Raw Surveillance Streams. (arXiv:2105.05528v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1809.00970",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lejeune_L/0/1/0/all/0/1\">Laurent Lejeune</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grossrieder_J/0/1/0/all/0/1\">Jan Grossrieder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sznitman_R/0/1/0/all/0/1\">Raphael Sznitman</a>",
          "description": "Recent machine learning strategies for segmentation tasks have shown great\nability when trained on large pixel-wise annotated image datasets. It remains a\nmajor challenge however to aggregate such datasets, as the time and monetary\ncost associated with collecting extensive annotations is extremely high. This\nis particularly the case for generating precise pixel-wise annotations in video\nand volumetric image data. To this end, this work presents a novel framework to\nproduce pixel-wise segmentations using minimal supervision. Our method relies\non 2D point supervision, whereby a single 2D location within an object of\ninterest is provided on each image of the data. Our method then estimates the\nobject appearance in a semi-supervised fashion by learning\nobject-image-specific features and by using these in a semi-supervised learning\nframework. Our object model is then used in a graph-based optimization problem\nthat takes into account all provided locations and the image data in order to\ninfer the complete pixel-wise segmentation. In practice, we solve this\noptimally as a tracking problem using a K-shortest path approach. Both the\nobject model and segmentation are then refined iteratively to further improve\nthe final segmentation. We show that by collecting 2D locations using a gaze\ntracker, our approach can provide state-of-the-art segmentations on a range of\nobjects and image modalities (video and 3D volumes), and that these can then be\nused to train supervised machine learning classifiers.",
          "link": "http://arxiv.org/abs/1809.00970",
          "publishedOn": "2021-07-20T02:04:46.694Z",
          "wordCount": null,
          "title": "Iterative multi-path tracking for video and volume segmentation with sparse point supervision. (arXiv:1809.00970v1 [cs.CV] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14399",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Macedo_D/0/1/0/all/0/1\">David Mac&#xea;do</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ludermir_T/0/1/0/all/0/1\">Teresa Ludermir</a>",
          "description": "Current out-of-distribution detection approaches usually present special\nrequirements (e.g., collecting outlier data and hyperparameter validation) and\nproduce side effects (classification accuracy drop and slow/inefficient\ninferences). Recently, entropic out-of-distribution detection has been proposed\nas a seamless approach (i.e., a solution that avoids all the previously\nmentioned drawbacks). The entropic out-of-distribution detection solution\ncomprises the IsoMax loss for training and the entropic score for\nout-of-distribution detection. The IsoMax loss works as a SoftMax loss drop-in\nreplacement because swapping the SoftMax loss with the IsoMax loss requires no\nchanges in the model's architecture or training procedures/hyperparameters. In\nthis paper, we propose to perform what we call an isometrization of the\ndistances used in the IsoMax loss. Additionally, we propose to replace the\nentropic score with the minimum distance score. Our experiments showed that\nthese simple modifications increase out-of-distribution detection performance\nwhile keeping the solution seamless. Code available at\n$\\href{https://github.com/dlmacedo/entropic-out-of-distribution-detection}{\\text{entropic\nout-of-distribution detection}}$.",
          "link": "http://arxiv.org/abs/2105.14399",
          "publishedOn": "2021-07-20T02:04:46.693Z",
          "wordCount": null,
          "title": "Improving Entropic Out-of-Distribution Detection using Isometric Distances and the Minimum Distance Score. (arXiv:2105.14399v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.04075",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1\">Xueying Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1\">Yueming Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dou_Q/0/1/0/all/0/1\">Qi Dou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_J/0/1/0/all/0/1\">Jing Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heng_P/0/1/0/all/0/1\">Pheng-Ann Heng</a>",
          "description": "Automated surgical gesture recognition is of great importance in\nrobot-assisted minimally invasive surgery. However, existing methods assume\nthat training and testing data are from the same domain, which suffers from\nsevere performance degradation when a domain gap exists, such as the simulator\nand real robot. In this paper, we propose a novel unsupervised domain\nadaptation framework which can simultaneously transfer multi-modality\nknowledge, i.e., both kinematic and visual data, from simulator to real robot.\nIt remedies the domain gap with enhanced transferable features by using\ntemporal cues in videos, and inherent correlations in multi-modal towards\nrecognizing gesture. Specifically, we first propose an MDO-K to align\nkinematics, which exploits temporal continuity to transfer motion directions\nwith smaller gap rather than position values, relieving the adaptation burden.\nMoreover, we propose a KV-Relation-ATT to transfer the co-occurrence signals of\nkinematics and vision. Such features attended by correlation similarity are\nmore informative for enhancing domain-invariance of the model. Two feature\nalignment strategies benefit the model mutually during the end-to-end learning\nprocess. We extensively evaluate our method for gesture recognition using DESK\ndataset with peg transfer procedure. Results show that our approach recovers\nthe performance with great improvement gains, up to 12.91% in ACC and 20.16% in\nF1score without using any annotations in real robot.",
          "link": "http://arxiv.org/abs/2103.04075",
          "publishedOn": "2021-07-20T02:04:46.690Z",
          "wordCount": null,
          "title": "Domain Adaptive Robotic Gesture Recognition with Unsupervised Kinematic-Visual Data Alignment. (arXiv:2103.04075v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08581",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Songlin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1\">Yuehua Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1\">Jing Dong</a>",
          "description": "With the identity information in face data more closely related to personal\ncredit and property security, people pay increasing attention to the protection\nof face data privacy. In different tasks, people have various requirements for\nface de-identification (De-ID), so we propose a systematical solution\ncompatible for these De-ID operations. Firstly, an attribute disentanglement\nand generative network is constructed to encode two parts of the face, which\nare the identity (facial features like mouth, nose and eyes) and expression\n(including expression, pose and illumination). Through face swapping, we can\nremove the original ID completely. Secondly, we add an adversarial vector\nmapping network to perturb the latent code of the face image, different from\nprevious traditional adversarial methods. Through this, we can construct\nunrestricted adversarial image to decrease ID similarity recognized by model.\nOur method can flexibly de-identify the face data in various ways and the\nprocessed images have high image quality.",
          "link": "http://arxiv.org/abs/2107.08581",
          "publishedOn": "2021-07-20T02:04:46.688Z",
          "wordCount": null,
          "title": "A Systematical Solution for Face De-identification. (arXiv:2107.08581v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2006.12434",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zhuang_X/0/1/0/all/0/1\">Xiahai Zhuang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_J/0/1/0/all/0/1\">Jiahang Xu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Luo_X/0/1/0/all/0/1\">Xinzhe Luo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_C/0/1/0/all/0/1\">Chen Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ouyang_C/0/1/0/all/0/1\">Cheng Ouyang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rueckert_D/0/1/0/all/0/1\">Daniel Rueckert</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Campello_V/0/1/0/all/0/1\">Victor M. Campello</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lekadir_K/0/1/0/all/0/1\">Karim Lekadir</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Vesal_S/0/1/0/all/0/1\">Sulaiman Vesal</a>, <a href=\"http://arxiv.org/find/eess/1/au:+RaviKumar_N/0/1/0/all/0/1\">Nishant RaviKumar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_Y/0/1/0/all/0/1\">Yashu Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Luo_G/0/1/0/all/0/1\">Gongning Luo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_J/0/1/0/all/0/1\">Jingkun Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_H/0/1/0/all/0/1\">Hongwei Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ly_B/0/1/0/all/0/1\">Buntheng Ly</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sermesant_M/0/1/0/all/0/1\">Maxime Sermesant</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Roth_H/0/1/0/all/0/1\">Holger Roth</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhu_W/0/1/0/all/0/1\">Wentao Zhu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_J/0/1/0/all/0/1\">Jiexiang Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ding_X/0/1/0/all/0/1\">Xinghao Ding</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_X/0/1/0/all/0/1\">Xinyue Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_S/0/1/0/all/0/1\">Sen Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>",
          "description": "Accurate computing, analysis and modeling of the ventricles and myocardium\nfrom medical images are important, especially in the diagnosis and treatment\nmanagement for patients suffering from myocardial infarction (MI). Late\ngadolinium enhancement (LGE) cardiac magnetic resonance (CMR) provides an\nimportant protocol to visualize MI. However, automated segmentation of LGE CMR\nis still challenging, due to the indistinguishable boundaries, heterogeneous\nintensity distribution and complex enhancement patterns of pathological\nmyocardium from LGE CMR. Furthermore, compared with the other sequences LGE CMR\nimages with gold standard labels are particularly limited, which represents\nanother obstacle for developing novel algorithms for automatic segmentation of\nLGE CMR. This paper presents the selective results from the Multi-Sequence\nCardiac MR (MS-CMR) Segmentation challenge, in conjunction with MICCAI 2019.\nThe challenge offered a data set of paired MS-CMR images, including auxiliary\nCMR sequences as well as LGE CMR, from 45 patients who underwent\ncardiomyopathy. It was aimed to develop new algorithms, as well as benchmark\nexisting ones for LGE CMR segmentation and compare them objectively. In\naddition, the paired MS-CMR images could enable algorithms to combine the\ncomplementary information from the other sequences for the segmentation of LGE\nCMR. Nine representative works were selected for evaluation and comparisons,\namong which three methods are unsupervised methods and the other six are\nsupervised. The results showed that the average performance of the nine methods\nwas comparable to the inter-observer variations. The success of these methods\nwas mainly attributed to the inclusion of the auxiliary sequences from the\nMS-CMR images, which provide important label information for the training of\ndeep neural networks.",
          "link": "http://arxiv.org/abs/2006.12434",
          "publishedOn": "2021-07-20T02:04:46.616Z",
          "wordCount": null,
          "title": "Cardiac Segmentation on Late Gadolinium Enhancement MRI: A Benchmark Study from Multi-Sequence Cardiac MR Segmentation Challenge. (arXiv:2006.12434v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08639",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nishimura_K/0/1/0/all/0/1\">Kazuya Nishimura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_H/0/1/0/all/0/1\">Hyeonwoo Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bise_R/0/1/0/all/0/1\">Ryoma Bise</a>",
          "description": "Cell detection is the task of detecting the approximate positions of cell\ncentroids from microscopy images. Recently, convolutional neural network-based\napproaches have achieved promising performance. However, these methods require\na certain amount of annotation for each imaging condition. This annotation is a\ntime-consuming and labor-intensive task. To overcome this problem, we propose a\nsemi-supervised cell-detection method that effectively uses a time-lapse\nsequence with one labeled image and the other images unlabeled. First, we train\na cell-detection network with a one-labeled image and estimate the unlabeled\nimages with the trained network. We then select high-confidence positions from\nthe estimations by tracking the detected cells from the labeled frame to those\nfar from it. Next, we generate pseudo-labels from the tracking results and\ntrain the network by using pseudo-labels. We evaluated our method for seven\nconditions of public datasets, and we achieved the best results relative to\nother semi-supervised methods. Our code is available at\nhttps://github.com/naivete5656/SCDTC",
          "link": "http://arxiv.org/abs/2107.08639",
          "publishedOn": "2021-07-20T02:04:46.615Z",
          "wordCount": null,
          "title": "Semi-supervised Cell Detection in Time-lapse Images Using Temporal Consistency. (arXiv:2107.08639v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08645",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haopeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lingbo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1\">Kunlin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shinan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Junyu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_B/0/1/0/all/0/1\">Bin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Rui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_J/0/1/0/all/0/1\">Jun Hou</a>",
          "description": "Video crowd localization is a crucial yet challenging task, which aims to\nestimate exact locations of human heads in the given crowded videos. To model\nspatial-temporal dependencies of human mobility, we propose a multi-focus\nGaussian neighbor attention (GNA), which can effectively exploit long-range\ncorrespondences while maintaining the spatial topological structure of the\ninput videos. In particular, our GNA can also capture the scale variation of\nhuman heads well using the equipped multi-focus mechanism. Based on the\nmulti-focus GNA, we develop a unified neural network called GNANet to\naccurately locate head centers in video clips by fully aggregating\nspatial-temporal information via a scene modeling module and a context\ncross-attention module. Moreover, to facilitate future researches in this\nfield, we introduce a large-scale crowded video benchmark named SenseCrowd,\nwhich consists of 60K+ frames captured in various surveillance scenarios and\n2M+ head annotations. Finally, we conduct extensive experiments on three\ndatasets including our SenseCrowd, and the experiment results show that the\nproposed method is capable to achieve state-of-the-art performance for both\nvideo crowd localization and counting. The code and the dataset will be\nreleased.",
          "link": "http://arxiv.org/abs/2107.08645",
          "publishedOn": "2021-07-20T02:04:46.614Z",
          "wordCount": null,
          "title": "Video Crowd Localization with Multi-focus Gaussian Neighbor Attention and a Large-Scale Benchmark. (arXiv:2107.08645v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2004.10141",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ben_Ari_R/0/1/0/all/0/1\">Rami Ben-Ari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shpigel_M/0/1/0/all/0/1\">Mor Shpigel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azulai_O/0/1/0/all/0/1\">Ophir Azulai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barzelay_U/0/1/0/all/0/1\">Udi Barzelay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rotman_D/0/1/0/all/0/1\">Daniel Rotman</a>",
          "description": "Classification of new class entities requires collecting and annotating\nhundreds or thousands of samples that is often prohibitively costly. Few-shot\nlearning suggests learning to classify new classes using just a few examples.\nOnly a small number of studies address the challenge of few-shot learning on\nspatio-temporal patterns such as videos. In this paper, we present the Temporal\nAware Embedding Network (TAEN) for few-shot action recognition, that learns to\nrepresent actions, in a metric space as a trajectory, conveying both short term\nsemantics and longer term connectivity between action parts. We demonstrate the\neffectiveness of TAEN on two few shot tasks, video classification and temporal\naction detection and evaluate our method on the Kinetics-400 and on ActivityNet\n1.2 few-shot benchmarks. With training of just a few fully connected layers we\nreach comparable results to prior art on both few shot video classification and\ntemporal detection tasks, while reaching state-of-the-art in certain scenarios.",
          "link": "http://arxiv.org/abs/2004.10141",
          "publishedOn": "2021-07-20T02:04:46.614Z",
          "wordCount": null,
          "title": "TAEN: Temporal Aware Embedding Network for Few-Shot Action Recognition. (arXiv:2004.10141v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.05107",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Congram_B/0/1/0/all/0/1\">Benjamin Congram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barfoot_T/0/1/0/all/0/1\">Timothy D. Barfoot</a>",
          "description": "Visual Teach and Repeat has shown relative navigation is a robust and\nefficient solution for autonomous vision-based path following in difficult\nenvironments. Adding additional absolute sensors such as Global Navigation\nSatellite Systems (GNSS) has the potential to expand the domain of Visual Teach\nand Repeat to environments where the ability to visually localize is not\nguaranteed. Our method of lazy mapping and delaying estimation until a\npath-tracking error is needed avoids the need to estimate absolute states. As a\nresult, map optimization is not required and paths can be driven immediately\nafter being taught. We validate our approach on a real robot through an\nexperiment in a joint indoor-outdoor environment comprising 3.5km of autonomous\nroute repeating across a variety of lighting conditions. We achieve smooth\nerror signals throughout the runs despite large sections of dropout for each\nsensor.",
          "link": "http://arxiv.org/abs/2101.05107",
          "publishedOn": "2021-07-20T02:04:46.613Z",
          "wordCount": null,
          "title": "Relatively Lazy: Indoor-Outdoor Navigation Using Vision and GNSS. (arXiv:2101.05107v2 [cs.RO] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.07997",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Rui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1\">Shunyi Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Ce Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_C/0/1/0/all/0/1\">Chenxi Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Libo Wang</a>",
          "description": "Semantic segmentation using fine-resolution remotely sensed images plays a\ncritical role in many practical applications, such as urban planning,\nenvironmental protection, natural and anthropogenic landscape monitoring, etc.\nHowever, the automation of semantic segmentation, i.e., automatic\ncategorization/labeling and segmentation is still a challenging task,\nparticularly for fine-resolution images with huge spatial and spectral\ncomplexity. Addressing such a problem represents an exciting research field,\nwhich paves the way for scene-level landscape pattern analysis and decision\nmaking. In this paper, we propose an approach for automatic land segmentation\nbased on the Feature Pyramid Network (FPN). As a classic architecture, FPN can\nbuild a feature pyramid with high-level semantics throughout. However,\nintrinsic defects in feature extraction and fusion hinder FPN from further\naggregating more discriminative features. Hence, we propose an Attention\nAggregation Module (AAM) to enhance multi-scale feature learning through\nattention-guided feature aggregation. Based on FPN and AAM, a novel framework\nnamed Attention Aggregation Feature Pyramid Network (A2-FPN) is developed for\nsemantic segmentation of fine-resolution remotely sensed images. Extensive\nexperiments conducted on three datasets demonstrate the effectiveness of our A2\n-FPN in segmentation accuracy. Code is available at\nhttps://github.com/lironui/A2-FPN.",
          "link": "http://arxiv.org/abs/2102.07997",
          "publishedOn": "2021-07-20T02:04:46.613Z",
          "wordCount": null,
          "title": "A2-FPN for Semantic Segmentation of Fine-Resolution Remotely Sensed Images. (arXiv:2102.07997v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.11860",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Garg_A/0/1/0/all/0/1\">Aksh Garg</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Salehi_S/0/1/0/all/0/1\">Sana Salehi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rocca_M/0/1/0/all/0/1\">Marianna La Rocca</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Garner_R/0/1/0/all/0/1\">Rachael Garner</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Duncan_D/0/1/0/all/0/1\">Dominique Duncan</a>",
          "description": "With COVID-19 cases rising rapidly, deep learning has emerged as a promising\ndiagnosis technique. However, identifying the most accurate models to\ncharacterize COVID-19 patients is challenging because comparing results\nobtained with different types of data and acquisition processes is non-trivial.\nIn this paper we designed, evaluated, and compared the performance of 20\nconvolutional neutral networks in classifying patients as COVID-19 positive,\nhealthy, or suffering from other pulmonary lung infections based on Chest CT\nscans, serving as the first to consider the EfficientNet family for COVID-19\ndiagnosis and employ intermediate activation maps for visualizing model\nperformance. All models are trained and evaluated in Python using 4173 Chest CT\nimages from the dataset entitled \"A COVID multiclass dataset of CT scans,\" with\n2168, 758, and 1247 images of patients that are COVID-19 positive, healthy, or\nsuffering from other pulmonary infections, respectively. EfficientNet-B5 was\nidentified as the best model with an F1 score of 0.9769+/-0.0046, accuracy of\n0.9759+/-0.0048, sensitivity of 0.9788+/-0.0055, specificity of\n0.9730+/-0.0057, and precision of 0.9751 +/- 0.0051. On an alternate 2-class\ndataset, EfficientNetB5 obtained an accuracy of 0.9845+/-0.0109, F1 score of\n0.9599+/-0.0251, sensitivity of 0.9682+/-0.0099, specificity of\n0.9883+/-0.0150, and precision of 0.9526 +/- 0.0523. Intermediate activation\nmaps and Gradient-weighted Class Activation Mappings offered\nhuman-interpretable evidence of the model's perception of ground-class\nopacities and consolidations, hinting towards a promising use-case of\nartificial intelligence-assisted radiology tools. With a prediction speed of\nunder 0.1 seconds on GPUs and 0.5 seconds on CPUs, our proposed model offers a\nrapid, scalable, and accurate diagnostic for COVID-19.",
          "link": "http://arxiv.org/abs/2012.11860",
          "publishedOn": "2021-07-20T02:04:46.612Z",
          "wordCount": null,
          "title": "Efficient and Visualizable Convolutional Neural Networks for COVID-19 Classification Using Chest CT. (arXiv:2012.11860v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08585",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Plested_J/0/1/0/all/0/1\">Jo Plested</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1\">Xuyang Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gedeon_T/0/1/0/all/0/1\">Tom Gedeon</a>",
          "description": "The current standard for a variety of computer vision tasks using smaller\nnumbers of labelled training examples is to fine-tune from weights pre-trained\non a large image classification dataset such as ImageNet. The application of\ntransfer learning and transfer learning methods tends to be rigidly binary. A\nmodel is either pre-trained or not pre-trained. Pre-training a model either\nincreases performance or decreases it, the latter being defined as negative\ntransfer. Application of L2-SP regularisation that decays the weights towards\ntheir pre-trained values is either applied or all weights are decayed towards\n0. This paper re-examines these assumptions. Our recommendations are based on\nextensive empirical evaluation that demonstrate the application of a non-binary\napproach to achieve optimal results. (1) Achieving best performance on each\nindividual dataset requires careful adjustment of various transfer learning\nhyperparameters not usually considered, including number of layers to transfer,\ndifferent learning rates for different layers and different combinations of\nL2SP and L2 regularization. (2) Best practice can be achieved using a number of\nmeasures of how well the pre-trained weights fit the target dataset to guide\noptimal hyperparameters. We present methods for non-binary transfer learning\nincluding combining L2SP and L2 regularization and performing non-traditional\nfine-tuning hyperparameter searches. Finally we suggest heuristics for\ndetermining the optimal transfer learning hyperparameters. The benefits of\nusing a non-binary approach are supported by final results that come close to\nor exceed state of the art performance on a variety of tasks that have\ntraditionally been more difficult for transfer learning.",
          "link": "http://arxiv.org/abs/2107.08585",
          "publishedOn": "2021-07-20T02:04:46.611Z",
          "wordCount": null,
          "title": "Non-binary deep transfer learning for imageclassification. (arXiv:2107.08585v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08640",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lonkar_S/0/1/0/all/0/1\">Subodh Lonkar</a>",
          "description": "Over the centuries, humans have developed and acquired a number of ways to\ncommunicate. But hardly any of them can be as natural and instinctive as facial\nexpressions. On the other hand, neural networks have taken the world by storm.\nAnd no surprises, that the area of Computer Vision and the problem of facial\nexpressions recognitions hasn't remained untouched. Although a wide range of\ntechniques have been applied, achieving extremely high accuracies and preparing\nhighly robust FER systems still remains a challenge due to heterogeneous\ndetails in human faces. In this paper, we will be deep diving into implementing\na system for recognition of facial expressions (FER) by leveraging neural\nnetworks, and more specifically, Convolutional Neural Networks (CNNs). We adopt\nthe fundamental concepts of deep learning and computer vision with various\narchitectures, fine-tune it's hyperparameters and experiment with various\noptimization methods and demonstrate a state-of-the-art single-network-accuracy\nof 70.10% on the FER2013 dataset without using any additional training data.",
          "link": "http://arxiv.org/abs/2107.08640",
          "publishedOn": "2021-07-20T02:04:46.611Z",
          "wordCount": null,
          "title": "Facial Expressions Recognition with Convolutional Neural Networks. (arXiv:2107.08640v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2011.02638",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1\">Kanglin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_G/0/1/0/all/0/1\">Gaofeng Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_F/0/1/0/all/0/1\">Fei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bozhi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_J/0/1/0/all/0/1\">Jiang Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_G/0/1/0/all/0/1\">Guoping Qiu</a>",
          "description": "Facial attributes in StyleGAN generated images are entangled in the latent\nspace which makes it very difficult to independently control a specific\nattribute without affecting the others. Supervised attribute editing requires\nannotated training data which is difficult to obtain and limits the editable\nattributes to those with labels. Therefore, unsupervised attribute editing in\nan disentangled latent space is key to performing neat and versatile semantic\nface editing. In this paper, we present a new technique termed\nStructure-Texture Independent Architecture with Weight Decomposition and\nOrthogonal Regularization (STIA-WO) to disentangle the latent space for\nunsupervised semantic face editing. By applying STIA-WO to GAN, we have\ndeveloped a StyleGAN termed STGAN-WO which performs weight decomposition\nthrough utilizing the style vector to construct a fully controllable weight\nmatrix to regulate image synthesis, and employs orthogonal regularization to\nensure each entry of the style vector only controls one independent feature\nmatrix. To further disentangle the facial attributes, STGAN-WO introduces a\nstructure-texture independent architecture which utilizes two independently and\nidentically distributed (i.i.d.) latent vectors to control the synthesis of the\ntexture and structure components in a disentangled way. Unsupervised semantic\nediting is achieved by moving the latent code in the coarse layers along its\northogonal directions to change texture related attributes or changing the\nlatent code in the fine layers to manipulate structure related ones. We present\nexperimental results which show that our new STGAN-WO can achieve better\nattribute editing than state of the art methods.",
          "link": "http://arxiv.org/abs/2011.02638",
          "publishedOn": "2021-07-20T02:04:46.610Z",
          "wordCount": null,
          "title": "Towards Disentangling Latent Space for Unsupervised Semantic Face Editing. (arXiv:2011.02638v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08621",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qingzhong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Pengfei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1\">Haoyi Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jian Zhao</a>",
          "description": "In this paper, we develop face.evoLVe -- a comprehensive library that\ncollects and implements a wide range of popular deep learning-based methods for\nface recognition. First of all, face.evoLVe is composed of key components that\ncover the full process of face analytics, including face alignment, data\nprocessing, various backbones, losses, and alternatives with bags of tricks for\nimproving performance. Later, face.evoLVe supports multi-GPU training on top of\ndifferent deep learning platforms, such as PyTorch and PaddlePaddle, which\nfacilitates researchers to work on both large-scale datasets with millions of\nimages and low-shot counterparts with limited well-annotated data. More\nimportantly, along with face.evoLVe, images before & after alignment in the\ncommon benchmark datasets are released with source codes and trained models\nprovided. All these efforts lower the technical burdens in reproducing the\nexisting methods for comparison, while users of our library could focus on\ndeveloping advanced approaches more efficiently. Last but not least,\nface.evoLVe is well designed and vibrantly evolving, so that new face\nrecognition approaches can be easily plugged into our framework. Note that we\nhave used face.evoLVe to participate in a number of face recognition\ncompetitions and secured the first place. The version that supports PyTorch is\npublicly available at https://github.com/ZhaoJ9014/face.evoLVe.PyTorch and the\nPaddlePaddle version is available at\nhttps://github.com/ZhaoJ9014/face.evoLVe.PyTorch/tree/master/paddle.\nFace.evoLVe has been widely used for face analytics, receiving 2.4K stars and\n622 forks.",
          "link": "http://arxiv.org/abs/2107.08621",
          "publishedOn": "2021-07-20T02:04:46.609Z",
          "wordCount": null,
          "title": "Face.evoLVe: A High-Performance Face Recognition Library. (arXiv:2107.08621v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2007.09465",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Jiang_J/0/1/0/all/0/1\">Jue Jiang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hu_Y/0/1/0/all/0/1\">Yu Chi Hu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tyagi_N/0/1/0/all/0/1\">Neelam Tyagi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rimner_A/0/1/0/all/0/1\">Andreas Rimner</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_N/0/1/0/all/0/1\">Nancy Lee</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Deasy_J/0/1/0/all/0/1\">Joseph O. Deasy</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Berry_S/0/1/0/all/0/1\">Sean Berry</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Veeraraghavan_H/0/1/0/all/0/1\">Harini Veeraraghavan</a>",
          "description": "We developed a new joint probabilistic segmentation and image distribution\nmatching generative adversarial network (PSIGAN) for unsupervised domain\nadaptation (UDA) and multi-organ segmentation from magnetic resonance (MRI)\nimages. Our UDA approach models the co-dependency between images and their\nsegmentation as a joint probability distribution using a new structure\ndiscriminator. The structure discriminator computes structure of interest\nfocused adversarial loss by combining the generated pseudo MRI with\nprobabilistic segmentations produced by a simultaneously trained segmentation\nsub-network. The segmentation sub-network is trained using the pseudo MRI\nproduced by the generator sub-network. This leads to a cyclical optimization of\nboth the generator and segmentation sub-networks that are jointly trained as\npart of an end-to-end network. Extensive experiments and comparisons against\nmultiple state-of-the-art methods were done on four different MRI sequences\ntotalling 257 scans for generating multi-organ and tumor segmentation. The\nexperiments included, (a) 20 T1-weighted (T1w) in-phase mdixon and (b) 20\nT2-weighted (T2w) abdominal MRI for segmenting liver, spleen, left and right\nkidneys, (c) 162 T2-weighted fat suppressed head and neck MRI (T2wFS) for\nparotid gland segmentation, and (d) 75 T2w MRI for lung tumor segmentation. Our\nmethod achieved an overall average DSC of 0.87 on T1w and 0.90 on T2w for the\nabdominal organs, 0.82 on T2wFS for the parotid glands, and 0.77 on T2w MRI for\nlung tumors.",
          "link": "http://arxiv.org/abs/2007.09465",
          "publishedOn": "2021-07-20T02:04:46.608Z",
          "wordCount": null,
          "title": "PSIGAN: Joint probabilistic segmentation and image distribution matching for unpaired cross-modality adaptation based MRI segmentation. (arXiv:2007.09465v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.05140",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">He Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wildes_R/0/1/0/all/0/1\">Richard P. Wildes</a>",
          "description": "Video predictive understanding encompasses a wide range of efforts that are\nconcerned with the anticipation of the unobserved future from the current as\nwell as historical video observations. Action prediction is a major sub-area of\nvideo predictive understanding and is the focus of this review. This sub-area\nhas two major subdivisions: early action recognition and future action\nprediction. Early action recognition is concerned with recognizing an ongoing\naction as soon as possible. Future action prediction is concerned with the\nanticipation of actions that follow those previously observed. In either case,\nthe \\textbf{\\textit{causal}} relationship between the past, current, and\npotential future information is the main focus. Various mathematical tools such\nas Markov Chains, Gaussian Processes, Auto-Regressive modeling, and Bayesian\nrecursive filtering are widely adopted jointly with computer vision techniques\nfor these two tasks. However, these approaches face challenges such as the\ncurse of dimensionality, poor generalization, and constraints from\ndomain-specific knowledge. Recently, structures that rely on deep convolutional\nneural networks and recurrent neural networks have been extensively proposed\nfor improving the performance of existing vision tasks, in general, and action\nprediction tasks, in particular. However, they have their own shortcomings, \\eg\nreliance on massive training data and lack of strong theoretical underpinnings.\nIn this survey, we start by introducing the major sub-areas of the broad area\nof video predictive understanding, which recently have received intensive\nattention and proven to have practical value. Next, a thorough review of\nvarious early action recognition and future action prediction algorithms are\nprovided with suitably organized divisions. Finally, we conclude our discussion\nwith future research directions.",
          "link": "http://arxiv.org/abs/2107.05140",
          "publishedOn": "2021-07-20T02:04:46.587Z",
          "wordCount": null,
          "title": "Review of Video Predictive Understanding: Early Action Recognition and Future Action Prediction. (arXiv:2107.05140v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.01319",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xing_Y/0/1/0/all/0/1\">Yifan Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_T/0/1/0/all/0/1\">Tong He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_T/0/1/0/all/0/1\">Tianjun Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yongxin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1\">Yuanjun Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_W/0/1/0/all/0/1\">Wei Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wipf_D/0/1/0/all/0/1\">David Wipf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1\">Stefano Soatto</a>",
          "description": "We propose a hierarchical graph neural network (GNN) model that learns how to\ncluster a set of images into an unknown number of identities using a training\nset of images annotated with labels belonging to a disjoint set of identities.\nOur hierarchical GNN uses a novel approach to merge connected components\npredicted at each level of the hierarchy to form a new graph at the next level.\nUnlike fully unsupervised hierarchical clustering, the choice of grouping and\ncomplexity criteria stems naturally from supervision in the training set. The\nresulting method, Hi-LANDER, achieves an average of 54% improvement in F-score\nand 8% increase in Normalized Mutual Information (NMI) relative to current\nGNN-based clustering algorithms. Additionally, state-of-the-art GNN-based\nmethods rely on separate models to predict linkage probabilities and node\ndensities as intermediate steps of the clustering process. In contrast, our\nunified framework achieves a seven-fold decrease in computational cost. We\nrelease our training and inference code at\nhttps://github.com/dmlc/dgl/tree/master/examples/pytorch/hilander.",
          "link": "http://arxiv.org/abs/2107.01319",
          "publishedOn": "2021-07-20T02:04:46.585Z",
          "wordCount": null,
          "title": "Learning Hierarchical Graph Neural Networks for Image Clustering. (arXiv:2107.01319v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.06419",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Wang_J/0/1/0/all/0/1\">Jinke Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lv_P/0/1/0/all/0/1\">Peiqing Lv</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_H/0/1/0/all/0/1\">Haiying Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shi_C/0/1/0/all/0/1\">Changfa Shi</a>",
          "description": "Background and objective: In this paper, a modified U-Net based framework is\npresented, which leverages techniques from Squeeze-and-Excitation (SE) block,\nAtrous Spatial Pyramid Pooling (ASPP) and residual learning for accurate and\nrobust liver CT segmentation, and the effectiveness of the proposed method was\ntested on two public datasets LiTS17 and SLiver07.\n\nMethods: A new network architecture called SAR-U-Net was designed. Firstly,\nthe SE block is introduced to adaptively extract image features after each\nconvolution in the U-Net encoder, while suppressing irrelevant regions, and\nhighlighting features of specific segmentation task; Secondly, ASPP was\nemployed to replace the transition layer and the output layer, and acquire\nmulti-scale image information via different receptive fields. Thirdly, to\nalleviate the degradation problem, the traditional convolution block was\nreplaced with the residual block and thus prompt the network to gain accuracy\nfrom considerably increased depth.\n\nResults: In the LiTS17 experiment, the mean values of Dice, VOE, RVD, ASD and\nMSD were 95.71, 9.52, -0.84, 1.54 and 29.14, respectively. Compared with other\nclosely related 2D-based models, the proposed method achieved the highest\naccuracy. In the experiment of the SLiver07, the mean values of Dice, VOE, RVD,\nASD and MSD were 97.31, 5.37, -1.08, 1.85 and 27.45, respectively. Compared\nwith other closely related models, the proposed method achieved the highest\nsegmentation accuracy except for the RVD.\n\nConclusion: The proposed model enables a great improvement on the accuracy\ncompared to 2D-based models, and its robustness in circumvent challenging\nproblems, such as small liver regions, discontinuous liver regions, and fuzzy\nliver boundaries, is also well demonstrated and validated.",
          "link": "http://arxiv.org/abs/2103.06419",
          "publishedOn": "2021-07-20T02:04:46.582Z",
          "wordCount": null,
          "title": "SAR-U-Net: squeeze-and-excitation block and atrous spatial pyramid pooling based residual U-Net for automatic liver segmentation in Computed Tomography. (arXiv:2103.06419v3 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.03670",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+He_R/0/1/0/all/0/1\">Ruian He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_Z/0/1/0/all/0/1\">Zhen Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_W/0/1/0/all/0/1\">Weimin Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_B/0/1/0/all/0/1\">Bo Yan</a>",
          "description": "Affective Analysis is not a single task, and the valence-arousal value,\nexpression class, and action unit can be predicted at the same time. Previous\nresearches did not pay enough attention to the entanglement and hierarchical\nrelation of these three facial attributes. We propose a novel model named\nfeature pyramid networks for multi-task affect analysis. The hierarchical\nfeatures are extracted to predict three labels and we apply a teacher-student\ntraining strategy to learn from pretrained single-task models. Extensive\nexperiment results demonstrate the proposed model outperforms other models.\nThis is a submission to The 2nd Workshop and Competition on Affective Behavior\nAnalysis in the wild (ABAW). The code and model are available for research\npurposes at https://github.com/ryanhe312/ABAW2-FPNMAA.",
          "link": "http://arxiv.org/abs/2107.03670",
          "publishedOn": "2021-07-20T02:04:46.580Z",
          "wordCount": null,
          "title": "Feature Pyramid Network for Multi-task Affective Analysis. (arXiv:2107.03670v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.03227",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Patel_D/0/1/0/all/0/1\">Deep Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_E/0/1/0/all/0/1\">Erin Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koul_A/0/1/0/all/0/1\">Anirudh Koul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganju_S/0/1/0/all/0/1\">Siddha Ganju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kasam_M/0/1/0/all/0/1\">Meher Anand Kasam</a>",
          "description": "Data imbalance is a ubiquitous problem in machine learning. In large scale\ncollected and annotated datasets, data imbalance is either mitigated manually\nby undersampling frequent classes and oversampling rare classes, or planned for\nwith imputation and augmentation techniques. In both cases balancing data\nrequires labels. In other words, only annotated data can be balanced.\nCollecting fully annotated datasets is challenging, especially for large scale\nsatellite systems such as the unlabeled NASA's 35 PB Earth Imagery dataset.\nAlthough the NASA Earth Imagery dataset is unlabeled, there are implicit\nproperties of the data source that we can rely on to hypothesize about its\nimbalance, such as distribution of land and water in the case of the Earth's\nimagery. We present a new iterative method to balance unlabeled data. Our\nmethod utilizes image embeddings as a proxy for image labels that can be used\nto balance data, and ultimately when trained increases overall accuracy.",
          "link": "http://arxiv.org/abs/2107.03227",
          "publishedOn": "2021-07-20T02:04:46.580Z",
          "wordCount": null,
          "title": "Scalable Data Balancing for Unlabeled Satellite Imagery. (arXiv:2107.03227v1 [cs.CV] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.04902",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kotseruba_I/0/1/0/all/0/1\">Iuliia Kotseruba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papagelis_M/0/1/0/all/0/1\">Manos Papagelis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsotsos_J/0/1/0/all/0/1\">John K. Tsotsos</a>",
          "description": "This work aims to study the dynamic between research in the industry and\nacademia in computer vision. The results are demonstrated on a set of top-5\nvision conferences that are representative of the field. Since data for such\nanalysis was not readily available, significant effort was spent on gathering\nand processing meta-data from the original publications. First, this study\nquantifies the share of industry-sponsored research. Specifically, it shows\nthat the proportion of papers published by industry-affiliated researchers is\nincreasing and that more academics join companies or collaborate with them.\nNext, the possible impact of industry presence is further explored, namely in\nthe distribution of research topics and citation patterns. The results indicate\nthat the distribution of the research topics is similar in industry and\nacademic papers. However, there is a strong preference towards citing industry\npapers. Finally, possible reasons for citation bias, such as code availability\nand influence, are investigated.",
          "link": "http://arxiv.org/abs/2107.04902",
          "publishedOn": "2021-07-20T02:04:46.579Z",
          "wordCount": null,
          "title": "Industry and Academic Research in Computer Vision. (arXiv:2107.04902v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.02503",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1\">Kaiyang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Ziwei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1\">Yu Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_T/0/1/0/all/0/1\">Tao Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Loy_C/0/1/0/all/0/1\">Chen Change Loy</a>",
          "description": "Generalization to out-of-distribution (OOD) data is a capability natural to\nhumans yet challenging for machines to reproduce. This is because most learning\nalgorithms strongly rely on the i.i.d.~assumption on source/target data, which\nis often violated in practice due to domain shift. Domain generalization (DG)\naims to achieve OOD generalization by using only source data for model\nlearning. Since first introduced in 2011, research in DG has made great\nprogresses. In particular, intensive research in this topic has led to a broad\nspectrum of methodologies, e.g., those based on domain alignment,\nmeta-learning, data augmentation, or ensemble learning, just to name a few; and\nhas covered various vision applications such as object recognition,\nsegmentation, action recognition, and person re-identification. In this paper,\nfor the first time a comprehensive literature review is provided to summarize\nthe developments in DG for computer vision over the past decade. Specifically,\nwe first cover the background by formally defining DG and relating it to other\nresearch fields like domain adaptation and transfer learning. Second, we\nconduct a thorough review into existing methods and present a categorization\nbased on their methodologies and motivations. Finally, we conclude this survey\nwith insights and discussions on future research directions.",
          "link": "http://arxiv.org/abs/2103.02503",
          "publishedOn": "2021-07-20T02:04:46.578Z",
          "wordCount": null,
          "title": "Domain Generalization in Vision: A Survey. (arXiv:2103.02503v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.04184",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alam_F/0/1/0/all/0/1\">Firoj Alam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alam_T/0/1/0/all/0/1\">Tanvirul Alam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Imran_M/0/1/0/all/0/1\">Muhammad Imran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ofli_F/0/1/0/all/0/1\">Ferda Ofli</a>",
          "description": "Images shared on social media help crisis managers gain situational awareness\nand assess incurred damages, among other response tasks. As the volume and\nvelocity of such content are typically high, real-time image classification has\nbecome an urgent need for a faster disaster response. Recent advances in\ncomputer vision and deep neural networks have enabled the development of models\nfor real-time image classification for a number of tasks, including detecting\ncrisis incidents, filtering irrelevant images, classifying images into specific\nhumanitarian categories, and assessing the severity of the damage. To develop\nrobust real-time models, it is necessary to understand the capability of the\npublicly available pre-trained models for these tasks, which remains to be\nunder-explored in the crisis informatics literature. In this study, we address\nsuch limitations by investigating ten different network architectures for four\ndifferent tasks using the largest publicly available datasets for these tasks.\nWe also explore various data augmentation strategies, semi-supervised\ntechniques, and a multitask learning setup. In our extensive experiments, we\nachieve promising results.",
          "link": "http://arxiv.org/abs/2104.04184",
          "publishedOn": "2021-07-20T02:04:46.578Z",
          "wordCount": null,
          "title": "Robust Training of Social Media Image Classification Models for Rapid Disaster Response. (arXiv:2104.04184v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.02739",
          "author": "<a href=\"http://arxiv.org/find/econ/1/au:+Han_S/0/1/0/all/0/1\">Sukjin Han</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Schulman_E/0/1/0/all/0/1\">Eric H. Schulman</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Grauman_K/0/1/0/all/0/1\">Kristen Grauman</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Ramakrishnan_S/0/1/0/all/0/1\">Santhosh Ramakrishnan</a>",
          "description": "Many differentiated products have key attributes that are unstructured and\nthus high-dimensional (e.g., design, text). Instead of treating unstructured\nattributes as unobservables in economic models, quantifying them can be\nimportant to answer interesting economic questions. To propose an analytical\nframework for this type of products, this paper considers one of the simplest\ndesign products -- fonts -- and investigates merger and product differentiation\nusing an original dataset from the world's largest online marketplace for\nfonts. We quantify font shapes by constructing embeddings from a deep\nconvolutional neural network. Each embedding maps a font's shape onto a\nlow-dimensional vector. In the resulting product space, designers are assumed\nto engage in Hotelling-type spatial competition. From the image embeddings, we\nconstruct two alternative measures that capture the degree of design\ndifferentiation. We then study the causal effects of a merger on the merging\nfirm's creative decisions using the constructed measures in a synthetic control\nmethod. We find that the merger causes the merging firm to increase the visual\nvariety of font design. Notably, such effects are not captured when using\ntraditional measures for product offerings (e.g., specifications and the number\nof products) constructed from structured data.",
          "link": "http://arxiv.org/abs/2107.02739",
          "publishedOn": "2021-07-20T02:04:46.577Z",
          "wordCount": null,
          "title": "Shapes as Product Differentiation: Neural Network Embedding in the Analysis of Markets for Fonts. (arXiv:2107.02739v1 [econ.EM] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.01579",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1\">Linqing Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jiwen Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>",
          "description": "In this paper, we propose a similarity-aware fusion network (SAFNet) to\nadaptively fuse 2D images and 3D point clouds for 3D semantic segmentation.\nExisting fusion-based methods achieve remarkable performances by integrating\ninformation from multiple modalities. However, they heavily rely on the\ncorrespondence between 2D pixels and 3D points by projection and can only\nperform the information fusion in a fixed manner, and thus their performances\ncannot be easily migrated to a more realistic scenario where the collected data\noften lack strict pair-wise features for prediction. To address this, we employ\na late fusion strategy where we first learn the geometric and contextual\nsimilarities between the input and back-projected (from 2D pixels) point clouds\nand utilize them to guide the fusion of two modalities to further exploit\ncomplementary information. Specifically, we employ a geometric similarity\nmodule (GSM) to directly compare the spatial coordinate distributions of\npair-wise 3D neighborhoods, and a contextual similarity module (CSM) to\naggregate and compare spatial contextual information of corresponding central\npoints. The two proposed modules can effectively measure how much image\nfeatures can help predictions, enabling the network to adaptively adjust the\ncontributions of two modalities to the final prediction of each point.\nExperimental results on the ScanNetV2 benchmark demonstrate that SAFNet\nsignificantly outperforms existing state-of-the-art fusion-based approaches\nacross various data integrity.",
          "link": "http://arxiv.org/abs/2107.01579",
          "publishedOn": "2021-07-20T02:04:46.576Z",
          "wordCount": null,
          "title": "Similarity-Aware Fusion Network for 3D Semantic Segmentation. (arXiv:2107.01579v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.16194",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mihai_D/0/1/0/all/0/1\">Daniela Mihai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hare_J/0/1/0/all/0/1\">Jonathon Hare</a>",
          "description": "We present a bottom-up differentiable relaxation of the process of drawing\npoints, lines and curves into a pixel raster. Our approach arises from the\nobservation that rasterising a pixel in an image given parameters of a\nprimitive can be reformulated in terms of the primitive's distance transform,\nand then relaxed to allow the primitive's parameters to be learned. This\nrelaxation allows end-to-end differentiable programs and deep networks to be\nlearned and optimised and provides several building blocks that allow control\nover how a compositional drawing process is modelled. We emphasise the\nbottom-up nature of our proposed approach, which allows for drawing operations\nto be composed in ways that can mimic the physical reality of drawing rather\nthan being tied to, for example, approaches in modern computer graphics. With\nthe proposed approach we demonstrate how sketches can be generated by directly\noptimising against photographs and how auto-encoders can be built to transform\nrasterised handwritten digits into vectors without supervision. Extensive\nexperimental results highlight the power of this approach under different\nmodelling assumptions for drawing tasks.",
          "link": "http://arxiv.org/abs/2103.16194",
          "publishedOn": "2021-07-20T02:04:46.572Z",
          "wordCount": null,
          "title": "Differentiable Drawing and Sketching. (arXiv:2103.16194v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.12056",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Shi_C/0/1/0/all/0/1\">Changfa Shi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xian_M/0/1/0/all/0/1\">Min Xian</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhou_X/0/1/0/all/0/1\">Xiancheng Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_H/0/1/0/all/0/1\">Haotian Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cheng_H/0/1/0/all/0/1\">Heng-Da Cheng</a>",
          "description": "Liver segmentation from abdominal CT images is an essential step for liver\ncancer computer-aided diagnosis and surgical planning. However, both the\naccuracy and robustness of existing liver segmentation methods cannot meet the\nrequirements of clinical applications. In particular, for the common clinical\ncases where the liver tissue contains major pathology, current segmentation\nmethods show poor performance. In this paper, we propose a novel low-rank\ntensor decomposition (LRTD) based multi-atlas segmentation (MAS) framework that\nachieves accurate and robust pathological liver segmentation of CT images.\nFirstly, we propose a multi-slice LRTD scheme to recover the underlying\nlow-rank structure embedded in 3D medical images. It performs the LRTD on small\nimage segments consisting of multiple consecutive image slices. Then, we\npresent an LRTD-based atlas construction method to generate tumor-free liver\natlases that mitigates the performance degradation of liver segmentation due to\nthe presence of tumors. Finally, we introduce an LRTD-based MAS algorithm to\nderive patient-specific liver atlases for each test image, and to achieve\naccurate pairwise image registration and label propagation. Extensive\nexperiments on three public databases of pathological liver cases validate the\neffectiveness of the proposed method. Both qualitative and quantitative results\ndemonstrate that, in the presence of major pathology, the proposed method is\nmore accurate and robust than state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2102.12056",
          "publishedOn": "2021-07-20T02:04:46.561Z",
          "wordCount": null,
          "title": "Multi-Slice Low-Rank Tensor Decomposition Based Multi-Atlas Segmentation: Application to Automatic Pathological Liver CT Segmentation. (arXiv:2102.12056v3 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.08715",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chopin_B/0/1/0/all/0/1\">Baptiste Chopin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Otberdout_N/0/1/0/all/0/1\">Naima Otberdout</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daoudi_M/0/1/0/all/0/1\">Mohamed Daoudi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bartolo_A/0/1/0/all/0/1\">Angela Bartolo</a>",
          "description": "Human motion prediction aims to forecast future human poses given a prior\npose sequence. The discontinuity of the predicted motion and the performance\ndeterioration in long-term horizons are still the main challenges encountered\nin current literature. In this work, we tackle these issues by using a compact\nmanifold-valued representation of human motion. Specifically, we model the\ntemporal evolution of the 3D human poses as trajectory, what allows us to map\nhuman motions to single points on a sphere manifold. To learn these\nnon-Euclidean representations, we build a manifold-aware Wasserstein generative\nadversarial model that captures the temporal and spatial dependencies of human\nmotion through different losses. Extensive experiments show that our approach\noutperforms the state-of-the-art on CMU MoCap and Human 3.6M datasets. Our\nqualitative results show the smoothness of the predicted motions.",
          "link": "http://arxiv.org/abs/2105.08715",
          "publishedOn": "2021-07-20T02:04:46.557Z",
          "wordCount": null,
          "title": "Human Motion Prediction Using Manifold-Aware Wasserstein GAN. (arXiv:2105.08715v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08653",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cho_H/0/1/0/all/0/1\">Hyeonwoo Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nishimura_K/0/1/0/all/0/1\">Kazuya Nishimura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watanabe_K/0/1/0/all/0/1\">Kazuhide Watanabe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bise_R/0/1/0/all/0/1\">Ryoma Bise</a>",
          "description": "The domain shift problem is an important issue in automatic cell detection. A\ndetection network trained with training data under a specific condition (source\ndomain) may not work well in data under other conditions (target domain). We\npropose an unsupervised domain adaptation method for cell detection using the\npseudo-cell-position heatmap, where a cell centroid becomes a peak with a\nGaussian distribution in the map. In the prediction result for the target\ndomain, even if a peak location is correct, the signal distribution around the\npeak often has anon-Gaussian shape. The pseudo-cell-position heatmap is\nre-generated using the peak positions in the predicted heatmap to have a clear\nGaussian shape. Our method selects confident pseudo-cell-position heatmaps\nusing a Bayesian network and adds them to the training data in the next\niteration. The method can incrementally extend the domain from the source\ndomain to the target domain in a semi-supervised manner. In the experiments\nusing 8 combinations of domains, the proposed method outperformed the existing\ndomain adaptation methods.",
          "link": "http://arxiv.org/abs/2107.08653",
          "publishedOn": "2021-07-20T02:04:46.488Z",
          "wordCount": null,
          "title": "Cell Detection in Domain Shift Problem Using Pseudo-Cell-Position Heatmap. (arXiv:2107.08653v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2005.04401",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bui_K/0/1/0/all/0/1\">Kevin Bui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_F/0/1/0/all/0/1\">Fredrick Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lou_Y/0/1/0/all/0/1\">Yifei Lou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xin_J/0/1/0/all/0/1\">Jack Xin</a>",
          "description": "In a class of piecewise-constant image segmentation models, we propose to\nincorporate a weighted difference of anisotropic and isotropic total variation\n(AITV) to regularize the partition boundaries in an image. In particular, we\nreplace the total variation regularization in the Chan-Vese segmentation model\nand a fuzzy region competition model by the proposed AITV. To deal with the\nnonconvex nature of AITV, we apply the difference-of-convex algorithm (DCA), in\nwhich the subproblems can be minimized by the primal-dual hybrid gradient\nmethod with linesearch. The convergence of the DCA scheme is analyzed. In\naddition, a generalization to color image segmentation is discussed. In the\nnumerical experiments, we compare the proposed models with the classic convex\napproaches and the two-stage segmentation methods (smoothing and then\nthresholding) on various images, showing that our models are effective in image\nsegmentation and robust with respect to impulsive noises.",
          "link": "http://arxiv.org/abs/2005.04401",
          "publishedOn": "2021-07-20T02:04:46.483Z",
          "wordCount": null,
          "title": "A Weighted Difference of Anisotropic and Isotropic Total Variation for Relaxed Mumford-Shah Color and Multiphase Image Segmentation. (arXiv:2005.04401v6 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.07335",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1\">Md. Mushfiqur Rahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abedin_T/0/1/0/all/0/1\">Thasin Abedin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prottoy_K/0/1/0/all/0/1\">Khondokar S. S. Prottoy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moshruba_A/0/1/0/all/0/1\">Ayana Moshruba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siddiqui_F/0/1/0/all/0/1\">Fazlul Hasan Siddiqui</a>",
          "description": "Video captioning, i.e. the task of generating captions from video sequences\ncreates a bridge between the Natural Language Processing and Computer Vision\ndomains of computer science. The task of generating a semantically accurate\ndescription of a video is quite complex. Considering the complexity, of the\nproblem, the results obtained in recent research works are praiseworthy.\nHowever, there is plenty of scope for further investigation. This paper\naddresses this scope and proposes a novel solution. Most video captioning\nmodels comprise two sequential/recurrent layers - one as a video-to-context\nencoder and the other as a context-to-caption decoder. This paper proposes a\nnovel architecture, namely Semantically Sensible Video Captioning (SSVC) which\nmodifies the context generation mechanism by using two novel approaches -\n\"stacked attention\" and \"spatial hard pull\". As there are no exclusive metrics\nfor evaluating video captioning models, we emphasize both quantitative and\nqualitative analysis of our model. Hence, we have used the BLEU scoring metric\nfor quantitative analysis and have proposed a human evaluation metric for\nqualitative analysis, namely the Semantic Sensibility (SS) scoring metric. SS\nScore overcomes the shortcomings of common automated scoring metrics. This\npaper reports that the use of the aforementioned novelties improves the\nperformance of state-of-the-art architectures.",
          "link": "http://arxiv.org/abs/2009.07335",
          "publishedOn": "2021-07-20T02:04:46.482Z",
          "wordCount": null,
          "title": "Video captioning with stacked attention and semantic hard pull. (arXiv:2009.07335v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08580",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Di Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yaohui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dantcheva_A/0/1/0/all/0/1\">Antitza Dantcheva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garattoni_L/0/1/0/all/0/1\">Lorenzo Garattoni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Francesca_G/0/1/0/all/0/1\">Gianpiero Francesca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bremond_F/0/1/0/all/0/1\">Francois Bremond</a>",
          "description": "Action recognition based on skeleton data has recently witnessed increasing\nattention and progress. State-of-the-art approaches adopting Graph\nConvolutional networks (GCNs) can effectively extract features on human\nskeletons relying on the pre-defined human topology. Despite associated\nprogress, GCN-based methods have difficulties to generalize across domains,\nespecially with different human topological structures. In this context, we\nintroduce UNIK, a novel skeleton-based action recognition method that is not\nonly effective to learn spatio-temporal features on human skeleton sequences\nbut also able to generalize across datasets. This is achieved by learning an\noptimal dependency matrix from the uniform distribution based on a multi-head\nattention mechanism. Subsequently, to study the cross-domain generalizability\nof skeleton-based action recognition in real-world videos, we re-evaluate\nstate-of-the-art approaches as well as the proposed UNIK in light of a novel\nPosetics dataset. This dataset is created from Kinetics-400 videos by\nestimating, refining and filtering poses. We provide an analysis on how much\nperformance improves on smaller benchmark datasets after pre-training on\nPosetics for the action classification task. Experimental results show that the\nproposed UNIK, with pre-training on Posetics, generalizes well and outperforms\nstate-of-the-art when transferred onto four target action classification\ndatasets: Toyota Smarthome, Penn Action, NTU-RGB+D 60 and NTU-RGB+D 120.",
          "link": "http://arxiv.org/abs/2107.08580",
          "publishedOn": "2021-07-20T02:04:46.481Z",
          "wordCount": null,
          "title": "UNIK: A Unified Framework for Real-world Skeleton-based Action Recognition. (arXiv:2107.08580v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2011.10934",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pan_Y/0/1/0/all/0/1\">Yiyuan Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xuecheng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Weijie Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_Y/0/1/0/all/0/1\">Yunxiang Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yue Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_R/0/1/0/all/0/1\">Rong Xiong</a>",
          "description": "Place recognition is indispensable for a drift-free localization system. Due\nto the variations of the environment, place recognition using single-modality\nhas limitations. In this paper, we propose a bi-modal place recognition method,\nwhich can extract a compound global descriptor from the two modalities, vision\nand LiDAR. Specifically, we first build the elevation image generated from 3D\npoints as a structural representation. Then, we derive the correspondences\nbetween 3D points and image pixels that are further used in merging the\npixel-wise visual features into the elevation map grids. In this way, we fuse\nthe structural features and visual features in the consistent bird-eye view\nframe, yielding a semantic representation, namely CORAL. And the whole network\nis called CORAL-VLAD. Comparisons on the Oxford RobotCar show that CORAL-VLAD\nhas superior performance against other state-of-the-art methods. We also\ndemonstrate that our network can be generalized to other scenes and sensor\nconfigurations on cross-city datasets.",
          "link": "http://arxiv.org/abs/2011.10934",
          "publishedOn": "2021-07-20T02:04:46.481Z",
          "wordCount": null,
          "title": "CORAL: Colored structural representation for bi-modal place recognition. (arXiv:2011.10934v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08623",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_G/0/1/0/all/0/1\">Guoping Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xingrong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xinwei He</a>",
          "description": "Medical image segmentation plays an essential role in developing\ncomputer-assisted diagnosis and therapy systems, yet still faces many\nchallenges. In the past few years, the popular encoder-decoder architectures\nbased on CNNs (e.g., U-Net) have been successfully applied in the task of\nmedical image segmentation. However, due to the locality of convolution\noperations, they demonstrate limitations in learning global context and\nlong-range spatial relations. Recently, several researchers try to introduce\ntransformers to both the encoder and decoder components with promising results,\nbut the efficiency requires further improvement due to the high computational\ncomplexity of transformers. In this paper, we propose LeViT-UNet, which\nintegrates a LeViT Transformer module into the U-Net architecture, for fast and\naccurate medical image segmentation. Specifically, we use LeViT as the encoder\nof the LeViT-UNet, which better trades off the accuracy and efficiency of the\nTransformer block. Moreover, multi-scale feature maps from transformer blocks\nand convolutional blocks of LeViT are passed into the decoder via\nskip-connection, which can effectively reuse the spatial information of the\nfeature maps. Our experiments indicate that the proposed LeViT-UNet achieves\nbetter performance comparing to various competing methods on several\nchallenging medical image segmentation benchmarks including Synapse and ACDC.\nCode and models will be publicly available at\nhttps://github.com/apple1986/LeViT_UNet.",
          "link": "http://arxiv.org/abs/2107.08623",
          "publishedOn": "2021-07-20T02:04:46.480Z",
          "wordCount": null,
          "title": "LeViT-UNet: Make Faster Encoders with Transformer for Medical Image Segmentation. (arXiv:2107.08623v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08650",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yao_T/0/1/0/all/0/1\">Tianyuan Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_C/0/1/0/all/0/1\">Chang Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Quan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_R/0/1/0/all/0/1\">Ruining Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yuanhan Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jiachen Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jha_A/0/1/0/all/0/1\">Aadarsh Jha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bao_S/0/1/0/all/0/1\">Shunxing Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_M/0/1/0/all/0/1\">Mengyang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fogo_A/0/1/0/all/0/1\">Agnes B. Fogo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Landman_B/0/1/0/all/0/1\">Bennett A.Landman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_C/0/1/0/all/0/1\">Catie Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Haichun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huo_Y/0/1/0/all/0/1\">Yuankai Huo</a>",
          "description": "Unsupervised learning algorithms (e.g., self-supervised learning,\nauto-encoder, contrastive learning) allow deep learning models to learn\neffective image representations from large-scale unlabeled data. In medical\nimage analysis, even unannotated data can be difficult to obtain for individual\nlabs. Fortunately, national-level efforts have been made to provide efficient\naccess to obtain biomedical image data from previous scientific publications.\nFor instance, NIH has launched the Open-i search engine that provides a\nlarge-scale image database with free access. However, the images in scientific\npublications consist of a considerable amount of compound figures with\nsubplots. To extract and curate individual subplots, many different compound\nfigure separation approaches have been developed, especially with the recent\nadvances in deep learning. However, previous approaches typically required\nresource extensive bounding box annotation to train detection models. In this\npaper, we propose a simple compound figure separation (SimCFS) framework that\nuses weak classification annotations from individual images. Our technical\ncontribution is three-fold: (1) we introduce a new side loss that is designed\nfor compound figure separation; (2) we introduce an intra-class image\naugmentation method to simulate hard cases; (3) the proposed framework enables\nan efficient deployment to new classes of images, without requiring resource\nextensive bounding box annotations. From the results, the SimCFS achieved a new\nstate-of-the-art performance on the ImageCLEF 2016 Compound Figure Separation\nDatabase. The source code of SimCFS is made publicly available at\nhttps://github.com/hrlblab/ImageSeperation.",
          "link": "http://arxiv.org/abs/2107.08650",
          "publishedOn": "2021-07-20T02:04:46.480Z",
          "wordCount": null,
          "title": "Compound Figure Separation of Biomedical Images with Side Loss. (arXiv:2107.08650v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08579",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ng_Y/0/1/0/all/0/1\">Yan Bin Ng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fernando_B/0/1/0/all/0/1\">Basura Fernando</a>",
          "description": "We present a new architecture for human action forecasting from videos. A\ntemporal recurrent encoder captures temporal information of input videos while\na self-attention model is used to attend on relevant feature dimensions of the\ninput space. To handle temporal variations in observed video data, a feature\nmasking techniques is employed. We classify observed actions accurately using\nan auxiliary classifier which helps to understand what has happened so far.\nThen the decoder generates actions for the future based on the output of the\nrecurrent encoder and the self-attention model. Experimentally, we validate\neach component of our architecture where we see that the impact of\nself-attention to identify relevant feature dimensions, temporal masking, and\nobserved auxiliary classifier. We evaluate our method on two standard action\nforecasting benchmarks and obtain state-of-the-art results.",
          "link": "http://arxiv.org/abs/2107.08579",
          "publishedOn": "2021-07-20T02:04:46.479Z",
          "wordCount": null,
          "title": "Action Forecasting with Feature-wise Self-Attention. (arXiv:2107.08579v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08470",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ho_Y/0/1/0/all/0/1\">Yung-Han Ho</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chan_C/0/1/0/all/0/1\">Chih-Chun Chan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Peng_W/0/1/0/all/0/1\">Wen-Hsiao Peng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hang_H/0/1/0/all/0/1\">Hsueh-Ming Hang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Domanski_M/0/1/0/all/0/1\">Marek Domanski</a>",
          "description": "This paper introduces an end-to-end learned image compression system, termed\nANFIC, based on Augmented Normalizing Flows (ANF). ANF is a new type of flow\nmodel, which stacks multiple variational autoencoders (VAE) for greater model\nexpressiveness. The VAE-based image compression has gone mainstream, showing\npromising compression performance. Our work presents the first attempt to\nleverage VAE-based compression in a flow-based framework. ANFIC advances\nfurther compression efficiency by stacking and extending hierarchically\nmultiple VAE's. The invertibility of ANF, together with our training\nstrategies, enables ANFIC to support a wide range of quality levels without\nchanging the encoding and decoding networks. Extensive experimental results\nshow that in terms of PSNR-RGB, ANFIC performs comparably to or better than the\nstate-of-the-art learned image compression. Moreover, it performs close to VVC\nintra coding, from low-rate compression up to nearly-lossless compression. In\nparticular, ANFIC achieves the state-of-the-art performance, when extended with\nconditional convolution for variable rate compression with a single model.",
          "link": "http://arxiv.org/abs/2107.08470",
          "publishedOn": "2021-07-20T02:04:46.478Z",
          "wordCount": null,
          "title": "ANFIC: Image Compression Using Augmented Normalizing Flows. (arXiv:2107.08470v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2009.10939",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ivgi_M/0/1/0/all/0/1\">Maor Ivgi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benny_Y/0/1/0/all/0/1\">Yaniv Benny</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ben_David_A/0/1/0/all/0/1\">Avichai Ben-David</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berant_J/0/1/0/all/0/1\">Jonathan Berant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolf_L/0/1/0/all/0/1\">Lior Wolf</a>",
          "description": "Generating images from scene graphs is a challenging task that attracted\nsubstantial interest recently. Prior works have approached this task by\ngenerating an intermediate layout description of the target image. However, the\nrepresentation of each object in the layout was generated independently, which\nresulted in high overlap, low coverage, and an overall blurry layout. We\npropose a novel method that alleviates these issues by generating the entire\nlayout description gradually to improve inter-object dependency. We empirically\nshow on the COCO-STUFF dataset that our approach improves the quality of both\nthe intermediate layout and the final image. Our approach improves the layout\ncoverage by almost 20 points and drops object overlap to negligible amounts.",
          "link": "http://arxiv.org/abs/2009.10939",
          "publishedOn": "2021-07-20T02:04:46.127Z",
          "wordCount": null,
          "title": "Scene Graph to Image Generation with Contextualized Object Layout Refinement. (arXiv:2009.10939v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.05318",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Skandarani_Y/0/1/0/all/0/1\">Youssef Skandarani</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jodoin_P/0/1/0/all/0/1\">Pierre-Marc Jodoin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lalande_A/0/1/0/all/0/1\">Alain Lalande</a>",
          "description": "Generative Adversarial Networks (GANs) have become increasingly powerful,\ngenerating mind-blowing photorealistic images that mimic the content of\ndatasets they were trained to replicate. One recurrent theme in medical imaging\nis whether GANs can also be effective at generating workable medical data as\nthey are for generating realistic RGB images. In this paper, we perform a\nmulti-GAN and multi-application study to gauge the benefits of GANs in medical\nimaging. We tested various GAN architectures from basic DCGAN to more\nsophisticated style-based GANs on three medical imaging modalities and organs\nnamely : cardiac cine-MRI, liver CT and RGB retina images. GANs were trained on\nwell-known and widely utilized datasets from which their FID score were\ncomputed to measure the visual acuity of their generated images. We further\ntested their usefulness by measuring the segmentation accuracy of a U-Net\ntrained on these generated images.\n\nResults reveal that GANs are far from being equal as some are ill-suited for\nmedical imaging applications while others are much better off. The\ntop-performing GANs are capable of generating realistic-looking medical images\nby FID standards that can fool trained experts in a visual Turing test and\ncomply to some metrics. However, segmentation results suggests that no GAN is\ncapable of reproducing the full richness of a medical datasets.",
          "link": "http://arxiv.org/abs/2105.05318",
          "publishedOn": "2021-07-20T02:04:46.096Z",
          "wordCount": null,
          "title": "GANs for Medical Image Synthesis: An Empirical Study. (arXiv:2105.05318v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.13797",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenhai Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_E/0/1/0/all/0/1\">Enze Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_D/0/1/0/all/0/1\">Deng-Ping Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_K/0/1/0/all/0/1\">Kaitao Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_D/0/1/0/all/0/1\">Ding Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_T/0/1/0/all/0/1\">Tong Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_P/0/1/0/all/0/1\">Ping Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_L/0/1/0/all/0/1\">Ling Shao</a>",
          "description": "Transformer recently has shown encouraging progresses in computer vision. In\nthis work, we present new baselines by improving the original Pyramid Vision\nTransformer (abbreviated as PVTv1) by adding three designs, including (1)\noverlapping patch embedding, (2) convolutional feed-forward networks, and (3)\nlinear complexity attention layers.\n\nWith these modifications, our PVTv2 significantly improves PVTv1 on three\ntasks e.g., classification, detection, and segmentation. Moreover, PVTv2\nachieves comparable or better performances than recent works such as Swin\nTransformer. We hope this work will facilitate state-of-the-art Transformer\nresearches in computer vision. Code is available at\nhttps://github.com/whai362/PVT .",
          "link": "http://arxiv.org/abs/2106.13797",
          "publishedOn": "2021-07-20T02:04:46.096Z",
          "wordCount": null,
          "title": "PVTv2: Improved Baselines with Pyramid Vision Transformer. (arXiv:2106.13797v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.11068",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1\">Ning Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_G/0/1/0/all/0/1\">Geng Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Che_Z/0/1/0/all/0/1\">Zhengping Che</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1\">Xuan Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xiaolong Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Q/0/1/0/all/0/1\">Qing Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1\">Jian Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jian Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Sijia Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanzhi Wang</a>",
          "description": "In deep model compression, the recent finding \"Lottery Ticket Hypothesis\"\n(LTH) (Frankle & Carbin, 2018) pointed out that there could exist a winning\nticket (i.e., a properly pruned sub-network together with original weight\ninitialization) that can achieve competitive performance than the original\ndense network. However, it is not easy to observe such winning property in many\nscenarios, where for example, a relatively large learning rate is used even if\nit benefits training the original dense model. In this work, we investigate the\nunderlying condition and rationale behind the winning property, and find that\nthe underlying reason is largely attributed to the correlation between\ninitialized weights and final-trained weights when the learning rate is not\nsufficiently large. Thus, the existence of winning property is correlated with\nan insufficient DNN pretraining, and is unlikely to occur for a well-trained\nDNN. To overcome this limitation, we propose the \"pruning & fine-tuning\" method\nthat consistently outperforms lottery ticket sparse training under the same\npruning algorithm and the same total training epochs. Extensive experiments\nover multiple deep models (VGG, ResNet, MobileNet-v2) on different datasets\nhave been conducted to justify our proposals.",
          "link": "http://arxiv.org/abs/2102.11068",
          "publishedOn": "2021-07-20T02:04:46.094Z",
          "wordCount": null,
          "title": "Lottery Ticket Preserves Weight Correlation: Is It Desirable or Not?. (arXiv:2102.11068v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1910.06070",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zhou_H/0/1/0/all/0/1\">Hao Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Laval_J/0/1/0/all/0/1\">Jorge Laval</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhou_A/0/1/0/all/0/1\">Anye Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_Y/0/1/0/all/0/1\">Yu Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_W/0/1/0/all/0/1\">Wenchao Wu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Qing_Z/0/1/0/all/0/1\">Zhu Qing</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Peeta_S/0/1/0/all/0/1\">Srinivas Peeta</a>",
          "description": "Self-driving technology companies and the research community are accelerating\ntheir pace to use machine learning longitudinal motion planning (mMP) for\nautonomous vehicles (AVs). This paper reviews the current state of the art in\nmMP, with an exclusive focus on its impact on traffic congestion. We identify\nthe availability of congestion scenarios in current datasets, and summarize the\nrequired features for training mMP. For learning methods, we survey the major\nmethods in both imitation learning and non-imitation learning. We also\nhighlight the emerging technologies adopted by some leading AV companies, e.g.\nTesla, Waymo, and Comma.ai. We find that: i) the AV industry has been mostly\nfocusing on the long tail problem related to safety and overlooked the impact\non traffic congestion, ii) the current public self-driving datasets have not\nincluded enough congestion scenarios, and mostly lack the necessary input\nfeatures/output labels to train mMP, and iii) albeit reinforcement learning\n(RL) approach can integrate congestion mitigation into the learning goal, the\nmajor mMP method adopted by industry is still behavior cloning (BC), whose\ncapability to learn a congestion-mitigating mMP remains to be seen. Based on\nthe review, the study identifies the research gaps in current mMP development.\nSome suggestions towards congestion mitigation for future mMP studies are\nproposed: i) enrich data collection to facilitate the congestion learning, ii)\nincorporate non-imitation learning methods to combine traffic efficiency into a\nsafety-oriented technical route, and iii) integrate domain knowledge from the\ntraditional car following (CF) theory to improve the string stability of mMP.",
          "link": "http://arxiv.org/abs/1910.06070",
          "publishedOn": "2021-07-20T02:04:46.003Z",
          "wordCount": null,
          "title": "Review of Learning-based Longitudinal Motion Planning for Autonomous Vehicles: Research Gaps between Self-driving and Traffic Congestion. (arXiv:1910.06070v2 [eess.SP] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1905.10784",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Belmonte_R/0/1/0/all/0/1\">Romain Belmonte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Allaert_B/0/1/0/all/0/1\">Benjamin Allaert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tirilly_P/0/1/0/all/0/1\">Pierre Tirilly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bilasco_I/0/1/0/all/0/1\">Ioan Marius Bilasco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Djeraba_C/0/1/0/all/0/1\">Chaabane Djeraba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sebe_N/0/1/0/all/0/1\">Nicu Sebe</a>",
          "description": "Although facial landmark localization (FLL) approaches are becoming\nincreasingly accurate for characterizing facial regions, one question remains\nunanswered: what is the impact of these approaches on subsequent related tasks?\nIn this paper, the focus is put on facial expression recognition (FER), where\nfacial landmarks are used for face registration, which is a common usage. Since\nthe most used datasets for facial landmark localization do not allow for a\nproper measurement of performance according to the different difficulties\n(e.g., pose, expression, illumination, occlusion, motion blur), we also\nquantify the performance of recent approaches in the presence of head pose\nvariations and facial expressions. Finally, a study of the impact of these\napproaches on FER is conducted. We show that the landmark accuracy achieved so\nfar optimizing the conventional Euclidean distance does not necessarily\nguarantee a gain in performance for FER. To deal with this issue, we propose a\nnew evaluation metric for FLL adapted to FER.",
          "link": "http://arxiv.org/abs/1905.10784",
          "publishedOn": "2021-07-20T02:04:46.002Z",
          "wordCount": null,
          "title": "Impact of facial landmark localization on facial expression recognition. (arXiv:1905.10784v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.02463",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mounir_R/0/1/0/all/0/1\">Ramy Mounir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gula_R/0/1/0/all/0/1\">Roman Gula</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Theuerkauf_J/0/1/0/all/0/1\">J&#xf6;rn Theuerkauf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarkar_S/0/1/0/all/0/1\">Sudeep Sarkar</a>",
          "description": "Using offline training schemes, researchers have tackled the event\nsegmentation problem by providing full or weak-supervision through manually\nannotated labels or self-supervised epoch-based training. Most works consider\nvideos that are at most 10's of minutes long. We present a self-supervised\nperceptual prediction framework capable of temporal event segmentation by\nbuilding stable representations of objects over time and demonstrate it on long\nvideos, spanning several days. The approach is deceptively simple but quite\neffective. We rely on predictions of high-level features computed by a standard\ndeep learning backbone. For prediction, we use an LSTM, augmented with an\nattention mechanism, trained in a self-supervised manner using the prediction\nerror. The self-learned attention maps effectively localize and track the\nevent-related objects in each frame. The proposed approach does not require\nlabels. It requires only a single pass through the video, with no separate\ntraining set. Given the lack of datasets of very long videos, we demonstrate\nour method on video from 10 days (254 hours) of continuous wildlife monitoring\ndata that we had collected with required permissions. We find that the approach\nis robust to various environmental conditions such as day/night conditions,\nrain, sharp shadows, and windy conditions. For the task of temporally locating\nevents, we had an 80% recall rate at 20% false-positive rate for frame-level\nsegmentation. At the activity level, we had an 80% activity recall rate for one\nfalse activity detection every 50 minutes. We will make the dataset, which is\nthe first of its kind, and the code available to the research community.",
          "link": "http://arxiv.org/abs/2005.02463",
          "publishedOn": "2021-07-20T02:04:46.001Z",
          "wordCount": null,
          "title": "Spatio-Temporal Event Segmentation and Localization for Wildlife Extended Videos. (arXiv:2005.02463v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08382",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chin_H/0/1/0/all/0/1\">Hsu-Hsun Chin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsay_R/0/1/0/all/0/1\">Ren-Song Tsay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Hsin-I Wu</a>",
          "description": "Recent convolutional neural network (CNN) development continues to advance\nthe state-of-the-art model accuracy for various applications. However, the\nenhanced accuracy comes at the cost of substantial memory bandwidth and storage\nrequirements and demanding computational resources. Although in the past the\nquantization methods have effectively reduced the deployment cost for edge\ndevices, it suffers from significant information loss when processing the\nbiased activations of contemporary CNNs. In this paper, we hence introduce an\nadaptive high-performance quantization method to resolve the issue of biased\nactivation by dynamically adjusting the scaling and shifting factors based on\nthe task loss. Our proposed method has been extensively evaluated on image\nclassification models (ResNet-18/34/50, MobileNet-V2, EfficientNet-B0) with\nImageNet dataset, object detection model (YOLO-V4) with COCO dataset, and\nlanguage models with PTB dataset. The results show that our 4-bit integer\n(INT4) quantization models achieve better accuracy than the state-of-the-art\n4-bit models, and in some cases, even surpass the golden full-precision models.\nThe final designs have been successfully deployed onto extremely\nresource-constrained edge devices for many practical applications.",
          "link": "http://arxiv.org/abs/2107.08382",
          "publishedOn": "2021-07-20T02:04:45.991Z",
          "wordCount": null,
          "title": "A High-Performance Adaptive Quantization Approach for Edge CNN Applications. (arXiv:2107.08382v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/1912.08393",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jia Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1\">Jinming Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_C/0/1/0/all/0/1\">Changqun Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1\">Mingcan Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yonghong Tian</a>",
          "description": "By the aid of attention mechanisms to weight the image features adaptively,\nrecent advanced deep learning-based models encourage the predicted results to\napproximate the ground-truth masks with as large predictable areas as possible,\nthus achieving the state-of-the-art performance. However, these methods do not\npay enough attention to small areas prone to misprediction. In this way, it is\nstill tough to accurately locate salient objects due to the existence of\nregions with indistinguishable foreground and background and regions with\ncomplex or fine structures. To address these problems, we propose a novel\nconvolutional neural network with purificatory mechanism and structural\nsimilarity loss. Specifically, in order to better locate preliminary salient\nobjects, we first introduce the promotion attention, which is based on spatial\nand channel attention mechanisms to promote attention to salient regions.\nSubsequently, for the purpose of restoring the indistinguishable regions that\ncan be regarded as error-prone regions of one model, we propose the\nrectification attention, which is learned from the areas of wrong prediction\nand guide the network to focus on error-prone regions thus rectifying errors.\nThrough these two attentions, we use the Purificatory Mechanism to impose\nstrict weights with different regions of the whole salient objects and purify\nresults from hard-to-distinguish regions, thus accurately predicting the\nlocations and details of salient objects. In addition to paying different\nattention to these hard-to-distinguish regions, we also consider the structural\nconstraints on complex regions and propose the Structural Similarity Loss. In\nexperiments, the proposed approach outperforms 19 state-of-the-art methods on\nsix datasets with a notable margin at over 27FPS on a single NVIDIA 1080Ti GPU.",
          "link": "http://arxiv.org/abs/1912.08393",
          "publishedOn": "2021-07-20T02:04:45.988Z",
          "wordCount": null,
          "title": "Salient Object Detection with Purificatory Mechanism and Structural Similarity Loss. (arXiv:1912.08393v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08591",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yingchao Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xian Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diao_W/0/1/0/all/0/1\">Wenhui Diao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jihao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1\">Xin Gao</a>",
          "description": "The balance between high accuracy and high speed has always been a\nchallenging task in semantic image segmentation. Compact segmentation networks\nare more widely used in the case of limited resources, while their performances\nare constrained. In this paper, motivated by the residual learning and global\naggregation, we propose a simple yet general and effective knowledge\ndistillation framework called double similarity distillation (DSD) to improve\nthe classification accuracy of all existing compact networks by capturing the\nsimilarity knowledge in pixel and category dimensions, respectively.\nSpecifically, we propose a pixel-wise similarity distillation (PSD) module that\nutilizes residual attention maps to capture more detailed spatial dependencies\nacross multiple layers. Compared with exiting methods, the PSD module greatly\nreduces the amount of calculation and is easy to expand. Furthermore,\nconsidering the differences in characteristics between semantic segmentation\ntask and other computer vision tasks, we propose a category-wise similarity\ndistillation (CSD) module, which can help the compact segmentation network\nstrengthen the global category correlation by constructing the correlation\nmatrix. Combining these two modules, DSD framework has no extra parameters and\nonly a minimal increase in FLOPs. Extensive experiments on four challenging\ndatasets, including Cityscapes, CamVid, ADE20K, and Pascal VOC 2012, show that\nDSD outperforms current state-of-the-art methods, proving its effectiveness and\ngenerality. The code and models will be publicly available.",
          "link": "http://arxiv.org/abs/2107.08591",
          "publishedOn": "2021-07-20T02:04:45.987Z",
          "wordCount": null,
          "title": "Double Similarity Distillation for Semantic Image Segmentation. (arXiv:2107.08591v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2007.02443",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Pomponi_J/0/1/0/all/0/1\">Jary Pomponi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Scardapane_S/0/1/0/all/0/1\">Simone Scardapane</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Uncini_A/0/1/0/all/0/1\">Aurelio Uncini</a>",
          "description": "Catastrophic forgetting (CF) happens whenever a neural network overwrites\npast knowledge while being trained on new tasks. Common techniques to handle CF\ninclude regularization of the weights (using, e.g., their importance on past\ntasks), and rehearsal strategies, where the network is constantly re-trained on\npast data. Generative models have also been applied for the latter, in order to\nhave endless sources of data. In this paper, we propose a novel method that\ncombines the strengths of regularization and generative-based rehearsal\napproaches. Our generative model consists of a normalizing flow (NF), a\nprobabilistic and invertible neural network, trained on the internal embeddings\nof the network. By keeping a single NF conditioned on the task, we show that\nour memory overhead remains constant. In addition, exploiting the invertibility\nof the NF, we propose a simple approach to regularize the network's embeddings\nwith respect to past tasks. We show that our method performs favorably with\nrespect to state-of-the-art approaches in the literature, with bounded\ncomputational power and memory overheads.",
          "link": "http://arxiv.org/abs/2007.02443",
          "publishedOn": "2021-07-20T02:04:45.985Z",
          "wordCount": null,
          "title": "Pseudo-Rehearsal for Continual Learning with Normalizing Flows. (arXiv:2007.02443v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08918",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_K/0/1/0/all/0/1\">Kai Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yang Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_W/0/1/0/all/0/1\">Wei Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1\">Jie Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zha_Z/0/1/0/all/0/1\">Zheng-Jun Zha</a>",
          "description": "Few-shot class-incremental learning is to recognize the new classes given few\nsamples and not forget the old classes. It is a challenging task since\nrepresentation optimization and prototype reorganization can only be achieved\nunder little supervision. To address this problem, we propose a novel\nincremental prototype learning scheme. Our scheme consists of a random episode\nselection strategy that adapts the feature representation to various generated\nincremental episodes to enhance the corresponding extensibility, and a\nself-promoted prototype refinement mechanism which strengthens the expression\nability of the new classes by explicitly considering the dependencies among\ndifferent classes. Particularly, a dynamic relation projection module is\nproposed to calculate the relation matrix in a shared embedding space and\nleverage it as the factor for bootstrapping the update of prototypes. Extensive\nexperiments on three benchmark datasets demonstrate the above-par incremental\nperformance, outperforming state-of-the-art methods by a margin of 13%, 17% and\n11%, respectively.",
          "link": "http://arxiv.org/abs/2107.08918",
          "publishedOn": "2021-07-20T02:04:45.984Z",
          "wordCount": null,
          "title": "Self-Promoted Prototype Refinement for Few-Shot Class-Incremental Learning. (arXiv:2107.08918v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08369",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Paul_S/0/1/0/all/0/1\">Sayak Paul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganju_S/0/1/0/all/0/1\">Siddha Ganju</a>",
          "description": "Floods wreak havoc throughout the world, causing billions of dollars in\ndamages, and uprooting communities, ecosystems and economies. Accurate and\nrobust flood detection including delineating open water flood areas and\nidentifying flood levels can aid in disaster response and mitigation. However,\nestimating flood levels remotely is of essence as physical access to flooded\nareas is limited and the ability to deploy instruments in potential flood zones\ncan be dangerous. Aligning flood extent mapping with local topography can\nprovide a plan-of-action that the disaster response team can consider. Thus,\nremote flood level estimation via satellites like Sentinel-1 can prove to be\nremedial. The Emerging Techniques in Computational Intelligence (ETCI)\ncompetition on Flood Detection tasked participants with predicting flooded\npixels after training with synthetic aperture radar (SAR) images in a\nsupervised setting. We use a cyclical approach involving two stages (1)\ntraining an ensemble model of multiple UNet architectures with available high\nand low confidence labeled data and, (2) generating pseudo labels or low\nconfidence labels on the unlabeled test dataset, and then, combining the\ngenerated labels with the previously available high confidence labeled dataset.\nThis assimilated dataset is used for the next round of training ensemble\nmodels. This cyclical process is repeated until the performance improvement\nplateaus. Additionally, we post process our results with Conditional Random\nFields. Our approach sets a high score on the public leaderboard for the ETCI\ncompetition with 0.7654 IoU. Our method, which we release with all the code\nincluding trained models, can also be used as an open science benchmark for the\nSentinel-1 released dataset on GitHub.",
          "link": "http://arxiv.org/abs/2107.08369",
          "publishedOn": "2021-07-20T02:04:45.661Z",
          "wordCount": null,
          "title": "Flood Segmentation on Sentinel-1 SAR Imagery with Semi-Supervised Learning. (arXiv:2107.08369v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08543",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Saparov_T/0/1/0/all/0/1\">Talgat Saparov</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kurmukov_A/0/1/0/all/0/1\">Anvar Kurmukov</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shirokih_B/0/1/0/all/0/1\">Boris Shirokih</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Belyaev_M/0/1/0/all/0/1\">Mikhail Belyaev</a>",
          "description": "Domain shift is one of the most salient challenges in medical computer\nvision. Due to immense variability in scanners' parameters and imaging\nprotocols, even images obtained from the same person and the same scanner could\ndiffer significantly. We address variability in computed tomography (CT) images\ncaused by different convolution kernels used in the reconstruction process, the\ncritical domain shift factor in CT. The choice of a convolution kernel affects\npixels' granularity, image smoothness, and noise level. We analyze a dataset of\npaired CT images, where smooth and sharp images were reconstructed from the\nsame sinograms with different kernels, thus providing identical anatomy but\ndifferent style. Though identical predictions are desired, we show that the\nconsistency, measured as the average Dice between predictions on pairs, is just\n0.54. We propose Filtered Back-Projection Augmentation (FBPAug), a simple and\nsurprisingly efficient approach to augment CT images in sinogram space\nemulating reconstruction with different kernels. We apply the proposed method\nin a zero-shot domain adaptation setup and show that the consistency boosts\nfrom 0.54 to 0.92 outperforming other augmentation approaches. Neither specific\npreparation of source domain data nor target domain data is required, so our\npublicly released FBPAug can be used as a plug-and-play module for zero-shot\ndomain adaptation in any CT-based task.",
          "link": "http://arxiv.org/abs/2107.08543",
          "publishedOn": "2021-07-20T02:04:45.229Z",
          "wordCount": 664,
          "title": "Zero-Shot Domain Adaptation in CT Segmentation by Filtered Back Projection Augmentation. (arXiv:2107.08543v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08406",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shutai Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Q/0/1/0/all/0/1\">Qiang Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yinhao Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chunhua Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_W/0/1/0/all/0/1\">Wei He</a>",
          "description": "Small target detection is known to be a challenging problem. Inspired by the\nstructural characteristics and physiological mechanism of eagle-eye, a\nminiature vision system is designed for small target detection in this paper.\nFirst, a hardware platform is established, which consists of a pan-tilt, a\nshort-focus camera and a long-focus camera. Then, based on the visual attention\nmechanism of eagle-eye, the cameras with different focal lengths are controlled\ncooperatively to achieve small target detection. Experimental results show that\nthe designed biological eagle-eye vision system can accurately detect small\ntargets, which has a strong adaptive ability.",
          "link": "http://arxiv.org/abs/2107.08406",
          "publishedOn": "2021-07-20T02:04:45.201Z",
          "wordCount": 552,
          "title": "A Miniature Biological Eagle-Eye Vision System for Small Target Detection. (arXiv:2107.08406v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08471",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dengshan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rujing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1\">Chengjun Xie</a>",
          "description": "Artificial neural networks that simulate human achieves great successes. From\nthe perspective of simulating human memory method, we propose a stepped sampler\nbased on the \"repeated input\". We repeatedly inputted data to the LSTM model\nstepwise in a batch. The stepped sampler is used to strengthen the ability of\nfusing the temporal information in LSTM. We tested the stepped sampler on the\nLSTM built-in in PyTorch. Compared with the traditional sampler of PyTorch,\nsuch as sequential sampler, batch sampler, the training loss of the proposed\nstepped sampler converges faster in the training of the model, and the training\nloss after convergence is more stable. Meanwhile, it can maintain a higher test\naccuracy. We quantified the algorithm of the stepped sampler.",
          "link": "http://arxiv.org/abs/2107.08471",
          "publishedOn": "2021-07-20T02:04:45.170Z",
          "wordCount": 556,
          "title": "A stepped sampling method for video detection using LSTM. (arXiv:2107.08471v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08391",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lian_D/0/1/0/all/0/1\">Dongze Lian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zehao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xing Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1\">Shenghua Gao</a>",
          "description": "An Axial Shifted MLP architecture (AS-MLP) is proposed in this paper.\nDifferent from MLP-Mixer, where the global spatial feature is encoded for the\ninformation flow through matrix transposition and one token-mixing MLP, we pay\nmore attention to the local features communication. By axially shifting\nchannels of the feature map, AS-MLP is able to obtain the information flow from\ndifferent axial directions, which captures the local dependencies. Such an\noperation enables us to utilize a pure MLP architecture to achieve the same\nlocal receptive field as CNN-like architecture. We can also design the\nreceptive field size and dilation of blocks of AS-MLP, etc, just like designing\nthose of convolution kernels. With the proposed AS-MLP architecture, our model\nobtains 83.3% Top-1 accuracy with 88M parameters and 15.2 GFLOPs on the\nImageNet-1K dataset. Such a simple yet effective architecture outperforms all\nMLP-based architectures and achieves competitive performance compared to the\ntransformer-based architectures (e.g., Swin Transformer) even with slightly\nlower FLOPs. In addition, AS-MLP is also the first MLP-based architecture to be\napplied to the downstream tasks (e.g., object detection and semantic\nsegmentation). The experimental results are also impressive. Our proposed\nAS-MLP obtains 51.5 mAP on the COCO validation set and 49.5 MS mIoU on the\nADE20K dataset, which is competitive compared to the transformer-based\narchitectures. Code is available at https://github.com/svip-lab/AS-MLP.",
          "link": "http://arxiv.org/abs/2107.08391",
          "publishedOn": "2021-07-20T02:04:45.154Z",
          "wordCount": 658,
          "title": "AS-MLP: An Axial Shifted MLP Architecture for Vision. (arXiv:2107.08391v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08756",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Perez_I/0/1/0/all/0/1\">Iker Perez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Skalski_P/0/1/0/all/0/1\">Piotr Skalski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barns_Graham_A/0/1/0/all/0/1\">Alec Barns-Graham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_J/0/1/0/all/0/1\">Jason Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sutton_D/0/1/0/all/0/1\">David Sutton</a>",
          "description": "Enabling interpretations of model uncertainties is of key importance in\nBayesian machine learning applications. Often, this requires to meaningfully\nattribute predictive uncertainties to source features in an image, text or\ncategorical array. However, popular attribution methods are particularly\ndesigned for classification and regression scores. In order to explain\nuncertainties, state of the art alternatives commonly procure counterfactual\nfeature vectors, and proceed by making direct comparisons. In this paper, we\nleverage path integrals to attribute uncertainties in Bayesian differentiable\nmodels. We present a novel algorithm that relies on in-distribution curves\nconnecting a feature vector to some counterfactual counterpart, and we retain\ndesirable properties of interpretability methods. We validate our approach on\nbenchmark image data sets with varying resolution, and show that it\nsignificantly simplifies interpretability over the existing alternatives.",
          "link": "http://arxiv.org/abs/2107.08756",
          "publishedOn": "2021-07-20T02:04:42.595Z",
          "wordCount": 572,
          "title": "Path Integrals for the Attribution of Model Uncertainties. (arXiv:2107.08756v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08892",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jiahuan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1\">Yansong Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_B/0/1/0/all/0/1\">Bing Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Ying Wu</a>",
          "description": "Existing popular unsupervised embedding learning methods focus on enhancing\nthe instance-level local discrimination of the given unlabeled images by\nexploring various negative data. However, the existed sample outliers which\nexhibit large intra-class divergences or small inter-class variations severely\nlimit their learning performance. We justify that the performance limitation is\ncaused by the gradient vanishing on these sample outliers. Moreover, the\nshortage of positive data and disregard for global discrimination consideration\nalso pose critical issues for unsupervised learning but are always ignored by\nexisting methods. To handle these issues, we propose a novel solution to\nexplicitly model and directly explore the uncertainty of the given unlabeled\nlearning samples. Instead of learning a deterministic feature point for each\nsample in the embedding space, we propose to represent a sample by a stochastic\nGaussian with the mean vector depicting its space localization and covariance\nvector representing the sample uncertainty. We leverage such uncertainty\nmodeling as momentum to the learning which is helpful to tackle the outliers.\nFurthermore, abundant positive candidates can be readily drawn from the learned\ninstance-specific distributions which are further adopted to mitigate the\naforementioned issues. Thorough rationale analyses and extensive experiments\nare presented to verify our superiority.",
          "link": "http://arxiv.org/abs/2107.08892",
          "publishedOn": "2021-07-20T02:04:42.575Z",
          "wordCount": 635,
          "title": "Unsupervised Embedding Learning from Uncertainty Momentum Modeling. (arXiv:2107.08892v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08751",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Memmel_M/0/1/0/all/0/1\">Marius Memmel</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gonzalez_C/0/1/0/all/0/1\">Camila Gonzalez</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mukhopadhyay_A/0/1/0/all/0/1\">Anirban Mukhopadhyay</a>",
          "description": "Deep learning for medical imaging suffers from temporal and privacy-related\nrestrictions on data availability. To still obtain viable models, continual\nlearning aims to train in sequential order, as and when data is available. The\nmain challenge that continual learning methods face is to prevent catastrophic\nforgetting, i.e., a decrease in performance on the data encountered earlier.\nThis issue makes continuous training of segmentation models for medical\napplications extremely difficult. Yet, often, data from at least two different\ndomains is available which we can exploit to train the model in a way that it\ndisregards domain-specific information. We propose an architecture that\nleverages the simultaneous availability of two or more datasets to learn a\ndisentanglement between the content and domain in an adversarial fashion. The\ndomain-invariant content representation then lays the base for continual\nsemantic segmentation. Our approach takes inspiration from domain adaptation\nand combines it with continual learning for hippocampal segmentation in brain\nMRI. We showcase that our method reduces catastrophic forgetting and\noutperforms state-of-the-art continual learning methods.",
          "link": "http://arxiv.org/abs/2107.08751",
          "publishedOn": "2021-07-20T02:04:42.557Z",
          "wordCount": 612,
          "title": "Adversarial Continual Learning for Multi-Domain Hippocampal Segmentation. (arXiv:2107.08751v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08850",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ganz_J/0/1/0/all/0/1\">Jonathan Ganz</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kirsch_T/0/1/0/all/0/1\">Tobias Kirsch</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hoffmann_L/0/1/0/all/0/1\">Lucas Hoffmann</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bertram_C/0/1/0/all/0/1\">Christof A. Bertram</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hoffmann_C/0/1/0/all/0/1\">Christoph Hoffmann</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Maier_A/0/1/0/all/0/1\">Andreas Maier</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Breininger_K/0/1/0/all/0/1\">Katharina Breininger</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Blumcke_I/0/1/0/all/0/1\">Ingmar Bl&#xfc;mcke</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jabari_S/0/1/0/all/0/1\">Samir Jabari</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Aubreville_M/0/1/0/all/0/1\">Marc Aubreville</a>",
          "description": "Meningioma is one of the most prevalent brain tumors in adults. To determine\nits malignancy, it is graded by a pathologist into three grades according to\nWHO standards. This grade plays a decisive role in treatment, and yet may be\nsubject to inter-rater discordance. In this work, we present and compare three\napproaches towards fully automatic meningioma grading from histology whole\nslide images. All approaches are following a two-stage paradigm, where we first\nidentify a region of interest based on the detection of mitotic figures in the\nslide using a state-of-the-art object detection deep learning network. This\nregion of highest mitotic rate is considered characteristic for biological\ntumor behavior. In the second stage, we calculate a score corresponding to\ntumor malignancy based on information contained in this region using three\ndifferent settings. In a first approach, image patches are sampled from this\nregion and regression is based on morphological features encoded by a\nResNet-based network. We compare this to learning a logistic regression from\nthe determined mitotic count, an approach which is easily traceable and\nexplainable. Lastly, we combine both approaches in a single network. We trained\nthe pipeline on 951 slides from 341 patients and evaluated them on a separate\nset of 141 slides from 43 patients. All approaches yield a high correlation to\nthe WHO grade. The logistic regression and the combined approach had the best\nresults in our experiments, yielding correct predictions in 32 and 33 of all\ncases, respectively, with the image-based approach only predicting 25 cases\ncorrectly. Spearman's correlation was 0.716, 0.792 and 0.790 respectively. It\nmay seem counterintuitive at first that morphological features provided by\nimage patches do not improve model performance. Yet, this mirrors the criteria\nof the grading scheme, where mitotic count is the only unequivocal parameter.",
          "link": "http://arxiv.org/abs/2107.08850",
          "publishedOn": "2021-07-20T02:04:42.480Z",
          "wordCount": 767,
          "title": "Automatic and explainable grading of meningiomas from histopathology images. (arXiv:2107.08850v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08767",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Nam_W/0/1/0/all/0/1\">Woo-Jeoung Nam</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_S/0/1/0/all/0/1\">Seong-Whan Lee</a>",
          "description": "As interpretability has been pointed out as the obstacle to the adoption of\nDeep Neural Networks (DNNs), there is an increasing interest in solving a\ntransparency issue to guarantee the impressive performance. In this paper, we\ndemonstrate the efficiency of recent attribution techniques to explain the\ndiagnostic decision by visualizing the significant factors in the input image.\nBy utilizing the characteristics of objectness that DNNs have learned, fully\ndecomposing the network prediction visualizes clear localization of target\nlesion. To verify our work, we conduct our experiments on Chest X-ray diagnosis\nwith publicly accessible datasets. As an intuitive assessment metric for\nexplanations, we report the performance of intersection of Union between visual\nexplanation and bounding box of lesions. Experiment results show that recently\nproposed attribution methods visualize the more accurate localization for the\ndiagnostic decision compared to the traditionally used CAM. Furthermore, we\nanalyze the inconsistency of intentions between humans and DNNs, which is\neasily obscured by high performance. By visualizing the relevant factors, it is\npossible to confirm that the criterion for decision is in line with the\nlearning strategy. Our analysis of unmasking machine intelligence represents\nthe necessity of explainability in the medical diagnostic decision.",
          "link": "http://arxiv.org/abs/2107.08767",
          "publishedOn": "2021-07-20T02:04:42.431Z",
          "wordCount": 654,
          "title": "Improving Interpretability of Deep Neural Networks in Medical Diagnosis by Investigating the Individual Units. (arXiv:2107.08767v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08768",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Oh_M/0/1/0/all/0/1\">Myeong-Seok Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1\">Yong-Ju Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Seong-Whan Lee</a>",
          "description": "Aerial image registration or matching is a geometric process of aligning two\naerial images captured in different environments. Estimating the precise\ntransformation parameters is hindered by various environments such as time,\nweather, and viewpoints. The characteristics of the aerial images are mainly\ncomposed of a straight line owing to building and road. Therefore, the straight\nlines are distorted when estimating homography parameters directly between two\nimages. In this paper, we propose a deep homography alignment network to\nprecisely match two aerial images by progressively estimating the various\ntransformation parameters. The proposed network is possible to train the\nmatching network with a higher degree of freedom by progressively analyzing the\ntransformation parameters. The precision matching performances have been\nincreased by applying homography transformation. In addition, we introduce a\nmethod that can effectively learn the difficult-to-learn homography estimation\nnetwork. Since there is no published learning data for aerial image\nregistration, in this paper, a pair of images to which random homography\ntransformation is applied within a certain range is used for learning. Hence,\nwe could confirm that the deep homography alignment network shows high\nprecision matching performance compared with conventional works.",
          "link": "http://arxiv.org/abs/2107.08768",
          "publishedOn": "2021-07-20T02:04:42.402Z",
          "wordCount": 624,
          "title": "Precise Aerial Image Matching based on Deep Homography Estimation. (arXiv:2107.08768v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08862",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zizhang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenkai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jizheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Man Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_Y/0/1/0/all/0/1\">Yuanzhu Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gou_X/0/1/0/all/0/1\">Xinchao Gou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_M/0/1/0/all/0/1\">Muqing Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1\">Jing Song</a>",
          "description": "The 3D visual perception for vehicles with the surround-view fisheye camera\nsystem is a critical and challenging task for low-cost urban autonomous\ndriving. While existing monocular 3D object detection methods perform not well\nenough on the fisheye images for mass production, partly due to the lack of 3D\ndatasets of such images. In this paper, we manage to overcome and avoid the\ndifficulty of acquiring the large scale of accurate 3D labeled truth data, by\nbreaking down the 3D object detection task into some sub-tasks, such as\nvehicle's contact point detection, type classification, re-identification and\nunit assembling, etc. Particularly, we propose the concept of Multidimensional\nVector to include the utilizable information generated in different dimensions\nand stages, instead of the descriptive approach for the bird's eye view (BEV)\nor a cube of eight points. The experiments of real fisheye images demonstrate\nthat our solution achieves state-of-the-art accuracy while being real-time in\npractice.",
          "link": "http://arxiv.org/abs/2107.08862",
          "publishedOn": "2021-07-20T02:04:42.276Z",
          "wordCount": 617,
          "title": "Disentangling and Vectorization: A 3D Visual Perception Approach for Autonomous Driving Based on Surround-View Fisheye Cameras. (arXiv:2107.08862v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08673",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Massalimova_A/0/1/0/all/0/1\">Aidana Massalimova</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Varol_H/0/1/0/all/0/1\">Huseyin Atakan Varol</a>",
          "description": "Alzheimer's disease (AD) is a progressive brain disorder that causes memory\nand functional impairments. The advances in machine learning and publicly\navailable medical datasets initiated multiple studies in AD diagnosis. In this\nwork, we utilize a multi-modal deep learning approach in classifying normal\ncognition, mild cognitive impairment and AD classes on the basis of structural\nMRI and diffusion tensor imaging (DTI) scans from the OASIS-3 dataset. In\naddition to a conventional multi-modal network, we also present an input\nagnostic architecture that allows diagnosis with either sMRI or DTI scan, which\ndistinguishes our method from previous multi-modal machine learning-based\nmethods. The results show that the input agnostic model achieves 0.96 accuracy\nwhen both structural MRI and DTI scans are provided as inputs.",
          "link": "http://arxiv.org/abs/2107.08673",
          "publishedOn": "2021-07-20T02:04:42.239Z",
          "wordCount": 581,
          "title": "Input Agnostic Deep Learning for Alzheimer's Disease Classification Using Multimodal MRI Images. (arXiv:2107.08673v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08712",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhaoqing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1\">Guoxin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_P/0/1/0/all/0/1\">Pengfei Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_W/0/1/0/all/0/1\">Wen Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_N/0/1/0/all/0/1\">Nannan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_M/0/1/0/all/0/1\">Mingming Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tongliang Liu</a>",
          "description": "By considering the spatial correspondence, dense self-supervised\nrepresentation learning has achieved superior performance on various dense\nprediction tasks. However, the pixel-level correspondence tends to be noisy\nbecause of many similar misleading pixels, e.g., backgrounds. To address this\nissue, in this paper, we propose to explore \\textbf{set} \\textbf{sim}ilarity\n(SetSim) for dense self-supervised representation learning. We generalize\npixel-wise similarity learning to set-wise one to improve the robustness\nbecause sets contain more semantic and structure information. Specifically, by\nresorting to attentional features of views, we establish corresponding sets,\nthus filtering out noisy backgrounds that may cause incorrect correspondences.\nMeanwhile, these attentional features can keep the coherence of the same image\nacross different views to alleviate semantic inconsistency. We further search\nthe cross-view nearest neighbours of sets and employ the structured\nneighbourhood information to enhance the robustness. Empirical evaluations\ndemonstrate that SetSim is superior to state-of-the-art methods on object\ndetection, keypoint detection, instance segmentation, and semantic\nsegmentation.",
          "link": "http://arxiv.org/abs/2107.08712",
          "publishedOn": "2021-07-20T02:04:42.135Z",
          "wordCount": 603,
          "title": "Exploring Set Similarity for Dense Self-supervised Representation Learning. (arXiv:2107.08712v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08715",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1\">Cong Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_S/0/1/0/all/0/1\">Shilei Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_D/0/1/0/all/0/1\">Dong Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Hongyu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_K/0/1/0/all/0/1\">Kai Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xianli Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_B/0/1/0/all/0/1\">Buyue Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Liansheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yefeng Zheng</a>",
          "description": "Universal lesion detection in computed tomography (CT) images is an important\nyet challenging task due to the large variations in lesion type, size, shape,\nand appearance. Considering that data in clinical routine (such as the\nDeepLesion dataset) are usually annotated with a long and a short diameter\naccording to the standard of Response Evaluation Criteria in Solid Tumors\n(RECIST) diameters, we propose RECIST-Net, a new approach to lesion detection\nin which the four extreme points and center point of the RECIST diameters are\ndetected. By detecting a lesion as keypoints, we provide a more conceptually\nstraightforward formulation for detection, and overcome several drawbacks\n(e.g., requiring extensive effort in designing data-appropriate anchors and\nlosing shape information) of existing bounding-box-based methods while\nexploring a single-task, one-stage approach compared to other RECIST-based\napproaches. Experiments show that RECIST-Net achieves a sensitivity of 92.49%\nat four false positives per image, outperforming other recent methods including\nthose using multi-task learning.",
          "link": "http://arxiv.org/abs/2107.08715",
          "publishedOn": "2021-07-20T02:04:42.115Z",
          "wordCount": 609,
          "title": "RECIST-Net: Lesion detection via grouping keypoints on RECIST-based annotation. (arXiv:2107.08715v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08737",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Minyoung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Young J. Kim</a>",
          "description": "We propose a 3D face generative model with local weights to increase the\nmodel's variations and expressiveness. The proposed model allows partial\nmanipulation of the face while still learning the whole face mesh. For this\npurpose, we address an effective way to extract local facial features from the\nentire data and explore a way to manipulate them during a holistic generation.\nFirst, we factorize the latent space of the whole face to the subspace\nindicating different parts of the face. In addition, local weights generated by\nnon-negative matrix factorization are applied to the factorized latent space so\nthat the decomposed part space is semantically meaningful. We experiment with\nour model and observe that effective facial part manipulation is possible and\nthat the model's expressiveness is improved.",
          "link": "http://arxiv.org/abs/2107.08737",
          "publishedOn": "2021-07-20T02:04:42.096Z",
          "wordCount": 584,
          "title": "Synthesizing Human Faces using Latent Space Factorization and Local Weights (Extended Version). (arXiv:2107.08737v1 [cs.GR])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08565",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhenpeng Chen</a>",
          "description": "Among 2D convolutional networks on point clouds, point-based approaches\nconsume point clouds of fixed size directly. By analysis of PointNet, a pioneer\nin introducing deep learning into point sets, we reveal that current\npoint-based methods are essentially spatial relationship processing networks.\nIn this paper, we take a different approach. Our architecture, named PE-Net,\nlearns the representation of point clouds in high-dimensional space, and\nencodes the unordered input points to feature vectors, which standard 2D CNNs\ncan be applied to. The recommended network can adapt to changes in the number\nof input points which is the limit of current methods. Experiments show that in\nthe tasks of classification and part segmentation, PE-Net achieves the\nstate-of-the-art performance in multiple challenging datasets, such as ModelNet\nand ShapeNetPart.",
          "link": "http://arxiv.org/abs/2107.08565",
          "publishedOn": "2021-07-20T02:04:41.858Z",
          "wordCount": 550,
          "title": "Learning point embedding for 3D data processing. (arXiv:2107.08565v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08430",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ge_Z/0/1/0/all/0/1\">Zheng Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Songtao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Feng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zeming Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jian Sun</a>",
          "description": "In this report, we present some experienced improvements to YOLO series,\nforming a new high-performance detector -- YOLOX. We switch the YOLO detector\nto an anchor-free manner and conduct other advanced detection techniques, i.e.,\na decoupled head and the leading label assignment strategy SimOTA to achieve\nstate-of-the-art results across a large scale range of models: For YOLO-Nano\nwith only 0.91M parameters and 1.08G FLOPs, we get 25.3% AP on COCO, surpassing\nNanoDet by 1.8% AP; for YOLOv3, one of the most widely used detectors in\nindustry, we boost it to 47.3% AP on COCO, outperforming the current best\npractice by 3.0% AP; for YOLOX-L with roughly the same amount of parameters as\nYOLOv4-CSP, YOLOv5-L, we achieve 50.0% AP on COCO at a speed of 68.9 FPS on\nTesla V100, exceeding YOLOv5-L by 1.8% AP. Further, we won the 1st Place on\nStreaming Perception Challenge (Workshop on Autonomous Driving at CVPR 2021)\nusing a single YOLOX-L model. We hope this report can provide useful experience\nfor developers and researchers in practical scenes, and we also provide deploy\nversions with ONNX, TensorRT, NCNN, and Openvino supported. Source code is at\nhttps://github.com/Megvii-BaseDetection/YOLOX.",
          "link": "http://arxiv.org/abs/2107.08430",
          "publishedOn": "2021-07-20T02:04:41.791Z",
          "wordCount": 625,
          "title": "YOLOX: Exceeding YOLO Series in 2021. (arXiv:2107.08430v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08392",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+He_T/0/1/0/all/0/1\">Tong He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1\">Chunhua Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hengel_A/0/1/0/all/0/1\">Anton van den Hengel</a>",
          "description": "We propose an approach to instance segmentation from 3D point clouds based on\ndynamic convolution. This enables it to adapt, at inference, to varying feature\nand object scales. Doing so avoids some pitfalls of bottom up approaches,\nincluding a dependence on hyper-parameter tuning and heuristic post-processing\npipelines to compensate for the inevitable variability in object sizes, even\nwithin a single scene. The representation capability of the network is greatly\nimproved by gathering homogeneous points that have identical semantic\ncategories and close votes for the geometric centroids. Instances are then\ndecoded via several simple convolution layers, where the parameters are\ngenerated conditioned on the input. The proposed approach is proposal-free, and\ninstead exploits a convolution process that adapts to the spatial and semantic\ncharacteristics of each instance. A light-weight transformer, built on the\nbottleneck layer, allows the model to capture long-range dependencies, with\nlimited computational overhead. The result is a simple, efficient, and robust\napproach that yields strong performance on various datasets: ScanNetV2, S3DIS,\nand PartNet. The consistent improvements on both voxel- and point-based\narchitectures imply the effectiveness of the proposed method. Code is available\nat: https://git.io/DyCo3D",
          "link": "http://arxiv.org/abs/2107.08392",
          "publishedOn": "2021-07-20T02:04:41.770Z",
          "wordCount": 628,
          "title": "Dynamic Convolution for 3D Point Cloud Instance Segmentation. (arXiv:2107.08392v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09464",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1\">Yongxiang Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_X/0/1/0/all/0/1\">Xiaolin Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1\">Yuncong Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lu Li</a>",
          "description": "As one of the prevalent components, Feature Pyramid Network (FPN) is widely\nused in the current object detection models to improve the performance of\nmulti-scale detection. However, its interaction is still in a local and lossy\nmanner, thus limiting the representation power. In this paper, to simulate a\nglobal view of human vision in object detection and address the inherent\ndefects of interaction mode in FPN, we construct a novel architecture termed\nContent-Augmented Feature Pyramid Network (CA-FPN). Unlike the vanilla FPN,\nwhich fuses features within a local receptive field, CA-FPN can adaptively\naggregate similar features from a global view. It is equipped with a global\ncontent extraction module and light linear spatial transformers. The former\nallows to extract multi-scale context information and the latter can deeply\ncombine the global content extraction module with the vanilla FPN using the\nlinearized attention function, which is designed to reduce model complexity.\nFurthermore, CA-FPN can be readily plugged into existing FPN-based models.\nExtensive experiments on the challenging COCO and PASCAL VOC object detection\ndatasets demonstrated that our CA-FPN significantly outperforms competitive\nFPN-based detectors without bells and whistles. When plugging CA-FPN into\nCascade R-CNN framework built upon a standard ResNet-50 backbone, our method\ncan achieve 44.8 AP on COCO mini-val. Its performance surpasses the previous\nstate-of-the-art by 1.5 AP, demonstrating the potentiality of application.",
          "link": "http://arxiv.org/abs/2105.09464",
          "publishedOn": "2021-07-20T02:04:41.740Z",
          "wordCount": 703,
          "title": "Content-Augmented Feature Pyramid Network with Light Linear Spatial Transformers for Object Detection. (arXiv:2105.09464v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08717",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jiaxiang Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiaokang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_G/0/1/0/all/0/1\">Gang Zeng</a>",
          "description": "Guided depth super-resolution is a practical task where a low-resolution and\nnoisy input depth map is restored to a high-resolution version, with the help\nof a high-resolution RGB guide image. Existing methods usually view this task\nas a generalized guided filtering problem that relies on designing explicit\nfilters and objective functions, or a dense regression problem that directly\npredicts the target image via deep neural networks. These methods suffer from\neither model capability or interpretability. Inspired by the recent progress in\nimplicit neural representation, we propose to formulate the guided\nsuper-resolution as a neural implicit image interpolation problem, where we\ntake the form of a general image interpolation but use a novel Joint Implicit\nImage Function (JIIF) representation to learn both the interpolation weights\nand values. JIIF represents the target image domain with spatially distributed\nlocal latent codes extracted from the input image and the guide image, and uses\na graph attention mechanism to learn the interpolation weights at the same time\nin one unified deep implicit function. We demonstrate the effectiveness of our\nJIIF representation on guided depth super-resolution task, significantly\noutperforming state-of-the-art methods on three public benchmarks. Code can be\nfound at \\url{https://git.io/JC2sU}.",
          "link": "http://arxiv.org/abs/2107.08717",
          "publishedOn": "2021-07-20T02:04:41.695Z",
          "wordCount": 639,
          "title": "Joint Implicit Image Function for Guided Depth Super-Resolution. (arXiv:2107.08717v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2103.01134",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pandey_P/0/1/0/all/0/1\">Prashant Pandey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raman_M/0/1/0/all/0/1\">Mrigank Raman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Varambally_S/0/1/0/all/0/1\">Sumanth Varambally</a>, <a href=\"http://arxiv.org/find/cs/1/au:+AP_P/0/1/0/all/0/1\">Prathosh AP</a>",
          "description": "Generalization of machine learning models trained on a set of source domains\non unseen target domains with different statistics, is a challenging problem.\nWhile many approaches have been proposed to solve this problem, they only\nutilize source data during training but do not take advantage of the fact that\na single target example is available at the time of inference. Motivated by\nthis, we propose a method that effectively uses the target sample during\ninference beyond mere classification. Our method has three components - (i) A\nlabel-preserving feature or metric transformation on source data such that the\nsource samples are clustered in accordance with their class irrespective of\ntheir domain (ii) A generative model trained on the these features (iii) A\nlabel-preserving projection of the target point on the source-feature manifold\nduring inference via solving an optimization problem on the input space of the\ngenerative model using the learned metric. Finally, the projected target is\nused in the classifier. Since the projected target feature comes from the\nsource manifold and has the same label as the real target by design, the\nclassifier is expected to perform better on it than the true target. We\ndemonstrate that our method outperforms the state-of-the-art Domain\nGeneralization methods on multiple datasets and tasks.",
          "link": "http://arxiv.org/abs/2103.01134",
          "publishedOn": "2021-07-20T02:04:41.676Z",
          "wordCount": 678,
          "title": "Domain Generalization via Inference-time Label-Preserving Target Projections. (arXiv:2103.01134v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08111",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Roth_H/0/1/0/all/0/1\">Holger R. Roth</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_D/0/1/0/all/0/1\">Dong Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_W/0/1/0/all/0/1\">Wenqi Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Myronenko_A/0/1/0/all/0/1\">Andriy Myronenko</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhu_W/0/1/0/all/0/1\">Wentao Zhu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_Z/0/1/0/all/0/1\">Ziyue Xu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_X/0/1/0/all/0/1\">Xiaosong Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_D/0/1/0/all/0/1\">Daguang Xu</a>",
          "description": "Building robust deep learning-based models requires diverse training data,\nideally from several sources. However, these datasets cannot be combined easily\nbecause of patient privacy concerns or regulatory hurdles, especially if\nmedical data is involved. Federated learning (FL) is a way to train machine\nlearning models without the need for centralized datasets. Each FL client\ntrains on their local data while only sharing model parameters with a global\nserver that aggregates the parameters from all clients. At the same time, each\nclient's data can exhibit differences and inconsistencies due to the local\nvariation in the patient population, imaging equipment, and acquisition\nprotocols. Hence, the federated learned models should be able to adapt to the\nlocal particularities of a client's data. In this work, we combine FL with an\nAutoML technique based on local neural architecture search by training a\n\"supernet\". Furthermore, we propose an adaptation scheme to allow for\npersonalized model architectures at each FL client's site. The proposed method\nis evaluated on four different datasets from 3D prostate MRI and shown to\nimprove the local models' performance after adaptation through selecting an\noptimal path through the AutoML supernet.",
          "link": "http://arxiv.org/abs/2107.08111",
          "publishedOn": "2021-07-20T02:04:41.619Z",
          "wordCount": 650,
          "title": "Federated Whole Prostate Segmentation in MRI with Personalized Neural Architectures. (arXiv:2107.08111v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08142",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1\">Ashesh Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pero_L/0/1/0/all/0/1\">Luca Del Pero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grimmett_H/0/1/0/all/0/1\">Hugo Grimmett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ondruska_P/0/1/0/all/0/1\">Peter Ondruska</a>",
          "description": "Despite the numerous successes of machine learning over the past decade\n(image recognition, decision-making, NLP, image synthesis), self-driving\ntechnology has not yet followed the same trend. In this paper, we study the\nhistory, composition, and development bottlenecks of the modern self-driving\nstack. We argue that the slow progress is caused by approaches that require too\nmuch hand-engineering, an over-reliance on road testing, and high fleet\ndeployment costs. We observe that the classical stack has several bottlenecks\nthat preclude the necessary scale needed to capture the long tail of rare\nevents. To resolve these problems, we outline the principles of Autonomy 2.0,\nan ML-first approach to self-driving, as a viable alternative to the currently\nadopted state-of-the-art. This approach is based on (i) a fully differentiable\nAV stack trainable from human demonstrations, (ii) closed-loop data-driven\nreactive simulation, and (iii) large-scale, low-cost data collections as\ncritical solutions towards scalability issues. We outline the general\narchitecture, survey promising works in this direction and propose key\nchallenges to be addressed by the community in the future.",
          "link": "http://arxiv.org/abs/2107.08142",
          "publishedOn": "2021-07-20T02:04:41.599Z",
          "wordCount": 616,
          "title": "Autonomy 2.0: Why is self-driving always 5 years away?. (arXiv:2107.08142v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08330",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Konwer_A/0/1/0/all/0/1\">Aishik Konwer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bae_J/0/1/0/all/0/1\">Joseph Bae</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Singh_G/0/1/0/all/0/1\">Gagandeep Singh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gattu_R/0/1/0/all/0/1\">Rishabh Gattu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ali_S/0/1/0/all/0/1\">Syed Ali</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Green_J/0/1/0/all/0/1\">Jeremy Green</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Phatak_T/0/1/0/all/0/1\">Tej Phatak</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Prasanna_P/0/1/0/all/0/1\">Prateek Prasanna</a>",
          "description": "COVID-19 image analysis has mostly focused on diagnostic tasks using single\ntimepoint scans acquired upon disease presentation or admission. We present a\ndeep learning-based approach to predict lung infiltrate progression from serial\nchest radiographs (CXRs) of COVID-19 patients. Our method first utilizes\nconvolutional neural networks (CNNs) for feature extraction from patches within\nthe concerned lung zone, and also from neighboring and remote boundary regions.\nThe framework further incorporates a multi-scale Gated Recurrent Unit (GRU)\nwith a correlation module for effective predictions. The GRU accepts CNN\nfeature vectors from three different areas as input and generates a fused\nrepresentation. The correlation module attempts to minimize the correlation\nloss between hidden representations of concerned and neighboring area feature\nvectors, while maximizing the loss between the same from concerned and remote\nregions. Further, we employ an attention module over the output hidden states\nof each encoder timepoint to generate a context vector. This vector is used as\nan input to a decoder module to predict patch severity grades at a future\ntimepoint. Finally, we ensemble the patch classification scores to calculate\npatient-wise grades. Specifically, our framework predicts zone-wise disease\nseverity for a patient on a given day by learning representations from the\nprevious temporal CXRs. Our novel multi-institutional dataset comprises\nsequential CXR scans from N=93 patients. Our approach outperforms transfer\nlearning and radiomic feature-based baseline approaches on this dataset.",
          "link": "http://arxiv.org/abs/2107.08330",
          "publishedOn": "2021-07-20T02:04:41.508Z",
          "wordCount": 742,
          "title": "Attention-based Multi-scale Gated Recurrent Encoder with Novel Correlation Loss for COVID-19 Progression Prediction. (arXiv:2107.08330v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08355",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Lin_L/0/1/0/all/0/1\">Liupeng Lin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_J/0/1/0/all/0/1\">Jie Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shen_H/0/1/0/all/0/1\">Huanfeng Shen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhao_L/0/1/0/all/0/1\">Lingli Zhao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yuan_Q/0/1/0/all/0/1\">Qiangqiang Yuan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_X/0/1/0/all/0/1\">Xinghua Li</a>",
          "description": "The data fusion technology aims to aggregate the characteristics of different\ndata and obtain products with multiple data advantages. To solves the problem\nof reduced resolution of PolSAR images due to system limitations, we propose a\nfully polarimetric synthetic aperture radar (PolSAR) images and\nsingle-polarization synthetic aperture radar SAR (SinSAR) images fusion network\nto generate high-resolution PolSAR (HR-PolSAR) images. To take advantage of the\npolarimetric information of the low-resolution PolSAR (LR-PolSAR) image and the\nspatial information of the high-resolution single-polarization SAR (HR-SinSAR)\nimage, we propose a fusion framework for joint LR-PolSAR image and HR-SinSAR\nimage and design a cross-attention mechanism to extract features from the joint\ninput data. Besides, based on the physical imaging mechanism, we designed the\nPolSAR polarimetric loss function for constrained network training. The\nexperimental results confirm the superiority of fusion network over traditional\nalgorithms. The average PSNR is increased by more than 3.6db, and the average\nMAE is reduced to less than 0.07. Experiments on polarimetric decomposition and\npolarimetric signature show that it maintains polarimetric information well.",
          "link": "http://arxiv.org/abs/2107.08355",
          "publishedOn": "2021-07-20T02:04:41.490Z",
          "wordCount": 621,
          "title": "Fully Polarimetric SAR and Single-Polarization SAR Image Fusion Network. (arXiv:2107.08355v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08274",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yijin Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1\">Li Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_P/0/1/0/all/0/1\">Pujin Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_J/0/1/0/all/0/1\">Junyan Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1\">Xiaoying Tang</a>",
          "description": "Manually annotating medical images is extremely expensive, especially for\nlarge-scale datasets. Self-supervised contrastive learning has been explored to\nlearn feature representations from unlabeled images. However, unlike natural\nimages, the application of contrastive learning to medical images is relatively\nlimited. In this work, we propose a self-supervised framework, namely\nlesion-based contrastive learning for automated diabetic retinopathy (DR)\ngrading. Instead of taking entire images as the input in the common contrastive\nlearning scheme, lesion patches are employed to encourage the feature extractor\nto learn representations that are highly discriminative for DR grading. We also\ninvestigate different data augmentation operations in defining our contrastive\nprediction task. Extensive experiments are conducted on the publicly-accessible\ndataset EyePACS, demonstrating that our proposed framework performs\noutstandingly on DR grading in terms of both linear evaluation and transfer\ncapacity evaluation.",
          "link": "http://arxiv.org/abs/2107.08274",
          "publishedOn": "2021-07-20T02:04:41.472Z",
          "wordCount": 588,
          "title": "Lesion-based Contrastive Learning for Diabetic Retinopathy Grading from Fundus Images. (arXiv:2107.08274v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08323",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vo_Ho_V/0/1/0/all/0/1\">Viet-Khoa Vo-Ho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_N/0/1/0/all/0/1\">Ngan Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamazaki_K/0/1/0/all/0/1\">Kashu Yamazaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugimoto_A/0/1/0/all/0/1\">Akihiro Sugimoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_M/0/1/0/all/0/1\">Minh-Triet Tran</a>",
          "description": "Temporal action proposal generation is an essential and challenging task that\naims at localizing temporal intervals containing human actions in untrimmed\nvideos. Most of existing approaches are unable to follow the human cognitive\nprocess of understanding the video context due to lack of attention mechanism\nto express the concept of an action or an agent who performs the action or the\ninteraction between the agent and the environment. Based on the action\ndefinition that a human, known as an agent, interacts with the environment and\nperforms an action that affects the environment, we propose a contextual\nAgent-Environment Network. Our proposed contextual AEN involves (i) agent\npathway, operating at a local level to tell about which humans/agents are\nacting and (ii) environment pathway operating at a global level to tell about\nhow the agents interact with the environment. Comprehensive evaluations on\n20-action THUMOS-14 and 200-action ActivityNet-1.3 datasets with different\nbackbone networks, i.e C3D and SlowFast, show that our method robustly exhibits\noutperformance against state-of-the-art methods regardless of the employed\nbackbone network.",
          "link": "http://arxiv.org/abs/2107.08323",
          "publishedOn": "2021-07-20T02:04:41.454Z",
          "wordCount": 613,
          "title": "Agent-Environment Network for Temporal Action Proposal Generation. (arXiv:2107.08323v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08305",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zare_S/0/1/0/all/0/1\">Samira Zare</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1\">Hien Van Nguyen</a>",
          "description": "Set-input deep networks have recently drawn much interest in computer vision\nand machine learning. This is in part due to the increasing number of important\ntasks such as meta-learning, clustering, and anomaly detection that are defined\non set inputs. These networks must take an arbitrary number of input samples\nand produce the output invariant to the input set permutation. Several\nalgorithms have been recently developed to address this urgent need. Our paper\nanalyzes these algorithms using both synthetic and real-world datasets, and\nshows that they are not effective in dealing with common data variations such\nas image translation or viewpoint change. To address this limitation, we\npropose a permutation-invariant cascaded attentional set operator (PICASO). The\ngist of PICASO is a cascade of multihead attention blocks with dynamic\ntemplates. The proposed operator is a stand-alone module that can be adapted\nand extended to serve different machine learning tasks. We demonstrate the\nutilities of PICASO in four diverse scenarios: (i) clustering, (ii) image\nclassification under novel viewpoints, (iii) image anomaly detection, and (iv)\nstate prediction. PICASO increases the SmallNORB image classification accuracy\nwith novel viewpoints by about 10% points. For set anomaly detection on CelebA\ndataset, our model improves the areas under ROC and PR curves dataset by about\n22% and 10%, respectively. For the state prediction on CLEVR dataset, it\nimproves the AP by about 40%.",
          "link": "http://arxiv.org/abs/2107.08305",
          "publishedOn": "2021-07-20T02:04:41.436Z",
          "wordCount": 654,
          "title": "PICASO: Permutation-Invariant Cascaded Attentional Set Operator. (arXiv:2107.08305v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08246",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ramachandran_S/0/1/0/all/0/1\">Saravanabalagi Ramachandran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sistu_G/0/1/0/all/0/1\">Ganesh Sistu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McDonald_J/0/1/0/all/0/1\">John McDonald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yogamani_S/0/1/0/all/0/1\">Senthil Yogamani</a>",
          "description": "We present the WoodScape fisheye semantic segmentation challenge for\nautonomous driving which was held as part of the CVPR 2021 Workshop on\nOmnidirectional Computer Vision (OmniCV). This challenge is one of the first\nopportunities for the research community to evaluate the semantic segmentation\ntechniques targeted for fisheye camera perception. Due to strong radial\ndistortion standard models don't generalize well to fisheye images and hence\nthe deformations in the visual appearance of objects and entities needs to be\nencoded implicitly or as explicit knowledge. This challenge served as a medium\nto investigate the challenges and new methodologies to handle the complexities\nwith perception on fisheye images. The challenge was hosted on CodaLab and used\nthe recently released WoodScape dataset comprising of 10k samples. In this\npaper, we provide a summary of the competition which attracted the\nparticipation of 71 global teams and a total of 395 submissions. The top teams\nrecorded significantly improved mean IoU and accuracy scores over the baseline\nPSPNet with ResNet-50 backbone. We summarize the methods of winning algorithms\nand analyze the failure cases. We conclude by providing future directions for\nthe research.",
          "link": "http://arxiv.org/abs/2107.08246",
          "publishedOn": "2021-07-20T02:04:41.417Z",
          "wordCount": 659,
          "title": "Woodscape Fisheye Semantic Segmentation for Autonomous Driving -- CVPR 2021 OmniCV Workshop Challenge. (arXiv:2107.08246v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08221",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schott_L/0/1/0/all/0/1\">Lukas Schott</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kugelgen_J/0/1/0/all/0/1\">Julius von K&#xfc;gelgen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trauble_F/0/1/0/all/0/1\">Frederik Tr&#xe4;uble</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gehler_P/0/1/0/all/0/1\">Peter Gehler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Russell_C/0/1/0/all/0/1\">Chris Russell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bethge_M/0/1/0/all/0/1\">Matthias Bethge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1\">Bernhard Sch&#xf6;lkopf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Locatello_F/0/1/0/all/0/1\">Francesco Locatello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brendel_W/0/1/0/all/0/1\">Wieland Brendel</a>",
          "description": "An important component for generalization in machine learning is to uncover\nunderlying latent factors of variation as well as the mechanism through which\neach factor acts in the world. In this paper, we test whether 17 unsupervised,\nweakly supervised, and fully supervised representation learning approaches\ncorrectly infer the generative factors of variation in simple datasets\n(dSprites, Shapes3D, MPI3D). In contrast to prior robustness work that\nintroduces novel factors of variation during test time, such as blur or other\n(un)structured noise, we here recompose, interpolate, or extrapolate only\nexisting factors of variation from the training data set (e.g., small and\nmedium-sized objects during training and large objects during testing). Models\nthat learn the correct mechanism should be able to generalize to this\nbenchmark. In total, we train and test 2000+ models and observe that all of\nthem struggle to learn the underlying mechanism regardless of supervision\nsignal and architectural bias. Moreover, the generalization capabilities of all\ntested models drop significantly as we move from artificial datasets towards\nmore realistic real-world datasets. Despite their inability to identify the\ncorrect mechanism, the models are quite modular as their ability to infer other\nin-distribution factors remains fairly stable, providing only a single factor\nis out-of-distribution. These results point to an important yet understudied\nproblem of learning mechanistic models of observations that can facilitate\ngeneralization.",
          "link": "http://arxiv.org/abs/2107.08221",
          "publishedOn": "2021-07-20T02:04:41.399Z",
          "wordCount": 673,
          "title": "Visual Representation Learning Does Not Generalize Strongly Within the Same Domain. (arXiv:2107.08221v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08228",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_L/0/1/0/all/0/1\">Lisha Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chau_L/0/1/0/all/0/1\">Lap-Pui Chau</a>",
          "description": "Vehicle re-identification (Re-ID) is to retrieve images of the same vehicle\nacross different cameras. Two key challenges lie in the subtle inter-instance\ndiscrepancy caused by near-duplicate identities and the large intra-instance\nvariance caused by different views. Since the holistic appearance suffers from\nviewpoint variation and distortion, part-level feature learning has been\nintroduced to enhance vehicle description. However, existing approaches to\nlocalize and amplify significant parts often fail to handle spatial\nmisalignment as well as occlusion and require expensive annotations. In this\npaper, we propose a weakly supervised Part-Mentored Attention Network (PMANet)\ncomposed of a Part Attention Network (PANet) for vehicle part localization with\nself-attention and a Part-Mentored Network (PMNet) for mentoring the global and\nlocal feature aggregation. Firstly, PANet is introduced to predict a foreground\nmask and pinpoint $K$ prominent vehicle parts only with weak identity\nsupervision. Secondly, we propose a PMNet to learn global and part-level\nfeatures with multi-scale attention and aggregate them in $K$ main-partial\ntasks via part transfer. Like humans who first differentiate objects with\ngeneral information and then observe salient parts for more detailed clues,\nPANet and PMNet construct a two-stage attention structure to perform a\ncoarse-to-fine search among identities. Finally, we address this Re-ID issue as\na multi-task problem, including global feature learning, identity\nclassification, and part transfer. We adopt Homoscedastic Uncertainty to learn\nthe optimal weighing of different losses. Comprehensive experiments are\nconducted on two benchmark datasets. Our approach outperforms recent\nstate-of-the-art methods by averagely 2.63% in CMC@1 on VehicleID and 2.2% in\nmAP on VeRi776. Results on occluded test sets also demonstrate the\ngeneralization ability of PMANet.",
          "link": "http://arxiv.org/abs/2107.08228",
          "publishedOn": "2021-07-20T02:04:41.369Z",
          "wordCount": 733,
          "title": "Looking Twice for Partial Clues: Weakly-supervised Part-Mentored Attention Network for Vehicle Re-Identification. (arXiv:2107.08228v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08192",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yunqing Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1\">Xuan Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_H/0/1/0/all/0/1\">Haiwen Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jingfeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yuan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_H/0/1/0/all/0/1\">Hui Xue</a>",
          "description": "In fine-grained image recognition (FGIR), the localization and amplification\nof region attention is an important factor, which has been explored a lot by\nconvolutional neural networks (CNNs) based approaches. The recently developed\nvision transformer (ViT) has achieved promising results on computer vision\ntasks. Compared with CNNs, Image sequentialization is a brand new manner.\nHowever, ViT is limited in its receptive field size and thus lacks local\nattention like CNNs due to the fixed size of its patches, and is unable to\ngenerate multi-scale features to learn discriminative region attention. To\nfacilitate the learning of discriminative region attention without box/part\nannotations, we use the strength of the attention weights to measure the\nimportance of the patch tokens corresponding to the raw images. We propose the\nrecurrent attention multi-scale transformer (RAMS-Trans), which uses the\ntransformer's self-attention to recursively learn discriminative region\nattention in a multi-scale manner. Specifically, at the core of our approach\nlies the dynamic patch proposal module (DPPM) guided region amplification to\ncomplete the integration of multi-scale image patches. The DPPM starts with the\nfull-size image patches and iteratively scales up the region attention to\ngenerate new patches from global to local by the intensity of the attention\nweights generated at each scale as an indicator. Our approach requires only the\nattention weights that come with ViT itself and can be easily trained\nend-to-end. Extensive experiments demonstrate that RAMS-Trans performs better\nthan concurrent works, in addition to efficient CNN models, achieving\nstate-of-the-art results on three benchmark datasets.",
          "link": "http://arxiv.org/abs/2107.08192",
          "publishedOn": "2021-07-20T02:04:41.304Z",
          "wordCount": 689,
          "title": "RAMS-Trans: Recurrent Attention Multi-scale Transformer forFine-grained Image Recognition. (arXiv:2107.08192v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08187",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hengli Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_R/0/1/0/all/0/1\">Rui Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Ming Liu</a>",
          "description": "Convolutional neural network (CNN)-based stereo matching approaches generally\nrequire a dense cost volume (DCV) for disparity estimation. However, generating\nsuch cost volumes is computationally-intensive and memory-consuming, hindering\nCNN training and inference efficiency. To address this problem, we propose\nSCV-Stereo, a novel CNN architecture, capable of learning dense stereo matching\nfrom sparse cost volume (SCV) representations. Our inspiration is derived from\nthe fact that DCV representations are somewhat redundant and can be replaced\nwith SCV representations. Benefiting from these SCV representations, our\nSCV-Stereo can update disparity estimations in an iterative fashion for\naccurate and efficient stereo matching. Extensive experiments carried out on\nthe KITTI Stereo benchmarks demonstrate that our SCV-Stereo can significantly\nminimize the trade-off between accuracy and efficiency for stereo matching. Our\nproject page is https://sites.google.com/view/scv-stereo.",
          "link": "http://arxiv.org/abs/2107.08187",
          "publishedOn": "2021-07-20T02:04:41.252Z",
          "wordCount": 582,
          "title": "SCV-Stereo: Learning Stereo Matching from a Sparse Cost Volume. (arXiv:2107.08187v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08186",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hengli Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_R/0/1/0/all/0/1\">Rui Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Ming Liu</a>",
          "description": "Stereo matching is a key component of autonomous driving perception. Recent\nunsupervised stereo matching approaches have received adequate attention due to\ntheir advantage of not requiring disparity ground truth. These approaches,\nhowever, perform poorly near occlusions. To overcome this drawback, in this\npaper, we propose CoT-Stereo, a novel unsupervised stereo matching approach.\nSpecifically, we adopt a co-teaching framework where two networks interactively\nteach each other about the occlusions in an unsupervised fashion, which greatly\nimproves the robustness of unsupervised stereo matching. Extensive experiments\non the KITTI Stereo benchmarks demonstrate the superior performance of\nCoT-Stereo over all other state-of-the-art unsupervised stereo matching\napproaches in terms of both accuracy and speed. Our project webpage is\nhttps://sites.google.com/view/cot-stereo.",
          "link": "http://arxiv.org/abs/2107.08186",
          "publishedOn": "2021-07-20T02:04:41.214Z",
          "wordCount": 566,
          "title": "Co-Teaching: An Ark to Unsupervised Stereo Matching. (arXiv:2107.08186v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08120",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Liu_Y/0/1/0/all/0/1\">Yilin Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_Y/0/1/0/all/0/1\">Yong Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yap_P/0/1/0/all/0/1\">Pew-Thian Yap</a>",
          "description": "Magnetic resonance Fingerprinting (MRF) is a relatively new multi-parametric\nquantitative imaging method that involves a two-step process: (i)\nreconstructing a series of time frames from highly-undersampled non-Cartesian\nspiral k-space data and (ii) pattern matching using the time frames to infer\ntissue properties (e.g., T1 and T2 relaxation times). In this paper, we\nintroduce a novel end-to-end deep learning framework to seamlessly map the\ntissue properties directly from spiral k-space MRF data, thereby avoiding\ntime-consuming processing such as the nonuniform fast Fourier transform (NUFFT)\nand the dictionary-based Fingerprint matching. Our method directly consumes the\nnon-Cartesian k- space data, performs adaptive density compensation, and\npredicts multiple tissue property maps in one forward pass. Experiments on both\n2D and 3D MRF data demonstrate that quantification accuracy comparable to\nstate-of-the-art methods can be accomplished within 0.5 second, which is 1100\nto 7700 times faster than the original MRF framework. The proposed method is\nthus promising for facilitating the adoption of MRF in clinical settings.",
          "link": "http://arxiv.org/abs/2107.08120",
          "publishedOn": "2021-07-20T02:04:40.658Z",
          "wordCount": 610,
          "title": "Real-Time Mapping of Tissue Properties for Magnetic Resonance Fingerprinting. (arXiv:2107.08120v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2103.09022",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Chung_H/0/1/0/all/0/1\">Hyungjin Chung</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huh_J/0/1/0/all/0/1\">Jaeyoung Huh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kim_G/0/1/0/all/0/1\">Geon Kim</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Park_Y/0/1/0/all/0/1\">Yong Keun Park</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ye_J/0/1/0/all/0/1\">Jong Chul Ye</a>",
          "description": "Optical diffraction tomography (ODT) produces three dimensional distribution\nof refractive index (RI) by measuring scattering fields at various angles.\nAlthough the distribution of RI index is highly informative, due to the missing\ncone problem stemming from the limited-angle acquisition of holograms,\nreconstructions have very poor resolution along axial direction compared to the\nhorizontal imaging plane. To solve this issue, here we present a novel\nunsupervised deep learning framework, which learns the probability distribution\nof missing projection views through optimal transport driven cycleGAN.\nExperimental results show that missing cone artifact in ODT can be\nsignificantly resolved by the proposed method.",
          "link": "http://arxiv.org/abs/2103.09022",
          "publishedOn": "2021-07-20T02:04:40.602Z",
          "wordCount": 589,
          "title": "Missing Cone Artifacts Removal in ODT using Unsupervised Deep Learning in Projection Domain. (arXiv:2103.09022v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.13530",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cai_R/0/1/0/all/0/1\">Ruojin Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hariharan_B/0/1/0/all/0/1\">Bharath Hariharan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Snavely_N/0/1/0/all/0/1\">Noah Snavely</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Averbuch_Elor_H/0/1/0/all/0/1\">Hadar Averbuch-Elor</a>",
          "description": "We present a technique for estimating the relative 3D rotation of an RGB\nimage pair in an extreme setting, where the images have little or no overlap.\nWe observe that, even when images do not overlap, there may be rich hidden cues\nas to their geometric relationship, such as light source directions, vanishing\npoints, and symmetries present in the scene. We propose a network design that\ncan automatically learn such implicit cues by comparing all pairs of points\nbetween the two input images. Our method therefore constructs dense feature\ncorrelation volumes and processes these to predict relative 3D rotations. Our\npredictions are formed over a fine-grained discretization of rotations,\nbypassing difficulties associated with regressing 3D rotations. We demonstrate\nour approach on a large variety of extreme RGB image pairs, including indoor\nand outdoor images captured under different lighting conditions and geographic\nlocations. Our evaluation shows that our model can successfully estimate\nrelative rotations among non-overlapping images without compromising\nperformance over overlapping image pairs.",
          "link": "http://arxiv.org/abs/2104.13530",
          "publishedOn": "2021-07-20T02:04:40.583Z",
          "wordCount": 635,
          "title": "Extreme Rotation Estimation using Dense Correlation Volumes. (arXiv:2104.13530v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.06979",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kato_M/0/1/0/all/0/1\">Masahiro Kato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teshima_T/0/1/0/all/0/1\">Takeshi Teshima</a>",
          "description": "Density ratio estimation (DRE) is at the core of various machine learning\ntasks such as anomaly detection and domain adaptation. In existing studies on\nDRE, methods based on Bregman divergence (BD) minimization have been\nextensively studied. However, BD minimization when applied with highly flexible\nmodels, such as deep neural networks, tends to suffer from what we call\ntrain-loss hacking, which is a source of overfitting caused by a typical\ncharacteristic of empirical BD estimators. In this paper, to mitigate\ntrain-loss hacking, we propose a non-negative correction for empirical BD\nestimators. Theoretically, we confirm the soundness of the proposed method\nthrough a generalization error bound. Through our experiments, the proposed\nmethods show a favorable performance in inlier-based outlier detection.",
          "link": "http://arxiv.org/abs/2006.06979",
          "publishedOn": "2021-07-20T02:04:40.526Z",
          "wordCount": 596,
          "title": "Non-Negative Bregman Divergence Minimization for Deep Direct Density Ratio Estimation. (arXiv:2006.06979v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2004.14595",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Marzahl_C/0/1/0/all/0/1\">Christian Marzahl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aubreville_M/0/1/0/all/0/1\">Marc Aubreville</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bertram_C/0/1/0/all/0/1\">Christof A. Bertram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maier_J/0/1/0/all/0/1\">Jennifer Maier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bergler_C/0/1/0/all/0/1\">Christian Bergler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kroger_C/0/1/0/all/0/1\">Christine Kr&#xf6;ger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Voigt_J/0/1/0/all/0/1\">J&#xf6;rn Voigt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Breininger_K/0/1/0/all/0/1\">Katharina Breininger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klopfleisch_R/0/1/0/all/0/1\">Robert Klopfleisch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maier_A/0/1/0/all/0/1\">Andreas Maier</a>",
          "description": "In many research areas, scientific progress is accelerated by\nmultidisciplinary access to image data and their interdisciplinary annotation.\nHowever, keeping track of these annotations to ensure a high-quality\nmulti-purpose data set is a challenging and labour intensive task. We developed\nthe open-source online platform EXACT (EXpert Algorithm Collaboration Tool)\nthat enables the collaborative interdisciplinary analysis of images from\ndifferent domains online and offline. EXACT supports multi-gigapixel medical\nwhole slide images as well as image series with thousands of images. The\nsoftware utilises a flexible plugin system that can be adapted to diverse\napplications such as counting mitotic figures with a screening mode, finding\nfalse annotations on a novel validation view, or using the latest deep learning\nimage analysis technologies. This is combined with a version control system\nwhich makes it possible to keep track of changes in the data sets and, for\nexample, to link the results of deep learning experiments to specific data set\nversions. EXACT is freely available and has already been successfully applied\nto a broad range of annotation tasks, including highly diverse applications\nlike deep learning supported cytology scoring, interdisciplinary multi-centre\nwhole slide image tumour annotation, and highly specialised whale sound\nspectroscopy clustering.",
          "link": "http://arxiv.org/abs/2004.14595",
          "publishedOn": "2021-07-20T02:04:40.502Z",
          "wordCount": 712,
          "title": "EXACT: A collaboration toolset for algorithm-aided annotation of images with annotation version control. (arXiv:2004.14595v3 [cs.HC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08394",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lejeune_L/0/1/0/all/0/1\">Laurent Lejeune</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sznitman_R/0/1/0/all/0/1\">Raphael Sznitman</a>",
          "description": "The ability to quickly annotate medical imaging data plays a critical role in\ntraining deep learning frameworks for segmentation. Doing so for image volumes\nor video sequences is even more pressing as annotating these is particularly\nburdensome. To alleviate this problem, this work proposes a new method to\nefficiently segment medical imaging volumes or videos using point-wise\nannotations only. This allows annotations to be collected extremely quickly and\nremains applicable to numerous segmentation tasks. Our approach trains a deep\nlearning model using an appropriate Positive/Unlabeled objective function using\nsparse point-wise annotations. While most methods of this kind assume that the\nproportion of positive samples in the data is known a-priori, we introduce a\nnovel self-supervised method to estimate this prior efficiently by combining a\nBayesian estimation framework and new stopping criteria. Our method iteratively\nestimates appropriate class priors and yields high segmentation quality for a\nvariety of object types and imaging modalities. In addition, by leveraging a\nspatio-temporal tracking framework, we regularize our predictions by leveraging\nthe complete data volume. We show experimentally that our approach outperforms\nstate-of-the-art methods tailored to the same problem.",
          "link": "http://arxiv.org/abs/2107.08394",
          "publishedOn": "2021-07-20T02:04:40.480Z",
          "wordCount": 623,
          "title": "A Positive/Unlabeled Approach for the Segmentation of Medical Sequences using Point-Wise Supervision. (arXiv:2107.08394v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.10507",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1\">Ke Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yufei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yingfeng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1\">Changjie Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Zhipeng Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1\">Wei Yang</a>",
          "description": "Graphically-rich applications such as games are ubiquitous with attractive\nvisual effects of Graphical User Interface (GUI) that offers a bridge between\nsoftware applications and end-users. However, various types of graphical\nglitches may arise from such GUI complexity and have become one of the main\ncomponent of software compatibility issues. Our study on bug reports from game\ndevelopment teams in NetEase Inc. indicates that graphical glitches frequently\noccur during the GUI rendering and severely degrade the quality of\ngraphically-rich applications such as video games. Existing automated testing\ntechniques for such applications focus mainly on generating various GUI test\nsequences and check whether the test sequences can cause crashes. These\ntechniques require constant human attention to captures non-crashing bugs such\nas bugs causing graphical glitches. In this paper, we present the first step in\nautomating the test oracle for detecting non-crashing bugs in graphically-rich\napplications. Specifically, we propose \\texttt{GLIB} based on a code-based data\naugmentation technique to detect game GUI glitches. We perform an evaluation of\n\\texttt{GLIB} on 20 real-world game apps (with bug reports available) and the\nresult shows that \\texttt{GLIB} can achieve 100\\% precision and 99.5\\% recall\nin detecting non-crashing bugs such as game GUI glitches. Practical application\nof \\texttt{GLIB} on another 14 real-world games (without bug reports) further\ndemonstrates that \\texttt{GLIB} can effectively uncover GUI glitches, with 48\nof 53 bugs reported by \\texttt{GLIB} having been confirmed and fixed so far.",
          "link": "http://arxiv.org/abs/2106.10507",
          "publishedOn": "2021-07-19T01:59:51.012Z",
          "wordCount": 727,
          "title": "GLIB: Towards Automated Test Oracle for Graphically-Rich Applications. (arXiv:2106.10507v3 [cs.SE] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.04388",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cooper_J/0/1/0/all/0/1\">Jessica Cooper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Um_I/0/1/0/all/0/1\">In Hwa Um</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arandjelovic_O/0/1/0/all/0/1\">Ognjen Arandjelovi&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harrison_D/0/1/0/all/0/1\">David J Harrison</a>",
          "description": "Multiplex immunofluorescence and immunohistochemistry benefit patients by\nallowing cancer pathologists to identify several proteins expressed on the\nsurface of cells, enabling cell classification, better understanding of the\ntumour micro-environment, more accurate diagnoses, prognoses, and tailored\nimmunotherapy based on the immune status of individual patients. However, they\nare expensive and time consuming processes which require complex staining and\nimaging techniques by expert technicians. Hoechst staining is much cheaper and\neasier to perform, but is not typically used in this case as it binds to DNA\nrather than to the proteins targeted by immunofluorescent techniques, and it\nwas not previously thought possible to differentiate cells expressing these\nproteins based only on DNA morphology. In this work we show otherwise, training\na deep convolutional neural network to identify cells expressing three proteins\n(T lymphocyte markers CD3 and CD8, and the B lymphocyte marker CD20) with\ngreater than 90% precision and recall, from Hoechst 33342 stained tissue only.\nOur model learns previously unknown morphological features associated with\nexpression of these proteins which can be used to accurately differentiate\nlymphocyte subtypes for use in key prognostic metrics such as assessment of\nimmune cell infiltration,and thereby predict and improve patient outcomes\nwithout the need for costly multiplex immunofluorescence.",
          "link": "http://arxiv.org/abs/2107.04388",
          "publishedOn": "2021-07-19T01:59:50.979Z",
          "wordCount": 673,
          "title": "Hoechst Is All You Need: Lymphocyte Classification with Deep Learning. (arXiv:2107.04388v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.07797",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1\">Wenbo Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Changgong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_F/0/1/0/all/0/1\">Fangneng Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_T/0/1/0/all/0/1\">Tien-Tsin Wong</a>",
          "description": "Graph convolutional networks have significantly improved 3D human pose\nestimation by representing the human skeleton as an undirected graph. However,\nthis representation fails to reflect the articulated characteristic of human\nskeletons as the hierarchical orders among the joints are not explicitly\npresented. In this paper, we propose to represent the human skeleton as a\ndirected graph with the joints as nodes and bones as edges that are directed\nfrom parent joints to child joints. By so doing, the directions of edges can\nexplicitly reflect the hierarchical relationships among the nodes. Based on\nthis representation, we adopt the spatial-temporal directed graph convolution\n(ST-DGConv) to extract features from 2D poses represented in a temporal\nsequence of directed graphs. We further propose a spatial-temporal conditional\ndirected graph convolution (ST-CondDGConv) to leverage varying non-local\ndependence for different poses by conditioning the graph topology on input\nposes. Altogether, we form a U-shaped network with ST-DGConv and ST-CondDGConv\nlayers, named U-shaped Conditional Directed Graph Convolutional Network\n(U-CondDGCN), for 3D human pose estimation from monocular videos. To evaluate\nthe effectiveness of our U-CondDGCN, we conducted extensive experiments on two\nchallenging large-scale benchmarks: Human3.6M and MPI-INF-3DHP. Both\nquantitative and qualitative results show that our method achieves top\nperformance. Also, ablation studies show that directed graphs can better\nexploit the hierarchy of articulated human skeletons than undirected graphs,\nand the conditional connections can yield adaptive graph topologies for\ndifferent kinds of poses.",
          "link": "http://arxiv.org/abs/2107.07797",
          "publishedOn": "2021-07-19T00:49:08.141Z",
          "wordCount": 683,
          "title": "Conditional Directed Graph Convolution for 3D Human Pose Estimation. (arXiv:2107.07797v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07933",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Garnot_V/0/1/0/all/0/1\">Vivien Sainte Fare Garnot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Landrieu_L/0/1/0/all/0/1\">Loic Landrieu</a>",
          "description": "Unprecedented access to multi-temporal satellite imagery has opened new\nperspectives for a variety of Earth observation tasks. Among them,\npixel-precise panoptic segmentation of agricultural parcels has major economic\nand environmental implications. While researchers have explored this problem\nfor single images, we argue that the complex temporal patterns of crop\nphenology are better addressed with temporal sequences of images. In this\npaper, we present the first end-to-end, single-stage method for panoptic\nsegmentation of Satellite Image Time Series (SITS). This module can be combined\nwith our novel image sequence encoding network which relies on temporal\nself-attention to extract rich and adaptive multi-scale spatio-temporal\nfeatures. We also introduce PASTIS, the first open-access SITS dataset with\npanoptic annotations. We demonstrate the superiority of our encoder for\nsemantic segmentation against multiple competing architectures, and set up the\nfirst state-of-the-art of panoptic segmentation of SITS. Our implementation and\nPASTIS are publicly available.",
          "link": "http://arxiv.org/abs/2107.07933",
          "publishedOn": "2021-07-19T00:49:08.120Z",
          "wordCount": 605,
          "title": "Panoptic Segmentation of Satellite Image Time Series with Convolutional Temporal Attention Networks. (arXiv:2107.07933v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07859",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jeon_H/0/1/0/all/0/1\">Hyeon Jeon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ko_H/0/1/0/all/0/1\">Hyung-Kwon Ko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jo_J/0/1/0/all/0/1\">Jaemin Jo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Youngtaek Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seo_J/0/1/0/all/0/1\">Jinwook Seo</a>",
          "description": "We propose Steadiness and Cohesiveness, two novel metrics to measure the\ninter-cluster reliability of multidimensional projection (MDP), specifically\nhow well the inter-cluster structures are preserved between the original\nhigh-dimensional space and the low-dimensional projection space. Measuring\ninter-cluster reliability is crucial as it directly affects how well\ninter-cluster tasks (e.g., identifying cluster relationships in the original\nspace from a projected view) can be conducted; however, despite the importance\nof inter-cluster tasks, we found that previous metrics, such as Trustworthiness\nand Continuity, fail to measure inter-cluster reliability. Our metrics consider\ntwo aspects of the inter-cluster reliability: Steadiness measures the extent to\nwhich clusters in the projected space form clusters in the original space, and\nCohesiveness measures the opposite. They extract random clusters with arbitrary\nshapes and positions in one space and evaluate how much the clusters are\nstretched or dispersed in the other space. Furthermore, our metrics can\nquantify pointwise distortions, allowing for the visualization of inter-cluster\nreliability in a projection, which we call a reliability map. Through\nquantitative experiments, we verify that our metrics precisely capture the\ndistortions that harm inter-cluster reliability while previous metrics have\ndifficulty capturing the distortions. A case study also demonstrates that our\nmetrics and the reliability map 1) support users in selecting the proper\nprojection techniques or hyperparameters and 2) prevent misinterpretation while\nperforming inter-cluster tasks, thus allow an adequate identification of\ninter-cluster structure.",
          "link": "http://arxiv.org/abs/2107.07859",
          "publishedOn": "2021-07-19T00:49:08.097Z",
          "wordCount": 686,
          "title": "Measuring and Explaining the Inter-Cluster Reliability of Multidimensional Projections. (arXiv:2107.07859v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07943",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shimizu_Y/0/1/0/all/0/1\">Yugo Shimizu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Furuta_R/0/1/0/all/0/1\">Ryosuke Furuta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_D/0/1/0/all/0/1\">Delong Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taniguchi_Y/0/1/0/all/0/1\">Yukinobu Taniguchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hinami_R/0/1/0/all/0/1\">Ryota Hinami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ishiwatari_S/0/1/0/all/0/1\">Shonosuke Ishiwatari</a>",
          "description": "Japanese comics (called manga) are traditionally created in monochrome\nformat. In recent years, in addition to monochrome comics, full color comics, a\nmore attractive medium, have appeared. Unfortunately, color comics require\nmanual colorization, which incurs high labor costs. Although automatic\ncolorization methods have been recently proposed, most of them are designed for\nillustrations, not for comics. Unlike illustrations, since comics are composed\nof many consecutive images, the painting style must be consistent. To realize\nconsistent colorization, we propose here a semi-automatic colorization method\nbased on generative adversarial networks (GAN); the method learns the painting\nstyle of a specific comic from small amount of training data. The proposed\nmethod takes a pair of a screen tone image and a flat colored image as input,\nand outputs a colorized image. Experiments show that the proposed method\nachieves better performance than the existing alternatives.",
          "link": "http://arxiv.org/abs/2107.07943",
          "publishedOn": "2021-07-19T00:49:08.092Z",
          "wordCount": 595,
          "title": "Painting Style-Aware Manga Colorization Based on Generative Adversarial Networks. (arXiv:2107.07943v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07539",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zuo_X/0/1/0/all/0/1\">Xinxin Zuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Sen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_M/0/1/0/all/0/1\">Minglun Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_L/0/1/0/all/0/1\">Li Cheng</a>",
          "description": "This paper presents a novel unsupervised approach to reconstruct human shape\nand pose from noisy point cloud. Traditional approaches search for\ncorrespondences and conduct model fitting iteratively where a good\ninitialization is critical. Relying on large amount of dataset with\nground-truth annotations, recent learning-based approaches predict\ncorrespondences for every vertice on the point cloud; Chamfer distance is\nusually used to minimize the distance between a deformed template model and the\ninput point cloud. However, Chamfer distance is quite sensitive to noise and\noutliers, thus could be unreliable to assign correspondences. To address these\nissues, we model the probability distribution of the input point cloud as\ngenerated from a parametric human model under a Gaussian Mixture Model. Instead\nof explicitly aligning correspondences, we treat the process of correspondence\nsearch as an implicit probabilistic association by updating the posterior\nprobability of the template model given the input. A novel unsupervised loss is\nfurther derived that penalizes the discrepancy between the deformed template\nand the input point cloud conditioned on the posterior probability. Our\napproach is very flexible, which works with both complete point cloud and\nincomplete ones including even a single depth image as input. Our network is\ntrained from scratch with no need to warm-up the network with supervised data.\nCompared to previous unsupervised methods, our method shows the capability to\ndeal with substantial noise and outliers. Extensive experiments conducted on\nvarious public synthetic datasets as well as a very noisy real dataset (i.e.\nCMU Panoptic) demonstrate the superior performance of our approach over the\nstate-of-the-art methods. Code can be found\n\\url{https://github.com/wangsen1312/unsupervised3dhuman.git}",
          "link": "http://arxiv.org/abs/2107.07539",
          "publishedOn": "2021-07-19T00:49:07.772Z",
          "wordCount": 701,
          "title": "Unsupervised 3D Human Mesh Recovery from Noisy Point Clouds. (arXiv:2107.07539v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07651",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junnan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Selvaraju_R/0/1/0/all/0/1\">Ramprasaath R. Selvaraju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gotmare_A/0/1/0/all/0/1\">Akhilesh Deepak Gotmare</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joty_S/0/1/0/all/0/1\">Shafiq Joty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1\">Caiming Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoi_S/0/1/0/all/0/1\">Steven Hoi</a>",
          "description": "Large-scale vision and language representation learning has shown promising\nimprovements on various vision-language tasks. Most existing methods employ a\ntransformer-based multimodal encoder to jointly model visual tokens\n(region-based image features) and word tokens. Because the visual tokens and\nword tokens are unaligned, it is challenging for the multimodal encoder to\nlearn image-text interactions. In this paper, we introduce a contrastive loss\nto ALign the image and text representations BEfore Fusing (ALBEF) them through\ncross-modal attention, which enables more grounded vision and language\nrepresentation learning. Unlike most existing methods, our method does not\nrequire bounding box annotations nor high-resolution images. In order to\nimprove learning from noisy web data, we propose momentum distillation, a\nself-training method which learns from pseudo-targets produced by a momentum\nmodel. We provide a theoretical analysis of ALBEF from a mutual information\nmaximization perspective, showing that different training tasks can be\ninterpreted as different ways to generate views for an image-text pair. ALBEF\nachieves state-of-the-art performance on multiple downstream vision-language\ntasks. On image-text retrieval, ALBEF outperforms methods that are pre-trained\non orders of magnitude larger datasets. On VQA and NLVR$^2$, ALBEF achieves\nabsolute improvements of 2.37% and 3.84% compared to the state-of-the-art,\nwhile enjoying faster inference speed. Code and pre-trained models are\navailable at https://github.com/salesforce/ALBEF/.",
          "link": "http://arxiv.org/abs/2107.07651",
          "publishedOn": "2021-07-19T00:49:07.747Z",
          "wordCount": 662,
          "title": "Align before Fuse: Vision and Language Representation Learning with Momentum Distillation. (arXiv:2107.07651v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07699",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1\">Peng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahaman_M/0/1/0/all/0/1\">Md Mamunur Rahaman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hechen Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_T/0/1/0/all/0/1\">Tao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grzegorzek_M/0/1/0/all/0/1\">Marcin Grzegorzek</a>",
          "description": "In recent years, deep learning has made brilliant achievements in image\nclassification. However, image classification of small datasets is still not\nobtained good research results. This article first briefly explains the\napplication and characteristics of convolutional neural networks and visual\ntransformers. Meanwhile, the influence of small data set on classification and\nthe solution are introduced. Then a series of experiments are carried out on\nthe small datasets by using various models, and the problems of some models in\nthe experiments are discussed. Through the comparison of experimental results,\nthe recommended deep learning model is given according to the model application\nenvironment. Finally, we give directions for future work.",
          "link": "http://arxiv.org/abs/2107.07699",
          "publishedOn": "2021-07-19T00:49:07.742Z",
          "wordCount": 571,
          "title": "A Comparison of Deep Learning Classification Methods on Small-scale Image Data set: from Converlutional Neural Networks to Visual Transformers. (arXiv:2107.07699v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2104.10785",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Godaz_R/0/1/0/all/0/1\">Reza Godaz</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Monsefi_R/0/1/0/all/0/1\">Reza Monsefi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Toutounian_F/0/1/0/all/0/1\">Faezeh Toutounian</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hosseini_R/0/1/0/all/0/1\">Reshad Hosseini</a>",
          "description": "In this paper we tackle two important challenges related to the accurate\npartial singular value decomposition (SVD) and numerical rank estimation of a\nhuge matrix to use in low-rank learning problems in a fast way. We use the\nconcepts of Krylov subspaces such as the Golub-Kahan bidiagonalization process\nas well as Ritz vectors to achieve these goals. Our experiments identify\nvarious advantages of the proposed methods compared to traditional and\nrandomized SVD (R-SVD) methods with respect to the accuracy of the singular\nvalues and corresponding singular vectors computed in a similar execution time.\nThe proposed methods are appropriate for applications involving huge matrices\nwhere accuracy in all spectrum of the desired singular values, and also all of\ncorresponding singular vectors is essential. We evaluate our method in the real\napplication of Riemannian similarity learning (RSL) between two various image\ndatasets of MNIST and USPS.",
          "link": "http://arxiv.org/abs/2104.10785",
          "publishedOn": "2021-07-19T00:49:07.530Z",
          "wordCount": 611,
          "title": "Accurate and fast matrix factorization for low-rank learning. (arXiv:2104.10785v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.13044",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_G/0/1/0/all/0/1\">Guangwei Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_G/0/1/0/all/0/1\">Guoan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yi Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1\">Jin Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jian Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yue_D/0/1/0/all/0/1\">Dong Yue</a>",
          "description": "In recent years, how to strike a good trade-off between accuracy and\ninference speed has become the core issue for real-time semantic segmentation\napplications, which plays a vital role in real-world scenarios such as\nautonomous driving systems and drones. In this study, we devise a novel\nlightweight network using a multi-scale context fusion (MSCFNet) scheme, which\nexplores an asymmetric encoder-decoder architecture to dispose this problem.\nMore specifically, the encoder adopts some developed efficient asymmetric\nresidual (EAR) modules, which are composed of factorization depth-wise\nconvolution and dilation convolution. Meanwhile, instead of complicated\ncomputation, simple deconvolution is applied in the decoder to further reduce\nthe amount of parameters while still maintaining high segmentation accuracy.\nAlso, MSCFNet has branches with efficient attention modules from different\nstages of the network to well capture multi-scale contextual information. Then\nwe combine them before the final classification to enhance the expression of\nthe features and improve the segmentation efficiency. Comprehensive experiments\non challenging datasets have demonstrated that the proposed MSCFNet, which\ncontains only 1.15M parameters, achieves 71.9\\% Mean IoU on the Cityscapes\ntesting dataset and can run at over 50 FPS on a single Titan XP GPU\nconfiguration.",
          "link": "http://arxiv.org/abs/2103.13044",
          "publishedOn": "2021-07-19T00:49:07.523Z",
          "wordCount": 679,
          "title": "MSCFNet: A Lightweight Network With Multi-Scale Context Fusion for Real-Time Semantic Segmentation. (arXiv:2103.13044v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.16056",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roy_W/0/1/0/all/0/1\">William Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kelly_G/0/1/0/all/0/1\">Glen Kelly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leer_R/0/1/0/all/0/1\">Robert Leer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ricardo_F/0/1/0/all/0/1\">Frederick Ricardo</a>",
          "description": "Generative Adversarial Networks (GANs) have been extremely successful in\nvarious application domains. Adversarial image synthesis has drawn increasing\nattention and made tremendous progress in recent years because of its wide\nrange of applications in many computer vision and image processing problems.\nAmong the many applications of GAN, image synthesis is the most well-studied\none, and research in this area has already demonstrated the great potential of\nusing GAN in image synthesis. In this paper, we provide a taxonomy of methods\nused in image synthesis, review different models for text-to-image synthesis\nand image-to-image translation, and discuss some evaluation metrics as well as\npossible future research directions in image synthesis with GAN.",
          "link": "http://arxiv.org/abs/2106.16056",
          "publishedOn": "2021-07-19T00:49:07.510Z",
          "wordCount": 581,
          "title": "A Survey on Adversarial Image Synthesis. (arXiv:2106.16056v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.05445",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yipeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hayes_T/0/1/0/all/0/1\">Tyler L. Hayes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanan_C/0/1/0/all/0/1\">Christopher Kanan</a>",
          "description": "Humans are incredibly good at transferring knowledge from one domain to\nanother, enabling rapid learning of new tasks. Likewise, transfer learning has\nenabled enormous success in many computer vision problems using pretraining.\nHowever, the benefits of transfer in multi-domain learning, where a network\nlearns multiple tasks defined by different datasets, has not been adequately\nstudied. Learning multiple domains could be beneficial or these domains could\ninterfere with each other given limited network capacity. In this work, we\ndecipher the conditions where interference and knowledge transfer occur in\nmulti-domain learning. We propose new metrics disentangling interference and\ntransfer and set up experimental protocols. We further examine the roles of\nnetwork capacity, task grouping, and dynamic loss weighting in reducing\ninterference and facilitating transfer. We demonstrate our findings on the\nCIFAR-100, MiniPlaces, and Tiny-ImageNet datasets.",
          "link": "http://arxiv.org/abs/2107.05445",
          "publishedOn": "2021-07-19T00:49:07.433Z",
          "wordCount": 591,
          "title": "Disentangling Transfer and Interference in Multi-Domain Learning. (arXiv:2107.05445v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.08194",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Davis_B/0/1/0/all/0/1\">Brian Davis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morse%7F_B/0/1/0/all/0/1\">Bryan Morse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Price%7F_B/0/1/0/all/0/1\">Brian Price</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tensmeyer%7F_C/0/1/0/all/0/1\">Chris Tensmeyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wiginton_C/0/1/0/all/0/1\">Curtis Wiginton</a>",
          "description": "We address the problem of form understanding: finding text entities and the\nrelationships/links between them in form images. The proposed FUDGE model\nformulates this problem on a graph of text elements (the vertices) and uses a\nGraph Convolutional Network to predict changes to the graph. The initial\nvertices are detected text lines and do not necessarily correspond to the final\ntext entities, which can span multiple lines. Also, initial edges contain many\nfalse-positive relationships. FUDGE edits the graph structure by combining text\nsegments (graph vertices) and pruning edges in an iterative fashion to obtain\nthe final text entities and relationships. While recent work in this area has\nfocused on leveraging large-scale pre-trained Language Models (LM), FUDGE\nachieves almost the same level of entity linking performance on the FUNSD\ndataset by learning only visual features from the (small) provided training\nset. FUDGE can be applied on forms where text recognition is difficult (e.g.\ndegraded or historical forms) and on forms in resource-poor languages where\npre-training such LMs is challenging. FUDGE is state-of-the-art on the\nhistorical NAF dataset.",
          "link": "http://arxiv.org/abs/2105.08194",
          "publishedOn": "2021-07-19T00:49:06.730Z",
          "wordCount": 652,
          "title": "Visual FUDGE: Form Understanding via Dynamic Graph Editing. (arXiv:2105.08194v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10313",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Broome_S/0/1/0/all/0/1\">Sofia Broom&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ask_K/0/1/0/all/0/1\">Katrina Ask</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rashid_M/0/1/0/all/0/1\">Maheen Rashid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andersen_P/0/1/0/all/0/1\">Pia Haubro Andersen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kjellstrom_H/0/1/0/all/0/1\">Hedvig Kjellstr&#xf6;m</a>",
          "description": "Orthopedic disorders are a common cause for euthanasia among horses, which\noften could have been avoided with earlier detection. These conditions often\ncreate varying degrees of subtle but long-term pain. It is challenging to train\na visual pain recognition method with video data depicting such pain, since the\nresulting pain behavior also is subtle, sparsely appearing, and varying, making\nit challenging for even an expert human labeler to provide accurate\nground-truth for the data. We show that transferring features from a dataset of\nhorses with acute nociceptive pain (where labeling is less ambiguous) can aid\nthe learning to recognize more complex orthopedic pain. Moreover, we present a\nhuman expert baseline for the problem, as well as an extensive empirical study\nof various domain transfer methods and of what is detected by the pain\nrecognition method trained on acute pain in the orthopedic dataset. Finally,\nthis is accompanied with a discussion around the challenges posed by real-world\nanimal behavior datasets and how best practices can be established for similar\nfine-grained action recognition tasks. Our code is available at\nhttps://github.com/sofiabroome/painface-recognition.",
          "link": "http://arxiv.org/abs/2105.10313",
          "publishedOn": "2021-07-19T00:49:06.704Z",
          "wordCount": 665,
          "title": "Sharing Pain: Using Domain Transfer Between Pain Types for Recognition of Sparse Pain Expressions in Horses. (arXiv:2105.10313v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.07002",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dehghani_M/0/1/0/all/0/1\">Mostafa Dehghani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tay_Y/0/1/0/all/0/1\">Yi Tay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gritsenko_A/0/1/0/all/0/1\">Alexey A. Gritsenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1\">Zhe Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Houlsby_N/0/1/0/all/0/1\">Neil Houlsby</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diaz_F/0/1/0/all/0/1\">Fernando Diaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Metzler_D/0/1/0/all/0/1\">Donald Metzler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vinyals_O/0/1/0/all/0/1\">Oriol Vinyals</a>",
          "description": "The world of empirical machine learning (ML) strongly relies on benchmarks in\norder to determine the relative effectiveness of different algorithms and\nmethods. This paper proposes the notion of \"a benchmark lottery\" that describes\nthe overall fragility of the ML benchmarking process. The benchmark lottery\npostulates that many factors, other than fundamental algorithmic superiority,\nmay lead to a method being perceived as superior. On multiple benchmark setups\nthat are prevalent in the ML community, we show that the relative performance\nof algorithms may be altered significantly simply by choosing different\nbenchmark tasks, highlighting the fragility of the current paradigms and\npotential fallacious interpretation derived from benchmarking ML methods. Given\nthat every benchmark makes a statement about what it perceives to be important,\nwe argue that this might lead to biased progress in the community. We discuss\nthe implications of the observed phenomena and provide recommendations on\nmitigating them using multiple machine learning domains and communities as use\ncases, including natural language processing, computer vision, information\nretrieval, recommender systems, and reinforcement learning.",
          "link": "http://arxiv.org/abs/2107.07002",
          "publishedOn": "2021-07-19T00:49:06.626Z",
          "wordCount": 620,
          "title": "The Benchmark Lottery. (arXiv:2107.07002v1 [cs.LG] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03686",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Thanthrige_U/0/1/0/all/0/1\">Udaya S.K.P. Miriya Thanthrige</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jung_P/0/1/0/all/0/1\">Peter Jung</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sezgin_A/0/1/0/all/0/1\">Aydin Sezgin</a>",
          "description": "We address the detection of material defects, which are inside a layered\nmaterial structure using compressive sensing based multiple-input and\nmultiple-output (MIMO) wireless radar. Here, the strong clutter due to the\nreflection of the layered structure's surface often makes the detection of the\ndefects challenging. Thus, sophisticated signal separation methods are required\nfor improved defect detection. In many scenarios, the number of defects that we\nare interested in is limited and the signaling response of the layered\nstructure can be modeled as a low-rank structure. Therefore, we propose joint\nrank and sparsity minimization for defect detection. In particular, we propose\na non-convex approach based on the iteratively reweighted nuclear and\n$\\ell_1-$norm (a double-reweighted approach) to obtain a higher accuracy\ncompared to the conventional nuclear norm and $\\ell_1-$norm minimization. To\nthis end, an iterative algorithm is designed to estimate the low-rank and\nsparse contributions. Further, we propose deep learning to learn the parameters\nof the algorithm (i.e., algorithm unfolding) to improve the accuracy and the\nspeed of convergence of the algorithm. Our numerical results show that the\nproposed approach outperforms the conventional approaches in terms of mean\nsquare errors of the recovered low-rank and sparse components and the speed of\nconvergence.",
          "link": "http://arxiv.org/abs/2106.03686",
          "publishedOn": "2021-07-19T00:49:06.597Z",
          "wordCount": 681,
          "title": "Deep Unfolding of Iteratively Reweighted ADMM for Wireless RF Sensing. (arXiv:2106.03686v2 [eess.SP] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.00597",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Minghao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1\">Houwen Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1\">Jianlong Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_H/0/1/0/all/0/1\">Haibin Ling</a>",
          "description": "Despite remarkable progress achieved, most neural architecture search (NAS)\nmethods focus on searching for one single accurate and robust architecture. To\nfurther build models with better generalization capability and performance,\nmodel ensemble is usually adopted and performs better than stand-alone models.\nInspired by the merits of model ensemble, we propose to search for multiple\ndiverse models simultaneously as an alternative way to find powerful models.\nSearching for ensembles is non-trivial and has two key challenges: enlarged\nsearch space and potentially more complexity for the searched model. In this\npaper, we propose a one-shot neural ensemble architecture search (NEAS)\nsolution that addresses the two challenges. For the first challenge, we\nintroduce a novel diversity-based metric to guide search space shrinking,\nconsidering both the potentiality and diversity of candidate operators. For the\nsecond challenge, we enable a new search dimension to learn layer sharing among\ndifferent models for efficiency purposes. The experiments on ImageNet clearly\ndemonstrate that our solution can improve the supernet's capacity of ranking\nensemble architectures, and further lead to better search results. The\ndiscovered architectures achieve superior performance compared with\nstate-of-the-arts such as MobileNetV3 and EfficientNet families under aligned\nsettings. Moreover, we evaluate the generalization ability and robustness of\nour searched architecture on the COCO detection benchmark and achieve a 3.1%\nimprovement on AP compared with MobileNetV3. Codes and models are available at\nhttps://github.com/researchmm/NEAS.",
          "link": "http://arxiv.org/abs/2104.00597",
          "publishedOn": "2021-07-19T00:49:06.565Z",
          "wordCount": 700,
          "title": "One-Shot Neural Ensemble Architecture Search by Diversity-Guided Search Space Shrinking. (arXiv:2104.00597v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.07684",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ishii_Y/0/1/0/all/0/1\">Yasunori Ishii</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamashita_T/0/1/0/all/0/1\">Takayoshi Yamashita</a>",
          "description": "It is difficult to collect data on a large scale in a monocular depth\nestimation because the task requires the simultaneous acquisition of RGB images\nand depths. Data augmentation is thus important to this task. However, there\nhas been little research on data augmentation for tasks such as monocular depth\nestimation, where the transformation is performed pixel by pixel. In this\npaper, we propose a data augmentation method, called CutDepth. In CutDepth,\npart of the depth is pasted onto an input image during training. The method\nextends variations data without destroying edge features. Experiments\nobjectively and subjectively show that the proposed method outperforms\nconventional methods of data augmentation. The estimation accuracy is improved\nwith CutDepth even though there are few training data at long distances.",
          "link": "http://arxiv.org/abs/2107.07684",
          "publishedOn": "2021-07-19T00:49:06.547Z",
          "wordCount": 561,
          "title": "CutDepth:Edge-aware Data Augmentation in Depth Estimation. (arXiv:2107.07684v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2011.10670",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1\">Junwei Liang</a>",
          "description": "With the advancement in computer vision deep learning, systems now are able\nto analyze an unprecedented amount of rich visual information from videos to\nenable applications such as autonomous driving, socially-aware robot assistant\nand public safety monitoring. Deciphering human behaviors to predict their\nfuture paths/trajectories and what they would do from videos is important in\nthese applications. However, human trajectory prediction still remains a\nchallenging task, as scene semantics and human intent are difficult to model.\nMany systems do not provide high-level semantic attributes to reason about\npedestrian future. This design hinders prediction performance in video data\nfrom diverse domains and unseen scenarios. To enable optimal future human\nbehavioral forecasting, it is crucial for the system to be able to detect and\nanalyze human activities as well as scene semantics, passing informative\nfeatures to the subsequent prediction module for context understanding.",
          "link": "http://arxiv.org/abs/2011.10670",
          "publishedOn": "2021-07-19T00:49:06.497Z",
          "wordCount": 626,
          "title": "From Recognition to Prediction: Analysis of Human Action and Trajectory Prediction in Video. (arXiv:2011.10670v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.04785",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_R/0/1/0/all/0/1\">Renqian Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1\">Xu Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1\">Tao Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_E/0/1/0/all/0/1\">Enhong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tie-Yan Liu</a>",
          "description": "Neural architecture search (NAS) with an accuracy predictor that predicts the\naccuracy of candidate architectures has drawn increasing attention due to its\nsimplicity and effectiveness. Previous works usually employ neural\nnetwork-based predictors which require more delicate design and are easy to\noverfit. Considering that most architectures are represented as sequences of\ndiscrete symbols which are more like tabular data and preferred by non-neural\npredictors, in this paper, we study an alternative approach which uses\nnon-neural model for accuracy prediction. Specifically, as decision tree based\nmodels can better handle tabular data, we leverage gradient boosting decision\ntree (GBDT) as the predictor for NAS. We demonstrate that the GBDT predictor\ncan achieve comparable (if not better) prediction accuracy than neural network\nbased predictors. Moreover, considering that a compact search space can ease\nthe search process, we propose to prune the search space gradually according to\nimportant features derived from GBDT. In this way, NAS can be performed by\nfirst pruning the search space and then searching a neural architecture, which\nis more efficient and effective. Experiments on NASBench-101 and ImageNet\ndemonstrate the effectiveness of using GBDT as predictor for NAS: (1) On\nNASBench-101, it is 22x, 8x, and 6x more sample efficient than random search,\nregularized evolution, and Monte Carlo Tree Search (MCTS) in finding the global\noptimum; (2) It achieves 24.2% top-1 error rate on ImageNet, and further\nachieves 23.4% top-1 error rate on ImageNet when enhanced with search space\npruning. Code is provided in the supplementary materials.",
          "link": "http://arxiv.org/abs/2007.04785",
          "publishedOn": "2021-07-19T00:49:06.477Z",
          "wordCount": 738,
          "title": "Accuracy Prediction with Non-neural Model for Neural Architecture Search. (arXiv:2007.04785v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.11150",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yi_J/0/1/0/all/0/1\">Jihun Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_E/0/1/0/all/0/1\">Eunji Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Siwon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1\">Sungroh Yoon</a>",
          "description": "In this work, we attempt to explain the prediction of any black-box\nclassifier from an information-theoretic perspective. For each input feature,\nwe compare the classifier outputs with and without that feature using two\ninformation-theoretic metrics. Accordingly, we obtain two attribution maps--an\ninformation gain (IG) map and a point-wise mutual information (PMI) map. IG map\nprovides a class-independent answer to \"How informative is each pixel?\", and\nPMI map offers a class-specific explanation of \"How much does each pixel\nsupport a specific class?\" Compared to existing methods, our method improves\nthe correctness of the attribution maps in terms of a quantitative metric. We\nalso provide a detailed analysis of an ImageNet classifier using the proposed\nmethod, and the code is available online.",
          "link": "http://arxiv.org/abs/2009.11150",
          "publishedOn": "2021-07-19T00:49:06.470Z",
          "wordCount": 580,
          "title": "Information-Theoretic Visual Explanation for Black-Box Classifiers. (arXiv:2009.11150v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.12150",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cardenas_B/0/1/0/all/0/1\">Bryan G. Cardenas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arya_D/0/1/0/all/0/1\">Devanshu Arya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_D/0/1/0/all/0/1\">Deepak K. Gupta</a>",
          "description": "Recent developments related to generative models have made it possible to\ngenerate diverse high-fidelity images. In particular, layout-to-image\ngeneration models have gained significant attention due to their capability to\ngenerate realistic complex images containing distinct objects. These models are\ngenerally conditioned on either semantic layouts or textual descriptions.\nHowever, unlike natural images, providing auxiliary information can be\nextremely hard in domains such as biomedical imaging and remote sensing. In\nthis work, we propose a multi-object generation framework that can synthesize\nimages with multiple objects without explicitly requiring their contextual\ninformation during the generation process. Based on a vector-quantized\nvariational autoencoder (VQ-VAE) backbone, our model learns to preserve spatial\ncoherency within an image as well as semantic coherency between the objects and\nthe background through two powerful autoregressive priors: PixelSNAIL and\nLayoutPixelSNAIL. While the PixelSNAIL learns the distribution of the latent\nencodings of the VQ-VAE, the LayoutPixelSNAIL is used to specifically learn the\nsemantic distribution of the objects. An implicit advantage of our approach is\nthat the generated samples are accompanied by object-level annotations. We\ndemonstrate how coherency and fidelity are preserved with our method through\nexperiments on the Multi-MNIST and CLEVR datasets; thereby outperforming\nstate-of-the-art multi-object generative methods. The efficacy of our approach\nis demonstrated through application on medical imaging datasets, where we show\nthat augmenting the training set with generated samples using our approach\nimproves the performance of existing models.",
          "link": "http://arxiv.org/abs/2006.12150",
          "publishedOn": "2021-07-19T00:49:06.464Z",
          "wordCount": 711,
          "title": "Generating Annotated High-Fidelity Images Containing Multiple Coherent Objects. (arXiv:2006.12150v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08039",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhizhong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ravichandran_A/0/1/0/all/0/1\">Avinash Ravichandran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fowlkes_C/0/1/0/all/0/1\">Charless Fowlkes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Polito_M/0/1/0/all/0/1\">Marzia Polito</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhotika_R/0/1/0/all/0/1\">Rahul Bhotika</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1\">Stefano Soatto</a>",
          "description": "Traditionally, distillation has been used to train a student model to emulate\nthe input/output functionality of a teacher. A more useful goal than emulation,\nyet under-explored, is for the student to learn feature representations that\ntransfer well to future tasks. However, we observe that standard distillation\nof task-specific teachers actually *reduces* the transferability of student\nrepresentations to downstream tasks. We show that a multi-head, multi-task\ndistillation method using an unlabeled proxy dataset and a generalist teacher\nis sufficient to consolidate representations from task-specific teacher(s) and\nimprove downstream performance, outperforming the teacher(s) and the strong\nbaseline of ImageNet pretrained features. Our method can also combine the\nrepresentational knowledge of multiple teachers trained on one or multiple\ndomains into a single model, whose representation is improved on all teachers'\ndomain(s).",
          "link": "http://arxiv.org/abs/2107.08039",
          "publishedOn": "2021-07-19T00:49:06.449Z",
          "wordCount": 568,
          "title": "Representation Consolidation for Training Expert Students. (arXiv:2107.08039v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2007.14509",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Robinson_J/0/1/0/all/0/1\">Joseph P. Robinson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_Z/0/1/0/all/0/1\">Zaid Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1\">Yu Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_M/0/1/0/all/0/1\">Ming Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1\">Yun Fu</a>",
          "description": "Kinship is a soft biometric detectable in media with an abundance of\npractical applications. Despite the difficulty of detecting kinship, annual\ndata challenges using still-images have consistently improved performances and\nattracted new researchers. Now, systems reach performance levels unforeseeable\na decade ago, closing in on performances acceptable to deploy in practice.\nSimilar to other biometric tasks, we expect systems can benefit from additional\nmodalities. We hypothesize that adding modalities to FIW, which contains only\nstill-images, will improve performance. Thus, to narrow the gap between\nresearch and reality and enhance the power of kinship recognition systems, we\nextend FIW with multimedia (MM) data (i.e., video, audio, and text captions).\nSpecifically, we introduce the first publicly available multi-task MM kinship\ndataset. To build FIW MM, we developed machinery to automatically collect,\nannotate, and prepare the data, requiring minimal human input and no financial\ncost. The proposed MM corpus allows the problem statements to be more realistic\ntemplate-based protocols. We show significant improvements in all benchmarks\nwith the added modalities. The results highlight edge cases to inspire future\nresearch with different areas of improvement. FIW MM provides the data required\nto increase the potential of automated systems to detect kinship in MM. It also\nallows experts from diverse fields to collaborate in novel ways.",
          "link": "http://arxiv.org/abs/2007.14509",
          "publishedOn": "2021-07-19T00:49:06.444Z",
          "wordCount": 706,
          "title": "Families In Wild Multimedia (FIW MM): A Multi-Modal Database for Recognizing Kinship. (arXiv:2007.14509v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.08382",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shaojie Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_M/0/1/0/all/0/1\">Mingbao Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chao_F/0/1/0/all/0/1\">Fei Chao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_X/0/1/0/all/0/1\">Xudong Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1\">Mingliang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yongjian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Feiyue Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_L/0/1/0/all/0/1\">Ling Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_R/0/1/0/all/0/1\">Rongrong Ji</a>",
          "description": "Generative Adversarial Networks (GANs) have been widely-used in image\ntranslation, but their high computational and storage costs impede the\ndeployment on mobile devices. Prevalent methods for CNN compression cannot be\ndirectly applied to GANs due to the complicated generator architecture and the\nunstable adversarial training. To solve these, in this paper, we introduce a\nnovel GAN compression method, termed DMAD, by proposing a Differentiable Mask\nand a co-Attention Distillation. The former searches for a light-weight\ngenerator architecture in a training-adaptive manner. To overcome channel\ninconsistency when pruning the residual connections, an adaptive cross-block\ngroup sparsity is further incorporated. The latter simultaneously distills\ninformative attention maps from both the generator and discriminator of a\npre-trained model to the searched generator, effectively stabilizing the\nadversarial training of our light-weight model. Experiments show that DMAD can\nreduce the Multiply Accumulate Operations (MACs) of CycleGAN by 13$\\times$ and\nthat of Pix2Pix by 4$\\times$ while retaining a comparable performance against\nthe full model. Our code can be available at https://github.com/SJLeo/DMAD.",
          "link": "http://arxiv.org/abs/2011.08382",
          "publishedOn": "2021-07-19T00:49:06.438Z",
          "wordCount": 663,
          "title": "Learning Efficient GANs for Image Translation via Differentiable Masks and co-Attention Distillation. (arXiv:2011.08382v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08031",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Achaji_L/0/1/0/all/0/1\">Lina Achaji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moreau_J/0/1/0/all/0/1\">Julien Moreau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fouqueray_T/0/1/0/all/0/1\">Thibault Fouqueray</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aioun_F/0/1/0/all/0/1\">Francois Aioun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Charpillet_F/0/1/0/all/0/1\">Francois Charpillet</a>",
          "description": "The human driver is no longer the only one concerned with the complexity of\nthe driving scenarios. Autonomous vehicles (AV) are similarly becoming involved\nin the process. Nowadays, the development of AV in urban places underpins\nessential safety concerns for vulnerable road users (VRUs) such as pedestrians.\nTherefore, to make the roads safer, it is critical to classify and predict\ntheir future behavior. In this paper, we present a framework based on multiple\nvariations of the Transformer models to reason attentively about the dynamic\nevolution of the pedestrians' past trajectory and predict its future actions of\ncrossing or not crossing the street. We proved that using only bounding boxes\nas input to our model can outperform the previous state-of-the-art models and\nreach a prediction accuracy of 91 % and an F1-score of 0.83 on the PIE dataset\nup to two seconds ahead in the future. In addition, we introduced a large-size\nsimulated dataset (CP2A) using CARLA for action prediction. Our model has\nsimilarly reached high accuracy (91 %) and F1-score (0.91) on this dataset.\nInterestingly, we showed that pre-training our Transformer model on the\nsimulated dataset and then fine-tuning it on the real dataset can be very\neffective for the action prediction task.",
          "link": "http://arxiv.org/abs/2107.08031",
          "publishedOn": "2021-07-19T00:49:06.431Z",
          "wordCount": 656,
          "title": "Is attention to bounding boxes all you need for pedestrian action prediction?. (arXiv:2107.08031v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07988",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liang_H/0/1/0/all/0/1\">Hao Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1\">Lulan Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_G/0/1/0/all/0/1\">Guikang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raj_B/0/1/0/all/0/1\">Bhiksha Raj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1\">Rita Singh</a>",
          "description": "Multiple studies in the past have shown that there is a strong correlation\nbetween human vocal characteristics and facial features. However, existing\napproaches generate faces simply from voice, without exploring the set of\nfeatures that contribute to these observed correlations. A computational\nmethodology to explore this can be devised by rephrasing the question to: \"how\nmuch would a target face have to change in order to be perceived as the\noriginator of a source voice?\" With this in perspective, we propose a framework\nto morph a target face in response to a given voice in a way that facial\nfeatures are implicitly guided by learned voice-face correlation in this paper.\nOur framework includes a guided autoencoder that converts one face to another,\ncontrolled by a unique model-conditioning component called a gating controller\nwhich modifies the reconstructed face based on input voice recordings. We\nevaluate the framework on VoxCelab and VGGFace datasets through human subjects\nand face retrieval. Various experiments demonstrate the effectiveness of our\nproposed model.",
          "link": "http://arxiv.org/abs/2107.07988",
          "publishedOn": "2021-07-19T00:49:06.425Z",
          "wordCount": 621,
          "title": "Controlled AutoEncoders to Generate Faces from Voices. (arXiv:2107.07988v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08037",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moing_G/0/1/0/all/0/1\">Guillaume Le Moing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ponce_J/0/1/0/all/0/1\">Jean Ponce</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmid_C/0/1/0/all/0/1\">Cordelia Schmid</a>",
          "description": "This presentation introduces a self-supervised learning approach to the\nsynthesis of new video clips from old ones, with several new key elements for\nimproved spatial resolution and realism: It conditions the synthesis process on\ncontextual information for temporal continuity and ancillary information for\nfine control. The prediction model is doubly autoregressive, in the latent\nspace of an autoencoder for forecasting, and in image space for updating\ncontextual information, which is also used to enforce spatio-temporal\nconsistency through a learnable optical flow module. Adversarial training of\nthe autoencoder in the appearance and temporal domains is used to further\nimprove the realism of its output. A quantizer inserted between the encoder and\nthe transformer in charge of forecasting future frames in latent space (and its\ninverse inserted between the transformer and the decoder) adds even more\nflexibility by affording simple mechanisms for handling multimodal ancillary\ninformation for controlling the synthesis process (eg, a few sample frames, an\naudio track, a trajectory in image space) and taking into account the\nintrinsically uncertain nature of the future by allowing multiple predictions.\nExperiments with an implementation of the proposed approach give very good\nqualitative and quantitative results on multiple tasks and standard benchmarks.",
          "link": "http://arxiv.org/abs/2107.08037",
          "publishedOn": "2021-07-19T00:49:06.418Z",
          "wordCount": 628,
          "title": "CCVS: Context-aware Controllable Video Synthesis. (arXiv:2107.08037v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/1905.10170",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Truong_T/0/1/0/all/0/1\">Thanh-Dat Truong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luu_K/0/1/0/all/0/1\">Khoa Luu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duong_C/0/1/0/all/0/1\">Chi Nhan Duong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_N/0/1/0/all/0/1\">Ngan Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_M/0/1/0/all/0/1\">Minh-Triet Tran</a>",
          "description": "Flow-based generative models have recently become one of the most efficient\napproaches to model data generation. Indeed, they are constructed with a\nsequence of invertible and tractable transformations. Glow first introduced a\nsimple type of generative flow using an invertible $1 \\times 1$ convolution.\nHowever, the $1 \\times 1$ convolution suffers from limited flexibility compared\nto the standard convolutions. In this paper, we propose a novel invertible $n\n\\times n$ convolution approach that overcomes the limitations of the invertible\n$1 \\times 1$ convolution. In addition, our proposed network is not only\ntractable and invertible but also uses fewer parameters than standard\nconvolutions. The experiments on CIFAR-10, ImageNet and Celeb-HQ datasets, have\nshown that our invertible $n \\times n$ convolution helps to improve the\nperformance of generative models significantly.",
          "link": "http://arxiv.org/abs/1905.10170",
          "publishedOn": "2021-07-19T00:49:06.400Z",
          "wordCount": 594,
          "title": "Generative Flow via Invertible nxn Convolution. (arXiv:1905.10170v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08000",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_C/0/1/0/all/0/1\">Chull Hwan Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_H/0/1/0/all/0/1\">Hye Joo Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Avrithis_Y/0/1/0/all/0/1\">Yannis Avrithis</a>",
          "description": "We address representation learning for large-scale instance-level image\nretrieval. Apart from backbone, training pipelines and loss functions, popular\napproaches have focused on different spatial pooling and attention mechanisms,\nwhich are at the core of learning a powerful global image representation. There\nare different forms of attention according to the interaction of elements of\nthe feature tensor (local and global) and the dimensions where it is applied\n(spatial and channel). Unfortunately, each study addresses only one or two\nforms of attention and applies it to different problems like classification,\ndetection or retrieval.\n\nWe present global-local attention module (GLAM), which is attached at the end\nof a backbone network and incorporates all four forms of attention: local and\nglobal, spatial and channel. We obtain a new feature tensor and, by spatial\npooling, we learn a powerful embedding for image retrieval. Focusing on global\ndescriptors, we provide empirical evidence of the interaction of all forms of\nattention and improve the state of the art on standard benchmarks.",
          "link": "http://arxiv.org/abs/2107.08000",
          "publishedOn": "2021-07-19T00:49:06.393Z",
          "wordCount": 606,
          "title": "All the attention you need: Global-local, spatial-channel attention for image retrieval. (arXiv:2107.08000v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2009.03787",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wagstaff_B/0/1/0/all/0/1\">Brandon Wagstaff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kelly_J/0/1/0/all/0/1\">Jonathan Kelly</a>",
          "description": "The self-supervised loss formulation for jointly training depth and egomotion\nneural networks with monocular images is well studied and has demonstrated\nstate-of-the-art accuracy. One of the main limitations of this approach,\nhowever, is that the depth and egomotion estimates are only determined up to an\nunknown scale. In this paper, we present a novel scale recovery loss that\nenforces consistency between a known camera height and the estimated camera\nheight, generating metric (scaled) depth and egomotion predictions. We show\nthat our proposed method is competitive with other scale recovery techniques\nthat require more information. Further, we demonstrate that our method\nfacilitates network retraining within new environments, whereas other\nscale-resolving approaches are incapable of doing so. Notably, our egomotion\nnetwork is able to produce more accurate estimates than a similar method which\nrecovers scale at test time only.",
          "link": "http://arxiv.org/abs/2009.03787",
          "publishedOn": "2021-07-19T00:49:06.379Z",
          "wordCount": 630,
          "title": "Self-Supervised Scale Recovery for Monocular Depth and Egomotion Estimation. (arXiv:2009.03787v4 [cs.RO] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.07907",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Liu_K/0/1/0/all/0/1\">Kanglin Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cao_G/0/1/0/all/0/1\">Gaofeng Cao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Duan_J/0/1/0/all/0/1\">Jiang Duan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Qiu_G/0/1/0/all/0/1\">Guoping Qiu</a>",
          "description": "Single-image HDR reconstruction or inverse tone mapping (iTM) is a\nchallenging task. In particular, recovering information in over-exposed regions\nis extremely difficult because details in such regions are almost completely\nlost. In this paper, we present a deep learning based iTM method that takes\nadvantage of the feature extraction and mapping power of deep convolutional\nneural networks (CNNs) and uses a lightness prior to modulate the CNN to better\nexploit observations in the surrounding areas of the over-exposed regions to\nenhance the quality of HDR image reconstruction. Specifically, we introduce a\nHierarchical Synthesis Network (HiSN) for inferring a HDR image from a LDR\ninput and a Lightness Adpative Modulation Network (LAMN) to incorporate the the\nlightness prior knowledge in the inferring process. The HiSN hierarchically\nsynthesizes the high-brightness component and the low-brightness component of\nthe HDR image whilst the LAMN uses a lightness adaptive mask that separates\ndetail-less saturated bright pixels from well-exposed lower light pixels to\nenable HiSN to better infer the missing information, particularly in the\ndifficult over-exposed detail-less areas. We present experimental results to\ndemonstrate the effectiveness of the new technique based on quantitative\nmeasures and visual comparisons. In addition, we present ablation studies of\nHiSN and visualization of the activation maps inside LAMN to help gain a deeper\nunderstanding of the internal working of the new iTM algorithm and explain why\nit can achieve much improved performance over state-of-the-art algorithms.",
          "link": "http://arxiv.org/abs/2107.07907",
          "publishedOn": "2021-07-19T00:49:06.350Z",
          "wordCount": 683,
          "title": "Lightness Modulated Deep Inverse Tone Mapping. (arXiv:2107.07907v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07986",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Josse_E/0/1/0/all/0/1\">Elias Josse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nerborg_A/0/1/0/all/0/1\">Amanda Nerborg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hernandez_Diaz_K/0/1/0/all/0/1\">Kevin Hernandez-Diaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alonso_Fernandez_F/0/1/0/all/0/1\">Fernando Alonso-Fernandez</a>",
          "description": "The world is expecting an aging population and shortage of healthcare\nprofessionals. This poses the problem of providing a safe and dignified life\nfor the elderly. Technological solutions involving cameras can contribute to\nsafety, comfort and efficient emergency responses, but they are invasive of\nprivacy. We use 'Griddy', a prototype with a Panasonic Grid-EYE, a\nlow-resolution infrared thermopile array sensor, which offers more privacy.\nMounted over a bed, it can determine if the user is on the bed or not without\nhuman interaction. For this purpose, two datasets were captured, one (480\nimages) under constant conditions, and a second one (200 images) under\ndifferent variations such as use of a duvet, sleeping with a pet, or increased\nroom temperature. We test three machine learning algorithms: Support Vector\nMachines (SVM), k-Nearest Neighbors (k-NN) and Neural Network (NN). With\n10-fold cross validation, the highest accuracy in the main dataset is for both\nSVM and k-NN (99%). The results with variable data show a lower reliability\nunder certain circumstances, highlighting the need of extra work to meet the\nchallenge of variations in the environment.",
          "link": "http://arxiv.org/abs/2107.07986",
          "publishedOn": "2021-07-19T00:49:06.343Z",
          "wordCount": 628,
          "title": "In-Bed Person Monitoring Using Thermal Infrared Sensors. (arXiv:2107.07986v1 [cs.HC])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07987",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Mingrui Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Weiyu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1\">Weizhi Lu</a>",
          "description": "Recently, it has been observed that {0,1,-1}-ternary codes which are simply\ngenerated from deep features by hard thresholding, tend to outperform\n{-1,1}-binary codes in image retrieval. To obtain better ternary codes, we for\nthe first time propose to jointly learn the features with the codes by\nappending a smoothed function to the networks. During training, the function\ncould evolve into a non-smoothed ternary function by a continuation method. The\nmethod circumvents the difficulty of directly training discrete functions and\nreduces the quantization errors of ternary codes. Experiments show that the\ngenerated codes indeed could achieve higher retrieval accuracy.",
          "link": "http://arxiv.org/abs/2107.07987",
          "publishedOn": "2021-07-19T00:49:06.308Z",
          "wordCount": 532,
          "title": "Deep Learning to Ternary Hash Codes by Continuation. (arXiv:2107.07987v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07919",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fabbrizzi_S/0/1/0/all/0/1\">Simone Fabbrizzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papadopoulos_S/0/1/0/all/0/1\">Symeon Papadopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ntoutsi_E/0/1/0/all/0/1\">Eirini Ntoutsi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kompatsiaris_I/0/1/0/all/0/1\">Ioannis Kompatsiaris</a>",
          "description": "Computer Vision (CV) has achieved remarkable results, outperforming humans in\nseveral tasks. Nonetheless, it may result in major discrimination if not dealt\nwith proper care. CV systems highly depend on the data they are fed with and\ncan learn and amplify biases within such data. Thus, both the problems of\nunderstanding and discovering biases are of utmost importance. Yet, to date\nthere is no comprehensive survey on bias in visual datasets. To this end, this\nwork aims to: i) describe the biases that can affect visual datasets; ii)\nreview the literature on methods for bias discovery and quantification in\nvisual datasets; iii) discuss existing attempts to collect bias-aware visual\ndatasets. A key conclusion of our study is that the problem of bias discovery\nand quantification in visual datasets is still open and there is room for\nimprovement in terms of both methods and the range of biases that can be\naddressed; moreover, there is no such thing as a bias-free dataset, so\nscientists and practitioners must become aware of the biases in their datasets\nand make them explicit. To this end, we propose a checklist that can be used to\nspot different types of bias during visual dataset collection.",
          "link": "http://arxiv.org/abs/2107.07919",
          "publishedOn": "2021-07-19T00:49:06.301Z",
          "wordCount": 632,
          "title": "A Survey on Bias in Visual Datasets. (arXiv:2107.07919v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07905",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Hong-Xing Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guibas_L/0/1/0/all/0/1\">Leonidas J. Guibas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jiajun Wu</a>",
          "description": "We study the problem of inferring an object-centric scene representation from\na single image, aiming to derive a representation that explains the image\nformation process, captures the scene's 3D nature, and is learned without\nsupervision. Most existing methods on scene decomposition lack one or more of\nthese characteristics, due to the fundamental challenge in integrating the\ncomplex 3D-to-2D image formation process into powerful inference schemes like\ndeep networks. In this paper, we propose unsupervised discovery of Object\nRadiance Fields (uORF), integrating recent progresses in neural 3D scene\nrepresentations and rendering with deep inference networks for unsupervised 3D\nscene decomposition. Trained on multi-view RGB images without annotations, uORF\nlearns to decompose complex scenes with diverse, textured background from a\nsingle image. We show that uORF performs well on unsupervised 3D scene\nsegmentation, novel view synthesis, and scene editing on three datasets.",
          "link": "http://arxiv.org/abs/2107.07905",
          "publishedOn": "2021-07-19T00:49:06.288Z",
          "wordCount": 580,
          "title": "Unsupervised Discovery of Object Radiance Fields. (arXiv:2107.07905v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07787",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Engel_N/0/1/0/all/0/1\">Nico Engel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belagiannis_V/0/1/0/all/0/1\">Vasileios Belagiannis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dietmayer_K/0/1/0/all/0/1\">Klaus Dietmayer</a>",
          "description": "We present a vehicle self-localization method using point-based deep neural\nnetworks. Our approach processes measurements and point features, i.e.\nlandmarks, from a high-definition digital map to infer the vehicle's pose. To\nlearn the best association and incorporate local information between the point\nsets, we propose an attention mechanism that matches the measurements to the\ncorresponding landmarks. Finally, we use this representation for the\npoint-cloud registration and the subsequent pose regression task. Furthermore,\nwe introduce a training simulation framework that artificially generates\nmeasurements and landmarks to facilitate the deployment process and reduce the\ncost of creating extensive datasets from real-world data. We evaluate our\nmethod on our dataset, as well as an adapted version of the Kitti odometry\ndataset, where we achieve superior performance compared to related approaches;\nand additionally show dominant generalization capabilities.",
          "link": "http://arxiv.org/abs/2107.07787",
          "publishedOn": "2021-07-19T00:49:06.279Z",
          "wordCount": 583,
          "title": "Attention-based Vehicle Self-Localization with HD Feature Maps. (arXiv:2107.07787v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07789",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pont_M/0/1/0/all/0/1\">Mathieu Pont</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vidal_J/0/1/0/all/0/1\">Jules Vidal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Delon_J/0/1/0/all/0/1\">Julie Delon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tierny_J/0/1/0/all/0/1\">Julien Tierny</a>",
          "description": "This paper presents a unified computational framework for the estimation of\ndistances, geodesics and barycenters of merge trees. We extend recent work on\nthe edit distance [106] and introduce a new metric, called the Wasserstein\ndistance between merge trees, which is purposely designed to enable efficient\ncomputations of geodesics and barycenters. Specifically, our new distance is\nstrictly equivalent to the L2-Wasserstein distance between extremum persistence\ndiagrams, but it is restricted to a smaller solution space, namely, the space\nof rooted partial isomorphisms between branch decomposition trees. This enables\na simple extension of existing optimization frameworks [112] for geodesics and\nbarycenters from persistence diagrams to merge trees. We introduce a task-based\nalgorithm which can be generically applied to distance, geodesic, barycenter or\ncluster computation. The task-based nature of our approach enables further\naccelerations with shared-memory parallelism. Extensive experiments on public\nensembles and SciVis contest benchmarks demonstrate the efficiency of our\napproach -- with barycenter computations in the orders of minutes for the\nlargest examples -- as well as its qualitative ability to generate\nrepresentative barycenter merge trees, visually summarizing the features of\ninterest found in the ensemble. We show the utility of our contributions with\ndedicated visualization applications: feature tracking, temporal reduction and\nensemble clustering. We provide a lightweight C++ implementation that can be\nused to reproduce our results.",
          "link": "http://arxiv.org/abs/2107.07789",
          "publishedOn": "2021-07-19T00:49:06.272Z",
          "wordCount": 664,
          "title": "Wasserstein Distances, Geodesics and Barycenters of Merge Trees. (arXiv:2107.07789v1 [cs.GR])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07826",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Blekos_K/0/1/0/all/0/1\">Kostas Blekos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nousias_S/0/1/0/all/0/1\">Stavros Nousias</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lalos_A/0/1/0/all/0/1\">Aris S Lalos</a>",
          "description": "Delineation approaches provide significant benefits to various domains,\nincluding agriculture, environmental and natural disasters monitoring. Most of\nthe work in the literature utilize traditional segmentation methods that\nrequire a large amount of computational and storage resources. Deep learning\nhas transformed computer vision and dramatically improved machine translation,\nthough it requires massive dataset for training and significant resources for\ninference. More importantly, energy-efficient embedded vision hardware\ndelivering real-time and robust performance is crucial in the aforementioned\napplication. In this work, we propose a U-Net based tree delineation method,\nwhich is effectively trained using multi-spectral imagery but can then\ndelineate single-spectrum images. The deep architecture that also performs\nlocalization, i.e., a class label corresponds to each pixel, has been\nsuccessfully used to allow training with a small set of segmented images. The\nground truth data were generated using traditional image denoising and\nsegmentation approaches. To be able to execute the proposed DNN efficiently in\nembedded platforms designed for deep learning approaches, we employ traditional\nmodel compression and acceleration methods. Extensive evaluation studies using\ndata collected from UAVs equipped with multi-spectral cameras demonstrate the\neffectiveness of the proposed methods in terms of delineation accuracy and\nexecution efficiency.",
          "link": "http://arxiv.org/abs/2107.07826",
          "publishedOn": "2021-07-19T00:49:06.255Z",
          "wordCount": 657,
          "title": "Efficient automated U-Net based tree crown delineation using UAV multi-spectral imagery on embedded devices. (arXiv:2107.07826v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07837",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Runde Li</a>",
          "description": "To solve the issue of video dehazing, there are two main tasks to attain: how\nto align adjacent frames to the reference frame; how to restore the reference\nframe. Some papers adopt explicit approaches (e.g., the Markov random field,\noptical flow, deformable convolution, 3D convolution) to align neighboring\nframes with the reference frame in feature space or image space, they then use\nvarious restoration methods to achieve the final dehazing results. In this\npaper, we propose a progressive alignment and restoration method for video\ndehazing. The alignment process aligns consecutive neighboring frames stage by\nstage without using the optical flow estimation. The restoration process is not\nonly implemented under the alignment process but also uses a refinement network\nto improve the dehazing performance of the whole network. The proposed networks\ninclude four fusion networks and one refinement network. To decrease the\nparameters of networks, three fusion networks in the first fusion stage share\nthe same parameters. Extensive experiments demonstrate that the proposed video\ndehazing method achieves outstanding performance against the-state-of-art\nmethods.",
          "link": "http://arxiv.org/abs/2107.07837",
          "publishedOn": "2021-07-19T00:49:06.241Z",
          "wordCount": 600,
          "title": "Progressive Deep Video Dehazing without Explicit Alignment Estimation. (arXiv:2107.07837v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07975",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Savioli_N/0/1/0/all/0/1\">Nicolo Savioli</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Marvao_A/0/1/0/all/0/1\">Antonio de Marvao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bai_W/0/1/0/all/0/1\">Wenjia Bai</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_S/0/1/0/all/0/1\">Shuo Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cook_S/0/1/0/all/0/1\">Stuart A. Cook</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chin_C/0/1/0/all/0/1\">Calvin W.L. Chin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rueckert_D/0/1/0/all/0/1\">Daniel Rueckert</a>, <a href=\"http://arxiv.org/find/eess/1/au:+ORegan_D/0/1/0/all/0/1\">Declan P. O&#x27;Regan</a>",
          "description": "Optimising the analysis of cardiac structure and function requires accurate\n3D representations of shape and motion. However, techniques such as cardiac\nmagnetic resonance imaging are conventionally limited to acquiring contiguous\ncross-sectional slices with low through-plane resolution and potential\ninter-slice spatial misalignment. Super-resolution in medical imaging aims to\nincrease the resolution of images but is conventionally trained on features\nfrom low resolution datasets and does not super-resolve corresponding\nsegmentations. Here we propose a semi-supervised multi-task generative\nadversarial network (Gemini-GAN) that performs joint super-resolution of the\nimages and their labels using a ground truth of high resolution 3D cines and\nsegmentations, while an unsupervised variational adversarial mixture\nautoencoder (V-AMA) is used for continuous domain adaptation. Our proposed\napproach is extensively evaluated on two transnational multi-ethnic populations\nof 1,331 and 205 adults respectively, delivering an improvement on state of the\nart methods in terms of Dice index, peak signal to noise ratio, and structural\nsimilarity index measure. This framework also exceeds the performance of state\nof the art generative domain adaptation models on external validation (Dice\nindex 0.81 vs 0.74 for the left ventricle). This demonstrates how joint\nsuper-resolution and segmentation, trained on 3D ground-truth data with\ncross-domain generalization, enables robust precision phenotyping in diverse\npopulations.",
          "link": "http://arxiv.org/abs/2107.07975",
          "publishedOn": "2021-07-19T00:49:06.224Z",
          "wordCount": 667,
          "title": "Joint Semi-supervised 3D Super-Resolution and Segmentation with Mixed Adversarial Gaussian Domain Adaptation. (arXiv:2107.07975v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07827",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kannan_N/0/1/0/all/0/1\">Nagajothi Kannan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Danda_S/0/1/0/all/0/1\">Sravan Danda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Challa_A/0/1/0/all/0/1\">Aditya Challa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+S_D/0/1/0/all/0/1\">Daya Sagar B S</a>",
          "description": "The study of water bodies such as rivers is an important problem in the\nremote sensing community. A meaningful set of quantitative features reflecting\nthe geophysical properties help us better understand the formation and\nevolution of rivers. Typically, river sub-basins are analysed using Cartosat\nDigital Elevation Models (DEMs), obtained at regular time epochs. One of the\nuseful geophysical features of a river sub-basin is that of a roughness measure\non DEMs. However, to the best of our knowledge, there is not much literature\navailable on theoretical analysis of roughness measures. In this article, we\nrevisit the roughness measure on DEM data adapted from multiscale\ngranulometries in mathematical morphology, namely multiscale directional\ngranulometric index (MDGI). This measure was classically used to obtain\nshape-size analysis in greyscale images. In earlier works, MDGIs were\nintroduced to capture the characteristic surficial roughness of a river\nsub-basin along specific directions. Also, MDGIs can be efficiently computed\nand are known to be useful features for classification of river sub-basins. In\nthis article, we provide a theoretical analysis of a MDGI. In particular, we\ncharacterize non-trivial sufficient conditions on the structure of DEMs under\nwhich MDGIs are invariant. These properties are illustrated with some\nfictitious DEMs. We also provide connections to a discrete derivative of volume\nof a DEM. Based on these connections, we provide intuition as to why a MDGI is\nconsidered a roughness measure. Further, we experimentally illustrate on\nLower-Indus, Wardha, and Barmer river sub-basins that the proposed features\ncapture the characteristics of the river sub-basin.",
          "link": "http://arxiv.org/abs/2107.07827",
          "publishedOn": "2021-07-19T00:49:06.208Z",
          "wordCount": 708,
          "title": "A Theoretical Analysis of Granulometry-based Roughness Measures on Cartosat DEMs. (arXiv:2107.07827v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07985",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Jiang_J/0/1/0/all/0/1\">Jue Jiang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rimner_A/0/1/0/all/0/1\">Andreas Rimner</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Deasy_J/0/1/0/all/0/1\">Joseph O. Deasy</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Veeraraghavan_H/0/1/0/all/0/1\">Harini Veeraraghavan</a>",
          "description": "Accurate and robust segmentation of lung cancers from CTs is needed to more\naccurately plan and deliver radiotherapy and to measure treatment response.\nThis is particularly difficult for tumors located close to mediastium, due to\nlow soft-tissue contrast. Therefore, we developed a new cross-modality educed\ndistillation (CMEDL) approach, using unpaired CT and MRI scans, whereby a\nteacher MRI network guides a student CT network to extract features that signal\nthe difference between foreground and background. Our contribution eliminates\ntwo requirements of distillation methods: (i) paired image sets by using an\nimage to image (I2I) translation and (ii) pre-training of the teacher network\nwith a large training set by using concurrent training of all networks. Our\nframework uses an end-to-end trained unpaired I2I translation, teacher, and\nstudent segmentation networks. Our framework can be combined with any I2I and\nsegmentation network. We demonstrate our framework's feasibility using 3\nsegmentation and 2 I2I methods. All networks were trained with 377 CT and 82\nT2w MRI from different sets of patients. Ablation tests and different\nstrategies for incorporating MRI information into CT were performed. Accuracy\nwas measured using Dice similarity (DSC), surface Dice (sDSC), and Hausdorff\ndistance at the 95$^{th}$ percentile (HD95). The CMEDL approach was\nsignificantly (p $<$ 0.001) more accurate than non-CMEDL methods,\nquantitatively and visually. It produced the highest segmentation accuracy\n(sDSC of 0.83 $\\pm$ 0.16 and HD95 of 5.20 $\\pm$ 6.86mm). CMEDL was also more\naccurate than using either pMRI's or the combination of CT's with pMRI's for\nsegmentation.",
          "link": "http://arxiv.org/abs/2107.07985",
          "publishedOn": "2021-07-19T00:49:06.202Z",
          "wordCount": 715,
          "title": "Unpaired cross-modality educed distillation (CMEDL) applied to CT lung tumor segmentation. (arXiv:2107.07985v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07786",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shatri_E/0/1/0/all/0/1\">Elona Shatri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fazekas_G/0/1/0/all/0/1\">Gy&#xf6;rgy Fazekas</a>",
          "description": "The main challenges of Optical Music Recognition (OMR) come from the nature\nof written music, its complexity and the difficulty of finding an appropriate\ndata representation. This paper provides a first look at DoReMi, an OMR dataset\nthat addresses these challenges, and a baseline object detection model to\nassess its utility. Researchers often approach OMR following a set of small\nstages, given that existing data often do not satisfy broader research. We\nexamine the possibility of changing this tendency by presenting more metadata.\nOur approach complements existing research; hence DoReMi allows harmonisation\nwith two existing datasets, DeepScores and MUSCIMA++. DoReMi was generated\nusing a music notation software and includes over 6400 printed sheet music\nimages with accompanying metadata useful in OMR research. Our dataset provides\nOMR metadata, MIDI, MEI, MusicXML and PNG files, each aiding a different stage\nof OMR. We obtain 64% mean average precision (mAP) in object detection using\nhalf of the data. Further work includes re-iterating through the creation\nprocess to satisfy custom OMR models. While we do not assume to have solved the\nmain challenges in OMR, this dataset opens a new course of discussions that\nwould ultimately aid that goal.",
          "link": "http://arxiv.org/abs/2107.07786",
          "publishedOn": "2021-07-19T00:49:06.177Z",
          "wordCount": 651,
          "title": "DoReMi: First glance at a universal OMR dataset. (arXiv:2107.07786v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07927",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Muzammul_M/0/1/0/all/0/1\">Muhammed Muzammul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xi Li</a>",
          "description": "This survey paper specially analyzed computer vision-based object detection\nchallenges and solutions by different techniques. We mainly highlighted object\ndetection by three different trending strategies, i.e., 1) domain adaptive deep\nlearning-based approaches (discrepancy-based, Adversarial-based,\nReconstruction-based, Hybrid). We examined general as well as tiny object\ndetection-related challenges and offered solutions by historical and\ncomparative analysis. In part 2) we mainly focused on tiny object detection\ntechniques (multi-scale feature learning, Data augmentation, Training strategy\n(TS), Context-based detection, GAN-based detection). In part 3), To obtain\nknowledge-able findings, we discussed different object detection methods, i.e.,\nconvolutions and convolutional neural networks (CNN), pooling operations with\ntrending types. Furthermore, we explained results with the help of some object\ndetection algorithms, i.e., R-CNN, Fast R-CNN, Faster R-CNN, YOLO, and SSD,\nwhich are generally considered the base bone of CV, CNN, and OD. We performed\ncomparative analysis on different datasets such as MS-COCO, PASCAL VOC07,12,\nand ImageNet to analyze results and present findings. At the end, we showed\nfuture directions with existing challenges of the field. In the future, OD\nmethods and models can be analyzed for real-time object detection, tracking\nstrategies.",
          "link": "http://arxiv.org/abs/2107.07927",
          "publishedOn": "2021-07-19T00:49:06.171Z",
          "wordCount": 627,
          "title": "A Survey on Deep Domain Adaptation and Tiny Object Detection Challenges, Techniques and Datasets. (arXiv:2107.07927v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07746",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1\">Xu Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_L/0/1/0/all/0/1\">Longhui Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_L/0/1/0/all/0/1\">Liangjian Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jinrong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_L/0/1/0/all/0/1\">Lingxi Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zenglin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Q/0/1/0/all/0/1\">Qi Tian</a>",
          "description": "Few-Shot image classification aims to utilize pretrained knowledge learned\nfrom a large-scale dataset to tackle a series of downstream classification\ntasks. Typically, each task involves only few training examples from brand-new\ncategories. This requires the pretraining models to focus on well-generalizable\nknowledge, but ignore domain-specific information. In this paper, we observe\nthat image background serves as a source of domain-specific knowledge, which is\na shortcut for models to learn in the source dataset, but is harmful when\nadapting to brand-new classes. To prevent the model from learning this shortcut\nknowledge, we propose COSOC, a novel Few-Shot Learning framework, to\nautomatically figure out foreground objects at both pretraining and evaluation\nstage. COSOC is a two-stage algorithm motivated by the observation that\nforeground objects from different images within the same class share more\nsimilar patterns than backgrounds. At the pretraining stage, for each class, we\ncluster contrastive-pretrained features of randomly cropped image patches, such\nthat crops containing only foreground objects can be identified by a single\ncluster. We then force the pretraining model to focus on found foreground\nobjects by a fusion sampling strategy; at the evaluation stage, among images in\neach training class of any few-shot task, we seek for shared contents and\nfilter out background. The recognized foreground objects of each class are used\nto match foreground of testing images. Extensive experiments tailored to\ninductive FSL tasks on two benchmarks demonstrate the state-of-the-art\nperformance of our method.",
          "link": "http://arxiv.org/abs/2107.07746",
          "publishedOn": "2021-07-19T00:49:06.158Z",
          "wordCount": 694,
          "title": "Rectifying the Shortcut Learning of Background: Shared Object Concentration for Few-Shot Image Recognition. (arXiv:2107.07746v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07778",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hubner_P/0/1/0/all/0/1\">Patrick H&#xfc;bner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weinmann_M/0/1/0/all/0/1\">Martin Weinmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wursthorn_S/0/1/0/all/0/1\">Sven Wursthorn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hinz_S/0/1/0/all/0/1\">Stefan Hinz</a>",
          "description": "In this paper, we present a novel pose normalization method for indoor\nmapping point clouds and triangle meshes that is robust against large fractions\nof the indoor mapping geometries deviating from an ideal Manhattan World\nstructure. In the case of building structures that contain multiple Manhattan\nWorld systems, the dominant Manhattan World structure supported by the largest\nfraction of geometries is determined and used for alignment. In a first step, a\nvertical alignment orienting a chosen axis to be orthogonal to horizontal floor\nand ceiling surfaces is conducted. Subsequently, a rotation around the\nresulting vertical axis is determined that aligns the dataset horizontally with\nthe coordinate axes. The proposed method is evaluated quantitatively against\nseveral publicly available indoor mapping datasets. Our implementation of the\nproposed procedure along with code for reproducing the evaluation will be made\navailable to the public upon acceptance for publication.",
          "link": "http://arxiv.org/abs/2107.07778",
          "publishedOn": "2021-07-19T00:49:06.151Z",
          "wordCount": 590,
          "title": "Pose Normalization of Indoor Mapping Datasets Partially Compliant to the Manhattan World Assumption. (arXiv:2107.07778v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07820",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Haan_P/0/1/0/all/0/1\">Puck de Haan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lowe_S/0/1/0/all/0/1\">Sindy L&#xf6;we</a>",
          "description": "Reliable detection of anomalies is crucial when deploying machine learning\nmodels in practice, but remains challenging due to the lack of labeled data. To\ntackle this challenge, contrastive learning approaches are becoming\nincreasingly popular, given the impressive results they have achieved in\nself-supervised representation learning settings. However, while most existing\ncontrastive anomaly detection and segmentation approaches have been applied to\nimages, none of them can use the contrastive losses directly for both anomaly\ndetection and segmentation. In this paper, we close this gap by making use of\nthe Contrastive Predictive Coding model (arXiv:1807.03748). We show that its\npatch-wise contrastive loss can directly be interpreted as an anomaly score,\nand how this allows for the creation of anomaly segmentation masks. The\nresulting model achieves promising results for both anomaly detection and\nsegmentation on the challenging MVTec-AD dataset.",
          "link": "http://arxiv.org/abs/2107.07820",
          "publishedOn": "2021-07-19T00:49:06.129Z",
          "wordCount": 583,
          "title": "Contrastive Predictive Coding for Anomaly Detection. (arXiv:2107.07820v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07805",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qaiser_T/0/1/0/all/0/1\">Talha Qaiser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Winzeck_S/0/1/0/all/0/1\">Stefan Winzeck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barfoot_T/0/1/0/all/0/1\">Theodore Barfoot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barwick_T/0/1/0/all/0/1\">Tara Barwick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doran_S/0/1/0/all/0/1\">Simon J. Doran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaiser_M/0/1/0/all/0/1\">Martin F. Kaiser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wedlake_L/0/1/0/all/0/1\">Linda Wedlake</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tunariu_N/0/1/0/all/0/1\">Nina Tunariu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koh_D/0/1/0/all/0/1\">Dow-Mu Koh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Messiou_C/0/1/0/all/0/1\">Christina Messiou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rockall_A/0/1/0/all/0/1\">Andrea Rockall</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glocker_B/0/1/0/all/0/1\">Ben Glocker</a>",
          "description": "Whole body magnetic resonance imaging (WB-MRI) is the recommended modality\nfor diagnosis of multiple myeloma (MM). WB-MRI is used to detect sites of\ndisease across the entire skeletal system, but it requires significant\nexpertise and is time-consuming to report due to the great number of images. To\naid radiological reading, we propose an auxiliary task-based multiple instance\nlearning approach (ATMIL) for MM classification with the ability to localize\nsites of disease. This approach is appealing as it only requires patient-level\nannotations where an attention mechanism is used to identify local regions with\nactive disease. We borrow ideas from multi-task learning and define an\nauxiliary task with adaptive reweighting to support and improve learning\nefficiency in the presence of data scarcity. We validate our approach on both\nsynthetic and real multi-center clinical data. We show that the MIL attention\nmodule provides a mechanism to localize bone regions while the adaptive\nreweighting of the auxiliary task considerably improves the performance.",
          "link": "http://arxiv.org/abs/2107.07805",
          "publishedOn": "2021-07-19T00:49:06.122Z",
          "wordCount": 623,
          "title": "Multiple Instance Learning with Auxiliary Task Weighting for Multiple Myeloma Classification. (arXiv:2107.07805v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07752",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Cognolato_F/0/1/0/all/0/1\">Francesco Cognolato</a>, <a href=\"http://arxiv.org/find/eess/1/au:+OBrien_K/0/1/0/all/0/1\">Kieran O&#x27;Brien</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jin_J/0/1/0/all/0/1\">Jin Jin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Robinson_S/0/1/0/all/0/1\">Simon Robinson</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Laun_F/0/1/0/all/0/1\">Frederik B. Laun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Barth_M/0/1/0/all/0/1\">Markus Barth</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bollmann_S/0/1/0/all/0/1\">Steffen Bollmann</a>",
          "description": "Deep learning based Quantitative Susceptibility Mapping (QSM) has shown great\npotential in recent years, outperforming traditional non-learning approaches in\nspeed and accuracy. However, many of the current deep learning approaches are\nnot data consistent, require in vivo training data or do not solve all steps of\nthe QSM processing pipeline. Here we aim to overcome these limitations and\ndeveloped a framework to solve the QSM processing steps jointly. We developed a\nnew hybrid training data generation method that enables the end-to-end training\nfor solving background field correction and dipole inversion in a\ndata-consistent fashion using a variational network that combines the QSM model\nterm and a learned regularizer. We demonstrate that NeXtQSM overcomes the\nlimitations of previous model-agnostic deep learning methods and show that\nNeXtQSM offers a complete deep learning based pipeline for computing robust,\nfast and accurate quantitative susceptibility maps.",
          "link": "http://arxiv.org/abs/2107.07752",
          "publishedOn": "2021-07-19T00:49:06.107Z",
          "wordCount": 613,
          "title": "NeXtQSM -- A complete deep learning pipeline for data-consistent quantitative susceptibility mapping trained with hybrid data. (arXiv:2107.07752v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07761",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Mascolini_A/0/1/0/all/0/1\">Alessio Mascolini</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cardamone_D/0/1/0/all/0/1\">Dario Cardamone</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ponzio_F/0/1/0/all/0/1\">Francesco Ponzio</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cataldo_S/0/1/0/all/0/1\">Santa Di Cataldo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ficarra_E/0/1/0/all/0/1\">Elisa Ficarra</a>",
          "description": "Computer-aided analysis of biological images typically requires extensive\ntraining on large-scale annotated datasets, which is not viable in many\nsituations. In this paper we present GAN-DL, a Discriminator Learner based on\nthe StyleGAN2 architecture, which we employ for self-supervised image\nrepresentation learning in the case of fluorescent biological images. We show\nthat Wasserstein Generative Adversarial Networks combined with linear Support\nVector Machines enable high-throughput compound screening based on raw images.\nWe demonstrate this by classifying active and inactive compounds tested for the\ninhibition of SARS-CoV-2 infection in VERO and HRCE cell lines. In contrast to\nprevious methods, our deep learning based approach does not require any\nannotation besides the one that is normally collected during the sample\npreparation process. We test our technique on the RxRx19a Sars-CoV-2 image\ncollection. The dataset consists of fluorescent images that were generated to\nassess the ability of regulatory-approved or in late-stage clinical trials\ncompound to modulate the in vitro infection from SARS-CoV-2 in both VERO and\nHRCE cell lines. We show that our technique can be exploited not only for\nclassification tasks, but also to effectively derive a dose response curve for\nthe tested treatments, in a self-supervised manner. Lastly, we demonstrate its\ngeneralization capabilities by successfully addressing a zero-shot learning\ntask, consisting in the categorization of four different cell types of the\nRxRx1 fluorescent images collection.",
          "link": "http://arxiv.org/abs/2107.07761",
          "publishedOn": "2021-07-19T00:49:06.096Z",
          "wordCount": 733,
          "title": "Exploiting generative self-supervised learning for the assessment of biological images with lack of annotations: a COVID-19 case-study. (arXiv:2107.07761v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07714",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Lavrik_E/0/1/0/all/0/1\">E. Lavrik</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Shiroya_M/0/1/0/all/0/1\">M. Shiroya</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Schmidt_H/0/1/0/all/0/1\">H.R. Schmidt</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Toia_A/0/1/0/all/0/1\">A. Toia</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Heuser_J/0/1/0/all/0/1\">J.M. Heuser</a>",
          "description": "Optical inspection of 1191 silicon micro-strip sensors was performed using a\ncustom made optical inspection setup, employing a machine-learning based\napproach for the defect analysis and subsequent quality assurance. Furthermore,\nmetrological control of the sensor's surface was performed. In this manuscript,\nwe present the analysis of various sensor surface defects. Among these are\nimplant breaks, p-stop breaks, aluminium strip opens, aluminium strip shorts,\nsurface scratches, double metallization layer defects, passivation layer\ndefects, bias resistor defects as well as dust particle identification. The\ndefect detection was done using the application of Convolutional Deep Neural\nNetworks (CDNNs). From this, defective strips and defect clusters were\nidentified, as well as a 2D map of the defects using their geometrical\npositions on the sensor was performed. Based on the total number of defects\nfound on the sensor's surface, a method for the estimation of sensor's overall\nquality grade and quality score was proposed.",
          "link": "http://arxiv.org/abs/2107.07714",
          "publishedOn": "2021-07-19T00:49:06.076Z",
          "wordCount": 610,
          "title": "Optical Inspection of the Silicon Micro-strip Sensors for the CBM Experiment employing Artificial Intelligence. (arXiv:2107.07714v1 [physics.ins-det])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07791",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gharaee_Z/0/1/0/all/0/1\">Zahra Gharaee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kowshik_S/0/1/0/all/0/1\">Shreyas Kowshik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stromann_O/0/1/0/all/0/1\">Oliver Stromann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Felsberg_M/0/1/0/all/0/1\">Michael Felsberg</a>",
          "description": "We present a novel learning-based approach to graph representations of road\nnetworks employing state-of-the-art graph convolutional neural networks. Our\napproach is applied to realistic road networks of 17 cities from Open Street\nMap. While edge features are crucial to generate descriptive graph\nrepresentations of road networks, graph convolutional networks usually rely on\nnode features only. We show that the highly representative edge features can\nstill be integrated into such networks by applying a line graph transformation.\nWe also propose a method for neighborhood sampling based on a topological\nneighborhood composed of both local and global neighbors. We compare the\nperformance of learning representations using different types of neighborhood\naggregation functions in transductive and inductive tasks and in supervised and\nunsupervised learning. Furthermore, we propose a novel aggregation approach,\nGraph Attention Isomorphism Network, GAIN. Our results show that GAIN\noutperforms state-of-the-art methods on the road type classification problem.",
          "link": "http://arxiv.org/abs/2107.07791",
          "publishedOn": "2021-07-19T00:49:06.068Z",
          "wordCount": 587,
          "title": "Graph Representation Learning for Road Type Classification. (arXiv:2107.07791v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07695",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahn_E/0/1/0/all/0/1\">Euijoon Ahn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jinman Kim</a>",
          "description": "Recent supervised deep learning methods have shown that heart rate can be\nmeasured remotely using facial videos. However, the performance of these\nsupervised method are dependent on the availability of large-scale labelled\ndata and they have been limited to 2D deep learning architectures that do not\nfully exploit the 3D spatiotemporal information. To solve this problem, we\npresent a novel 3D self-supervised spatiotemporal learning framework for remote\nHR estimation on facial videos. Concretely, we propose a landmark-based spatial\naugmentation which splits the face into several informative parts based on the\nShafer's dichromatic reflection model and a novel sparsity-based temporal\naugmentation exploiting Nyquist-Shannon sampling theorem to enhance the signal\nmodelling ability. We evaluated our method on 3 public datasets and\noutperformed other self-supervised methods and achieved competitive accuracy\nwith the state-of-the-art supervised methods.",
          "link": "http://arxiv.org/abs/2107.07695",
          "publishedOn": "2021-07-19T00:49:06.044Z",
          "wordCount": 572,
          "title": "Self-Supervised Learning Framework for Remote Heart Rate Estimation Using Spatiotemporal Augmentation. (arXiv:2107.07695v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07707",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1\">Ming Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fischer_T/0/1/0/all/0/1\">Tobias Fischer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sunderhauf_N/0/1/0/all/0/1\">Niko S&#xfc;nderhauf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Milford_M/0/1/0/all/0/1\">Michael Milford</a>",
          "description": "Probabilistic state-estimation approaches offer a principled foundation for\ndesigning localization systems, because they naturally integrate sequences of\nimperfect motion and exteroceptive sensor data. Recently, probabilistic\nlocalization systems utilizing appearance-invariant visual place recognition\n(VPR) methods as the primary exteroceptive sensor have demonstrated\nstate-of-the-art performance in the presence of substantial appearance change.\nHowever, existing systems 1) do not fully utilize odometry data within the\nmotion models, and 2) are unable to handle route deviations, due to the\nassumption that query traverses exactly repeat the mapping traverse. To address\nthese shortcomings, we present a new probabilistic topometric localization\nsystem which incorporates full 3-dof odometry into the motion model and\nfurthermore, adds an \"off-map\" state within the state-estimation framework,\nallowing query traverses which feature significant route detours from the\nreference map to be successfully localized. We perform extensive evaluation on\nmultiple query traverses from the Oxford RobotCar dataset exhibiting both\nsignificant appearance change and deviations from routes previously traversed.\nIn particular, we evaluate performance on two practically relevant localization\ntasks: loop closure detection and global localization. Our approach achieves\nmajor performance improvements over both existing and improved state-of-the-art\nsystems.",
          "link": "http://arxiv.org/abs/2107.07707",
          "publishedOn": "2021-07-19T00:49:06.038Z",
          "wordCount": 634,
          "title": "Probabilistic Appearance-Invariant Topometric Localization with New Place Awareness. (arXiv:2107.07707v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07706",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chaojian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wuyang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1\">Yuchen Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tianlong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1\">Yonggan Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhangyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yingyan Lin</a>",
          "description": "Semantic segmentation for scene understanding is nowadays widely demanded,\nraising significant challenges for the algorithm efficiency, especially its\napplications on resource-limited platforms. Current segmentation models are\ntrained and evaluated on massive high-resolution scene images (\"data level\")\nand suffer from the expensive computation arising from the required multi-scale\naggregation(\"network level\"). In both folds, the computational and energy costs\nin training and inference are notable due to the often desired large input\nresolutions and heavy computational burden of segmentation models. To this end,\nwe propose DANCE, general automated DAta-Network Co-optimization for Efficient\nsegmentation model training and inference. Distinct from existing efficient\nsegmentation approaches that focus merely on light-weight network design, DANCE\ndistinguishes itself as an automated simultaneous data-network co-optimization\nvia both input data manipulation and network architecture slimming.\nSpecifically, DANCE integrates automated data slimming which adaptively\ndownsamples/drops input images and controls their corresponding contribution to\nthe training loss guided by the images' spatial complexity. Such a downsampling\noperation, in addition to slimming down the cost associated with the input size\ndirectly, also shrinks the dynamic range of input object and context scales,\ntherefore motivating us to also adaptively slim the network to match the\ndownsampled data. Extensive experiments and ablating studies (on four SOTA\nsegmentation models with three popular segmentation datasets under two training\nsettings) demonstrate that DANCE can achieve \"all-win\" towards efficient\nsegmentation(reduced training cost, less expensive inference, and better mean\nIntersection-over-Union (mIoU)).",
          "link": "http://arxiv.org/abs/2107.07706",
          "publishedOn": "2021-07-19T00:49:06.031Z",
          "wordCount": 687,
          "title": "DANCE: DAta-Network Co-optimization for Efficient Segmentation Model Training and Inference. (arXiv:2107.07706v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07578",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Patel_M/0/1/0/all/0/1\">Mann Patel</a>",
          "description": "Violence rates however have been brought down about 57% during the span of\nthe past 4 decades yet it doesn't change the way that the demonstration of\nviolence actually happens, unseen by the law. Violence can be mass controlled\nsometimes by higher authorities, however, to hold everything in line one must\n\"Microgovern\" over each movement occurring in every road of each square. To\naddress the butterfly effects impact in our setting, I made a unique model and\na theorized system to handle the issue utilizing deep learning. The model takes\nthe input of the CCTV video feeds and after drawing inference, recognizes if a\nviolent movement is going on. And hypothesized architecture aims towards\nprobability-driven computation of video feeds and reduces overhead from naively\ncomputing for every CCTV video feeds.",
          "link": "http://arxiv.org/abs/2107.07578",
          "publishedOn": "2021-07-19T00:49:06.004Z",
          "wordCount": 561,
          "title": "Real-Time Violence Detection Using CNN-LSTM. (arXiv:2107.07578v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07596",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Lo_C/0/1/0/all/0/1\">Chen-Chou Lo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Vandewalle_P/0/1/0/all/0/1\">Patrick Vandewalle</a>",
          "description": "We integrate sparse radar data into a monocular depth estimation model and\nintroduce a novel preprocessing method for reducing the sparseness and limited\nfield of view provided by radar. We explore the intrinsic error of different\nradar modalities and show our proposed method results in more data points with\nreduced error. We further propose a novel method for estimating dense depth\nmaps from monocular 2D images and sparse radar measurements using deep learning\nbased on the deep ordinal regression network by Fu et al. Radar data are\nintegrated by first converting the sparse 2D points to a height-extended 3D\nmeasurement and then including it into the network using a late fusion\napproach. Experiments are conducted on the nuScenes dataset. Our experiments\ndemonstrate state-of-the-art performance in both day and night scenes.",
          "link": "http://arxiv.org/abs/2107.07596",
          "publishedOn": "2021-07-19T00:49:05.988Z",
          "wordCount": 593,
          "title": "Depth Estimation from Monocular Images and Sparse radar using Deep Ordinal Regression Network. (arXiv:2107.07596v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07557",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ramachandran_S/0/1/0/all/0/1\">Saravanabalagi Ramachandran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McDonald_J/0/1/0/all/0/1\">John McDonald</a>",
          "description": "OdoViz is a reactive web-based tool for 3D visualization and processing of\nautonomous vehicle datasets designed to support common tasks in visual place\nrecognition research. The system includes functionality for loading,\ninspecting, visualizing, and processing GPS/INS poses, point clouds and camera\nimages. It supports a number of commonly used driving datasets and can be\nadapted to load custom datasets with minimal effort. OdoViz's design consists\nof a slim server to serve the datasets coupled with a rich client frontend.\nThis design supports multiple deployment configurations including single user\nstand-alone installations, research group installations serving datasets\ninternally across a lab, or publicly accessible web-frontends for providing\nonline interfaces for exploring and interacting with datasets. The tool allows\nviewing complete vehicle trajectories traversed at multiple different time\nperiods simultaneously, facilitating tasks such as sub-sampling, comparing and\nfinding pose correspondences both across and within sequences. This\nsignificantly reduces the effort required in creating subsets of data from\nexisting datasets for machine learning tasks. Further to the above, the system\nalso supports adding custom extensions and plugins to extend the capabilities\nof the software for other potential data management, visualization and\nprocessing tasks. The platform has been open-sourced to promote its use and\nencourage further contributions from the research community.",
          "link": "http://arxiv.org/abs/2107.07557",
          "publishedOn": "2021-07-19T00:49:05.971Z",
          "wordCount": 644,
          "title": "OdoViz: A 3D Odometry Visualization and Processing Tool. (arXiv:2107.07557v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07676",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Z/0/1/0/all/0/1\">Zida Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Siheng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Ya Zhang</a>",
          "description": "3D hand-object pose estimation is an important issue to understand the\ninteraction between human and environment. Current hand-object pose estimation\nmethods require detailed 3D labels, which are expensive and labor-intensive. To\ntackle the problem of data collection, we propose a semi-supervised 3D\nhand-object pose estimation method with two key techniques: pose dictionary\nlearning and an object-oriented coordinate system. The proposed pose dictionary\nlearning module can distinguish infeasible poses by reconstruction error,\nenabling unlabeled data to provide supervision signals. The proposed\nobject-oriented coordinate system can make 3D estimations equivariant to the\ncamera perspective. Experiments are conducted on FPHA and HO-3D datasets. Our\nmethod reduces estimation error by 19.5% / 24.9% for hands/objects compared to\nstraightforward use of labeled data on FPHA and outperforms several baseline\nmethods. Extensive experiments also validate the robustness of the proposed\nmethod.",
          "link": "http://arxiv.org/abs/2107.07676",
          "publishedOn": "2021-07-19T00:49:05.963Z",
          "wordCount": 571,
          "title": "Semi-supervised 3D Hand-Object Pose Estimation via Pose Dictionary Learning. (arXiv:2107.07676v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07647",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Colbert_I/0/1/0/all/0/1\">Ian Colbert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kreutz_Delgado_K/0/1/0/all/0/1\">Ken Kreutz-Delgado</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1\">Srinjoy Das</a>",
          "description": "A novel energy-efficient edge computing paradigm is proposed for real-time\ndeep learning-based image upsampling applications. State-of-the-art deep\nlearning solutions for image upsampling are currently trained using either\nresize or sub-pixel convolution to learn kernels that generate high fidelity\nimages with minimal artifacts. However, performing inference with these learned\nconvolution kernels requires memory-intensive feature map transformations that\ndominate time and energy costs in real-time applications. To alleviate this\npressure on memory bandwidth, we confine the use of resize or sub-pixel\nconvolution to training in the cloud by transforming learned convolution\nkernels to deconvolution kernels before deploying them for inference as a\nfunctionally equivalent deconvolution. These kernel transformations, intended\nas a one-time cost when shifting from training to inference, enable a systems\ndesigner to use each algorithm in their optimal context by preserving the image\nfidelity learned when training in the cloud while minimizing data transfer\npenalties during inference at the edge. We also explore existing variants of\ndeconvolution inference algorithms and introduce a novel variant for\nconsideration. We analyze and compare the inference properties of\nconvolution-based upsampling algorithms using a quantitative model of incurred\ntime and energy costs and show that using deconvolution for inference at the\nedge improves both system latency and energy efficiency when compared to their\nsub-pixel or resize convolution counterparts.",
          "link": "http://arxiv.org/abs/2107.07647",
          "publishedOn": "2021-07-19T00:49:05.921Z",
          "wordCount": 664,
          "title": "An Energy-Efficient Edge Computing Paradigm for Convolution-based Image Upsampling. (arXiv:2107.07647v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07576",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Irbaz_M/0/1/0/all/0/1\">Mohammad Sabik Irbaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nasim_M/0/1/0/all/0/1\">MD Abdullah Al Nasim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferdous_R/0/1/0/all/0/1\">Refat E Ferdous</a>",
          "description": "During the COVID-19 pandemic, most of the human-to-human interactions have\nbeen stopped. To mitigate the spread of deadly coronavirus, many offices took\nthe initiative so that the employees can work from home. But, tracking the\nemployees and finding out if they are really performing what they were supposed\nto turn out to be a serious challenge for all the companies and organizations\nwho are facilitating \"Work From Home\". To deal with the challenge effectively,\nwe came up with a solution to track the employees with face recognition. We\nhave been testing this system experimentally for our office. To train the face\nrecognition module, we used FaceNet with KNN using the Labeled Faces in the\nWild (LFW) dataset and achieved 97.8% accuracy. We integrated the trained model\ninto our central system, where the employees log their time. In this paper, we\ndiscuss in brief the system we have been experimenting with and the pros and\ncons of the system.",
          "link": "http://arxiv.org/abs/2107.07576",
          "publishedOn": "2021-07-19T00:49:05.915Z",
          "wordCount": 666,
          "title": "Real-Time Face Recognition System for Remote Employee Tracking. (arXiv:2107.07576v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07608",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qing Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jian Zhang</a>",
          "description": "Contrastive learning is a discriminative approach that aims at grouping\nsimilar samples closer and diverse samples far from each other. It it an\nefficient technique to train an encoder generating distinguishable and\ninformative representations, and it may even increase the encoder's\ntransferability. Most current applications of contrastive learning benefit only\na single representation from the last layer of an encoder.In this paper, we\npropose a multi-level contrasitive learning approach which applies contrastive\nlosses at different layers of an encoder to learn multiple representations from\nthe encoder. Afterward, an ensemble can be constructed to take advantage of the\nmultiple representations for the downstream tasks. We evaluated the proposed\nmethod on few-shot learning problems and conducted experiments using the\nmini-ImageNet and the tiered-ImageNet datasets. Our model achieved the new\nstate-of-the-art results for both datasets, comparing to previous regular,\nensemble, and contrastive learing (single-level) based approaches.",
          "link": "http://arxiv.org/abs/2107.07608",
          "publishedOn": "2021-07-19T00:49:05.614Z",
          "wordCount": 572,
          "title": "Multi-Level Contrastive Learning for Few-Shot Problems. (arXiv:2107.07608v1 [cs.CV])"
        }
      ]
    },
    {
      "title": "cs.LG updates on arXiv.org",
      "feedUrl": "http://export.arxiv.org/rss/cs.LG",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2107.09735",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mizrahi_I/0/1/0/all/0/1\">Itzik Mizrahi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Avidan_S/0/1/0/all/0/1\">Shai Avidan</a>",
          "description": "Deep Neural Networks require large amounts of labeled data for their\ntraining. Collecting this data at scale inevitably causes label noise.Hence,the\nneed to develop learning algorithms that are robust to label noise. In recent\nyears, k Nearest Neighbors (kNN) emerged as a viable solution to this problem.\nDespite its success, kNN is not without its problems. Mainly, it requires a\nhuge memory footprint to store all the training samples and it needs an\nadvanced data structure to allow for fast retrieval of the relevant examples,\ngiven a query sample. We propose a neural network, termed kNet, that learns to\nperform kNN. Once trained, we no longer need to store the training data, and\nprocessing a query sample is a simple matter of inference. To use kNet, we\nfirst train a preliminary network on the data set, and then train kNet on the\npenultimate layer of the preliminary network.We find that kNet gives a smooth\napproximation of kNN,and cannot handle the sharp label changes between samples\nthat kNN can exhibit. This indicates that currently kNet is best suited to\napproximate kNN with a fairly large k. Experiments on two data sets show that\nthis is the regime in which kNN works best,and can therefore be replaced by\nkNet.In practice, kNet consistently improve the results of all preliminary\nnetworks, in all label noise regimes, by up to 3%.",
          "link": "http://arxiv.org/abs/2107.09735",
          "publishedOn": "2021-07-22T02:03:13.021Z",
          "wordCount": 662,
          "title": "kNet: A Deep kNN Network To Handle Label Noise. (arXiv:2107.09735v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2002.04225",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1\">Jason Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_S/0/1/0/all/0/1\">Santiago Gonzalez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shahrzad_H/0/1/0/all/0/1\">Hormoz Shahrzad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miikkulainen_R/0/1/0/all/0/1\">Risto Miikkulainen</a>",
          "description": "Metalearning of deep neural network (DNN) architectures and hyperparameters\nhas become an increasingly important area of research. At the same time,\nnetwork regularization has been recognized as a crucial dimension to effective\ntraining of DNNs. However, the role of metalearning in establishing effective\nregularization has not yet been fully explored. There is recent evidence that\nloss-function optimization could play this role, however it is computationally\nimpractical as an outer loop to full training. This paper presents an algorithm\ncalled Evolutionary Population-Based Training (EPBT) that interleaves the\ntraining of a DNN's weights with the metalearning of loss functions. They are\nparameterized using multivariate Taylor expansions that EPBT can directly\noptimize. Such simultaneous adaptation of weights and loss functions can be\ndeceptive, and therefore EPBT uses a quality-diversity heuristic called Novelty\nPulsation as well as knowledge distillation to prevent overfitting during\ntraining. On the CIFAR-10 and SVHN image classification benchmarks, EPBT\nresults in faster, more accurate learning. The discovered hyperparameters adapt\nto the training process and serve to regularize the learning task by\ndiscouraging overfitting to the labels. EPBT thus demonstrates a practical\ninstantiation of regularization metalearning based on simultaneous training.",
          "link": "http://arxiv.org/abs/2002.04225",
          "publishedOn": "2021-07-22T02:03:13.014Z",
          "wordCount": 666,
          "title": "Regularized Evolutionary Population-Based Training. (arXiv:2002.04225v4 [cs.NE] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.09927",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dikopoulou_Z/0/1/0/all/0/1\">Zoumpolia Dikopoulou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moustakidis_S/0/1/0/all/0/1\">Serafeim Moustakidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karlsson_P/0/1/0/all/0/1\">Patrik Karlsson</a>",
          "description": "Explainable artificial intelligence (XAI) is an emerging new domain in which\na set of processes and tools allow humans to better comprehend the decisions\ngenerated by black box models. However, most of the available XAI tools are\noften limited to simple explanations mainly quantifying the impact of\nindividual features to the models' output. Therefore, human users are not able\nto understand how the features are related to each other to make predictions,\nwhereas the inner workings of the trained models remain hidden. This paper\ncontributes to the development of a novel graphical explainability tool that\nnot only indicates the significant features of the model but also reveals the\nconditional relationships between features and the inference capturing both the\ndirect and indirect impact of features to the models' decision. The proposed\nXAI methodology, termed as gLIME, provides graphical model-agnostic\nexplanations either at the global (for the entire dataset) or the local scale\n(for specific data points). It relies on a combination of local interpretable\nmodel-agnostic explanations (LIME) with graphical least absolute shrinkage and\nselection operator (GLASSO) producing undirected Gaussian graphical models.\nRegularization is adopted to shrink small partial correlation coefficients to\nzero providing sparser and more interpretable graphical explanations. Two\nwell-known classification datasets (BIOPSY and OAI) were selected to confirm\nthe superiority of gLIME over LIME in terms of both robustness and consistency\nover multiple permutations. Specifically, gLIME accomplished increased\nstability over the two datasets with respect to features' importance (76%-96%\ncompared to 52%-77% using LIME). gLIME demonstrates a unique potential to\nextend the functionality of the current state-of-the-art in XAI by providing\ninformative graphically given explanations that could unlock black boxes.",
          "link": "http://arxiv.org/abs/2107.09927",
          "publishedOn": "2021-07-22T02:03:12.993Z",
          "wordCount": 700,
          "title": "GLIME: A new graphical methodology for interpretable model-agnostic explanations. (arXiv:2107.09927v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.01009",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yiqiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1\">Wang Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jindong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_X/0/1/0/all/0/1\">Xin Qin</a>",
          "description": "The success of machine learning applications often needs a large quantity of\ndata. Recently, federated learning (FL) is attracting increasing attention due\nto the demand for data privacy and security, especially in the medical field.\nHowever, the performance of existing FL approaches often deteriorates when\nthere exist domain shifts among clients, and few previous works focus on\npersonalization in healthcare. In this article, we propose FedHealth 2, an\nextension of FedHealth \\cite{chen2020fedhealth} to tackle domain shifts and get\npersonalized models for local clients. FedHealth 2 obtains the client\nsimilarities via a pretrained model, and then it averages all weighted models\nwith preserving local batch normalization. Wearable activity recognition and\nCOVID-19 auxiliary diagnosis experiments have evaluated that FedHealth 2 can\nachieve better accuracy (10%+ improvement for activity recognition) and\npersonalized healthcare without compromising privacy and security.",
          "link": "http://arxiv.org/abs/2106.01009",
          "publishedOn": "2021-07-22T02:03:12.987Z",
          "wordCount": 657,
          "title": "FedHealth 2: Weighted Federated Transfer Learning via Batch Normalization for Personalized Healthcare. (arXiv:2106.01009v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.10066",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Galy_Fajou_T/0/1/0/all/0/1\">Th&#xe9;o Galy-Fajou</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Opper_M/0/1/0/all/0/1\">Manfred Opper</a>",
          "description": "Gaussian Processes (\\textbf{GPs}) are flexible non-parametric models with\nstrong probabilistic interpretation. While being a standard choice for\nperforming inference on time series, GPs have few techniques to work in a\nstreaming setting. \\cite{bui2017streaming} developed an efficient variational\napproach to train online GPs by using sparsity techniques: The whole set of\nobservations is approximated by a smaller set of inducing points (\\textbf{IPs})\nand moved around with new data. Both the number and the locations of the IPs\nwill affect greatly the performance of the algorithm. In addition to optimizing\ntheir locations, we propose to adaptively add new points, based on the\nproperties of the GP and the structure of the data.",
          "link": "http://arxiv.org/abs/2107.10066",
          "publishedOn": "2021-07-22T02:03:12.980Z",
          "wordCount": 550,
          "title": "Adaptive Inducing Points Selection For Gaussian Processes. (arXiv:2107.10066v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2107.10211",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_G/0/1/0/all/0/1\">Guodong Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hsu_K/0/1/0/all/0/1\">Kyle Hsu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_J/0/1/0/all/0/1\">Jianing Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Finn_C/0/1/0/all/0/1\">Chelsea Finn</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Grosse_R/0/1/0/all/0/1\">Roger Grosse</a>",
          "description": "Annealed importance sampling (AIS) and related algorithms are highly\neffective tools for marginal likelihood estimation, but are not fully\ndifferentiable due to the use of Metropolis-Hastings (MH) correction steps.\nDifferentiability is a desirable property as it would admit the possibility of\noptimizing marginal likelihood as an objective using gradient-based methods. To\nthis end, we propose a differentiable AIS algorithm by abandoning MH steps,\nwhich further unlocks mini-batch computation. We provide a detailed convergence\nanalysis for Bayesian linear regression which goes beyond previous analyses by\nexplicitly accounting for non-perfect transitions. Using this analysis, we\nprove that our algorithm is consistent in the full-batch setting and provide a\nsublinear convergence rate. However, we show that the algorithm is inconsistent\nwhen mini-batch gradients are used due to a fundamental incompatibility between\nthe goals of last-iterate convergence to the posterior and elimination of the\npathwise stochastic error. This result is in stark contrast to our experience\nwith stochastic optimization and stochastic gradient Langevin dynamics, where\nthe effects of gradient noise can be washed out by taking more steps of a\nsmaller size. Our negative result relies crucially on our explicit\nconsideration of convergence to the stationary distribution, and it helps\nexplain the difficulty of developing practically effective AIS-like algorithms\nthat exploit mini-batch gradients.",
          "link": "http://arxiv.org/abs/2107.10211",
          "publishedOn": "2021-07-22T02:03:12.972Z",
          "wordCount": 652,
          "title": "Differentiable Annealed Importance Sampling and the Perils of Gradient Noise. (arXiv:2107.10211v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2004.05867",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Wei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_W/0/1/0/all/0/1\">Weitao Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">Richard Yi Da Xu</a>",
          "description": "The prevailing thinking is that orthogonal weights are crucial to enforcing\ndynamical isometry and speeding up training. The increase in learning speed\nthat results from orthogonal initialization in linear networks has been\nwell-proven. However, while the same is believed to also hold for nonlinear\nnetworks when the dynamical isometry condition is satisfied, the training\ndynamics behind this contention have not been thoroughly explored. In this\nwork, we study the dynamics of ultra-wide networks across a range of\narchitectures, including Fully Connected Networks (FCNs) and Convolutional\nNeural Networks (CNNs) with orthogonal initialization via neural tangent kernel\n(NTK). Through a series of propositions and lemmas, we prove that two NTKs, one\ncorresponding to Gaussian weights and one to orthogonal weights, are equal when\nthe network width is infinite. Further, during training, the NTK of an\northogonally-initialized infinite-width network should theoretically remain\nconstant. This suggests that the orthogonal initialization cannot speed up\ntraining in the NTK (lazy training) regime, contrary to the prevailing\nthoughts. In order to explore under what circumstances can orthogonality\naccelerate training, we conduct a thorough empirical investigation outside the\nNTK regime. We find that when the hyper-parameters are set to achieve a linear\nregime in nonlinear activation, orthogonal initialization can improve the\nlearning speed with a large learning rate or large depth.",
          "link": "http://arxiv.org/abs/2004.05867",
          "publishedOn": "2021-07-22T02:03:12.966Z",
          "wordCount": 711,
          "title": "On the Neural Tangent Kernel of Deep Networks with Orthogonal Initialization. (arXiv:2004.05867v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.00515",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Rudner_T/0/1/0/all/0/1\">Tim G. J. Rudner</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Key_O/0/1/0/all/0/1\">Oscar Key</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gal_Y/0/1/0/all/0/1\">Yarin Gal</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rainforth_T/0/1/0/all/0/1\">Tom Rainforth</a>",
          "description": "We show that the gradient estimates used in training Deep Gaussian Processes\n(DGPs) with importance-weighted variational inference are susceptible to\nsignal-to-noise ratio (SNR) issues. Specifically, we show both theoretically\nand via an extensive empirical evaluation that the SNR of the gradient\nestimates for the latent variable's variational parameters decreases as the\nnumber of importance samples increases. As a result, these gradient estimates\ndegrade to pure noise if the number of importance samples is too large. To\naddress this pathology, we show how doubly reparameterized gradient estimators,\noriginally proposed for training variational autoencoders, can be adapted to\nthe DGP setting and that the resultant estimators completely remedy the SNR\nissue, thereby providing more reliable training. Finally, we demonstrate that\nour fix can lead to consistent improvements in the predictive performance of\nDGP models.",
          "link": "http://arxiv.org/abs/2011.00515",
          "publishedOn": "2021-07-22T02:03:12.958Z",
          "wordCount": 614,
          "title": "On Signal-to-Noise Ratio Issues in Variational Inference for Deep Gaussian Processes. (arXiv:2011.00515v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.10072",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gong_W/0/1/0/all/0/1\">Wenbo Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yingzhen Li</a>",
          "description": "Scoring matching (SM), and its related counterpart, Stein discrepancy (SD)\nhave achieved great success in model training and evaluations. However, recent\nresearch shows their limitations when dealing with certain types of\ndistributions. One possible fix is incorporating the original score matching\n(or Stein discrepancy) with a diffusion matrix, which is called diffusion score\nmatching (DSM) (or diffusion Stein discrepancy (DSD)). However, the lack of\ninterpretation of the diffusion limits its usage within simple distributions\nand manually chosen matrix. In this work, we plan to fill this gap by\ninterpreting the diffusion matrix using normalizing flows. Specifically, we\ntheoretically prove that DSM (or DSD) is equivalent to the original score\nmatching (or Stein discrepancy) evaluated in the transformed space defined by\nthe normalizing flow, where the diffusion matrix is the inverse of the flow's\nJacobian matrix. In addition, we also build its connection to Riemannian\nmanifolds and further extend it to continuous flows, where the change of DSM is\ncharacterized by an ODE.",
          "link": "http://arxiv.org/abs/2107.10072",
          "publishedOn": "2021-07-22T02:03:12.952Z",
          "wordCount": 604,
          "title": "Interpreting diffusion score matching using normalizing flow. (arXiv:2107.10072v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09951",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_F/0/1/0/all/0/1\">Feng Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1\">Han Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ning_Y/0/1/0/all/0/1\">Yilin Ning</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ong_M/0/1/0/all/0/1\">Marcus Eng Hock Ong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_M/0/1/0/all/0/1\">Mengling Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsu_W/0/1/0/all/0/1\">Wynne Hsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_B/0/1/0/all/0/1\">Bibhas Chakraborty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1\">Nan Liu</a>",
          "description": "Objective: Temporal electronic health records (EHRs) can be a wealth of\ninformation for secondary uses, such as clinical events prediction or chronic\ndisease management. However, challenges exist for temporal data representation.\nWe therefore sought to identify these challenges and evaluate novel\nmethodologies for addressing them through a systematic examination of deep\nlearning solutions.\n\nMethods: We searched five databases (PubMed, EMBASE, the Institute of\nElectrical and Electronics Engineers [IEEE] Xplore Digital Library, the\nAssociation for Computing Machinery [ACM] digital library, and Web of Science)\ncomplemented with hand-searching in several prestigious computer science\nconference proceedings. We sought articles that reported deep learning\nmethodologies on temporal data representation in structured EHR data from\nJanuary 1, 2010, to August 30, 2020. We summarized and analyzed the selected\narticles from three perspectives: nature of time series, methodology, and model\nimplementation.\n\nResults: We included 98 articles related to temporal data representation\nusing deep learning. Four major challenges were identified, including data\nirregularity, data heterogeneity, data sparsity, and model opacity. We then\nstudied how deep learning techniques were applied to address these challenges.\nFinally, we discuss some open challenges arising from deep learning.\n\nConclusion: Temporal EHR data present several major challenges for clinical\nprediction modeling and data utilization. To some extent, current deep learning\nsolutions can address these challenges. Future studies can consider designing\ncomprehensive and integrated solutions. Moreover, researchers should\nincorporate additional clinical domain knowledge into study designs and enhance\nthe interpretability of the model to facilitate its implementation in clinical\npractice.",
          "link": "http://arxiv.org/abs/2107.09951",
          "publishedOn": "2021-07-22T02:03:12.945Z",
          "wordCount": 702,
          "title": "Deep learning for temporal data representation in electronic health records: A systematic review of challenges and methodologies. (arXiv:2107.09951v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09767",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_C/0/1/0/all/0/1\">Chun Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sindhgatta_R/0/1/0/all/0/1\">Renuka Sindhgatta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moreira_C/0/1/0/all/0/1\">Catarina Moreira</a>",
          "description": "Modern data analytics underpinned by machine learning techniques has become a\nkey enabler to the automation of data-led decision making. As an important\nbranch of state-of-the-art data analytics, business process predictions are\nalso faced with a challenge in regard to the lack of explanation to the\nreasoning and decision by the underlying `black-box' prediction models. With\nthe development of interpretable machine learning techniques, explanations can\nbe generated for a black-box model, making it possible for (human) users to\naccess the reasoning behind machine learned predictions. In this paper, we aim\nto present an approach that allows us to use model explanations to investigate\ncertain reasoning applied by machine learned predictions and detect potential\nissues with the underlying methods thus enhancing trust in business process\nprediction models. A novel contribution of our approach is the proposal of\nmodel inspection that leverages both the explanations generated by\ninterpretable machine learning mechanisms and the contextual or domain\nknowledge extracted from event logs that record historical process execution.\nFindings drawn from this work are expected to serve as a key input to\ndeveloping model reliability metrics and evaluation in the context of business\nprocess predictions.",
          "link": "http://arxiv.org/abs/2107.09767",
          "publishedOn": "2021-07-22T02:03:12.924Z",
          "wordCount": 631,
          "title": "Explainable AI Enabled Inspection of Business Process Prediction Models. (arXiv:2107.09767v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09815",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Leanza_A/0/1/0/all/0/1\">Antonio Leanza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reina_G/0/1/0/all/0/1\">Giulio Reina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blanco_Claraco_J/0/1/0/all/0/1\">Jose-Luis Blanco-Claraco</a>",
          "description": "Sideslip angle is an important variable for understanding and monitoring\nvehicle dynamics but it lacks an inexpensive method for direct measurement.\nTherefore, it is typically estimated from inertial and other proprioceptive\nsensors onboard using filtering methods from the family of the Kalman Filter.\nAs a novel alternative, this work proposes modelling the problem directly as a\ngraphical model (factor graph), which can then be optimized using a variety of\nmethods, such as whole dataset batch optimization for offline processing or\nfixed-lag smoother for on-line operation. Experimental results on real vehicle\ndatasets validate the proposal with a good agreement between estimated and\nactual sideslip angle, showing similar performance than the state-of-the-art\nwith a great potential for future extensions due to the flexible mathematical\nframework.",
          "link": "http://arxiv.org/abs/2107.09815",
          "publishedOn": "2021-07-22T02:03:12.906Z",
          "wordCount": 559,
          "title": "A Factor Graph-based approach to vehicle sideslip angle estimation. (arXiv:2107.09815v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09781",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Useche_D/0/1/0/all/0/1\">Diego H. Useche</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Giraldo_Carvajal_A/0/1/0/all/0/1\">Andres Giraldo-Carvajal</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Zuluaga_Bucheli_H/0/1/0/all/0/1\">Hernan M. Zuluaga-Bucheli</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Jaramillo_Villegas_J/0/1/0/all/0/1\">Jose A. Jaramillo-Villegas</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Gonzalez_F/0/1/0/all/0/1\">Fabio A. Gonz&#xe1;lez</a>",
          "description": "This paper presents a hybrid classical-quantum program for density estimation\nand supervised classification. The program is implemented as a quantum circuit\nin a high-dimensional quantum computer simulator. We show that the proposed\nquantum protocols allow to estimate probability density functions and to make\npredictions in a supervised learning manner. This model can be generalized to\nfind expected values of density matrices in high-dimensional quantum computers.\nExperiments on various data sets are presented. Results show that the proposed\nmethod is a viable strategy to implement supervised classification and density\nestimation in a high-dimensional quantum computer.",
          "link": "http://arxiv.org/abs/2107.09781",
          "publishedOn": "2021-07-22T02:03:12.887Z",
          "wordCount": 532,
          "title": "Quantum Measurement Classification with Qudits. (arXiv:2107.09781v1 [quant-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2107.10243",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Behera_M/0/1/0/all/0/1\">Monik Raj Behera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Upadhyay_S/0/1/0/all/0/1\">Sudhir Upadhyay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shetty_S/0/1/0/all/0/1\">Suresh Shetty</a>",
          "description": "Over the recent years, Federated machine learning continues to gain interest\nand momentum where there is a need to draw insights from data while preserving\nthe data provider's privacy. However, one among other existing challenges in\nthe adoption of federated learning has been the lack of fair, transparent and\nuniversally agreed incentivization schemes for rewarding the federated learning\ncontributors. Smart contracts on a blockchain network provide transparent,\nimmutable and independently verifiable proofs by all participants of the\nnetwork. We leverage this open and transparent nature of smart contracts on a\nblockchain to define incentivization rules for the contributors, which is based\non a novel scalar quantity - federated contribution. Such a smart contract\nbased reward-driven model has the potential to revolutionize the federated\nlearning adoption in enterprises. Our contribution is two-fold: first is to\nshow how smart contract based blockchain can be a very natural communication\nchannel for federated learning. Second, leveraging this infrastructure, we can\nshow how an intuitive measure of each agents' contribution can be built and\nintegrated with the life cycle of the training and reward process.",
          "link": "http://arxiv.org/abs/2107.10243",
          "publishedOn": "2021-07-22T02:03:12.861Z",
          "wordCount": 631,
          "title": "Federated Learning using Smart Contracts on Blockchains, based on Reward Driven Approach. (arXiv:2107.10243v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2107.10060",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hou_L/0/1/0/all/0/1\">Liang Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Q/0/1/0/all/0/1\">Qi Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1\">Huawei Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1\">Xueqi Cheng</a>",
          "description": "Conditional generative models aim to learn the underlying joint distribution\nof data and labels, and thus realize conditional generation. Among them,\nauxiliary classifier generative adversarial networks (AC-GAN) have been widely\nused, but suffer from the issue of low intra-class diversity on generated\nsamples. In this paper, we point out that the fundamental reason is that the\nclassifier of AC-GAN is generator-agnostic, and thus cannot provide informative\nguidance to the generator to approximate the target joint distribution, leading\nto a minimization of conditional entropy that decreases the intra-class\ndiversity. Based on this finding, we propose novel cGANs with auxiliary\ndiscriminative classifier (ADC-GAN) to address the issue of AC-GAN.\nSpecifically, the auxiliary discriminative classifier becomes generator-aware\nby distinguishing between the real and fake data while recognizing their\nlabels. We then optimize the generator based on the auxiliary classifier along\nwith the original discriminator to match the joint and marginal distributions\nof the generated samples with those of the real samples. We provide theoretical\nanalysis and empirical evidence on synthetic and real-world datasets to\ndemonstrate the superiority of the proposed ADC-GAN compared to competitive\ncGANs.",
          "link": "http://arxiv.org/abs/2107.10060",
          "publishedOn": "2021-07-22T02:03:12.853Z",
          "wordCount": 613,
          "title": "CGANs with Auxiliary Discriminative Classifier. (arXiv:2107.10060v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2101.05303",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Han Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_V/0/1/0/all/0/1\">Vivian Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Chenhao Tan</a>",
          "description": "Although AI holds promise for improving human decision making in societally\ncritical domains, it remains an open question how human-AI teams can reliably\noutperform AI alone and human alone in challenging prediction tasks (also known\nas complementary performance). We explore two directions to understand the gaps\nin achieving complementary performance. First, we argue that the typical\nexperimental setup limits the potential of human-AI teams. To account for lower\nAI performance out-of-distribution than in-distribution because of distribution\nshift, we design experiments with different distribution types and investigate\nhuman performance for both in-distribution and out-of-distribution examples.\nSecond, we develop novel interfaces to support interactive explanations so that\nhumans can actively engage with AI assistance. Using virtual pilot studies and\nlarge-scale randomized experiments across three tasks, we demonstrate a clear\ndifference between in-distribution and out-of-distribution, and observe mixed\nresults for interactive explanations: while interactive explanations improve\nhuman perception of AI assistance's usefulness, they may reinforce human biases\nand lead to limited performance improvement. Overall, our work points out\ncritical challenges and future directions towards enhancing human performance\nwith AI assistance.",
          "link": "http://arxiv.org/abs/2101.05303",
          "publishedOn": "2021-07-22T02:03:12.846Z",
          "wordCount": 670,
          "title": "Understanding the Effect of Out-of-distribution Examples and Interactive Explanations on Human-AI Decision Making. (arXiv:2101.05303v3 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.10015",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Thanapalasingam_T/0/1/0/all/0/1\">Thiviyan Thanapalasingam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berkel_L/0/1/0/all/0/1\">Lucas van Berkel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bloem_P/0/1/0/all/0/1\">Peter Bloem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Groth_P/0/1/0/all/0/1\">Paul Groth</a>",
          "description": "In this paper, we describe a reproduction of the Relational Graph\nConvolutional Network (RGCN). Using our reproduction, we explain the intuition\nbehind the model. Our reproduction results empirically validate the correctness\nof our implementations using benchmark Knowledge Graph datasets on node\nclassification and link prediction tasks. Our explanation provides a friendly\nunderstanding of the different components of the RGCN for both users and\nresearchers extending the RGCN approach. Furthermore, we introduce two new\nconfigurations of the RGCN that are more parameter efficient. The code and\ndatasets are available at https://github.com/thiviyanT/torch-rgcn.",
          "link": "http://arxiv.org/abs/2107.10015",
          "publishedOn": "2021-07-22T02:03:12.839Z",
          "wordCount": 520,
          "title": "Relational Graph Convolutional Networks: A Closer Look. (arXiv:2107.10015v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2003.01247",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Granziol_D/0/1/0/all/0/1\">Diego Granziol</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wan_X/0/1/0/all/0/1\">Xingchen Wan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Albanie_S/0/1/0/all/0/1\">Samuel Albanie</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Roberts_S/0/1/0/all/0/1\">Stephen Roberts</a>",
          "description": "We analyse and explain the increased generalisation performance\n\\latestEdits{of} Iterate Averaging using a Gaussian Process perturbation model\nbetween the true and batch risk surface on the high dimensional quadratic. %\nBased on our theoretical results We derive three phenomena \\latestEdits{from\nour theoretical results:} (1) The importance of combining iterate averaging\nwith large learning rates and regularisation for improved regularisation (2)\nJustification for less frequent averaging. (3) That we expect adaptive gradient\nmethods to work equally well or better with iterate averaging than their non\nadaptive counterparts. Inspired by these results\\latestEdits{, together with}\nempirical investigations of the importance of appropriate regularisation for\nthe solution diversity of the iterates, we propose two adaptive algorithms with\niterate averaging. \\latestEdits{These} give significantly better results than\nSGD, require less tuning and do not require early stopping or validation set\nmonitoring. We showcase the efficacy of our approach on the CIFAR-10/100,\nImageNet and Penn Treebank datasets on a variety of modern and classical\nnetwork architectures.",
          "link": "http://arxiv.org/abs/2003.01247",
          "publishedOn": "2021-07-22T02:03:12.832Z",
          "wordCount": 630,
          "title": "Iterative Averaging in the Quest for Best Test Error. (arXiv:2003.01247v4 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.10143",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sadrtdinov_I/0/1/0/all/0/1\">Ildus Sadrtdinov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chirkova_N/0/1/0/all/0/1\">Nadezhda Chirkova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lobacheva_E/0/1/0/all/0/1\">Ekaterina Lobacheva</a>",
          "description": "Memorization studies of deep neural networks (DNNs) help to understand what\npatterns and how do DNNs learn, and motivate improvements to DNN training\napproaches. In this work, we investigate the memorization properties of SimCLR,\na widely used contrastive self-supervised learning approach, and compare them\nto the memorization of supervised learning and random labels training. We find\nthat both training objects and augmentations may have different complexity in\nthe sense of how SimCLR learns them. Moreover, we show that SimCLR is similar\nto random labels training in terms of the distribution of training objects\ncomplexity.",
          "link": "http://arxiv.org/abs/2107.10143",
          "publishedOn": "2021-07-22T02:03:12.825Z",
          "wordCount": 538,
          "title": "On the Memorization Properties of Contrastive Learning. (arXiv:2107.10143v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.10140",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Prabhu_V/0/1/0/all/0/1\">Viraj Prabhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khare_S/0/1/0/all/0/1\">Shivam Khare</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kartik_D/0/1/0/all/0/1\">Deeksha Kartik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoffman_J/0/1/0/all/0/1\">Judy Hoffman</a>",
          "description": "Most modern approaches for domain adaptive semantic segmentation rely on\ncontinued access to source data during adaptation, which may be infeasible due\nto computational or privacy constraints. We focus on source-free domain\nadaptation for semantic segmentation, wherein a source model must adapt itself\nto a new target domain given only unlabeled target data. We propose\nSelf-Supervised Selective Self-Training (S4T), a source-free adaptation\nalgorithm that first uses the model's pixel-level predictive consistency across\ndiverse views of each target image along with model confidence to classify\npixel predictions as either reliable or unreliable. Next, the model is\nself-trained, using predicted pseudolabels for reliable predictions and\npseudolabels inferred via a selective interpolation strategy for unreliable\nones. S4T matches or improves upon the state-of-the-art in source-free\nadaptation on 3 standard benchmarks for semantic segmentation within a single\nepoch of adaptation.",
          "link": "http://arxiv.org/abs/2107.10140",
          "publishedOn": "2021-07-22T02:03:12.801Z",
          "wordCount": 581,
          "title": "S4T: Source-free domain adaptation for semantic segmentation via self-supervised selective self-training. (arXiv:2107.10140v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.10159",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bertossi_L/0/1/0/all/0/1\">Leopoldo Bertossi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reyes_G/0/1/0/all/0/1\">Gabriela Reyes</a>",
          "description": "We describe how answer-set programs can be used to declaratively specify\ncounterfactual interventions on entities under classification, and reason about\nthem. In particular, they can be used to define and compute responsibility\nscores as attribution-based explanations for outcomes from classification\nmodels. The approach allows for the inclusion of domain knowledge and supports\nquery answering. A detailed example with a naive-Bayes classifier is presented.",
          "link": "http://arxiv.org/abs/2107.10159",
          "publishedOn": "2021-07-22T02:03:12.794Z",
          "wordCount": 524,
          "title": "Answer-Set Programs for Reasoning about Counterfactual Interventions and Responsibility Scores for Classification. (arXiv:2107.10159v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09912",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zanette_A/0/1/0/all/0/1\">Andrea Zanette</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_K/0/1/0/all/0/1\">Kefan Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jonathan Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brunskill_E/0/1/0/all/0/1\">Emma Brunskill</a>",
          "description": "In the stochastic linear contextual bandit setting there exist several\nminimax procedures for exploration with policies that are reactive to the data\nbeing acquired. In practice, there can be a significant engineering overhead to\ndeploy these algorithms, especially when the dataset is collected in a\ndistributed fashion or when a human in the loop is needed to implement a\ndifferent policy. Exploring with a single non-reactive policy is beneficial in\nsuch cases. Assuming some batch contexts are available, we design a single\nstochastic policy to collect a good dataset from which a near-optimal policy\ncan be extracted. We present a theoretical analysis as well as numerical\nexperiments on both synthetic and real-world datasets.",
          "link": "http://arxiv.org/abs/2107.09912",
          "publishedOn": "2021-07-22T02:03:12.787Z",
          "wordCount": 551,
          "title": "Design of Experiments for Stochastic Contextual Linear Bandits. (arXiv:2107.09912v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09807",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mahdavimoghaddama_M/0/1/0/all/0/1\">Mahnoosh Mahdavimoghaddama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nikanjama_A/0/1/0/all/0/1\">Amin Nikanjama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdoos_M/0/1/0/all/0/1\">Monireh Abdoos</a>",
          "description": "Cooperative multi-agent systems are being widely used in different domains.\nInteraction among agents would bring benefits, including reducing operating\ncosts, high scalability, and facilitating parallel processing. These systems\nare also a good option for handling large-scale, unknown, and dynamic\nenvironments. However, learning in these environments has become a very\nimportant challenge in various applications. These challenges include the\neffect of search space size on learning time, inefficient cooperation among\nagents, and the lack of proper coordination among agents' decisions. Moreover,\nreinforcement learning algorithms may suffer from long convergence time in\nthese problems. In this paper, a communication framework using knowledge\ntransfer concepts is introduced to address such challenges in the herding\nproblem with large state space. To handle the problems of convergence,\nknowledge transfer has been utilized that can significantly increase the\nefficiency of reinforcement learning algorithms. Coordination between the\nagents is carried out through a head agent in each group of agents and a\ncoordinator agent respectively. The results demonstrate that this framework\ncould indeed enhance the speed of learning and reduce convergence time.",
          "link": "http://arxiv.org/abs/2107.09807",
          "publishedOn": "2021-07-22T02:03:12.780Z",
          "wordCount": 628,
          "title": "Multi-agent Reinforcement Learning Improvement in a Dynamic Environment Using Knowledge Transfer. (arXiv:2107.09807v1 [cs.MA])"
        },
        {
          "id": "http://arxiv.org/abs/2107.10125",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ober_S/0/1/0/all/0/1\">Sebastian W. Ober</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Aitchison_L/0/1/0/all/0/1\">Laurence Aitchison</a>",
          "description": "Recent work introduced deep kernel processes as an entirely kernel-based\nalternative to NNs (Aitchison et al. 2020). Deep kernel processes flexibly\nlearn good top-layer representations by alternately sampling the kernel from a\ndistribution over positive semi-definite matrices and performing nonlinear\ntransformations. A particular deep kernel process, the deep Wishart process\n(DWP), is of particular interest because its prior is equivalent to deep\nGaussian process (DGP) priors. However, inference in DWPs has not yet been\npossible due to the lack of sufficiently flexible distributions over positive\nsemi-definite matrices. Here, we give a novel approach to obtaining flexible\ndistributions over positive semi-definite matrices by generalising the Bartlett\ndecomposition of the Wishart probability density. We use this new distribution\nto develop an approximate posterior for the DWP that includes dependency across\nlayers. We develop a doubly-stochastic inducing-point inference scheme for the\nDWP and show experimentally that inference in the DWP gives improved\nperformance over doing inference in a DGP with the equivalent prior.",
          "link": "http://arxiv.org/abs/2107.10125",
          "publishedOn": "2021-07-22T02:03:12.772Z",
          "wordCount": 597,
          "title": "A variational approximate posterior for the deep Wishart process. (arXiv:2107.10125v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2103.10492",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fuad_M/0/1/0/all/0/1\">Md. Tahmid Hasan Fuad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fime_A/0/1/0/all/0/1\">Awal Ahmed Fime</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sikder_D/0/1/0/all/0/1\">Delowar Sikder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iftee_M/0/1/0/all/0/1\">Md. Akil Raihan Iftee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rabbi_J/0/1/0/all/0/1\">Jakaria Rabbi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Al_rakhami_M/0/1/0/all/0/1\">Mabrook S. Al-rakhami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gumae_A/0/1/0/all/0/1\">Abdu Gumae</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sen_O/0/1/0/all/0/1\">Ovishake Sen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fuad_M/0/1/0/all/0/1\">Mohtasim Fuad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Islam_M/0/1/0/all/0/1\">Md. Nazrul Islam</a>",
          "description": "In recent years, researchers have proposed many deep learning (DL) methods\nfor various tasks, and particularly face recognition (FR) made an enormous leap\nusing these techniques. Deep FR systems benefit from the hierarchical\narchitecture of the DL methods to learn discriminative face representation.\nTherefore, DL techniques significantly improve state-of-the-art performance on\nFR systems and encourage diverse and efficient real-world applications. In this\npaper, we present a comprehensive analysis of various FR systems that leverage\nthe different types of DL techniques, and for the study, we summarize 168\nrecent contributions from this area. We discuss the papers related to different\nalgorithms, architectures, loss functions, activation functions, datasets,\nchallenges, improvement ideas, current and future trends of DL-based FR\nsystems. We provide a detailed discussion of various DL methods to understand\nthe current state-of-the-art, and then we discuss various activation and loss\nfunctions for the methods. Additionally, we summarize different datasets used\nwidely for FR tasks and discuss challenges related to illumination, expression,\npose variations, and occlusion. Finally, we discuss improvement ideas, current\nand future trends of FR tasks.",
          "link": "http://arxiv.org/abs/2103.10492",
          "publishedOn": "2021-07-22T02:03:12.750Z",
          "wordCount": 710,
          "title": "Recent Advances in Deep Learning Techniques for Face Recognition. (arXiv:2103.10492v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.10014",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kloepfer_D/0/1/0/all/0/1\">Dominik Kloepfer</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Aviles_Rivero_A/0/1/0/all/0/1\">Angelica I. Aviles-Rivero</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Heydecker_D/0/1/0/all/0/1\">Daniel Heydecker</a>",
          "description": "Graph vertex embeddings based on random walks have become increasingly\ninfluential in recent years, showing good performance in several tasks as they\nefficiently transform a graph into a more computationally digestible format\nwhile preserving relevant information. However, the theoretical properties of\nsuch algorithms, in particular the influence of hyperparameters and of the\ngraph structure on their convergence behaviour, have so far not been\nwell-understood. In this work, we provide a theoretical analysis for\nrandom-walks based embeddings techniques. Firstly, we prove that, under some\nweak assumptions, vertex embeddings derived from random walks do indeed\nconverge both in the single limit of the number of random walks $N \\to \\infty$\nand in the double limit of both $N$ and the length of each random walk\n$L\\to\\infty$. Secondly, we derive concentration bounds quantifying the converge\nrate of the corpora for the single and double limits. Thirdly, we use these\nresults to derive a heuristic for choosing the hyperparameters $N$ and $L$. We\nvalidate and illustrate the practical importance of our findings with a range\nof numerical and visual experiments on several graphs drawn from real-world\napplications.",
          "link": "http://arxiv.org/abs/2107.10014",
          "publishedOn": "2021-07-22T02:03:12.743Z",
          "wordCount": 625,
          "title": "Delving Into Deep Walkers: A Convergence Analysis of Random-Walk-Based Vertex Embeddings. (arXiv:2107.10014v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2107.10093",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ngo_D/0/1/0/all/0/1\">Daniel Ngo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stapleton_L/0/1/0/all/0/1\">Logan Stapleton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Syrgkanis_V/0/1/0/all/0/1\">Vasilis Syrgkanis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhiwei Steven Wu</a>",
          "description": "Randomized experiments can be susceptible to selection bias due to potential\nnon-compliance by the participants. While much of the existing work has studied\ncompliance as a static behavior, we propose a game-theoretic model to study\ncompliance as dynamic behavior that may change over time. In rounds, a social\nplanner interacts with a sequence of heterogeneous agents who arrive with their\nunobserved private type that determines both their prior preferences across the\nactions (e.g., control and treatment) and their baseline rewards without taking\nany treatment. The planner provides each agent with a randomized recommendation\nthat may alter their beliefs and their action selection. We develop a novel\nrecommendation mechanism that views the planner's recommendation as a form of\ninstrumental variable (IV) that only affects an agents' action selection, but\nnot the observed rewards. We construct such IVs by carefully mapping the\nhistory -- the interactions between the planner and the previous agents -- to a\nrandom recommendation. Even though the initial agents may be completely\nnon-compliant, our mechanism can incentivize compliance over time, thereby\nenabling the estimation of the treatment effect of each treatment, and\nminimizing the cumulative regret of the planner whose goal is to identify the\noptimal treatment.",
          "link": "http://arxiv.org/abs/2107.10093",
          "publishedOn": "2021-07-22T02:03:12.735Z",
          "wordCount": 654,
          "title": "Incentivizing Compliance with Algorithmic Instruments. (arXiv:2107.10093v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09937",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Huimin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Zhengmian Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_B/0/1/0/all/0/1\">Bin Gu</a>",
          "description": "Adversarial attacks by generating examples which are almost indistinguishable\nfrom natural examples, pose a serious threat to learning models. Defending\nagainst adversarial attacks is a critical element for a reliable learning\nsystem. Support vector machine (SVM) is a classical yet still important\nlearning algorithm even in the current deep learning era. Although a wide range\nof researches have been done in recent years to improve the adversarial\nrobustness of learning models, but most of them are limited to deep neural\nnetworks (DNNs) and the work for kernel SVM is still vacant. In this paper, we\naim at kernel SVM and propose adv-SVM to improve its adversarial robustness via\nadversarial training, which has been demonstrated to be the most promising\ndefense techniques. To the best of our knowledge, this is the first work that\ndevotes to the fast and scalable adversarial training of kernel SVM.\nSpecifically, we first build connection of perturbations of samples between\noriginal and kernel spaces, and then give a reduced and equivalent formulation\nof adversarial training of kernel SVM based on the connection. Next, doubly\nstochastic gradients (DSG) based on two unbiased stochastic approximations\n(i.e., one is on training points and another is on random features) are applied\nto update the solution of our objective function. Finally, we prove that our\nalgorithm optimized by DSG converges to the optimal solution at the rate of\nO(1/t) under the constant and diminishing stepsizes. Comprehensive experimental\nresults show that our adversarial training algorithm enjoys robustness against\nvarious attacks and meanwhile has the similar efficiency and scalability with\nclassical DSG algorithm.",
          "link": "http://arxiv.org/abs/2107.09937",
          "publishedOn": "2021-07-22T02:03:12.727Z",
          "wordCount": 701,
          "title": "Fast and Scalable Adversarial Training of Kernel SVM via Doubly Stochastic Gradients. (arXiv:2107.09937v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.10236",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meyer_M/0/1/0/all/0/1\">Matthias Meyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wenner_M/0/1/0/all/0/1\">Michaela Wenner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hibert_C/0/1/0/all/0/1\">Cl&#xe9;ment Hibert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walter_F/0/1/0/all/0/1\">Fabian Walter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thiele_L/0/1/0/all/0/1\">Lothar Thiele</a>",
          "description": "Real-world datasets collected with sensor networks often contain incomplete\nand uncertain labels as well as artefacts arising from the system environment.\nComplete and reliable labeling is often infeasible for large-scale and\nlong-term sensor network deployments due to the labor and time overhead,\nlimited availability of experts and missing ground truth. In addition, if the\nmachine learning method used for analysis is sensitive to certain features of a\ndeployment, labeling and learning needs to be repeated for every new\ndeployment. To address these challenges, we propose to make use of system\ncontext information formalized in an information graph and embed it in the\nlearning process via contrastive learning. Based on real-world data we show\nthat this approach leads to an increased accuracy in case of weakly labeled\ndata and leads to an increased robustness and transferability of the classifier\nto new sensor locations.",
          "link": "http://arxiv.org/abs/2107.10236",
          "publishedOn": "2021-07-22T02:03:12.719Z",
          "wordCount": 590,
          "title": "Using system context information to complement weakly labeled data. (arXiv:2107.10236v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.10174",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1\">Kunhong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yucheng Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1\">Yahong Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_Y/0/1/0/all/0/1\">Yunfeng Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bingshuai Li</a>",
          "description": "In recent years, researchers have been paying increasing attention to the\nthreats brought by deep learning models to data security and privacy,\nespecially in the field of domain adaptation. Existing unsupervised domain\nadaptation (UDA) methods can achieve promising performance without transferring\ndata from source domain to target domain. However, UDA with representation\nalignment or self-supervised pseudo-labeling relies on the transferred source\nmodels. In many data-critical scenarios, methods based on model transferring\nmay suffer from membership inference attacks and expose private data. In this\npaper, we aim to overcome a challenging new setting where the source models are\nonly queryable but cannot be transferred to the target domain. We propose\nBlack-box Probe Domain Adaptation (BPDA), which adopts query mechanism to probe\nand refine information from source model using third-party dataset. In order to\ngain more informative query results, we further propose Distributionally\nAdversarial Training (DAT) to align the distribution of third-party data with\nthat of target data. BPDA uses public third-party dataset and adversarial\nexamples based on DAT as the information carrier between source and target\ndomains, dispensing with transferring source data or model. Experimental\nresults on benchmarks of Digit-Five, Office-Caltech, Office-31, Office-Home,\nand DomainNet demonstrate the feasibility of BPDA without model transferring.",
          "link": "http://arxiv.org/abs/2107.10174",
          "publishedOn": "2021-07-22T02:03:12.698Z",
          "wordCount": 637,
          "title": "Black-box Probe for Unsupervised Domain Adaptation without Model Transferring. (arXiv:2107.10174v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09716",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Severo_D/0/1/0/all/0/1\">Daniel Severo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Domanovitz_E/0/1/0/all/0/1\">Elad Domanovitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khisti_A/0/1/0/all/0/1\">Ashish Khisti</a>",
          "description": "Traditionally, quantization is designed to minimize the reconstruction error\nof a data source. When considering downstream classification tasks, other\nmeasures of distortion can be of interest; such as the 0-1 classification loss.\nFurthermore, it is desirable that the performance of these quantizers not\ndeteriorate once they are deployed into production, as relearning the scheme\nonline is not always possible. In this work, we present a class of algorithms\nthat learn distributed quantization schemes for binary classification tasks.\nOur method performs well on unseen data, and is faster than previous methods\nproportional to a quadratic term of the dataset size. It works by regularizing\nthe 0-1 loss with the reconstruction error. We present experiments on synthetic\nmixture and bivariate Gaussian data and compare training, testing, and\ngeneralization errors with a family of benchmark quantization schemes from the\nliterature. Our method is called Regularized Classification-Aware Quantization.",
          "link": "http://arxiv.org/abs/2107.09716",
          "publishedOn": "2021-07-22T02:03:12.691Z",
          "wordCount": 578,
          "title": "Regularized Classification-Aware Quantization. (arXiv:2107.09716v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.10201",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Sonnerat_N/0/1/0/all/0/1\">Nicolas Sonnerat</a>, <a href=\"http://arxiv.org/find/math/1/au:+Wang_P/0/1/0/all/0/1\">Pengming Wang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Ktena_I/0/1/0/all/0/1\">Ira Ktena</a>, <a href=\"http://arxiv.org/find/math/1/au:+Bartunov_S/0/1/0/all/0/1\">Sergey Bartunov</a>, <a href=\"http://arxiv.org/find/math/1/au:+Nair_V/0/1/0/all/0/1\">Vinod Nair</a>",
          "description": "Large Neighborhood Search (LNS) is a combinatorial optimization heuristic\nthat starts with an assignment of values for the variables to be optimized, and\niteratively improves it by searching a large neighborhood around the current\nassignment. In this paper we consider a learning-based LNS approach for mixed\ninteger programs (MIPs). We train a Neural Diving model to represent a\nprobability distribution over assignments, which, together with an existing MIP\nsolver, generates an initial assignment. Formulating the subsequent search\nsteps as a Markov Decision Process, we train a Neural Neighborhood Selection\npolicy to select a search neighborhood at each step, which is searched using a\nMIP solver to find the next assignment. The policy network is trained using\nimitation learning. We propose a target policy for imitation that, given enough\ncompute resources, is guaranteed to select the neighborhood containing the\noptimal next assignment across all possible choices for the neighborhood of a\nspecified size. Our approach matches or outperforms all the baselines on five\nreal-world MIP datasets with large-scale instances from diverse applications,\nincluding two production applications at Google. At large running times it\nachieves $2\\times$ to $37.8\\times$ better average primal gap than the best\nbaseline on three of the datasets.",
          "link": "http://arxiv.org/abs/2107.10201",
          "publishedOn": "2021-07-22T02:03:12.682Z",
          "wordCount": 641,
          "title": "Learning a Large Neighborhood Search Algorithm for Mixed Integer Programs. (arXiv:2107.10201v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09996",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Koutras_D/0/1/0/all/0/1\">Dimitrios I. Koutras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kapoutsis_A/0/1/0/all/0/1\">Athanasios Ch. Kapoutsis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amanatiadis_A/0/1/0/all/0/1\">Angelos A. Amanatiadis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kosmatopoulos_E/0/1/0/all/0/1\">Elias B. Kosmatopoulos</a>",
          "description": "This paper is an initial endeavor to bridge the gap between powerful Deep\nReinforcement Learning methodologies and the problem of exploration/coverage of\nunknown terrains. Within this scope, MarsExplorer, an openai-gym compatible\nenvironment tailored to exploration/coverage of unknown areas, is presented.\nMarsExplorer translates the original robotics problem into a Reinforcement\nLearning setup that various off-the-shelf algorithms can tackle. Any learned\npolicy can be straightforwardly applied to a robotic platform without an\nelaborate simulation model of the robot's dynamics to apply a different\nlearning/adaptation phase. One of its core features is the controllable\nmulti-dimensional procedural generation of terrains, which is the key for\nproducing policies with strong generalization capabilities. Four different\nstate-of-the-art RL algorithms (A3C, PPO, Rainbow, and SAC) are trained on the\nMarsExplorer environment, and a proper evaluation of their results compared to\nthe average human-level performance is reported. In the follow-up experimental\nanalysis, the effect of the multi-dimensional difficulty setting on the\nlearning capabilities of the best-performing algorithm (PPO) is analyzed. A\nmilestone result is the generation of an exploration policy that follows the\nHilbert curve without providing this information to the environment or\nrewarding directly or indirectly Hilbert-curve-like trajectories. The\nexperimental analysis is concluded by comparing PPO learned policy results with\nfrontier-based exploration context for extended terrain sizes. The source code\ncan be found at: https://github.com/dimikout3/GeneralExplorationPolicy.",
          "link": "http://arxiv.org/abs/2107.09996",
          "publishedOn": "2021-07-22T02:03:12.675Z",
          "wordCount": 670,
          "title": "MarsExplorer: Exploration of Unknown Terrains via Deep Reinforcement Learning and Procedurally Generated Environments. (arXiv:2107.09996v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09787",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xinyi Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_C/0/1/0/all/0/1\">Cheng Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yaochen Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1\">Shuiwang Ji</a>",
          "description": "We study self-supervised learning on graphs using contrastive methods. A\ngeneral scheme of prior methods is to optimize two-view representations of\ninput graphs. In many studies, a single graph-level representation is computed\nas one of the contrastive objectives, capturing limited characteristics of\ngraphs. We argue that contrasting graphs in multiple subspaces enables graph\nencoders to capture more abundant characteristics. To this end, we propose a\ngroup contrastive learning framework in this work. Our framework embeds the\ngiven graph into multiple subspaces, of which each representation is prompted\nto encode specific characteristics of graphs. To learn diverse and informative\nrepresentations, we develop principled objectives that enable us to capture the\nrelations among both intra-space and inter-space representations in groups.\nUnder the proposed framework, we further develop an attention-based representor\nfunction to compute representations that capture different substructures of a\ngiven graph. Built upon our framework, we extend two current methods into\nGroupCL and GroupIG, equipped with the proposed objective. Comprehensive\nexperimental results show our framework achieves a promising boost in\nperformance on a variety of datasets. In addition, our qualitative results show\nthat features generated from our representor successfully capture various\nspecific characteristics of graphs.",
          "link": "http://arxiv.org/abs/2107.09787",
          "publishedOn": "2021-07-22T02:03:12.667Z",
          "wordCount": 620,
          "title": "Group Contrastive Self-Supervised Learning on Graphs. (arXiv:2107.09787v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.10030",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dona_J/0/1/0/all/0/1\">J&#xe9;r&#xe9;mie Dona</a> (MLIA), <a href=\"http://arxiv.org/find/cs/1/au:+Gallinari_P/0/1/0/all/0/1\">Patrick Gallinari</a> (MLIA)",
          "description": "We consider the task of feature selection for reconstruction which consists\nin choosing a small subset of features from which whole data instances can be\nreconstructed. This is of particular importance in several contexts involving\nfor example costly physical measurements, sensor placement or information\ncompression. To break the intrinsic combinatorial nature of this problem, we\nformulate the task as optimizing a binary mask distribution enabling an\naccurate reconstruction. We then face two main challenges. One concerns\ndifferentiability issues due to the binary distribution. The second one\ncorresponds to the elimination of redundant information by selecting variables\nin a correlated fashion which requires modeling the covariance of the binary\ndistribution. We address both issues by introducing a relaxation of the problem\nvia a novel reparameterization of the logitNormal distribution. We demonstrate\nthat the proposed method provides an effective exploration scheme and leads to\nefficient feature selection for reconstruction through evaluation on several\nhigh dimensional image benchmarks. We show that the method leverages the\nintrinsic geometry of the data, facilitating reconstruction.",
          "link": "http://arxiv.org/abs/2107.10030",
          "publishedOn": "2021-07-22T02:03:12.647Z",
          "wordCount": 614,
          "title": "Differentiable Feature Selection, a Reparameterization Approach. (arXiv:2107.10030v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09786",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xing Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jingtao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakrabarti_C/0/1/0/all/0/1\">Chaitali Chakrabarti</a>",
          "description": "Split learning is a promising privacy-preserving distributed learning scheme\nthat has low computation requirement at the edge device but has the\ndisadvantage of high communication overhead between edge device and server. To\nreduce the communication overhead, this paper proposes a loss-based\nasynchronous training scheme that updates the client-side model less frequently\nand only sends/receives activations/gradients in selected epochs. To further\nreduce the communication overhead, the activations/gradients are quantized\nusing 8-bit floating point prior to transmission. An added benefit of the\nproposed communication reduction method is that the computations at the client\nside are reduced due to reduction in the number of client model updates.\nFurthermore, the privacy of the proposed communication reduction based split\nlearning method is almost the same as traditional split learning. Simulation\nresults on VGG11, VGG13 and ResNet18 models on CIFAR-10 show that the\ncommunication cost is reduced by 1.64x-106.7x and the computations in the\nclient are reduced by 2.86x-32.1x when the accuracy degradation is less than\n0.5% for the single-client case. For 5 and 10-client cases, the communication\ncost reduction is 11.9x and 11.3x on VGG11 for 0.5% loss in accuracy.",
          "link": "http://arxiv.org/abs/2107.09786",
          "publishedOn": "2021-07-22T02:03:12.638Z",
          "wordCount": 621,
          "title": "Communication and Computation Reduction for Split Learning using Asynchronous Training. (arXiv:2107.09786v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.10146",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Raeis_M/0/1/0/all/0/1\">Majid Raeis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leon_Garcia_A/0/1/0/all/0/1\">Alberto Leon-Garcia</a>",
          "description": "Traffic signal control is one of the most effective methods of traffic\nmanagement in urban areas. In recent years, traffic control methods based on\ndeep reinforcement learning (DRL) have gained attention due to their ability to\nexploit real-time traffic data, which is often poorly used by the traditional\nhand-crafted methods. While most recent DRL-based methods have focused on\nmaximizing the throughput or minimizing the average travel time of the\nvehicles, the fairness of the traffic signal controllers has often been\nneglected. This is particularly important as neglecting fairness can lead to\nsituations where some vehicles experience extreme waiting times, or where the\nthroughput of a particular traffic flow is highly impacted by the fluctuations\nof another conflicting flow at the intersection. In order to address these\nissues, we introduce two notions of fairness: delay-based and throughput-based\nfairness, which correspond to the two issues mentioned above. Furthermore, we\npropose two DRL-based traffic signal control methods for implementing these\nfairness notions, that can achieve a high throughput as well. We evaluate the\nperformance of our proposed methods using three traffic arrival distributions,\nand find that our methods outperform the baselines in the tested scenarios.",
          "link": "http://arxiv.org/abs/2107.10146",
          "publishedOn": "2021-07-22T02:03:12.630Z",
          "wordCount": 639,
          "title": "A Deep Reinforcement Learning Approach for Fair Traffic Signal Control. (arXiv:2107.10146v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09957",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Patel_D/0/1/0/all/0/1\">Deep Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sastry_P/0/1/0/all/0/1\">P.S. Sastry</a>",
          "description": "Deep Neural Networks, often owing to the overparameterization, are shown to\nbe capable of exactly memorizing even randomly labelled data. Empirical studies\nhave also shown that none of the standard regularization techniques mitigate\nsuch overfitting. We investigate whether the choice of the loss function can\naffect this memorization. We empirically show, with benchmark data sets MNIST\nand CIFAR-10, that a symmetric loss function, as opposed to either\ncross-entropy or squared error loss, results in significant improvement in the\nability of the network to resist such overfitting. We then provide a formal\ndefinition for robustness to memorization and provide a theoretical explanation\nas to why the symmetric losses provide this robustness. Our results clearly\nbring out the role loss functions alone can play in this phenomenon of\nmemorization.",
          "link": "http://arxiv.org/abs/2107.09957",
          "publishedOn": "2021-07-22T02:03:12.624Z",
          "wordCount": 579,
          "title": "Memorization in Deep Neural Networks: Does the Loss Function matter?. (arXiv:2107.09957v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09883",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aakur_S/0/1/0/all/0/1\">Sathyanarayanan N. Aakur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narayanan_S/0/1/0/all/0/1\">Sai Narayanan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Indla_V/0/1/0/all/0/1\">Vineela Indla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bagavathi_A/0/1/0/all/0/1\">Arunkumar Bagavathi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramnath_V/0/1/0/all/0/1\">Vishalini Laguduva Ramnath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramachandran_A/0/1/0/all/0/1\">Akhilesh Ramachandran</a>",
          "description": "The emergence of novel pathogens and zoonotic diseases like the SARS-CoV-2\nhave underlined the need for developing novel diagnosis and intervention\npipelines that can learn rapidly from small amounts of labeled data. Combined\nwith technological advances in next-generation sequencing, metagenome-based\ndiagnostic tools hold much promise to revolutionize rapid point-of-care\ndiagnosis. However, there are significant challenges in developing such an\napproach, the chief among which is to learn self-supervised representations\nthat can help detect novel pathogen signatures with very low amounts of labeled\ndata. This is particularly a difficult task given that closely related\npathogens can share more than 90% of their genome structure. In this work, we\naddress these challenges by proposing MG-Net, a self-supervised representation\nlearning framework that leverages multi-modal context using pseudo-imaging data\nderived from clinical metagenome sequences. We show that the proposed framework\ncan learn robust representations from unlabeled data that can be used for\ndownstream tasks such as metagenome sequence classification with limited access\nto labeled data. Extensive experiments show that the learned features\noutperform current baseline metagenome representations, given only 1000 samples\nper class.",
          "link": "http://arxiv.org/abs/2107.09883",
          "publishedOn": "2021-07-22T02:03:12.617Z",
          "wordCount": 667,
          "title": "MG-NET: Leveraging Pseudo-Imaging for Multi-Modal Metagenome Analysis. (arXiv:2107.09883v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09770",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dinitz_M/0/1/0/all/0/1\">Michael Dinitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Im_S/0/1/0/all/0/1\">Sungjin Im</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lavastida_T/0/1/0/all/0/1\">Thomas Lavastida</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moseley_B/0/1/0/all/0/1\">Benjamin Moseley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vassilvitskii_S/0/1/0/all/0/1\">Sergei Vassilvitskii</a>",
          "description": "A recent line of research investigates how algorithms can be augmented with\nmachine-learned predictions to overcome worst case lower bounds. This area has\nrevealed interesting algorithmic insights into problems, with particular\nsuccess in the design of competitive online algorithms. However, the question\nof improving algorithm running times with predictions has largely been\nunexplored.\n\nWe take a first step in this direction by combining the idea of\nmachine-learned predictions with the idea of \"warm-starting\" primal-dual\nalgorithms. We consider one of the most important primitives in combinatorial\noptimization: weighted bipartite matching and its generalization to\n$b$-matching. We identify three key challenges when using learned dual\nvariables in a primal-dual algorithm. First, predicted duals may be infeasible,\nso we give an algorithm that efficiently maps predicted infeasible duals to\nnearby feasible solutions. Second, once the duals are feasible, they may not be\noptimal, so we show that they can be used to quickly find an optimal solution.\nFinally, such predictions are useful only if they can be learned, so we show\nthat the problem of learning duals for matching has low sample complexity. We\nvalidate our theoretical findings through experiments on both real and\nsynthetic data. As a result we give a rigorous, practical, and empirically\neffective method to compute bipartite matchings.",
          "link": "http://arxiv.org/abs/2107.09770",
          "publishedOn": "2021-07-22T02:03:12.598Z",
          "wordCount": 645,
          "title": "Faster Matchings via Learned Duals. (arXiv:2107.09770v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09904",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Law_A/0/1/0/all/0/1\">Anwesha Law</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_A/0/1/0/all/0/1\">Ashish Ghosh</a>",
          "description": "Multi-label (ML) classification is an actively researched topic currently,\nwhich deals with convoluted and overlapping boundaries that arise due to\nseveral labels being active for a particular data instance. We propose a\nclassifier capable of extracting underlying features and introducing\nnon-linearity to the data to handle the complex decision boundaries. A novel\nneural network model has been developed where the input features are subjected\nto two transformations adapted from multi-label functional link artificial\nneural network and autoencoders. First, a functional expansion of the original\nfeatures are made using basis functions. This is followed by an\nautoencoder-aided transformation and reduction on the expanded features. This\nnetwork is capable of improving separability for the multi-label data owing to\nthe two-layer transformation while reducing the expanded feature space to a\nmore manageable amount. This balances the input dimension which leads to a\nbetter classification performance even for a limited amount of data. The\nproposed network has been validated on five ML datasets which shows its\nsuperior performance in comparison with six well-established ML classifiers.\nFurthermore, a single-label variation of the proposed network has also been\nformulated simultaneously and tested on four relevant datasets against three\nexisting classifiers to establish its effectiveness.",
          "link": "http://arxiv.org/abs/2107.09904",
          "publishedOn": "2021-07-22T02:03:12.584Z",
          "wordCount": 633,
          "title": "Integration of Autoencoder and Functional Link Artificial Neural Network for Multi-label Classification. (arXiv:2107.09904v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09950",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dionelis_N/0/1/0/all/0/1\">Nikolaos Dionelis</a>",
          "description": "Generative models, such as Generative Adversarial Networks (GANs), have been\nused for unsupervised anomaly detection. While performance keeps improving,\nseveral limitations exist particularly attributed to difficulties at capturing\nmultimodal supports and to the ability to approximate the underlying\ndistribution closer to the tails, i.e. the boundary of the distribution's\nsupport. This paper proposes an approach that attempts to alleviate such\nshortcomings. We propose an invertible-residual-network-based model, the\nBoundary of Distribution Support Generator (BDSG). GANs generally do not\nguarantee the existence of a probability distribution and here, we use the\nrecently developed Invertible Residual Network (IResNet) and Residual Flow\n(ResFlow), for density estimation. These models have not yet been used for\nanomaly detection. We leverage IResNet and ResFlow for Out-of-Distribution\n(OoD) sample detection and for sample generation on the boundary using a\ncompound loss function that forces the samples to lie on the boundary. The BDSG\naddresses non-convex support, disjoint components, and multimodal\ndistributions. Results on synthetic data and data from multimodal\ndistributions, such as MNIST and CIFAR-10, demonstrate competitive performance\ncompared to methods from the literature.",
          "link": "http://arxiv.org/abs/2107.09950",
          "publishedOn": "2021-07-22T02:03:12.563Z",
          "wordCount": 641,
          "title": "Boundary of Distribution Support Generator (BDSG): Sample Generation on the Boundary. (arXiv:2107.09950v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09869",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ahmad_Z/0/1/0/all/0/1\">Zeeshan Ahmad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tabassum_A/0/1/0/all/0/1\">Anika Tabassum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guan_L/0/1/0/all/0/1\">Ling Guan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_N/0/1/0/all/0/1\">Naimul Khan</a>",
          "description": "Electrocardiogram (ECG) is an authoritative source to diagnose and counter\ncritical cardiovascular syndromes such as arrhythmia and myocardial infarction\n(MI). Current machine learning techniques either depend on manually extracted\nfeatures or large and complex deep learning networks which merely utilize the\n1D ECG signal directly. Since intelligent multimodal fusion can perform at the\nstateof-the-art level with an efficient deep network, therefore, in this paper,\nwe propose two computationally efficient multimodal fusion frameworks for ECG\nheart beat classification called Multimodal Image Fusion (MIF) and Multimodal\nFeature Fusion (MFF). At the input of these frameworks, we convert the raw ECG\ndata into three different images using Gramian Angular Field (GAF), Recurrence\nPlot (RP) and Markov Transition Field (MTF). In MIF, we first perform image\nfusion by combining three imaging modalities to create a single image modality\nwhich serves as input to the Convolutional Neural Network (CNN). In MFF, we\nextracted features from penultimate layer of CNNs and fused them to get unique\nand interdependent information necessary for better performance of classifier.\nThese informational features are finally used to train a Support Vector Machine\n(SVM) classifier for ECG heart-beat classification. We demonstrate the\nsuperiority of the proposed fusion models by performing experiments on\nPhysioNets MIT-BIH dataset for five distinct conditions of arrhythmias which\nare consistent with the AAMI EC57 protocols and on PTB diagnostics dataset for\nMyocardial Infarction (MI) classification. We achieved classification accuracy\nof 99.7% and 99.2% on arrhythmia and MI classification, respectively.",
          "link": "http://arxiv.org/abs/2107.09869",
          "publishedOn": "2021-07-22T02:03:12.556Z",
          "wordCount": 677,
          "title": "ECG Heartbeat Classification Using Multimodal Fusion. (arXiv:2107.09869v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09734",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Delaney_E/0/1/0/all/0/1\">Eoin Delaney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Greene_D/0/1/0/all/0/1\">Derek Greene</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keane_M/0/1/0/all/0/1\">Mark T. Keane</a>",
          "description": "Whilst an abundance of techniques have recently been proposed to generate\ncounterfactual explanations for the predictions of opaque black-box systems,\nmarkedly less attention has been paid to exploring the uncertainty of these\ngenerated explanations. This becomes a critical issue in high-stakes scenarios,\nwhere uncertain and misleading explanations could have dire consequences (e.g.,\nmedical diagnosis and treatment planning). Moreover, it is often difficult to\ndetermine if the generated explanations are well grounded in the training data\nand sensitive to distributional shifts. This paper proposes several practical\nsolutions that can be leveraged to solve these problems by establishing novel\nconnections with other research works in explainability (e.g., trust scores)\nand uncertainty estimation (e.g., Monte Carlo Dropout). Two experiments\ndemonstrate the utility of our proposed solutions.",
          "link": "http://arxiv.org/abs/2107.09734",
          "publishedOn": "2021-07-22T02:03:12.526Z",
          "wordCount": 571,
          "title": "Uncertainty Estimation and Out-of-Distribution Detection for Counterfactual Explanations: Pitfalls and Solutions. (arXiv:2107.09734v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09768",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dadgar_S/0/1/0/all/0/1\">Sajad Dadgar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghatee_M/0/1/0/all/0/1\">Mehdi Ghatee</a>",
          "description": "During the COVID-19 pandemic, social media platforms were ideal for\ncommunicating due to social isolation and quarantine. Also, it was the primary\nsource of misinformation dissemination on a large scale, referred to as the\ninfodemic. Therefore, automatic debunking misinformation is a crucial problem.\nTo tackle this problem, we present two COVID-19 related misinformation datasets\non Twitter and propose a misinformation detection system comprising\nnetwork-based and content-based processes based on machine learning algorithms\nand NLP techniques. In the network-based process, we focus on social\nproperties, network characteristics, and users. On the other hand, we classify\nmisinformation using the content of the tweets directly in the content-based\nprocess, which contains text classification models (paragraph-level and\nsentence-level) and similarity models. The evaluation results on the\nnetwork-based process show the best results for the artificial neural network\nmodel with an F1 score of 88.68%. In the content-based process, our novel\nsimilarity models, which obtained an F1 score of 90.26%, show an improvement in\nthe misinformation classification results compared to the network-based models.\nIn addition, in the text classification models, the best result was achieved\nusing the stacking ensemble-learning model by obtaining an F1 score of 95.18%.\nFurthermore, we test our content-based models on the Constraint@AAAI2021\ndataset, and by getting an F1 score of 94.38%, we improve the baseline results.\nFinally, we develop a fact-checking website called Checkovid that uses each\nprocess to detect misinformative and informative claims in the domain of\nCOVID-19 from different perspectives.",
          "link": "http://arxiv.org/abs/2107.09768",
          "publishedOn": "2021-07-22T02:03:12.520Z",
          "wordCount": 756,
          "title": "Checkovid: A COVID-19 misinformation detection system on Twitter using network and content mining perspectives. (arXiv:2107.09768v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.10234",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhiqian Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1\">Fanglan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_T/0/1/0/all/0/1\">Taoran Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_K/0/1/0/all/0/1\">Kaiqun Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1\">Liang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1\">Feng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1\">Lingfei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aggarwal_C/0/1/0/all/0/1\">Charu Aggarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1\">Chang-Tien Lu</a>",
          "description": "During the past decade, deep learning's performance has been widely\nrecognized in a variety of machine learning tasks, ranging from image\nclassification, speech recognition to natural language understanding. Graph\nneural networks (GNN) are a type of deep learning that is designed to handle\nnon-Euclidean issues using graph-structured data that are difficult to solve\nwith traditional deep learning techniques. The majority of GNNs were created\nusing a variety of processes, including random walk, PageRank, graph\nconvolution, and heat diffusion, making direct comparisons impossible. Previous\nstudies have primarily focused on classifying current models into distinct\ncategories, with little investigation of their internal relationships. This\nresearch proposes a unified theoretical framework and a novel perspective that\ncan methodologically integrate existing GNN into our framework. We survey and\ncategorize existing GNN models into spatial and spectral domains, as well as\nshow linkages between subcategories within each domain. Further investigation\nreveals a strong relationship between the spatial, spectral, and subgroups of\nthese domains.",
          "link": "http://arxiv.org/abs/2107.10234",
          "publishedOn": "2021-07-22T02:03:12.479Z",
          "wordCount": 618,
          "title": "Bridging the Gap between Spatial and Spectral Domains: A Theoretical Framework for Graph Neural Networks. (arXiv:2107.10234v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.10253",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pertsch_K/0/1/0/all/0/1\">Karl Pertsch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1\">Youngwoon Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yue Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lim_J/0/1/0/all/0/1\">Joseph J. Lim</a>",
          "description": "Demonstration-guided reinforcement learning (RL) is a promising approach for\nlearning complex behaviors by leveraging both reward feedback and a set of\ntarget task demonstrations. Prior approaches for demonstration-guided RL treat\nevery new task as an independent learning problem and attempt to follow the\nprovided demonstrations step-by-step, akin to a human trying to imitate a\ncompletely unseen behavior by following the demonstrator's exact muscle\nmovements. Naturally, such learning will be slow, but often new behaviors are\nnot completely unseen: they share subtasks with behaviors we have previously\nlearned. In this work, we aim to exploit this shared subtask structure to\nincrease the efficiency of demonstration-guided RL. We first learn a set of\nreusable skills from large offline datasets of prior experience collected\nacross many tasks. We then propose Skill-based Learning with Demonstrations\n(SkiLD), an algorithm for demonstration-guided RL that efficiently leverages\nthe provided demonstrations by following the demonstrated skills instead of the\nprimitive actions, resulting in substantial performance improvements over prior\ndemonstration-guided RL approaches. We validate the effectiveness of our\napproach on long-horizon maze navigation and complex robot manipulation tasks.",
          "link": "http://arxiv.org/abs/2107.10253",
          "publishedOn": "2021-07-22T02:03:12.471Z",
          "wordCount": 612,
          "title": "Demonstration-Guided Reinforcement Learning with Learned Skills. (arXiv:2107.10253v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.10188",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qingxiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaliszyk_C/0/1/0/all/0/1\">Cezary Kaliszyk</a>",
          "description": "The heterogeneous nature of the logical foundations used in different\ninteractive proof assistant libraries has rendered discovery of similar\nmathematical concepts among them difficult. In this paper, we compare a\npreviously proposed algorithm for matching concepts across libraries with our\nunsupervised embedding approach that can help us retrieve similar concepts. Our\napproach is based on the fasttext implementation of Word2Vec, on top of which a\ntree traversal module is added to adapt its algorithm to the representation\nformat of our data export pipeline. We compare the explainability,\ncustomizability, and online-servability of the approaches and argue that the\nneural embedding approach has more potential to be integrated into an\ninteractive proof assistant.",
          "link": "http://arxiv.org/abs/2107.10188",
          "publishedOn": "2021-07-22T02:03:12.396Z",
          "wordCount": 553,
          "title": "JEFL: Joint Embedding of Formal Proof Libraries. (arXiv:2107.10188v1 [cs.LO])"
        },
        {
          "id": "http://arxiv.org/abs/2107.10171",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Black_E/0/1/0/all/0/1\">Emily Black</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fredrikson_M/0/1/0/all/0/1\">Matt Fredrikson</a>",
          "description": "We introduce leave-one-out unfairness, which characterizes how likely a\nmodel's prediction for an individual will change due to the inclusion or\nremoval of a single other person in the model's training data. Leave-one-out\nunfairness appeals to the idea that fair decisions are not arbitrary: they\nshould not be based on the chance event of any one person's inclusion in the\ntraining data. Leave-one-out unfairness is closely related to algorithmic\nstability, but it focuses on the consistency of an individual point's\nprediction outcome over unit changes to the training data, rather than the\nerror of the model in aggregate. Beyond formalizing leave-one-out unfairness,\nwe characterize the extent to which deep models behave leave-one-out unfairly\non real data, including in cases where the generalization error is small.\nFurther, we demonstrate that adversarial training and randomized smoothing\ntechniques have opposite effects on leave-one-out fairness, which sheds light\non the relationships between robustness, memorization, individual fairness, and\nleave-one-out fairness in deep models. Finally, we discuss salient practical\napplications that may be negatively affected by leave-one-out unfairness.",
          "link": "http://arxiv.org/abs/2107.10171",
          "publishedOn": "2021-07-22T02:03:12.363Z",
          "wordCount": 615,
          "title": "Leave-one-out Unfairness. (arXiv:2107.10171v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2104.14060",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yunxiang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_J/0/1/0/all/0/1\">Jianzhong Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qingwei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Rui Zhang</a>",
          "description": "Graph structural information such as topologies or connectivities provides\nvaluable guidance for graph convolutional networks (GCNs) to learn nodes'\nrepresentations. Existing GCN models that capture nodes' structural information\nweight in- and out-neighbors equally or differentiate in- and out-neighbors\nglobally without considering nodes' local topologies. We observe that in- and\nout-neighbors contribute differently for nodes with different local topologies.\nTo explore the directional structural information for different nodes, we\npropose a GCN model with weighted structural features, named WGCN. WGCN first\ncaptures nodes' structural fingerprints via a direction and degree aware Random\nWalk with Restart algorithm, where the walk is guided by both edge direction\nand nodes' in- and out-degrees. Then, the interactions between nodes'\nstructural fingerprints are used as the weighted node structural features. To\nfurther capture nodes' high-order dependencies and graph geometry, WGCN embeds\ngraphs into a latent space to obtain nodes' latent neighbors and geometrical\nrelationships. Based on nodes' geometrical relationships in the latent space,\nWGCN differentiates latent, in-, and out-neighbors with an attention-based\ngeometrical aggregation. Experiments on transductive node classification tasks\nshow that WGCN outperforms the baseline models consistently by up to 17.07% in\nterms of accuracy on five benchmark datasets.",
          "link": "http://arxiv.org/abs/2104.14060",
          "publishedOn": "2021-07-22T02:03:12.348Z",
          "wordCount": 667,
          "title": "WGCN: Graph Convolutional Networks with Weighted Structural Features. (arXiv:2104.14060v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.10043",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Revach_G/0/1/0/all/0/1\">Guy Revach</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shlezinger_N/0/1/0/all/0/1\">Nir Shlezinger</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ni_X/0/1/0/all/0/1\">Xiaoyong Ni</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Escoriza_A/0/1/0/all/0/1\">Adria Lopez Escoriza</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sloun_R/0/1/0/all/0/1\">Ruud J. G. van Sloun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Eldar_Y/0/1/0/all/0/1\">Yonina C. Eldar</a>",
          "description": "Real-time state estimation of dynamical systems is a fundamental task in\nsignal processing and control. For systems that are well-represented by a fully\nknown linear Gaussian state space (SS) model, the celebrated Kalman filter (KF)\nis a low complexity optimal solution. However, both linearity of the underlying\nSS model and accurate knowledge of it are often not encountered in practice.\nHere, we present KalmanNet, a real-time state estimator that learns from data\nto carry out Kalman filtering under non-linear dynamics with partial\ninformation. By incorporating the structural SS model with a dedicated\nrecurrent neural network module in the flow of the KF, we retain data\nefficiency and interpretability of the classic algorithm while implicitly\nlearning complex dynamics from data. We numerically demonstrate that KalmanNet\novercomes nonlinearities and model mismatch, outperforming classic filtering\nmethods operating with both mismatched and accurate domain knowledge.",
          "link": "http://arxiv.org/abs/2107.10043",
          "publishedOn": "2021-07-22T02:03:12.306Z",
          "wordCount": 597,
          "title": "KalmanNet: Neural Network Aided Kalman Filtering for Partially Known Dynamics. (arXiv:2107.10043v1 [eess.SP])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09892",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sudarshan_V/0/1/0/all/0/1\">Viswanath P. Sudarshan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Upadhyay_U/0/1/0/all/0/1\">Uddeshya Upadhyay</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Egan_G/0/1/0/all/0/1\">Gary F. Egan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_Z/0/1/0/all/0/1\">Zhaolin Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Awate_S/0/1/0/all/0/1\">Suyash P. Awate</a>",
          "description": "Radiation exposure in positron emission tomography (PET) imaging limits its\nusage in the studies of radiation-sensitive populations, e.g., pregnant women,\nchildren, and adults that require longitudinal imaging. Reducing the PET\nradiotracer dose or acquisition time reduces photon counts, which can\ndeteriorate image quality. Recent deep-neural-network (DNN) based methods for\nimage-to-image translation enable the mapping of low-quality PET images\n(acquired using substantially reduced dose), coupled with the associated\nmagnetic resonance imaging (MRI) images, to high-quality PET images. However,\nsuch DNN methods focus on applications involving test data that match the\nstatistical characteristics of the training data very closely and give little\nattention to evaluating the performance of these DNNs on new\nout-of-distribution (OOD) acquisitions. We propose a novel DNN formulation that\nmodels the (i) underlying sinogram-based physics of the PET imaging system and\n(ii) the uncertainty in the DNN output through the per-voxel heteroscedasticity\nof the residuals between the predicted and the high-quality reference images.\nOur sinogram-based uncertainty-aware DNN framework, namely, suDNN, estimates a\nstandard-dose PET image using multimodal input in the form of (i) a\nlow-dose/low-count PET image and (ii) the corresponding multi-contrast MRI\nimages, leading to improved robustness of suDNN to OOD acquisitions. Results on\nin vivo simultaneous PET-MRI, and various forms of OOD data in PET-MRI, show\nthe benefits of suDNN over the current state of the art, quantitatively and\nqualitatively.",
          "link": "http://arxiv.org/abs/2107.09892",
          "publishedOn": "2021-07-22T02:03:12.299Z",
          "wordCount": 699,
          "title": "Towards Lower-Dose PET using Physics-Based Uncertainty-Aware Multimodal Learning with Robustness to Out-of-Distribution Data. (arXiv:2107.09892v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2012.12310",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kaplan_A/0/1/0/all/0/1\">Alan D. Kaplan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Q/0/1/0/all/0/1\">Qi Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohan_K/0/1/0/all/0/1\">K. Aditya Mohan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nelson_L/0/1/0/all/0/1\">Lindsay D. Nelson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1\">Sonia Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levin_H/0/1/0/all/0/1\">Harvey Levin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torres_Espin_A/0/1/0/all/0/1\">Abel Torres-Espin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chou_A/0/1/0/all/0/1\">Austin Chou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huie_J/0/1/0/all/0/1\">J. Russell Huie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferguson_A/0/1/0/all/0/1\">Adam R. Ferguson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McCrea_M/0/1/0/all/0/1\">Michael McCrea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giacino_J/0/1/0/all/0/1\">Joseph Giacino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sundaram_S/0/1/0/all/0/1\">Shivshankar Sundaram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Markowitz_A/0/1/0/all/0/1\">Amy J. Markowitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manley_G/0/1/0/all/0/1\">Geoffrey T. Manley</a>",
          "description": "Prognoses of Traumatic Brain Injury (TBI) outcomes are neither easily nor\naccurately determined from clinical indicators. This is due in part to the\nheterogeneity of damage inflicted to the brain, ultimately resulting in diverse\nand complex outcomes. Using a data-driven approach on many distinct data\nelements may be necessary to describe this large set of outcomes and thereby\nrobustly depict the nuanced differences among TBI patients' recovery. In this\nwork, we develop a method for modeling large heterogeneous data types relevant\nto TBI. Our approach is geared toward the probabilistic representation of mixed\ncontinuous and discrete variables with missing values. The model is trained on\na dataset encompassing a variety of data types, including demographics,\nblood-based biomarkers, and imaging findings. In addition, it includes a set of\nclinical outcome assessments at 3, 6, and 12 months post-injury. The model is\nused to stratify patients into distinct groups in an unsupervised learning\nsetting. We use the model to infer outcomes using input data, and show that the\ncollection of input data reduces uncertainty of outcomes over a baseline\napproach. In addition, we quantify the performance of a likelihood scoring\ntechnique that can be used to self-evaluate the extrapolation risk of prognosis\non unseen patients.",
          "link": "http://arxiv.org/abs/2012.12310",
          "publishedOn": "2021-07-22T02:03:12.279Z",
          "wordCount": 721,
          "title": "Mixture Model Framework for Traumatic Brain Injury Prognosis Using Heterogeneous Clinical and Outcome Data. (arXiv:2012.12310v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1811.02319",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jiawei Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_Y/0/1/0/all/0/1\">Yingxia Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_B/0/1/0/all/0/1\">Bin Cui</a>",
          "description": "The performance of deep neural networks crucially depends on good\nhyperparameter configurations. Bayesian optimization is a powerful framework\nfor optimizing the hyperparameters of DNNs. These methods need sufficient\nevaluation data to approximate and minimize the validation error function of\nhyperparameters. However, the expensive evaluation cost of DNNs leads to very\nfew evaluation data within a limited time, which greatly reduces the efficiency\nof Bayesian optimization. Besides, the previous researches focus on using the\ncomplete evaluation data to conduct Bayesian optimization, and ignore the\nintermediate evaluation data generated by early stopping methods. To alleviate\nthe insufficient evaluation data problem, we propose a fast hyperparameter\noptimization method, HOIST, that utilizes both the complete and intermediate\nevaluation data to accelerate the hyperparameter optimization of DNNs.\nSpecifically, we train multiple basic surrogates to gather information from the\nmixed evaluation data, and then combine all basic surrogates using weighted\nbagging to provide an accurate ensemble surrogate. Our empirical studies show\nthat HOIST outperforms the state-of-the-art approaches on a wide range of DNNs,\nincluding feed forward neural networks, convolutional neural networks,\nrecurrent neural networks, and variational autoencoder.",
          "link": "http://arxiv.org/abs/1811.02319",
          "publishedOn": "2021-07-22T02:03:12.271Z",
          "wordCount": 675,
          "title": "Fast Hyperparameter Optimization of Deep Neural Networks via Ensembling Multiple Surrogates. (arXiv:1811.02319v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.10111",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pilat_M/0/1/0/all/0/1\">Martin Pil&#xe1;t</a>",
          "description": "The problem of coordinating the charging of electric vehicles gains more\nimportance as the number of such vehicles grows. In this paper, we develop a\nmethod for the training of controllers for the coordination of EV charging. In\ncontrast to most existing works on this topic, we require the controllers to\npreserve the privacy of the users, therefore we do not allow any communication\nfrom the controller to any third party.\n\nIn order to train the controllers, we use the idea of imitation learning --\nwe first find an optimum solution for a relaxed version of the problem using\nquadratic optimization and then train the controllers to imitate this solution.\nWe also investigate the effects of regularization of the optimum solution on\nthe performance of the controllers. The method is evaluated on realistic data\nand shows improved performance and training speed compared to similar\ncontrollers trained using evolutionary algorithms.",
          "link": "http://arxiv.org/abs/2107.10111",
          "publishedOn": "2021-07-22T02:03:12.263Z",
          "wordCount": 582,
          "title": "Training Electric Vehicle Charging Controllers with Imitation Learning. (arXiv:2107.10111v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09931",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Prasad_A/0/1/0/all/0/1\">Archiki Prasad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rehan_M/0/1/0/all/0/1\">Mohammad Ali Rehan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pathak_S/0/1/0/all/0/1\">Shreya Pathak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jyothi_P/0/1/0/all/0/1\">Preethi Jyothi</a>",
          "description": "While recent benchmarks have spurred a lot of new work on improving the\ngeneralization of pretrained multilingual language models on multilingual\ntasks, techniques to improve code-switched natural language understanding tasks\nhave been far less explored. In this work, we propose the use of bilingual\nintermediate pretraining as a reliable technique to derive large and consistent\nperformance gains on three different NLP tasks using code-switched text. We\nachieve substantial absolute improvements of 7.87%, 20.15%, and 10.99%, on the\nmean accuracies and F1 scores over previous state-of-the-art systems for\nHindi-English Natural Language Inference (NLI), Question Answering (QA) tasks,\nand Spanish-English Sentiment Analysis (SA) respectively. We show consistent\nperformance gains on four different code-switched language-pairs\n(Hindi-English, Spanish-English, Tamil-English and Malayalam-English) for SA.\nWe also present a code-switched masked language modelling (MLM) pretraining\ntechnique that consistently benefits SA compared to standard MLM pretraining\nusing real code-switched text.",
          "link": "http://arxiv.org/abs/2107.09931",
          "publishedOn": "2021-07-22T02:03:12.243Z",
          "wordCount": 583,
          "title": "The Effectiveness of Intermediate-Task Training for Code-Switched Natural Language Understanding. (arXiv:2107.09931v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09947",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dockes_J/0/1/0/all/0/1\">J&#xe9;ro&#xf4;me Dock&#xe8;s</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Varoquaux_G/0/1/0/all/0/1\">Ga&#xeb;l Varoquaux</a> (PARIETAL), <a href=\"http://arxiv.org/find/cs/1/au:+Poline_J/0/1/0/all/0/1\">Jean-Baptiste Poline</a>",
          "description": "Machine learning brings the hope of finding new biomarkers extracted from\ncohorts with rich biomedical measurements. A good biomarker is one that gives\nreliable detection of the corresponding condition. However, biomarkers are\noften extracted from a cohort that differs from the target population. Such a\nmismatch, known as a dataset shift, can undermine the application of the\nbiomarker to new individuals. Dataset shifts are frequent in biomedical\nresearch, e.g. because of recruitment biases. When a dataset shift occurs,\nstandard machine-learning techniques do not suffice to extract and validate\nbiomarkers. This article provides an overview of when and how dataset shifts\nbreaks machine-learning extracted biomarkers, as well as detection and\ncorrection strategies.",
          "link": "http://arxiv.org/abs/2107.09947",
          "publishedOn": "2021-07-22T02:03:12.235Z",
          "wordCount": 559,
          "title": "Preventing dataset shift from breaking machine-learning biomarkers. (arXiv:2107.09947v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.10239",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bustos_A/0/1/0/all/0/1\">Aurelia Bustos</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Mas_Serrano_P/0/1/0/all/0/1\">Patricio Mas_Serrano</a> (2 and 3), <a href=\"http://arxiv.org/find/cs/1/au:+Boquera_M/0/1/0/all/0/1\">Mari L. Boquera</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Salinas_J/0/1/0/all/0/1\">Jose M. Salinas</a> (4) ((1) MedBravo, (2) Hospital General Universitario de Alicante Spain -HGUA, (3) Institute for Health and Biomedical Research of Alicante -ISABIAL, (4) Department of Health Informatics, Hospital Universitario San Juan de Alicante Spain)",
          "description": "Introduction: Real-world data generated from clinical practice can be used to\nanalyze the real-world evidence (RWE) of COVID-19 pharmacotherapy and validate\nthe results of randomized clinical trials (RCTs). Machine learning (ML) methods\nare being used in RWE and are promising tools for precision-medicine. In this\nstudy, ML methods are applied to study the efficacy of therapies on COVID-19\nhospital admissions in the Valencian Region in Spain. Methods: 5244 and 1312\nCOVID-19 hospital admissions - dated between January 2020 and January 2021 from\n10 health departments, were used respectively for training and validation of\nseparate treatment-effect models (TE-ML) for remdesivir, corticosteroids,\ntocilizumab, lopinavir-ritonavir, azithromycin and\nchloroquine/hydroxychloroquine. 2390 admissions from 2 additional health\ndepartments were reserved as an independent test to analyze retrospectively the\nsurvival benefits of therapies in the population selected by the TE-ML models\nusing cox-proportional hazard models. TE-ML models were adjusted using\ntreatment propensity scores to control for pre-treatment confounding variables\nassociated to outcome and further evaluated for futility. ML architecture was\nbased on boosted decision-trees. Results: In the populations identified by the\nTE-ML models, only Remdesivir and Tocilizumab were significantly associated\nwith an increase in survival time, with hazard ratios of 0.41 (P = 0.04) and\n0.21 (P = 0.001), respectively. No survival benefits from chloroquine\nderivatives, lopinavir-ritonavir and azithromycin were demonstrated. Tools to\nexplain the predictions of TE-ML models are explored at patient-level as\npotential tools for personalized decision making and precision medicine.\nConclusion: ML methods are suitable tools toward RWE analysis of COVID-19\npharmacotherapies. Results obtained reproduce published results on RWE and\nvalidate the results from RCTs.",
          "link": "http://arxiv.org/abs/2107.10239",
          "publishedOn": "2021-07-22T02:03:12.228Z",
          "wordCount": 788,
          "title": "Machine Learning for Real-World Evidence Analysis of COVID-19 Pharmacotherapy. (arXiv:2107.10239v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.06424",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tavakoli_M/0/1/0/all/0/1\">Mohammadamin Tavakoli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sadowsk_P/0/1/0/all/0/1\">Peter Sadowsk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baldi_P/0/1/0/all/0/1\">Pierre Baldi</a>",
          "description": "In a physical neural system, backpropagation is faced with a number of\nobstacles including: the need for labeled data, the violation of the locality\nlearning principle, the need for symmetric connections, and the lack of\nmodularity. Tourbillon is a new architecture that addresses all these\nlimitations. At its core, it consists of a stack of circular autoencoders\nfollowed by an output layer. The circular autoencoders are trained in\nself-supervised mode by recirculation algorithms and the top layer in\nsupervised mode by stochastic gradient descent, with the option of propagating\nerror information through the entire stack using non-symmetric connections.\nWhile the Tourbillon architecture is meant primarily to address physical\nconstraints, and not to improve current engineering applications of deep\nlearning, we demonstrate its viability on standard benchmark datasets including\nMNIST, Fashion MNIST, and CIFAR10. We show that Tourbillon can achieve\ncomparable performance to models trained with backpropagation and outperform\nmodels that are trained with other physically plausible algorithms, such as\nfeedback alignment.",
          "link": "http://arxiv.org/abs/2107.06424",
          "publishedOn": "2021-07-22T02:03:12.221Z",
          "wordCount": 605,
          "title": "Tourbillon: a Physically Plausible Neural Architecture. (arXiv:2107.06424v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.10098",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lachapelle_S/0/1/0/all/0/1\">S&#xe9;bastien Lachapelle</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lopez_P/0/1/0/all/0/1\">Pau Rodr&#xed;guez L&#xf3;pez</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Priol_R/0/1/0/all/0/1\">R&#xe9;mi Le Priol</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lacoste_A/0/1/0/all/0/1\">Alexandre Lacoste</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lacoste_Julien_S/0/1/0/all/0/1\">Simon Lacoste-Julien</a>",
          "description": "It can be argued that finding an interpretable low-dimensional representation\nof a potentially high-dimensional phenomenon is central to the scientific\nenterprise. Independent component analysis (ICA) refers to an ensemble of\nmethods which formalize this goal and provide estimation procedure for\npractical application. This work proposes mechanism sparsity regularization as\na new principle to achieve nonlinear ICA when latent factors depend sparsely on\nobserved auxiliary variables and/or past latent factors. We show that the\nlatent variables can be recovered up to a permutation if one regularizes the\nlatent mechanisms to be sparse and if some graphical criterion is satisfied by\nthe data generating process. As a special case, our framework shows how one can\nleverage unknown-target interventions on the latent factors to disentangle\nthem, thus drawing further connections between ICA and causality. We validate\nour theoretical results with toy experiments.",
          "link": "http://arxiv.org/abs/2107.10098",
          "publishedOn": "2021-07-22T02:03:12.213Z",
          "wordCount": 614,
          "title": "Discovering Latent Causal Variables via Mechanism Sparsity: A New Principle for Nonlinear ICA. (arXiv:2107.10098v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2107.10004",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jaganathan_S/0/1/0/all/0/1\">Srikrishna Jaganathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jian Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borsdorf_A/0/1/0/all/0/1\">Anja Borsdorf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shetty_K/0/1/0/all/0/1\">Karthik Shetty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maier_A/0/1/0/all/0/1\">Andreas Maier</a>",
          "description": "Deep Learning-based 2D/3D registration methods are highly robust but often\nlack the necessary registration accuracy for clinical application. A refinement\nstep using the classical optimization-based 2D/3D registration method applied\nin combination with Deep Learning-based techniques can provide the required\naccuracy. However, it also increases the runtime. In this work, we propose a\nnovel Deep Learning driven 2D/3D registration framework that can be used\nend-to-end for iterative registration tasks without relying on any further\nrefinement step. We accomplish this by learning the update step of the 2D/3D\nregistration framework using Point-to-Plane Correspondences. The update step is\nlearned using iterative residual refinement-based optical flow estimation, in\ncombination with the Point-to-Plane correspondence solver embedded as a known\noperator. Our proposed method achieves an average runtime of around 8s, a mean\nre-projection distance error of 0.60 $\\pm$ 0.40 mm with a success ratio of 97\npercent and a capture range of 60 mm. The combination of high registration\naccuracy, high robustness, and fast runtime makes our solution ideal for\nclinical applications.",
          "link": "http://arxiv.org/abs/2107.10004",
          "publishedOn": "2021-07-22T02:03:12.195Z",
          "wordCount": 616,
          "title": "Deep Iterative 2D/3D Registration. (arXiv:2107.10004v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.10209",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Awasthi_P/0/1/0/all/0/1\">Pranjal Awasthi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_A/0/1/0/all/0/1\">Alex Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vijayaraghavan_A/0/1/0/all/0/1\">Aravindan Vijayaraghavan</a>",
          "description": "We present polynomial time and sample efficient algorithms for learning an\nunknown depth-2 feedforward neural network with general ReLU activations, under\nmild non-degeneracy assumptions. In particular, we consider learning an unknown\nnetwork of the form $f(x) = {a}^{\\mathsf{T}}\\sigma({W}^\\mathsf{T}x+b)$, where\n$x$ is drawn from the Gaussian distribution, and $\\sigma(t) := \\max(t,0)$ is\nthe ReLU activation. Prior works for learning networks with ReLU activations\nassume that the bias $b$ is zero. In order to deal with the presence of the\nbias terms, our proposed algorithm consists of robustly decomposing multiple\nhigher order tensors arising from the Hermite expansion of the function $f(x)$.\nUsing these ideas we also establish identifiability of the network parameters\nunder minimal assumptions.",
          "link": "http://arxiv.org/abs/2107.10209",
          "publishedOn": "2021-07-22T02:03:12.177Z",
          "wordCount": 564,
          "title": "Efficient Algorithms for Learning Depth-2 Neural Networks with General ReLU Activations. (arXiv:2107.10209v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09936",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kallis_R/0/1/0/all/0/1\">Rafael Kallis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sorbo_A/0/1/0/all/0/1\">Andrea Di Sorbo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Canfora_G/0/1/0/all/0/1\">Gerardo Canfora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panichella_S/0/1/0/all/0/1\">Sebastiano Panichella</a>",
          "description": "Software maintenance and evolution involves critical activities for the\nsuccess of software projects. To support such activities and keep code\nup-to-date and error-free, software communities make use of issue trackers,\ni.e., tools for signaling, handling, and addressing the issues occurring in\nsoftware systems. However, in popular projects, tens or hundreds of issue\nreports are daily submitted. In this context, identifying the type of each\nsubmitted report (e.g., bug report, feature request, etc.) would facilitate the\nmanagement and the prioritization of the issues to address. To support issue\nhandling activities, in this paper, we propose Ticket Tagger, a GitHub app\nanalyzing the issue title and description through machine learning techniques\nto automatically recognize the types of reports submitted on GitHub and assign\nlabels to each issue accordingly. We empirically evaluated the tool's\nprediction performance on about 30,000 GitHub issues. Our results show that the\nTicket Tagger can identify the correct labels to assign to GitHub issues with\nreasonably high effectiveness. Considering these results and the fact that the\ntool is designed to be easily integrated in the GitHub issue management\nprocess, Ticket Tagger consists in a useful solution for developers.",
          "link": "http://arxiv.org/abs/2107.09936",
          "publishedOn": "2021-07-22T02:03:12.170Z",
          "wordCount": 618,
          "title": "Predicting Issue Types on GitHub. (arXiv:2107.09936v1 [cs.SE])"
        },
        {
          "id": "http://arxiv.org/abs/2107.10034",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chvalovsky_K/0/1/0/all/0/1\">Karel Chvalovsk&#xfd;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jakub%5Cr%7Bu%7Dv_J/0/1/0/all/0/1\">Jan Jakub&#x16f;v</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Olsak_M/0/1/0/all/0/1\">Miroslav Ol&#x161;&#xe1;k</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Urban_J/0/1/0/all/0/1\">Josef Urban</a>",
          "description": "Saturation-style automated theorem provers (ATPs) based on the given clause\nprocedure are today the strongest general reasoners for classical first-order\nlogic. The clause selection heuristics in such systems are, however, often\nevaluating clauses in isolation, ignoring other clauses. This has changed\nrecently by equipping the E/ENIGMA system with a graph neural network (GNN)\nthat chooses the next given clause based on its evaluation in the context of\npreviously selected clauses. In this work, we describe several algorithms and\nexperiments with ENIGMA, advancing the idea of contextual evaluation based on\nlearning important components of the graph of clauses.",
          "link": "http://arxiv.org/abs/2107.10034",
          "publishedOn": "2021-07-22T02:03:12.132Z",
          "wordCount": 544,
          "title": "Learning Theorem Proving Components. (arXiv:2107.10034v1 [cs.LO])"
        },
        {
          "id": "http://arxiv.org/abs/2107.10254",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Venkataraman_S/0/1/0/all/0/1\">Shobha Venkataraman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amos_B/0/1/0/all/0/1\">Brandon Amos</a>",
          "description": "Fixed-point iterations are at the heart of numerical computing and are often\na computational bottleneck in real-time applications, which typically instead\nneed a fast solution of moderate accuracy. Classical acceleration methods for\nfixed-point problems focus on designing algorithms with theoretical guarantees\nthat apply to any fixed-point problem. We present neural fixed-point\nacceleration, a framework to automatically learn to accelerate convex\nfixed-point problems that are drawn from a distribution, using ideas from\nmeta-learning and classical acceleration algorithms. We apply our framework to\nSCS, the state-of-the-art solver for convex cone programming, and design models\nand loss functions to overcome the challenges of learning over unrolled\noptimization and acceleration instabilities. Our work brings neural\nacceleration into any optimization problem expressible with CVXPY. The source\ncode behind this paper is available at\nhttps://github.com/facebookresearch/neural-scs",
          "link": "http://arxiv.org/abs/2107.10254",
          "publishedOn": "2021-07-22T02:03:12.124Z",
          "wordCount": 565,
          "title": "Neural Fixed-Point Acceleration for Convex Optimization. (arXiv:2107.10254v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.10154",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Krajnak_V/0/1/0/all/0/1\">Vladim&#xed;r Kraj&#x148;&#xe1;k</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Naik_S/0/1/0/all/0/1\">Shibabrat Naik</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Wiggins_S/0/1/0/all/0/1\">Stephen Wiggins</a>",
          "description": "In this paper we use support vector machines (SVM) to develop a machine\nlearning framework to discover the phase space structure that can distinguish\nbetween distinct reaction pathways. The machine learning model is trained using\ndata from trajectories of Hamilton's equations but lends itself for use in\nmolecular dynamics simulation. The framework is specifically designed to\nrequire minimal a priori knowledge of the dynamics in a system. We benchmark\nour approach with a model Hamiltonian for the reaction of an ion and a molecule\ndue to Chesnavich consisting of two parts: a rigid, symmetric top representing\nthe $\\text{CH}_3^{+}$ ion, and a mobile $\\text{H}$ atom. We begin with\ntrajectories and use support vector machines to determine the boundaries\nbetween initial conditions corresponding to different classes of trajectories.\nWe then show that these boundaries between different classes of trajectories\napproximate invariant phase space structures of the same type observed in\nearlier analyses of Chesnavich's model. Our approach is designed with\nextensions to higher-dimensional applications in mind. SVM is known to work\nwell even with small amounts of data, therefore our approach is computationally\nbetter suited than existing methods for high-dimensional systems and systems\nwhere integrating trajectories is expensive.",
          "link": "http://arxiv.org/abs/2107.10154",
          "publishedOn": "2021-07-22T02:03:12.093Z",
          "wordCount": 631,
          "title": "Predicting trajectory behaviour via machine-learned invariant manifolds. (arXiv:2107.10154v1 [physics.chem-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09700",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Hong_S/0/1/0/all/0/1\">Sungmin Hong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Marinescu_R/0/1/0/all/0/1\">Razvan Marinescu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dalca_A/0/1/0/all/0/1\">Adrian V. Dalca</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bonkhoff_A/0/1/0/all/0/1\">Anna K. Bonkhoff</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bretzner_M/0/1/0/all/0/1\">Martin Bretzner</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rost_N/0/1/0/all/0/1\">Natalia S. Rost</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Golland_P/0/1/0/all/0/1\">Polina Golland</a>",
          "description": "Image synthesis via Generative Adversarial Networks (GANs) of\nthree-dimensional (3D) medical images has great potential that can be extended\nto many medical applications, such as, image enhancement and disease\nprogression modeling. However, current GAN technologies for 3D medical image\nsynthesis need to be significantly improved to be readily adapted to real-world\nmedical problems. In this paper, we extend the state-of-the-art StyleGAN2\nmodel, which natively works with two-dimensional images, to enable 3D image\nsynthesis. In addition to the image synthesis, we investigate the\ncontrollability and interpretability of the 3D-StyleGAN via style vectors\ninherited form the original StyleGAN2 that are highly suitable for medical\napplications: (i) the latent space projection and reconstruction of unseen real\nimages, and (ii) style mixing. We demonstrate the 3D-StyleGAN's performance and\nfeasibility with ~12,000 three-dimensional full brain MR T1 images, although it\ncan be applied to any 3D volumetric images. Furthermore, we explore different\nconfigurations of hyperparameters to investigate potential improvement of the\nimage synthesis with larger networks. The codes and pre-trained networks are\navailable online: https://github.com/sh4174/3DStyleGAN.",
          "link": "http://arxiv.org/abs/2107.09700",
          "publishedOn": "2021-07-22T02:03:12.057Z",
          "wordCount": null,
          "title": "3D-StyleGAN: A Style-Based Generative Adversarial Network for Generative Modeling of Three-Dimensional Medical Images. (arXiv:2107.09700v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09804",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Majumdar_S/0/1/0/all/0/1\">Saikat Majumdar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samavatian_M/0/1/0/all/0/1\">Mohammad Hossein Samavatian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barber_K/0/1/0/all/0/1\">Kristin Barber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teodorescu_R/0/1/0/all/0/1\">Radu Teodorescu</a>",
          "description": "Deep neural network (DNN) classifiers are powerful tools that drive a broad\nspectrum of important applications, from image recognition to autonomous\nvehicles. Unfortunately, DNNs are known to be vulnerable to adversarial attacks\nthat affect virtually all state-of-the-art models. These attacks make small\nimperceptible modifications to inputs that are sufficient to induce the DNNs to\nproduce the wrong classification.\n\nIn this paper we propose a novel, lightweight adversarial correction and/or\ndetection mechanism for image classifiers that relies on undervolting (running\na chip at a voltage that is slightly below its safe margin). We propose using\ncontrolled undervolting of the chip running the inference process in order to\nintroduce a limited number of compute errors. We show that these errors disrupt\nthe adversarial input in a way that can be used either to correct the\nclassification or detect the input as adversarial. We evaluate the proposed\nsolution in an FPGA design and through software simulation. We evaluate 10\nattacks on two popular DNNs and show an average detection rate of 80% to 95%.",
          "link": "http://arxiv.org/abs/2107.09804",
          "publishedOn": "2021-07-22T02:03:11.978Z",
          "wordCount": null,
          "title": "Using Undervolting as an On-Device Defense Against Adversarial Machine Learning Attacks. (arXiv:2107.09804v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2002.01335",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Slowik_A/0/1/0/all/0/1\">Agnieszka S&#x142;owik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Abhinav Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamilton_W/0/1/0/all/0/1\">William L. Hamilton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jamnik_M/0/1/0/all/0/1\">Mateja Jamnik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holden_S/0/1/0/all/0/1\">Sean B. Holden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pal_C/0/1/0/all/0/1\">Christopher Pal</a>",
          "description": "In order to communicate, humans flatten a complex representation of ideas and\ntheir attributes into a single word or a sentence. We investigate the impact of\nrepresentation learning in artificial agents by developing graph referential\ngames. We empirically show that agents parametrized by graph neural networks\ndevelop a more compositional language compared to bag-of-words and sequence\nmodels, which allows them to systematically generalize to new combinations of\nfamiliar features.",
          "link": "http://arxiv.org/abs/2002.01335",
          "publishedOn": "2021-07-22T02:03:11.963Z",
          "wordCount": null,
          "title": "Structural Inductive Biases in Emergent Communication. (arXiv:2002.01335v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2002.11867",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhiqian Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1\">Fanglan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_T/0/1/0/all/0/1\">Taoran Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_K/0/1/0/all/0/1\">Kaiqun Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1\">Liang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1\">Feng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1\">Lingfei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aggarwal_C/0/1/0/all/0/1\">Charu Aggarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1\">Chang-Tien Lu</a>",
          "description": "Deep learning's success has been widely recognized in a variety of machine\nlearning tasks, including image classification, audio recognition, and natural\nlanguage processing. As an extension of deep learning beyond these domains,\ngraph neural networks (GNNs) are designed to handle the non-Euclidean\ngraph-structure which is intractable to previous deep learning techniques.\nExisting GNNs are presented using various techniques, making direct comparison\nand cross-reference more complex. Although existing studies categorize GNNs\ninto spatial-based and spectral-based techniques, there hasn't been a thorough\nexamination of their relationship. To close this gap, this study presents a\nsingle framework that systematically incorporates most GNNs. We organize\nexisting GNNs into spatial and spectral domains, as well as expose the\nconnections within each domain. A review of spectral graph theory and\napproximation theory builds a strong relationship across the spatial and\nspectral domains in further investigation.",
          "link": "http://arxiv.org/abs/2002.11867",
          "publishedOn": "2021-07-22T02:03:11.958Z",
          "wordCount": null,
          "title": "Bridging the Gap between Spatial and Spectral Domains: A Survey on Graph Neural Networks. (arXiv:2002.11867v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.14993",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chang_M/0/1/0/all/0/1\">Michael Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaushik_S/0/1/0/all/0/1\">Sidhant Kaushik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1\">Sergey Levine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Griffiths_T/0/1/0/all/0/1\">Thomas L. Griffiths</a>",
          "description": "Many transfer problems require re-using previously optimal decisions for\nsolving new tasks, which suggests the need for learning algorithms that can\nmodify the mechanisms for choosing certain actions independently of those for\nchoosing others. However, there is currently no formalism nor theory for how to\nachieve this kind of modular credit assignment. To answer this question, we\ndefine modular credit assignment as a constraint on minimizing the algorithmic\nmutual information among feedback signals for different decisions. We introduce\nwhat we call the modularity criterion for testing whether a learning algorithm\nsatisfies this constraint by performing causal analysis on the algorithm\nitself. We generalize the recently proposed societal decision-making framework\nas a more granular formalism than the Markov decision process to prove that for\ndecision sequences that do not contain cycles, certain single-step temporal\ndifference action-value methods meet this criterion while all policy-gradient\nmethods do not. Empirical evidence suggests that such action-value methods are\nmore sample efficient than policy-gradient methods on transfer problems that\nrequire only sparse changes to a sequence of previously optimal decisions.",
          "link": "http://arxiv.org/abs/2106.14993",
          "publishedOn": "2021-07-22T02:03:11.878Z",
          "wordCount": 692,
          "title": "Modularity in Reinforcement Learning via Algorithmic Independence in Credit Assignment. (arXiv:2106.14993v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.13461",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_E/0/1/0/all/0/1\">Enpeng Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hentenryck_P/0/1/0/all/0/1\">Pascal Van Hentenryck</a>",
          "description": "Large-scale ride-sharing systems combine real-time dispatching and routing\noptimization over a rolling time horizon with a model predictive control (MPC)\ncomponent that relocates idle vehicles to anticipate the demand. The MPC\noptimization operates over a longer time horizon to compensate for the inherent\nmyopic nature of the real-time dispatching. These longer time horizons are\nbeneficial for the quality of relocation decisions but increase computational\ncomplexity. Consequently, the ride-sharing operators are often forced to use a\nrelatively short time horizon. To address this computational challenge, this\npaper proposes a hybrid approach that combines machine learning and\noptimization. The machine-learning component learns the optimal solution to the\nMPC on the aggregated level to overcome the sparsity and high-dimensionality of\nthe solution. The optimization component transforms the machine-learning\nprediction back to the original granularity through a tractable transportation\nmodel. As a consequence, the original NP-hard MPC problem is reduced to a\npolynomial time prediction and optimization, which allows the ride-sharing\noperators to consider a longer time horizon. Experimental results show that the\nhybrid approach achieves significantly better service quality than the MPC\noptimization in terms of average rider waiting time, due to its ability to\nmodel a longer horizon.",
          "link": "http://arxiv.org/abs/2105.13461",
          "publishedOn": "2021-07-22T02:03:11.869Z",
          "wordCount": 666,
          "title": "Learning Model-Based Vehicle-Relocation Decisions for Real-Time Ride-Sharing: Hybridizing Learning and Optimization. (arXiv:2105.13461v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05426",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Antonello_R/0/1/0/all/0/1\">Richard Antonello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turek_J/0/1/0/all/0/1\">Javier Turek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vo_V/0/1/0/all/0/1\">Vy Vo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huth_A/0/1/0/all/0/1\">Alexander Huth</a>",
          "description": "How related are the representations learned by neural language models,\ntranslation models, and language tagging tasks? We answer this question by\nadapting an encoder-decoder transfer learning method from computer vision to\ninvestigate the structure among 100 different feature spaces extracted from\nhidden representations of various networks trained on language tasks. This\nmethod reveals a low-dimensional structure where language models and\ntranslation models smoothly interpolate between word embeddings, syntactic and\nsemantic tasks, and future word embeddings. We call this low-dimensional\nstructure a language representation embedding because it encodes the\nrelationships between representations needed to process language for a variety\nof NLP tasks. We find that this representation embedding can predict how well\neach individual feature space maps to human brain responses to natural language\nstimuli recorded using fMRI. Additionally, we find that the principal dimension\nof this structure can be used to create a metric which highlights the brain's\nnatural language processing hierarchy. This suggests that the embedding\ncaptures some part of the brain's natural language representation structure.",
          "link": "http://arxiv.org/abs/2106.05426",
          "publishedOn": "2021-07-22T02:03:11.861Z",
          "wordCount": 653,
          "title": "Low-Dimensional Structure in the Space of Language Representations is Reflected in Brain Responses. (arXiv:2106.05426v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.09729",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shaham_U/0/1/0/all/0/1\">Uri Shaham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levy_O/0/1/0/all/0/1\">Omer Levy</a>",
          "description": "We combine beam search with the probabilistic pruning technique of nucleus\nsampling to create two deterministic nucleus search algorithms for natural\nlanguage generation. The first algorithm, p-exact search, locally prunes the\nnext-token distribution and performs an exact search over the remaining space.\nThe second algorithm, dynamic beam search, shrinks and expands the beam size\naccording to the entropy of the candidate's probability distribution. Despite\nthe probabilistic intuition behind nucleus search, experiments on machine\ntranslation and summarization benchmarks show that both algorithms reach the\nsame performance levels as standard beam search.",
          "link": "http://arxiv.org/abs/2107.09729",
          "publishedOn": "2021-07-22T02:03:11.854Z",
          "wordCount": 534,
          "title": "What Do You Get When You Cross Beam Search with Nucleus Sampling?. (arXiv:2107.09729v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09853",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Furui_A/0/1/0/all/0/1\">Akira Furui</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Igaue_T/0/1/0/all/0/1\">Takuya Igaue</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tsuji_T/0/1/0/all/0/1\">Toshio Tsuji</a>",
          "description": "Electromyogram (EMG) has been utilized to interface signals for prosthetic\nhands and information devices owing to its ability to reflect human motion\nintentions. Although various EMG classification methods have been introduced\ninto EMG-based control systems, they do not fully consider the stochastic\ncharacteristics of EMG signals. This paper proposes an EMG pattern\nclassification method incorporating a scale mixture-based generative model. A\nscale mixture model is a stochastic EMG model in which the EMG variance is\nconsidered as a random variable, enabling the representation of uncertainty in\nthe variance. This model is extended in this study and utilized for EMG pattern\nclassification. The proposed method is trained by variational Bayesian\nlearning, thereby allowing the automatic determination of the model complexity.\nFurthermore, to optimize the hyperparameters of the proposed method with a\npartial discriminative approach, a mutual information-based determination\nmethod is introduced. Simulation and EMG analysis experiments demonstrated the\nrelationship between the hyperparameters and classification accuracy of the\nproposed method as well as the validity of the proposed method. The comparison\nusing public EMG datasets revealed that the proposed method outperformed the\nvarious conventional classifiers. These results indicated the validity of the\nproposed method and its applicability to EMG-based control systems. In EMG\npattern recognition, a classifier based on a generative model that reflects the\nstochastic characteristics of EMG signals can outperform the conventional\ngeneral-purpose classifier.",
          "link": "http://arxiv.org/abs/2107.09853",
          "publishedOn": "2021-07-22T02:03:11.824Z",
          "wordCount": 686,
          "title": "EMG Pattern Recognition via Bayesian Inference with Scale Mixture-Based Stochastic Generative Models. (arXiv:2107.09853v1 [eess.SP])"
        },
        {
          "id": "http://arxiv.org/abs/2104.09036",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jinghao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yanqiao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qiang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuhui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Liang Wang</a>",
          "description": "Multimedia content is of predominance in the modern Web era. Investigating\nhow users interact with multimodal items is a continuing concern within the\nrapid development of recommender systems. The majority of previous work focuses\non modeling user-item interactions with multimodal features included as side\ninformation. However, this scheme is not well-designed for multimedia\nrecommendation. Specifically, only collaborative item-item relationships are\nimplicitly modeled through high-order item-user-item relations. Considering\nthat items are associated with rich contents in multiple modalities, we argue\nthat the latent semantic item-item structures underlying these multimodal\ncontents could be beneficial for learning better item representations and\nfurther boosting recommendation. To this end, we propose a LATent sTructure\nmining method for multImodal reCommEndation, which we term LATTICE for brevity.\nTo be specific, in the proposed LATTICE model, we devise a novel modality-aware\nstructure learning layer, which learns item-item structures for each modality\nand aggregates multiple modalities to obtain latent item graphs. Based on the\nlearned latent graphs, we perform graph convolutions to explicitly inject\nhigh-order item affinities into item representations. These enriched item\nrepresentations can then be plugged into existing collaborative filtering\nmethods to make more accurate recommendations. Extensive experiments on three\nreal-world datasets demonstrate the superiority of our method over\nstate-of-the-art multimedia recommendation methods and validate the efficacy of\nmining latent item-item relationships from multimodal features.",
          "link": "http://arxiv.org/abs/2104.09036",
          "publishedOn": "2021-07-22T02:03:11.794Z",
          "wordCount": 695,
          "title": "Mining Latent Structures for Multimedia Recommendation. (arXiv:2104.09036v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.09814",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Kontolati_K/0/1/0/all/0/1\">Katiana Kontolati</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Loukrezis_D/0/1/0/all/0/1\">Dimitrios Loukrezis</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Santos_K/0/1/0/all/0/1\">Ketson R. M. dos Santos</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Giovanis_D/0/1/0/all/0/1\">Dimitrios G. Giovanis</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Shields_M/0/1/0/all/0/1\">Michael D. Shields</a>",
          "description": "In this work we introduce a manifold learning-based method for uncertainty\nquantification (UQ) in systems describing complex spatiotemporal processes. Our\nfirst objective is to identify the embedding of a set of high-dimensional data\nrepresenting quantities of interest of the computational or analytical model.\nFor this purpose, we employ Grassmannian diffusion maps, a two-step nonlinear\ndimension reduction technique which allows us to reduce the dimensionality of\nthe data and identify meaningful geometric descriptions in a parsimonious and\ninexpensive manner. Polynomial chaos expansion is then used to construct a\nmapping between the stochastic input parameters and the diffusion coordinates\nof the reduced space. An adaptive clustering technique is proposed to identify\nan optimal number of clusters of points in the latent space. The similarity of\npoints allows us to construct a number of geometric harmonic emulators which\nare finally utilized as a set of inexpensive pre-trained models to perform an\ninverse map of realizations of latent features to the ambient space and thus\nperform accurate out-of-sample predictions. Thus, the proposed method acts as\nan encoder-decoder system which is able to automatically handle very\nhigh-dimensional data while simultaneously operating successfully in the\nsmall-data regime. The method is demonstrated on two benchmark problems and on\na system of advection-diffusion-reaction equations which model a first-order\nchemical reaction between two species. In all test cases, the proposed method\nis able to achieve highly accurate approximations which ultimately lead to the\nsignificant acceleration of UQ tasks.",
          "link": "http://arxiv.org/abs/2107.09814",
          "publishedOn": "2021-07-22T02:03:11.771Z",
          "wordCount": 699,
          "title": "Manifold learning-based polynomial chaos expansions for high-dimensional surrogate models. (arXiv:2107.09814v1 [physics.data-an])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09802",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chien_S/0/1/0/all/0/1\">Steve Chien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_P/0/1/0/all/0/1\">Prateek Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krichene_W/0/1/0/all/0/1\">Walid Krichene</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rendle_S/0/1/0/all/0/1\">Steffen Rendle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1\">Shuang Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thakurta_A/0/1/0/all/0/1\">Abhradeep Thakurta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Li Zhang</a>",
          "description": "We study the problem of differentially private (DP) matrix completion under\nuser-level privacy. We design a joint differentially private variant of the\npopular Alternating-Least-Squares (ALS) method that achieves: i) (nearly)\noptimal sample complexity for matrix completion (in terms of number of items,\nusers), and ii) the best known privacy/utility trade-off both theoretically, as\nwell as on benchmark data sets. In particular, we provide the first global\nconvergence analysis of ALS with noise introduced to ensure DP, and show that,\nin comparison to the best known alternative (the Private Frank-Wolfe algorithm\nby Jain et al. (2018)), our error bounds scale significantly better with\nrespect to the number of items and users, which is critical in practical\nproblems. Extensive validation on standard benchmarks demonstrate that the\nalgorithm, in combination with carefully designed sampling procedures, is\nsignificantly more accurate than existing techniques, thus promising to be the\nfirst practical DP embedding model.",
          "link": "http://arxiv.org/abs/2107.09802",
          "publishedOn": "2021-07-22T02:03:11.763Z",
          "wordCount": 601,
          "title": "Private Alternating Least Squares: Practical Private Matrix Completion with Tighter Rates. (arXiv:2107.09802v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09766",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tsukada_T/0/1/0/all/0/1\">Takeshi Tsukada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Unno_H/0/1/0/all/0/1\">Hiroshi Unno</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sekiyama_T/0/1/0/all/0/1\">Taro Sekiyama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suenaga_K/0/1/0/all/0/1\">Kohei Suenaga</a>",
          "description": "Loop-invariant synthesis is the basis of every program verification\nprocedure. Due to its undecidability in general, a tool for invariant synthesis\nnecessarily uses heuristics. Despite the common belief that the design of\nheuristics is vital for the effective performance of a verifier, little work\nhas been performed toward obtaining the optimal heuristics for each\ninvariant-synthesis tool. Instead, developers have hand-tuned the heuristics of\ntools. This study demonstrates that we can effectively and automatically learn\na good heuristic via reinforcement learning for an invariant synthesizer PCSat.\nOur experiment shows that PCSat combined with the heuristic learned by\nreinforcement learning outperforms the state-of-the-art solvers for this task.\nTo the best of our knowledge, this is the first work that investigates learning\nthe heuristics of an invariant synthesis tool.",
          "link": "http://arxiv.org/abs/2107.09766",
          "publishedOn": "2021-07-22T02:03:11.756Z",
          "wordCount": 560,
          "title": "Enhancing Loop-Invariant Synthesis via Reinforcement Learning. (arXiv:2107.09766v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/1808.01345",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cazzaniga_P/0/1/0/all/0/1\">Paolo Cazzaniga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nobile_M/0/1/0/all/0/1\">Marco S. Nobile</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramazzotti_D/0/1/0/all/0/1\">Daniele Ramazzotti</a>",
          "description": "Bayesian Networks have been widely used in the last decades in many fields,\nto describe statistical dependencies among random variables. In general,\nlearning the structure of such models is a problem with considerable\ntheoretical interest that poses many challenges. On the one hand, it is a\nwell-known NP-complete problem, practically hardened by the huge search space\nof possible solutions. On the other hand, the phenomenon of I-equivalence,\ni.e., different graphical structures underpinning the same set of statistical\ndependencies, may lead to multimodal fitness landscapes further hindering\nmaximum likelihood approaches to solve the task. In particular, we exploit the\nNSGA-II multi-objective optimization procedure in order to explicitly account\nfor both the likelihood of a solution and the number of selected arcs, by\nsetting these as the two objective functions of the method. The aim of this\nwork is to investigate the behavior of NSGA-II and analyse the quality of its\nsolutions. We thus thoroughly examined the optimization results obtained on a\nwide set of simulated data, by considering both the goodness of the inferred\nsolutions in terms of the objective functions values achieved, and by comparing\nthe retrieved structures with the ground truth, i.e., the networks used to\ngenerate the target data. Our results show that NSGA-II can converge to\nsolutions characterized by better likelihood and less arcs than classic\napproaches, although paradoxically characterized in many cases by a lower\nsimilarity with the target network.",
          "link": "http://arxiv.org/abs/1808.01345",
          "publishedOn": "2021-07-22T02:03:11.747Z",
          "wordCount": 701,
          "title": "Investigating the performance of multi-objective optimization when learning Bayesian Networks. (arXiv:1808.01345v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.05373",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Oliveira_C/0/1/0/all/0/1\">Catarina Oliveira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torres_J/0/1/0/all/0/1\">Jo&#xe3;o Torres</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silva_M/0/1/0/all/0/1\">Maria In&#xea;s Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aparicio_D/0/1/0/all/0/1\">David Apar&#xed;cio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ascensao_J/0/1/0/all/0/1\">Jo&#xe3;o Tiago Ascens&#xe3;o</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bizarro_P/0/1/0/all/0/1\">Pedro Bizarro</a>",
          "description": "Money laundering is a global phenomenon with wide-reaching social and\neconomic consequences. Cryptocurrencies are particularly susceptible due to the\nlack of control by authorities and their anonymity. Thus, it is important to\ndevelop new techniques to detect and prevent illicit cryptocurrency\ntransactions. In our work, we propose new features based on the structure of\nthe graph and past labels to boost the performance of machine learning methods\nto detect money laundering. Our method, GuiltyWalker, performs random walks on\nthe bitcoin transaction graph and computes features based on the distance to\nillicit transactions. We combine these new features with features proposed by\nWeber et al. and observe an improvement of about 5pp regarding illicit\nclassification. Namely, we observe that our proposed features are particularly\nhelpful during a black market shutdown, where the algorithm by Weber et al. was\nlow performing.",
          "link": "http://arxiv.org/abs/2102.05373",
          "publishedOn": "2021-07-22T02:03:11.738Z",
          "wordCount": 613,
          "title": "GuiltyWalker: Distance to illicit nodes in the Bitcoin network. (arXiv:2102.05373v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.09898",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jiankai Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yuanshun Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1\">Weihao Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1\">Junyuan Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chong Wang</a>",
          "description": "Recently researchers have studied input leakage problems in Federated\nLearning (FL) where a malicious party can reconstruct sensitive training inputs\nprovided by users from shared gradient. It raises concerns about FL since input\nleakage contradicts the privacy-preserving intention of using FL. Despite a\nrelatively rich literature on attacks and defenses of input reconstruction in\nHorizontal FL, input leakage and protection in vertical FL starts to draw\nresearcher's attention recently. In this paper, we study how to defend against\ninput leakage attacks in Vertical FL. We design an adversarial training-based\nframework that contains three modules: adversarial reconstruction, noise\nregularization, and distance correlation minimization. Those modules can not\nonly be employed individually but also applied together since they are\nindependent to each other. Through extensive experiments on a large-scale\nindustrial online advertising dataset, we show our framework is effective in\nprotecting input privacy while retaining the model utility.",
          "link": "http://arxiv.org/abs/2107.09898",
          "publishedOn": "2021-07-22T02:03:11.719Z",
          "wordCount": 603,
          "title": "Defending against Reconstruction Attack in Vertical Federated Learning. (arXiv:2107.09898v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.05855",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chourasia_R/0/1/0/all/0/1\">Rishav Chourasia</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ye_J/0/1/0/all/0/1\">Jiayuan Ye</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shokri_R/0/1/0/all/0/1\">Reza Shokri</a>",
          "description": "What is the information leakage of an iterative learning algorithm about its\ntraining data, when the internal state of the algorithm is \\emph{not}\nobservable? How much is the contribution of each specific training epoch to the\nfinal leakage? We study this problem for noisy gradient descent algorithms, and\nmodel the \\emph{dynamics} of R\\'enyi differential privacy loss throughout the\ntraining process. Our analysis traces a provably tight bound on the R\\'enyi\ndivergence between the pair of probability distributions over parameters of\nmodels with neighboring datasets. We prove that the privacy loss converges\nexponentially fast, for smooth and strongly convex loss functions, which is a\nsignificant improvement over composition theorems. For Lipschitz, smooth, and\nstrongly convex loss functions, we prove optimal utility for differential\nprivacy algorithms with a small gradient complexity.",
          "link": "http://arxiv.org/abs/2102.05855",
          "publishedOn": "2021-07-22T02:03:11.710Z",
          "wordCount": 597,
          "title": "Differential Privacy Dynamics of Langevin Diffusion and Noisy Gradient Descent. (arXiv:2102.05855v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.12903",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Ximei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jinghan Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_M/0/1/0/all/0/1\">Mingsheng Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianmin Wang</a>",
          "description": "Deep learning has made revolutionary advances to diverse applications in the\npresence of large-scale labeled datasets. However, it is prohibitively\ntime-costly and labor-expensive to collect sufficient labeled data in most\nrealistic scenarios. To mitigate the requirement for labeled data,\nsemi-supervised learning (SSL) focuses on simultaneously exploring both labeled\nand unlabeled data, while transfer learning (TL) popularizes a favorable\npractice of fine-tuning a pre-trained model to the target data. A dilemma is\nthus encountered: Without a decent pre-trained model to provide an implicit\nregularization, SSL through self-training from scratch will be easily misled by\ninaccurate pseudo-labels, especially in large-sized label space; Without\nexploring the intrinsic structure of unlabeled data, TL through fine-tuning\nfrom limited labeled data is at risk of under-transfer caused by model shift.\nTo escape from this dilemma, we present Self-Tuning to enable data-efficient\ndeep learning by unifying the exploration of labeled and unlabeled data and the\ntransfer of a pre-trained model, as well as a Pseudo Group Contrast (PGC)\nmechanism to mitigate the reliance on pseudo-labels and boost the tolerance to\nfalse labels. Self-Tuning outperforms its SSL and TL counterparts on five tasks\nby sharp margins, e.g. it doubles the accuracy of fine-tuning on Cars with 15%\nlabels.",
          "link": "http://arxiv.org/abs/2102.12903",
          "publishedOn": "2021-07-22T02:03:11.692Z",
          "wordCount": 661,
          "title": "Self-Tuning for Data-Efficient Deep Learning. (arXiv:2102.12903v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.01508",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Goffrier_G/0/1/0/all/0/1\">Graham W. Van Goffrier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mostajeran_C/0/1/0/all/0/1\">Cyrus Mostajeran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sepulchre_R/0/1/0/all/0/1\">Rodolphe Sepulchre</a>",
          "description": "Covariance data as represented by symmetric positive definite (SPD) matrices\nare ubiquitous throughout technical study as efficient descriptors of\ninterdependent systems. Euclidean analysis of SPD matrices, while\ncomputationally fast, can lead to skewed and even unphysical interpretations of\ndata. Riemannian methods preserve the geometric structure of SPD data at the\ncost of expensive eigenvalue computations. In this paper, we propose a\ngeometric method for unsupervised clustering of SPD data based on the Thompson\nmetric. This technique relies upon a novel \"inductive midrange\" centroid\ncomputation for SPD data, whose properties are examined and numerically\nconfirmed. We demonstrate the incorporation of the Thompson metric and\ninductive midrange into X-means and K-means++ clustering algorithms.",
          "link": "http://arxiv.org/abs/2006.01508",
          "publishedOn": "2021-07-22T02:03:11.685Z",
          "wordCount": 582,
          "title": "Inductive Geometric Matrix Midranges. (arXiv:2006.01508v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.09989",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Li_G/0/1/0/all/0/1\">Guangyuan Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lv_J/0/1/0/all/0/1\">Jun Lv</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tong_X/0/1/0/all/0/1\">Xiangrong Tong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_C/0/1/0/all/0/1\">Chengyan Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_G/0/1/0/all/0/1\">Guang Yang</a>",
          "description": "Magnetic resonance imaging (MRI) is an important medical imaging modality,\nbut its acquisition speed is quite slow due to the physiological limitations.\nRecently, super-resolution methods have shown excellent performance in\naccelerating MRI. In some circumstances, it is difficult to obtain\nhigh-resolution images even with prolonged scan time. Therefore, we proposed a\nnovel super-resolution method that uses a generative adversarial network (GAN)\nwith cyclic loss and attention mechanism to generate high-resolution MR images\nfrom low-resolution MR images by a factor of 2. We implemented our model on\npelvic images from healthy subjects as training and validation data, while\nthose data from patients were used for testing. The MR dataset was obtained\nusing different imaging sequences, including T2, T2W SPAIR, and mDIXON-W. Four\nmethods, i.e., BICUBIC, SRCNN, SRGAN, and EDSR were used for comparison.\nStructural similarity, peak signal to noise ratio, root mean square error, and\nvariance inflation factor were used as calculation indicators to evaluate the\nperformances of the proposed method. Various experimental results showed that\nour method can better restore the details of the high-resolution MR image as\ncompared to the other methods. In addition, the reconstructed high-resolution\nMR image can provide better lesion textures in the tumor patients, which is\npromising to be used in clinical diagnosis.",
          "link": "http://arxiv.org/abs/2107.09989",
          "publishedOn": "2021-07-22T02:03:11.657Z",
          "wordCount": 677,
          "title": "High-Resolution Pelvic MRI Reconstruction Using a Generative Adversarial Network with Attention and Cyclic Loss. (arXiv:2107.09989v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2106.03464",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sancarlos_A/0/1/0/all/0/1\">Abel Sancarlos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cameron_M/0/1/0/all/0/1\">Morgan Cameron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peuvedic_J/0/1/0/all/0/1\">Jean-Marc Le Peuvedic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Groulier_J/0/1/0/all/0/1\">Juliette Groulier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duval_J/0/1/0/all/0/1\">Jean-Louis Duval</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cueto_E/0/1/0/all/0/1\">Elias Cueto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chinesta_F/0/1/0/all/0/1\">Francisco Chinesta</a>",
          "description": "The concept of Hybrid Twin (HT) has recently received a growing interest\nthanks to the availability of powerful machine learning techniques. This twin\nconcept combines physics-based models within a model-order reduction\nframework-to obtain real-time feedback rates-and data science. Thus, the main\nidea of the HT is to develop on-the-fly data-driven models to correct possible\ndeviations between measurements and physics-based model predictions. This paper\nis focused on the computation of stable, fast and accurate corrections in the\nHybrid Twin framework. Furthermore, regarding the delicate and important\nproblem of stability, a new approach is proposed, introducing several\nsub-variants and guaranteeing a low computational cost as well as the\nachievement of a stable time-integration.",
          "link": "http://arxiv.org/abs/2106.03464",
          "publishedOn": "2021-07-22T02:03:11.649Z",
          "wordCount": 569,
          "title": "Learning stable reduced-order models for hybrid twins. (arXiv:2106.03464v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.14496",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Janner_M/0/1/0/all/0/1\">Michael Janner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mordatch_I/0/1/0/all/0/1\">Igor Mordatch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1\">Sergey Levine</a>",
          "description": "We introduce the $\\gamma$-model, a predictive model of environment dynamics\nwith an infinite probabilistic horizon. Replacing standard single-step models\nwith $\\gamma$-models leads to generalizations of the procedures central to\nmodel-based control, including the model rollout and model-based value\nestimation. The $\\gamma$-model, trained with a generative reinterpretation of\ntemporal difference learning, is a natural continuous analogue of the successor\nrepresentation and a hybrid between model-free and model-based mechanisms. Like\na value function, it contains information about the long-term future; like a\nstandard predictive model, it is independent of task reward. We instantiate the\n$\\gamma$-model as both a generative adversarial network and normalizing flow,\ndiscuss how its training reflects an inescapable tradeoff between training-time\nand testing-time compounding errors, and empirically investigate its utility\nfor prediction and control.",
          "link": "http://arxiv.org/abs/2010.14496",
          "publishedOn": "2021-07-22T02:03:11.642Z",
          "wordCount": 594,
          "title": "$\\gamma$-Models: Generative Temporal Difference Learning for Infinite-Horizon Prediction. (arXiv:2010.14496v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.10006",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nordmark_N/0/1/0/all/0/1\">Nils Nordmark</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ayenew_M/0/1/0/all/0/1\">Mola Ayenew</a>",
          "description": "The parsing of windows in building facades is a long-desired but challenging\ntask in computer vision. It is crucial to urban analysis, semantic\nreconstruction, lifecycle analysis, digital twins, and scene parsing amongst\nother building-related tasks that require high-quality semantic data. This\narticle investigates the usage of the mask R-CNN framework to be used for\nwindow detection of facade imagery input. We utilize transfer learning to train\nour proposed method on COCO weights with our own collected dataset of street\nview images of facades to produce instance segmentations of our new window\nclass. Experimental results show that our suggested approach with a relatively\nsmall dataset trains the network only with transfer learning and augmentation\nachieves results on par with prior state-of-the-art window detection\napproaches, even without post-optimization techniques.",
          "link": "http://arxiv.org/abs/2107.10006",
          "publishedOn": "2021-07-22T02:03:11.629Z",
          "wordCount": 577,
          "title": "Window Detection In Facade Imagery: A Deep Learning Approach Using Mask R-CNN. (arXiv:2107.10006v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2010.00130",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abadal_S/0/1/0/all/0/1\">Sergi Abadal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1\">Akshay Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guirado_R/0/1/0/all/0/1\">Robert Guirado</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lopez_Alonso_J/0/1/0/all/0/1\">Jorge L&#xf3;pez-Alonso</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alarcon_E/0/1/0/all/0/1\">Eduard Alarc&#xf3;n</a>",
          "description": "Graph Neural Networks (GNNs) have exploded onto the machine learning scene in\nrecent years owing to their capability to model and learn from graph-structured\ndata. Such an ability has strong implications in a wide variety of fields whose\ndata is inherently relational, for which conventional neural networks do not\nperform well. Indeed, as recent reviews can attest, research in the area of\nGNNs has grown rapidly and has lead to the development of a variety of GNN\nalgorithm variants as well as to the exploration of groundbreaking applications\nin chemistry, neurology, electronics, or communication networks, among others.\nAt the current stage of research, however, the efficient processing of GNNs is\nstill an open challenge for several reasons. Besides of their novelty, GNNs are\nhard to compute due to their dependence on the input graph, their combination\nof dense and very sparse operations, or the need to scale to huge graphs in\nsome applications. In this context, this paper aims to make two main\ncontributions. On the one hand, a review of the field of GNNs is presented from\nthe perspective of computing. This includes a brief tutorial on the GNN\nfundamentals, an overview of the evolution of the field in the last decade, and\na summary of operations carried out in the multiple phases of different GNN\nalgorithm variants. On the other hand, an in-depth analysis of current software\nand hardware acceleration schemes is provided, from which a hardware-software,\ngraph-aware, and communication-centric vision for GNN accelerators is\ndistilled.",
          "link": "http://arxiv.org/abs/2010.00130",
          "publishedOn": "2021-07-22T02:03:11.611Z",
          "wordCount": 739,
          "title": "Computing Graph Neural Networks: A Survey from Algorithms to Accelerators. (arXiv:2010.00130v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02039",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Janner_M/0/1/0/all/0/1\">Michael Janner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qiyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1\">Sergey Levine</a>",
          "description": "Reinforcement learning (RL) is typically concerned with estimating\nsingle-step policies or single-step models, leveraging the Markov property to\nfactorize the problem in time. However, we can also view RL as a sequence\nmodeling problem, with the goal being to predict a sequence of actions that\nleads to a sequence of high rewards. Viewed in this way, it is tempting to\nconsider whether powerful, high-capacity sequence prediction models that work\nwell in other domains, such as natural-language processing, can also provide\nsimple and effective solutions to the RL problem. To this end, we explore how\nRL can be reframed as \"one big sequence modeling\" problem, using\nstate-of-the-art Transformer architectures to model distributions over\nsequences of states, actions, and rewards. Addressing RL as a sequence modeling\nproblem significantly simplifies a range of design decisions: we no longer\nrequire separate behavior policy constraints, as is common in prior work on\noffline model-free RL, and we no longer require ensembles or other epistemic\nuncertainty estimators, as is common in prior work on model-based RL. All of\nthese roles are filled by the same Transformer sequence model. In our\nexperiments, we demonstrate the flexibility of this approach across\nlong-horizon dynamics prediction, imitation learning, goal-conditioned RL, and\noffline RL.",
          "link": "http://arxiv.org/abs/2106.02039",
          "publishedOn": "2021-07-22T02:03:11.604Z",
          "wordCount": 663,
          "title": "Reinforcement Learning as One Big Sequence Modeling Problem. (arXiv:2106.02039v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.03159",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gong_W/0/1/0/all/0/1\">Wenbo Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kaibo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yingzhen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hernandez_Lobato_J/0/1/0/all/0/1\">Jos&#xe9; Miguel Hern&#xe1;ndez-Lobato</a>",
          "description": "Sliced Stein discrepancy (SSD) and its kernelized variants have demonstrated\npromising successes in goodness-of-fit tests and model learning in high\ndimensions. Despite their theoretical elegance, their empirical performance\ndepends crucially on the search of optimal slicing directions to discriminate\nbetween two distributions. Unfortunately, previous gradient-based optimisation\napproaches for this task return sub-optimal results: they are computationally\nexpensive, sensitive to initialization, and they lack theoretical guarantees\nfor convergence. We address these issues in two steps. First, we provide\ntheoretical results stating that the requirement of using optimal slicing\ndirections in the kernelized version of SSD can be relaxed, validating the\nresulting discrepancy with finite random slicing directions. Second, given that\ngood slicing directions are crucial for practical performance, we propose a\nfast algorithm for finding such slicing directions based on ideas of active\nsub-space construction and spectral decomposition. Experiments on\ngoodness-of-fit tests and model learning show that our approach achieves both\nimproved performance and faster convergence. Especially, we demonstrate a\n14-80x speed-up in goodness-of-fit tests when comparing with gradient-based\nalternatives.",
          "link": "http://arxiv.org/abs/2102.03159",
          "publishedOn": "2021-07-22T02:03:11.596Z",
          "wordCount": 655,
          "title": "Active Slices for Sliced Stein Discrepancy. (arXiv:2102.03159v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.06043",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mitchell_E/0/1/0/all/0/1\">Eric Mitchell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rafailov_R/0/1/0/all/0/1\">Rafael Rafailov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_X/0/1/0/all/0/1\">Xue Bin Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1\">Sergey Levine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1\">Chelsea Finn</a>",
          "description": "This paper introduces the offline meta-reinforcement learning (offline\nmeta-RL) problem setting and proposes an algorithm that performs well in this\nsetting. Offline meta-RL is analogous to the widely successful supervised\nlearning strategy of pre-training a model on a large batch of fixed,\npre-collected data (possibly from various tasks) and fine-tuning the model to a\nnew task with relatively little data. That is, in offline meta-RL, we\nmeta-train on fixed, pre-collected data from several tasks in order to adapt to\na new task with a very small amount (less than 5 trajectories) of data from the\nnew task. By nature of being offline, algorithms for offline meta-RL can\nutilize the largest possible pool of training data available and eliminate\npotentially unsafe or costly data collection during meta-training. This setting\ninherits the challenges of offline RL, but it differs significantly because\noffline RL does not generally consider a) transfer to new tasks or b) limited\ndata from the test task, both of which we face in offline meta-RL. Targeting\nthe offline meta-RL setting, we propose Meta-Actor Critic with Advantage\nWeighting (MACAW), an optimization-based meta-learning algorithm that uses\nsimple, supervised regression objectives for both the inner and outer loop of\nmeta-training. On offline variants of common meta-RL benchmarks, we empirically\nfind that this approach enables fully offline meta-reinforcement learning and\nachieves notable gains over prior methods.",
          "link": "http://arxiv.org/abs/2008.06043",
          "publishedOn": "2021-07-22T02:03:11.586Z",
          "wordCount": 713,
          "title": "Offline Meta-Reinforcement Learning with Advantage Weighting. (arXiv:2008.06043v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.03733",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Peng_L/0/1/0/all/0/1\">Lingwei Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_H/0/1/0/all/0/1\">Hui Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1\">Zhebang Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_F/0/1/0/all/0/1\">Fei Li</a>",
          "description": "Model-free deep reinforcement learning has achieved great success in many\ndomains, such as video games, recommendation systems and robotic control tasks.\nIn continuous control tasks, widely used policies with Gaussian distributions\nresults in ineffective exploration of environments and limited performance of\nalgorithms in many cases. In this paper, we propose a density-free off-policy\nalgorithm, Generative Actor-Critic(GAC), using the push-forward model to\nincrease the expressiveness of policies, which also includes an entropy-like\ntechnique, MMD-entropy regularizer, to balance the exploration and\nexploitation. Additionnally, we devise an adaptive mechanism to automatically\nscale this regularizer, which further improves the stability and robustness of\nGAC. The experiment results show that push-forward policies possess desirable\nfeatures, such as multi-modality, which can improve the efficiency of\nexploration and asymptotic performance of algorithms obviously.",
          "link": "http://arxiv.org/abs/2105.03733",
          "publishedOn": "2021-07-22T02:03:11.579Z",
          "wordCount": 588,
          "title": "Generative Actor-Critic: An Off-policy Algorithm Using the Push-forward Model. (arXiv:2105.03733v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.04191",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1\">Kongtao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Franko_K/0/1/0/all/0/1\">Ken Franko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sang_R/0/1/0/all/0/1\">Ruoxin Sang</a>",
          "description": "The deployment of convolutional neural networks is often hindered by high\ncomputational and storage requirements. Structured model pruning is a promising\napproach to alleviate these requirements. Using the VGG-16 model as an example,\nwe measure the accuracy-efficiency trade-off for various structured model\npruning methods and datasets (CIFAR-10 and ImageNet) on Tensor Processing Units\n(TPUs). To measure the actual performance of models, we develop a structured\nmodel pruning library for TensorFlow2 to modify models in place (instead of\nadding mask layers). We show that structured model pruning can significantly\nimprove model memory usage and speed on TPUs without losing accuracy,\nespecially for small datasets (e.g., CIFAR-10).",
          "link": "http://arxiv.org/abs/2107.04191",
          "publishedOn": "2021-07-22T02:03:11.558Z",
          "wordCount": 570,
          "title": "Structured Model Pruning of Convolutional Networks on Tensor Processing Units. (arXiv:2107.04191v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03699",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Suri_A/0/1/0/all/0/1\">Anshuman Suri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Evans_D/0/1/0/all/0/1\">David Evans</a>",
          "description": "Property inference attacks reveal statistical properties about a training set\nbut are difficult to distinguish from the primary purposes of statistical\nmachine learning, which is to produce models that capture statistical\nproperties about a distribution. Motivated by Yeom et al.'s membership\ninference framework, we propose a formal and generic definition of property\ninference attacks. The proposed notion describes attacks that can distinguish\nbetween possible training distributions, extending beyond previous property\ninference attacks that infer the ratio of a particular type of data in the\ntraining data set. In this paper, we show how our definition captures previous\nproperty inference attacks as well as a new attack that reveals the average\ndegree of nodes of a training graph and report on experiments giving insight\ninto the potential risks of property inference attacks.",
          "link": "http://arxiv.org/abs/2106.03699",
          "publishedOn": "2021-07-22T02:03:11.549Z",
          "wordCount": 596,
          "title": "Formalizing Distribution Inference Risks. (arXiv:2106.03699v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.02356",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Chen_S/0/1/0/all/0/1\">Shixiang Chen</a>, <a href=\"http://arxiv.org/find/math/1/au:+Deng_Z/0/1/0/all/0/1\">Zengde Deng</a>, <a href=\"http://arxiv.org/find/math/1/au:+Ma_S/0/1/0/all/0/1\">Shiqian Ma</a>, <a href=\"http://arxiv.org/find/math/1/au:+So_A/0/1/0/all/0/1\">Anthony Man-Cho So</a>",
          "description": "We consider the problem of maximizing the $\\ell_1$ norm of a linear map over\nthe sphere, which arises in various machine learning applications such as\northogonal dictionary learning (ODL) and robust subspace recovery (RSR). The\nproblem is numerically challenging due to its nonsmooth objective and nonconvex\nconstraint, and its algorithmic aspects have not been well explored. In this\npaper, we show how the manifold structure of the sphere can be exploited to\ndesign fast algorithms for tackling this problem. Specifically, our\ncontribution is threefold. First, we present a manifold proximal point\nalgorithm (ManPPA) for the problem and show that it converges at a sublinear\nrate. Furthermore, we show that ManPPA can achieve a quadratic convergence rate\nwhen applied to the ODL and RSR problems. Second, we propose a stochastic\nvariant of ManPPA called StManPPA, which is well suited for large-scale\ncomputation, and establish its sublinear convergence rate. Both ManPPA and\nStManPPA have provably faster convergence rates than existing subgradient-type\nmethods. Third, using ManPPA as a building block, we propose a new approach to\nsolving a matrix analog of the problem, in which the sphere is replaced by the\nStiefel manifold. The results from our extensive numerical experiments on the\nODL and RSR problems demonstrate the efficiency and efficacy of our proposed\nmethods.",
          "link": "http://arxiv.org/abs/2005.02356",
          "publishedOn": "2021-07-22T02:03:11.528Z",
          "wordCount": 701,
          "title": "Manifold Proximal Point Algorithms for Dual Principal Component Pursuit and Orthogonal Dictionary Learning. (arXiv:2005.02356v2 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09829",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yunqi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hanxiong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shuyuan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1\">Yingqiang Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongfeng Zhang</a>",
          "description": "Recommender systems are gaining increasing and critical impacts on human and\nsociety since a growing number of users use them for information seeking and\ndecision making. Therefore, it is crucial to address the potential unfairness\nproblems in recommendations. Just like users have personalized preferences on\nitems, users' demands for fairness are also personalized in many scenarios.\nTherefore, it is important to provide personalized fair recommendations for\nusers to satisfy their personalized fairness demands. Besides, previous works\non fair recommendation mainly focus on association-based fairness. However, it\nis important to advance from associative fairness notions to causal fairness\nnotions for assessing fairness more properly in recommender systems. Based on\nthe above considerations, this paper focuses on achieving personalized\ncounterfactual fairness for users in recommender systems. To this end, we\nintroduce a framework for achieving counterfactually fair recommendations\nthrough adversary learning by generating feature-independent user embeddings\nfor recommendation. The framework allows recommender systems to achieve\npersonalized fairness for users while also covering non-personalized\nsituations. Experiments on two real-world datasets with shallow and deep\nrecommendation algorithms show that our method can generate fairer\nrecommendations for users with a desirable recommendation performance.",
          "link": "http://arxiv.org/abs/2105.09829",
          "publishedOn": "2021-07-22T02:03:11.520Z",
          "wordCount": 659,
          "title": "Personalized Counterfactual Fairness in Recommendation. (arXiv:2105.09829v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.02373",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schreurs_J/0/1/0/all/0/1\">Joachim Schreurs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meulemeester_H/0/1/0/all/0/1\">Hannes De Meulemeester</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fanuel_M/0/1/0/all/0/1\">Micha&#xeb;l Fanuel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moor_B/0/1/0/all/0/1\">Bart De Moor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suykens_J/0/1/0/all/0/1\">Johan A.K. Suykens</a>",
          "description": "Commonly, machine learning models minimize an empirical expectation. As a\nresult, the trained models typically perform well for the majority of the data\nbut the performance may deteriorate in less dense regions of the dataset. This\nissue also arises in generative modeling. A generative model may overlook\nunderrepresented modes that are less frequent in the empirical data\ndistribution. This problem is known as complete mode coverage. We propose a\nsampling procedure based on ridge leverage scores which significantly improves\nmode coverage when compared to standard methods and can easily be combined with\nany GAN. Ridge leverage scores are computed by using an explicit feature map,\nassociated with the next-to-last layer of a GAN discriminator or of a\npre-trained network, or by using an implicit feature map corresponding to a\nGaussian kernel. Multiple evaluations against recent approaches of complete\nmode coverage show a clear improvement when using the proposed sampling\nstrategy.",
          "link": "http://arxiv.org/abs/2104.02373",
          "publishedOn": "2021-07-22T02:03:11.513Z",
          "wordCount": 637,
          "title": "Leverage Score Sampling for Complete Mode Coverage in Generative Adversarial Networks. (arXiv:2104.02373v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.00931",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Neu_G/0/1/0/all/0/1\">Gergely Neu</a>",
          "description": "We study the generalization properties of the popular stochastic optimization\nmethod known as stochastic gradient descent (SGD) for optimizing general\nnon-convex loss functions. Our main contribution is providing upper bounds on\nthe generalization error that depend on local statistics of the stochastic\ngradients evaluated along the path of iterates calculated by SGD. The key\nfactors our bounds depend on are the variance of the gradients (with respect to\nthe data distribution) and the local smoothness of the objective function along\nthe SGD path, and the sensitivity of the loss function to perturbations to the\nfinal output. Our key technical tool is combining the information-theoretic\ngeneralization bounds previously used for analyzing randomized variants of SGD\nwith a perturbation analysis of the iterates.",
          "link": "http://arxiv.org/abs/2102.00931",
          "publishedOn": "2021-07-22T02:03:11.505Z",
          "wordCount": 580,
          "title": "Information-Theoretic Generalization Bounds for Stochastic Gradient Descent. (arXiv:2102.00931v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1905.08616",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wong_A/0/1/0/all/0/1\">Alex Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_X/0/1/0/all/0/1\">Xiaohan Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsuei_S/0/1/0/all/0/1\">Stephanie Tsuei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1\">Stefano Soatto</a>",
          "description": "We describe a method to infer dense depth from camera motion and sparse depth\nas estimated using a visual-inertial odometry system. Unlike other scenarios\nusing point clouds from lidar or structured light sensors, we have few hundreds\nto few thousand points, insufficient to inform the topology of the scene. Our\nmethod first constructs a piecewise planar scaffolding of the scene, and then\nuses it to infer dense depth using the image along with the sparse points. We\nuse a predictive cross-modal criterion, akin to `self-supervision,' measuring\nphotometric consistency across time, forward-backward pose consistency, and\ngeometric compatibility with the sparse point cloud. We also launch the first\nvisual-inertial + depth dataset, which we hope will foster additional\nexploration into combining the complementary strengths of visual and inertial\nsensors. To compare our method to prior work, we adopt the unsupervised KITTI\ndepth completion benchmark, and show state-of-the-art performance on it. Code\navailable at:\nhttps://github.com/alexklwong/unsupervised-depth-completion-visual-inertial-odometry.",
          "link": "http://arxiv.org/abs/1905.08616",
          "publishedOn": "2021-07-22T02:03:11.485Z",
          "wordCount": 646,
          "title": "Unsupervised Depth Completion from Visual Inertial Odometry. (arXiv:1905.08616v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.01937",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Goyal_A/0/1/0/all/0/1\">Anirudh Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Didolkar_A/0/1/0/all/0/1\">Aniket Didolkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ke_N/0/1/0/all/0/1\">Nan Rosemary Ke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blundell_C/0/1/0/all/0/1\">Charles Blundell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beaudoin_P/0/1/0/all/0/1\">Philippe Beaudoin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heess_N/0/1/0/all/0/1\">Nicolas Heess</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mozer_M/0/1/0/all/0/1\">Michael Mozer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1\">Yoshua Bengio</a>",
          "description": "Visual environments are structured, consisting of distinct objects or\nentities. These entities have properties -- both visible and latent -- that\ndetermine the manner in which they interact with one another. To partition\nimages into entities, deep-learning researchers have proposed structural\ninductive biases such as slot-based architectures. To model interactions among\nentities, equivariant graph neural nets (GNNs) are used, but these are not\nparticularly well suited to the task for two reasons. First, GNNs do not\npredispose interactions to be sparse, as relationships among independent\nentities are likely to be. Second, GNNs do not factorize knowledge about\ninteractions in an entity-conditional manner. As an alternative, we take\ninspiration from cognitive science and resurrect a classic approach, production\nsystems, which consist of a set of rule templates that are applied by binding\nplaceholder variables in the rules to specific entities. Rules are scored on\ntheir match to entities, and the best fitting rules are applied to update\nentity properties. In a series of experiments, we demonstrate that this\narchitecture achieves a flexible, dynamic flow of control and serves to\nfactorize entity-specific and rule-based information. This disentangling of\nknowledge achieves robust future-state prediction in rich visual environments,\noutperforming state-of-the-art methods using GNNs, and allows for the\nextrapolation from simple (few object) environments to more complex\nenvironments.",
          "link": "http://arxiv.org/abs/2103.01937",
          "publishedOn": "2021-07-22T02:03:11.474Z",
          "wordCount": 683,
          "title": "Neural Production Systems. (arXiv:2103.01937v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.10199",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Banburski_A/0/1/0/all/0/1\">Andrzej Banburski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torre_F/0/1/0/all/0/1\">Fernanda De La Torre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pant_N/0/1/0/all/0/1\">Nishka Pant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shastri_I/0/1/0/all/0/1\">Ishana Shastri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poggio_T/0/1/0/all/0/1\">Tomaso Poggio</a>",
          "description": "Recent theoretical results show that gradient descent on deep neural networks\nunder exponential loss functions locally maximizes classification margin, which\nis equivalent to minimizing the norm of the weight matrices under margin\nconstraints. This property of the solution however does not fully characterize\nthe generalization performance. We motivate theoretically and show empirically\nthat the area under the curve of the margin distribution on the training set is\nin fact a good measure of generalization. We then show that, after data\nseparation is achieved, it is possible to dynamically reduce the training set\nby more than 99% without significant loss of performance. Interestingly, the\nresulting subset of \"high capacity\" features is not consistent across different\ntraining runs, which is consistent with the theoretical claim that all training\npoints should converge to the same asymptotic margin under SGD and in the\npresence of both batch normalization and weight decay.",
          "link": "http://arxiv.org/abs/2107.10199",
          "publishedOn": "2021-07-22T02:03:11.455Z",
          "wordCount": 601,
          "title": "Distribution of Classification Margins: Are All Data Equal?. (arXiv:2107.10199v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2101.12741",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Renshen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fujii_Y/0/1/0/all/0/1\">Yasuhisa Fujii</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Popat_A/0/1/0/all/0/1\">Ashok C. Popat</a>",
          "description": "Paragraphs are an important class of document entities. We propose a new\napproach for paragraph identification by spatial graph convolutional neural\nnetworks (GCN) applied on OCR text boxes. Two steps, namely line splitting and\nline clustering, are performed to extract paragraphs from the lines in OCR\nresults. Each step uses a beta-skeleton graph constructed from bounding boxes,\nwhere the graph edges provide efficient support for graph convolution\noperations. With only pure layout input features, the GCN model size is 3~4\norders of magnitude smaller compared to R-CNN based models, while achieving\ncomparable or better accuracies on PubLayNet and other datasets. Furthermore,\nthe GCN models show good generalization from synthetic training data to\nreal-world images, and good adaptivity for variable document styles.",
          "link": "http://arxiv.org/abs/2101.12741",
          "publishedOn": "2021-07-22T02:03:11.448Z",
          "wordCount": 603,
          "title": "Post-OCR Paragraph Recognition by Graph Convolutional Networks. (arXiv:2101.12741v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.07487",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Si_S/0/1/0/all/0/1\">Shijing Si</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Oates_C/0/1/0/all/0/1\">Chris. J. Oates</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Duncan_A/0/1/0/all/0/1\">Andrew B. Duncan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Carin_L/0/1/0/all/0/1\">Lawrence Carin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Briol_F/0/1/0/all/0/1\">Fran&#xe7;ois-Xavier Briol</a>",
          "description": "Control variates are a well-established tool to reduce the variance of Monte\nCarlo estimators. However, for large-scale problems including high-dimensional\nand large-sample settings, their advantages can be outweighed by a substantial\ncomputational cost. This paper considers control variates based on Stein\noperators, presenting a framework that encompasses and generalizes existing\napproaches that use polynomials, kernels and neural networks. A learning\nstrategy based on minimising a variational objective through stochastic\noptimization is proposed, leading to scalable and effective control variates.\nNovel theoretical results are presented to provide insight into the variance\nreduction that can be achieved, and an empirical assessment, including\napplications to Bayesian inference, is provided in support.",
          "link": "http://arxiv.org/abs/2006.07487",
          "publishedOn": "2021-07-22T02:03:11.427Z",
          "wordCount": 574,
          "title": "Scalable Control Variates for Monte Carlo Methods via Stochastic Optimization. (arXiv:2006.07487v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.10110",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Cheng_S/0/1/0/all/0/1\">Shuyu Cheng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wu_G/0/1/0/all/0/1\">Guoqiang Wu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhu_J/0/1/0/all/0/1\">Jun Zhu</a>",
          "description": "Zeroth-order (ZO) optimization is widely used to handle challenging tasks,\nsuch as query-based black-box adversarial attacks and reinforcement learning.\nVarious attempts have been made to integrate prior information into the\ngradient estimation procedure based on finite differences, with promising\nempirical results. However, their convergence properties are not well\nunderstood. This paper makes an attempt to fill this gap by analyzing the\nconvergence of prior-guided ZO algorithms under a greedy descent framework with\nvarious gradient estimators. We provide a convergence guarantee for the\nprior-guided random gradient-free (PRGF) algorithms. Moreover, to further\naccelerate over greedy descent methods, we present a new accelerated random\nsearch (ARS) algorithm that incorporates prior information, together with a\nconvergence analysis. Finally, our theoretical results are confirmed by\nexperiments on several numerical benchmarks as well as adversarial attacks.",
          "link": "http://arxiv.org/abs/2107.10110",
          "publishedOn": "2021-07-22T02:03:11.420Z",
          "wordCount": 574,
          "title": "On the Convergence of Prior-Guided Zeroth-Order Optimization Algorithms. (arXiv:2107.10110v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2101.07948",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Ziheng Wang</a>",
          "description": "The last few years have seen gigantic leaps in algorithms and systems to\nsupport efficient deep learning inference. Pruning and quantization algorithms\ncan now consistently compress neural networks by an order of magnitude. For a\ncompressed neural network, a multitude of inference frameworks have been\ndesigned to maximize the performance of the target hardware. While we find\nmature support for quantized neural networks in production frameworks such as\nOpenVINO and MNN, support for pruned sparse neural networks is still lacking.\nTo tackle this challenge, we present SparseDNN, a sparse deep learning\ninference engine targeting CPUs. We present both kernel-level optimizations\nwith a sparse code generator to accelerate sparse operators and novel\nnetwork-level optimizations catering to sparse networks. We show that our\nsparse code generator can achieve significant speedups over state-of-the-art\nsparse and dense libraries. On end-to-end benchmarks such as Huggingface\npruneBERT, SparseDNN achieves up to 5x throughput improvement over dense\ninference with state-of-the-art OpenVINO. Open source library at:\nhttps://github.com/marsupialtail/sparsednn.",
          "link": "http://arxiv.org/abs/2101.07948",
          "publishedOn": "2021-07-22T02:03:11.399Z",
          "wordCount": 628,
          "title": "SparseDNN: Fast Sparse Deep Learning Inference on CPUs. (arXiv:2101.07948v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.12063",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hamalainen_P/0/1/0/all/0/1\">Perttu H&#xe4;m&#xe4;l&#xe4;inen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trapp_M/0/1/0/all/0/1\">Martin Trapp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saloheimo_T/0/1/0/all/0/1\">Tuure Saloheimo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Solin_A/0/1/0/all/0/1\">Arno Solin</a>",
          "description": "We propose Deep Residual Mixture Models (DRMMs), a novel deep generative\nmodel architecture. Compared to other deep models, DRMMs allow more flexible\nconditional sampling: The model can be trained once with all variables, and\nthen used for sampling with arbitrary combinations of conditioning variables,\nGaussian priors, and (in)equality constraints. This provides new opportunities\nfor interactive and exploratory machine learning, where one should minimize the\nuser waiting for retraining a model. We demonstrate DRMMs in constrained\nmulti-limb inverse kinematics and controllable generation of animations.",
          "link": "http://arxiv.org/abs/2006.12063",
          "publishedOn": "2021-07-22T02:03:11.380Z",
          "wordCount": 557,
          "title": "Deep Residual Mixture Models. (arXiv:2006.12063v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.09728",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kang_A/0/1/0/all/0/1\">Akum S. Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_L/0/1/0/all/0/1\">Loveleen C. Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mastorides_S/0/1/0/all/0/1\">Stephen M. Mastorides</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Foulis_P/0/1/0/all/0/1\">Philip R. Foulis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DeLand_L/0/1/0/all/0/1\">Lauren A. DeLand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seifert_R/0/1/0/all/0/1\">Robert P. Seifert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borkowski_A/0/1/0/all/0/1\">Andrew Borkowski</a>",
          "description": "Flow cytometry is a technique that measures multiple fluorescence and light\nscatter-associated parameters from individual cells as they flow a single file\nthrough an excitation light source. These cells are labeled with antibodies to\ndetect various antigens and the fluorescence signals reflect antigen\nexpression. Interpretation of the multiparameter flow cytometry data is\nlaborious, time-consuming, and expensive. It involves manual interpretation of\ncell distribution and pattern recognition on two-dimensional plots by highly\ntrained medical technologists and pathologists. Using various machine learning\nalgorithms, we attempted to develop an automated analysis for clinical flow\ncytometry cases that would automatically classify normal and chronic\nlymphocytic leukemia cases. We achieved the best success with the Gradient\nBoosting. The XGBoost classifier achieved a specificity of 1.00 and a\nsensitivity of 0.67, a negative predictive value of 0.75, a positive predictive\nvalue of 1.00, and an overall accuracy of 0.83 in prospectively classifying\ncases with malignancies.",
          "link": "http://arxiv.org/abs/2107.09728",
          "publishedOn": "2021-07-22T02:03:11.310Z",
          "wordCount": 606,
          "title": "Machine Learning Approaches to Automated Flow Cytometry Diagnosis of Chronic Lymphocytic Leukemia. (arXiv:2107.09728v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09785",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bitencourt_H/0/1/0/all/0/1\">Hugo Vinicius Bitencourt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guimaraes_F/0/1/0/all/0/1\">Frederico Gadelha Guimar&#xe3;es</a>",
          "description": "In Internet of things (IoT), data is continuously recorded from different\ndata sources and devices can suffer faults in their embedded electronics, thus\nleading to a high-dimensional data sets and concept drift events. Therefore,\nmethods that are capable of high-dimensional non-stationary time series are of\ngreat value in IoT applications. Fuzzy Time Series (FTS) models stand out as\ndata-driven non-parametric models of easy implementation and high accuracy.\nUnfortunately, FTS encounters difficulties when dealing with data sets of many\nvariables and scenarios with concept drift. We present a new approach to handle\nhigh-dimensional non-stationary time series, by projecting the original\nhigh-dimensional data into a low dimensional embedding space and using FTS\napproach. Combining these techniques enables a better representation of the\ncomplex content of non-stationary multivariate time series and accurate\nforecasts. Our model is able to explain 98% of the variance and reach 11.52% of\nRMSE, 2.68% of MAE and 2.91% of MAPE.",
          "link": "http://arxiv.org/abs/2107.09785",
          "publishedOn": "2021-07-22T02:03:11.237Z",
          "wordCount": 628,
          "title": "High-dimensional Multivariate Time Series Forecasting in IoT Applications using Embedding Non-stationary Fuzzy Time Series. (arXiv:2107.09785v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09949",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shin_E/0/1/0/all/0/1\">Eura Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klasnja_P/0/1/0/all/0/1\">Pedja Klasnja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murphy_S/0/1/0/all/0/1\">Susan Murphy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doshi_Velez_F/0/1/0/all/0/1\">Finale Doshi-Velez</a>",
          "description": "Motivated by the need for efficient and personalized learning in mobile\nhealth, we investigate the problem of online kernel selection for Gaussian\nProcess regression in the multi-task setting. We propose a novel generative\nprocess on the kernel composition for this purpose. Our method demonstrates\nthat trajectories of kernel evolutions can be transferred between users to\nimprove learning and that the kernels themselves are meaningful for an mHealth\nprediction goal.",
          "link": "http://arxiv.org/abs/2107.09949",
          "publishedOn": "2021-07-22T02:03:11.218Z",
          "wordCount": 508,
          "title": "Online structural kernel selection for mobile health. (arXiv:2107.09949v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09817",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Mei_X/0/1/0/all/0/1\">Xinhao Mei</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_X/0/1/0/all/0/1\">Xubo Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huang_Q/0/1/0/all/0/1\">Qiushi Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Plumbley_M/0/1/0/all/0/1\">Mark D. Plumbley</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_W/0/1/0/all/0/1\">Wenwu Wang</a>",
          "description": "Audio captioning aims to automatically generate a natural language\ndescription of an audio clip. Most captioning models follow an encoder-decoder\narchitecture, where the decoder predicts words based on the audio features\nextracted by the encoder. Convolutional neural networks (CNNs) and recurrent\nneural networks (RNNs) are often used as the audio encoder. However, CNNs can\nbe limited in modelling temporal relationships among the time frames in an\naudio signal, while RNNs can be limited in modelling the long-range\ndependencies among the time frames. In this paper, we propose an Audio\nCaptioning Transformer (ACT), which is a full Transformer network based on an\nencoder-decoder architecture and is totally convolution-free. The proposed\nmethod has a better ability to model the global information within an audio\nsignal as well as capture temporal relationships between audio events. We\nevaluate our model on AudioCaps, which is the largest audio captioning dataset\npublicly available. Our model shows competitive performance compared to other\nstate-of-the-art approaches.",
          "link": "http://arxiv.org/abs/2107.09817",
          "publishedOn": "2021-07-22T02:03:11.212Z",
          "wordCount": 600,
          "title": "Audio Captioning Transformer. (arXiv:2107.09817v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09773",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dagan_Y/0/1/0/all/0/1\">Yuval Dagan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daskalakis_C/0/1/0/all/0/1\">Constantinos Daskalakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dikkala_N/0/1/0/all/0/1\">Nishanth Dikkala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goel_S/0/1/0/all/0/1\">Surbhi Goel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kandiros_A/0/1/0/all/0/1\">Anthimos Vardis Kandiros</a>",
          "description": "We consider a general statistical estimation problem wherein binary labels\nacross different observations are not independent conditioned on their feature\nvectors, but dependent, capturing settings where e.g. these observations are\ncollected on a spatial domain, a temporal domain, or a social network, which\ninduce dependencies. We model these dependencies in the language of Markov\nRandom Fields and, importantly, allow these dependencies to be substantial, i.e\ndo not assume that the Markov Random Field capturing these dependencies is in\nhigh temperature. As our main contribution we provide algorithms and\nstatistically efficient estimation rates for this model, giving several\ninstantiations of our bounds in logistic regression, sparse logistic\nregression, and neural network settings with dependent data. Our estimation\nguarantees follow from novel results for estimating the parameters (i.e.\nexternal fields and interaction strengths) of Ising models from a {\\em single}\nsample. {We evaluate our estimation approach on real networked data, showing\nthat it outperforms standard regression approaches that ignore dependencies,\nacross three text classification datasets: Cora, Citeseer and Pubmed.}",
          "link": "http://arxiv.org/abs/2107.09773",
          "publishedOn": "2021-07-22T02:03:11.191Z",
          "wordCount": 609,
          "title": "Statistical Estimation from Dependent Data. (arXiv:2107.09773v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2011.04419",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Verma_V/0/1/0/all/0/1\">Vikas Verma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luong_M/0/1/0/all/0/1\">Minh-Thang Luong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kawaguchi_K/0/1/0/all/0/1\">Kenji Kawaguchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pham_H/0/1/0/all/0/1\">Hieu Pham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1\">Quoc V. Le</a>",
          "description": "Despite recent success, most contrastive self-supervised learning methods are\ndomain-specific, relying heavily on data augmentation techniques that require\nknowledge about a particular domain, such as image cropping and rotation. To\novercome such limitation, we propose a novel domain-agnostic approach to\ncontrastive learning, named DACL, that is applicable to domains where\ninvariances, and thus, data augmentation techniques, are not readily available.\nKey to our approach is the use of Mixup noise to create similar and dissimilar\nexamples by mixing data samples differently either at the input or hidden-state\nlevels. To demonstrate the effectiveness of DACL, we conduct experiments across\nvarious domains such as tabular data, images, and graphs. Our results show that\nDACL not only outperforms other domain-agnostic noising methods, such as\nGaussian-noise, but also combines well with domain-specific methods, such as\nSimCLR, to improve self-supervised visual representation learning. Finally, we\ntheoretically analyze our method and show advantages over the Gaussian-noise\nbased contrastive learning approach.",
          "link": "http://arxiv.org/abs/2011.04419",
          "publishedOn": "2021-07-21T02:01:37.638Z",
          "wordCount": 624,
          "title": "Towards Domain-Agnostic Contrastive Learning. (arXiv:2011.04419v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.09519",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Gaetan_F/0/1/0/all/0/1\">Frusque Gaetan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gabriel_M/0/1/0/all/0/1\">Michau Gabriel</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Olga_F/0/1/0/all/0/1\">Fink Olga</a>",
          "description": "Acoustic monitoring for machine fault detection is a recent and expanding\nresearch path that has already provided promising results for industries.\nHowever, it is impossible to collect enough data to learn all types of faults\nfrom a machine. Thus, new algorithms, trained using data from healthy\nconditions only, were developed to perform unsupervised anomaly detection. A\nkey issue in the development of these algorithms is the noise in the signals,\nas it impacts the anomaly detection performance. In this work, we propose a\npowerful data-driven and quasi non-parametric denoising strategy for spectral\ndata based on a tensor decomposition: the Non-negative Canonical Polyadic (CP)\ndecomposition. This method is particularly adapted for machine emitting\nstationary sound. We demonstrate in a case study, the Malfunctioning Industrial\nMachine Investigation and Inspection (MIMII) baseline, how the use of our\ndenoising strategy leads to a sensible improvement of the unsupervised anomaly\ndetection. Such approaches are capable to make sound-based monitoring of\nindustrial processes more reliable.",
          "link": "http://arxiv.org/abs/2107.09519",
          "publishedOn": "2021-07-21T02:01:37.625Z",
          "wordCount": 635,
          "title": "Canonical Polyadic Decomposition and Deep Learning for Machine Fault Detection. (arXiv:2107.09519v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08285",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Reich_C/0/1/0/all/0/1\">Christoph Reich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prangemeier_T/0/1/0/all/0/1\">Tim Prangemeier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wildner_C/0/1/0/all/0/1\">Christian Wildner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koeppl_H/0/1/0/all/0/1\">Heinz Koeppl</a>",
          "description": "Time-lapse fluorescent microscopy (TLFM) combined with predictive\nmathematical modelling is a powerful tool to study the inherently dynamic\nprocesses of life on the single-cell level. Such experiments are costly,\ncomplex and labour intensive. A complimentary approach and a step towards in\nsilico experimentation, is to synthesise the imagery itself. Here, we propose\nMulti-StyleGAN as a descriptive approach to simulate time-lapse fluorescence\nmicroscopy imagery of living cells, based on a past experiment. This novel\ngenerative adversarial network synthesises a multi-domain sequence of\nconsecutive timesteps. We showcase Multi-StyleGAN on imagery of multiple live\nyeast cells in microstructured environments and train on a dataset recorded in\nour laboratory. The simulation captures underlying biophysical factors and time\ndependencies, such as cell morphology, growth, physical interactions, as well\nas the intensity of a fluorescent reporter protein. An immediate application is\nto generate additional training and validation data for feature extraction\nalgorithms or to aid and expedite development of advanced experimental\ntechniques such as online monitoring or control of cells.\n\nCode and dataset is available at\nhttps://git.rwth-aachen.de/bcs/projects/tp/multi-stylegan.",
          "link": "http://arxiv.org/abs/2106.08285",
          "publishedOn": "2021-07-21T02:01:37.619Z",
          "wordCount": 674,
          "title": "Multi-StyleGAN: Towards Image-Based Simulation of Time-Lapse Live-Cell Microscopy. (arXiv:2106.08285v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.05041",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Tran_G/0/1/0/all/0/1\">Gia-Lac Tran</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Milios_D/0/1/0/all/0/1\">Dimitrios Milios</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Michiardi_P/0/1/0/all/0/1\">Pietro Michiardi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Filippone_M/0/1/0/all/0/1\">Maurizio Filippone</a>",
          "description": "Approximations to Gaussian processes based on inducing variables, combined\nwith variational inference techniques, enable state-of-the-art sparse\napproaches to infer GPs at scale through mini batch-based learning. In this\nwork, we address one limitation of sparse GPs, which is due to the challenge in\ndealing with a large number of inducing variables without imposing a special\nstructure on the inducing inputs. In particular, we introduce a novel\nhierarchical prior, which imposes sparsity on the set of inducing variables. We\ntreat our model variationally, and we experimentally show considerable\ncomputational gains compared to standard sparse GPs when sparsity on the\ninducing variables is realized considering the nearest inducing inputs of a\nrandom mini-batch of the data. We perform an extensive experimental validation\nthat demonstrates the effectiveness of our approach compared to the\nstate-of-the-art. Our approach enables the possibility to use sparse GPs using\na large number of inducing points without incurring a prohibitive computational\ncost.",
          "link": "http://arxiv.org/abs/2011.05041",
          "publishedOn": "2021-07-21T02:01:37.612Z",
          "wordCount": 615,
          "title": "Sparse within Sparse Gaussian Processes using Neighbor Information. (arXiv:2011.05041v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06054",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Biswas_S/0/1/0/all/0/1\">Sumon Biswas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajan_H/0/1/0/all/0/1\">Hridesh Rajan</a>",
          "description": "In recent years, many incidents have been reported where machine learning\nmodels exhibited discrimination among people based on race, sex, age, etc.\nResearch has been conducted to measure and mitigate unfairness in machine\nlearning models. For a machine learning task, it is a common practice to build\na pipeline that includes an ordered set of data preprocessing stages followed\nby a classifier. However, most of the research on fairness has considered a\nsingle classifier based prediction task. What are the fairness impacts of the\npreprocessing stages in machine learning pipeline? Furthermore, studies showed\nthat often the root cause of unfairness is ingrained in the data itself, rather\nthan the model. But no research has been conducted to measure the unfairness\ncaused by a specific transformation made in the data preprocessing stage. In\nthis paper, we introduced the causal method of fairness to reason about the\nfairness impact of data preprocessing stages in ML pipeline. We leveraged\nexisting metrics to define the fairness measures of the stages. Then we\nconducted a detailed fairness evaluation of the preprocessing stages in 37\npipelines collected from three different sources. Our results show that certain\ndata transformers are causing the model to exhibit unfairness. We identified a\nnumber of fairness patterns in several categories of data transformers.\nFinally, we showed how the local fairness of a preprocessing stage composes in\nthe global fairness of the pipeline. We used the fairness composition to choose\nappropriate downstream transformer that mitigates unfairness in the machine\nlearning pipeline.",
          "link": "http://arxiv.org/abs/2106.06054",
          "publishedOn": "2021-07-21T02:01:37.283Z",
          "wordCount": 773,
          "title": "Fair Preprocessing: Towards Understanding Compositional Fairness of Data Transformers in Machine Learning Pipeline. (arXiv:2106.06054v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.00243",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tan_Y/0/1/0/all/0/1\">Yue Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_G/0/1/0/all/0/1\">Guodong Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1\">Tianyi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Q/0/1/0/all/0/1\">Qinghua Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jing Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chengqi Zhang</a>",
          "description": "The heterogeneity across devices usually hinders the optimization convergence\nand generalization performance of federated learning (FL) when the aggregation\nof devices' knowledge occurs in the gradient space. For example, devices may\ndiffer in terms of data distribution, network latency, input/output space,\nand/or model architecture, which can easily lead to the misalignment of their\nlocal gradients. To improve the tolerance to heterogeneity, we propose a novel\nfederated prototype learning (FedProto) framework in which the devices and\nserver communicate the class prototypes instead of the gradients. FedProto\naggregates the local prototypes collected from different devices, and then\nsends the global prototypes back to all devices to regularize the training of\nlocal models. The training on each device aims to minimize the classification\nerror on the local data while keeping the resulting local prototypes\nsufficiently close to the corresponding global ones. Through experiments, we\npropose a benchmark setting tailored for heterogeneous FL, with FedProto\noutperforming several recent FL approaches on multiple datasets.",
          "link": "http://arxiv.org/abs/2105.00243",
          "publishedOn": "2021-07-21T02:01:37.276Z",
          "wordCount": 629,
          "title": "FedProto: Federated Prototype Learning over Heterogeneous Devices. (arXiv:2105.00243v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.11289",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hawks_B/0/1/0/all/0/1\">Benjamin Hawks</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duarte_J/0/1/0/all/0/1\">Javier Duarte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fraser_N/0/1/0/all/0/1\">Nicholas J. Fraser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pappalardo_A/0/1/0/all/0/1\">Alessandro Pappalardo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_N/0/1/0/all/0/1\">Nhan Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Umuroglu_Y/0/1/0/all/0/1\">Yaman Umuroglu</a>",
          "description": "Efficient machine learning implementations optimized for inference in\nhardware have wide-ranging benefits, depending on the application, from lower\ninference latency to higher data throughput and reduced energy consumption. Two\npopular techniques for reducing computation in neural networks are pruning,\nremoving insignificant synapses, and quantization, reducing the precision of\nthe calculations. In this work, we explore the interplay between pruning and\nquantization during the training of neural networks for ultra low latency\napplications targeting high energy physics use cases. Techniques developed for\nthis study have potential applications across many other domains. We study\nvarious configurations of pruning during quantization-aware training, which we\nterm quantization-aware pruning, and the effect of techniques like\nregularization, batch normalization, and different pruning schemes on\nperformance, computational complexity, and information content metrics. We find\nthat quantization-aware pruning yields more computationally efficient models\nthan either pruning or quantization alone for our task. Further,\nquantization-aware pruning typically performs similar to or better in terms of\ncomputational efficiency compared to other neural architecture search\ntechniques like Bayesian optimization. Surprisingly, while networks with\ndifferent training configurations can have similar performance for the\nbenchmark application, the information content in the network can vary\nsignificantly, affecting its generalizability.",
          "link": "http://arxiv.org/abs/2102.11289",
          "publishedOn": "2021-07-21T02:01:37.257Z",
          "wordCount": 709,
          "title": "Ps and Qs: Quantization-aware pruning for efficient low latency neural network inference. (arXiv:2102.11289v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.11271",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yarats_D/0/1/0/all/0/1\">Denis Yarats</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fergus_R/0/1/0/all/0/1\">Rob Fergus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lazaric_A/0/1/0/all/0/1\">Alessandro Lazaric</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pinto_L/0/1/0/all/0/1\">Lerrel Pinto</a>",
          "description": "Learning effective representations in image-based environments is crucial for\nsample efficient Reinforcement Learning (RL). Unfortunately, in RL,\nrepresentation learning is confounded with the exploratory experience of the\nagent -- learning a useful representation requires diverse data, while\neffective exploration is only possible with coherent representations.\nFurthermore, we would like to learn representations that not only generalize\nacross tasks but also accelerate downstream exploration for efficient\ntask-specific training. To address these challenges we propose Proto-RL, a\nself-supervised framework that ties representation learning with exploration\nthrough prototypical representations. These prototypes simultaneously serve as\na summarization of the exploratory experience of an agent as well as a basis\nfor representing observations. We pre-train these task-agnostic representations\nand prototypes on environments without downstream task information. This\nenables state-of-the-art downstream policy learning on a set of difficult\ncontinuous control tasks.",
          "link": "http://arxiv.org/abs/2102.11271",
          "publishedOn": "2021-07-21T02:01:37.250Z",
          "wordCount": 596,
          "title": "Reinforcement Learning with Prototypical Representations. (arXiv:2102.11271v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.04125",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chepurko_N/0/1/0/all/0/1\">Nadiia Chepurko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clarkson_K/0/1/0/all/0/1\">Kenneth L. Clarkson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Horesh_L/0/1/0/all/0/1\">Lior Horesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1\">David P. Woodruff</a>",
          "description": "We create classical (non-quantum) dynamic data structures supporting queries\nfor recommender systems and least-squares regression that are comparable to\ntheir quantum analogues. De-quantizing such algorithms has received a flurry of\nattention in recent years; we obtain sharper bounds for these problems. More\nsignificantly, we achieve these improvements by arguing that the previous\nquantum-inspired algorithms for these problems are doing leverage or\nridge-leverage score sampling in disguise; these are powerful and standard\ntechniques in randomized numerical linear algebra. With this recognition, we\nare able to employ the large body of work in numerical linear algebra to obtain\nalgorithms for these problems that are simpler or faster (or both) than\nexisting approaches.",
          "link": "http://arxiv.org/abs/2011.04125",
          "publishedOn": "2021-07-21T02:01:37.244Z",
          "wordCount": 639,
          "title": "Quantum-Inspired Algorithms from Randomized Numerical Linear Algebra. (arXiv:2011.04125v5 [cs.DS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.09640",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Caballero_M/0/1/0/all/0/1\">Michael Caballero</a>",
          "description": "One major sub-domain in the subject of polling public opinion with social\nmedia data is electoral prediction. Electoral prediction utilizing social media\ndata potentially would significantly affect campaign strategies, complementing\ntraditional polling methods and providing cheaper polling in real-time. First,\nthis paper explores past successful methods from research for analysis and\nprediction of the 2020 US Presidential Election using Twitter data. Then, this\nresearch proposes a new method for electoral prediction which combines\nsentiment, from NLP on the text of tweets, and structural data with aggregate\npolling, a time series analysis, and a special focus on Twitter users critical\nto the election. Though this method performed worse than its baseline of\npolling predictions, it is inconclusive whether this is an accurate method for\npredicting elections due to scarcity of data. More research and more data are\nneeded to accurately measure this method's overall effectiveness.",
          "link": "http://arxiv.org/abs/2107.09640",
          "publishedOn": "2021-07-21T02:01:37.237Z",
          "wordCount": 592,
          "title": "Predicting the 2020 US Presidential Election with Twitter. (arXiv:2107.09640v1 [cs.SI])"
        },
        {
          "id": "http://arxiv.org/abs/2105.14686",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Weize Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yankai Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hexu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Peng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>",
          "description": "Hyperbolic neural networks have shown great potential for modeling complex\ndata. However, existing hyperbolic networks are not completely hyperbolic, as\nthey encode features in a hyperbolic space yet formalize most of their\noperations in the tangent space (a Euclidean subspace) at the origin of the\nhyperbolic space. This hybrid method greatly limits the modeling ability of\nnetworks. In this paper, we propose a fully hyperbolic framework to build\nhyperbolic networks based on the Lorentz model by adapting the Lorentz\ntransformations (including boost and rotation) to formalize essential\noperations of neural networks. Moreover, we also prove that linear\ntransformation in tangent spaces used by existing hyperbolic networks is a\nrelaxation of the Lorentz rotation and does not include the boost, implicitly\nlimiting the capabilities of existing hyperbolic networks. The experimental\nresults on four NLP tasks show that our method has better performance for\nbuilding both shallow and deep networks. Our code will be released to\nfacilitate follow-up research.",
          "link": "http://arxiv.org/abs/2105.14686",
          "publishedOn": "2021-07-21T02:01:37.231Z",
          "wordCount": 624,
          "title": "Fully Hyperbolic Neural Networks. (arXiv:2105.14686v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06639",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_J/0/1/0/all/0/1\">John Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malik_K/0/1/0/all/0/1\">Kshitiz Malik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_H/0/1/0/all/0/1\">Hongyuan Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yousefpour_A/0/1/0/all/0/1\">Ashkan Yousefpour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rabbat_M/0/1/0/all/0/1\">Michael Rabbat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malek_M/0/1/0/all/0/1\">Mani Malek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huba_D/0/1/0/all/0/1\">Dzmitry Huba</a>",
          "description": "Federated Learning (FL) trains a shared model across distributed devices\nwhile keeping the training data on the devices. Most FL schemes are\nsynchronous: they perform a synchronized aggregation of model updates from\nindividual devices. Synchronous training can be slow because of late-arriving\ndevices (stragglers). On the other hand, completely asynchronous training makes\nFL less private because of incompatibility with secure aggregation. In this\nwork, we propose a model aggregation scheme, FedBuff, that combines the best\nproperties of synchronous and asynchronous FL. Similar to synchronous FL,\nFedBuff is compatible with secure aggregation. Similar to asynchronous FL,\nFedBuff is robust to stragglers. In FedBuff, clients trains asynchronously and\nsend updates to the server. The server aggregates client updates in a private\nbuffer until updates have been received, at which point a server model update\nis immediately performed. We provide theoretical convergence guarantees for\nFedBuff in a non-convex setting. Empirically, FedBuff converges up to 3.8x\nfaster than previous proposals for synchronous FL (e.g., FedAvgM), and up to\n2.5x faster than previous proposals for asynchronous FL (e.g., FedAsync). We\nshow that FedBuff is robust to different staleness distributions and is more\nscalable than synchronous FL techniques.",
          "link": "http://arxiv.org/abs/2106.06639",
          "publishedOn": "2021-07-21T02:01:37.215Z",
          "wordCount": 653,
          "title": "Federated Learning with Buffered Asynchronous Aggregation. (arXiv:2106.06639v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.04426",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roller_S/0/1/0/all/0/1\">Stephen Roller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sukhbaatar_S/0/1/0/all/0/1\">Sainbayar Sukhbaatar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szlam_A/0/1/0/all/0/1\">Arthur Szlam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weston_J/0/1/0/all/0/1\">Jason Weston</a>",
          "description": "We investigate the training of sparse layers that use different parameters\nfor different inputs based on hashing in large Transformer models.\nSpecifically, we modify the feedforward layer to hash to different sets of\nweights depending on the current token, over all tokens in the sequence. We\nshow that this procedure either outperforms or is competitive with\nlearning-to-route mixture-of-expert methods such as Switch Transformers and\nBASE Layers, while requiring no routing parameters or extra terms in the\nobjective function such as a load balancing loss, and no sophisticated\nassignment algorithm. We study the performance of different hashing techniques,\nhash sizes and input features, and show that balanced and random hashes focused\non the most local features work best, compared to either learning clusters or\nusing longer-range context. We show our approach works well both on large\nlanguage modeling and dialogue tasks, and on downstream fine-tuning tasks.",
          "link": "http://arxiv.org/abs/2106.04426",
          "publishedOn": "2021-07-21T02:01:37.209Z",
          "wordCount": 614,
          "title": "Hash Layers For Large Sparse Models. (arXiv:2106.04426v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.01124",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sarafanov_M/0/1/0/all/0/1\">Mikhail Sarafanov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nikitin_N/0/1/0/all/0/1\">Nikolay O. Nikitin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalyuzhnaya_A/0/1/0/all/0/1\">Anna V. Kalyuzhnaya</a>",
          "description": "In the paper, we propose an adaptive data-driven model-based approach for\nfilling the gaps in time series. The approach is based on the automated\nevolutionary identification of the optimal structure for a composite\ndata-driven model. It allows adapting the model for the effective gap-filling\nin a specific dataset without the involvement of the data scientist. As a case\nstudy, both synthetic and real datasets from different fields (environmental,\neconomic, etc) are used. The experiments confirm that the proposed approach\nallows achieving the higher quality of the gap restoration and improve the\neffectiveness of forecasting models.",
          "link": "http://arxiv.org/abs/2103.01124",
          "publishedOn": "2021-07-21T02:01:37.203Z",
          "wordCount": 584,
          "title": "Automated data-driven approach for gap filling in the time series using evolutionary learning. (arXiv:2103.01124v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.09627",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Reyes_J/0/1/0/all/0/1\">Jonatan Reyes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jorio_L/0/1/0/all/0/1\">Lisa Di Jorio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Low_Kam_C/0/1/0/all/0/1\">Cecile Low-Kam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kersten_Oertel_M/0/1/0/all/0/1\">Marta Kersten-Oertel</a>",
          "description": "Federated Learning using the Federated Averaging algorithm has shown great\nadvantages for large-scale applications that rely on collaborative learning,\nespecially when the training data is either unbalanced or inaccessible due to\nprivacy constraints. We hypothesize that Federated Averaging underestimates the\nfull extent of heterogeneity of data when the aggregation is performed. We\npropose Precision-weighted Federated Learning a novel algorithm that takes into\naccount the variance of the stochastic gradients when computing the weighted\naverage of the parameters of models trained in a Federated Learning setting.\nWith Precision-weighted Federated Learning, we provide an alternate averaging\nscheme that leverages the heterogeneity of the data when it has a large\ndiversity of features in its composition. Our method was evaluated using\nstandard image classification datasets with two different data partitioning\nstrategies (IID/non-IID) to measure the performance and speed of our method in\nresource-constrained environments, such as mobile and IoT devices. We obtained\na good balance between computational efficiency and convergence rates with\nPrecision-weighted Federated Learning. Our performance evaluations show 9%\nbetter predictions with MNIST, 18% with Fashion-MNIST, and 5% with CIFAR-10 in\nthe non-IID setting. Further reliability evaluations ratify the stability in\nour method by reaching a 99% reliability index with IID partitions and 96% with\nnon-IID partitions. In addition, we obtained a 20x speedup on Fashion-MNIST\nwith only 10 clients and up to 37x with 100 clients participating in the\naggregation concurrently per communication round. The results indicate that\nPrecision-weighted Federated Learning is an effective and faster alternative\napproach for aggregating private data, especially in domains where data is\nhighly heterogeneous.",
          "link": "http://arxiv.org/abs/2107.09627",
          "publishedOn": "2021-07-21T02:01:37.196Z",
          "wordCount": 688,
          "title": "Precision-Weighted Federated Learning. (arXiv:2107.09627v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.00304",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Unke_O/0/1/0/all/0/1\">Oliver T. Unke</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Chmiela_S/0/1/0/all/0/1\">Stefan Chmiela</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Gastegger_M/0/1/0/all/0/1\">Michael Gastegger</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Schutt_K/0/1/0/all/0/1\">Kristof T. Sch&#xfc;tt</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Sauceda_H/0/1/0/all/0/1\">Huziel E. Sauceda</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Muller_K/0/1/0/all/0/1\">Klaus-Robert M&#xfc;ller</a>",
          "description": "Machine-learned force fields (ML-FFs) combine the accuracy of ab initio\nmethods with the efficiency of conventional force fields. However, current\nML-FFs typically ignore electronic degrees of freedom, such as the total charge\nor spin state, and assume chemical locality, which is problematic when\nmolecules have inconsistent electronic states, or when nonlocal effects play a\nsignificant role. This work introduces SpookyNet, a deep neural network for\nconstructing ML-FFs with explicit treatment of electronic degrees of freedom\nand quantum nonlocality. Chemically meaningful inductive biases and analytical\ncorrections built into the network architecture allow it to properly model\nphysical limits. SpookyNet improves upon the current state-of-the-art (or\nachieves similar performance) on popular quantum chemistry data sets. Notably,\nit is able to generalize across chemical and conformational space and can\nleverage the learned chemical insights, e.g. by predicting unknown spin states,\nthus helping to close a further important remaining gap for today's machine\nlearning models in quantum chemistry.",
          "link": "http://arxiv.org/abs/2105.00304",
          "publishedOn": "2021-07-21T02:01:37.189Z",
          "wordCount": 621,
          "title": "SpookyNet: Learning Force Fields with Electronic Degrees of Freedom and Nonlocal Effects. (arXiv:2105.00304v2 [physics.chem-ph] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.01936",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Liangxi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_F/0/1/0/all/0/1\">Feng Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_G/0/1/0/all/0/1\">Guo-Jun Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Heng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_L/0/1/0/all/0/1\">Ling Shao</a>",
          "description": "Federated learning (FL) allows multiple clients to collaboratively learn a\nglobally shared model through cycles of model aggregation and local model\ntraining, without the need to share data. Most existing FL methods train local\nmodels separately on different clients, and then simply average their\nparameters to obtain a centralized model on the server side. However, these\napproaches generally suffer from large aggregation errors and severe local\nforgetting, which are particularly bad in heterogeneous data settings. To\ntackle these issues, in this paper, we propose a novel FL framework that uses\nonline Laplace approximation to approximate posteriors on both the client and\nserver side. On the server side, a multivariate Gaussian product mechanism is\nemployed to construct and maximize a global posterior, largely reducing the\naggregation errors induced by large discrepancies between local models. On the\nclient side, a prior loss that uses the global posterior probabilistic\nparameters delivered from the server is designed to guide the local training.\nBinding such learning constraints from other clients enables our method to\nmitigate local forgetting. Finally, we achieve state-of-the-art results on\nseveral benchmarks, clearly demonstrating the advantages of the proposed\nmethod.",
          "link": "http://arxiv.org/abs/2102.01936",
          "publishedOn": "2021-07-21T02:01:37.170Z",
          "wordCount": 660,
          "title": "A Bayesian Federated Learning Framework with Online Laplace Approximation. (arXiv:2102.01936v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.15390",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chicheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_M/0/1/0/all/0/1\">Manish Kumar Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riek_L/0/1/0/all/0/1\">Laurel D. Riek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhuri_K/0/1/0/all/0/1\">Kamalika Chaudhuri</a>",
          "description": "In many real-world applications, multiple agents seek to learn how to perform\nhighly related yet slightly different tasks in an online bandit learning\nprotocol. We formulate this problem as the $\\epsilon$-multi-player multi-armed\nbandit problem, in which a set of players concurrently interact with a set of\narms, and for each arm, the reward distributions for all players are similar\nbut not necessarily identical. We develop an upper confidence bound-based\nalgorithm, RobustAgg$(\\epsilon)$, that adaptively aggregates rewards collected\nby different players. In the setting where an upper bound on the pairwise\nsimilarities of reward distributions between players is known, we achieve\ninstance-dependent regret guarantees that depend on the amenability of\ninformation sharing across players. We complement these upper bounds with\nnearly matching lower bounds. In the setting where pairwise similarities are\nunknown, we provide a lower bound, as well as an algorithm that trades off\nminimax regret guarantees for adaptivity to unknown similarity structure.",
          "link": "http://arxiv.org/abs/2010.15390",
          "publishedOn": "2021-07-21T02:01:37.164Z",
          "wordCount": 634,
          "title": "Multitask Bandit Learning Through Heterogeneous Feedback Aggregation. (arXiv:2010.15390v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.11858",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sreenivasaiah_D/0/1/0/all/0/1\">Deepthi Sreenivasaiah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Otterbach_J/0/1/0/all/0/1\">Johannes Otterbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wollmann_T/0/1/0/all/0/1\">Thomas Wollmann</a>",
          "description": "Image segmentation is a common and challenging task in autonomous driving.\nAvailability of sufficient pixel-level annotations for the training data is a\nhurdle. Active learning helps learning from small amounts of data by suggesting\nthe most promising samples for labeling. In this work, we propose a new\npool-based method for active learning, which proposes promising patches\nextracted from full image, in each acquisition step. The problem is framed in\nan exploration-exploitation framework by combining an embedding based on\nUniform Manifold Approximation to model representativeness with entropy as\nuncertainty measure to model informativeness. We applied our proposed method to\nthe autonomous driving datasets CamVid and Cityscapes and performed a\nquantitative comparison with state-of-the-art baselines. We find that our\nactive learning method achieves better performance compared to previous\nmethods.",
          "link": "http://arxiv.org/abs/2106.11858",
          "publishedOn": "2021-07-21T02:01:37.157Z",
          "wordCount": 584,
          "title": "MEAL: Manifold Embedding-based Active Learning. (arXiv:2106.11858v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.09176",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1\">Yan Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shimizu_S/0/1/0/all/0/1\">Shohei Shimizu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_R/0/1/0/all/0/1\">Ruichu Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_F/0/1/0/all/0/1\">Feng Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamamoto_M/0/1/0/all/0/1\">Michio Yamamoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_Z/0/1/0/all/0/1\">Zhifeng Hao</a>",
          "description": "Discovering causal structures among latent factors from observed data is a\nparticularly challenging problem. Despite some efforts for this problem,\nexisting methods focus on the single-domain data only. In this paper, we\npropose Multi-Domain Linear Non-Gaussian Acyclic Models for Latent Factors\n(MD-LiNA), where the causal structure among latent factors of interest is\nshared for all domains, and we provide its identification results. The model\nenriches the causal representation for multi-domain data. We propose an\nintegrated two-phase algorithm to estimate the model. In particular, we first\nlocate the latent factors and estimate the factor loading matrix. Then to\nuncover the causal structure among shared latent factors of interest, we derive\na score function based on the characterization of independence relations\nbetween external influences and the dependence relations between multi-domain\nlatent factors and latent factors of interest. We show that the proposed method\nprovides locally consistent estimators. Experimental results on both synthetic\nand real-world data demonstrate the efficacy and robustness of our approach.",
          "link": "http://arxiv.org/abs/2009.09176",
          "publishedOn": "2021-07-21T02:01:37.150Z",
          "wordCount": 635,
          "title": "Causal Discovery with Multi-Domain LiNGAM for Latent Factors. (arXiv:2009.09176v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.01188",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Arefeen_Y/0/1/0/all/0/1\">Yamin Arefeen</a> (1), <a href=\"http://arxiv.org/find/eess/1/au:+Beker_O/0/1/0/all/0/1\">Onur Beker</a> (2), <a href=\"http://arxiv.org/find/eess/1/au:+Cho_J/0/1/0/all/0/1\">Jaejin Cho</a> (3), <a href=\"http://arxiv.org/find/eess/1/au:+Yu_H/0/1/0/all/0/1\">Heng Yu</a> (4), <a href=\"http://arxiv.org/find/eess/1/au:+Adalsteinsson_E/0/1/0/all/0/1\">Elfar Adalsteinsson</a> (1 and 5 and 6), <a href=\"http://arxiv.org/find/eess/1/au:+Bilgic_B/0/1/0/all/0/1\">Berkin Bilgic</a> (3 and 5 and 7) ((1) Massachusetts Institute of Technology, (2) &#xc9;cole Polytechnique F&#xe9;d&#xe9;rale de Lausanne, (3) Athinoula A. Martinos Center for Biomedical Imaging (4) Tsinghua University, (5) Harvard-MIT Health Sciences and Technology, (6) Institute for Medical Engineering and Science, (7) Harvard Medical School)",
          "description": "Purpose: To develop a scan-specific model that estimates and corrects k-space\nerrors made when reconstructing accelerated Magnetic Resonance Imaging (MRI)\ndata.\n\nMethods: Scan-Specific Artifact Reduction in k-space (SPARK) trains a\nconvolutional-neural-network to estimate and correct k-space errors made by an\ninput reconstruction technique by back-propagating from the mean-squared-error\nloss between an auto-calibration signal (ACS) and the input technique's\nreconstructed ACS. First, SPARK is applied to GRAPPA and demonstrates improved\nrobustness over other scan-specific models, such as RAKI and residual-RAKI.\nSubsequent experiments demonstrate that SPARK synergizes with residual-RAKI to\nimprove reconstruction performance. SPARK also improves reconstruction quality\nwhen applied to advanced acquisition and reconstruction techniques like 2D\nvirtual coil (VC-) GRAPPA, 2D LORAKS, 3D GRAPPA without an integrated ACS\nregion, and 2D/3D wave-encoded images.\n\nResults: SPARK yields 1.5x - 2x RMSE reduction when applied to GRAPPA and\nimproves robustness to ACS size for various acceleration rates in comparison to\nother scan-specific techniques. When applied to advanced reconstruction\ntechniques such as residual-RAKI, 2D VC-GRAPPA and LORAKS, SPARK achieves up to\n20% RMSE improvement. SPARK with 3D GRAPPA also improves performance by ~2x and\nperceived image quality without a fully sampled ACS region. Finally, SPARK\nsynergizes with non-cartesian 2D and 3D wave-encoding imaging by reducing RMSE\nbetween 20-25% and providing qualitative improvements.\n\nConclusion: SPARK synergizes with physics-based acquisition and\nreconstruction techniques to improve accelerated MRI by training scan-specific\nmodels to estimate and correct reconstruction errors in k-space.",
          "link": "http://arxiv.org/abs/2104.01188",
          "publishedOn": "2021-07-21T02:01:37.134Z",
          "wordCount": 766,
          "title": "Scan Specific Artifact Reduction in K-space (SPARK) Neural Networks Synergize with Physics-based Reconstruction to Accelerate MRI. (arXiv:2104.01188v2 [eess.SP] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.04656",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Gupta_C/0/1/0/all/0/1\">Chirag Gupta</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ramdas_A/0/1/0/all/0/1\">Aaditya K. Ramdas</a>",
          "description": "We prove calibration guarantees for the popular histogram binning (also\ncalled uniform-mass binning) method of Zadrozny and Elkan [2001]. Histogram\nbinning has displayed strong practical performance, but theoretical guarantees\nhave only been shown for sample split versions that avoid 'double dipping' the\ndata. We demonstrate that the statistical cost of sample splitting is\npractically significant on a credit default dataset. We then prove calibration\nguarantees for the original method that double dips the data, using a certain\nMarkov property of order statistics. Based on our results, we make practical\nrecommendations for choosing the number of bins in histogram binning. In our\nillustrative simulations, we propose a new tool for assessing calibration --\nvalidity plots -- which provide more information than an ECE estimate. Code for\nthis work will be made publicly available at\nhttps://github.com/aigen/df-posthoc-calibration.",
          "link": "http://arxiv.org/abs/2105.04656",
          "publishedOn": "2021-07-21T02:01:37.126Z",
          "wordCount": 594,
          "title": "Distribution-free calibration guarantees for histogram binning without sample splitting. (arXiv:2105.04656v2 [stat.ME] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.13792",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Frei_S/0/1/0/all/0/1\">Spencer Frei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1\">Quanquan Gu</a>",
          "description": "Although the optimization objectives for learning neural networks are highly\nnon-convex, gradient-based methods have been wildly successful at learning\nneural networks in practice. This juxtaposition has led to a number of recent\nstudies on provable guarantees for neural networks trained by gradient descent.\nUnfortunately, the techniques in these works are often highly specific to the\nproblem studied in each setting, relying on different assumptions on the\ndistribution, optimization parameters, and network architectures, making it\ndifficult to generalize across different settings. In this work, we propose a\nunified non-convex optimization framework for the analysis of neural network\ntraining. We introduce the notions of proxy convexity and proxy\nPolyak-Lojasiewicz (PL) inequalities, which are satisfied if the original\nobjective function induces a proxy objective function that is implicitly\nminimized when using gradient methods. We show that stochastic gradient descent\n(SGD) on objectives satisfying proxy convexity or the proxy PL inequality leads\nto efficient guarantees for proxy objective functions. We further show that\nmany existing guarantees for neural networks trained by gradient descent can be\nunified through proxy convexity and proxy PL inequalities.",
          "link": "http://arxiv.org/abs/2106.13792",
          "publishedOn": "2021-07-21T02:01:37.120Z",
          "wordCount": 659,
          "title": "Proxy Convexity: A Unified Framework for the Analysis of Neural Networks Trained by Gradient Descent. (arXiv:2106.13792v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.09554",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tempelmeier_N/0/1/0/all/0/1\">Nicolas Tempelmeier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feuerhake_U/0/1/0/all/0/1\">Udo Feuerhake</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wage_O/0/1/0/all/0/1\">Oskar Wage</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Demidova_E/0/1/0/all/0/1\">Elena Demidova</a>",
          "description": "The discovery of spatio-temporal dependencies within urban road networks that\ncause Recurrent Congestion (RC) patterns is crucial for numerous real-world\napplications, including urban planning and scheduling of public transportation\nservices. While most existing studies investigate temporal patterns of RC\nphenomena, the influence of the road network topology on RC is often\noverlooked. This article proposes the ST-Discovery algorithm, a novel\nunsupervised spatio-temporal data mining algorithm that facilitates the\neffective data-driven discovery of RC dependencies induced by the road network\ntopology using real-world traffic data. We factor out regularly reoccurring\ntraffic phenomena, such as rush hours, mainly induced by the daytime, by\nmodelling and systematically exploiting temporal traffic load outliers. We\npresent an algorithm that first constructs connected subgraphs of the road\nnetwork based on the traffic speed outliers. Second, the algorithm identifies\npairs of subgraphs that indicate spatio-temporal correlations in their traffic\nload behaviour to identify topological dependencies within the road network.\nFinally, we rank the identified subgraph pairs based on the dependency score\ndetermined by our algorithm. Our experimental results demonstrate that\nST-Discovery can effectively reveal topological dependencies in urban road\nnetworks.",
          "link": "http://arxiv.org/abs/2107.09554",
          "publishedOn": "2021-07-21T02:01:37.112Z",
          "wordCount": 630,
          "title": "Mining Topological Dependencies of Recurrent Congestion in Road Networks. (arXiv:2107.09554v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.04754",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Aizenbud_Y/0/1/0/all/0/1\">Yariv Aizenbud</a>, <a href=\"http://arxiv.org/find/math/1/au:+Sober_B/0/1/0/all/0/1\">Barak Sober</a>",
          "description": "A common observation in data-driven applications is that high dimensional\ndata has a low intrinsic dimension, at least locally. In this work, we consider\nthe problem of estimating a $d$ dimensional sub-manifold of $\\mathbb{R}^D$ from\na finite set of noisy samples. Assuming that the data was sampled uniformly\nfrom a tubular neighborhood of $\\mathcal{M}\\in \\mathcal{C}^k$, a compact\nmanifold without boundary, we present an algorithm that takes a point $r$ from\nthe tubular neighborhood and outputs $\\hat p_n\\in \\mathbb{R}^D$, and\n$\\widehat{T_{\\hat p_n}\\mathcal{M}}$ an element in the Grassmanian $Gr(d, D)$.\nWe prove that as the number of samples $n\\to\\infty$ the point $\\hat p_n$\nconverges to $p\\in \\mathcal{M}$ and $\\widehat{T_{\\hat p_n}\\mathcal{M}}$\nconverges to $T_p\\mathcal{M}$ (the tangent space at that point) with high\nprobability. Furthermore, we show that the estimation yields asymptotic rates\nof convergence of $n^{-\\frac{k}{2k + d}}$ for the point estimation and\n$n^{-\\frac{k-1}{2k + d}}$ for the estimation of the tangent space. These rates\nare known to be optimal for the case of function estimation.",
          "link": "http://arxiv.org/abs/2105.04754",
          "publishedOn": "2021-07-21T02:01:37.106Z",
          "wordCount": 610,
          "title": "Non-Parametric Estimation of Manifolds from Noisy Data. (arXiv:2105.04754v2 [math.ST] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.09602",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Bharati_S/0/1/0/all/0/1\">Subrato Bharati</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Podder_P/0/1/0/all/0/1\">Prajoy Podder</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mondal_M/0/1/0/all/0/1\">M. Rubaiyat Hossain Mondal</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Prasath_V/0/1/0/all/0/1\">V.B. Surya Prasath</a>",
          "description": "The outbreak of novel coronavirus disease (COVID- 19) has claimed millions of\nlives and has affected all aspects of human life. This paper focuses on the\napplication of deep learning (DL) models to medical imaging and drug discovery\nfor managing COVID-19 disease. In this article, we detail various medical\nimaging-based studies such as X-rays and computed tomography (CT) images along\nwith DL methods for classifying COVID-19 affected versus pneumonia. The\napplications of DL techniques to medical images are further described in terms\nof image localization, segmentation, registration, and classification leading\nto COVID-19 detection. The reviews of recent papers indicate that the highest\nclassification accuracy of 99.80% is obtained when InstaCovNet-19 DL method is\napplied to an X-ray dataset of 361 COVID-19 patients, 362 pneumonia patients\nand 365 normal people. Furthermore, it can be seen that the best classification\naccuracy of 99.054% can be achieved when EDL_COVID DL method is applied to a CT\nimage dataset of 7500 samples where COVID-19 patients, lung tumor patients and\nnormal people are equal in number. Moreover, we illustrate the potential DL\ntechniques in drug or vaccine discovery in combating the coronavirus. Finally,\nwe address a number of problems, concerns and future research directions\nrelevant to DL applications for COVID-19.",
          "link": "http://arxiv.org/abs/2107.09602",
          "publishedOn": "2021-07-21T02:01:37.098Z",
          "wordCount": 729,
          "title": "Medical Imaging with Deep Learning for COVID- 19 Diagnosis: A Comprehensive Review. (arXiv:2107.09602v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2103.00222",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Unlu_A/0/1/0/all/0/1\">Ali Unlu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Aitchison_L/0/1/0/all/0/1\">Laurence Aitchison</a>",
          "description": "We develop variational Laplace for Bayesian neural networks (BNNs) which\nexploits a local approximation of the curvature of the likelihood to estimate\nthe ELBO without the need for stochastic sampling of the neural-network\nweights. The Variational Laplace objective is simple to evaluate, as it is (in\nessence) the log-likelihood, plus weight-decay, plus a squared-gradient\nregularizer. Variational Laplace gave better test performance and expected\ncalibration errors than maximum a-posteriori inference and standard\nsampling-based variational inference, despite using the same variational\napproximate posterior. Finally, we emphasise care needed in benchmarking\nstandard VI as there is a risk of stopping before the variance parameters have\nconverged. We show that early-stopping can be avoided by increasing the\nlearning rate for the variance parameters.",
          "link": "http://arxiv.org/abs/2103.00222",
          "publishedOn": "2021-07-21T02:01:37.091Z",
          "wordCount": 583,
          "title": "Variational Laplace for Bayesian neural networks. (arXiv:2103.00222v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.05319",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hwang_U/0/1/0/all/0/1\">Uiwon Hwang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Heeseung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_D/0/1/0/all/0/1\">Dahuin Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jang_H/0/1/0/all/0/1\">Hyemi Jang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hyungyu Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1\">Sungroh Yoon</a>",
          "description": "Generative adversarial networks (GANs) with clustered latent spaces can\nperform conditional generation in a completely unsupervised manner. However,\nthe salient attributes of unlabeled data in the real-world are mostly\nimbalanced. Existing unsupervised conditional GANs cannot properly cluster the\nattributes in their latent spaces because they assume uniform distributions of\nthe attributes. To address this problem, we theoretically derive Stein latent\noptimization that provides reparameterizable gradient estimations of the latent\ndistribution parameters assuming a Gaussian mixture prior in a continuous\nlatent space. Structurally, we introduce an encoder network and a novel\ncontrastive loss to help generated data from a single mixture component to\nrepresent a single attribute. We confirm that the proposed method, named Stein\nLatent Optimization for GANs (SLOGAN), successfully learns the balanced or\nimbalanced attributes and performs unsupervised tasks such as unsupervised\nconditional generation, unconditional generation, and cluster assignment even\nin the absence of information of the attributes (e.g. the imbalance ratio).\nMoreover, we demonstrate that the attributes to be learned can be manipulated\nusing a small amount of probe data.",
          "link": "http://arxiv.org/abs/2106.05319",
          "publishedOn": "2021-07-21T02:01:37.085Z",
          "wordCount": 634,
          "title": "Stein Latent Optimization for GANs. (arXiv:2106.05319v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.09562",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Milbich_T/0/1/0/all/0/1\">Timo Milbich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_K/0/1/0/all/0/1\">Karsten Roth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sinha_S/0/1/0/all/0/1\">Samarth Sinha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidt_L/0/1/0/all/0/1\">Ludwig Schmidt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghassemi_M/0/1/0/all/0/1\">Marzyeh Ghassemi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ommer_B/0/1/0/all/0/1\">Bj&#xf6;rn Ommer</a>",
          "description": "Deep Metric Learning (DML) aims to find representations suitable for\nzero-shot transfer to a priori unknown test distributions. However, common\nevaluation protocols only test a single, fixed data split in which train and\ntest classes are assigned randomly. More realistic evaluations should consider\na broad spectrum of distribution shifts with potentially varying degree and\ndifficulty. In this work, we systematically construct train-test splits of\nincreasing difficulty and present the ooDML benchmark to characterize\ngeneralization under out-of-distribution shifts in DML. ooDML is designed to\nprobe the generalization performance on much more challenging, diverse\ntrain-to-test distribution shifts. Based on our new benchmark, we conduct a\nthorough empirical analysis of state-of-the-art DML methods. We find that while\ngeneralization tends to consistently degrade with difficulty, some methods are\nbetter at retaining performance as the distribution shift increases. Finally,\nwe propose few-shot DML as an efficient way to consistently improve\ngeneralization in response to unknown test shifts presented in ooDML. Code\navailable here:\nhttps://github.com/Confusezius/Characterizing_Generalization_in_DeepMetricLearning.",
          "link": "http://arxiv.org/abs/2107.09562",
          "publishedOn": "2021-07-21T02:01:37.052Z",
          "wordCount": 604,
          "title": "Characterizing Generalization under Out-Of-Distribution Shifts in Deep Metric Learning. (arXiv:2107.09562v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.04570",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Eiras_F/0/1/0/all/0/1\">Francisco Eiras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alfarra_M/0/1/0/all/0/1\">Motasem Alfarra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_M/0/1/0/all/0/1\">M. Pawan Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1\">Philip H. S. Torr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dokania_P/0/1/0/all/0/1\">Puneet K. Dokania</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghanem_B/0/1/0/all/0/1\">Bernard Ghanem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bibi_A/0/1/0/all/0/1\">Adel Bibi</a>",
          "description": "Randomized smoothing has recently emerged as an effective tool that enables\ncertification of deep neural network classifiers at scale. All prior art on\nrandomized smoothing has focused on isotropic $\\ell_p$ certification, which has\nthe advantage of yielding certificates that can be easily compared among\nisotropic methods via $\\ell_p$-norm radius. However, isotropic certification\nlimits the region that can be certified around an input to worst-case\nadversaries, i.e., it cannot reason about other \"close\", potentially large,\nconstant prediction safe regions. To alleviate this issue, (i) we theoretically\nextend the isotropic randomized smoothing $\\ell_1$ and $\\ell_2$ certificates to\ntheir generalized anisotropic counterparts following a simplified analysis.\nMoreover, (ii) we propose evaluation metrics allowing for the comparison of\ngeneral certificates - a certificate is superior to another if it certifies a\nsuperset region - with the quantification of each certificate through the\nvolume of the certified region. We introduce ANCER, a practical framework for\nobtaining anisotropic certificates for a given test set sample via volume\nmaximization. Our empirical results demonstrate that ANCER achieves\nstate-of-the-art $\\ell_1$ and $\\ell_2$ certified accuracy on both CIFAR-10 and\nImageNet at multiple radii, while certifying substantially larger regions in\nterms of volume, thus highlighting the benefits of moving away from isotropic\nanalysis. Code used in our experiments is available in\nhttps://github.com/MotasemAlfarra/ANCER.",
          "link": "http://arxiv.org/abs/2107.04570",
          "publishedOn": "2021-07-21T02:01:37.040Z",
          "wordCount": 687,
          "title": "ANCER: Anisotropic Certification via Sample-wise Volume Maximization. (arXiv:2107.04570v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.02913",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bernau_D/0/1/0/all/0/1\">Daniel Bernau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eibl_G/0/1/0/all/0/1\">G&#xfc;nther Eibl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grassal_P/0/1/0/all/0/1\">Philip W. Grassal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keller_H/0/1/0/all/0/1\">Hannah Keller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kerschbaum_F/0/1/0/all/0/1\">Florian Kerschbaum</a>",
          "description": "Differential privacy allows bounding the influence that training data records\nhave on a machine learning model. To use differential privacy in machine\nlearning, data scientists must choose privacy parameters $(\\epsilon,\\delta)$.\nChoosing meaningful privacy parameters is key, since models trained with weak\nprivacy parameters might result in excessive privacy leakage, while strong\nprivacy parameters might overly degrade model utility. However, privacy\nparameter values are difficult to choose for two main reasons. First, the\ntheoretical upper bound on privacy loss $(\\epsilon,\\delta)$ might be loose,\ndepending on the chosen sensitivity and data distribution of practical\ndatasets. Second, legal requirements and societal norms for anonymization often\nrefer to individual identifiability, to which $(\\epsilon,\\delta)$ are only\nindirectly related.\n\nWe transform $(\\epsilon,\\delta)$ to a bound on the Bayesian posterior belief\nof the adversary assumed by differential privacy concerning the presence of any\nrecord in the training dataset. The bound holds for multidimensional queries\nunder composition, and we show that it can be tight in practice. Furthermore,\nwe derive an identifiability bound, which relates the adversary assumed in\ndifferential privacy to previous work on membership inference adversaries. We\nformulate an implementation of this differential privacy adversary that allows\ndata scientists to audit model training and compute empirical identifiability\nscores and empirical $(\\epsilon,\\delta)$.",
          "link": "http://arxiv.org/abs/2103.02913",
          "publishedOn": "2021-07-21T02:01:37.032Z",
          "wordCount": 690,
          "title": "Quantifying identifiability to choose and audit $\\epsilon$ in differentially private deep learning. (arXiv:2103.02913v3 [cs.CR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.11203",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cai_T/0/1/0/all/0/1\">Tianle Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_R/0/1/0/all/0/1\">Ruiqi Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jason D. Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_Q/0/1/0/all/0/1\">Qi Lei</a>",
          "description": "One of the central problems in machine learning is domain adaptation. Unlike\npast theoretical work, we consider a new model for subpopulation shift in the\ninput or representation space. In this work, we propose a provably effective\nframework for domain adaptation based on label propagation. In our analysis, we\nuse a simple but realistic expansion assumption, proposed in\n\\citet{wei2021theoretical}. Using a teacher classifier trained on the source\ndomain, our algorithm not only propagates to the target domain but also\nimproves upon the teacher. By leveraging existing generalization bounds, we\nalso obtain end-to-end finite-sample guarantees on the entire algorithm. In\naddition, we extend our theoretical framework to a more general setting of\nsource-to-target transfer based on a third unlabeled dataset, which can be\neasily applied in various learning scenarios. Inspired by our theory, we adapt\nconsistency-based semi-supervised learning methods to domain adaptation\nsettings and gain significant improvements.",
          "link": "http://arxiv.org/abs/2102.11203",
          "publishedOn": "2021-07-21T02:01:37.021Z",
          "wordCount": 628,
          "title": "A Theory of Label Propagation for Subpopulation Shift. (arXiv:2102.11203v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.02684",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Devos_A/0/1/0/all/0/1\">Arnout Devos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dandi_Y/0/1/0/all/0/1\">Yatin Dandi</a>",
          "description": "In this paper, we propose a learning algorithm that enables a model to\nquickly exploit commonalities among related tasks from an unseen task\ndistribution, before quickly adapting to specific tasks from that same\ndistribution. We investigate how learning with different task distributions can\nfirst improve adaptability by meta-finetuning on related tasks before improving\ngoal task generalization with finetuning. Synthetic regression experiments\nvalidate the intuition that learning to meta-learn improves adaptability and\nconsecutively generalization. Experiments on more complex image classification,\ncontinual regression, and reinforcement learning tasks demonstrate that\nlearning to meta-learn generally improves task-specific adaptation. The\nmethodology, setup, and hypotheses in this proposal were positively evaluated\nby peer review before conclusive experiments were carried out.",
          "link": "http://arxiv.org/abs/2012.02684",
          "publishedOn": "2021-07-21T02:01:37.004Z",
          "wordCount": 577,
          "title": "Model-Agnostic Learning to Meta-Learn. (arXiv:2012.02684v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.10586",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1\">Kaidi Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chenan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1\">Hao Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kailkhura_B/0/1/0/all/0/1\">Bhavya Kailkhura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1\">Xue Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldhahn_R/0/1/0/all/0/1\">Ryan Goldhahn</a>",
          "description": "To tackle the susceptibility of deep neural networks to examples, the\nadversarial training has been proposed which provides a notion of robust\nthrough an inner maximization problem presenting the first-order embedded\nwithin the outer minimization of the training loss. To generalize the\nadversarial robustness over different perturbation types, the adversarial\ntraining method has been augmented with the improved inner maximization\npresenting a union of multiple perturbations e.g., various $\\ell_p$\nnorm-bounded perturbations.",
          "link": "http://arxiv.org/abs/2104.10586",
          "publishedOn": "2021-07-21T02:01:36.979Z",
          "wordCount": 591,
          "title": "Mixture of Robust Experts (MoRE):A Robust Denoising Method towards multiple perturbations. (arXiv:2104.10586v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.13677",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Huang_W/0/1/0/all/0/1\">Wenqi Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ke_Z/0/1/0/all/0/1\">Ziwen Ke</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cui_Z/0/1/0/all/0/1\">Zhuo-Xu Cui</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cheng_J/0/1/0/all/0/1\">Jing Cheng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Qiu_Z/0/1/0/all/0/1\">Zhilang Qiu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jia_S/0/1/0/all/0/1\">Sen Jia</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ying_L/0/1/0/all/0/1\">Leslie Ying</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhu_Y/0/1/0/all/0/1\">Yanjie Zhu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liang_D/0/1/0/all/0/1\">Dong Liang</a>",
          "description": "In dynamic magnetic resonance (MR) imaging, low-rank plus sparse (L+S)\ndecomposition, or robust principal component analysis (PCA), has achieved\nstunning performance. However, the selection of the parameters of L+S is\nempirical, and the acceleration rate is limited, which are common failings of\niterative compressed sensing MR imaging (CS-MRI) reconstruction methods. Many\ndeep learning approaches have been proposed to address these issues, but few of\nthem use a low-rank prior. In this paper, a model-based low-rank plus sparse\nnetwork, dubbed L+S-Net, is proposed for dynamic MR reconstruction. In\nparticular, we use an alternating linearized minimization method to solve the\noptimization problem with low-rank and sparse regularization. Learned soft\nsingular value thresholding is introduced to ensure the clear separation of the\nL component and S component. Then, the iterative steps are unrolled into a\nnetwork in which the regularization parameters are learnable. We prove that the\nproposed L+S-Net achieves global convergence under two standard assumptions.\nExperiments on retrospective and prospective cardiac cine datasets show that\nthe proposed model outperforms state-of-the-art CS and existing deep learning\nmethods and has great potential for extremely high acceleration factors (up to\n24x).",
          "link": "http://arxiv.org/abs/2010.13677",
          "publishedOn": "2021-07-21T02:01:36.971Z",
          "wordCount": 677,
          "title": "Deep Low-rank plus Sparse Network for Dynamic MR Imaging. (arXiv:2010.13677v3 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.05108",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cooper_J/0/1/0/all/0/1\">Jessica Cooper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arandjelovic_O/0/1/0/all/0/1\">Ognjen Arandjelovi&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harrison_D/0/1/0/all/0/1\">David J Harrison</a>",
          "description": "Understanding the predictions made by Artificial Intelligence (AI) systems is\nbecoming more and more important as deep learning models are used for\nincreasingly complex and high-stakes tasks. Saliency mapping - an easily\ninterpretable visual attribution method - is one important tool for this, but\nexisting formulations are limited by either computational cost or architectural\nconstraints. We therefore propose Hierarchical Perturbation, a very fast and\ncompletely model-agnostic method for explaining model predictions with robust\nsaliency maps. Using standard benchmarks and datasets, we show that our\nsaliency maps are of competitive or superior quality to those generated by\nexisting model-agnostic methods - and are over 20X faster to compute.",
          "link": "http://arxiv.org/abs/2103.05108",
          "publishedOn": "2021-07-21T02:01:36.929Z",
          "wordCount": 587,
          "title": "Believe The HiPe: Hierarchical Perturbation for Fast, Robust and Model-Agnostic Explanations. (arXiv:2103.05108v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.09645",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yarats_D/0/1/0/all/0/1\">Denis Yarats</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fergus_R/0/1/0/all/0/1\">Rob Fergus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lazaric_A/0/1/0/all/0/1\">Alessandro Lazaric</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pinto_L/0/1/0/all/0/1\">Lerrel Pinto</a>",
          "description": "We present DrQ-v2, a model-free reinforcement learning (RL) algorithm for\nvisual continuous control. DrQ-v2 builds on DrQ, an off-policy actor-critic\napproach that uses data augmentation to learn directly from pixels. We\nintroduce several improvements that yield state-of-the-art results on the\nDeepMind Control Suite. Notably, DrQ-v2 is able to solve complex humanoid\nlocomotion tasks directly from pixel observations, previously unattained by\nmodel-free RL. DrQ-v2 is conceptually simple, easy to implement, and provides\nsignificantly better computational footprint compared to prior work, with the\nmajority of tasks taking just 8 hours to train on a single GPU. Finally, we\npublicly release DrQ-v2's implementation to provide RL practitioners with a\nstrong and computationally efficient baseline.",
          "link": "http://arxiv.org/abs/2107.09645",
          "publishedOn": "2021-07-21T02:01:36.923Z",
          "wordCount": 545,
          "title": "Mastering Visual Continuous Control: Improved Data-Augmented Reinforcement Learning. (arXiv:2107.09645v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2103.10790",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Katona_A/0/1/0/all/0/1\">Adam Katona</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Franks_D/0/1/0/all/0/1\">Daniel W. Franks</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walker_J/0/1/0/all/0/1\">James Alfred Walker</a>",
          "description": "One of the most important lessons from the success of deep learning is that\nlearned representations tend to perform much better at any task compared to\nrepresentations we design by hand. Yet evolution of evolvability algorithms,\nwhich aim to automatically learn good genetic representations, have received\nrelatively little attention, perhaps because of the large amount of\ncomputational power they require. The recent method Evolvability ES allows\ndirect selection for evolvability with little computation. However, it can only\nbe used to solve problems where evolvability and task performance are aligned.\nWe propose Quality Evolvability ES, a method that simultaneously optimizes for\ntask performance and evolvability and without this restriction. Our proposed\napproach Quality Evolvability has similar motivation to Quality Diversity\nalgorithms, but with some important differences. While Quality Diversity aims\nto find an archive of diverse and well-performing, but potentially genetically\ndistant individuals, Quality Evolvability aims to find a single individual with\na diverse and well-performing distribution of offspring. By doing so Quality\nEvolvability is forced to discover more evolvable representations. We\ndemonstrate on robotic locomotion control tasks that Quality Evolvability ES,\nsimilarly to Quality Diversity methods, can learn faster than objective-based\nmethods and can handle deceptive problems.",
          "link": "http://arxiv.org/abs/2103.10790",
          "publishedOn": "2021-07-21T02:01:36.890Z",
          "wordCount": 687,
          "title": "Quality Evolvability ES: Evolving Individuals With a Distribution of Well Performing and Diverse Offspring. (arXiv:2103.10790v2 [cs.NE] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.08898",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fisch_A/0/1/0/all/0/1\">Adam Fisch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schuster_T/0/1/0/all/0/1\">Tal Schuster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaakkola_T/0/1/0/all/0/1\">Tommi Jaakkola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barzilay_R/0/1/0/all/0/1\">Regina Barzilay</a>",
          "description": "We develop a novel approach to conformal prediction when the target task has\nlimited data available for training. Conformal prediction identifies a small\nset of promising output candidates in place of a single prediction, with\nguarantees that the set contains the correct answer with high probability. When\ntraining data is limited, however, the predicted set can easily become unusably\nlarge. In this work, we obtain substantially tighter prediction sets while\nmaintaining desirable marginal guarantees by casting conformal prediction as a\nmeta-learning paradigm over exchangeable collections of auxiliary tasks. Our\nconformalization algorithm is simple, fast, and agnostic to the choice of\nunderlying model, learning algorithm, or dataset. We demonstrate the\neffectiveness of this approach across a number of few-shot classification and\nregression tasks in natural language processing, computer vision, and\ncomputational chemistry for drug discovery.",
          "link": "http://arxiv.org/abs/2102.08898",
          "publishedOn": "2021-07-21T02:01:36.863Z",
          "wordCount": 603,
          "title": "Few-shot Conformal Prediction with Auxiliary Tasks. (arXiv:2102.08898v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.12922",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Turian_J/0/1/0/all/0/1\">Joseph Turian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shier_J/0/1/0/all/0/1\">Jordie Shier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tzanetakis_G/0/1/0/all/0/1\">George Tzanetakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McNally_K/0/1/0/all/0/1\">Kirk McNally</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henry_M/0/1/0/all/0/1\">Max Henry</a>",
          "description": "We release synth1B1, a multi-modal audio corpus consisting of 1 billion\n4-second synthesized sounds, paired with the synthesis parameters used to\ngenerate them. The dataset is 100x larger than any audio dataset in the\nliterature. We also introduce torchsynth, an open source modular synthesizer\nthat generates the synth1B1 samples on-the-fly at 16200x faster than real-time\n(714MHz) on a single GPU. Finally, we release two new audio datasets: FM synth\ntimbre and subtractive synth pitch. Using these datasets, we demonstrate new\nrank-based evaluation criteria for existing audio representations. Finally, we\npropose a novel approach to synthesizer hyperparameter optimization.",
          "link": "http://arxiv.org/abs/2104.12922",
          "publishedOn": "2021-07-21T02:01:36.832Z",
          "wordCount": 571,
          "title": "One Billion Audio Sounds from GPU-enabled Modular Synthesis. (arXiv:2104.12922v2 [cs.SD] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2002.09067",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_K/0/1/0/all/0/1\">Kensen Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bieber_D/0/1/0/all/0/1\">David Bieber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sutton_C/0/1/0/all/0/1\">Charles Sutton</a>",
          "description": "Sampling is a fundamental technique, and sampling without replacement is\noften desirable when duplicate samples are not beneficial. Within machine\nlearning, sampling is useful for generating diverse outputs from a trained\nmodel. We present an elegant procedure for sampling without replacement from a\nbroad class of randomized programs, including generative neural models that\nconstruct outputs sequentially. Our procedure is efficient even for\nexponentially-large output spaces. Unlike prior work, our approach is\nincremental, i.e., samples can be drawn one at a time, allowing for increased\nflexibility. We also present a new estimator for computing expectations from\nsamples drawn without replacement. We show that incremental sampling without\nreplacement is applicable to many domains, e.g., program synthesis and\ncombinatorial optimization.",
          "link": "http://arxiv.org/abs/2002.09067",
          "publishedOn": "2021-07-21T02:01:36.825Z",
          "wordCount": 582,
          "title": "Incremental Sampling Without Replacement for Sequence Models. (arXiv:2002.09067v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.09597",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Hayakawa_S/0/1/0/all/0/1\">Satoshi Hayakawa</a>, <a href=\"http://arxiv.org/find/math/1/au:+Oberhauser_H/0/1/0/all/0/1\">Harald Oberhauser</a>, <a href=\"http://arxiv.org/find/math/1/au:+Lyons_T/0/1/0/all/0/1\">Terry Lyons</a>",
          "description": "We study kernel quadrature rules with positive weights for probability\nmeasures on general domains. Our theoretical analysis combines the spectral\nproperties of the kernel with random sampling of points. This results in\neffective algorithms to construct kernel quadrature rules with positive weights\nand small worst-case error. Besides additional robustness, our numerical\nexperiments indicate that this can achieve fast convergence rates that compete\nwith the optimal bounds in well-known examples.",
          "link": "http://arxiv.org/abs/2107.09597",
          "publishedOn": "2021-07-21T02:01:36.719Z",
          "wordCount": 506,
          "title": "Positively Weighted Kernel Quadrature via Subsampling. (arXiv:2107.09597v1 [math.NA])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09217",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_S/0/1/0/all/0/1\">Shuting Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1\">Xiangxiang Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Wei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_F/0/1/0/all/0/1\">Feng Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_C/0/1/0/all/0/1\">Changzhi Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiangrong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_S/0/1/0/all/0/1\">Shaoliang Peng</a>",
          "description": "The Corona Virus Disease 2019 (COVID-19) belongs to human coronaviruses\n(HCoVs), which spreads rapidly around the world. Compared with new drug\ndevelopment, drug repurposing may be the best shortcut for treating COVID-19.\nTherefore, we constructed a comprehensive heterogeneous network based on the\nHCoVs-related target proteins and use the previously proposed deepDTnet, to\ndiscover potential drug candidates for COVID-19. We obtain high performance in\npredicting the possible drugs effective for COVID-19 related proteins. In\nsummary, this work utilizes a powerful heterogeneous network-based deep\nlearning method, which may be beneficial to quickly identify candidate\nrepurposable drugs toward future clinical trials for COVID-19. The code and\ndata are available at https://github.com/stjin-XMU/HnDR-COVID.",
          "link": "http://arxiv.org/abs/2107.09217",
          "publishedOn": "2021-07-21T02:01:36.701Z",
          "wordCount": 601,
          "title": "Heterogeneous network-based drug repurposing for COVID-19. (arXiv:2107.09217v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2101.08032",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yin_W/0/1/0/all/0/1\">Wanguang Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1\">Zhengming Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Quanying Liu</a>",
          "description": "Linear discriminant analysis (LDA) is a widely used algorithm in machine\nlearning to extract a low-dimensional representation of high-dimensional data,\nit features to find the orthogonal discriminant projection subspace by using\nthe Fisher discriminant criterion. However, the traditional Euclidean-based\nmethods for solving LDA are easily convergent to spurious local minima and\nhardly obtain an optimal solution. To address such a problem, in this paper, we\npropose a novel algorithm namely Riemannian-based discriminant analysis (RDA)\nfor subspace learning. In order to obtain an explicit solution, we transform\nthe traditional Euclidean-based methods to the Riemannian manifold space and\nuse the trust-region method to learn the discriminant projection subspace. We\ncompare the proposed algorithm to existing variants of LDA, as well as the\nunsupervised tensor decomposition methods on image classification tasks. The\nnumerical results suggest that RDA achieves state-of-the-art performance in\nclassification accuracy.",
          "link": "http://arxiv.org/abs/2101.08032",
          "publishedOn": "2021-07-21T02:01:36.638Z",
          "wordCount": 618,
          "title": "Riemannian Manifold Optimization for Discriminant Subspace Learning. (arXiv:2101.08032v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.00755",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shekhar_S/0/1/0/all/0/1\">Shubhanshu Shekhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fields_G/0/1/0/all/0/1\">Greg Fields</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghavamzadeh_M/0/1/0/all/0/1\">Mohammad Ghavamzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Javidi_T/0/1/0/all/0/1\">Tara Javidi</a>",
          "description": "Machine learning models trained on uncurated datasets can often end up\nadversely affecting inputs belonging to underrepresented groups. To address\nthis issue, we consider the problem of adaptively constructing training sets\nwhich allow us to learn classifiers that are fair in a minimax sense. We first\npropose an adaptive sampling algorithm based on the principle of optimism, and\nderive theoretical bounds on its performance. We also propose heuristic\nextensions of this algorithm suitable for application to large scale, practical\nproblems. Next, by deriving algorithm independent lower-bounds for a specific\nclass of problems, we show that the performance achieved by our adaptive scheme\ncannot be improved in general. We then validate the benefits of adaptively\nconstructing training sets via experiments on synthetic tasks with logistic\nregression classifiers, as well as on several real-world tasks using\nconvolutional neural networks (CNNs).",
          "link": "http://arxiv.org/abs/2103.00755",
          "publishedOn": "2021-07-21T02:01:36.628Z",
          "wordCount": 596,
          "title": "Adaptive Sampling for Minimax Fair Classification. (arXiv:2103.00755v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.09546",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Petersen_E/0/1/0/all/0/1\">Eike Petersen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potdevin_Y/0/1/0/all/0/1\">Yannik Potdevin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohammadi_E/0/1/0/all/0/1\">Esfandiar Mohammadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zidowitz_S/0/1/0/all/0/1\">Stephan Zidowitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Breyer_S/0/1/0/all/0/1\">Sabrina Breyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nowotka_D/0/1/0/all/0/1\">Dirk Nowotka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henn_S/0/1/0/all/0/1\">Sandra Henn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pechmann_L/0/1/0/all/0/1\">Ludwig Pechmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leucker_M/0/1/0/all/0/1\">Martin Leucker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rostalski_P/0/1/0/all/0/1\">Philipp Rostalski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Herzog_C/0/1/0/all/0/1\">Christian Herzog</a>",
          "description": "Machine learning is expected to fuel significant improvements in medical\ncare. To ensure that fundamental principles such as beneficence, respect for\nhuman autonomy, prevention of harm, justice, privacy, and transparency are\nrespected, medical machine learning applications must be developed responsibly.\nIn this paper, we survey the technical challenges involved in creating medical\nmachine learning systems responsibly and in conformity with existing\nregulations, as well as possible solutions to address these challenges. We\nbegin by providing a brief overview of existing regulations affecting medical\nmachine learning, showing that properties such as safety, robustness,\nreliability, privacy, security, transparency, explainability, and\nnondiscrimination are all demanded already by existing law and regulations -\nalbeit, in many cases, to an uncertain degree. Next, we discuss the underlying\ntechnical challenges, possible ways for addressing them, and their respective\nmerits and drawbacks. We notice that distribution shift, spurious correlations,\nmodel underspecification, and data scarcity represent severe challenges in the\nmedical context (and others) that are very difficult to solve with classical\nblack-box deep neural networks. Important measures that may help to address\nthese challenges include the use of large and representative datasets and\nfederated learning as a means to that end, the careful exploitation of domain\nknowledge wherever feasible, the use of inherently transparent models,\ncomprehensive model testing and verification, as well as stakeholder inclusion.",
          "link": "http://arxiv.org/abs/2107.09546",
          "publishedOn": "2021-07-21T02:01:36.619Z",
          "wordCount": 693,
          "title": "Responsible and Regulatory Conform Machine Learning for Medicine: A Survey of Technical Challenges and Solutions. (arXiv:2107.09546v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2010.13972",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mitchell_R/0/1/0/all/0/1\">Rory Mitchell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frank_E/0/1/0/all/0/1\">Eibe Frank</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holmes_G/0/1/0/all/0/1\">Geoffrey Holmes</a>",
          "description": "SHAP (SHapley Additive exPlanation) values provide a game theoretic\ninterpretation of the predictions of machine learning models based on Shapley\nvalues. While exact calculation of SHAP values is computationally intractable\nin general, a recursive polynomial-time algorithm called TreeShap is available\nfor decision tree models. However, despite its polynomial time complexity,\nTreeShap can become a significant bottleneck in practical machine learning\npipelines when applied to large decision tree ensembles. We present\nGPUTreeShap, a modified TreeShap algorithm suitable for massively parallel\ncomputation on graphics processing units. Our approach first preprocesses each\ndecision tree to isolate variable sized sub-problems from the original\nrecursive algorithm, then solves a bin packing problem, and finally maps\nsub-problems to single-instruction, multiple-thread (SIMT) tasks for parallel\nexecution with specialised hardware instructions. With a single NVIDIA Tesla\nV100-32 GPU, we achieve speedups of up to 19x for SHAP values, and speedups of\nup to 340x for SHAP interaction values, over a state-of-the-art multi-core CPU\nimplementation executed on two 20-core Xeon E5-2698 v4 2.2 GHz CPUs. We also\nexperiment with multi-GPU computing using eight V100 GPUs, demonstrating\nthroughput of 1.2M rows per second -- equivalent CPU-based performance is\nestimated to require 6850 CPU cores.",
          "link": "http://arxiv.org/abs/2010.13972",
          "publishedOn": "2021-07-21T02:01:36.593Z",
          "wordCount": 663,
          "title": "GPUTreeShap: Massively Parallel Exact Calculation of SHAP Scores for Tree Ensembles. (arXiv:2010.13972v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.05675",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jinhai Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hua Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lin Chen</a>",
          "description": "Few-shot learning aims at rapidly adapting to novel categories with only a\nhandful of samples at test time, which has been predominantly tackled with the\nidea of meta-learning. However, meta-learning approaches essentially learn\nacross a variety of few-shot tasks and thus still require large-scale training\ndata with fine-grained supervision to derive a generalized model, thereby\ninvolving prohibitive annotation cost. In this paper, we advance the few-shot\nclassification paradigm towards a more challenging scenario, i.e.,\ncross-granularity few-shot classification, where the model observes only coarse\nlabels during training while is expected to perform fine-grained classification\nduring testing. This task largely relieves the annotation cost since\nfine-grained labeling usually requires strong domain-specific expertise. To\nbridge the cross-granularity gap, we approximate the fine-grained data\ndistribution by greedy clustering of each coarse-class into pseudo-fine-classes\naccording to the similarity of image embeddings. We then propose a\nmeta-embedder that jointly optimizes the visual- and semantic-discrimination,\nin both instance-wise and coarse class-wise, to obtain a good feature space for\nthis coarse-to-fine pseudo-labeling process. Extensive experiments and ablation\nstudies are conducted to demonstrate the effectiveness and robustness of our\napproach on three representative datasets.",
          "link": "http://arxiv.org/abs/2007.05675",
          "publishedOn": "2021-07-21T02:01:36.578Z",
          "wordCount": 674,
          "title": "Towards Cross-Granularity Few-Shot Learning: Coarse-to-Fine Pseudo-Labeling with Visual-Semantic Meta-Embedding. (arXiv:2007.05675v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.05206",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ma_K/0/1/0/all/0/1\">Ke Ma</a>, <a href=\"http://arxiv.org/find/eess/1/au:+He_D/0/1/0/all/0/1\">Dongxuan He</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sun_H/0/1/0/all/0/1\">Hancun Sun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_Z/0/1/0/all/0/1\">Zhaocheng Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_S/0/1/0/all/0/1\">Sheng Chen</a>",
          "description": "Huge overhead of beam training imposes a significant challenge in\nmillimeter-wave (mmWave) wireless communications. To address this issue, in\nthis paper, we propose a wide beam based training approach to calibrate the\nnarrow beam direction according to the channel power leakage. To handle the\ncomplex nonlinear properties of the channel power leakage, deep learning is\nutilized to predict the optimal narrow beam directly. Specifically, three deep\nlearning assisted calibrated beam training schemes are proposed. The first\nscheme adopts convolution neural network to implement the prediction based on\nthe instantaneous received signals of wide beam training. We also perform the\nadditional narrow beam training based on the predicted probabilities for\nfurther beam direction calibrations. However, the first scheme only depends on\none wide beam training, which lacks the robustness to noise. To tackle this\nproblem, the second scheme adopts long-short term memory (LSTM) network for\ntracking the movement of users and calibrating the beam direction according to\nthe received signals of prior beam training, in order to enhance the robustness\nto noise. To further reduce the overhead of wide beam training, our third\nscheme, an adaptive beam training strategy, selects partial wide beams to be\ntrained based on the prior received signals. Two criteria, namely, optimal\nneighboring criterion and maximum probability criterion, are designed for the\nselection. Furthermore, to handle mobile scenarios, auxiliary LSTM is\nintroduced to calibrate the directions of the selected wide beams more\nprecisely. Simulation results demonstrate that our proposed schemes achieve\nsignificantly higher beamforming gain with smaller beam training overhead\ncompared with the conventional and existing deep-learning based counterparts.",
          "link": "http://arxiv.org/abs/2101.05206",
          "publishedOn": "2021-07-21T02:01:36.571Z",
          "wordCount": 740,
          "title": "Deep Learning Assisted Calibrated Beam Training for Millimeter-Wave Communication Systems. (arXiv:2101.05206v3 [eess.SP] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.12177",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Langevin_A/0/1/0/all/0/1\">Antoine Langevin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carbonneau_M/0/1/0/all/0/1\">Marc-Andr&#xe9; Carbonneau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheriet_M/0/1/0/all/0/1\">Mohamed Cheriet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gagnon_G/0/1/0/all/0/1\">Ghyslain Gagnon</a>",
          "description": "Non-intrusive load monitoring (NILM) is a technique that uses a single sensor\nto measure the total power consumption of a building. Using an energy\ndisaggregation method, the consumption of individual appliances can be\nestimated from the aggregate measurement. Recent disaggregation algorithms have\nsignificantly improved the performance of NILM systems. However, the\ngeneralization capability of these methods to different houses as well as the\ndisaggregation of multi-state appliances are still major challenges. In this\npaper we address these issues and propose an energy disaggregation approach\nbased on the variational autoencoders framework. The probabilistic encoder\nmakes this approach an efficient model for encoding information relevant to the\nreconstruction of the target appliance consumption. In particular, the proposed\nmodel accurately generates more complex load profiles, thus improving the power\nsignal reconstruction of multi-state appliances. Moreover, its regularized\nlatent space improves the generalization capabilities of the model across\ndifferent houses. The proposed model is compared to state-of-the-art NILM\napproaches on the UK-DALE and REFIT datasets, and yields competitive results.\nThe mean absolute error reduces by 18% on average across all appliances\ncompared to the state-of-the-art. The F1-Score increases by more than 11%,\nshowing improvements for the detection of the target appliance in the aggregate\nmeasurement.",
          "link": "http://arxiv.org/abs/2103.12177",
          "publishedOn": "2021-07-21T02:01:36.564Z",
          "wordCount": 669,
          "title": "Energy Disaggregation using Variational Autoencoders. (arXiv:2103.12177v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.08001",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hatua_A/0/1/0/all/0/1\">Amartya Hatua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_A/0/1/0/all/0/1\">Arjun Mukherjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verma_R/0/1/0/all/0/1\">Rakesh M. Verma</a>",
          "description": "This article describes research on claim verification carried out using a\nmultiple GAN-based model. The proposed model consists of three pairs of\ngenerators and discriminators. The generator and discriminator pairs are\nresponsible for generating synthetic data for supported and refuted claims and\nclaim labels. A theoretical discussion about the proposed model is provided to\nvalidate the equilibrium state of the model. The proposed model is applied to\nthe FEVER dataset, and a pre-trained language model is used for the input text\ndata. The synthetically generated data helps to gain information which helps\nthe model to perform better than state of the art models and other standard\nclassifiers.",
          "link": "http://arxiv.org/abs/2103.08001",
          "publishedOn": "2021-07-21T02:01:36.542Z",
          "wordCount": 598,
          "title": "Claim Verification using a Multi-GAN based Model. (arXiv:2103.08001v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.09598",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Franzmeyer_T/0/1/0/all/0/1\">Tim Franzmeyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malinowski_M/0/1/0/all/0/1\">Mateusz Malinowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henriques_J/0/1/0/all/0/1\">Jo&#xe3;o F. Henriques</a>",
          "description": "Can artificial agents learn to assist others in achieving their goals without\nknowing what those goals are? Generic reinforcement learning agents could be\ntrained to behave altruistically towards others by rewarding them for\naltruistic behaviour, i.e., rewarding them for benefiting other agents in a\ngiven situation. Such an approach assumes that other agents' goals are known so\nthat the altruistic agent can cooperate in achieving those goals. However,\nexplicit knowledge of other agents' goals is often difficult to acquire. Even\nassuming such knowledge to be given, training of altruistic agents would\nrequire manually-tuned external rewards for each new environment. Thus, it is\nbeneficial to develop agents that do not depend on external supervision and can\nlearn altruistic behaviour in a task-agnostic manner. Assuming that other\nagents rationally pursue their goals, we hypothesize that giving them more\nchoices will allow them to pursue those goals better. Some concrete examples\ninclude opening a door for others or safeguarding them to pursue their\nobjectives without interference. We formalize this concept and propose an\naltruistic agent that learns to increase the choices another agent has by\nmaximizing the number of states that the other agent can reach in its future.\nWe evaluate our approach on three different multi-agent environments where\nanother agent's success depends on the altruistic agent's behaviour. Finally,\nwe show that our unsupervised agents can perform comparably to agents\nexplicitly trained to work cooperatively. In some cases, our agents can even\noutperform the supervised ones.",
          "link": "http://arxiv.org/abs/2107.09598",
          "publishedOn": "2021-07-21T02:01:36.535Z",
          "wordCount": 681,
          "title": "Learning Altruistic Behaviours in Reinforcement Learning without External Rewards. (arXiv:2107.09598v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2106.08909",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brandfonbrener_D/0/1/0/all/0/1\">David Brandfonbrener</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Whitney_W/0/1/0/all/0/1\">William F. Whitney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranganath_R/0/1/0/all/0/1\">Rajesh Ranganath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bruna_J/0/1/0/all/0/1\">Joan Bruna</a>",
          "description": "Most prior approaches to offline reinforcement learning (RL) have taken an\niterative actor-critic approach involving off-policy evaluation. In this paper\nwe show that simply doing one step of constrained/regularized policy\nimprovement using an on-policy Q estimate of the behavior policy performs\nsurprisingly well. This one-step algorithm beats the previously reported\nresults of iterative algorithms on a large portion of the D4RL benchmark. The\nsimple one-step baseline achieves this strong performance without many of the\ntricks used by previously proposed iterative algorithms and is more robust to\nhyperparameters. We argue that the relatively poor performance of iterative\napproaches is a result of the high variance inherent in doing off-policy\nevaluation and magnified by the repeated optimization of policies against those\nhigh-variance estimates. In addition, we hypothesize that the strong\nperformance of the one-step algorithm is due to a combination of favorable\nstructure in the environment and behavior policy.",
          "link": "http://arxiv.org/abs/2106.08909",
          "publishedOn": "2021-07-21T02:01:36.527Z",
          "wordCount": 607,
          "title": "Offline RL Without Off-Policy Evaluation. (arXiv:2106.08909v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.09543",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Osuala_R/0/1/0/all/0/1\">Richard Osuala</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kushibar_K/0/1/0/all/0/1\">Kaisar Kushibar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Garrucho_L/0/1/0/all/0/1\">Lidia Garrucho</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Linardos_A/0/1/0/all/0/1\">Akis Linardos</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Szafranowska_Z/0/1/0/all/0/1\">Zuzanna Szafranowska</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Klein_S/0/1/0/all/0/1\">Stefan Klein</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Glocker_B/0/1/0/all/0/1\">Ben Glocker</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Diaz_O/0/1/0/all/0/1\">Oliver Diaz</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lekadir_K/0/1/0/all/0/1\">Karim Lekadir</a>",
          "description": "Despite technological and medical advances, the detection, interpretation,\nand treatment of cancer based on imaging data continue to pose significant\nchallenges. These include high inter-observer variability, difficulty of\nsmall-sized lesion detection, nodule interpretation and malignancy\ndetermination, inter- and intra-tumour heterogeneity, class imbalance,\nsegmentation inaccuracies, and treatment effect uncertainty. The recent\nadvancements in Generative Adversarial Networks (GANs) in computer vision as\nwell as in medical imaging may provide a basis for enhanced capabilities in\ncancer detection and analysis. In this review, we assess the potential of GANs\nto address a number of key challenges of cancer imaging, including data\nscarcity and imbalance, domain and dataset shifts, data access and privacy,\ndata annotation and quantification, as well as cancer detection, tumour\nprofiling and treatment planning. We provide a critical appraisal of the\nexisting literature of GANs applied to cancer imagery, together with\nsuggestions on future research directions to address these challenges. We\nanalyse and discuss 163 papers that apply adversarial training techniques in\nthe context of cancer imaging and elaborate their methodologies, advantages and\nlimitations. With this work, we strive to bridge the gap between the needs of\nthe clinical cancer imaging community and the current and prospective research\non GANs in the artificial intelligence community.",
          "link": "http://arxiv.org/abs/2107.09543",
          "publishedOn": "2021-07-21T02:01:36.520Z",
          "wordCount": 691,
          "title": "A Review of Generative Adversarial Networks in Cancer Imaging: New Applications, New Solutions. (arXiv:2107.09543v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09647",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mayer_J/0/1/0/all/0/1\">Jana Mayer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Westermann_J/0/1/0/all/0/1\">Johannes Westermann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muriedas_J/0/1/0/all/0/1\">Juan Pedro Guti&#xe9;rrez H. Muriedas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mettin_U/0/1/0/all/0/1\">Uwe Mettin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lampe_A/0/1/0/all/0/1\">Alexander Lampe</a>",
          "description": "In recent years, reinforcement learning (RL) has gained increasing attention\nin control engineering. Especially, policy gradient methods are widely used. In\nthis work, we improve the tracking performance of proximal policy optimization\n(PPO) for arbitrary reference signals by incorporating information about future\nreference values. Two variants of extending the argument of the actor and the\ncritic taking future reference values into account are presented. In the first\nvariant, global future reference values are added to the argument. For the\nsecond variant, a novel kind of residual space with future reference values\napplicable to model-free reinforcement learning is introduced. Our approach is\nevaluated against a PI controller on a simple drive train model. We expect our\nmethod to generalize to arbitrary references better than previous approaches,\npointing towards the applicability of RL to control real systems.",
          "link": "http://arxiv.org/abs/2107.09647",
          "publishedOn": "2021-07-21T02:01:36.513Z",
          "wordCount": 584,
          "title": "Proximal Policy Optimization for Tracking Control Exploiting Future Reference Information. (arXiv:2107.09647v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.07856",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1\">Yu Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mei_S/0/1/0/all/0/1\">Song Mei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Huan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1\">Caiming Xiong</a>",
          "description": "Modern machine learning models with high accuracy are often miscalibrated --\nthe predicted top probability does not reflect the actual accuracy, and tends\nto be over-confident. It is commonly believed that such over-confidence is\nmainly due to over-parametrization, in particular when the model is large\nenough to memorize the training data and maximize the confidence.\n\nIn this paper, we show theoretically that over-parametrization is not the\nonly reason for over-confidence. We prove that logistic regression is\ninherently over-confident, in the realizable, under-parametrized setting where\nthe data is generated from the logistic model, and the sample size is much\nlarger than the number of parameters. Further, this over-confidence happens for\ngeneral well-specified binary classification problems as long as the activation\nis symmetric and concave on the positive part. Perhaps surprisingly, we also\nshow that over-confidence is not always the case -- there exists another\nactivation function (and a suitable loss function) under which the learned\nclassifier is under-confident at some probability values. Overall, our theory\nprovides a precise characterization of calibration in realizable binary\nclassification, which we verify on simulations and real data experiments.",
          "link": "http://arxiv.org/abs/2102.07856",
          "publishedOn": "2021-07-21T02:01:36.497Z",
          "wordCount": 668,
          "title": "Don't Just Blame Over-parametrization for Over-confidence: Theoretical Analysis of Calibration in Binary Classification. (arXiv:2102.07856v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.13416",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Burton_C/0/1/0/all/0/1\">Charles Burton</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Stubbs_S/0/1/0/all/0/1\">Spencer Stubbs</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Onyisi_P/0/1/0/all/0/1\">Peter Onyisi</a>",
          "description": "Mixture Density Networks (MDNs) can be used to generate probability density\nfunctions of model parameters $\\boldsymbol{\\theta}$ given a set of observables\n$\\mathbf{x}$. In some applications, training data are available only for\ndiscrete values of a continuous parameter $\\boldsymbol{\\theta}$. In such\nsituations a number of performance-limiting issues arise which can result in\nbiased estimates. We demonstrate the usage of MDNs for parameter estimation,\ndiscuss the origins of the biases, and propose a corrective method for each\nissue.",
          "link": "http://arxiv.org/abs/2103.13416",
          "publishedOn": "2021-07-21T02:01:36.490Z",
          "wordCount": 549,
          "title": "Mixture Density Network Estimation of Continuous Variable Maximum Likelihood Using Discrete Training Samples. (arXiv:2103.13416v2 [physics.data-an] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.10314",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xue_Y/0/1/0/all/0/1\">Ye Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lau_V/0/1/0/all/0/1\">Vincent Lau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_S/0/1/0/all/0/1\">Songfu Cai</a>",
          "description": "Sparse coding is a class of unsupervised methods for learning a sparse\nrepresentation of the input data in the form of a linear combination of a\ndictionary and a sparse code. This learning framework has led to\nstate-of-the-art results in various image and video processing tasks. However,\nclassical methods learn the dictionary and the sparse code based on alternating\noptimizations, usually without theoretical guarantees for either optimality or\nconvergence due to non-convexity of the problem. Recent works on sparse coding\nwith a complete dictionary provide strong theoretical guarantees thanks to the\ndevelopment of the non-convex optimization. However, initial non-convex\napproaches learn the dictionary in the sparse coding problem sequentially in an\natom-by-atom manner, which leads to a long execution time. More recent works\nseek to directly learn the entire dictionary at once, which substantially\nreduces the execution time. However, the associated recovery performance is\ndegraded with a finite number of data samples. In this paper, we propose an\nefficient sparse coding scheme with a two-stage optimization. The proposed\nscheme leverages the global and local Riemannian geometry of the two-stage\noptimization problem and facilitates fast implementation for superb dictionary\nrecovery performance by a finite number of samples without atom-by-atom\ncalculation. We further prove that, with high probability, the proposed scheme\ncan exactly recover any atom in the target dictionary with a finite number of\nsamples if it is adopted to recover one atom of the dictionary. An application\non wireless sensor data compression is also proposed. Experiments on both\nsynthetic and real-world data verify the efficiency and effectiveness of the\nproposed scheme.",
          "link": "http://arxiv.org/abs/2104.10314",
          "publishedOn": "2021-07-21T02:01:36.482Z",
          "wordCount": 753,
          "title": "Efficient Sparse Coding using Hierarchical Riemannian Pursuit. (arXiv:2104.10314v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02081",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Vargas_F/0/1/0/all/0/1\">Francisco Vargas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Thodoroff_P/0/1/0/all/0/1\">Pierre Thodoroff</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lawrence_N/0/1/0/all/0/1\">Neil D. Lawrence</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lamacraft_A/0/1/0/all/0/1\">Austen Lamacraft</a>",
          "description": "The Schr\\\"odinger bridge problem (SBP) finds the most likely stochastic\nevolution between two probability distributions given a prior stochastic\nevolution. As well as applications in the natural sciences, problems of this\nkind have important applications in machine learning such as dataset alignment\nand hypothesis testing. Whilst the theory behind this problem is relatively\nmature, scalable numerical recipes to estimate the Schr\\\"odinger bridge remain\nan active area of research. We prove an equivalence between the SBP and maximum\nlikelihood estimation enabling direct application of successful machine\nlearning techniques. We propose a numerical procedure to estimate SBPs using\nGaussian process and demonstrate the practical usage of our approach in\nnumerical simulations and experiments.",
          "link": "http://arxiv.org/abs/2106.02081",
          "publishedOn": "2021-07-21T02:01:36.474Z",
          "wordCount": 576,
          "title": "Solving Schr\\\"odinger Bridges via Maximum Likelihood. (arXiv:2106.02081v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.09621",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1\">Guoliang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuai Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jie Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Meihong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_X/0/1/0/all/0/1\">Xiaohui Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_T/0/1/0/all/0/1\">Tony Xiao Han</a>",
          "description": "Integrated sensing and communication (ISAC) is a promising technology to\nimprove the band-utilization efficiency via spectrum sharing or hardware\nsharing between radar and communication systems. Since a common radio resource\nbudget is shared by both functionalities, there exists a tradeoff between the\nsensing and communication performance. However, this tradeoff curve is\ncurrently unknown in ISAC systems with human motion recognition tasks based on\ndeep learning. To fill this gap, this paper formulates and solves a\nmulti-objective optimization problem which simultaneously maximizes the\nrecognition accuracy and the communication data rate. The key ingredient of\nthis new formulation is a nonlinear recognition accuracy model with respect to\nthe wireless resources, where the model is derived from power function\nregression of the system performance of the deep spectrogram network. To avoid\ncost-expensive data collection procedures, a primitive-based autoregressive\nhybrid (PBAH) channel model is developed, which facilitates efficient training\nand testing dataset generation for human motion recognition in a virtual\nenvironment. Extensive results demonstrate that the proposed wireless\nrecognition accuracy and PBAH channel models match the actual experimental data\nvery well. Moreover, it is found that the accuracy-rate region consists of a\ncommunication saturation zone, a sensing saturation zone, and a\ncommunication-sensing adversarial zone, of which the third zone achieves the\ndesirable balanced performance for ISAC systems.",
          "link": "http://arxiv.org/abs/2107.09621",
          "publishedOn": "2021-07-21T02:01:36.468Z",
          "wordCount": 682,
          "title": "Rethinking the Tradeoff in Integrated Sensing and Communication: Recognition Accuracy versus Communication Rate. (arXiv:2107.09621v1 [cs.IT])"
        },
        {
          "id": "http://arxiv.org/abs/2107.03974",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pong_V/0/1/0/all/0/1\">Vitchyr H. Pong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nair_A/0/1/0/all/0/1\">Ashvin Nair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_L/0/1/0/all/0/1\">Laura Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1\">Catherine Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1\">Sergey Levine</a>",
          "description": "Meta-reinforcement learning (RL) can meta-train policies that adapt to new\ntasks with orders of magnitude less data than standard RL, but meta-training\nitself is costly and time-consuming. If we can meta-train on offline data, then\nwe can reuse the same static dataset, labeled once with rewards for different\ntasks, to meta-train policies that adapt to a variety of new tasks at meta-test\ntime. Although this capability would make meta-RL a practical tool for\nreal-world use, offline meta-RL presents additional challenges beyond online\nmeta-RL or standard offline RL settings. Meta-RL learns an exploration strategy\nthat collects data for adapting, and also meta-trains a policy that quickly\nadapts to data from a new task. Since this policy was meta-trained on a fixed,\noffline dataset, it might behave unpredictably when adapting to data collected\nby the learned exploration strategy, which differs systematically from the\noffline data and thus induces distributional shift. We do not want to remove\nthis distributional shift by simply adopting a conservative exploration\nstrategy, because learning an exploration strategy enables an agent to collect\nbetter data for faster adaptation. Instead, we propose a hybrid offline meta-RL\nalgorithm, which uses offline data with rewards to meta-train an adaptive\npolicy, and then collects additional unsupervised online data, without any\nreward labels to bridge this distribution shift. By not requiring reward labels\nfor online collection, this data can be much cheaper to collect. We compare our\nmethod to prior work on offline meta-RL on simulated robot locomotion and\nmanipulation tasks and find that using additional unsupervised online data\ncollection leads to a dramatic improvement in the adaptive capabilities of the\nmeta-trained policies, matching the performance of fully online meta-RL on a\nrange of challenging domains that require generalization to new tasks.",
          "link": "http://arxiv.org/abs/2107.03974",
          "publishedOn": "2021-07-21T02:01:36.449Z",
          "wordCount": 747,
          "title": "Offline Meta-Reinforcement Learning with Online Self-Supervision. (arXiv:2107.03974v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.03814",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Birrell_J/0/1/0/all/0/1\">Jeremiah Birrell</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dupuis_P/0/1/0/all/0/1\">Paul Dupuis</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Katsoulakis_M/0/1/0/all/0/1\">Markos A. Katsoulakis</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rey_Bellet_L/0/1/0/all/0/1\">Luc Rey-Bellet</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_J/0/1/0/all/0/1\">Jie Wang</a>",
          "description": "We derive a new variational formula for the R\\'enyi family of divergences,\n$R_\\alpha(Q\\|P)$, between probability measures $Q$ and $P$. Our result\ngeneralizes the classical Donsker-Varadhan variational formula for the\nKullback-Leibler divergence. We further show that this R\\'enyi variational\nformula holds over a range of function spaces; this leads to a formula for the\noptimizer under very weak assumptions and is also key in our development of a\nconsistency theory for R\\'enyi divergence estimators. By applying this theory\nto neural-network estimators, we show that if a neural network family satisfies\none of several strengthened versions of the universal approximation property\nthen the corresponding R\\'enyi divergence estimator is consistent. In contrast\nto density-estimator based methods, our estimators involve only expectations\nunder $Q$ and $P$ and hence are more effective in high dimensional systems. We\nillustrate this via several numerical examples of neural network estimation in\nsystems of up to 5000 dimensions.",
          "link": "http://arxiv.org/abs/2007.03814",
          "publishedOn": "2021-07-21T02:01:36.442Z",
          "wordCount": 643,
          "title": "Variational Representations and Neural Network Estimation of R\\'enyi Divergences. (arXiv:2007.03814v4 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.09572",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Erez_L/0/1/0/all/0/1\">Liad Erez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koren_T/0/1/0/all/0/1\">Tomer Koren</a>",
          "description": "We study the online learning with feedback graphs framework introduced by\nMannor and Shamir (2011), in which the feedback received by the online learner\nis specified by a graph $G$ over the available actions. We develop an algorithm\nthat simultaneously achieves regret bounds of the form:\n$\\smash{\\mathcal{O}(\\sqrt{\\theta(G) T})}$ with adversarial losses;\n$\\mathcal{O}(\\theta(G)\\operatorname{polylog}{T})$ with stochastic losses; and\n$\\mathcal{O}(\\theta(G)\\operatorname{polylog}{T} + \\smash{\\sqrt{\\theta(G) C})}$\nwith stochastic losses subject to $C$ adversarial corruptions. Here,\n$\\theta(G)$ is the clique covering number of the graph $G$. Our algorithm is an\ninstantiation of Follow-the-Regularized-Leader with a novel regularization that\ncan be seen as a product of a Tsallis entropy component (inspired by Zimmert\nand Seldin (2019)) and a Shannon entropy component (analyzed in the corrupted\nstochastic case by Amir et al. (2020)), thus subtly interpolating between the\ntwo forms of entropies. One of our key technical contributions is in\nestablishing the convexity of this regularizer and controlling its inverse\nHessian, despite its complex product structure.",
          "link": "http://arxiv.org/abs/2107.09572",
          "publishedOn": "2021-07-21T02:01:36.436Z",
          "wordCount": 583,
          "title": "Best-of-All-Worlds Bounds for Online Learning with Feedback Graphs. (arXiv:2107.09572v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09355",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Haotian Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qianxiao Li</a>",
          "description": "We study the approximation properties of convolutional architectures applied\nto time series modelling, which can be formulated mathematically as a\nfunctional approximation problem. In the recurrent setting, recent results\nreveal an intricate connection between approximation efficiency and memory\nstructures in the data generation process. In this paper, we derive parallel\nresults for convolutional architectures, with WaveNet being a prime example.\nOur results reveal that in this new setting, approximation efficiency is not\nonly characterised by memory, but also additional fine structures in the target\nrelationship. This leads to a novel definition of spectrum-based regularity\nthat measures the complexity of temporal relationships under the convolutional\napproximation scheme. These analyses provide a foundation to understand the\ndifferences between architectural choices for time series modelling and can\ngive theoretically grounded guidance for practical applications.",
          "link": "http://arxiv.org/abs/2107.09355",
          "publishedOn": "2021-07-21T02:01:36.429Z",
          "wordCount": 578,
          "title": "Approximation Theory of Convolutional Architectures for Time Series Modelling. (arXiv:2107.09355v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09542",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hanneke_S/0/1/0/all/0/1\">Steve Hanneke</a>",
          "description": "This open problem asks whether there exists an online learning algorithm for\nbinary classification that guarantees, for all target concepts, to make a\nsublinear number of mistakes, under only the assumption that the (possibly\nrandom) sequence of points X allows that such a learning algorithm can exist\nfor that sequence. As a secondary problem, it also asks whether a specific\nconcise condition completely determines whether a given (possibly random)\nsequence of points X admits the existence of online learning algorithms\nguaranteeing a sublinear number of mistakes for all target concepts.",
          "link": "http://arxiv.org/abs/2107.09542",
          "publishedOn": "2021-07-21T02:01:36.422Z",
          "wordCount": 547,
          "title": "Open Problem: Is There an Online Learning Algorithm That Learns Whenever Online Learning Is Possible?. (arXiv:2107.09542v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.06212",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Manda_B/0/1/0/all/0/1\">Bharadwaj Manda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dhayarkar_S/0/1/0/all/0/1\">Shubham Dhayarkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitheran_S/0/1/0/all/0/1\">Sai Mitheran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Viekash_V/0/1/0/all/0/1\">V.K. Viekash</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muthuganapathy_R/0/1/0/all/0/1\">Ramanathan Muthuganapathy</a>",
          "description": "Ongoing advancements in the fields of 3D modelling and digital archiving have\nled to an outburst in the amount of data stored digitally. Consequently,\nseveral retrieval systems have been developed depending on the type of data\nstored in these databases. However, unlike text data or images, performing a\nsearch for 3D models is non-trivial. Among 3D models, retrieving 3D\nEngineering/CAD models or mechanical components is even more challenging due to\nthe presence of holes, volumetric features, presence of sharp edges etc., which\nmake CAD a domain unto itself. The research work presented in this paper aims\nat developing a dataset suitable for building a retrieval system for 3D CAD\nmodels based on deep learning. 3D CAD models from the available CAD databases\nare collected, and a dataset of computer-generated sketch data, termed\n'CADSketchNet', has been prepared. Additionally, hand-drawn sketches of the\ncomponents are also added to CADSketchNet. Using the sketch images from this\ndataset, the paper also aims at evaluating the performance of various retrieval\nsystem or a search engine for 3D CAD models that accepts a sketch image as the\ninput query. Many experimental models are constructed and tested on\nCADSketchNet. These experiments, along with the model architecture, choice of\nsimilarity metrics are reported along with the search results.",
          "link": "http://arxiv.org/abs/2107.06212",
          "publishedOn": "2021-07-21T02:01:36.416Z",
          "wordCount": 713,
          "title": "'CADSketchNet' -- An Annotated Sketch dataset for 3D CAD Model Retrieval with Deep Neural Networks. (arXiv:2107.06212v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.09539",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gauthier_S/0/1/0/all/0/1\">Shanel Gauthier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Therien_B/0/1/0/all/0/1\">Benjamin Th&#xe9;rien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alsene_Racicot_L/0/1/0/all/0/1\">Laurent Als&#xe8;ne-Racicot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rish_I/0/1/0/all/0/1\">Irina Rish</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belilovsky_E/0/1/0/all/0/1\">Eugene Belilovsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eickenberg_M/0/1/0/all/0/1\">Michael Eickenberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolf_G/0/1/0/all/0/1\">Guy Wolf</a>",
          "description": "The wavelet scattering transform creates geometric invariants and deformation\nstability from an initial structured signal. In multiple signal domains it has\nbeen shown to yield more discriminative representations compared to other\nnon-learned representations, and to outperform learned representations in\ncertain tasks, particularly on limited labeled data and highly structured\nsignals. The wavelet filters used in the scattering transform are typically\nselected to create a tight frame via a parameterized mother wavelet. Focusing\non Morlet wavelets, we propose to instead adapt the scales, orientations, and\nslants of the filters to produce problem-specific parametrizations of the\nscattering transform. We show that our learned versions of the scattering\ntransform yield significant performance gains over the standard scattering\ntransform in the small sample classification settings, and our empirical\nresults suggest that tight frames may not always be necessary for scattering\ntransforms to extract effective representations.",
          "link": "http://arxiv.org/abs/2107.09539",
          "publishedOn": "2021-07-21T02:01:36.391Z",
          "wordCount": 583,
          "title": "Parametric Scattering Networks. (arXiv:2107.09539v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09577",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vu_T/0/1/0/all/0/1\">Tung T. Vu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ngo_H/0/1/0/all/0/1\">Hien Quoc Ngo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marzetta_T/0/1/0/all/0/1\">Thomas L. Marzetta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matthaiou_M/0/1/0/all/0/1\">Michail Matthaiou</a>",
          "description": "Federated learning (FL) has been considered as a promising learning framework\nfor future machine learning systems due to its privacy preservation and\ncommunication efficiency. In beyond-5G/6G systems, it is likely to have\nmultiple FL groups with different learning purposes. This scenario leads to a\nquestion: How does a wireless network support multiple FL groups? As an answer,\nwe first propose to use a cell-free massive multiple-input multiple-output\n(MIMO) network to guarantee the stable operation of multiple FL processes by\nletting the iterations of these FL processes be executed together within a\nlarge-scale coherence time. We then develop a novel scheme that asynchronously\nexecutes the iterations of FL processes under multicasting downlink and\nconventional uplink transmission protocols. Finally, we propose a\nsimple/low-complexity resource allocation algorithm which optimally chooses the\npower and computation resources to minimize the execution time of each\niteration of each FL process.",
          "link": "http://arxiv.org/abs/2107.09577",
          "publishedOn": "2021-07-21T02:01:36.385Z",
          "wordCount": 611,
          "title": "How Does Cell-Free Massive MIMO Support Multiple Federated Learning Groups?. (arXiv:2107.09577v1 [cs.IT])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09502",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_B/0/1/0/all/0/1\">Bo Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1\">Yuefeng Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1\">Jiabao Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1\">Peng Liu</a>",
          "description": "Deep neural networks (DNNs) are under threat from adversarial example\nattacks. The adversary can easily change the outputs of DNNs by adding small\nwell-designed perturbations to inputs. Adversarial example detection is a\nfundamental work for robust DNNs-based service. Adversarial examples show the\ndifference between humans and DNNs in image recognition. From a human-centric\nperspective, image features could be divided into dominant features that are\ncomprehensible to humans, and recessive features that are incomprehensible to\nhumans, yet are exploited by DNNs. In this paper, we reveal that imperceptible\nadversarial examples are the product of recessive features misleading neural\nnetworks, and an adversarial attack is essentially a kind of method to enrich\nthese recessive features in the image. The imperceptibility of the adversarial\nexamples indicates that the perturbations enrich recessive features, yet hardly\naffect dominant features. Therefore, adversarial examples are sensitive to\nfiltering off recessive features, while benign examples are immune to such\noperation. Inspired by this idea, we propose a label-only adversarial detection\napproach that is referred to as feature-filter. Feature-filter utilizes\ndiscrete cosine transform to approximately separate recessive features from\ndominant features, and gets a mutant image that is filtered off recessive\nfeatures. By only comparing DNN's prediction labels on the input and its\nmutant, feature-filter can real-time detect imperceptible adversarial examples\nat high accuracy and few false positives.",
          "link": "http://arxiv.org/abs/2107.09502",
          "publishedOn": "2021-07-21T02:01:36.368Z",
          "wordCount": 653,
          "title": "Feature-Filter: Detecting Adversarial Examples through Filtering off Recessive Features. (arXiv:2107.09502v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2103.09957",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_E/0/1/0/all/0/1\">Emma Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_A/0/1/0/all/0/1\">Andy Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krishnan_R/0/1/0/all/0/1\">Rayan Krishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_J/0/1/0/all/0/1\">Jin Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ng_A/0/1/0/all/0/1\">Andrew Y. Ng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajpurkar_P/0/1/0/all/0/1\">Pranav Rajpurkar</a>",
          "description": "A major obstacle to the integration of deep learning models for chest x-ray\ninterpretation into clinical settings is the lack of understanding of their\nfailure modes. In this work, we first investigate whether there are patient\nsubgroups that chest x-ray models are likely to misclassify. We find that\npatient age and the radiographic finding of lung lesion, pneumothorax or\nsupport devices are statistically relevant features for predicting\nmisclassification for some chest x-ray models. Second, we develop\nmisclassification predictors on chest x-ray models using their outputs and\nclinical features. We find that our best performing misclassification\nidentifier achieves an AUROC close to 0.9 for most diseases. Third, employing\nour misclassification identifiers, we develop a corrective algorithm to\nselectively flip model predictions that have high likelihood of\nmisclassification at inference time. We observe F1 improvement on the\nprediction of Consolidation (0.008 [95% CI 0.005, 0.010]) and Edema (0.003,\n[95% CI 0.001, 0.006]). By carrying out our investigation on ten distinct and\nhigh-performing chest x-ray models, we are able to derive insights across model\narchitectures and offer a generalizable framework applicable to other medical\nimaging tasks.",
          "link": "http://arxiv.org/abs/2103.09957",
          "publishedOn": "2021-07-21T02:01:36.362Z",
          "wordCount": 697,
          "title": "CheXbreak: Misclassification Identification for Deep Learning Models Interpreting Chest X-rays. (arXiv:2103.09957v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.09362",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ito_H/0/1/0/all/0/1\">Hiroki Ito</a>, <a href=\"http://arxiv.org/find/eess/1/au:+AprilPyone_M/0/1/0/all/0/1\">MaungMaung AprilPyone</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kiya_H/0/1/0/all/0/1\">Hitoshi Kiya</a>",
          "description": "Since production-level trained deep neural networks (DNNs) are of a great\nbusiness value, protecting such DNN models against copyright infringement and\nunauthorized access is in a rising demand. However, conventional model\nprotection methods focused only the image classification task, and these\nprotection methods were never applied to semantic segmentation although it has\nan increasing number of applications. In this paper, we propose to protect\nsemantic segmentation models from unauthorized access by utilizing block-wise\ntransformation with a secret key for the first time. Protected models are\ntrained by using transformed images. Experiment results show that the proposed\nprotection method allows rightful users with the correct key to access the\nmodel to full capacity and deteriorate the performance for unauthorized users.\nHowever, protected models slightly drop the segmentation performance compared\nto non-protected models.",
          "link": "http://arxiv.org/abs/2107.09362",
          "publishedOn": "2021-07-21T02:01:36.354Z",
          "wordCount": 606,
          "title": "Protecting Semantic Segmentation Models by Using Block-wise Image Encryption with Secret Key from Unauthorized Access. (arXiv:2107.09362v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09130",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yasaei_R/0/1/0/all/0/1\">Rozhin Yasaei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1\">Shih-Yuan Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naeini_E/0/1/0/all/0/1\">Emad Kasaeyan Naeini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faruque_M/0/1/0/all/0/1\">Mohammad Abdullah Al Faruque</a>",
          "description": "Aggressive time-to-market constraints and enormous hardware design and\nfabrication costs have pushed the semiconductor industry toward hardware\nIntellectual Properties (IP) core design. However, the globalization of the\nintegrated circuits (IC) supply chain exposes IP providers to theft and illegal\nredistribution of IPs. Watermarking and fingerprinting are proposed to detect\nIP piracy. Nevertheless, they come with additional hardware overhead and cannot\nguarantee IP security as advanced attacks are reported to remove the watermark,\nforge, or bypass it. In this work, we propose a novel methodology, GNN4IP, to\nassess similarities between circuits and detect IP piracy. We model the\nhardware design as a graph and construct a graph neural network model to learn\nits behavior using the comprehensive dataset of register transfer level codes\nand gate-level netlists that we have gathered. GNN4IP detects IP piracy with\n96% accuracy in our dataset and recognizes the original IP in its obfuscated\nversion with 100% accuracy.",
          "link": "http://arxiv.org/abs/2107.09130",
          "publishedOn": "2021-07-21T02:01:36.345Z",
          "wordCount": 594,
          "title": "GNN4IP: Graph Neural Network for Hardware Intellectual Property Piracy Detection. (arXiv:2107.09130v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09510",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Yu_H/0/1/0/all/0/1\">Han Yu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Vaessen_T/0/1/0/all/0/1\">Thomas Vaessen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Myin_Germeys_I/0/1/0/all/0/1\">Inez Myin-Germeys</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sano_A/0/1/0/all/0/1\">Akane Sano</a>",
          "description": "Multimodal wearable physiological data in daily life settings have been used\nto estimate self-reported stress labels.However, missing data modalities in\ndata collection make it challenging to leverage all the collected samples.\nBesides, heterogeneous sensor data and labels among individuals add challenges\nin building robust stress detection models. In this paper, we proposed a\nmodality fusion network (MFN) to train models and infer self-reported binary\nstress labels under both complete and incomplete modality condition. In\naddition, we applied a personalized attention (PA) strategy to leverage\npersonalized representation along with the generalized one-size-fits-all model.\nWe evaluated our methods on a multimodal wearable sensor dataset (N=41)\nincluding galvanic skin response (GSR) and electrocardiogram (ECG). Compared to\nthe baseline method using the samples with complete modalities, the performance\nof the MFN improved by 1.6\\% in f1-scores. On the other hand, the proposed PA\nstrategy showed a 2.3\\% higher stress detection f1-score and approximately up\nto 70\\% reduction in personalized model parameter size (9.1 MB) compared to the\nprevious state-of-the-art transfer learning strategy (29.3 MB).",
          "link": "http://arxiv.org/abs/2107.09510",
          "publishedOn": "2021-07-21T02:01:36.339Z",
          "wordCount": 618,
          "title": "Modality Fusion Network and Personalized Attention in Momentary Stress Detection in the Wild. (arXiv:2107.09510v1 [eess.SP])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09414",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tornede_A/0/1/0/all/0/1\">Alexander Tornede</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gehring_L/0/1/0/all/0/1\">Lukas Gehring</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tornede_T/0/1/0/all/0/1\">Tanja Tornede</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wever_M/0/1/0/all/0/1\">Marcel Wever</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hullermeier_E/0/1/0/all/0/1\">Eyke H&#xfc;llermeier</a>",
          "description": "The problem of selecting an algorithm that appears most suitable for a\nspecific instance of an algorithmic problem class, such as the Boolean\nsatisfiability problem, is called instance-specific algorithm selection. Over\nthe past decade, the problem has received considerable attention, resulting in\na number of different methods for algorithm selection. Although most of these\nmethods are based on machine learning, surprisingly little work has been done\non meta learning, that is, on taking advantage of the complementarity of\nexisting algorithm selection methods in order to combine them into a single\nsuperior algorithm selector. In this paper, we introduce the problem of meta\nalgorithm selection, which essentially asks for the best way to combine a given\nset of algorithm selectors. We present a general methodological framework for\nmeta algorithm selection as well as several concrete learning methods as\ninstantiations of this framework, essentially combining ideas of meta learning\nand ensemble learning. In an extensive experimental evaluation, we demonstrate\nthat ensembles of algorithm selectors can significantly outperform single\nalgorithm selectors and have the potential to form the new state of the art in\nalgorithm selection.",
          "link": "http://arxiv.org/abs/2107.09414",
          "publishedOn": "2021-07-21T02:01:36.271Z",
          "wordCount": 624,
          "title": "Algorithm Selection on a Meta Level. (arXiv:2107.09414v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09321",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1\">Siqi Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Weilong Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xianliang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suo_H/0/1/0/all/0/1\">Hongbin Suo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jinwei Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1\">Zhijie Yan</a>",
          "description": "In this paper we describe a speaker diarization system that enables\nlocalization and identification of all speakers present in a conversation or\nmeeting. We propose a novel systematic approach to tackle several long-standing\nchallenges in speaker diarization tasks: (1) to segment and separate\noverlapping speech from two speakers; (2) to estimate the number of speakers\nwhen participants may enter or leave the conversation at any time; (3) to\nprovide accurate speaker identification on short text-independent utterances;\n(4) to track down speakers movement during the conversation; (5) to detect\nspeaker change incidence real-time. First, a differential directional\nmicrophone array-based approach is exploited to capture the target speakers'\nvoice in far-field adverse environment. Second, an online speaker-location\njoint clustering approach is proposed to keep track of speaker location. Third,\nan instant speaker number detector is developed to trigger the mechanism that\nseparates overlapped speech. The results suggest that our system effectively\nincorporates spatial information and achieves significant gains.",
          "link": "http://arxiv.org/abs/2107.09321",
          "publishedOn": "2021-07-21T02:01:36.264Z",
          "wordCount": 619,
          "title": "A Real-time Speaker Diarization System Based on Spatial Spectrum. (arXiv:2107.09321v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09099",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1\">Qiushi Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ko_T/0/1/0/all/0/1\">Tom Ko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1\">H Lilian Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xubo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1\">Bo Wu</a>",
          "description": "Punctuation is critical in understanding natural language text. Currently,\nmost automatic speech recognition (ASR) systems do not generate punctuation,\nwhich affects the performance of downstream tasks, such as intent detection and\nslot filling. This gives rise to the need for punctuation restoration. Recent\nwork in punctuation restoration heavily utilizes pre-trained language models\nwithout considering data imbalance when predicting punctuation classes. In this\nwork, we address this problem by proposing a token-level supervised contrastive\nlearning method that aims at maximizing the distance of representation of\ndifferent punctuation marks in the embedding space. The result shows that\ntraining with token-level supervised contrastive learning obtains up to 3.2%\nabsolute F1 improvement on the test set.",
          "link": "http://arxiv.org/abs/2107.09099",
          "publishedOn": "2021-07-21T02:01:36.257Z",
          "wordCount": 554,
          "title": "Token-Level Supervised Contrastive Learning for Punctuation Restoration. (arXiv:2107.09099v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09145",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ha_W/0/1/0/all/0/1\">Wooseok Ha</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Singh_C/0/1/0/all/0/1\">Chandan Singh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lanusse_F/0/1/0/all/0/1\">Francois Lanusse</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Song_E/0/1/0/all/0/1\">Eli Song</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dang_S/0/1/0/all/0/1\">Song Dang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+He_K/0/1/0/all/0/1\">Kangmin He</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Upadhyayula_S/0/1/0/all/0/1\">Srigokul Upadhyayula</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yu_B/0/1/0/all/0/1\">Bin Yu</a>",
          "description": "Recent deep-learning models have achieved impressive prediction performance,\nbut often sacrifice interpretability and computational efficiency.\nInterpretability is crucial in many disciplines, such as science and medicine,\nwhere models must be carefully vetted or where interpretation is the goal\nitself. Moreover, interpretable models are concise and often yield\ncomputational efficiency. Here, we propose adaptive wavelet distillation (AWD),\na method which aims to distill information from a trained neural network into a\nwavelet transform. Specifically, AWD penalizes feature attributions of a neural\nnetwork in the wavelet domain to learn an effective multi-resolution wavelet\ntransform. The resulting model is highly predictive, concise, computationally\nefficient, and has properties (such as a multi-scale structure) which make it\neasy to interpret. In close collaboration with domain experts, we showcase how\nAWD addresses challenges in two real-world settings: cosmological parameter\ninference and molecular-partner prediction. In both cases, AWD yields a\nscientifically interpretable and concise model which gives predictive\nperformance better than state-of-the-art neural networks. Moreover, AWD\nidentifies predictive features that are scientifically meaningful in the\ncontext of respective domains. All code and models are released in a\nfull-fledged package available on Github\n(https://github.com/Yu-Group/adaptive-wavelets).",
          "link": "http://arxiv.org/abs/2107.09145",
          "publishedOn": "2021-07-21T02:01:36.204Z",
          "wordCount": 630,
          "title": "Adaptive wavelet distillation from neural networks through interpretations. (arXiv:2107.09145v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09095",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pikoulis_E/0/1/0/all/0/1\">Erion-Vasilis Pikoulis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mavrokefalidis_C/0/1/0/all/0/1\">Christos Mavrokefalidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lalos_A/0/1/0/all/0/1\">Aris S. Lalos</a>",
          "description": "Deep learning and especially the use of Deep Neural Networks (DNNs) provides\nimpressive results in various regression and classification tasks. However, to\nachieve these results, there is a high demand for computing and storing\nresources. This becomes problematic when, for instance, real-time, mobile\napplications are considered, in which the involved (embedded) devices have\nlimited resources. A common way of addressing this problem is to transform the\noriginal large pre-trained networks into new smaller models, by utilizing Model\nCompression and Acceleration (MCA) techniques. Within the MCA framework, we\npropose a clustering-based approach that is able to increase the number of\nemployed centroids/representatives, while at the same time, have an\nacceleration gain compared to conventional, $k$-means based approaches. This is\nachieved by imposing a special structure to the employed representatives, which\nis enabled by the particularities of the problem at hand. Moreover, the\ntheoretical acceleration gains are presented and the key system\nhyper-parameters that affect that gain, are identified. Extensive evaluation\nstudies carried out using various state-of-the-art DNN models trained in image\nclassification, validate the superiority of the proposed method as compared for\nits use in MCA tasks.",
          "link": "http://arxiv.org/abs/2107.09095",
          "publishedOn": "2021-07-21T02:01:36.197Z",
          "wordCount": 623,
          "title": "A New Clustering-Based Technique for the Acceleration of Deep Convolutional Networks. (arXiv:2107.09095v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09545",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ayoub_J/0/1/0/all/0/1\">Jackie Ayoub</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_N/0/1/0/all/0/1\">Na Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">X. Jessie Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_F/0/1/0/all/0/1\">Feng Zhou</a>",
          "description": "It is extremely important to ensure a safe takeover transition in\nconditionally automated driving. One of the critical factors that quantifies\nthe safe takeover transition is takeover time. Previous studies identified the\neffects of many factors on takeover time, such as takeover lead time,\nnon-driving tasks, modalities of the takeover requests (TORs), and scenario\nurgency. However, there is a lack of research to predict takeover time by\nconsidering these factors all at the same time. Toward this end, we used\neXtreme Gradient Boosting (XGBoost) to predict the takeover time using a\ndataset from a meta-analysis study [1]. In addition, we used SHAP (SHapley\nAdditive exPlanation) to analyze and explain the effects of the predictors on\ntakeover time. We identified seven most critical predictors that resulted in\nthe best prediction performance. Their main effects and interaction effects on\ntakeover time were examined. The results showed that the proposed approach\nprovided both good performance and explainability. Our findings have\nimplications on the design of in-vehicle monitoring and alert systems to\nfacilitate the interaction between the drivers and the automated vehicle.",
          "link": "http://arxiv.org/abs/2107.09545",
          "publishedOn": "2021-07-21T02:01:36.176Z",
          "wordCount": 615,
          "title": "Predicting Driver Takeover Time in Conditionally Automated Driving. (arXiv:2107.09545v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09204",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wilmet_V/0/1/0/all/0/1\">Vincent Wilmet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verma_S/0/1/0/all/0/1\">Sauraj Verma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Redl_T/0/1/0/all/0/1\">Tabea Redl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sandaker_H/0/1/0/all/0/1\">H&#xe5;kon Sandaker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhenning Li</a>",
          "description": "Anomaly detection in images plays a significant role for many applications\nacross all industries, such as disease diagnosis in healthcare or quality\nassurance in manufacturing. Manual inspection of images, when extended over a\nmonotonously repetitive period of time is very time consuming and can lead to\nanomalies being overlooked.Artificial neural networks have proven themselves\nvery successful on simple, repetitive tasks, in some cases even outperforming\nhumans. Therefore, in this paper we investigate different methods of deep\nlearning, including supervised and unsupervised learning, for anomaly detection\napplied to a quality assurance use case. We utilize the MVTec anomaly dataset\nand develop three different models, a CNN for supervised anomaly detection,\nKD-CAE for autoencoder anomaly detection, NI-CAE for noise induced anomaly\ndetection and a DCGAN for generating reconstructed images. By experiments, we\nfound that KD-CAE performs better on the anomaly datasets compared to CNN and\nNI-CAE, with NI-CAE performing the best on the Transistor dataset. We also\nimplemented a DCGAN for the creation of new training data but due to\ncomputational limitation and lack of extrapolating the mechanics of AnoGAN, we\nrestricted ourselves just to the generation of GAN based images. We conclude\nthat unsupervised methods are more powerful for anomaly detection in images,\nespecially in a setting where only a small amount of anomalous data is\navailable, or the data is unlabeled.",
          "link": "http://arxiv.org/abs/2107.09204",
          "publishedOn": "2021-07-21T02:01:36.145Z",
          "wordCount": 686,
          "title": "A Comparison of Supervised and Unsupervised Deep Learning Methods for Anomaly Detection in Images. (arXiv:2107.09204v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09507",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Cui_J/0/1/0/all/0/1\">Jian Cui</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_Y/0/1/0/all/0/1\">Yisi Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lan_Z/0/1/0/all/0/1\">Zirui Lan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sourina_O/0/1/0/all/0/1\">Olga Sourina</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Muller_Wittig_W/0/1/0/all/0/1\">Wolfgang M&#xfc;ller-Wittig</a>",
          "description": "In the context of electroencephalogram (EEG)-based driver drowsiness\nrecognition, it is still a challenging task to design a calibration-free\nsystem, since there exists a significant variability of EEG signals among\ndifferent subjects and recording sessions. As deep learning has received much\nresearch attention in recent years, many efforts have been made to use deep\nlearning methods for EEG signal recognition. However, existing works mostly\ntreat deep learning models as blackbox classifiers, while what have been\nlearned by the models and to which extent they are affected by the noise from\nEEG data are still underexplored. In this paper, we develop a novel\nconvolutional neural network that can explain its decision by highlighting the\nlocal areas of the input sample that contain important information for the\nclassification. The network has a compact structure for ease of interpretation\nand takes advantage of separable convolutions to process the EEG signals in a\nspatial-temporal sequence. Results show that the model achieves an average\naccuracy of 78.35% on 11 subjects for leave-one-out cross-subject drowsiness\nrecognition, which is higher than the conventional baseline methods of\n53.4%-72.68% and state-of-art deep learning methods of 63.90%-65.61%.\nVisualization results show that the model has learned to recognize biologically\nexplainable features from EEG signals, e.g., Alpha spindles, as strong\nindicators of drowsiness across different subjects. In addition, we also\nexplore reasons behind some wrongly classified samples and how the model is\naffected by artifacts and noise in the data. Our work illustrates a promising\ndirection on using interpretable deep learning models to discover meaning\npatterns related to different mental states from complex EEG signals.",
          "link": "http://arxiv.org/abs/2107.09507",
          "publishedOn": "2021-07-21T02:01:36.039Z",
          "wordCount": 713,
          "title": "EEG-based Cross-Subject Driver Drowsiness Recognition with Interpretable CNN. (arXiv:2107.09507v1 [eess.SP])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09518",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zehong Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Ying-Jun Angela Zhang</a>",
          "description": "Federated learning (FL) has recently emerged as a promising technology to\nenable artificial intelligence (AI) at the network edge, where distributed\nmobile devices collaboratively train a shared AI model under the coordination\nof an edge server. To significantly improve the communication efficiency of FL,\nover-the-air computation allows a large number of mobile devices to\nconcurrently upload their local models by exploiting the superposition property\nof wireless multi-access channels. Due to wireless channel fading, the model\naggregation error at the edge server is dominated by the weakest channel among\nall devices, causing severe straggler issues. In this paper, we propose a\nrelay-assisted cooperative FL scheme to effectively address the straggler\nissue. In particular, we deploy multiple half-duplex relays to cooperatively\nassist the devices in uploading the local model updates to the edge server. The\nnature of the over-the-air computation poses system objectives and constraints\nthat are distinct from those in traditional relay communication systems.\nMoreover, the strong coupling between the design variables renders the\noptimization of such a system challenging. To tackle the issue, we propose an\nalternating-optimization-based algorithm to optimize the transceiver and relay\noperation with low complexity. Then, we analyze the model aggregation error in\na single-relay case and show that our relay-assisted scheme achieves a smaller\nerror than the one without relays provided that the relay transmit power and\nthe relay channel gains are sufficiently large. The analysis provides critical\ninsights on relay deployment in the implementation of cooperative FL. Extensive\nnumerical results show that our design achieves faster convergence compared\nwith state-of-the-art schemes.",
          "link": "http://arxiv.org/abs/2107.09518",
          "publishedOn": "2021-07-21T02:01:36.023Z",
          "wordCount": 721,
          "title": "Relay-Assisted Cooperative Federated Learning. (arXiv:2107.09518v1 [cs.IT])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09509",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Nath_R/0/1/0/all/0/1\">Rajdeep Kumar Nath</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Thapliyal_H/0/1/0/all/0/1\">Himanshu Thapliyal</a>",
          "description": "The advent of IoT has enabled the design of connected and integrated smart\nhealth monitoring systems. These smart health monitoring systems could be\nrealized in a smart home context to render long-term care to the elderly\npopulation. In this paper, we present the design of a wearable health\nmonitoring system suitable for older adults in a smart home context. The\nproposed system offers solutions to monitor the stress, blood pressure, and\nlocation of an individual within a smart home environment. The stress detection\nmodel proposed in this work uses Electrodermal Activity (EDA),\nPhotoplethysmogram (PPG), and Skin Temperature (ST) sensors embedded in a smart\nwristband for detecting physiological stress. The stress detection model is\ntrained and tested using stress labels obtained from salivary cortisol which is\na clinically established biomarker for physiological stress. A voice-based\nprototype is also implemented and the feasibility of the proposed system for\nintegration in a smart home environment is analyzed by simulating a data\nacquisition and streaming scenario. We have also proposed a blood pressure\nestimation model using PPG signal and advanced regression techniques for\nintegration with the stress detection model in the wearable health monitoring\nsystem. Finally, the design of a voice-assisted indoor location system is\nproposed for integration with the proposed system within a smart home\nenvironment. The proposed wearable health monitoring system is an important\ndirection to realize a smart home environment with extensive diagnostic\ncapabilities so that such a system could be useful for rendering long-term and\npersonalized care to the aging population in the comfort of their home.",
          "link": "http://arxiv.org/abs/2107.09509",
          "publishedOn": "2021-07-21T02:01:36.014Z",
          "wordCount": 719,
          "title": "Wearable Health Monitoring System for Older Adults in a Smart Home Environment. (arXiv:2107.09509v1 [eess.SP])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09648",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Michaelov_J/0/1/0/all/0/1\">James A. Michaelov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bardolph_M/0/1/0/all/0/1\">Megan D. Bardolph</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Coulson_S/0/1/0/all/0/1\">Seana Coulson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bergen_B/0/1/0/all/0/1\">Benjamin K. Bergen</a>",
          "description": "Despite being designed for performance rather than cognitive plausibility,\ntransformer language models have been found to be better at predicting metrics\nused to assess human language comprehension than language models with other\narchitectures, such as recurrent neural networks. Based on how well they\npredict the N400, a neural signal associated with processing difficulty, we\npropose and provide evidence for one possible explanation - their predictions\nare affected by the preceding context in a way analogous to the effect of\nsemantic facilitation in humans.",
          "link": "http://arxiv.org/abs/2107.09648",
          "publishedOn": "2021-07-21T02:01:35.987Z",
          "wordCount": 554,
          "title": "Different kinds of cognitive plausibility: why are transformers better than RNNs at predicting N400 amplitude?. (arXiv:2107.09648v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09661",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Merchant_A/0/1/0/all/0/1\">Amil Merchant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Metz_L/0/1/0/all/0/1\">Luke Metz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schoenholz_S/0/1/0/all/0/1\">Sam Schoenholz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cubuk_E/0/1/0/all/0/1\">Ekin Dogus Cubuk</a>",
          "description": "Optimization of non-convex loss surfaces containing many local minima remains\na critical problem in a variety of domains, including operations research,\ninformatics, and material design. Yet, current techniques either require\nextremely high iteration counts or a large number of random restarts for good\nperformance. In this work, we propose adapting recent developments in\nmeta-learning to these many-minima problems by learning the optimization\nalgorithm for various loss landscapes. We focus on problems from atomic\nstructural optimization--finding low energy configurations of many-atom\nsystems--including widely studied models such as bimetallic clusters and\ndisordered silicon. We find that our optimizer learns a 'hopping' behavior\nwhich enables efficient exploration and improves the rate of low energy minima\ndiscovery. Finally, our learned optimizers show promising generalization with\nefficiency gains on never before seen tasks (e.g. new elements or\ncompositions). Code will be made available shortly.",
          "link": "http://arxiv.org/abs/2107.09661",
          "publishedOn": "2021-07-21T02:01:35.981Z",
          "wordCount": 574,
          "title": "Learn2Hop: Learned Optimization on Rough Landscapes. (arXiv:2107.09661v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09282",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_M/0/1/0/all/0/1\">Mingkai Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_S/0/1/0/all/0/1\">Shan You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Fei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_C/0/1/0/all/0/1\">Chen Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Changshui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaogang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chang Xu</a>",
          "description": "Self-supervised Learning (SSL) including the mainstream contrastive learning\nhas achieved great success in learning visual representations without data\nannotations. However, most of methods mainly focus on the instance level\ninformation (\\ie, the different augmented images of the same instance should\nhave the same feature or cluster into the same class), but there is a lack of\nattention on the relationships between different instances. In this paper, we\nintroduced a novel SSL paradigm, which we term as relational self-supervised\nlearning (ReSSL) framework that learns representations by modeling the\nrelationship between different instances. Specifically, our proposed method\nemploys sharpened distribution of pairwise similarities among different\ninstances as \\textit{relation} metric, which is thus utilized to match the\nfeature embeddings of different augmentations. Moreover, to boost the\nperformance, we argue that weak augmentations matter to represent a more\nreliable relation, and leverage momentum strategy for practical efficiency.\nExperimental results show that our proposed ReSSL significantly outperforms the\nprevious state-of-the-art algorithms in terms of both performance and training\nefficiency. Code is available at \\url{https://github.com/KyleZheng1997/ReSSL}.",
          "link": "http://arxiv.org/abs/2107.09282",
          "publishedOn": "2021-07-21T02:01:35.973Z",
          "wordCount": 615,
          "title": "ReSSL: Relational Self-Supervised Learning with Weak Augmentation. (arXiv:2107.09282v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09437",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_L/0/1/0/all/0/1\">Ling Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1\">Kan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_C/0/1/0/all/0/1\">Choy Heng Lai</a>",
          "description": "The success of deep neural networks in real-world problems has prompted many\nattempts to explain their training dynamics and generalization performance, but\nmore guiding principles for the training of neural networks are still needed.\nMotivated by the edge of chaos principle behind the optimal performance of\nneural networks, we study the role of various hyperparameters in modern neural\nnetwork training algorithms in terms of the order-chaos phase diagram. In\nparticular, we study a fully analytical feedforward neural network trained on\nthe widely adopted Fashion-MNIST dataset, and study the dynamics associated\nwith the hyperparameters in back-propagation during the training process. We\nfind that for the basic algorithm of stochastic gradient descent with momentum,\nin the range around the commonly used hyperparameter values, clear scaling\nrelations are present with respect to the training time during the ordered\nphase in the phase diagram, and the model's optimal generalization power at the\nedge of chaos is similar across different training parameter combinations. In\nthe chaotic phase, the same scaling no longer exists. The scaling allows us to\nchoose the training parameters to achieve faster training without sacrificing\nperformance. In addition, we find that the commonly used model regularization\nmethod - weight decay - effectively pushes the model towards the ordered phase\nto achieve better performance. Leveraging on this fact and the scaling\nrelations in the other hyperparameters, we derived a principled guideline for\nhyperparameter determination, such that the model can achieve optimal\nperformance by saturating it at the edge of chaos. Demonstrated on this simple\nneural network model and training algorithm, our work improves the\nunderstanding of neural network training dynamics, and can potentially be\nextended to guiding principles of more complex model architectures and\nalgorithms.",
          "link": "http://arxiv.org/abs/2107.09437",
          "publishedOn": "2021-07-21T02:01:35.966Z",
          "wordCount": 740,
          "title": "Edge of chaos as a guiding principle for modern neural network training. (arXiv:2107.09437v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09240",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yi-Fu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_J/0/1/0/all/0/1\">Jaesik Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahn_S/0/1/0/all/0/1\">Sungjin Ahn</a>",
          "description": "Transformers have been successful for many natural language processing tasks.\nHowever, applying transformers to the video domain for tasks such as long-term\nvideo generation and scene understanding has remained elusive due to the high\ncomputational complexity and the lack of natural tokenization. In this paper,\nwe propose the Object-Centric Video Transformer (OCVT) which utilizes an\nobject-centric approach for decomposing scenes into tokens suitable for use in\na generative video transformer. By factoring the video into objects, our fully\nunsupervised model is able to learn complex spatio-temporal dynamics of\nmultiple interacting objects in a scene and generate future frames of the\nvideo. Our model is also significantly more memory-efficient than pixel-based\nmodels and thus able to train on videos of length up to 70 frames with a single\n48GB GPU. We compare our model with previous RNN-based approaches as well as\nother possible video transformer baselines. We demonstrate OCVT performs well\nwhen compared to baselines in generating future frames. OCVT also develops\nuseful representations for video reasoning, achieving start-of-the-art\nperformance on the CATER task.",
          "link": "http://arxiv.org/abs/2107.09240",
          "publishedOn": "2021-07-21T02:01:35.947Z",
          "wordCount": 618,
          "title": "Generative Video Transformer: Can Objects be the Words?. (arXiv:2107.09240v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09224",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Xiuyuan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Osband_I/0/1/0/all/0/1\">Ian Osband</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_B/0/1/0/all/0/1\">Benjamin Van Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_Z/0/1/0/all/0/1\">Zheng Wen</a>",
          "description": "A fundamental challenge for any intelligent system is prediction: given some\ninputs $X_1,..,X_\\tau$ can you predict outcomes $Y_1,.., Y_\\tau$. The KL\ndivergence $\\mathbf{d}_{\\mathrm{KL}}$ provides a natural measure of prediction\nquality, but the majority of deep learning research looks only at the marginal\npredictions per input $X_t$. In this technical report we propose a scoring rule\n$\\mathbf{d}_{\\mathrm{KL}}^\\tau$, parameterized by $\\tau \\in \\mathcal{N}$ that\nevaluates the joint predictions at $\\tau$ inputs simultaneously. We show that\nthe commonly-used $\\tau=1$ can be insufficient to drive good decisions in many\nsettings of interest. We also show that, as $\\tau$ grows, performing well\naccording to $\\mathbf{d}_{\\mathrm{KL}}^\\tau$ recovers universal guarantees for\nany possible decision. Finally, we provide problem-dependent guidance on the\nscale of $\\tau$ for which our score provides sufficient guarantees for good\nperformance.",
          "link": "http://arxiv.org/abs/2107.09224",
          "publishedOn": "2021-07-21T02:01:35.941Z",
          "wordCount": 566,
          "title": "Evaluating Probabilistic Inference in Deep Learning: Beyond Marginal Predictions. (arXiv:2107.09224v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09402",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Safiuddin_M/0/1/0/all/0/1\">Mohammad Safiuddin</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Reddy_C/0/1/0/all/0/1\">CH Likith Reddy</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Vasantada_G/0/1/0/all/0/1\">Ganesh Vasantada</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Harsha_C/0/1/0/all/0/1\">CHJNS Harsha</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Gangolu_S/0/1/0/all/0/1\">Srinu Gangolu</a>",
          "description": "The microstructure of material strongly influences its mechanical properties\nand the microstructure itself is influenced by the processing conditions. Thus,\nestablishing a Process-Structure-Property relationship is a crucial task in\nmaterial design and is of interest in many engineering applications. We develop\na GAN (Generative Adversarial Network) to synthesize microstructures based on\ngiven processing conditions. This approach is devoid of feature engineering,\nneeds little domain awareness, and can be applied to a wide variety of material\nsystems. Results show that our GAN model can produce high-fidelity multi-phase\nmicrostructures which have a good correlation with the given processing\nconditions.",
          "link": "http://arxiv.org/abs/2107.09402",
          "publishedOn": "2021-07-21T02:01:35.934Z",
          "wordCount": 537,
          "title": "Establishing process-structure linkages using Generative Adversarial Networks. (arXiv:2107.09402v1 [cond-mat.mtrl-sci])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09301",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Mourdoukoutas_N/0/1/0/all/0/1\">Nikolaos Mourdoukoutas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Federici_M/0/1/0/all/0/1\">Marco Federici</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pantalos_G/0/1/0/all/0/1\">Georges Pantalos</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wilk_M/0/1/0/all/0/1\">Mark van der Wilk</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fortuin_V/0/1/0/all/0/1\">Vincent Fortuin</a>",
          "description": "We propose a novel Bayesian neural network architecture that can learn\ninvariances from data alone by inferring a posterior distribution over\ndifferent weight-sharing schemes. We show that our model outperforms other\nnon-invariant architectures, when trained on datasets that contain specific\ninvariances. The same holds true when no data augmentation is performed.",
          "link": "http://arxiv.org/abs/2107.09301",
          "publishedOn": "2021-07-21T02:01:35.929Z",
          "wordCount": 501,
          "title": "A Bayesian Approach to Invariant Deep Neural Networks. (arXiv:2107.09301v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09392",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Hu_C/0/1/0/all/0/1\">Cheng-Hung Hu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Peng_Y/0/1/0/all/0/1\">Yu-Huai Peng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yamagishi_J/0/1/0/all/0/1\">Junichi Yamagishi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tsao_Y/0/1/0/all/0/1\">Yu Tsao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_H/0/1/0/all/0/1\">Hsin-Min Wang</a>",
          "description": "Neural evaluation metrics derived for numerous speech generation tasks have\nrecently attracted great attention. In this paper, we propose SVSNet, the first\nend-to-end neural network model to assess the speaker voice similarity between\nnatural speech and synthesized speech. Unlike most neural evaluation metrics\nthat use hand-crafted features, SVSNet directly takes the raw waveform as input\nto more completely utilize speech information for prediction. SVSNet consists\nof encoder, co-attention, distance calculation, and prediction modules and is\ntrained in an end-to-end manner. The experimental results on the Voice\nConversion Challenge 2018 and 2020 (VCC2018 and VCC2020) datasets show that\nSVSNet notably outperforms well-known baseline systems in the assessment of\nspeaker similarity at the utterance and system levels.",
          "link": "http://arxiv.org/abs/2107.09392",
          "publishedOn": "2021-07-21T02:01:35.922Z",
          "wordCount": 589,
          "title": "SVSNet: An End-to-end Speaker Voice Similarity Assessment Model. (arXiv:2107.09392v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09461",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhize Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Richtarik_P/0/1/0/all/0/1\">Peter Richt&#xe1;rik</a>",
          "description": "Due to the high communication cost in distributed and federated learning,\nmethods relying on compressed communication are becoming increasingly popular.\nBesides, the best theoretically and practically performing gradient-type\nmethods invariably rely on some form of acceleration/momentum to reduce the\nnumber of communications (faster convergence), e.g., Nesterov's accelerated\ngradient descent (Nesterov, 2004) and Adam (Kingma and Ba, 2014). In order to\ncombine the benefits of communication compression and convergence acceleration,\nwe propose a \\emph{compressed and accelerated} gradient method for distributed\noptimization, which we call CANITA. Our CANITA achieves the \\emph{first\naccelerated rate}\n$O\\bigg(\\sqrt{\\Big(1+\\sqrt{\\frac{\\omega^3}{n}}\\Big)\\frac{L}{\\epsilon}} +\n\\omega\\big(\\frac{1}{\\epsilon}\\big)^{\\frac{1}{3}}\\bigg)$, which improves upon\nthe state-of-the-art non-accelerated rate\n$O\\left((1+\\frac{\\omega}{n})\\frac{L}{\\epsilon} +\n\\frac{\\omega^2+n}{\\omega+n}\\frac{1}{\\epsilon}\\right)$ of DIANA (Khaled et al.,\n2020b) for distributed general convex problems, where $\\epsilon$ is the target\nerror, $L$ is the smooth parameter of the objective, $n$ is the number of\nmachines/devices, and $\\omega$ is the compression parameter (larger $\\omega$\nmeans more compression can be applied, and no compression implies $\\omega=0$).\nOur results show that as long as the number of devices $n$ is large (often true\nin distributed/federated learning), or the compression $\\omega$ is not very\nhigh, CANITA achieves the faster convergence rate\n$O\\Big(\\sqrt{\\frac{L}{\\epsilon}}\\Big)$, i.e., the number of communication\nrounds is $O\\Big(\\sqrt{\\frac{L}{\\epsilon}}\\Big)$ (vs.\n$O\\big(\\frac{L}{\\epsilon}\\big)$ achieved by previous works). As a result,\nCANITA enjoys the advantages of both compression (compressed communication in\neach round) and acceleration (much fewer communication rounds).",
          "link": "http://arxiv.org/abs/2107.09461",
          "publishedOn": "2021-07-21T02:01:35.903Z",
          "wordCount": 676,
          "title": "CANITA: Faster Rates for Distributed Convex Optimization with Communication Compression. (arXiv:2107.09461v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09408",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Riera_M/0/1/0/all/0/1\">Marc Riera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arnau_J/0/1/0/all/0/1\">Jose-Maria Arnau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_A/0/1/0/all/0/1\">Antonio Gonzalez</a>",
          "description": "Deep Neural Networks (DNNs) have achieved tremendous success for cognitive\napplications. The core operation in a DNN is the dot product between quantized\ninputs and weights. Prior works exploit the weight/input repetition that arises\ndue to quantization to avoid redundant computations in Convolutional Neural\nNetworks (CNNs). However, in this paper we show that their effectiveness is\nseverely limited when applied to Fully-Connected (FC) layers, which are\ncommonly used in state-of-the-art DNNs, as it is the case of modern Recurrent\nNeural Networks (RNNs) and Transformer models.\n\nTo improve energy-efficiency of FC computation we present CREW, a hardware\naccelerator that implements Computation Reuse and an Efficient Weight Storage\nmechanism to exploit the large number of repeated weights in FC layers. CREW\nfirst performs the multiplications of the unique weights by their respective\ninputs and stores the results in an on-chip buffer. The storage requirements\nare modest due to the small number of unique weights and the relatively small\nsize of the input compared to convolutional layers. Next, CREW computes each\noutput by fetching and adding its required products. To this end, each weight\nis replaced offline by an index in the buffer of unique products. Indices are\ntypically smaller than the quantized weights, since the number of unique\nweights for each input tends to be much lower than the range of quantized\nweights, which reduces storage and memory bandwidth requirements.\n\nOverall, CREW greatly reduces the number of multiplications and provides\nsignificant savings in model memory footprint and memory bandwidth usage. We\nevaluate CREW on a diverse set of modern DNNs. On average, CREW provides 2.61x\nspeedup and 2.42x energy savings over a TPU-like accelerator. Compared to UCNN,\na state-of-art computation reuse technique, CREW achieves 2.10x speedup and\n2.08x energy savings on average.",
          "link": "http://arxiv.org/abs/2107.09408",
          "publishedOn": "2021-07-21T02:01:35.897Z",
          "wordCount": 730,
          "title": "CREW: Computation Reuse and Efficient Weight Storage for Hardware-accelerated MLPs and RNNs. (arXiv:2107.09408v1 [cs.AR])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09384",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ostwald_D/0/1/0/all/0/1\">Dirk Ostwald</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Usee_F/0/1/0/all/0/1\">Franziska Us&#xe9;e</a>",
          "description": "Backpropagation (BP) is a core component of the contemporary deep learning\nincarnation of neural networks. Briefly, BP is an algorithm that exploits the\ncomputational architecture of neural networks to efficiently evaluate the\ngradient of a cost function during neural network parameter optimization. The\nvalidity of BP rests on the application of a multivariate chain rule to the\ncomputational architecture of neural networks and their associated objective\nfunctions. Introductions to deep learning theory commonly present the\ncomputational architecture of neural networks in matrix form, but eschew a\nparallel formulation and justification of BP in the framework of matrix\ndifferential calculus. This entails several drawbacks for the theory and\ndidactics of deep learning. In this work, we overcome these limitations by\nproviding a full induction proof of the BP algorithm in matrix notation.\nSpecifically, we situate the BP algorithm in the framework of matrix\ndifferential calculus, encompass affine-linear potential functions, prove the\nvalidity of the BP algorithm in inductive form, and exemplify the\nimplementation of the matrix form BP algorithm in computer code.",
          "link": "http://arxiv.org/abs/2107.09384",
          "publishedOn": "2021-07-21T02:01:35.890Z",
          "wordCount": 616,
          "title": "An induction proof of the backpropagation algorithm in matrix notation. (arXiv:2107.09384v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09483",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Delong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zheqi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Xiaomin Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zewen Li</a>",
          "description": "Computational intelligence-based ocean characteristics forecasting\napplications, such as Significant Wave Height (SWH) prediction, are crucial for\navoiding social and economic loss in coastal cities. Compared to the\ntraditional empirical-based or numerical-based forecasting models, \"soft\ncomputing\" approaches, including machine learning and deep learning models,\nhave shown numerous success in recent years. In this paper, we focus on\nenabling the deep learning model to learn both short-term and long-term\nspatial-temporal dependencies for SWH prediction. A Wavelet Graph Neural\nNetwork (WGNN) approach is proposed to integrate the advantages of wavelet\ntransform and graph neural network. Several parallel graph neural networks are\nseparately trained on wavelet decomposed data, and the reconstruction of each\nmodel's prediction forms the final SWH prediction. Experimental results show\nthat the proposed WGNN approach outperforms other models, including the\nnumerical models, the machine learning models, and several deep learning\nmodels.",
          "link": "http://arxiv.org/abs/2107.09483",
          "publishedOn": "2021-07-21T02:01:35.883Z",
          "wordCount": 596,
          "title": "Significant Wave Height Prediction based on Wavelet Graph Neural Network. (arXiv:2107.09483v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09144",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tetali_H/0/1/0/all/0/1\">Harsha Vardhan Tetali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harley_J/0/1/0/all/0/1\">Joel B. Harley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haeffele_B/0/1/0/all/0/1\">Benjamin D. Haeffele</a>",
          "description": "With the recent success of representation learning methods, which includes\ndeep learning as a special case, there has been considerable interest in\ndeveloping representation learning techniques that can incorporate known\nphysical constraints into the learned representation. As one example, in many\napplications that involve a signal propagating through physical media (e.g.,\noptics, acoustics, fluid dynamics, etc), it is known that the dynamics of the\nsignal must satisfy constraints imposed by the wave equation. Here we propose a\nmatrix factorization technique that decomposes such signals into a sum of\ncomponents, where each component is regularized to ensure that it satisfies\nwave equation constraints. Although our proposed formulation is non-convex, we\nprove that our model can be efficiently solved to global optimality in\npolynomial time. We demonstrate the benefits of our work by applications in\nstructural health monitoring, where prior work has attempted to solve this\nproblem using sparse dictionary learning approaches that do not come with any\ntheoretical guarantees regarding convergence to global optimality and employ\nheuristics to capture desired physical constraints.",
          "link": "http://arxiv.org/abs/2107.09144",
          "publishedOn": "2021-07-21T02:01:35.877Z",
          "wordCount": 599,
          "title": "Wave-Informed Matrix Factorization withGlobal Optimality Guarantees. (arXiv:2107.09144v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09305",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1\">Wenxian Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yuxuan Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Hao Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bohan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>",
          "description": "Deep neural networks often have a huge number of parameters, which posts\nchallenges in deployment in application scenarios with limited memory and\ncomputation capacity. Knowledge distillation is one approach to derive compact\nmodels from bigger ones. However, it has been observed that a converged heavy\nteacher model is strongly constrained for learning a compact student network\nand could make the optimization subject to poor local optima. In this paper, we\npropose ProKT, a new model-agnostic method by projecting the supervision\nsignals of a teacher model into the student's parameter space. Such projection\nis implemented by decomposing the training objective into local intermediate\ntargets with an approximate mirror descent technique. The proposed method could\nbe less sensitive with the quirks during optimization which could result in a\nbetter local optimum. Experiments on both image and text datasets show that our\nproposed ProKT consistently achieves superior performance compared to other\nexisting knowledge distillation methods.",
          "link": "http://arxiv.org/abs/2107.09305",
          "publishedOn": "2021-07-21T02:01:35.858Z",
          "wordCount": 597,
          "title": "Follow Your Path: a Progressive Method for Knowledge Distillation. (arXiv:2107.09305v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09200",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Zlokapa_A/0/1/0/all/0/1\">Alexander Zlokapa</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Neven_H/0/1/0/all/0/1\">Hartmut Neven</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Lloyd_S/0/1/0/all/0/1\">Seth Lloyd</a>",
          "description": "Given the success of deep learning in classical machine learning, quantum\nalgorithms for traditional neural network architectures may provide one of the\nmost promising settings for quantum machine learning. Considering a\nfully-connected feedforward neural network, we show that conditions amenable to\nclassical trainability via gradient descent coincide with those necessary for\nefficiently solving quantum linear systems. We propose a quantum algorithm to\napproximately train a wide and deep neural network up to $O(1/n)$ error for a\ntraining set of size $n$ by performing sparse matrix inversion in $O(\\log n)$\ntime. To achieve an end-to-end exponential speedup over gradient descent, the\ndata distribution must permit efficient state preparation and readout. We\nnumerically demonstrate that the MNIST image dataset satisfies such conditions;\nmoreover, the quantum algorithm matches the accuracy of the fully-connected\nnetwork. Beyond the proven architecture, we provide empirical evidence for\n$O(\\log n)$ training of a convolutional neural network with pooling.",
          "link": "http://arxiv.org/abs/2107.09200",
          "publishedOn": "2021-07-21T02:01:35.851Z",
          "wordCount": 602,
          "title": "A quantum algorithm for training wide and deep classical neural networks. (arXiv:2107.09200v1 [quant-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09194",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Stephenson_W/0/1/0/all/0/1\">William T. Stephenson</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Frangella_Z/0/1/0/all/0/1\">Zachary Frangella</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Udell_M/0/1/0/all/0/1\">Madeleine Udell</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Broderick_T/0/1/0/all/0/1\">Tamara Broderick</a>",
          "description": "Models like LASSO and ridge regression are extensively used in practice due\nto their interpretability, ease of use, and strong theoretical guarantees.\nCross-validation (CV) is widely used for hyperparameter tuning in these models,\nbut do practical optimization methods minimize the true out-of-sample loss? A\nrecent line of research promises to show that the optimum of the CV loss\nmatches the optimum of the out-of-sample loss (possibly after simple\ncorrections). It remains to show how tractable it is to minimize the CV loss.\nIn the present paper, we show that, in the case of ridge regression, the CV\nloss may fail to be quasiconvex and thus may have multiple local optima. We can\nguarantee that the CV loss is quasiconvex in at least one case: when the\nspectrum of the covariate matrix is nearly flat and the noise in the observed\nresponses is not too high. More generally, we show that quasiconvexity status\nis independent of many properties of the observed data (response norm,\ncovariate-matrix right singular vectors and singular-value scaling) and has a\ncomplex dependence on the few that remain. We empirically confirm our theory\nusing simulated experiments.",
          "link": "http://arxiv.org/abs/2107.09194",
          "publishedOn": "2021-07-21T02:01:35.844Z",
          "wordCount": 635,
          "title": "Can we globally optimize cross-validation loss? Quasiconvexity in ridge regression. (arXiv:2107.09194v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09323",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Siblini_W/0/1/0/all/0/1\">Wissam Siblini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Coter_G/0/1/0/all/0/1\">Guillaume Coter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fabry_R/0/1/0/all/0/1\">R&#xe9;my Fabry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Guelton_L/0/1/0/all/0/1\">Liyun He-Guelton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oble_F/0/1/0/all/0/1\">Fr&#xe9;d&#xe9;ric Obl&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lebichot_B/0/1/0/all/0/1\">Bertrand Lebichot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borgne_Y/0/1/0/all/0/1\">Yann-A&#xeb;l Le Borgne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bontempi_G/0/1/0/all/0/1\">Gianluca Bontempi</a>",
          "description": "The dark face of digital commerce generalization is the increase of fraud\nattempts. To prevent any type of attacks, state of the art fraud detection\nsystems are now embedding Machine Learning (ML) modules. The conception of such\nmodules is only communicated at the level of research and papers mostly focus\non results for isolated benchmark datasets and metrics. But research is only a\npart of the journey, preceded by the right formulation of the business problem\nand collection of data, and followed by a practical integration. In this paper,\nwe give a wider vision of the process, on a case study of transfer learning for\nfraud detection, from business to research, and back to business.",
          "link": "http://arxiv.org/abs/2107.09323",
          "publishedOn": "2021-07-21T02:01:35.837Z",
          "wordCount": 568,
          "title": "Transfer Learning for Credit Card Fraud Detection: A Journey from Research to Production. (arXiv:2107.09323v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09088",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Strupl_M/0/1/0/all/0/1\">Miroslav &#x160;trupl</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Faccio_F/0/1/0/all/0/1\">Francesco Faccio</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ashley_D/0/1/0/all/0/1\">Dylan R. Ashley</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Srivastava_R/0/1/0/all/0/1\">Rupesh Kumar Srivastava</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Schmidhuber_J/0/1/0/all/0/1\">J&#xfc;rgen Schmidhuber</a>",
          "description": "Reward-Weighted Regression (RWR) belongs to a family of widely known\niterative Reinforcement Learning algorithms based on the\nExpectation-Maximization framework. In this family, learning at each iteration\nconsists of sampling a batch of trajectories using the current policy and\nfitting a new policy to maximize a return-weighted log-likelihood of actions.\nAlthough RWR is known to yield monotonic improvement of the policy under\ncertain circumstances, whether and under which conditions RWR converges to the\noptimal policy have remained open questions. In this paper, we provide for the\nfirst time a proof that RWR converges to a global optimum when no function\napproximation is used.",
          "link": "http://arxiv.org/abs/2107.09088",
          "publishedOn": "2021-07-21T02:01:35.829Z",
          "wordCount": 575,
          "title": "Reward-Weighted Regression Converges to a Global Optimum. (arXiv:2107.09088v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09208",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Souza_M/0/1/0/all/0/1\">Mila Soares de Oliveira de Souza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moura_P/0/1/0/all/0/1\">Pedro Nuno de Souza Moura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Briot_J/0/1/0/all/0/1\">Jean-Pierre Briot</a>",
          "description": "This paper presents a comparative analysis on two artificial neural networks\n(with different architectures) for the task of tempo estimation. For this\npurpose, it also proposes the modeling, training and evaluation of a B-RNN\n(Bidirectional Recurrent Neural Network) model capable of estimating tempo in\nbpm (beats per minutes) of musical pieces, without using external auxiliary\nmodules. An extensive database (12,550 pieces in total) was curated to conduct\na quantitative and qualitative analysis over the experiment. Percussion-only\ntracks were also included in the dataset. The performance of the B-RNN is\ncompared to that of state-of-the-art models. For further comparison, a\nstate-of-the-art CNN was also retrained with the same datasets used for the\nB-RNN training. Evaluation results for each model and datasets are presented\nand discussed, as well as observations and ideas for future research. Tempo\nestimation was more accurate for the percussion only dataset, suggesting that\nthe estimation can be more accurate for percussion-only tracks, although\nfurther experiments (with more of such datasets) should be made to gather\nstronger evidence.",
          "link": "http://arxiv.org/abs/2107.09208",
          "publishedOn": "2021-07-21T02:01:35.810Z",
          "wordCount": 621,
          "title": "Music Tempo Estimation via Neural Networks -- A Comparative Analysis. (arXiv:2107.09208v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09091",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mazumdar_A/0/1/0/all/0/1\">Arya Mazumdar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pal_S/0/1/0/all/0/1\">Soumyabrata Pal</a>",
          "description": "One-bit compressed sensing (1bCS) is an extreme-quantized signal acquisition\nmethod that has been widely studied in the past decade. In 1bCS, linear samples\nof a high dimensional signal are quantized to only one bit per sample (sign of\nthe measurement). Assuming the original signal vector to be sparse, existing\nresults either aim to find the support of the vector, or approximate the signal\nwithin an $\\epsilon$-ball. The focus of this paper is support recovery, which\noften also computationally facilitates approximate signal recovery. A universal\nmeasurement matrix for 1bCS refers to one set of measurements that work for all\nsparse signals. With universality, it is known that $\\tilde{\\Theta}(k^2)$ 1bCS\nmeasurements are necessary and sufficient for support recovery (where $k$\ndenotes the sparsity). In this work, we show that it is possible to universally\nrecover the support with a small number of false positives with\n$\\tilde{O}(k^{3/2})$ measurements. If the dynamic range of the signal vector is\nknown, then with a different technique, this result can be improved to only\n$\\tilde{O}(k)$ measurements. Further results on support recovery are also\nprovided.",
          "link": "http://arxiv.org/abs/2107.09091",
          "publishedOn": "2021-07-21T02:01:35.804Z",
          "wordCount": 620,
          "title": "Support Recovery in Universal One-bit Compressed Sensing. (arXiv:2107.09091v1 [cs.IT])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09356",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Eloff_K/0/1/0/all/0/1\">Kevin Eloff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Engelbrecht_H/0/1/0/all/0/1\">Herman Engelbrecht</a>",
          "description": "Communication between agents in collaborative multi-agent settings is in\ngeneral implicit or a direct data stream. This paper considers text-based\nnatural language as a novel form of communication between multiple agents\ntrained with reinforcement learning. This could be considered first steps\ntoward a truly autonomous communication without the need to define a limited\nset of instructions, and natural collaboration between humans and robots.\nInspired by the game of Blind Leads, we propose an environment where one agent\nuses natural language instructions to guide another through a maze. We test the\nability of reinforcement learning agents to effectively communicate through\ndiscrete word-level symbols and show that the agents are able to sufficiently\ncommunicate through natural language with a limited vocabulary. Although the\ncommunication is not always perfect English, the agents are still able to\nnavigate the maze. We achieve a BLEU score of 0.85, which is an improvement of\n0.61 over randomly generated sequences while maintaining a 100% maze completion\nrate. This is a 3.5 times the performance of the random baseline using our\nreference set.",
          "link": "http://arxiv.org/abs/2107.09356",
          "publishedOn": "2021-07-21T02:01:35.797Z",
          "wordCount": 665,
          "title": "Toward Collaborative Reinforcement Learning Agents that Communicate Through Text-Based Natural Language. (arXiv:2107.09356v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09366",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Spantidi_O/0/1/0/all/0/1\">Ourania Spantidi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zervakis_G/0/1/0/all/0/1\">Georgios Zervakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anagnostopoulos_I/0/1/0/all/0/1\">Iraklis Anagnostopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amrouch_H/0/1/0/all/0/1\">Hussam Amrouch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henkel_J/0/1/0/all/0/1\">J&#xf6;rg Henkel</a>",
          "description": "Recent Deep Neural Networks (DNNs) managed to deliver superhuman accuracy\nlevels on many AI tasks. Several applications rely more and more on DNNs to\ndeliver sophisticated services and DNN accelerators are becoming integral\ncomponents of modern systems-on-chips. DNNs perform millions of arithmetic\noperations per inference and DNN accelerators integrate thousands of\nmultiply-accumulate units leading to increased energy requirements. Approximate\ncomputing principles are employed to significantly lower the energy consumption\nof DNN accelerators at the cost of some accuracy loss. Nevertheless, recent\nresearch demonstrated that complex DNNs are increasingly sensitive to\napproximation. Hence, the obtained energy savings are often limited when\ntargeting tight accuracy constraints. In this work, we present a dynamically\nconfigurable approximate multiplier that supports three operation modes, i.e.,\nexact, positive error, and negative error. In addition, we propose a\nfilter-oriented approximation method to map the weights to the appropriate\nmodes of the approximate multiplier. Our mapping algorithm balances the\npositive with the negative errors due to the approximate multiplications,\naiming at maximizing the energy reduction while minimizing the overall\nconvolution error. We evaluate our approach on multiple DNNs and datasets\nagainst state-of-the-art approaches, where our method achieves 18.33% energy\ngains on average across 7 NNs on 4 different datasets for a maximum accuracy\ndrop of only 1%.",
          "link": "http://arxiv.org/abs/2107.09366",
          "publishedOn": "2021-07-21T02:01:35.789Z",
          "wordCount": 656,
          "title": "Positive/Negative Approximate Multipliers for DNN Accelerators. (arXiv:2107.09366v1 [cs.AR])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09262",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghose_S/0/1/0/all/0/1\">Sanchita Ghose</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prevost_J/0/1/0/all/0/1\">John J. Prevost</a>",
          "description": "Deep learning based visual to sound generation systems essentially need to be\ndeveloped particularly considering the synchronicity aspects of visual and\naudio features with time. In this research we introduce a novel task of guiding\na class conditioned generative adversarial network with the temporal visual\ninformation of a video input for visual to sound generation task adapting the\nsynchronicity traits between audio-visual modalities. Our proposed FoleyGAN\nmodel is capable of conditioning action sequences of visual events leading\ntowards generating visually aligned realistic sound tracks. We expand our\npreviously proposed Automatic Foley dataset to train with FoleyGAN and evaluate\nour synthesized sound through human survey that shows noteworthy (on average\n81\\%) audio-visual synchronicity performance. Our approach also outperforms in\nstatistical experiments compared with other baseline models and audio-visual\ndatasets.",
          "link": "http://arxiv.org/abs/2107.09262",
          "publishedOn": "2021-07-21T02:01:35.782Z",
          "wordCount": 610,
          "title": "FoleyGAN: Visually Guided Generative Adversarial Network-Based Synchronous Sound Generation in Silent Videos. (arXiv:2107.09262v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09422",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Addanki_R/0/1/0/all/0/1\">Ravichandra Addanki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Battaglia_P/0/1/0/all/0/1\">Peter W. Battaglia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Budden_D/0/1/0/all/0/1\">David Budden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deac_A/0/1/0/all/0/1\">Andreea Deac</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Godwin_J/0/1/0/all/0/1\">Jonathan Godwin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keck_T/0/1/0/all/0/1\">Thomas Keck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wai Lok Sibon Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanchez_Gonzalez_A/0/1/0/all/0/1\">Alvaro Sanchez-Gonzalez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stott_J/0/1/0/all/0/1\">Jacklynn Stott</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thakoor_S/0/1/0/all/0/1\">Shantanu Thakoor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Velickovic_P/0/1/0/all/0/1\">Petar Veli&#x10d;kovi&#x107;</a>",
          "description": "Effectively and efficiently deploying graph neural networks (GNNs) at scale\nremains one of the most challenging aspects of graph representation learning.\nMany powerful solutions have only ever been validated on comparatively small\ndatasets, often with counter-intuitive outcomes -- a barrier which has been\nbroken by the Open Graph Benchmark Large-Scale Challenge (OGB-LSC). We entered\nthe OGB-LSC with two large-scale GNNs: a deep transductive node classifier\npowered by bootstrapping, and a very deep (up to 50-layer) inductive graph\nregressor regularised by denoising objectives. Our models achieved an\naward-level (top-3) performance on both the MAG240M and PCQM4M benchmarks. In\ndoing so, we demonstrate evidence of scalable self-supervised graph\nrepresentation learning, and utility of very deep GNNs -- both very important\nopen issues. Our code is publicly available at:\nhttps://github.com/deepmind/deepmind-research/tree/master/ogb_lsc.",
          "link": "http://arxiv.org/abs/2107.09422",
          "publishedOn": "2021-07-21T02:01:35.764Z",
          "wordCount": 610,
          "title": "Large-scale graph representation learning with very deep GNNs and self-supervision. (arXiv:2107.09422v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09182",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Petersen_B/0/1/0/all/0/1\">Brenden K. Petersen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santiago_C/0/1/0/all/0/1\">Claudio P. Santiago</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Larma_M/0/1/0/all/0/1\">Mikel Landajuela Larma</a>",
          "description": "Many AutoML problems involve optimizing discrete objects under a black-box\nreward. Neural-guided search provides a flexible means of searching these\ncombinatorial spaces using an autoregressive recurrent neural network. A major\nbenefit of this approach is that builds up objects sequentially--this provides\nan opportunity to incorporate domain knowledge into the search by directly\nmodifying the logits emitted during sampling. In this work, we formalize a\nframework for incorporating such in situ priors and constraints into\nneural-guided search, and provide sufficient conditions for enforcing\nconstraints. We integrate several priors and constraints from existing works\ninto this framework, propose several new ones, and demonstrate their efficacy\nin informing the task of symbolic regression.",
          "link": "http://arxiv.org/abs/2107.09182",
          "publishedOn": "2021-07-21T02:01:35.757Z",
          "wordCount": 537,
          "title": "Incorporating domain knowledge into neural-guided search. (arXiv:2107.09182v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09428",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Wang_T/0/1/0/all/0/1\">Tianzi Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fujita_Y/0/1/0/all/0/1\">Yuya Fujita</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chang_X/0/1/0/all/0/1\">Xuankai Chang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Watanabe_S/0/1/0/all/0/1\">Shinji Watanabe</a>",
          "description": "Non-autoregressive (NAR) modeling has gained more and more attention in\nspeech processing. With recent state-of-the-art attention-based automatic\nspeech recognition (ASR) structure, NAR can realize promising real-time factor\n(RTF) improvement with only small degradation of accuracy compared to the\nautoregressive (AR) models. However, the recognition inference needs to wait\nfor the completion of a full speech utterance, which limits their applications\non low latency scenarios. To address this issue, we propose a novel end-to-end\nstreaming NAR speech recognition system by combining blockwise-attention and\nconnectionist temporal classification with mask-predict (Mask-CTC) NAR. During\ninference, the input audio is separated into small blocks and then processed in\na blockwise streaming way. To address the insertion and deletion error at the\nedge of the output of each block, we apply an overlapping decoding strategy\nwith a dynamic mapping trick that can produce more coherent sentences.\nExperimental results show that the proposed method improves online ASR\nrecognition in low latency conditions compared to vanilla Mask-CTC. Moreover,\nit can achieve a much faster inference speed compared to the AR attention-based\nmodels. All of our codes will be publicly available at\nhttps://github.com/espnet/espnet.",
          "link": "http://arxiv.org/abs/2107.09428",
          "publishedOn": "2021-07-21T02:01:35.750Z",
          "wordCount": 638,
          "title": "Streaming End-to-End ASR based on Blockwise Non-Autoregressive Models. (arXiv:2107.09428v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09251",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shin_D/0/1/0/all/0/1\">Daniel Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brown_D/0/1/0/all/0/1\">Daniel S. Brown</a>",
          "description": "We study how an offline dataset of prior (possibly random) experience can be\nused to address two challenges that autonomous systems face when they endeavor\nto learn from, adapt to, and collaborate with humans : (1) identifying the\nhuman's intent and (2) safely optimizing the autonomous system's behavior to\nachieve this inferred intent. First, we use the offline dataset to efficiently\ninfer the human's reward function via pool-based active preference learning.\nSecond, given this learned reward function, we perform offline reinforcement\nlearning to optimize a policy based on the inferred human intent. Crucially,\nour proposed approach does not require actual physical rollouts or an accurate\nsimulator for either the reward learning or policy optimization steps, enabling\nboth safe and efficient apprenticeship learning. We identify and evaluate our\napproach on a subset of existing offline RL benchmarks that are well suited for\noffline reward learning and also evaluate extensions of these benchmarks which\nallow more open-ended behaviors. Our experiments show that offline\npreference-based reward learning followed by offline reinforcement learning\nenables efficient and high-performing policies, while only requiring small\nnumbers of preference queries. Videos available at\nhttps://sites.google.com/view/offline-prefs.",
          "link": "http://arxiv.org/abs/2107.09251",
          "publishedOn": "2021-07-21T02:01:35.743Z",
          "wordCount": 619,
          "title": "OPAL: Offline Preference-Based Apprenticeship Learning. (arXiv:2107.09251v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09309",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Odema_M/0/1/0/all/0/1\">Mohanad Odema</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rashid_N/0/1/0/all/0/1\">Nafiul Rashid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Demirel_B/0/1/0/all/0/1\">Berken Utku Demirel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faruque_M/0/1/0/all/0/1\">Mohammad Abdullah Al Faruque</a>",
          "description": "Edge-Cloud hierarchical systems employing intelligence through Deep Neural\nNetworks (DNNs) endure the dilemma of workload distribution within them.\nPrevious solutions proposed to distribute workloads at runtime according to the\nstate of the surroundings, like the wireless conditions. However, such\nconditions are usually overlooked at design time. This paper addresses this\nissue for DNN architectural design by presenting a novel methodology, LENS,\nwhich administers multi-objective Neural Architecture Search (NAS) for\ntwo-tiered systems, where the performance objectives are refashioned to\nconsider the wireless communication parameters. From our experimental search\nspace, we demonstrate that LENS improves upon the traditional solution's Pareto\nset by 76.47% and 75% with respect to the energy and latency metrics,\nrespectively.",
          "link": "http://arxiv.org/abs/2107.09309",
          "publishedOn": "2021-07-21T02:01:35.736Z",
          "wordCount": 579,
          "title": "LENS: Layer Distribution Enabled Neural Architecture Search in Edge-Cloud Hierarchies. (arXiv:2107.09309v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09370",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Stock_P/0/1/0/all/0/1\">Pierre Stock</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gribonval_R/0/1/0/all/0/1\">R&#xe9;mi Gribonval</a>",
          "description": "Neural networks with the Rectified Linear Unit (ReLU) nonlinearity are\ndescribed by a vector of parameters $\\theta$, and realized as a piecewise\nlinear continuous function $R_{\\theta}: x \\in \\mathbb R^{d} \\mapsto\nR_{\\theta}(x) \\in \\mathbb R^{k}$. Natural scalings and permutations operations\non the parameters $\\theta$ leave the realization unchanged, leading to\nequivalence classes of parameters that yield the same realization. These\nconsiderations in turn lead to the notion of identifiability -- the ability to\nrecover (the equivalence class of) $\\theta$ from the sole knowledge of its\nrealization $R_{\\theta}$. The overall objective of this paper is to introduce\nan embedding for ReLU neural networks of any depth, $\\Phi(\\theta)$, that is\ninvariant to scalings and that provides a locally linear parameterization of\nthe realization of the network. Leveraging these two key properties, we derive\nsome conditions under which a deep ReLU network is indeed locally identifiable\nfrom the knowledge of the realization on a finite set of samples $x_{i} \\in\n\\mathbb R^{d}$. We study the shallow case in more depth, establishing necessary\nand sufficient conditions for the network to be identifiable from a bounded\nsubset $\\mathcal X \\subseteq \\mathbb R^{d}$.",
          "link": "http://arxiv.org/abs/2107.09370",
          "publishedOn": "2021-07-21T02:01:35.729Z",
          "wordCount": 618,
          "title": "An Embedding of ReLU Networks and an Analysis of their Identifiability. (arXiv:2107.09370v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09106",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Whitehead_S/0/1/0/all/0/1\">Spencer Whitehead</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Hui Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feris_R/0/1/0/all/0/1\">Rogerio Feris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saenko_K/0/1/0/all/0/1\">Kate Saenko</a>",
          "description": "Generalization to out-of-distribution data has been a problem for Visual\nQuestion Answering (VQA) models. To measure generalization to novel questions,\nwe propose to separate them into \"skills\" and \"concepts\". \"Skills\" are visual\ntasks, such as counting or attribute recognition, and are applied to \"concepts\"\nmentioned in the question, such as objects and people. VQA methods should be\nable to compose skills and concepts in novel ways, regardless of whether the\nspecific composition has been seen in training, yet we demonstrate that\nexisting models have much to improve upon towards handling new compositions. We\npresent a novel method for learning to compose skills and concepts that\nseparates these two factors implicitly within a model by learning grounded\nconcept representations and disentangling the encoding of skills from that of\nconcepts. We enforce these properties with a novel contrastive learning\nprocedure that does not rely on external annotations and can be learned from\nunlabeled image-question pairs. Experiments demonstrate the effectiveness of\nour approach for improving compositional and grounding performance.",
          "link": "http://arxiv.org/abs/2107.09106",
          "publishedOn": "2021-07-21T02:01:35.711Z",
          "wordCount": 624,
          "title": "Separating Skills and Concepts for Novel Visual Question Answering. (arXiv:2107.09106v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09234",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Boggust_A/0/1/0/all/0/1\">Angie Boggust</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoover_B/0/1/0/all/0/1\">Benjamin Hoover</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Satyanarayan_A/0/1/0/all/0/1\">Arvind Satyanarayan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Strobelt_H/0/1/0/all/0/1\">Hendrik Strobelt</a>",
          "description": "Saliency methods -- techniques to identify the importance of input features\non a model's output -- are a common first step in understanding neural network\nbehavior. However, interpreting saliency requires tedious manual inspection to\nidentify and aggregate patterns in model behavior, resulting in ad hoc or\ncherry-picked analysis. To address these concerns, we present Shared Interest:\na set of metrics for comparing saliency with human annotated ground truths. By\nproviding quantitative descriptors, Shared Interest allows ranking, sorting,\nand aggregation of inputs thereby facilitating large-scale systematic analysis\nof model behavior. We use Shared Interest to identify eight recurring patterns\nin model behavior including focusing on a sufficient subset of ground truth\nfeatures or being distracted by contextual features. Working with\nrepresentative real-world users, we show how Shared Interest can be used to\nrapidly develop or lose trust in a model's reliability, uncover issues that are\nmissed in manual analyses, and enable interactive probing of model behavior.",
          "link": "http://arxiv.org/abs/2107.09234",
          "publishedOn": "2021-07-21T02:01:35.704Z",
          "wordCount": 605,
          "title": "Shared Interest: Large-Scale Visual Analysis of Model Behavior by Measuring Human-AI Alignment. (arXiv:2107.09234v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09484",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kronberger_G/0/1/0/all/0/1\">Gabriel Kronberger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kommenda_M/0/1/0/all/0/1\">Michael Kommenda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Promberger_A/0/1/0/all/0/1\">Andreas Promberger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nickel_F/0/1/0/all/0/1\">Falk Nickel</a>",
          "description": "Friction systems are mechanical systems wherein friction is used for force\ntransmission (e.g. mechanical braking systems or automatic gearboxes). For\nfinding optimal and safe design parameters, engineers have to predict friction\nsystem performance. This is especially difficult in real-world applications,\nbecause it is affected by many parameters. We have used symbolic regression and\ngenetic programming for finding accurate and trustworthy prediction models for\nthis task. However, it is not straight-forward how nominal variables can be\nincluded. In particular, a one-hot-encoding is unsatisfactory because genetic\nprogramming tends to remove such indicator variables. We have therefore used\nso-called factor variables for representing nominal variables in symbolic\nregression models. Our results show that GP is able to produce symbolic\nregression models for predicting friction performance with predictive accuracy\nthat is comparable to artificial neural networks. The symbolic regression\nmodels with factor variables are less complex than models using a one-hot\nencoding.",
          "link": "http://arxiv.org/abs/2107.09484",
          "publishedOn": "2021-07-21T02:01:35.697Z",
          "wordCount": 628,
          "title": "Predicting Friction System Performance with Symbolic Regression and Genetic Programming with Factor Variables. (arXiv:2107.09484v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09359",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Carvalho_J/0/1/0/all/0/1\">Jo&#xe3;o Carvalho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tateo_D/0/1/0/all/0/1\">Davide Tateo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muratore_F/0/1/0/all/0/1\">Fabio Muratore</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peters_J/0/1/0/all/0/1\">Jan Peters</a>",
          "description": "Reinforcement learning methods for robotics are increasingly successful due\nto the constant development of better policy gradient techniques. A precise\n(low variance) and accurate (low bias) gradient estimator is crucial to face\nincreasingly complex tasks. Traditional policy gradient algorithms use the\nlikelihood-ratio trick, which is known to produce unbiased but high variance\nestimates. More modern approaches exploit the reparametrization trick, which\ngives lower variance gradient estimates but requires differentiable value\nfunction approximators. In this work, we study a different type of stochastic\ngradient estimator: the Measure-Valued Derivative. This estimator is unbiased,\nhas low variance, and can be used with differentiable and non-differentiable\nfunction approximators. We empirically evaluate this estimator in the\nactor-critic policy gradient setting and show that it can reach comparable\nperformance with methods based on the likelihood-ratio or reparametrization\ntricks, both in low and high-dimensional action spaces.",
          "link": "http://arxiv.org/abs/2107.09359",
          "publishedOn": "2021-07-21T02:01:35.690Z",
          "wordCount": 575,
          "title": "An Empirical Analysis of Measure-Valued Derivatives for Policy Gradients. (arXiv:2107.09359v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09391",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gulshad_S/0/1/0/all/0/1\">Sadaf Gulshad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sosnovik_I/0/1/0/all/0/1\">Ivan Sosnovik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smeulders_A/0/1/0/all/0/1\">Arnold Smeulders</a>",
          "description": "We focus on building robustness in the convolutions of neural visual\nclassifiers, especially against natural perturbations like elastic\ndeformations, occlusions and Gaussian noise. Existing CNNs show outstanding\nperformance on clean images, but fail to tackle naturally occurring\nperturbations. In this paper, we start from elastic perturbations, which\napproximate (local) view-point changes of the object. We present\nelastically-augmented convolutions (EAConv) by parameterizing filters as a\ncombination of fixed elastically-perturbed bases functions and trainable\nweights for the purpose of integrating unseen viewpoints in the CNN. We show on\nCIFAR-10 and STL-10 datasets that the general robustness of our method on\nunseen occlusion and Gaussian perturbations improves, while even improving the\nperformance on clean images slightly without performing any data augmentation.",
          "link": "http://arxiv.org/abs/2107.09391",
          "publishedOn": "2021-07-21T02:01:35.682Z",
          "wordCount": 556,
          "title": "Built-in Elastic Transformations for Improved Robustness. (arXiv:2107.09391v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09286",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ai_Q/0/1/0/all/0/1\">Qingzhong Ai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1\">Lirong He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shiyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zenglin Xu</a>",
          "description": "Recent studies show that advanced priors play a major role in deep generative\nmodels. Exemplar VAE, as a variant of VAE with an exemplar-based prior, has\nachieved impressive results. However, due to the nature of model design, an\nexemplar-based model usually requires vast amounts of data to participate in\ntraining, which leads to huge computational complexity. To address this issue,\nwe propose Bayesian Pseudocoresets Exemplar VAE (ByPE-VAE), a new variant of\nVAE with a prior based on Bayesian pseudocoreset. The proposed prior is\nconditioned on a small-scale pseudocoreset rather than the whole dataset for\nreducing the computational cost and avoiding overfitting. Simultaneously, we\nobtain the optimal pseudocoreset via a stochastic optimization algorithm during\nVAE training aiming to minimize the Kullback-Leibler divergence between the\nprior based on the pseudocoreset and that based on the whole dataset.\nExperimental results show that ByPE-VAE can achieve competitive improvements\nover the state-of-the-art VAEs in the tasks of density estimation,\nrepresentation learning, and generative data augmentation. Particularly, on a\nbasic VAE architecture, ByPE-VAE is up to 3 times faster than Exemplar VAE\nwhile almost holding the performance. Code is available at our supplementary\nmaterials.",
          "link": "http://arxiv.org/abs/2107.09286",
          "publishedOn": "2021-07-21T02:01:35.665Z",
          "wordCount": 612,
          "title": "ByPE-VAE: Bayesian Pseudocoresets Exemplar VAE. (arXiv:2107.09286v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09480",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Amato_D/0/1/0/all/0/1\">Domenico Amato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giancarlo_R/0/1/0/all/0/1\">Raffaele Giancarlo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bosco_G/0/1/0/all/0/1\">Giosu&#xe8; Lo Bosco</a>",
          "description": "Sorted Table Search Procedures are the quintessential query-answering tool,\nstill very useful, e.g, Search Engines (Google Chrome). Speeding them up, in\nsmall additional space with respect to the table being searched into, is still\na quite significant achievement. Static Learned Indexes have been very\nsuccessful in achieving such a speed-up, but leave open a major question: To\nwhat extent one can enjoy the speed-up of Learned Indexes while using constant\nor nearly constant additional space. By generalizing the experimental\nmethodology of a recent benchmarking study on Learned Indexes, we shed light on\nthis question, by considering two scenarios. The first, quite elementary, i.e.,\ntextbook code, and the second using advanced Learned Indexing algorithms and\nthe supporting sophisticated software platforms. Although in both cases one\nwould expect a positive answer, its achievement is not as simple as it seems.\nIndeed, our extensive set of experiments reveal a complex relationship between\nquery time and model space. The findings regarding this relationship and the\ncorresponding quantitative estimates, across memory levels, can be of interest\nto algorithm designers and of use to practitioners as well. As an essential\npart of our research, we introduce two new models that are of interest in their\nown right. The first is a constant space model that can be seen as a\ngeneralization of $k$-ary search, while the second is a synoptic {\\bf RMI}, in\nwhich we can control model space usage.",
          "link": "http://arxiv.org/abs/2107.09480",
          "publishedOn": "2021-07-21T02:01:35.658Z",
          "wordCount": 696,
          "title": "Learned Sorted Table Search and Static Indexes in Small Space: Methodological and Practical Insights via an Experimental Study. (arXiv:2107.09480v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09203",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1\">Zhan Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gama_F/0/1/0/all/0/1\">Fernando Gama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_A/0/1/0/all/0/1\">Alejandro Ribeiro</a>",
          "description": "Graph neural networks (GNNs) are naturally distributed architectures for\nlearning representations from network data. This renders them suitable\ncandidates for decentralized tasks. In these scenarios, the underlying graph\noften changes with time due to link failures or topology variations, creating a\nmismatch between the graphs on which GNNs were trained and the ones on which\nthey are tested. Online learning can be leveraged to retrain GNNs at testing\ntime to overcome this issue. However, most online algorithms are centralized\nand usually offer guarantees only on convex problems, which GNNs rarely lead\nto. This paper develops the Wide and Deep GNN (WD-GNN), a novel architecture\nthat can be updated with distributed online learning mechanisms. The WD-GNN\nconsists of two components: the wide part is a linear graph filter and the deep\npart is a nonlinear GNN. At training time, the joint wide and deep architecture\nlearns nonlinear representations from data. At testing time, the wide, linear\npart is retrained, while the deep, nonlinear one remains fixed. This often\nleads to a convex formulation. We further propose a distributed online learning\nalgorithm that can be implemented in a decentralized setting. We also show the\nstability of the WD-GNN to changes of the underlying graph and analyze the\nconvergence of the proposed online learning procedure. Experiments on movie\nrecommendation, source localization and robot swarm control corroborate\ntheoretical findings and show the potential of the WD-GNN for distributed\nonline learning.",
          "link": "http://arxiv.org/abs/2107.09203",
          "publishedOn": "2021-07-21T02:01:35.651Z",
          "wordCount": 681,
          "title": "Wide and Deep Graph Neural Network with Distributed Online Learning. (arXiv:2107.09203v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09256",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Uy_W/0/1/0/all/0/1\">Wayne Isaac Tan Uy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuepeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1\">Yuxiao Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peherstorfer_B/0/1/0/all/0/1\">Benjamin Peherstorfer</a>",
          "description": "Noise poses a challenge for learning dynamical-system models because already\nsmall variations can distort the dynamics described by trajectory data. This\nwork builds on operator inference from scientific machine learning to infer\nlow-dimensional models from high-dimensional state trajectories polluted with\nnoise. The presented analysis shows that, under certain conditions, the\ninferred operators are unbiased estimators of the well-studied projection-based\nreduced operators from traditional model reduction. Furthermore, the connection\nbetween operator inference and projection-based model reduction enables\nbounding the mean-squared errors of predictions made with the learned models\nwith respect to traditional reduced models. The analysis also motivates an\nactive operator inference approach that judiciously samples high-dimensional\ntrajectories with the aim of achieving a low mean-squared error by reducing the\neffect of noise. Numerical experiments with high-dimensional linear and\nnonlinear state dynamics demonstrate that predictions obtained with active\noperator inference have orders of magnitude lower mean-squared errors than\noperator inference with traditional, equidistantly sampled trajectory data.",
          "link": "http://arxiv.org/abs/2107.09256",
          "publishedOn": "2021-07-21T02:01:35.603Z",
          "wordCount": 601,
          "title": "Active operator inference for learning low-dimensional dynamical-system models from noisy data. (arXiv:2107.09256v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09133",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kunin_D/0/1/0/all/0/1\">Daniel Kunin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sagastuy_Brena_J/0/1/0/all/0/1\">Javier Sagastuy-Brena</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gillespie_L/0/1/0/all/0/1\">Lauren Gillespie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Margalit_E/0/1/0/all/0/1\">Eshed Margalit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tanaka_H/0/1/0/all/0/1\">Hidenori Tanaka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganguli_S/0/1/0/all/0/1\">Surya Ganguli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamins_D/0/1/0/all/0/1\">Daniel L. K. Yamins</a>",
          "description": "In this work we explore the limiting dynamics of deep neural networks trained\nwith stochastic gradient descent (SGD). We find empirically that long after\nperformance has converged, networks continue to move through parameter space by\na process of anomalous diffusion in which distance travelled grows as a power\nlaw in the number of gradient updates with a nontrivial exponent. We reveal an\nintricate interaction between the hyperparameters of optimization, the\nstructure in the gradient noise, and the Hessian matrix at the end of training\nthat explains this anomalous diffusion. To build this understanding, we first\nderive a continuous-time model for SGD with finite learning rates and batch\nsizes as an underdamped Langevin equation. We study this equation in the\nsetting of linear regression, where we can derive exact, analytic expressions\nfor the phase space dynamics of the parameters and their instantaneous\nvelocities from initialization to stationarity. Using the Fokker-Planck\nequation, we show that the key ingredient driving these dynamics is not the\noriginal training loss, but rather the combination of a modified loss, which\nimplicitly regularizes the velocity, and probability currents, which cause\noscillations in phase space. We identify qualitative and quantitative\npredictions of this theory in the dynamics of a ResNet-18 model trained on\nImageNet. Through the lens of statistical physics, we uncover a mechanistic\norigin for the anomalous limiting dynamics of deep neural networks trained with\nSGD.",
          "link": "http://arxiv.org/abs/2107.09133",
          "publishedOn": "2021-07-21T02:01:35.596Z",
          "wordCount": 700,
          "title": "Rethinking the limiting dynamics of SGD: modified loss, phase space oscillations, and anomalous diffusion. (arXiv:2107.09133v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09232",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Utimula_K/0/1/0/all/0/1\">Keishu Utimula</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hayaschi_K/0/1/0/all/0/1\">Ken-taro Hayaschi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakano_K/0/1/0/all/0/1\">Kousuke Nakano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hongo_K/0/1/0/all/0/1\">Kenta Hongo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maezono_R/0/1/0/all/0/1\">Ryo Maezono</a>",
          "description": "When agents are swarmed to carry out a mission, there is often a sudden\nfailure of some of the agents observed from the command base. It is generally\ndifficult to distinguish whether the failure is caused by actuators\n(hypothesis, $h_a$) or sensors (hypothesis, $h_s$) solely by the communication\nbetween the command base and the concerning agent. By making a collision to the\nagent by another, we would be able to distinguish which hypothesis is likely:\nFor $h_a$, we expect to detect corresponding displacements while for $h_a$ we\ndo not. Such swarm strategies to grasp the situation are preferably to be\ngenerated autonomously by artificial intelligence (AI). Preferable actions\n($e.g.$, the collision) for the distinction would be those maximizing the\ndifference between the expected behaviors for each hypothesis, as a value\nfunction. Such actions exist, however, only very sparsely in the whole\npossibilities, for which the conventional search based on gradient methods does\nnot make sense. Instead, we have successfully applied the reinforcement\nlearning technique, achieving the maximization of such a sparse value function.\nThe machine learning actually concluded autonomously the colliding action to\ndistinguish the hypothesises. Getting recognized an agent with actuator error\nby the action, the agents behave as if other ones want to assist the\nmalfunctioning one to achieve a given mission.",
          "link": "http://arxiv.org/abs/2107.09232",
          "publishedOn": "2021-07-21T02:01:35.577Z",
          "wordCount": 674,
          "title": "Reinforcement learning autonomously identifying the source of errors for agents in a group mission. (arXiv:2107.09232v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09139",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Varga_B/0/1/0/all/0/1\">Bal&#xe1;zs Varga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulcsar_B/0/1/0/all/0/1\">Bal&#xe1;zs Kulcs&#xe1;r</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chehreghani_M/0/1/0/all/0/1\">Morteza Haghir Chehreghani</a>",
          "description": "This paper presents a constrained policy gradient algorithm. We introduce\nconstraints for safe learning with the following steps. First, learning is\nslowed down (lazy learning) so that the episodic policy change can be computed\nwith the help of the policy gradient theorem and the neural tangent kernel.\nThen, this enables us the evaluation of the policy at arbitrary states too. In\nthe same spirit, learning can be guided, ensuring safety via augmenting episode\nbatches with states where the desired action probabilities are prescribed.\nFinally, exogenous discounted sum of future rewards (returns) can be computed\nat these specific state-action pairs such that the policy network satisfies\nconstraints. Computing the returns is based on solving a system of linear\nequations (equality constraints) or a constrained quadratic program (inequality\nconstraints). Simulation results suggest that adding constraints (external\ninformation) to the learning can improve learning in terms of speed and safety\nreasonably if constraints are appropriately selected. The efficiency of the\nconstrained learning was demonstrated with a shallow and wide ReLU network in\nthe Cartpole and Lunar Lander OpenAI gym environments. The main novelty of the\npaper is giving a practical use of the neural tangent kernel in reinforcement\nlearning.",
          "link": "http://arxiv.org/abs/2107.09139",
          "publishedOn": "2021-07-21T02:01:35.570Z",
          "wordCount": 641,
          "title": "Constrained Policy Gradient Method for Safe and Fast Reinforcement Learning: a Neural Tangent Kernel Based Approach. (arXiv:2107.09139v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09142",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hawthorne_C/0/1/0/all/0/1\">Curtis Hawthorne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simon_I/0/1/0/all/0/1\">Ian Simon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swavely_R/0/1/0/all/0/1\">Rigel Swavely</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manilow_E/0/1/0/all/0/1\">Ethan Manilow</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Engel_J/0/1/0/all/0/1\">Jesse Engel</a>",
          "description": "Automatic Music Transcription has seen significant progress in recent years\nby training custom deep neural networks on large datasets. However, these\nmodels have required extensive domain-specific design of network architectures,\ninput/output representations, and complex decoding schemes. In this work, we\nshow that equivalent performance can be achieved using a generic\nencoder-decoder Transformer with standard decoding methods. We demonstrate that\nthe model can learn to translate spectrogram inputs directly to MIDI-like\noutput events for several transcription tasks. This sequence-to-sequence\napproach simplifies transcription by jointly modeling audio features and\nlanguage-like output dependencies, thus removing the need for task-specific\narchitectures. These results point toward possibilities for creating new Music\nInformation Retrieval models by focusing on dataset creation and labeling\nrather than custom model design.",
          "link": "http://arxiv.org/abs/2107.09142",
          "publishedOn": "2021-07-21T02:01:35.563Z",
          "wordCount": 555,
          "title": "Sequence-to-Sequence Piano Transcription with Transformers. (arXiv:2107.09142v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09207",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Hou_T/0/1/0/all/0/1\">Thomas Y. Hou</a>, <a href=\"http://arxiv.org/find/math/1/au:+Li_Z/0/1/0/all/0/1\">Zhenzhen Li</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhang_Z/0/1/0/all/0/1\">Ziyun Zhang</a>",
          "description": "We show that the Riemannian gradient descent algorithm on the low-rank matrix\nmanifold almost surely escapes some spurious critical points on the boundary of\nthe manifold. Given that the low-rank matrix manifold is an incomplete set,\nthis result is the first to overcome this difficulty and partially justify the\nglobal use of the Riemannian gradient descent on the manifold. The spurious\ncritical points are some rank-deficient matrices that capture only part of the\nSVD components of the ground truth. They exhibit very singular behavior and\nevade the classical analysis of strict saddle points. We show that using the\ndynamical low-rank approximation and a rescaled gradient flow, some of the\nspurious critical points can be converted to classical strict saddle points,\nwhich leads to the desired result. Numerical experiments are provided to\nsupport our theoretical findings.",
          "link": "http://arxiv.org/abs/2107.09207",
          "publishedOn": "2021-07-21T02:01:35.534Z",
          "wordCount": 586,
          "title": "Asymptotic Escape of Spurious Critical Points on the Low-rank Matrix Manifold. (arXiv:2107.09207v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09338",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ai_Q/0/1/0/all/0/1\">Qingzhong Ai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shiyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zenglin Xu</a>",
          "description": "Stein variational gradient descent (SVGD) and its variants have shown\npromising successes in approximate inference for complex distributions.\nHowever, their empirical performance depends crucially on the choice of optimal\nkernel. Unfortunately, RBF kernel with median heuristics is a common choice in\nprevious approaches which has been proved sub-optimal. Inspired by the paradigm\nof multiple kernel learning, our solution to this issue is using a combination\nof multiple kernels to approximate the optimal kernel instead of a single one\nwhich may limit the performance and flexibility. To do so, we extend Kernelized\nStein Discrepancy (KSD) to its multiple kernel view called Multiple Kernelized\nStein Discrepancy (MKSD). Further, we leverage MKSD to construct a general\nalgorithm based on SVGD, which be called Multiple Kernel SVGD (MK-SVGD).\nBesides, we automatically assign a weight to each kernel without any other\nparameters. The proposed method not only gets rid of optimal kernel dependence\nbut also maintains computational effectiveness. Experiments on various tasks\nand models show the effectiveness of our method.",
          "link": "http://arxiv.org/abs/2107.09338",
          "publishedOn": "2021-07-21T02:01:35.518Z",
          "wordCount": 596,
          "title": "Kernel Selection for Stein Variational Gradient Descent. (arXiv:2107.09338v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09202",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Severo_D/0/1/0/all/0/1\">Daniel Severo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Townsend_J/0/1/0/all/0/1\">James Townsend</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khisti_A/0/1/0/all/0/1\">Ashish Khisti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Makhzani_A/0/1/0/all/0/1\">Alireza Makhzani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ullrich_K/0/1/0/all/0/1\">Karen Ullrich</a>",
          "description": "Current methods that optimally compress multisets are not suitable for\nhigh-dimensional symbols, as their compute time scales linearly with alphabet\nsize. Compressing a multiset as an ordered sequence with off-the-shelf codecs\nis computationally more efficient, but has a sub-optimal compression rate, as\nbits are wasted encoding the order between symbols. We present a method that\ncan recover those bits, assuming symbols are i.i.d., at the cost of an\nadditional $\\mathcal{O}(|\\mathcal{M}|\\log M)$ in average time complexity, where\n$|\\mathcal{M}|$ and $M$ are the total and unique number of symbols in the\nmultiset. Our method is compatible with any prefix-free code. Experiments show\nthat, when paired with efficient coders, our method can efficiently compress\nhigh-dimensional sources such as multisets of images and collections of JSON\nfiles.",
          "link": "http://arxiv.org/abs/2107.09202",
          "publishedOn": "2021-07-21T02:01:35.511Z",
          "wordCount": 560,
          "title": "Compressing Multisets with Large Alphabets. (arXiv:2107.09202v1 [cs.IT])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09060",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Kustner_T/0/1/0/all/0/1\">Thomas K&#xfc;stner</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pan_J/0/1/0/all/0/1\">Jiazhen Pan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Qi_H/0/1/0/all/0/1\">Haikun Qi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cruz_G/0/1/0/all/0/1\">Gastao Cruz</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gilliam_C/0/1/0/all/0/1\">Christopher Gilliam</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Blu_T/0/1/0/all/0/1\">Thierry Blu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_B/0/1/0/all/0/1\">Bin Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gatidis_S/0/1/0/all/0/1\">Sergios Gatidis</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Botnar_R/0/1/0/all/0/1\">Ren&#xe9; Botnar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Prieto_C/0/1/0/all/0/1\">Claudia Prieto</a>",
          "description": "Physiological motion, such as cardiac and respiratory motion, during Magnetic\nResonance (MR) image acquisition can cause image artifacts. Motion correction\ntechniques have been proposed to compensate for these types of motion during\nthoracic scans, relying on accurate motion estimation from undersampled\nmotion-resolved reconstruction. A particular interest and challenge lie in the\nderivation of reliable non-rigid motion fields from the undersampled\nmotion-resolved data. Motion estimation is usually formulated in image space\nvia diffusion, parametric-spline, or optical flow methods. However, image-based\nregistration can be impaired by remaining aliasing artifacts due to the\nundersampled motion-resolved reconstruction. In this work, we describe a\nformalism to perform non-rigid registration directly in the sampled Fourier\nspace, i.e. k-space. We propose a deep-learning based approach to perform fast\nand accurate non-rigid registration from the undersampled k-space data. The\nbasic working principle originates from the Local All-Pass (LAP) technique, a\nrecently introduced optical flow-based registration. The proposed LAPNet is\ncompared against traditional and deep learning image-based registrations and\ntested on fully-sampled and highly-accelerated (with two undersampling\nstrategies) 3D respiratory motion-resolved MR images in a cohort of 40 patients\nwith suspected liver or lung metastases and 25 healthy subjects. The proposed\nLAPNet provided consistent and superior performance to image-based approaches\nthroughout different sampling trajectories and acceleration factors.",
          "link": "http://arxiv.org/abs/2107.09060",
          "publishedOn": "2021-07-21T02:01:35.437Z",
          "wordCount": 677,
          "title": "LAPNet: Non-rigid Registration derived in k-space for Magnetic Resonance Imaging. (arXiv:2107.09060v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09101",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nousias_S/0/1/0/all/0/1\">Stavros Nousias</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pikoulis_E/0/1/0/all/0/1\">Erion-Vasilis Pikoulis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mavrokefalidis_C/0/1/0/all/0/1\">Christos Mavrokefalidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lalos_A/0/1/0/all/0/1\">Aris S. Lalos</a>",
          "description": "Automotive Cyber-Physical Systems (ACPS) have attracted a significant amount\nof interest in the past few decades, while one of the most critical operations\nin these systems is the perception of the environment. Deep learning and,\nespecially, the use of Deep Neural Networks (DNNs) provides impressive results\nin analyzing and understanding complex and dynamic scenes from visual data. The\nprediction horizons for those perception systems are very short and inference\nmust often be performed in real time, stressing the need of transforming the\noriginal large pre-trained networks into new smaller models, by utilizing Model\nCompression and Acceleration (MCA) techniques. Our goal in this work is to\ninvestigate best practices for appropriately applying novel weight sharing\ntechniques, optimizing the available variables and the training procedures\ntowards the significant acceleration of widely adopted DNNs. Extensive\nevaluation studies carried out using various state-of-the-art DNN models in\nobject detection and tracking experiments, provide details about the type of\nerrors that manifest after the application of weight sharing techniques,\nresulting in significant acceleration gains with negligible accuracy losses.",
          "link": "http://arxiv.org/abs/2107.09101",
          "publishedOn": "2021-07-21T02:01:35.427Z",
          "wordCount": 620,
          "title": "Accelerating deep neural networks for efficient scene understanding in automotive cyber-physical systems. (arXiv:2107.09101v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09170",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vicente_J/0/1/0/all/0/1\">Juan Pablo de Vicente</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soto_A/0/1/0/all/0/1\">Alvaro Soto</a>",
          "description": "Current datasets to train social behaviors are usually borrowed from\nsurveillance applications that capture visual data from a bird's-eye\nperspective. This leaves aside precious relationships and visual cues that\ncould be captured through a first-person view of a scene. In this work, we\npropose a strategy to exploit the power of current game engines, such as Unity,\nto transform pre-existing bird's-eye view datasets into a first-person view, in\nparticular, a depth view. Using this strategy, we are able to generate large\nvolumes of synthetic data that can be used to pre-train a social navigation\nmodel. To test our ideas, we present DeepSocNav, a deep learning based model\nthat takes advantage of the proposed approach to generate synthetic data.\nFurthermore, DeepSocNav includes a self-supervised strategy that is included as\nan auxiliary task. This consists of predicting the next depth frame that the\nagent will face. Our experiments show the benefits of the proposed model that\nis able to outperform relevant baselines in terms of social navigation scores.",
          "link": "http://arxiv.org/abs/2107.09170",
          "publishedOn": "2021-07-21T02:01:35.400Z",
          "wordCount": 624,
          "title": "DeepSocNav: Social Navigation by Imitating Human Behaviors. (arXiv:2107.09170v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09078",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Cai_H/0/1/0/all/0/1\">Haoyuan Cai</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Ye_Q/0/1/0/all/0/1\">Qi Ye</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Deng_D/0/1/0/all/0/1\">Dong-Ling Deng</a>",
          "description": "Quantum computers hold unprecedented potentials for machine learning\napplications. Here, we prove that physical quantum circuits are PAC (probably\napproximately correct) learnable on a quantum computer via empirical risk\nminimization: to learn a quantum circuit with at most $n^c$ gates and each gate\nacting on a constant number of qubits, the sample complexity is bounded by\n$\\tilde{O}(n^{c+1})$. In particular, we explicitly construct a family of\nvariational quantum circuits with $O(n^{c+1})$ elementary gates arranged in a\nfixed pattern, which can represent all physical quantum circuits consisting of\nat most $n^c$ elementary gates. Our results provide a valuable guide for\nquantum machine learning in both theory and experiment.",
          "link": "http://arxiv.org/abs/2107.09078",
          "publishedOn": "2021-07-21T02:01:35.387Z",
          "wordCount": 544,
          "title": "Sample Complexity of Learning Quantum Circuits. (arXiv:2107.09078v1 [quant-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09110",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mishra_A/0/1/0/all/0/1\">Abhinav Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sriharsha_R/0/1/0/all/0/1\">Ram Sriharsha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_S/0/1/0/all/0/1\">Sichen Zhong</a>",
          "description": "Decomposing a complex time series into trend, seasonality, and remainder\ncomponents is an important primitive that facilitates time series anomaly\ndetection, change point detection and forecasting. Although numerous batch\nalgorithms are known for time series decomposition, none operate well in an\nonline scalable setting where high throughput and real-time response are\nparamount. In this paper, we propose OnlineSTL, a novel online algorithm for\ntime series decomposition which solves the scalability problem and is deployed\nfor real-time metrics monitoring on high resolution, high ingest rate data.\nExperiments on different synthetic and real world time series datasets\ndemonstrate that OnlineSTL achieves orders of magnitude speedups while\nmaintaining quality of decomposition.",
          "link": "http://arxiv.org/abs/2107.09110",
          "publishedOn": "2021-07-21T02:01:35.365Z",
          "wordCount": 550,
          "title": "OnlineSTL: Scaling Time Series Decomposition by 100x. (arXiv:2107.09110v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09158",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Larma_M/0/1/0/all/0/1\">Mikel Landajuela Larma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petersen_B/0/1/0/all/0/1\">Brenden K. Petersen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Soo K. Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santiago_C/0/1/0/all/0/1\">Claudio P. Santiago</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glatt_R/0/1/0/all/0/1\">Ruben Glatt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mundhenk_T/0/1/0/all/0/1\">T. Nathan Mundhenk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pettit_J/0/1/0/all/0/1\">Jacob F. Pettit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faissol_D/0/1/0/all/0/1\">Daniel M. Faissol</a>",
          "description": "Many machine learning strategies designed to automate mathematical tasks\nleverage neural networks to search large combinatorial spaces of mathematical\nsymbols. In contrast to traditional evolutionary approaches, using a neural\nnetwork at the core of the search allows learning higher-level symbolic\npatterns, providing an informed direction to guide the search. When no labeled\ndata is available, such networks can still be trained using reinforcement\nlearning. However, we demonstrate that this approach can suffer from an early\ncommitment phenomenon and from initialization bias, both of which limit\nexploration. We present two exploration methods to tackle these issues,\nbuilding upon ideas of entropy regularization and distribution initialization.\nWe show that these techniques can improve the performance, increase sample\nefficiency, and lower the complexity of solutions for the task of symbolic\nregression.",
          "link": "http://arxiv.org/abs/2107.09158",
          "publishedOn": "2021-07-21T02:01:35.334Z",
          "wordCount": 610,
          "title": "Improving exploration in policy gradient search: Application to symbolic optimization. (arXiv:2107.09158v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09051",
          "author": "<a href=\"http://arxiv.org/find/q-fin/1/au:+Cao_L/0/1/0/all/0/1\">Longbing Cao</a>",
          "description": "AI in finance broadly refers to the applications of AI techniques in\nfinancial businesses. This area has been lasting for decades with both classic\nand modern AI techniques applied to increasingly broader areas of finance,\neconomy and society. In contrast to either discussing the problems, aspects and\nopportunities of finance that have benefited from specific AI techniques and in\nparticular some new-generation AI and data science (AIDS) areas or reviewing\nthe progress of applying specific techniques to resolving certain financial\nproblems, this review offers a comprehensive and dense roadmap of the\noverwhelming challenges, techniques and opportunities of AI research in finance\nover the past decades. The landscapes and challenges of financial businesses\nand data are firstly outlined, followed by a comprehensive categorization and a\ndense overview of the decades of AI research in finance. We then structure and\nillustrate the data-driven analytics and learning of financial businesses and\ndata. The comparison, criticism and discussion of classic vs. modern AI\ntechniques for finance are followed. Lastly, open issues and opportunities\naddress future AI-empowered finance and finance-motivated AI research.",
          "link": "http://arxiv.org/abs/2107.09051",
          "publishedOn": "2021-07-21T02:01:35.316Z",
          "wordCount": 627,
          "title": "AI in Finance: Challenges, Techniques and Opportunities. (arXiv:2107.09051v1 [q-fin.CP])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09123",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jain_T/0/1/0/all/0/1\">Tanmay Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Avaneesh/0/1/0/all/0/1\">Avaneesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verma_R/0/1/0/all/0/1\">Rohit Verma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shorey_R/0/1/0/all/0/1\">Rajeev Shorey</a>",
          "description": "With the increasing reliance of users on smart devices, bringing essential\ncomputation at the edge has become a crucial requirement for any type of\nbusiness. Many such computations utilize Convolution Neural Networks (CNNs) to\nperform AI tasks, having high resource and computation requirements, that are\ninfeasible for edge devices. Splitting the CNN architecture to perform part of\nthe computation on edge and remaining on the cloud is an area of research that\nhas seen increasing interest in the field. In this paper, we assert that\nrunning CNNs between an edge device and the cloud is synonymous to solving a\nresource-constrained optimization problem that minimizes the latency and\nmaximizes resource utilization at the edge. We formulate a multi-objective\noptimization problem and propose the LMOS algorithm to achieve a Pareto\nefficient solution. Experiments done on real-world edge devices show that, LMOS\nensures feasible execution of different CNN models at the edge and also\nimproves upon existing state-of-the-art approaches.",
          "link": "http://arxiv.org/abs/2107.09123",
          "publishedOn": "2021-07-21T02:01:35.299Z",
          "wordCount": 598,
          "title": "Latency-Memory Optimized Splitting of Convolution Neural Networks for Resource Constrained Edge Devices. (arXiv:2107.09123v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09118",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Khaledyan_D/0/1/0/all/0/1\">Donya Khaledyan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tajally_A/0/1/0/all/0/1\">AmirReza Tajally</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sarkhosh_R/0/1/0/all/0/1\">Reza Sarkhosh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shamsi_A/0/1/0/all/0/1\">Afshar Shamsi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Asgharnezhad_H/0/1/0/all/0/1\">Hamzeh Asgharnezhad</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Khosravi_A/0/1/0/all/0/1\">Abbas Khosravi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nahavandi_S/0/1/0/all/0/1\">Saeid Nahavandi</a>",
          "description": "Deep learning (DL) models have received particular attention in medical\nimaging due to their promising pattern recognition capabilities. However, Deep\nNeural Networks (DNNs) require a huge amount of data, and because of the lack\nof sufficient data in this field, transfer learning can be a great solution.\nDNNs used for disease diagnosis meticulously concentrate on improving the\naccuracy of predictions without providing a figure about their confidence of\npredictions. Knowing how much a DNN model is confident in a computer-aided\ndiagnosis model is necessary for gaining clinicians' confidence and trust in\nDL-based solutions. To address this issue, this work presents three different\nmethods for quantifying uncertainties for skin cancer detection from images. It\nalso comprehensively evaluates and compares performance of these DNNs using\nnovel uncertainty-related metrics. The obtained results reveal that the\npredictive uncertainty estimation methods are capable of flagging risky and\nerroneous predictions with a high uncertainty estimate. We also demonstrate\nthat ensemble approaches are more reliable in capturing uncertainties through\ninference.",
          "link": "http://arxiv.org/abs/2107.09118",
          "publishedOn": "2021-07-21T02:01:35.272Z",
          "wordCount": 625,
          "title": "Confidence Aware Neural Networks for Skin Cancer Detection. (arXiv:2107.09118v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09070",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+List_F/0/1/0/all/0/1\">Florian List</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Rodd_N/0/1/0/all/0/1\">Nicholas L. Rodd</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Lewis_G/0/1/0/all/0/1\">Geraint F. Lewis</a>",
          "description": "The two leading hypotheses for the Galactic Center Excess (GCE) in the\n$\\textit{Fermi}$ data are an unresolved population of faint millisecond pulsars\n(MSPs) and dark-matter (DM) annihilation. The dichotomy between these\nexplanations is typically reflected by modeling them as two separate emission\ncomponents. However, point-sources (PSs) such as MSPs become statistically\ndegenerate with smooth Poisson emission in the ultra-faint limit (formally\nwhere each source is expected to contribute much less than one photon on\naverage), leading to an ambiguity that can render questions such as whether the\nemission is PS-like or Poissonian in nature ill-defined. We present a\nconceptually new approach that describes the PS and Poisson emission in a\nunified manner and only afterwards derives constraints on the Poissonian\ncomponent from the so obtained results. For the implementation of this\napproach, we leverage deep learning techniques, centered around a neural\nnetwork-based method for histogram regression that expresses uncertainties in\nterms of quantiles. We demonstrate that our method is robust against a number\nof systematics that have plagued previous approaches, in particular DM / PS\nmisattribution. In the $\\textit{Fermi}$ data, we find a faint GCE described by\na median source-count distribution (SCD) peaked at a flux of $\\sim4 \\times\n10^{-11} \\ \\text{counts} \\ \\text{cm}^{-2} \\ \\text{s}^{-1}$ (corresponding to\n$\\sim3 - 4$ expected counts per PS), which would require $N \\sim\n\\mathcal{O}(10^4)$ sources to explain the entire excess (median value $N =\n\\text{29,300}$ across the sky). Although faint, this SCD allows us to derive\nthe constraint $\\eta_P \\leq 66\\%$ for the Poissonian fraction of the GCE flux\n$\\eta_P$ at 95% confidence, suggesting that a substantial amount of the GCE\nflux is due to PSs.",
          "link": "http://arxiv.org/abs/2107.09070",
          "publishedOn": "2021-07-21T02:01:35.252Z",
          "wordCount": 759,
          "title": "Dim but not entirely dark: Extracting the Galactic Center Excess' source-count distribution with neural nets. (arXiv:2107.09070v1 [astro-ph.HE])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09082",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Veiga_M/0/1/0/all/0/1\">Maria Han Veiga</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Meng_X/0/1/0/all/0/1\">Xi Meng</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Gnedin_O/0/1/0/all/0/1\">Oleg Y. Gnedin</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Gnedin_N/0/1/0/all/0/1\">Nickolay Y. Gnedin</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Huan_X/0/1/0/all/0/1\">Xun Huan</a>",
          "description": "We describe a novel end-to-end approach using Machine Learning to reconstruct\nthe power spectrum of cosmological density perturbations at high redshift from\nobserved quasar spectra. State-of-the-art cosmological simulations of structure\nformation are used to generate a large synthetic dataset of line-of-sight\nabsorption spectra paired with 1-dimensional fluid quantities along the same\nline-of-sight, such as the total density of matter and the density of neutral\natomic hydrogen. With this dataset, we build a series of data-driven models to\npredict the power spectrum of total matter density. We are able to produce\nmodels which yield reconstruction to accuracy of about 1% for wavelengths $k\n\\leq 2 h Mpc^{-1}$, while the error increases at larger $k$. We show the size\nof data sample required to reach a particular error rate, giving a sense of how\nmuch data is necessary to reach a desired accuracy. This work provides a\nfoundation for developing methods to analyse very large upcoming datasets with\nthe next-generation observational facilities.",
          "link": "http://arxiv.org/abs/2107.09082",
          "publishedOn": "2021-07-21T02:01:35.213Z",
          "wordCount": 625,
          "title": "Reconstruction of the Density Power Spectrum from Quasar Spectra using Machine Learning. (arXiv:2107.09082v1 [astro-ph.CO])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09086",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Auddy_S/0/1/0/all/0/1\">Sayantan Auddy</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Dey_R/0/1/0/all/0/1\">Ramit Dey</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Lin_M/0/1/0/all/0/1\">Min-Kai Lin</a> (ASIAA, NCTS Physics Division), <a href=\"http://arxiv.org/find/astro-ph/1/au:+Hall_C/0/1/0/all/0/1\">Cassandra Hall</a>",
          "description": "The observed sub-structures, like annular gaps, in dust emissions from\nprotoplanetary disk, are often interpreted as signatures of embedded planets.\nFitting a model of planetary gaps to these observed features using customized\nsimulations or empirical relations can reveal the characteristics of the hidden\nplanets. However, customized fitting is often impractical owing to the\nincreasing sample size and the complexity of disk-planet interaction. In this\npaper we introduce the architecture of DPNNet-2.0, second in the series after\nDPNNet \\citep{aud20}, designed using a Convolutional Neural Network ( CNN, here\nspecifically ResNet50) for predicting exoplanet masses directly from simulated\nimages of protoplanetary disks hosting a single planet. DPNNet-2.0 additionally\nconsists of a multi-input framework that uses both a CNN and multi-layer\nperceptron (a class of artificial neural network) for processing image and disk\nparameters simultaneously. This enables DPNNet-2.0 to be trained using images\ndirectly, with the added option of considering disk parameters (disk\nviscosities, disk temperatures, disk surface density profiles, dust abundances,\nand particle Stokes numbers) generated from disk-planet hydrodynamic\nsimulations as inputs. This work provides the required framework and is the\nfirst step towards the use of computer vision (implementing CNN) to directly\nextract mass of an exoplanet from planetary gaps observed in dust-surface\ndensity maps by telescopes such as the Atacama Large (sub-)Millimeter Array.",
          "link": "http://arxiv.org/abs/2107.09086",
          "publishedOn": "2021-07-21T02:01:35.180Z",
          "wordCount": 681,
          "title": "DPNNet-2.0 Part I: Finding hidden planets from simulated images of protoplanetary disk gaps. (arXiv:2107.09086v1 [astro-ph.EP])"
        },
        {
          "id": "http://arxiv.org/abs/2107.09055",
          "author": "<a href=\"http://arxiv.org/find/q-fin/1/au:+Sonkiya_P/0/1/0/all/0/1\">Priyank Sonkiya</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Bajpai_V/0/1/0/all/0/1\">Vikas Bajpai</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Bansal_A/0/1/0/all/0/1\">Anukriti Bansal</a>",
          "description": "The stock market has been a popular topic of interest in the recent past. The\ngrowth in the inflation rate has compelled people to invest in the stock and\ncommodity markets and other areas rather than saving. Further, the ability of\nDeep Learning models to make predictions on the time series data has been\nproven time and again. Technical analysis on the stock market with the help of\ntechnical indicators has been the most common practice among traders and\ninvestors. One more aspect is the sentiment analysis - the emotion of the\ninvestors that shows the willingness to invest. A variety of techniques have\nbeen used by people around the globe involving basic Machine Learning and\nNeural Networks. Ranging from the basic linear regression to the advanced\nneural networks people have experimented with all possible techniques to\npredict the stock market. It's evident from recent events how news and\nheadlines affect the stock markets and cryptocurrencies. This paper proposes an\nensemble of state-of-the-art methods for predicting stock prices. Firstly\nsentiment analysis of the news and the headlines for the company Apple Inc,\nlisted on the NASDAQ is performed using a version of BERT, which is a\npre-trained transformer model by Google for Natural Language Processing (NLP).\nAfterward, a Generative Adversarial Network (GAN) predicts the stock price for\nApple Inc using the technical indicators, stock indexes of various countries,\nsome commodities, and historical prices along with the sentiment scores.\nComparison is done with baseline models like - Long Short Term Memory (LSTM),\nGated Recurrent Units (GRU), vanilla GAN, and Auto-Regressive Integrated Moving\nAverage (ARIMA) model.",
          "link": "http://arxiv.org/abs/2107.09055",
          "publishedOn": "2021-07-21T02:01:35.125Z",
          "wordCount": 699,
          "title": "Stock price prediction using BERT and GAN. (arXiv:2107.09055v1 [q-fin.ST])"
        },
        {
          "id": "http://arxiv.org/abs/2107.00088",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Hooten_S/0/1/0/all/0/1\">Sean Hooten</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Beausoleil_R/0/1/0/all/0/1\">Raymond G. Beausoleil</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Vaerenbergh_T/0/1/0/all/0/1\">Thomas Van Vaerenbergh</a>",
          "description": "We present a proof-of-concept technique for the inverse design of\nelectromagnetic devices motivated by the policy gradient method in\nreinforcement learning, named PHORCED (PHotonic Optimization using REINFORCE\nCriteria for Enhanced Design). This technique uses a probabilistic generative\nneural network interfaced with an electromagnetic solver to assist in the\ndesign of photonic devices, such as grating couplers. We show that PHORCED\nobtains better performing grating coupler designs than local gradient-based\ninverse design via the adjoint method, while potentially providing faster\nconvergence over competing state-of-the-art generative methods. Furthermore, we\nimplement transfer learning with PHORCED, demonstrating that a neural network\ntrained to optimize 8$^\\circ$ grating couplers can then be re-trained on\ngrating couplers with alternate scattering angles while requiring >$10\\times$\nfewer simulations than control cases.",
          "link": "http://arxiv.org/abs/2107.00088",
          "publishedOn": "2021-07-20T02:04:49.165Z",
          "wordCount": 591,
          "title": "Inverse Design of Grating Couplers Using the Policy Gradient Method from Reinforcement Learning. (arXiv:2107.00088v2 [physics.comp-ph] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.03920",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Dalmasso_N/0/1/0/all/0/1\">Niccol&#xf2; Dalmasso</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhao_D/0/1/0/all/0/1\">David Zhao</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Izbicki_R/0/1/0/all/0/1\">Rafael Izbicki</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lee_A/0/1/0/all/0/1\">Ann B. Lee</a>",
          "description": "Many areas of science make extensive use of computer simulators that\nimplicitly encode likelihood functions of complex systems. Classical\nstatistical methods are poorly suited for these so-called likelihood-free\ninference (LFI) settings, outside the asymptotic and low-dimensional regimes.\nAlthough new machine learning methods, such as normalizing flows, have\nrevolutionized the sample efficiency and capacity of LFI methods, it remains an\nopen question whether they produce reliable measures of uncertainty. This paper\npresents a statistical framework for LFI that unifies classical statistics with\nmodern machine learning to: (1) efficiently construct frequentist confidence\nsets and hypothesis tests with finite-sample guarantees of nominal coverage\n(type I error control) and power; (2) provide practical diagnostics for\nassessing empirical coverage over the entire parameter space. We refer to our\nframework as likelihood-free frequentist inference (LF2I). Any method that\nestimates a test statistic, like the likelihood ratio, can be plugged into our\nframework to create valid confidence sets and compute diagnostics, without\ncostly Monte Carlo samples at fixed parameter settings. In this work, we\nspecifically study the power of two test statistics (ACORE and BFF), which,\nrespectively, maximize versus integrate an odds function over the parameter\nspace. Our study offers multifaceted perspectives on the challenges in LF2I.",
          "link": "http://arxiv.org/abs/2107.03920",
          "publishedOn": "2021-07-20T02:04:49.148Z",
          "wordCount": 674,
          "title": "Likelihood-Free Frequentist Inference: Bridging Classical Statistics and Machine Learning in Simulation and Uncertainty Quantification. (arXiv:2107.03920v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.09110",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wagener_N/0/1/0/all/0/1\">Nolan Wagener</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boots_B/0/1/0/all/0/1\">Byron Boots</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1\">Ching-An Cheng</a>",
          "description": "Many sequential decision problems involve finding a policy that maximizes\ntotal reward while obeying safety constraints. Although much recent research\nhas focused on the development of safe reinforcement learning (RL) algorithms\nthat produce a safe policy after training, ensuring safety during training as\nwell remains an open problem. A fundamental challenge is performing exploration\nwhile still satisfying constraints in an unknown Markov decision process (MDP).\nIn this work, we address this problem for the chance-constrained setting. We\npropose a new algorithm, SAILR, that uses an intervention mechanism based on\nadvantage functions to keep the agent safe throughout training and optimizes\nthe agent's policy using off-the-shelf RL algorithms designed for unconstrained\nMDPs. Our method comes with strong guarantees on safety during both training\nand deployment (i.e., after training and without the intervention mechanism)\nand policy performance compared to the optimal safety-constrained policy. In\nour experiments, we show that SAILR violates constraints far less during\ntraining than standard safe RL and constrained MDP approaches and converges to\na well-performing policy that can be deployed safely without intervention. Our\ncode is available at https://github.com/nolanwagener/safe_rl.",
          "link": "http://arxiv.org/abs/2106.09110",
          "publishedOn": "2021-07-20T02:04:49.130Z",
          "wordCount": 653,
          "title": "Safe Reinforcement Learning Using Advantage-Based Intervention. (arXiv:2106.09110v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1908.01089",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_C/0/1/0/all/0/1\">Chirag Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balakrishnan_S/0/1/0/all/0/1\">Sivaraman Balakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramdas_A/0/1/0/all/0/1\">Aaditya Ramdas</a>",
          "description": "We derive bounds on the path length $\\zeta$ of gradient descent (GD) and\ngradient flow (GF) curves for various classes of smooth convex and nonconvex\nfunctions. Among other results, we prove that: (a) if the iterates are linearly\nconvergent with factor $(1-c)$, then $\\zeta$ is at most $\\mathcal{O}(1/c)$; (b)\nunder the Polyak-Kurdyka-Lojasiewicz (PKL) condition, $\\zeta$ is at most\n$\\mathcal{O}(\\sqrt{\\kappa})$, where $\\kappa$ is the condition number, and at\nleast $\\widetilde\\Omega(\\sqrt{d} \\wedge \\kappa^{1/4})$; (c) for quadratics,\n$\\zeta$ is $\\Theta(\\min\\{\\sqrt{d},\\sqrt{\\log \\kappa}\\})$ and in some cases can\nbe independent of $\\kappa$; (d) assuming just convexity, $\\zeta$ can be at most\n$2^{4d\\log d}$; (e) for separable quasiconvex functions, $\\zeta$ is\n${\\Theta}(\\sqrt{d})$. Thus, we advance current understanding of the properties\nof GD and GF curves beyond rates of convergence. We expect our techniques to\nfacilitate future studies for other algorithms.",
          "link": "http://arxiv.org/abs/1908.01089",
          "publishedOn": "2021-07-20T02:04:49.113Z",
          "wordCount": 637,
          "title": "Path Length Bounds for Gradient Descent and Flow. (arXiv:1908.01089v4 [cs.LG] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.04086",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bajaj_M/0/1/0/all/0/1\">Mohit Bajaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chu_L/0/1/0/all/0/1\">Lingyang Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_Z/0/1/0/all/0/1\">Zi Yu Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pei_J/0/1/0/all/0/1\">Jian Pei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lanjun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lam_P/0/1/0/all/0/1\">Peter Cho-Ho Lam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yong Zhang</a>",
          "description": "Massive deployment of Graph Neural Networks (GNNs) in high-stake applications\ngenerates a strong demand for explanations that are robust to noise and align\nwell with human intuition. Most existing methods generate explanations by\nidentifying a subgraph of an input graph that has a strong correlation with the\nprediction. These explanations are not robust to noise because independently\noptimizing the correlation for a single input can easily overfit noise.\nMoreover, they do not align well with human intuition because removing an\nidentified subgraph from an input graph does not necessarily change the\nprediction result. In this paper, we propose a novel method to generate robust\ncounterfactual explanations on GNNs by explicitly modelling the common decision\nlogic of GNNs on similar input graphs. Our explanations are naturally robust to\nnoise because they are produced from the common decision boundaries of a GNN\nthat govern the predictions of many similar input graphs. The explanations also\nalign well with human intuition because removing the set of edges identified by\nan explanation from the input graph changes the prediction significantly.\nExhaustive experiments on many public datasets demonstrate the superior\nperformance of our method.",
          "link": "http://arxiv.org/abs/2107.04086",
          "publishedOn": "2021-07-20T02:04:49.068Z",
          "wordCount": 645,
          "title": "Robust Counterfactual Explanations on Graph Neural Networks. (arXiv:2107.04086v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.04631",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Xu_F/0/1/0/all/0/1\">Fangcao Xu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sun_J/0/1/0/all/0/1\">Jian Sun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cervone_G/0/1/0/all/0/1\">Guido Cervone</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Salvador_M/0/1/0/all/0/1\">Mark Salvador</a>",
          "description": "Atmospheric correction is a fundamental task in remote sensing because\nobservations are taken either of the atmosphere or looking through the\natmosphere. Atmospheric correction errors can significantly alter the spectral\nsignature of the observations, and lead to invalid classifications or target\ndetection. This is even more crucial when working with hyperspectral data,\nwhere a precise measurement of spectral properties is required.\nState-of-the-art physics-based atmospheric correction approaches require\nextensive prior knowledge about sensor characteristics, collection geometry,\nand environmental characteristics of the scene being collected. These\napproaches are computationally expensive, prone to inaccuracy due to lack of\nsufficient environmental and collection information, and often impossible for\nreal-time applications. In this paper, a geometry-dependent hybrid neural\nnetwork is proposed for automatic atmospheric correction using multi-scan\nhyperspectral data collected from different geometries. The proposed network\ncan characterize the atmosphere without any additional meteorological data. A\ngrid-search method is also proposed to solve the temperature emissivity\nseparation problem. Results show that the proposed network has the capacity to\naccurately characterize the atmosphere and estimate target emissivity spectra\nwith a Mean Absolute Error (MAE) under 0.02 for 29 different materials. This\nsolution can lead to accurate atmospheric correction to improve target\ndetection for real time applications.",
          "link": "http://arxiv.org/abs/2107.04631",
          "publishedOn": "2021-07-20T02:04:49.049Z",
          "wordCount": 670,
          "title": "Ill-posed Surface Emissivity Retrieval from Multi-Geometry Hyperspectral Images using a Hybrid Deep Neural Network. (arXiv:2107.04631v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.05318",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Skandarani_Y/0/1/0/all/0/1\">Youssef Skandarani</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jodoin_P/0/1/0/all/0/1\">Pierre-Marc Jodoin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lalande_A/0/1/0/all/0/1\">Alain Lalande</a>",
          "description": "Generative Adversarial Networks (GANs) have become increasingly powerful,\ngenerating mind-blowing photorealistic images that mimic the content of\ndatasets they were trained to replicate. One recurrent theme in medical imaging\nis whether GANs can also be effective at generating workable medical data as\nthey are for generating realistic RGB images. In this paper, we perform a\nmulti-GAN and multi-application study to gauge the benefits of GANs in medical\nimaging. We tested various GAN architectures from basic DCGAN to more\nsophisticated style-based GANs on three medical imaging modalities and organs\nnamely : cardiac cine-MRI, liver CT and RGB retina images. GANs were trained on\nwell-known and widely utilized datasets from which their FID score were\ncomputed to measure the visual acuity of their generated images. We further\ntested their usefulness by measuring the segmentation accuracy of a U-Net\ntrained on these generated images.\n\nResults reveal that GANs are far from being equal as some are ill-suited for\nmedical imaging applications while others are much better off. The\ntop-performing GANs are capable of generating realistic-looking medical images\nby FID standards that can fool trained experts in a visual Turing test and\ncomply to some metrics. However, segmentation results suggests that no GAN is\ncapable of reproducing the full richness of a medical datasets.",
          "link": "http://arxiv.org/abs/2105.05318",
          "publishedOn": "2021-07-20T02:04:49.029Z",
          "wordCount": 674,
          "title": "GANs for Medical Image Synthesis: An Empirical Study. (arXiv:2105.05318v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.01319",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xing_Y/0/1/0/all/0/1\">Yifan Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_T/0/1/0/all/0/1\">Tong He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_T/0/1/0/all/0/1\">Tianjun Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yongxin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1\">Yuanjun Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_W/0/1/0/all/0/1\">Wei Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wipf_D/0/1/0/all/0/1\">David Wipf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1\">Stefano Soatto</a>",
          "description": "We propose a hierarchical graph neural network (GNN) model that learns how to\ncluster a set of images into an unknown number of identities using a training\nset of images annotated with labels belonging to a disjoint set of identities.\nOur hierarchical GNN uses a novel approach to merge connected components\npredicted at each level of the hierarchy to form a new graph at the next level.\nUnlike fully unsupervised hierarchical clustering, the choice of grouping and\ncomplexity criteria stems naturally from supervision in the training set. The\nresulting method, Hi-LANDER, achieves an average of 54% improvement in F-score\nand 8% increase in Normalized Mutual Information (NMI) relative to current\nGNN-based clustering algorithms. Additionally, state-of-the-art GNN-based\nmethods rely on separate models to predict linkage probabilities and node\ndensities as intermediate steps of the clustering process. In contrast, our\nunified framework achieves a seven-fold decrease in computational cost. We\nrelease our training and inference code at\nhttps://github.com/dmlc/dgl/tree/master/examples/pytorch/hilander.",
          "link": "http://arxiv.org/abs/2107.01319",
          "publishedOn": "2021-07-20T02:04:49.013Z",
          "wordCount": 624,
          "title": "Learning Hierarchical Graph Neural Networks for Image Clustering. (arXiv:2107.01319v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.10564",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Gupta_C/0/1/0/all/0/1\">Chirag Gupta</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Podkopaev_A/0/1/0/all/0/1\">Aleksandr Podkopaev</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ramdas_A/0/1/0/all/0/1\">Aaditya Ramdas</a>",
          "description": "We study three notions of uncertainty quantification -- calibration,\nconfidence intervals and prediction sets -- for binary classification in the\ndistribution-free setting, that is without making any distributional\nassumptions on the data. With a focus towards calibration, we establish a\n'tripod' of theorems that connect these three notions for score-based\nclassifiers. A direct implication is that distribution-free calibration is only\npossible, even asymptotically, using a scoring function whose level sets\npartition the feature space into at most countably many sets. Parametric\ncalibration schemes such as variants of Platt scaling do not satisfy this\nrequirement, while nonparametric schemes based on binning do. To close the\nloop, we derive distribution-free confidence intervals for binned probabilities\nfor both fixed-width and uniform-mass binning. As a consequence of our 'tripod'\ntheorems, these confidence intervals for binned probabilities lead to\ndistribution-free calibration. We also derive extensions to settings with\nstreaming data and covariate shift.",
          "link": "http://arxiv.org/abs/2006.10564",
          "publishedOn": "2021-07-20T02:04:48.995Z",
          "wordCount": 637,
          "title": "Distribution-free binary classification: prediction sets, confidence intervals and calibration. (arXiv:2006.10564v3 [stat.ML] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.03227",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Patel_D/0/1/0/all/0/1\">Deep Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_E/0/1/0/all/0/1\">Erin Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koul_A/0/1/0/all/0/1\">Anirudh Koul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganju_S/0/1/0/all/0/1\">Siddha Ganju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kasam_M/0/1/0/all/0/1\">Meher Anand Kasam</a>",
          "description": "Data imbalance is a ubiquitous problem in machine learning. In large scale\ncollected and annotated datasets, data imbalance is either mitigated manually\nby undersampling frequent classes and oversampling rare classes, or planned for\nwith imputation and augmentation techniques. In both cases balancing data\nrequires labels. In other words, only annotated data can be balanced.\nCollecting fully annotated datasets is challenging, especially for large scale\nsatellite systems such as the unlabeled NASA's 35 PB Earth Imagery dataset.\nAlthough the NASA Earth Imagery dataset is unlabeled, there are implicit\nproperties of the data source that we can rely on to hypothesize about its\nimbalance, such as distribution of land and water in the case of the Earth's\nimagery. We present a new iterative method to balance unlabeled data. Our\nmethod utilizes image embeddings as a proxy for image labels that can be used\nto balance data, and ultimately when trained increases overall accuracy.",
          "link": "http://arxiv.org/abs/2107.03227",
          "publishedOn": "2021-07-20T02:04:48.978Z",
          "wordCount": 618,
          "title": "Scalable Data Balancing for Unlabeled Satellite Imagery. (arXiv:2107.03227v1 [cs.CV] CROSS LISTED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.03311",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Burkhalter_L/0/1/0/all/0/1\">Lukas Burkhalter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lycklama_H/0/1/0/all/0/1\">Hidde Lycklama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Viand_A/0/1/0/all/0/1\">Alexander Viand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuchler_N/0/1/0/all/0/1\">Nicolas K&#xfc;chler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hithnawi_A/0/1/0/all/0/1\">Anwar Hithnawi</a>",
          "description": "Federated Learning is an emerging decentralized machine learning paradigm\nthat allows a large number of clients to train a joint model without the need\nto share their private data. Participants instead only share ephemeral updates\nnecessary to train the model. To ensure the confidentiality of the client\nupdates, Federated Learning systems employ secure aggregation; clients encrypt\ntheir gradient updates, and only the aggregated model is revealed to the\nserver. Achieving this level of data protection, however, presents new\nchallenges to the robustness of Federated Learning, i.e., the ability to\ntolerate failures and attacks. Unfortunately, in this setting, a malicious\nclient can now easily exert influence on the model behavior without being\ndetected. As Federated Learning is being deployed in practice in a range of\nsensitive applications, its robustness is growing in importance. In this paper,\nwe take a step towards understanding and improving the robustness of secure\nFederated Learning. We start this paper with a systematic study that evaluates\nand analyzes existing attack vectors and discusses potential defenses and\nassesses their effectiveness. We then present RoFL, a secure Federated Learning\nsystem that improves robustness against malicious clients through input checks\non the encrypted model updates. RoFL extends Federated Learning's secure\naggregation protocol to allow expressing a variety of properties and\nconstraints on model updates using zero-knowledge proofs. To enable RoFL to\nscale to typical Federated Learning settings, we introduce several ML and\ncryptographic optimizations specific to Federated Learning. We implement and\nevaluate a prototype of RoFL and show that realistic ML models can be trained\nin a reasonable time while improving robustness.",
          "link": "http://arxiv.org/abs/2107.03311",
          "publishedOn": "2021-07-20T02:04:48.935Z",
          "wordCount": 731,
          "title": "RoFL: Attestable Robustness for Secure Federated Learning. (arXiv:2107.03311v2 [cs.CR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.12627",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Huang_H/0/1/0/all/0/1\">Hsin-Yuan Huang</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Kueng_R/0/1/0/all/0/1\">Richard Kueng</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Torlai_G/0/1/0/all/0/1\">Giacomo Torlai</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Albert_V/0/1/0/all/0/1\">Victor V. Albert</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Preskill_J/0/1/0/all/0/1\">John Preskill</a>",
          "description": "Classical machine learning (ML) provides a potentially powerful approach to\nsolving challenging quantum many-body problems in physics and chemistry.\nHowever, the advantages of ML over more traditional methods have not been\nfirmly established. In this work, we prove that classical ML algorithms can\nefficiently predict ground state properties of gapped Hamiltonians in finite\nspatial dimensions, after learning from data obtained by measuring other\nHamiltonians in the same quantum phase of matter. In contrast, under widely\naccepted complexity theory assumptions, classical algorithms that do not learn\nfrom data cannot achieve the same guarantee. We also prove that classical ML\nalgorithms can efficiently classify a wide range of quantum phases of matter.\nOur arguments are based on the concept of a classical shadow, a succinct\nclassical description of a many-body quantum state that can be constructed in\nfeasible quantum experiments and be used to predict many properties of the\nstate. Extensive numerical experiments corroborate our theoretical results in a\nvariety of scenarios, including Rydberg atom systems, 2D random Heisenberg\nmodels, symmetry-protected topological phases, and topologically ordered\nphases.",
          "link": "http://arxiv.org/abs/2106.12627",
          "publishedOn": "2021-07-20T02:04:48.915Z",
          "wordCount": 642,
          "title": "Provably efficient machine learning for quantum many-body problems. (arXiv:2106.12627v2 [quant-ph] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.07851",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuqi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poskitt_C/0/1/0/all/0/1\">Christopher M. Poskitt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jun Sun</a>",
          "description": "Cyber-physical systems (CPSs) are widespread in critical domains, and\nsignificant damage can be caused if an attacker is able to modify the code of\ntheir programmable logic controllers (PLCs). Unfortunately, traditional\ntechniques for attesting code integrity (i.e. verifying that it has not been\nmodified) rely on firmware access or roots-of-trust, neither of which\nproprietary or legacy PLCs are likely to provide. In this paper, we propose a\npractical code integrity checking solution based on privacy-preserving black\nbox models that instead attest the input/output behaviour of PLC programs.\nUsing faithful offline copies of the PLC programs, we identify their most\nimportant inputs through an information flow analysis, execute them on multiple\ncombinations to collect data, then train neural networks able to predict PLC\noutputs (i.e. actuator commands) from their inputs. By exploiting the black box\nnature of the model, our solution maintains the privacy of the original PLC\ncode and does not assume that attackers are unaware of its presence. The trust\ninstead comes from the fact that it is extremely hard to attack the PLC code\nand neural networks at the same time and with consistent outcomes. We evaluated\nour approach on a modern six-stage water treatment plant testbed, finding that\nit could predict actuator states from PLC inputs with near-100% accuracy, and\nthus could detect all 120 effective code mutations that we subjected the PLCs\nto. Finally, we found that it is not practically possible to simultaneously\nmodify the PLC code and apply discreet adversarial noise to our attesters in a\nway that leads to consistent (mis-)predictions.",
          "link": "http://arxiv.org/abs/2106.07851",
          "publishedOn": "2021-07-20T02:04:48.896Z",
          "wordCount": 750,
          "title": "Code Integrity Attestation for PLCs using Black Box Neural Network Predictions. (arXiv:2106.07851v2 [cs.CR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.04764",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ibrahim_S/0/1/0/all/0/1\">Sara Hajj Ibrahim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nassar_M/0/1/0/all/0/1\">Mohamed Nassar</a>",
          "description": "Deep learning is a type of machine learning that adapts a deep hierarchy of\nconcepts. Deep learning classifiers link the most basic version of concepts at\nthe input layer to the most abstract version of concepts at the output layer,\nalso known as a class or label. However, once trained over a finite set of\nclasses, some deep learning models do not have the power to say that a given\ninput does not belong to any of the classes and simply cannot be linked.\nCorrectly invalidating the prediction of unrelated classes is a challenging\nproblem that has been tackled in many ways in the literature. Novelty detection\ngives deep learning the ability to output \"do not know\" for novel/unseen\nclasses. Still, no attention has been given to the security aspects of novelty\ndetection. In this paper, we consider the case study of abstraction-based\nnovelty detection and show that it is not robust against adversarial samples.\nMoreover, we show the feasibility of crafting adversarial samples that fool the\ndeep learning classifier and bypass the novelty detection monitoring at the\nsame time. In other words, these monitoring boxes are hackable. We demonstrate\nthat novelty detection itself ends up as an attack surface.",
          "link": "http://arxiv.org/abs/2107.04764",
          "publishedOn": "2021-07-20T02:04:48.877Z",
          "wordCount": 661,
          "title": "Hack The Box: Fooling Deep Learning Abstraction-Based Monitors. (arXiv:2107.04764v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.06981",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weiss_G/0/1/0/all/0/1\">Gail Weiss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldberg_Y/0/1/0/all/0/1\">Yoav Goldberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yahav_E/0/1/0/all/0/1\">Eran Yahav</a>",
          "description": "What is the computational model behind a Transformer? Where recurrent neural\nnetworks have direct parallels in finite state machines, allowing clear\ndiscussion and thought around architecture variants or trained models,\nTransformers have no such familiar parallel. In this paper we aim to change\nthat, proposing a computational model for the transformer-encoder in the form\nof a programming language. We map the basic components of a transformer-encoder\n-- attention and feed-forward computation -- into simple primitives, around\nwhich we form a programming language: the Restricted Access Sequence Processing\nLanguage (RASP). We show how RASP can be used to program solutions to tasks\nthat could conceivably be learned by a Transformer, and how a Transformer can\nbe trained to mimic a RASP solution. In particular, we provide RASP programs\nfor histograms, sorting, and Dyck-languages. We further use our model to relate\ntheir difficulty in terms of the number of required layers and attention heads:\nanalyzing a RASP program implies a maximum number of heads and layers necessary\nto encode a task in a transformer. Finally, we see how insights gained from our\nabstraction might be used to explain phenomena seen in recent works.",
          "link": "http://arxiv.org/abs/2106.06981",
          "publishedOn": "2021-07-20T02:04:48.833Z",
          "wordCount": 651,
          "title": "Thinking Like Transformers. (arXiv:2106.06981v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.05802",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+An_D/0/1/0/all/0/1\">Dongsheng An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_N/0/1/0/all/0/1\">Na Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_X/0/1/0/all/0/1\">Xianfeng Gu</a>",
          "description": "Optimal transport (OT) plays an essential role in various areas like machine\nlearning and deep learning. However, computing discrete optimal transport plan\nfor large scale problems with adequate accuracy and efficiency is still highly\nchallenging. Recently, methods based on the Sinkhorn algorithm add an entropy\nregularizer to the prime problem and get a trade off between efficiency and\naccuracy. In this paper, we propose a novel algorithm to further improve the\nefficiency and accuracy based on Nesterov's smoothing technique. Basically, the\nnon-smooth c-transform of the Kantorovich potential is approximated by the\nsmooth Log-Sum-Exp function, which finally smooths the original non-smooth\nKantorovich dual functional (energy). The smooth Kantorovich functional can be\noptimized by the fast proximal gradient algorithm (FISTA) efficiently.\nTheoretically, the computational complexity of the proposed method is given by\n$O(n^{\\frac{5}{2}} \\sqrt{\\log n} /\\epsilon)$, which is lower than that of the\nSinkhorn algorithm. Empirically, compared with the Sinkhorn algorithm, our\nexperimental results demonstrate that the proposed method achieves faster\nconvergence and better accuracy with the same parameter.",
          "link": "http://arxiv.org/abs/2104.05802",
          "publishedOn": "2021-07-20T02:04:48.814Z",
          "wordCount": 634,
          "title": "Efficient Optimal Transport Algorithm by Accelerated Gradient descent. (arXiv:2104.05802v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.01134",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pandey_P/0/1/0/all/0/1\">Prashant Pandey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raman_M/0/1/0/all/0/1\">Mrigank Raman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Varambally_S/0/1/0/all/0/1\">Sumanth Varambally</a>, <a href=\"http://arxiv.org/find/cs/1/au:+AP_P/0/1/0/all/0/1\">Prathosh AP</a>",
          "description": "Generalization of machine learning models trained on a set of source domains\non unseen target domains with different statistics, is a challenging problem.\nWhile many approaches have been proposed to solve this problem, they only\nutilize source data during training but do not take advantage of the fact that\na single target example is available at the time of inference. Motivated by\nthis, we propose a method that effectively uses the target sample during\ninference beyond mere classification. Our method has three components - (i) A\nlabel-preserving feature or metric transformation on source data such that the\nsource samples are clustered in accordance with their class irrespective of\ntheir domain (ii) A generative model trained on the these features (iii) A\nlabel-preserving projection of the target point on the source-feature manifold\nduring inference via solving an optimization problem on the input space of the\ngenerative model using the learned metric. Finally, the projected target is\nused in the classifier. Since the projected target feature comes from the\nsource manifold and has the same label as the real target by design, the\nclassifier is expected to perform better on it than the true target. We\ndemonstrate that our method outperforms the state-of-the-art Domain\nGeneralization methods on multiple datasets and tasks.",
          "link": "http://arxiv.org/abs/2103.01134",
          "publishedOn": "2021-07-20T02:04:48.795Z",
          "wordCount": 678,
          "title": "Domain Generalization via Inference-time Label-Preserving Target Projections. (arXiv:2103.01134v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.14399",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Macedo_D/0/1/0/all/0/1\">David Mac&#xea;do</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ludermir_T/0/1/0/all/0/1\">Teresa Ludermir</a>",
          "description": "Current out-of-distribution detection approaches usually present special\nrequirements (e.g., collecting outlier data and hyperparameter validation) and\nproduce side effects (classification accuracy drop and slow/inefficient\ninferences). Recently, entropic out-of-distribution detection has been proposed\nas a seamless approach (i.e., a solution that avoids all the previously\nmentioned drawbacks). The entropic out-of-distribution detection solution\ncomprises the IsoMax loss for training and the entropic score for\nout-of-distribution detection. The IsoMax loss works as a SoftMax loss drop-in\nreplacement because swapping the SoftMax loss with the IsoMax loss requires no\nchanges in the model's architecture or training procedures/hyperparameters. In\nthis paper, we propose to perform what we call an isometrization of the\ndistances used in the IsoMax loss. Additionally, we propose to replace the\nentropic score with the minimum distance score. Our experiments showed that\nthese simple modifications increase out-of-distribution detection performance\nwhile keeping the solution seamless. Code available at\n$\\href{https://github.com/dlmacedo/entropic-out-of-distribution-detection}{\\text{entropic\nout-of-distribution detection}}$.",
          "link": "http://arxiv.org/abs/2105.14399",
          "publishedOn": "2021-07-20T02:04:48.643Z",
          "wordCount": 638,
          "title": "Improving Entropic Out-of-Distribution Detection using Isometric Distances and the Minimum Distance Score. (arXiv:2105.14399v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08821",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Quanshi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_T/0/1/0/all/0/1\">Tian Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1\">Lixin Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1\">Zhanxing Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1\">Hang Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Ying Nian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1\">Jie Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hao Zhang</a>",
          "description": "This is the Proceedings of ICML 2021 Workshop on Theoretic Foundation,\nCriticism, and Application Trend of Explainable AI. Deep neural networks (DNNs)\nhave undoubtedly brought great success to a wide range of applications in\ncomputer vision, computational linguistics, and AI. However, foundational\nprinciples underlying the DNNs' success and their resilience to adversarial\nattacks are still largely missing. Interpreting and theorizing the internal\nmechanisms of DNNs becomes a compelling yet controversial topic. This workshop\npays a special interest in theoretic foundations, limitations, and new\napplication trends in the scope of XAI. These issues reflect new bottlenecks in\nthe future development of XAI.",
          "link": "http://arxiv.org/abs/2107.08821",
          "publishedOn": "2021-07-20T02:04:48.623Z",
          "wordCount": 567,
          "title": "Proceedings of ICML 2021 Workshop on Theoretic Foundation, Criticism, and Application Trend of Explainable AI. (arXiv:2107.08821v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08795",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hong_Z/0/1/0/all/0/1\">Zhenhou Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianzong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_X/0/1/0/all/0/1\">Xiaoyang Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jie Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1\">Chendong Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_J/0/1/0/all/0/1\">Jing Xiao</a>",
          "description": "Text to speech (TTS) is a crucial task for user interaction, but TTS model\ntraining relies on a sizable set of high-quality original datasets. Due to\nprivacy and security issues, the original datasets are usually unavailable\ndirectly. Recently, federated learning proposes a popular distributed machine\nlearning paradigm with an enhanced privacy protection mechanism. It offers a\npractical and secure framework for data owners to collaborate with others, thus\nobtaining a better global model trained on the larger dataset. However, due to\nthe high complexity of transformer models, the convergence process becomes slow\nand unstable in the federated learning setting. Besides, the transformer model\ntrained in federated learning is costly communication and limited computational\nspeed on clients, impeding its popularity. To deal with these challenges, we\npropose the federated dynamic transformer. On the one hand, the performance is\ngreatly improved comparing with the federated transformer, approaching\ncentralize-trained Transformer-TTS when increasing clients number. On the other\nhand, it achieves faster and more stable convergence in the training phase and\nsignificantly reduces communication time. Experiments on the LJSpeech dataset\nalso strongly prove our method's advantage.",
          "link": "http://arxiv.org/abs/2107.08795",
          "publishedOn": "2021-07-20T02:04:48.580Z",
          "wordCount": 624,
          "title": "Federated Learning with Dynamic Transformer for Text to Speech. (arXiv:2107.08795v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08835",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiuqi/0/1/0/all/0/1\">Jiuqi</a> (Elise) <a href=\"http://arxiv.org/find/cs/1/au:+Zhang/0/1/0/all/0/1\">Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1\">Di Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boulet_B/0/1/0/all/0/1\">Benoit Boulet</a>",
          "description": "With the rapid increase in the integration of renewable energy generation and\nthe wide adoption of various electric appliances, power grids are now faced\nwith more and more challenges. One prominent challenge is to implement\nefficient anomaly detection for different types of anomalous behaviors within\npower grids. These anomalous behaviors might be induced by unusual consumption\npatterns of the users, faulty grid infrastructures, outages, external\ncyberattacks, or energy fraud. Identifying such anomalies is of critical\nimportance for the reliable and efficient operation of modern power grids.\nVarious methods have been proposed for anomaly detection on power grid\ntime-series data. This paper presents a short survey of the recent advances in\nanomaly detection for power grid time-series data. Specifically, we first\noutline current research challenges in the power grid anomaly detection domain\nand further review the major anomaly detection approaches. Finally, we conclude\nthe survey by identifying the potential directions for future research.",
          "link": "http://arxiv.org/abs/2107.08835",
          "publishedOn": "2021-07-20T02:04:48.542Z",
          "wordCount": 602,
          "title": "Time Series Anomaly Detection for Smart Grids: A Survey. (arXiv:2107.08835v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08861",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yu Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wentao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jiawei Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_B/0/1/0/all/0/1\">Bolin Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yaliang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jingren Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Wentao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Ce Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_B/0/1/0/all/0/1\">Bin Cui</a>",
          "description": "End-to-end AutoML has attracted intensive interests from both academia and\nindustry, which automatically searches for ML pipelines in a space induced by\nfeature engineering, algorithm/model selection, and hyper-parameter tuning.\nExisting AutoML systems, however, suffer from scalability issues when applying\nto application domains with large, high-dimensional search spaces. We present\nVolcanoML, a scalable and extensible framework that facilitates systematic\nexploration of large AutoML search spaces. VolcanoML introduces and implements\nbasic building blocks that decompose a large search space into smaller ones,\nand allows users to utilize these building blocks to compose an execution plan\nfor the AutoML problem at hand. VolcanoML further supports a Volcano-style\nexecution model - akin to the one supported by modern database systems - to\nexecute the plan constructed. Our evaluation demonstrates that, not only does\nVolcanoML raise the level of expressiveness for search space decomposition in\nAutoML, it also leads to actual findings of decomposition strategies that are\nsignificantly more efficient than the ones employed by state-of-the-art AutoML\nsystems such as auto-sklearn.",
          "link": "http://arxiv.org/abs/2107.08861",
          "publishedOn": "2021-07-20T02:04:48.525Z",
          "wordCount": 616,
          "title": "VolcanoML: Speeding up End-to-End AutoML via Scalable Search Space Decomposition. (arXiv:2107.08861v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08888",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_M/0/1/0/all/0/1\">Mingqi Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pun_M/0/1/0/all/0/1\">Mon-on Pun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Dong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haojun Li</a>",
          "description": "Maintaining long-term exploration ability remains one of the challenges of\ndeep reinforcement learning (DRL). In practice, the reward shaping-based\napproaches are leveraged to provide intrinsic rewards for the agent to\nincentivize motivation. However, most existing IRS modules rely on attendant\nmodels or additional memory to record and analyze learning procedures, which\nleads to high computational complexity and low robustness. Moreover, they\noveremphasize the influence of a single state on exploration, which cannot\nevaluate the exploration performance from a global perspective. To tackle the\nproblem, state entropy-based methods are proposed to encourage the agent to\nvisit the state space more equitably. However, the estimation error and sample\ncomplexity are prohibitive when handling environments with high-dimensional\nobservation. In this paper, we introduce a novel metric entitled Jain's\nfairness index (JFI) to replace the entropy regularizer, which requires no\nadditional models or memory. In particular, JFI overcomes the vanishing\nintrinsic rewards problem and can be generalized into arbitrary tasks.\nFurthermore, we use a variational auto-encoder (VAE) model to capture the\nlife-long novelty of states. Finally, the global JFI score and local state\nnovelty are combined to form a multimodal intrinsic reward, controlling the\nexploration extent more precisely. Finally, extensive simulation results\ndemonstrate that our multimodal reward shaping (MMRS) method can achieve higher\nperformance in contrast to other benchmark schemes.",
          "link": "http://arxiv.org/abs/2107.08888",
          "publishedOn": "2021-07-20T02:04:48.508Z",
          "wordCount": 658,
          "title": "Multimodal Reward Shaping for Efficient Exploration in Reinforcement Learning. (arXiv:2107.08888v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08933",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Koutini_K/0/1/0/all/0/1\">Khaled Koutini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eghbal_zadeh_H/0/1/0/all/0/1\">Hamid Eghbal-zadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henkel_F/0/1/0/all/0/1\">Florian Henkel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schluter_J/0/1/0/all/0/1\">Jan Schl&#xfc;ter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Widmer_G/0/1/0/all/0/1\">Gerhard Widmer</a>",
          "description": "Convolutional Neural Networks (CNNs) have been dominating classification\ntasks in various domains, such as machine vision, machine listening, and\nnatural language processing. In machine listening, while generally exhibiting\nvery good generalization capabilities, CNNs are sensitive to the specific audio\nrecording device used, which has been recognized as a substantial problem in\nthe acoustic scene classification (DCASE) community. In this study, we\ninvestigate the relationship between over-parameterization of acoustic scene\nclassification models, and their resulting generalization abilities.\nSpecifically, we test scaling CNNs in width and depth, under different\nconditions. Our results indicate that increasing width improves generalization\nto unseen devices, even without an increase in the number of parameters.",
          "link": "http://arxiv.org/abs/2107.08933",
          "publishedOn": "2021-07-20T02:04:48.490Z",
          "wordCount": 562,
          "title": "Over-Parameterization and Generalization in Audio Classification. (arXiv:2107.08933v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08924",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Osband_I/0/1/0/all/0/1\">Ian Osband</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_Z/0/1/0/all/0/1\">Zheng Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asghari_M/0/1/0/all/0/1\">Mohammad Asghari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ibrahimi_M/0/1/0/all/0/1\">Morteza Ibrahimi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Xiyuan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_B/0/1/0/all/0/1\">Benjamin Van Roy</a>",
          "description": "We introduce the \\textit{epistemic neural network} (ENN) as an interface for\nuncertainty modeling in deep learning. All existing approaches to uncertainty\nmodeling can be expressed as ENNs, and any ENN can be identified with a\nBayesian neural network. However, this new perspective provides several\npromising directions for future research. Where prior work has developed\nprobabilistic inference tools for neural networks; we ask instead, `which\nneural networks are suitable as tools for probabilistic inference?'. We propose\na clear and simple metric for progress in ENNs: the KL-divergence with respect\nto a target distribution. We develop a computational testbed based on inference\nin a neural network Gaussian process and release our code as a benchmark at\n\\url{https://github.com/deepmind/enn}. We evaluate several canonical approaches\nto uncertainty modeling in deep learning, and find they vary greatly in their\nperformance. We provide insight to the sensitivity of these results and show\nthat our metric is highly correlated with performance in sequential decision\nproblems. Finally, we provide indications that new ENN architectures can\nimprove performance in both the statistical quality and computational cost.",
          "link": "http://arxiv.org/abs/2107.08924",
          "publishedOn": "2021-07-20T02:04:48.445Z",
          "wordCount": 612,
          "title": "Epistemic Neural Networks. (arXiv:2107.08924v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08849",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ntakouris_T/0/1/0/all/0/1\">Theodoros Ntakouris</a>",
          "description": "In this document, a neural network is employed in order to estimate the\nsolution of the initial value problem in the context of non linear\ntrajectories. Such trajectories can be subject to gravity, thrust, drag,\ncentrifugal force, temperature, ambient air density and pressure. First, we\ngenerate a grid of trajectory points given a specified uniform density as a\ndesign parameter and then we investigate the performance of a neural network in\na compression and inverse problem task: the network is trained to predict the\ninitial conditions of the dynamics model we used in the simulation, given a\ntarget point in space. We investigate this as a regression task, with error\npropagation in consideration. For target points, up to a radius of 2\nkilometers, the model is able to accurately predict the initial conditions of\nthe trajectories, with sub-meter deviation. This simulation-based training\nprocess and novel real-world evaluation method is capable of computing\ntrajectories of arbitrary dimensions.",
          "link": "http://arxiv.org/abs/2107.08849",
          "publishedOn": "2021-07-20T02:04:48.411Z",
          "wordCount": 604,
          "title": "Exploring the efficacy of neural networks for trajectory compression and the inverse problem. (arXiv:2107.08849v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08902",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bhatia_B/0/1/0/all/0/1\">Bhumika Bhatia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verma_A/0/1/0/all/0/1\">Anuj Verma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anjum/0/1/0/all/0/1\">Anjum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Katarya_R/0/1/0/all/0/1\">Rahul Katarya</a>",
          "description": "Cyberbullying is of extreme prevalence today. Online-hate comments, toxicity,\ncyberbullying amongst children and other vulnerable groups are only growing\nover online classes, and increased access to social platforms, especially post\nCOVID-19. It is paramount to detect and ensure minors' safety across social\nplatforms so that any violence or hate-crime is automatically detected and\nstrict action is taken against it. In our work, we explore binary\nclassification by using a combination of datasets from various social media\nplatforms that cover a wide range of cyberbullying such as sexism, racism,\nabusive, and hate-speech. We experiment through multiple models such as\nBi-LSTM, GloVe, state-of-the-art models like BERT, and apply a unique\npreprocessing technique by introducing a slang-abusive corpus, achieving a\nhigher precision in comparison to models without slang preprocessing.",
          "link": "http://arxiv.org/abs/2107.08902",
          "publishedOn": "2021-07-20T02:04:48.393Z",
          "wordCount": 626,
          "title": "Analysing Cyberbullying using Natural Language Processing by Understanding Jargon in Social Media. (arXiv:2107.08902v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08873",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1\">Guang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mu_K/0/1/0/all/0/1\">Ke Mu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_C/0/1/0/all/0/1\">Chunhe Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhijia Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_T/0/1/0/all/0/1\">Tierui Gong</a>",
          "description": "Federated learning is a widely used distributed deep learning framework that\nprotects the privacy of each client by exchanging model parameters rather than\nraw data. However, federated learning suffers from high communication costs, as\na considerable number of model parameters need to be transmitted many times\nduring the training process, making the approach inefficient, especially when\nthe communication network bandwidth is limited. This article proposes RingFed,\na novel framework to reduce communication overhead during the training process\nof federated learning. Rather than transmitting parameters between the center\nserver and each client, as in original federated learning, in the proposed\nRingFed, the updated parameters are transmitted between each client in turn,\nand only the final result is transmitted to the central server, thereby\nreducing the communication overhead substantially. After several local updates,\nclients first send their parameters to another proximal client, not to the\ncenter server directly, to preaggregate. Experiments on two different public\ndatasets show that RingFed has fast convergence, high model accuracy, and low\ncommunication cost.",
          "link": "http://arxiv.org/abs/2107.08873",
          "publishedOn": "2021-07-20T02:04:48.329Z",
          "wordCount": 609,
          "title": "RingFed: Reducing Communication Costs in Federated Learning on Non-IID Data. (arXiv:2107.08873v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08828",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singla_A/0/1/0/all/0/1\">Adish Singla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rafferty_A/0/1/0/all/0/1\">Anna N. Rafferty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radanovic_G/0/1/0/all/0/1\">Goran Radanovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heffernan_N/0/1/0/all/0/1\">Neil T. Heffernan</a>",
          "description": "This survey article has grown out of the RL4ED workshop organized by the\nauthors at the Educational Data Mining (EDM) 2021 conference. We organized this\nworkshop as part of a community-building effort to bring together researchers\nand practitioners interested in the broad areas of reinforcement learning (RL)\nand education (ED). This article aims to provide an overview of the workshop\nactivities and summarize the main research directions in the area of RL for ED.",
          "link": "http://arxiv.org/abs/2107.08828",
          "publishedOn": "2021-07-20T02:04:48.308Z",
          "wordCount": 509,
          "title": "Reinforcement Learning for Education: Opportunities and Challenges. (arXiv:2107.08828v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08787",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lu_Y/0/1/0/all/0/1\">Yichen Lu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fridlyand_J/0/1/0/all/0/1\">Jane Fridlyand</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tang_T/0/1/0/all/0/1\">Tiffany Tang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Qi_T/0/1/0/all/0/1\">Ting Qi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Simon_N/0/1/0/all/0/1\">Noah Simon</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Leng_N/0/1/0/all/0/1\">Ning Leng</a>",
          "description": "Finding translational biomarkers stands center stage of the future of\npersonalized medicine in healthcare. We observed notable challenges in\nidentifying robust biomarkers as some with great performance in one scenario\noften fail to perform well in new trials (e.g. different population,\nindications). With rapid development in the clinical trial world (e.g. assay,\ndisease definition), new trials very likely differ from legacy ones in many\nperspectives and in development of biomarkers this heterogeneity should be\nconsidered. In response, we recommend considering building in the heterogeneity\nwhen evaluating biomarkers. In this paper, we present one evaluation strategy\nby using leave-one-study-out (LOSO) in place of conventional cross-validation\n(cv) methods to account for the potential heterogeneity across trials used for\nbuilding and testing the biomarkers. To demonstrate the performance of K-fold\nvs LOSO cv in estimating the effect size of biomarkers, we leveraged data from\nclinical trials and simulation studies. In our assessment, LOSO cv provided a\nmore objective estimate of the future performance. This conclusion remained\ntrue across different evaluation metrics and different statistical methods.",
          "link": "http://arxiv.org/abs/2107.08787",
          "publishedOn": "2021-07-20T02:04:48.291Z",
          "wordCount": 633,
          "title": "The Future will be Different than Today: Model Evaluation Considerations when Developing Translational Clinical Biomarker. (arXiv:2107.08787v1 [stat.AP])"
        },
        {
          "id": "http://arxiv.org/abs/2008.01683",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Azzimonti_L/0/1/0/all/0/1\">Laura Azzimonti</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Corani_G/0/1/0/all/0/1\">Giorgio Corani</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Scutari_M/0/1/0/all/0/1\">Marco Scutari</a>",
          "description": "Score functions for learning the structure of Bayesian networks in the\nliterature assume that data are a homogeneous set of observations; whereas it\nis often the case that they comprise different related, but not homogeneous,\ndata sets collected in different ways. In this paper we propose a new Bayesian\nDirichlet score, which we call Bayesian Hierarchical Dirichlet (BHD). The\nproposed score is based on a hierarchical model that pools information across\ndata sets to learn a single encompassing network structure, while taking into\naccount the differences in their probabilistic structures. We derive a\nclosed-form expression for BHD using a variational approximation of the\nmarginal likelihood, we study the associated computational cost and we evaluate\nits performance using simulated data. We find that, when data comprise multiple\nrelated data sets, BHD outperforms the Bayesian Dirichlet equivalent uniform\n(BDeu) score in terms of reconstruction accuracy as measured by the Structural\nHamming distance, and that it is as accurate as BDeu when data are homogeneous.\nThis improvement is particularly clear when either the number of variables in\nthe network or the number of observations is large. Moreover, the estimated\nnetworks are sparser and therefore more interpretable than those obtained with\nBDeu thanks to a lower number of false positive arcs.",
          "link": "http://arxiv.org/abs/2008.01683",
          "publishedOn": "2021-07-20T02:04:47.806Z",
          "wordCount": 682,
          "title": "A Bayesian Hierarchical Score for Structure Learning from Related Data Sets. (arXiv:2008.01683v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.03980",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Takeuchi_K/0/1/0/all/0/1\">Koh Takeuchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nishida_R/0/1/0/all/0/1\">Ryo Nishida</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kashima_H/0/1/0/all/0/1\">Hisashi Kashima</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Onishi_M/0/1/0/all/0/1\">Masaki Onishi</a>",
          "description": "Crowd movement guidance has been a fascinating problem in various fields,\nsuch as easing traffic congestion in unusual events and evacuating people from\nan emergency-affected area. To grab the reins of crowds, there has been\nconsiderable demand for a decision support system that can answer a typical\nquestion: ``what will be the outcomes of each of the possible options in the\ncurrent situation. In this paper, we consider the problem of estimating the\neffects of crowd movement guidance from past data. To cope with limited amount\nof available data biased by past decision-makers, we leverage two recent\ntechniques in deep representation learning for spatial data analysis and causal\ninference. We use a spatial convolutional operator to extract effective spatial\nfeatures of crowds from a small amount of data and use balanced representation\nlearning based on the integral probability metrics to mitigate the selection\nbias and missing counterfactual outcomes. To evaluate the performance on\nestimating the treatment effects of possible guidance, we use a multi-agent\nsimulator to generate realistic data on evacuation scenarios in a crowded\ntheater, since there are no available datasets recording outcomes of all\npossible crowd movement guidance. The results of three experiments demonstrate\nthat our proposed method reduces the estimation error by at most 56% from\nstate-of-the-art methods.",
          "link": "http://arxiv.org/abs/2102.03980",
          "publishedOn": "2021-07-20T02:04:47.788Z",
          "wordCount": 685,
          "title": "Grab the Reins of Crowds: Estimating the Effects of Crowd Movement Guidance Using Causal Inference. (arXiv:2102.03980v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.00434",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Malach_E/0/1/0/all/0/1\">Eran Malach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yehudai_G/0/1/0/all/0/1\">Gilad Yehudai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shalev_Shwartz_S/0/1/0/all/0/1\">Shai Shalev-Shwartz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shamir_O/0/1/0/all/0/1\">Ohad Shamir</a>",
          "description": "Several recent works have shown separation results between deep neural\nnetworks, and hypothesis classes with inferior approximation capacity such as\nshallow networks or kernel classes. On the other hand, the fact that deep\nnetworks can efficiently express a target function does not mean that this\ntarget function can be learned efficiently by deep neural networks. In this\nwork we study the intricate connection between learnability and approximation\ncapacity. We show that learnability with deep networks of a target function\ndepends on the ability of simpler classes to approximate the target.\nSpecifically, we show that a necessary condition for a function to be learnable\nby gradient descent on deep neural networks is to be able to approximate the\nfunction, at least in a weak sense, with shallow neural networks. We also show\nthat a class of functions can be learned by an efficient statistical query\nalgorithm if and only if it can be approximated in a weak sense by some kernel\nclass. We give several examples of functions which demonstrate depth\nseparation, and conclude that they cannot be efficiently learned, even by a\nhypothesis class that can efficiently approximate them.",
          "link": "http://arxiv.org/abs/2102.00434",
          "publishedOn": "2021-07-20T02:04:47.732Z",
          "wordCount": 672,
          "title": "The Connection Between Approximation, Depth Separation and Learnability in Neural Networks. (arXiv:2102.00434v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.16336",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Goren_E/0/1/0/all/0/1\">Emily M. Goren</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Maitra_R/0/1/0/all/0/1\">Ranjan Maitra</a>",
          "description": "Partially recorded data are frequently encountered in many applications and\nusually clustered by first removing incomplete cases or features with missing\nvalues, or by imputing missing values, followed by application of a clustering\nalgorithm to the resulting altered dataset. Here, we develop clustering\nmethodology through a model-based approach using the marginal density for the\nobserved values, assuming a finite mixture model of multivariate $t$\ndistributions. We compare our approximate algorithm to the corresponding full\nexpectation-maximization (EM) approach that considers the missing values in the\nincomplete data set and makes a missing at random (MAR) assumption, as well as\ncase deletion and imputation methods. Since only the observed values are\nutilized, our approach is computationally more efficient than imputation or\nfull EM. Simulation studies demonstrate that our approach has favorable\nrecovery of the true cluster partition compared to case deletion and imputation\nunder various missingness mechanisms, and is at least competitive with the full\nEM approach, even when MAR assumptions are violated. Our methodology is\ndemonstrated on a problem of clustering gamma-ray bursts and is implemented at\nhttps://github.com/emilygoren/MixtClust.",
          "link": "http://arxiv.org/abs/2103.16336",
          "publishedOn": "2021-07-20T02:04:47.479Z",
          "wordCount": null,
          "title": "Model-based clustering of partial records. (arXiv:2103.16336v3 [stat.ME] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.04046",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ahfock_D/0/1/0/all/0/1\">Daniel Ahfock</a>, <a href=\"http://arxiv.org/find/stat/1/au:+McLachlan_G/0/1/0/all/0/1\">Geoffrey J. McLachlan</a>",
          "description": "There has been increasing attention to semi-supervised learning (SSL)\napproaches in machine learning to forming a classifier in situations where the\ntraining data for a classifier consists of a limited number of classified\nobservations but a much larger number of unclassified observations. This is\nbecause the procurement of classified data can be quite costly due to high\nacquisition costs and subsequent financial, time, and ethical issues that can\narise in attempts to provide the true class labels for the unclassified data\nthat have been acquired. We provide here a review of statistical SSL approaches\nto this problem, focussing on the recent result that a classifier formed from a\npartially classified sample can actually have smaller expected error rate than\nthat if the sample were completely classified.",
          "link": "http://arxiv.org/abs/2104.04046",
          "publishedOn": "2021-07-20T02:04:47.476Z",
          "wordCount": null,
          "title": "Semi-Supervised Learning of Classifiers from a Statistical Perspective: A Brief Review. (arXiv:2104.04046v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.07868",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Haibin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhiyong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Dong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hung-yi Lee</a>",
          "description": "Automatic speaker verification (ASV) is a well developed technology for\nbiometric identification, and has been ubiquitous implemented in\nsecurity-critic applications, such as banking and access control. However,\nprevious works have shown that ASV is under the radar of adversarial attacks,\nwhich are very similar to their original counterparts from human's perception,\nyet will manipulate the ASV render wrong prediction. Due to the very late\nemergence of adversarial attacks for ASV, effective countermeasures against\nthem are limited. Given that the security of ASV is of high priority, in this\nwork, we propose the idea of \"voting for the right answer\" to prevent risky\ndecisions of ASV in blind spot areas, by employing random sampling and voting.\nExperimental results show that our proposed method improves the robustness\nagainst both the limited-knowledge attackers by pulling the adversarial samples\nout of the blind spots, and the perfect-knowledge attackers by introducing\nrandomness and increasing the attackers' budgets.",
          "link": "http://arxiv.org/abs/2106.07868",
          "publishedOn": "2021-07-20T02:04:47.463Z",
          "wordCount": null,
          "title": "Voting for the right answer: Adversarial defense for speaker verification. (arXiv:2106.07868v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03723",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhuo_W/0/1/0/all/0/1\">Wei Zhuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_G/0/1/0/all/0/1\">Guang Tan</a>",
          "description": "We consider graph representation learning in a self-supervised manner. Graph\nneural networks (GNNs) use neighborhood aggregation as a core component that\nresults in feature smoothing among nodes in proximity. While successful in\nvarious prediction tasks, such a paradigm falls short of capturing nodes'\nsimilarities over a long distance, which proves to be important for\nhigh-quality learning. To tackle this problem, we strengthen the graph with two\nadditional graph views, in which nodes are directly linked to those with the\nmost similar features or local structures. Not restricted by connectivity in\nthe original graph, the generated views allow the model to enhance its\nexpressive power with new and complementary perspectives from which to look at\nthe relationship between nodes. Following a contrastive learning approach, we\npropose a method that aims to maximize the agreement between representations\nacross generated views and the original graph. We also propose a channel-level\ncontrast approach that greatly reduces computation cost, compared to the\ncommonly used node level contrast, which requires computation cost quadratic in\nthe number of nodes. Extensive experiments on seven assortative graphs and four\ndisassortative graphs demonstrate the effectiveness of our approach.",
          "link": "http://arxiv.org/abs/2106.03723",
          "publishedOn": "2021-07-20T02:04:47.461Z",
          "wordCount": null,
          "title": "Self-Supervised Graph Learning with Proximity-based Views and Channel Contrast. (arXiv:2106.03723v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.10360",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moreira_T/0/1/0/all/0/1\">T&#xfa;lio Marcondes Moreira</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Faria_J/0/1/0/all/0/1\">Jackson Geraldo de Faria Jr</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Melo_P/0/1/0/all/0/1\">Pedro O.S. Vaz de Melo</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Chaimowicz_L/0/1/0/all/0/1\">Luiz Chaimowicz</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Medeiros_Ribeiro_G/0/1/0/all/0/1\">Gilberto Medeiros-Ribeiro</a> (1) ((1) Universidade Federal de Minas Gerais, Belo Horizonte, Brazil)",
          "description": "Tidal range structures have been considered for large scale electricity\ngeneration for their potential ability to produce reasonable predictable energy\nwithout the emission of greenhouse gases. Once the main forcing components for\ndriving the tides have deterministic dynamics, the available energy in a given\ntidal power plant has been estimated, through analytical and numerical\noptimisation routines, as a mostly predictable event. This constraint imposes\nstate-of-art flexible operation methods to rely on tidal predictions\n(concurrent with measured data and up to a multiple of half-tidal cycles into\nthe future) to infer best operational strategies for tidal lagoons, with the\nadditional cost of requiring to run optimisation routines for every new tide.\nIn this paper, we propose a novel optimised operation of tidal lagoons with\nproximal policy optimisation through Unity ML-Agents. We compare this technique\nwith 6 different operation optimisation approaches (baselines) devised from the\nliterature, utilising the Swansea Bay Tidal Lagoon as a case study. We show\nthat our approach is successful in maximising energy generation through an\noptimised operational policy of turbines and sluices, yielding competitive\nresults with state-of-the-art methods of optimisation, regardless of test data\nused, requiring training once and performing real-time flexible control with\nmeasured ocean data only.",
          "link": "http://arxiv.org/abs/2106.10360",
          "publishedOn": "2021-07-20T02:04:47.421Z",
          "wordCount": null,
          "title": "Prediction-Free, Real-Time Flexible Control of Tidal Lagoons through Proximal Policy Optimisation: A Case Study for the Swansea Lagoon. (arXiv:2106.10360v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.04180",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hafez_Kolahi_H/0/1/0/all/0/1\">Hassan Hafez-Kolahi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moniri_B/0/1/0/all/0/1\">Behrad Moniri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kasaei_S/0/1/0/all/0/1\">Shohreh Kasaei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baghshah_M/0/1/0/all/0/1\">Mahdieh Soleymani Baghshah</a>",
          "description": "In parametric Bayesian learning, a prior is assumed on the parameter $W$\nwhich determines the distribution of samples. In this setting, Minimum Excess\nRisk (MER) is defined as the difference between the minimum expected loss\nachievable when learning from data and the minimum expected loss that could be\nachieved if $W$ was observed. In this paper, we build upon and extend the\nrecent results of (Xu & Raginsky, 2020) to analyze the MER in Bayesian learning\nand derive information-theoretic bounds on it. We formulate the problem as a\n(constrained) rate-distortion optimization and show how the solution can be\nbounded above and below by two other rate-distortion functions that are easier\nto study. The lower bound represents the minimum possible excess risk\nachievable by any process using $R$ bits of information from the parameter $W$.\nFor the upper bound, the optimization is further constrained to use $R$ bits\nfrom the training set, a setting which relates MER to information-theoretic\nbounds on the generalization gap in frequentist learning. We derive\ninformation-theoretic bounds on the difference between these upper and lower\nbounds and show that they can provide order-wise tight rates for MER under\ncertain conditions. This analysis gives more insight into the\ninformation-theoretic nature of Bayesian learning as well as providing novel\nbounds.",
          "link": "http://arxiv.org/abs/2105.04180",
          "publishedOn": "2021-07-20T02:04:47.413Z",
          "wordCount": null,
          "title": "Rate-Distortion Analysis of Minimum Excess Risk in Bayesian Learning. (arXiv:2105.04180v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.05556",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Ozcelik_R/0/1/0/all/0/1\">R&#x131;za &#xd6;z&#xe7;elik</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Bag_A/0/1/0/all/0/1\">Alperen Ba&#x11f;</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Atil_B/0/1/0/all/0/1\">Berk At&#x131;l</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ozgur_A/0/1/0/all/0/1\">Arzucan &#xd6;zg&#xfc;r</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ozkirimli_E/0/1/0/all/0/1\">Elif &#xd6;zk&#x131;r&#x131;ml&#x131;</a>",
          "description": "Motivation: Computational models that accurately identify high-affinity\nprotein-compound pairs can accelerate drug discovery pipelines. These models\naim to learn binding mechanics through drug-target interaction datasets and use\nthe learned knowledge for predicting the affinity of an input protein-compound\npair. However, the datasets they rely on bear misleading patterns that bias\nmodels towards memorizing dataset-specific biomolecule properties, instead of\nlearning binding mechanics. This results in models that struggle while\npredicting drug-target affinities (DTA), especially between de novo\nbiomolecules. Here we present DebiasedDTA, the first DTA model debiasing\napproach that avoids dataset biases in order to boost affinity prediction for\nnovel biomolecules. DebiasedDTA uses ensemble learning and sample weight\nadaptation for bias identification and avoidance and is applicable to almost\nall existing DTA prediction models. Results: The results show that DebiasedDTA\ncan boost models while predicting the interactions between novel biomolecules.\nKnown biomolecules also benefit from the performance improvement, especially\nwhen the test biomolecules are dissimilar to the training set. The experiments\nalso show that DebiasedDTA can augment DTA prediction models of different input\nand model structures and is able to avoid biases of different sources.\nAvailability and Implementation: The source code, the models, and the datasets\nare freely available for download at\nhttps://github.com/boun-tabi/debiaseddta-reproduce, implementation in Python3,\nand supported for Linux, MacOS and MS Windows. Contact:\narzucan.ozgur@boun.edu.tr, elif.ozkirimli@roche.com",
          "link": "http://arxiv.org/abs/2107.05556",
          "publishedOn": "2021-07-20T02:04:47.411Z",
          "wordCount": null,
          "title": "DebiasedDTA: Model Debiasing to Boost Drug-Target Affinity Prediction. (arXiv:2107.05556v2 [q-bio.QM] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.13061",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1\">Jiaqing Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ying_R/0/1/0/all/0/1\">Rex Ying</a>",
          "description": "Structural features are important features in graph datasets. However,\nalthough there are some correlation analysis of features based on covariance,\nthere is no relevant research on exploring structural feature correlation on\ngraphs with graph neural network based models. In this paper, we introduce\ngraph feature to feature (Fea2Fea) prediction pipelines in a low dimensional\nspace to explore some preliminary results on structural feature correlation,\nwhich is based on graph neural network. The results show that there exists high\ncorrelation between some of the structural features. A non-redundant feature\ncombination with initial node features, which is filtered by graph neural\nnetwork has improved its classification accuracy in some graph datasets. We\ncompare the difference between concatenation methods on connecting embeddings\nbetween features and show that the simplest is the best. We generalize on the\nsynthetic geometric graphs and certify the results on prediction difficulty\nbetween two structural features.",
          "link": "http://arxiv.org/abs/2106.13061",
          "publishedOn": "2021-07-20T02:04:47.406Z",
          "wordCount": null,
          "title": "Fea2Fea: Exploring Structural Feature Correlations via Graph Neural Networks. (arXiv:2106.13061v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.06419",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Wang_J/0/1/0/all/0/1\">Jinke Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lv_P/0/1/0/all/0/1\">Peiqing Lv</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_H/0/1/0/all/0/1\">Haiying Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shi_C/0/1/0/all/0/1\">Changfa Shi</a>",
          "description": "Background and objective: In this paper, a modified U-Net based framework is\npresented, which leverages techniques from Squeeze-and-Excitation (SE) block,\nAtrous Spatial Pyramid Pooling (ASPP) and residual learning for accurate and\nrobust liver CT segmentation, and the effectiveness of the proposed method was\ntested on two public datasets LiTS17 and SLiver07.\n\nMethods: A new network architecture called SAR-U-Net was designed. Firstly,\nthe SE block is introduced to adaptively extract image features after each\nconvolution in the U-Net encoder, while suppressing irrelevant regions, and\nhighlighting features of specific segmentation task; Secondly, ASPP was\nemployed to replace the transition layer and the output layer, and acquire\nmulti-scale image information via different receptive fields. Thirdly, to\nalleviate the degradation problem, the traditional convolution block was\nreplaced with the residual block and thus prompt the network to gain accuracy\nfrom considerably increased depth.\n\nResults: In the LiTS17 experiment, the mean values of Dice, VOE, RVD, ASD and\nMSD were 95.71, 9.52, -0.84, 1.54 and 29.14, respectively. Compared with other\nclosely related 2D-based models, the proposed method achieved the highest\naccuracy. In the experiment of the SLiver07, the mean values of Dice, VOE, RVD,\nASD and MSD were 97.31, 5.37, -1.08, 1.85 and 27.45, respectively. Compared\nwith other closely related models, the proposed method achieved the highest\nsegmentation accuracy except for the RVD.\n\nConclusion: The proposed model enables a great improvement on the accuracy\ncompared to 2D-based models, and its robustness in circumvent challenging\nproblems, such as small liver regions, discontinuous liver regions, and fuzzy\nliver boundaries, is also well demonstrated and validated.",
          "link": "http://arxiv.org/abs/2103.06419",
          "publishedOn": "2021-07-20T02:04:47.391Z",
          "wordCount": null,
          "title": "SAR-U-Net: squeeze-and-excitation block and atrous spatial pyramid pooling based residual U-Net for automatic liver segmentation in Computed Tomography. (arXiv:2103.06419v3 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.09022",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Chung_H/0/1/0/all/0/1\">Hyungjin Chung</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huh_J/0/1/0/all/0/1\">Jaeyoung Huh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kim_G/0/1/0/all/0/1\">Geon Kim</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Park_Y/0/1/0/all/0/1\">Yong Keun Park</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ye_J/0/1/0/all/0/1\">Jong Chul Ye</a>",
          "description": "Optical diffraction tomography (ODT) produces three dimensional distribution\nof refractive index (RI) by measuring scattering fields at various angles.\nAlthough the distribution of RI index is highly informative, due to the missing\ncone problem stemming from the limited-angle acquisition of holograms,\nreconstructions have very poor resolution along axial direction compared to the\nhorizontal imaging plane. To solve this issue, here we present a novel\nunsupervised deep learning framework, which learns the probability distribution\nof missing projection views through optimal transport driven cycleGAN.\nExperimental results show that missing cone artifact in ODT can be\nsignificantly resolved by the proposed method.",
          "link": "http://arxiv.org/abs/2103.09022",
          "publishedOn": "2021-07-20T02:04:47.260Z",
          "wordCount": null,
          "title": "Missing Cone Artifacts Removal in ODT using Unsupervised Deep Learning in Projection Domain. (arXiv:2103.09022v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.07830",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bu_Z/0/1/0/all/0/1\">Zhiqi Bu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hua Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_Q/0/1/0/all/0/1\">Qi Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_W/0/1/0/all/0/1\">Weijie J. Su</a>",
          "description": "In deep learning with differential privacy (DP), the neural network achieves\nthe privacy usually at the cost of slower convergence (and thus lower\nperformance) than its non-private counterpart. This work gives the first\nconvergence analysis of the DP deep learning, through the lens of training\ndynamics and the neural tangent kernel (NTK). Our convergence theory\nsuccessfully characterizes the effects of two key components in the DP\ntraining: the per-sample clipping (flat or layerwise) and the noise addition.\nOur analysis not only initiates a general principled framework to understand\nthe DP deep learning with any network architecture and loss function, but also\nmotivates a new clipping method -- the global clipping, that significantly\nimproves the convergence while preserving the same privacy guarantee as the\nexisting local clipping.\n\nIn terms of theoretical results, we establish the precise connection between\nthe per-sample clipping and NTK matrix. We show that in the gradient flow,\ni.e., with infinitesimal learning rate, the noise level of DP optimizers does\nnot affect the convergence. We prove that DP gradient descent (GD) with global\nclipping guarantees the monotone convergence to zero loss, which can be\nviolated by the existing DP-GD with local clipping. Notably, our analysis\nframework easily extends to other optimizers, e.g., DP-Adam. Empirically\nspeaking, DP optimizers equipped with global clipping perform strongly on a\nwide range of classification and regression tasks. In particular, our global\nclipping is surprisingly effective at learning calibrated classifiers, in\ncontrast to the existing DP classifiers which are oftentimes over-confident and\nunreliable. Implementation-wise, the new clipping can be realized by adding one\nline of code into the Opacus library.",
          "link": "http://arxiv.org/abs/2106.07830",
          "publishedOn": "2021-07-20T02:04:47.255Z",
          "wordCount": null,
          "title": "On the Convergence of Deep Learning with Differential Privacy. (arXiv:2106.07830v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09540",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiaolin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1\">Shuai Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1\">Kai Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_H/0/1/0/all/0/1\">Hao Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1\">Zejin Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yongji Wang</a>",
          "description": "The increasing concerns about data privacy and security drive an emerging\nfield of studying privacy-preserving machine learning from isolated data\nsources, i.e., federated learning. A class of federated learning, vertical\nfederated learning, where different parties hold different features for common\nusers, has a great potential of driving a more variety of business cooperation\namong enterprises in many fields. In machine learning, decision tree ensembles\nsuch as gradient boosting decision tree (GBDT) and random forest are widely\napplied powerful models with high interpretability and modeling efficiency.\nHowever, the interpretability is compromised in state-of-the-art vertical\nfederated learning frameworks such as SecureBoost with anonymous features to\navoid possible data breaches. To address this issue in the inference process,\nin this paper, we propose Fed-EINI to protect data privacy and allow the\ndisclosure of feature meaning by concealing decision paths with a\ncommunication-efficient secure computation method for inference outputs. The\nadvantages of Fed-EINI will be demonstrated through both theoretical analysis\nand extensive numerical results.",
          "link": "http://arxiv.org/abs/2105.09540",
          "publishedOn": "2021-07-20T02:04:47.253Z",
          "wordCount": null,
          "title": "Fed-EINI: An Efficient and Interpretable Inference Framework for Decision Tree Ensembles in Federated Learning. (arXiv:2105.09540v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.11793",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Huang_W/0/1/0/all/0/1\">Wanjun Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pan_X/0/1/0/all/0/1\">Xiang Pan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_M/0/1/0/all/0/1\">Minghua Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Low_S/0/1/0/all/0/1\">Steven H. Low</a>",
          "description": "AC optimal power flow (AC-OPF) problems need to be solved more frequently in\nthe future to maintain stable and economic power system operation. To tackle\nthis challenge, a deep neural network-based voltage-constrained approach\n(DeepOPF-V) is proposed to solve AC-OPF problems with high computational\nefficiency. Its unique design predicts voltages of all buses and then uses them\nto reconstruct the remaining variables without solving non-linear AC power flow\nequations. A fast post-processing process is developed to enforce the box\nconstraints. The effectiveness of DeepOPF-V is validated by simulations on IEEE\n118/300-bus systems and a 2000-bus test system. Compared with existing studies,\nDeepOPF-V achieves decent computation speedup up to four orders of magnitude\nand comparable performance in optimality gap and preserving the feasibility of\nthe solution.",
          "link": "http://arxiv.org/abs/2103.11793",
          "publishedOn": "2021-07-20T02:04:47.241Z",
          "wordCount": null,
          "title": "DeepOPF-V: Solving AC-OPF Problems Efficiently. (arXiv:2103.11793v2 [eess.SY] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.09663",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qi_M/0/1/0/all/0/1\">Meng Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mengxin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1\">Zuo-Jun Shen</a>",
          "description": "In this work, we propose a deep reinforcement learning (DRL) model for\nfinding a feasible solution for (mixed) integer programming (MIP) problems.\nFinding a feasible solution for MIP problems is critical because many\nsuccessful heuristics rely on a known initial feasible solution. However, it is\nin general NP-hard. Inspired by the feasibility pump (FP), a well-known\nheuristic for searching feasible MIP solutions, we develop a smart feasibility\npump (SFP) method using DRL. In addition to multi-layer perception (MLP), we\npropose a novel convolution neural network (CNN) structure for the policy\nnetwork to capture the hidden information of the constraint matrix of the MIP\nproblem. Numerical experiments on various problem instances show that SFP\nsignificantly outperforms the classic FP in terms of the number of steps\nrequired to reach the first feasible solution. Moreover, the CNN structure\nworks without the projection of the current solution as the input, which saves\nthe computational effort at each step of the FP algorithms to find projections.\nThis highlights the representational power of the CNN structure.",
          "link": "http://arxiv.org/abs/2102.09663",
          "publishedOn": "2021-07-20T02:04:47.225Z",
          "wordCount": null,
          "title": "Smart Feasibility Pump: Reinforcement Learning for (Mixed) Integer Programming. (arXiv:2102.09663v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.10818",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roth_A/0/1/0/all/0/1\">Aaron M. Roth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1\">Jing Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manocha_D/0/1/0/all/0/1\">Dinesh Manocha</a>",
          "description": "We present a novel sensor-based learning navigation algorithm to compute a\ncollision-free trajectory for a robot in dense and dynamic environments with\nmoving obstacles or targets. Our approach uses deep reinforcement\nlearning-based expert policy that is trained using a sim2real paradigm. In\norder to increase the reliability and handle the failure cases of the expert\npolicy, we combine with a policy extraction technique to transform the\nresulting policy into a decision tree format. The resulting decision tree has\nproperties which we use to analyze and modify the policy and improve\nperformance on navigation metrics including smoothness, frequency of\noscillation, frequency of immobilization, and obstruction of target. We are\nable to modify the policy to address these imperfections without retraining,\ncombining the learning power of deep learning with the control of\ndomain-specific algorithms. We highlight the benefits of our algorithm in\nsimulated environments and navigating a Clearpath Jackal robot among moving\npedestrians. (Videos at this url:\nhttps://gamma.umd.edu/researchdirections/xrl/navviper)",
          "link": "http://arxiv.org/abs/2104.10818",
          "publishedOn": "2021-07-20T02:04:47.223Z",
          "wordCount": null,
          "title": "XAI-N: Sensor-based Robot Navigation using Expert Policies and Decision Trees. (arXiv:2104.10818v2 [cs.RO] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.04075",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1\">Xueying Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1\">Yueming Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dou_Q/0/1/0/all/0/1\">Qi Dou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_J/0/1/0/all/0/1\">Jing Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heng_P/0/1/0/all/0/1\">Pheng-Ann Heng</a>",
          "description": "Automated surgical gesture recognition is of great importance in\nrobot-assisted minimally invasive surgery. However, existing methods assume\nthat training and testing data are from the same domain, which suffers from\nsevere performance degradation when a domain gap exists, such as the simulator\nand real robot. In this paper, we propose a novel unsupervised domain\nadaptation framework which can simultaneously transfer multi-modality\nknowledge, i.e., both kinematic and visual data, from simulator to real robot.\nIt remedies the domain gap with enhanced transferable features by using\ntemporal cues in videos, and inherent correlations in multi-modal towards\nrecognizing gesture. Specifically, we first propose an MDO-K to align\nkinematics, which exploits temporal continuity to transfer motion directions\nwith smaller gap rather than position values, relieving the adaptation burden.\nMoreover, we propose a KV-Relation-ATT to transfer the co-occurrence signals of\nkinematics and vision. Such features attended by correlation similarity are\nmore informative for enhancing domain-invariance of the model. Two feature\nalignment strategies benefit the model mutually during the end-to-end learning\nprocess. We extensively evaluate our method for gesture recognition using DESK\ndataset with peg transfer procedure. Results show that our approach recovers\nthe performance with great improvement gains, up to 12.91% in ACC and 20.16% in\nF1score without using any annotations in real robot.",
          "link": "http://arxiv.org/abs/2103.04075",
          "publishedOn": "2021-07-20T02:04:47.219Z",
          "wordCount": null,
          "title": "Domain Adaptive Robotic Gesture Recognition with Unsupervised Kinematic-Visual Data Alignment. (arXiv:2103.04075v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02246",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Michelle M. Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zitnik_M/0/1/0/all/0/1\">Marinka Zitnik</a>",
          "description": "Spatial context is central to understanding health and disease. Yet reference\nprotein interaction networks lack such contextualization, thereby limiting the\nstudy of where protein interactions likely occur in the human body and how they\nmay be altered in disease. Contextualized protein interactions could better\ncharacterize genes with disease-specific interactions and elucidate diseases'\nmanifestation in specific cell types. Here, we introduce AWARE, a graph neural\nmessage passing approach to inject cellular and tissue context into protein\nembeddings. AWARE optimizes for a multi-scale embedding space, whose structure\nreflects network topology at a single-cell resolution. We construct a\nmulti-scale network of the Human Cell Atlas and apply AWARE to learn protein,\ncell type, and tissue embeddings that uphold cell type and tissue hierarchies.\nWe demonstrate AWARE's utility on the novel task of predicting whether a\nprotein is altered in disease and where that association most likely manifests\nin the human body. To this end, AWARE outperforms generic embeddings without\ncontextual information by at least 12.5%, showing AWARE's potential to reveal\ncontext-dependent roles of proteins in disease.",
          "link": "http://arxiv.org/abs/2106.02246",
          "publishedOn": "2021-07-20T02:04:47.216Z",
          "wordCount": null,
          "title": "Deep Contextual Learners for Protein Networks. (arXiv:2106.02246v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.04184",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alam_F/0/1/0/all/0/1\">Firoj Alam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alam_T/0/1/0/all/0/1\">Tanvirul Alam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Imran_M/0/1/0/all/0/1\">Muhammad Imran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ofli_F/0/1/0/all/0/1\">Ferda Ofli</a>",
          "description": "Images shared on social media help crisis managers gain situational awareness\nand assess incurred damages, among other response tasks. As the volume and\nvelocity of such content are typically high, real-time image classification has\nbecome an urgent need for a faster disaster response. Recent advances in\ncomputer vision and deep neural networks have enabled the development of models\nfor real-time image classification for a number of tasks, including detecting\ncrisis incidents, filtering irrelevant images, classifying images into specific\nhumanitarian categories, and assessing the severity of the damage. To develop\nrobust real-time models, it is necessary to understand the capability of the\npublicly available pre-trained models for these tasks, which remains to be\nunder-explored in the crisis informatics literature. In this study, we address\nsuch limitations by investigating ten different network architectures for four\ndifferent tasks using the largest publicly available datasets for these tasks.\nWe also explore various data augmentation strategies, semi-supervised\ntechniques, and a multitask learning setup. In our extensive experiments, we\nachieve promising results.",
          "link": "http://arxiv.org/abs/2104.04184",
          "publishedOn": "2021-07-20T02:04:47.190Z",
          "wordCount": null,
          "title": "Robust Training of Social Media Image Classification Models for Rapid Disaster Response. (arXiv:2104.04184v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.00502",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1\">Zuowei Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Haizhao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shijun Zhang</a>",
          "description": "This paper concentrates on the approximation power of deep feed-forward\nneural networks in terms of width and depth. It is proved by construction that\nReLU networks with width $\\mathcal{O}\\big(\\max\\{d\\lfloor N^{1/d}\\rfloor,\\,\nN+2\\}\\big)$ and depth $\\mathcal{O}(L)$ can approximate a H\\\"older continuous\nfunction on $[0,1]^d$ with an approximation rate\n$\\mathcal{O}\\big(\\lambda\\sqrt{d} (N^2L^2\\ln N)^{-\\alpha/d}\\big)$, where\n$\\alpha\\in (0,1]$ and $\\lambda>0$ are H\\\"older order and constant,\nrespectively. Such a rate is optimal up to a constant in terms of width and\ndepth separately, while existing results are only nearly optimal without the\nlogarithmic factor in the approximation rate. More generally, for an arbitrary\ncontinuous function $f$ on $[0,1]^d$, the approximation rate becomes\n$\\mathcal{O}\\big(\\,\\sqrt{d}\\,\\omega_f\\big( (N^2L^2\\ln N)^{-1/d}\\big)\\,\\big)$,\nwhere $\\omega_f(\\cdot)$ is the modulus of continuity. We also extend our\nanalysis to any continuous function $f$ on a bounded set. Particularly, if ReLU\nnetworks with depth $31$ and width $\\mathcal{O}(N)$ are used to approximate\none-dimensional Lipschitz continuous functions on $[0,1]$ with a Lipschitz\nconstant $\\lambda>0$, the approximation rate in terms of the total number of\nparameters, $W=\\mathcal{O}(N^2)$, becomes $\\mathcal{O}(\\tfrac{\\lambda}{W\\ln\nW})$, which has not been discovered in the literature for fixed-depth ReLU\nnetworks.",
          "link": "http://arxiv.org/abs/2103.00502",
          "publishedOn": "2021-07-20T02:04:47.189Z",
          "wordCount": null,
          "title": "Optimal Approximation Rate of ReLU Networks in terms of Width and Depth. (arXiv:2103.00502v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.12534",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Kim_J/0/1/0/all/0/1\">Joonho Kim</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Oz_Y/0/1/0/all/0/1\">Yaron Oz</a>",
          "description": "We consider information spreading measures in randomly initialized\nvariational quantum circuits and introduce entanglement diagnostics for\nefficient variational quantum/classical computations. We establish a robust\nconnection between entanglement measures and optimization accuracy by solving\ntwo eigensolver problems for Ising Hamiltonians with nearest-neighbor and\nlong-range spin interactions. As the circuit depth affects the average\nentanglement of random circuit states, the entanglement diagnostics can\nidentify a high-performing depth range for optimization tasks encoded in local\nHamiltonians. We argue, based on an eigensolver problem for the\nSachdev-Ye-Kitaev model, that entanglement alone is insufficient as a\ndiagnostic to the approximation of volume-law entangled target states and that\na large number of circuit parameters is needed for such an optimization task.",
          "link": "http://arxiv.org/abs/2102.12534",
          "publishedOn": "2021-07-20T02:04:47.181Z",
          "wordCount": null,
          "title": "Entanglement Diagnostics for Efficient Quantum Computation. (arXiv:2102.12534v2 [quant-ph] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.02503",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1\">Kaiyang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Ziwei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1\">Yu Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_T/0/1/0/all/0/1\">Tao Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Loy_C/0/1/0/all/0/1\">Chen Change Loy</a>",
          "description": "Generalization to out-of-distribution (OOD) data is a capability natural to\nhumans yet challenging for machines to reproduce. This is because most learning\nalgorithms strongly rely on the i.i.d.~assumption on source/target data, which\nis often violated in practice due to domain shift. Domain generalization (DG)\naims to achieve OOD generalization by using only source data for model\nlearning. Since first introduced in 2011, research in DG has made great\nprogresses. In particular, intensive research in this topic has led to a broad\nspectrum of methodologies, e.g., those based on domain alignment,\nmeta-learning, data augmentation, or ensemble learning, just to name a few; and\nhas covered various vision applications such as object recognition,\nsegmentation, action recognition, and person re-identification. In this paper,\nfor the first time a comprehensive literature review is provided to summarize\nthe developments in DG for computer vision over the past decade. Specifically,\nwe first cover the background by formally defining DG and relating it to other\nresearch fields like domain adaptation and transfer learning. Second, we\nconduct a thorough review into existing methods and present a categorization\nbased on their methodologies and motivations. Finally, we conclude this survey\nwith insights and discussions on future research directions.",
          "link": "http://arxiv.org/abs/2103.02503",
          "publishedOn": "2021-07-20T02:04:47.181Z",
          "wordCount": null,
          "title": "Domain Generalization in Vision: A Survey. (arXiv:2103.02503v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1911.05461",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mello_R/0/1/0/all/0/1\">Rodrigo Fernandes de Mello</a>",
          "description": "The Statistical Learning Theory (SLT) provides the foundation to ensure that\na supervised algorithm generalizes the mapping $f: \\mathcal{X} \\to \\mathcal{Y}$\ngiven $f$ is selected from its search space bias $\\mathcal{F}$. SLT depends on\nthe Shattering coefficient function $\\mathcal{N}(\\mathcal{F},n)$ to upper bound\nthe empirical risk minimization principle, from which one can estimate the\nnecessary training sample size to ensure the probabilistic learning convergence\nand, most importantly, the characterization of the capacity of $\\mathcal{F}$,\nincluding its underfitting and overfitting abilities while addressing specific\ntarget problems. However, the analytical solution of the Shattering coefficient\nis still an open problem since the first studies by Vapnik and Chervonenkis in\n$1962$, which we address on specific datasets, in this paper, by employing\nequivalence relations from Topology, data separability results by Har-Peled and\nJones, and combinatorics. Our approach computes the Shattering coefficient for\nboth binary and multi-class datasets, leading to the following additional\ncontributions: (i) the estimation of the required number of hyperplanes in the\nworst and best-case classification scenarios and the respective $\\Omega$ and\n$O$ complexities; (ii) the estimation of the training sample sizes required to\nensure supervised learning; and (iii) the comparison of dataset embeddings,\nonce they (re)organize samples into some new space configuration. All results\nintroduced and discussed along this paper are supported by the R package\nshattering (https://cran.r-project.org/web/packages/shattering).",
          "link": "http://arxiv.org/abs/1911.05461",
          "publishedOn": "2021-07-20T02:04:47.162Z",
          "wordCount": null,
          "title": "On the Complexity of Labeled Datasets. (arXiv:1911.05461v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.15728",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1\">Hang Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suarez_Paniagua_V/0/1/0/all/0/1\">V&#xed;ctor Su&#xe1;rez-Paniagua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Whiteley_W/0/1/0/all/0/1\">William Whiteley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Honghan Wu</a>",
          "description": "Diagnostic or procedural coding of clinical notes aims to derive a coded\nsummary of disease-related information about patients. Such coding is usually\ndone manually in hospitals but could potentially be automated to improve the\nefficiency and accuracy of medical coding. Recent studies on deep learning for\nautomated medical coding achieved promising performances. However, the\nexplainability of these models is usually poor, preventing them to be used\nconfidently in supporting clinical practice. Another limitation is that these\nmodels mostly assume independence among labels, ignoring the complex\ncorrelation among medical codes which can potentially be exploited to improve\nthe performance. We propose a Hierarchical Label-wise Attention Network (HLAN),\nwhich aimed to interpret the model by quantifying importance (as attention\nweights) of words and sentences related to each of the labels. Secondly, we\npropose to enhance the major deep learning models with a label embedding (LE)\ninitialisation approach, which learns a dense, continuous vector representation\nand then injects the representation into the final layers and the label-wise\nattention layers in the models. We evaluated the methods using three settings\non the MIMIC-III discharge summaries: full codes, top-50 codes, and the UK NHS\nCOVID-19 shielding codes. Experiments were conducted to compare HLAN and LE\ninitialisation to the state-of-the-art neural network based methods. HLAN\nachieved the best Micro-level AUC and $F_1$ on the top-50 code prediction and\ncomparable results on the NHS COVID-19 shielding code prediction to other\nmodels. By highlighting the most salient words and sentences for each label,\nHLAN showed more meaningful and comprehensive model interpretation compared to\nits downgraded baselines and the CNN-based models. LE initialisation\nconsistently boosted most deep learning models for automated medical coding.",
          "link": "http://arxiv.org/abs/2010.15728",
          "publishedOn": "2021-07-20T02:04:47.162Z",
          "wordCount": null,
          "title": "Explainable Automated Coding of Clinical Notes using Hierarchical Label-wise Attention Networks and Label Embedding Initialisation. (arXiv:2010.15728v4 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.07545",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wadia_N/0/1/0/all/0/1\">Neha S. Wadia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duckworth_D/0/1/0/all/0/1\">Daniel Duckworth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schoenholz_S/0/1/0/all/0/1\">Samuel S. Schoenholz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dyer_E/0/1/0/all/0/1\">Ethan Dyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sohl_Dickstein_J/0/1/0/all/0/1\">Jascha Sohl-Dickstein</a>",
          "description": "Machine learning is predicated on the concept of generalization: a model\nachieving low error on a sufficiently large training set should also perform\nwell on novel samples from the same distribution. We show that both data\nwhitening and second order optimization can harm or entirely prevent\ngeneralization. In general, model training harnesses information contained in\nthe sample-sample second moment matrix of a dataset. For a general class of\nmodels, namely models with a fully connected first layer, we prove that the\ninformation contained in this matrix is the only information which can be used\nto generalize. Models trained using whitened data, or with certain second order\noptimization schemes, have less access to this information, resulting in\nreduced or nonexistent generalization ability. We experimentally verify these\npredictions for several architectures, and further demonstrate that\ngeneralization continues to be harmed even when theoretical requirements are\nrelaxed. However, we also show experimentally that regularized second order\noptimization can provide a practical tradeoff, where training is accelerated\nbut less information is lost, and generalization can in some circumstances even\nimprove.",
          "link": "http://arxiv.org/abs/2008.07545",
          "publishedOn": "2021-07-20T02:04:47.161Z",
          "wordCount": null,
          "title": "Whitening and second order optimization both make information in the dataset unusable during training, and can reduce or prevent generalization. (arXiv:2008.07545v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.09830",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Colas_C/0/1/0/all/0/1\">C&#xe9;dric Colas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karch_T/0/1/0/all/0/1\">Tristan Karch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sigaud_O/0/1/0/all/0/1\">Olivier Sigaud</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oudeyer_P/0/1/0/all/0/1\">Pierre-Yves Oudeyer</a>",
          "description": "Building autonomous machines that can explore open-ended environments,\ndiscover possible interactions and autonomously build repertoires of skills is\na general objective of artificial intelligence. Developmental approaches argue\nthat this can only be achieved by autonomous and intrinsically motivated\nlearning agents that can generate, select and learn to solve their own\nproblems. In recent years, we have seen a convergence of developmental\napproaches, and developmental robotics in particular, with deep reinforcement\nlearning (RL) methods, forming the new domain of developmental machine\nlearning. Within this new domain, we review here a set of methods where deep RL\nalgorithms are trained to tackle the developmental robotics problem of the\nautonomous acquisition of open-ended repertoires of skills. Intrinsically\nmotivated goal-conditioned RL algorithms train agents to learn to represent,\ngenerate and pursue their own goals. The self-generation of goals requires the\nlearning of compact goal encodings as well as their associated goal-achievement\nfunctions, which results in new challenges compared to traditional RL\nalgorithms designed to tackle pre-defined sets of goals using external reward\nsignals. This paper proposes a typology of these methods at the intersection of\ndeep RL and developmental approaches, surveys recent approaches and discusses\nfuture avenues.",
          "link": "http://arxiv.org/abs/2012.09830",
          "publishedOn": "2021-07-20T02:04:47.161Z",
          "wordCount": null,
          "title": "Intrinsically Motivated Goal-Conditioned Reinforcement Learning: a Short Survey. (arXiv:2012.09830v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.05791",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rojas_J/0/1/0/all/0/1\">Junior Rojas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sifakis_E/0/1/0/all/0/1\">Eftychios Sifakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kavan_L/0/1/0/all/0/1\">Ladislav Kavan</a>",
          "description": "We present a differentiable soft-body physics simulator that can be composed\nwith neural networks as a differentiable layer. In contrast to other\ndifferentiable physics approaches that use explicit forward models to define\nstate transitions, we focus on implicit state transitions defined via function\nminimization. Implicit state transitions appear in implicit numerical\nintegration methods, which offer the benefits of large time steps and excellent\nnumerical stability, but require a special treatment to achieve\ndifferentiability due to the absence of an explicit differentiable forward\npass. In contrast to other implicit differentiation approaches that require\nexplicit formulas for the force function and the force Jacobian matrix, we\npresent an energy-based approach that allows us to compute these derivatives\nautomatically and in a matrix-free fashion via reverse-mode automatic\ndifferentiation. This allows for more flexibility and productivity when\ndefining physical models and is particularly important in the context of neural\nnetwork training, which often relies on reverse-mode automatic differentiation\n(backpropagation). We demonstrate the effectiveness of our differentiable\nsimulator in policy optimization for locomotion tasks and show that it achieves\nbetter sample efficiency than model-free reinforcement learning.",
          "link": "http://arxiv.org/abs/2102.05791",
          "publishedOn": "2021-07-20T02:04:47.160Z",
          "wordCount": null,
          "title": "Differentiable Implicit Soft-Body Physics. (arXiv:2102.05791v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08925",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Martin_C/0/1/0/all/0/1\">Christoph Martin</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Sharafi_N/0/1/0/all/0/1\">Nahal Sharafi</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Hallerberg_S/0/1/0/all/0/1\">Sarah Hallerberg</a>",
          "description": "Covariant Lyapunov vectors (CLVs) characterize the directions along which\nperturbations in dynamical systems grow. They have also been studied as\npotential predictors of critical transitions and extreme events. For many\napplications, it is, however, necessary to estimate the vectors from data since\nmodel equations are unknown for many interesting phenomena. We propose a novel\nmethod for estimating CLVs based on data records without knowing the underlying\nequations of the system which is suitable also for high-dimensional data and\ncomputationally inexpensive. We demonstrate that this purely data-driven\napproach can accurately estimate CLVs from data records generated by chaotic\ndynamical systems of dimension 128 and multiple lower-dimensional systems and\nthus provides the foundation for numerous future applications in data-analysis\nand data-based predictions.",
          "link": "http://arxiv.org/abs/2107.08925",
          "publishedOn": "2021-07-20T02:04:47.152Z",
          "wordCount": null,
          "title": "Estimating covariant Lyapunov vectors from data. (arXiv:2107.08925v1 [physics.data-an])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08792",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kong_K/0/1/0/all/0/1\">Kyeongbo Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1\">Kyunghun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_W/0/1/0/all/0/1\">Woo-Jin Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_S/0/1/0/all/0/1\">Suk-Ju Kang</a>",
          "description": "Conditional generative adversarial networks (cGANs) have demonstrated\nremarkable success due to their class-wise controllability and superior quality\nfor complex generation tasks. Typical cGANs solve the joint distribution\nmatching problem by decomposing two easier sub-problems: marginal matching and\nconditional matching. From our toy experiments, we found that it is the best to\napply only conditional matching to certain samples due to the content-aware\noptimization of the discriminator. This paper proposes a simple (a few lines of\ncode) but effective training methodology, selective focusing learning, which\nenforces the discriminator and generator to learn easy samples of each class\nrapidly while maintaining diversity. Our key idea is to selectively apply\nconditional and joint matching for the data in each mini-batch. We conducted\nexperiments on recent cGAN variants in ImageNet (64x64 and 128x128), CIFAR-10,\nand CIFAR-100 datasets, and improved the performance significantly (up to\n35.18% in terms of FID) without sacrificing diversity.",
          "link": "http://arxiv.org/abs/2107.08792",
          "publishedOn": "2021-07-20T02:04:47.039Z",
          "wordCount": null,
          "title": "Selective Focusing Learning in Conditional GANs. (arXiv:2107.08792v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08909",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Miura_T/0/1/0/all/0/1\">Takayuki Miura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasegawa_S/0/1/0/all/0/1\">Satoshi Hasegawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shibahara_T/0/1/0/all/0/1\">Toshiki Shibahara</a>",
          "description": "The advance of explainable artificial intelligence, which provides reasons\nfor its predictions, is expected to accelerate the use of deep neural networks\nin the real world like Machine Learning as a Service (MLaaS) that returns\npredictions on queried data with the trained model. Deep neural networks\ndeployed in MLaaS face the threat of model extraction attacks. A model\nextraction attack is an attack to violate intellectual property and privacy in\nwhich an adversary steals trained models in a cloud using only their\npredictions. In particular, a data-free model extraction attack has been\nproposed recently and is more critical. In this attack, an adversary uses a\ngenerative model instead of preparing input data. The feasibility of this\nattack, however, needs to be studied since it requires more queries than that\nwith surrogate datasets. In this paper, we propose MEGEX, a data-free model\nextraction attack against a gradient-based explainable AI. In this method, an\nadversary uses the explanations to train the generative model and reduces the\nnumber of queries to steal the model. Our experiments show that our proposed\nmethod reconstructs high-accuracy models -- 0.97$\\times$ and 0.98$\\times$ the\nvictim model accuracy on SVHN and CIFAR-10 datasets given 2M and 20M queries,\nrespectively. This implies that there is a trade-off between the\ninterpretability of models and the difficulty of stealing them.",
          "link": "http://arxiv.org/abs/2107.08909",
          "publishedOn": "2021-07-20T02:04:47.019Z",
          "wordCount": null,
          "title": "MEGEX: Data-Free Model Extraction Attack against Gradient-Based Explainable AI. (arXiv:2107.08909v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08881",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Velickovic_P/0/1/0/all/0/1\">Petar Veli&#x10d;kovi&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bosnjak_M/0/1/0/all/0/1\">Matko Bo&#x161;njak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kipf_T/0/1/0/all/0/1\">Thomas Kipf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lerchner_A/0/1/0/all/0/1\">Alexander Lerchner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hadsell_R/0/1/0/all/0/1\">Raia Hadsell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pascanu_R/0/1/0/all/0/1\">Razvan Pascanu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blundell_C/0/1/0/all/0/1\">Charles Blundell</a>",
          "description": "Neural networks leverage robust internal representations in order to\ngeneralise. Learning them is difficult, and often requires a large training set\nthat covers the data distribution densely. We study a common setting where our\ntask is not purely opaque. Indeed, very often we may have access to information\nabout the underlying system (e.g. that observations must obey certain laws of\nphysics) that any \"tabula rasa\" neural network would need to re-learn from\nscratch, penalising data efficiency. We incorporate this information into a\npre-trained reasoning module, and investigate its role in shaping the\ndiscovered representations in diverse self-supervised learning settings from\npixels. Our approach paves the way for a new class of data-efficient\nrepresentation learning.",
          "link": "http://arxiv.org/abs/2107.08881",
          "publishedOn": "2021-07-20T02:04:47.018Z",
          "wordCount": null,
          "title": "Reasoning-Modulated Representations. (arXiv:2107.08881v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08249",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1\">Jie Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomczak_J/0/1/0/all/0/1\">Jakub M. Tomczak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eiben_A/0/1/0/all/0/1\">Agoston E. Eiben</a>",
          "description": "When controllers (brains) and morphologies (bodies) of robots simultaneously\nevolve, this can lead to a problem, namely the brain & body mismatch problem.\nIn this research, we propose a solution of lifetime learning. We set up a\nsystem where modular robots can create offspring that inherit the bodies of\nparents by recombination and mutation. With regards to the brains of the\noffspring, we use two methods to create them. The first one entails solely\nevolution which means the brain of a robot child is inherited from its parents.\nThe second approach is evolution plus learning which means the brain of a child\nis inherited as well, but additionally is developed by a learning algorithm -\nRevDEknn. We compare these two methods by running experiments in a simulator\ncalled Revolve and use efficiency, efficacy, and the morphology intelligence of\nthe robots for the comparison. The experiments show that the evolution plus\nlearning method does not only lead to a higher fitness level, but also to more\nmorphologically evolving robots. This constitutes a quantitative demonstration\nthat changes in the brain can induce changes in the body, leading to the\nconcept of morphological intelligence, which is quantified by the learning\ndelta, meaning the ability of a morphology to facilitate learning.",
          "link": "http://arxiv.org/abs/2107.08249",
          "publishedOn": "2021-07-20T02:04:46.996Z",
          "wordCount": null,
          "title": "The Effects of Learning in Morphologically Evolving Robot Systems. (arXiv:2107.08249v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08176",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Peixin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jingyi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jun Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_G/0/1/0/all/0/1\">Guoliang Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xingen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_T/0/1/0/all/0/1\">Ting Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1\">Jin Song Dong</a>",
          "description": "Although deep learning has demonstrated astonishing performance in many\napplications, there are still concerns on their dependability. One desirable\nproperty of deep learning applications with societal impact is fairness (i.e.,\nnon-discrimination). Unfortunately, discrimination might be intrinsically\nembedded into the models due to discrimination in the training data. As a\ncountermeasure, fairness testing systemically identifies discriminative\nsamples, which can be used to retrain the model and improve its fairness.\nExisting fairness testing approaches however have two major limitations. First,\nthey only work well on traditional machine learning models and have poor\nperformance (e.g., effectiveness and efficiency) on deep learning models.\nSecond, they only work on simple tabular data and are not applicable for\ndomains such as text. In this work, we bridge the gap by proposing a scalable\nand effective approach for systematically searching for discriminative samples\nwhile extending fairness testing to address a challenging domain, i.e., text\nclassification. Compared with state-of-the-art methods, our approach only\nemploys lightweight procedures like gradient computation and clustering, which\nmakes it significantly more scalable. Experimental results show that on\naverage, our approach explores the search space more effectively (9.62 and 2.38\ntimes more than the state-of-art methods respectively on tabular and text\ndatasets) and generates much more individual discriminatory instances (24.95\nand 2.68 times) within reasonable time. The retrained models reduce\ndiscrimination by 57.2% and 60.2% respectively on average.",
          "link": "http://arxiv.org/abs/2107.08176",
          "publishedOn": "2021-07-20T02:04:46.989Z",
          "wordCount": null,
          "title": "Automatic Fairness Testing of Neural Classifiers through Adversarial Sampling. (arXiv:2107.08176v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08221",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schott_L/0/1/0/all/0/1\">Lukas Schott</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kugelgen_J/0/1/0/all/0/1\">Julius von K&#xfc;gelgen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trauble_F/0/1/0/all/0/1\">Frederik Tr&#xe4;uble</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gehler_P/0/1/0/all/0/1\">Peter Gehler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Russell_C/0/1/0/all/0/1\">Chris Russell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bethge_M/0/1/0/all/0/1\">Matthias Bethge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1\">Bernhard Sch&#xf6;lkopf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Locatello_F/0/1/0/all/0/1\">Francesco Locatello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brendel_W/0/1/0/all/0/1\">Wieland Brendel</a>",
          "description": "An important component for generalization in machine learning is to uncover\nunderlying latent factors of variation as well as the mechanism through which\neach factor acts in the world. In this paper, we test whether 17 unsupervised,\nweakly supervised, and fully supervised representation learning approaches\ncorrectly infer the generative factors of variation in simple datasets\n(dSprites, Shapes3D, MPI3D). In contrast to prior robustness work that\nintroduces novel factors of variation during test time, such as blur or other\n(un)structured noise, we here recompose, interpolate, or extrapolate only\nexisting factors of variation from the training data set (e.g., small and\nmedium-sized objects during training and large objects during testing). Models\nthat learn the correct mechanism should be able to generalize to this\nbenchmark. In total, we train and test 2000+ models and observe that all of\nthem struggle to learn the underlying mechanism regardless of supervision\nsignal and architectural bias. Moreover, the generalization capabilities of all\ntested models drop significantly as we move from artificial datasets towards\nmore realistic real-world datasets. Despite their inability to identify the\ncorrect mechanism, the models are quite modular as their ability to infer other\nin-distribution factors remains fairly stable, providing only a single factor\nis out-of-distribution. These results point to an important yet understudied\nproblem of learning mechanistic models of observations that can facilitate\ngeneralization.",
          "link": "http://arxiv.org/abs/2107.08221",
          "publishedOn": "2021-07-20T02:04:46.986Z",
          "wordCount": null,
          "title": "Visual Representation Learning Does Not Generalize Strongly Within the Same Domain. (arXiv:2107.08221v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08225",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Muehlebach_M/0/1/0/all/0/1\">Michael Muehlebach</a>, <a href=\"http://arxiv.org/find/math/1/au:+Jordan_M/0/1/0/all/0/1\">Michael I. Jordan</a>",
          "description": "We introduce a class of first-order methods for smooth constrained\noptimization that are based on an analogy to non-smooth dynamical systems. Two\ndistinctive features of our approach are that (i) projections or optimizations\nover the entire feasible set are avoided, in stark contrast to projected\ngradient methods or the Frank-Wolfe method, and (ii) iterates are allowed to\nbecome infeasible, which differs from active set or feasible direction methods,\nwhere the descent motion stops as soon as a new constraint is encountered. The\nresulting algorithmic procedure is simple to implement even when constraints\nare nonlinear, and is suitable for large-scale constrained optimization\nproblems in which the feasible set fails to have a simple structure. The key\nunderlying idea is that constraints are expressed in terms of velocities\ninstead of positions, which has the algorithmic consequence that optimizations\nover feasible sets at each iteration are replaced with optimizations over\nlocal, sparse convex approximations. The result is a simplified suite of\nalgorithms and an expanded range of possible applications in machine learning.",
          "link": "http://arxiv.org/abs/2107.08225",
          "publishedOn": "2021-07-20T02:04:46.985Z",
          "wordCount": null,
          "title": "On Constraints in First-Order Optimization: A View from Non-Smooth Dynamical Systems. (arXiv:2107.08225v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08147",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Young Geun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Carole-Jean Wu</a>",
          "description": "Federated learning enables a cluster of decentralized mobile devices at the\nedge to collaboratively train a shared machine learning model, while keeping\nall the raw training samples on device. This decentralized training approach is\ndemonstrated as a practical solution to mitigate the risk of privacy leakage.\nHowever, enabling efficient FL deployment at the edge is challenging because of\nnon-IID training data distribution, wide system heterogeneity and\nstochastic-varying runtime effects in the field. This paper jointly optimizes\ntime-to-convergence and energy efficiency of state-of-the-art FL use cases by\ntaking into account the stochastic nature of edge execution. We propose AutoFL\nby tailor-designing a reinforcement learning algorithm that learns and\ndetermines which K participant devices and per-device execution targets for\neach FL model aggregation round in the presence of stochastic runtime variance,\nsystem and data heterogeneity. By considering the unique characteristics of FL\nedge deployment judiciously, AutoFL achieves 3.6 times faster model convergence\ntime and 4.7 and 5.2 times higher energy efficiency for local clients and\nglobally over the cluster of K participants, respectively.",
          "link": "http://arxiv.org/abs/2107.08147",
          "publishedOn": "2021-07-20T02:04:46.984Z",
          "wordCount": null,
          "title": "AutoFL: Enabling Heterogeneity-Aware Energy Efficient Federated Learning. (arXiv:2107.08147v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08189",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Avati_A/0/1/0/all/0/1\">Anand Avati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seneviratne_M/0/1/0/all/0/1\">Martin Seneviratne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_E/0/1/0/all/0/1\">Emily Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zhen Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lakshminarayanan_B/0/1/0/all/0/1\">Balaji Lakshminarayanan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_A/0/1/0/all/0/1\">Andrew M. Dai</a>",
          "description": "Machine learning has recently demonstrated impressive progress in predictive\naccuracy across a wide array of tasks. Most ML approaches focus on\ngeneralization performance on unseen data that are similar to the training data\n(In-Distribution, or IND). However, real world applications and deployments of\nML rarely enjoy the comfort of encountering examples that are always IND. In\nsuch situations, most ML models commonly display erratic behavior on\nOut-of-Distribution (OOD) examples, such as assigning high confidence to wrong\npredictions, or vice-versa. Implications of such unusual model behavior are\nfurther exacerbated in the healthcare setting, where patient health can\npotentially be put at risk. It is crucial to study the behavior and robustness\nproperties of models under distributional shift, understand common failure\nmodes, and take mitigation steps before the model is deployed. Having a\nbenchmark that shines light upon these aspects of a model is a first and\nnecessary step in addressing the issue. Recent work and interest in increasing\nmodel robustness in OOD settings have focused more on image modality, while the\nElectronic Health Record (EHR) modality is still largely under-explored. We aim\nto bridge this gap by releasing BEDS-Bench, a benchmark for quantifying the\nbehavior of ML models over EHR data under OOD settings. We use two open access,\nde-identified EHR datasets to construct several OOD data settings to run tests\non, and measure relevant metrics that characterize crucial aspects of a model's\nOOD behavior. We evaluate several learning algorithms under BEDS-Bench and find\nthat all of them show poor generalization performance under distributional\nshift in general. Our results highlight the need and the potential to improve\nrobustness of EHR models under distributional shift, and BEDS-Bench provides\none way to measure progress towards that goal.",
          "link": "http://arxiv.org/abs/2107.08189",
          "publishedOn": "2021-07-20T02:04:46.984Z",
          "wordCount": null,
          "title": "BEDS-Bench: Behavior of EHR-models under Distributional Shift--A Benchmark. (arXiv:2107.08189v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08140",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korb_K/0/1/0/all/0/1\">Kevin B Korb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Allison_L/0/1/0/all/0/1\">Lloyd Allison</a>",
          "description": "Causal discovery automates the learning of causal Bayesian networks from data\nand has been of active interest from their beginning. With the sourcing of\nlarge data sets off the internet, interest in scaling up to very large data\nsets has grown. One approach to this is to parallelize search using Markov\nBlanket (MB) discovery as a first step, followed by a process of combining MBs\nin a global causal model. We develop and explore three new methods of MB\ndiscovery using Minimum Message Length (MML) and compare them empirically to\nthe best existing methods, whether developed specifically as MB discovery or as\nfeature selection. Our best MML method is consistently competitive and has some\nadvantageous features.",
          "link": "http://arxiv.org/abs/2107.08140",
          "publishedOn": "2021-07-20T02:04:46.983Z",
          "wordCount": null,
          "title": "Markov Blanket Discovery using Minimum Message Length. (arXiv:2107.08140v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08170",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Petrenko_A/0/1/0/all/0/1\">Aleksei Petrenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wijmans_E/0/1/0/all/0/1\">Erik Wijmans</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shacklett_B/0/1/0/all/0/1\">Brennan Shacklett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koltun_V/0/1/0/all/0/1\">Vladlen Koltun</a>",
          "description": "We present Megaverse, a new 3D simulation platform for reinforcement learning\nand embodied AI research. The efficient design of our engine enables\nphysics-based simulation with high-dimensional egocentric observations at more\nthan 1,000,000 actions per second on a single 8-GPU node. Megaverse is up to\n70x faster than DeepMind Lab in fully-shaded 3D scenes with interactive\nobjects. We achieve this high simulation performance by leveraging batched\nsimulation, thereby taking full advantage of the massive parallelism of modern\nGPUs. We use Megaverse to build a new benchmark that consists of several\nsingle-agent and multi-agent tasks covering a variety of cognitive challenges.\nWe evaluate model-free RL on this benchmark to provide baselines and facilitate\nfuture research. The source code is available at https://www.megaverse.info",
          "link": "http://arxiv.org/abs/2107.08170",
          "publishedOn": "2021-07-20T02:04:46.983Z",
          "wordCount": null,
          "title": "Megaverse: Simulating Embodied Agents at One Million Experiences per Second. (arXiv:2107.08170v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08148",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Molino_P/0/1/0/all/0/1\">Piero Molino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Re_C/0/1/0/all/0/1\">Christopher R&#xe9;</a>",
          "description": "In the last years machine learning (ML) has moved from a academic endeavor to\na pervasive technology adopted in almost every aspect of computing. ML-powered\nproducts are now embedded in our digital lives: from recommendations of what to\nwatch, to divining our search intent, to powering virtual assistants in\nconsumer and enterprise settings. Recent successes in applying ML in natural\nsciences revealed that ML can be used to tackle some of the hardest real-world\nproblems humanity faces today. For these reasons ML has become central in the\nstrategy of tech companies and has gathered even more attention from academia\nthan ever before. Despite these successes, what we have witnessed so far is\njust the beginning. Right now the people training and using ML models are\nexpert developers working within large organizations, but we believe the next\nwave of ML systems will allow a larger amount of people, potentially without\ncoding skills, to perform the same tasks. These new ML systems will not require\nusers to fully understand all the details of how models are trained and\nutilized for obtaining predictions. Declarative interfaces are well suited for\nthis goal, by hiding complexity and favouring separation of interests, and can\nlead to increased productivity. We worked on such abstract interfaces by\ndeveloping two declarative ML systems, Overton and Ludwig, that require users\nto declare only their data schema (names and types of inputs) and tasks rather\nthen writing low level ML code. In this article we will describe how ML systems\nare currently structured, highlight important factors for their success and\nadoption, what are the issues current ML systems are facing and how the systems\nwe developed addressed them. Finally we will talk about learnings from the\ndevelopment of ML systems throughout the years and how we believe the next\ngeneration of ML systems will look like.",
          "link": "http://arxiv.org/abs/2107.08148",
          "publishedOn": "2021-07-20T02:04:46.981Z",
          "wordCount": null,
          "title": "Declarative Machine Learning Systems. (arXiv:2107.08148v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08763",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Girgis_A/0/1/0/all/0/1\">Antonious M. Girgis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Data_D/0/1/0/all/0/1\">Deepesh Data</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diggavi_S/0/1/0/all/0/1\">Suhas Diggavi</a>",
          "description": "We study privacy in a distributed learning framework, where clients\ncollaboratively build a learning model iteratively through interactions with a\nserver from whom we need privacy. Motivated by stochastic optimization and the\nfederated learning (FL) paradigm, we focus on the case where a small fraction\nof data samples are randomly sub-sampled in each round to participate in the\nlearning process, which also enables privacy amplification. To obtain even\nstronger local privacy guarantees, we study this in the shuffle privacy model,\nwhere each client randomizes its response using a local differentially private\n(LDP) mechanism and the server only receives a random permutation (shuffle) of\nthe clients' responses without their association to each client. The principal\nresult of this paper is a privacy-optimization performance trade-off for\ndiscrete randomization mechanisms in this sub-sampled shuffle privacy model.\nThis is enabled through a new theoretical technique to analyze the Renyi\nDifferential Privacy (RDP) of the sub-sampled shuffle model. We numerically\ndemonstrate that, for important regimes, with composition our bound yields\nsignificant improvement in privacy guarantee over the state-of-the-art\napproximate Differential Privacy (DP) guarantee (with strong composition) for\nsub-sampled shuffled models. We also demonstrate numerically significant\nimprovement in privacy-learning performance operating point using real data\nsets.",
          "link": "http://arxiv.org/abs/2107.08763",
          "publishedOn": "2021-07-20T02:04:46.980Z",
          "wordCount": null,
          "title": "Renyi Differential Privacy of the Subsampled Shuffle Model in Distributed Learning. (arXiv:2107.08763v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.10440",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zecevic_M/0/1/0/all/0/1\">Matej Ze&#x10d;evi&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dhami_D/0/1/0/all/0/1\">Devendra Singh Dhami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karanam_A/0/1/0/all/0/1\">Athresh Karanam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Natarajan_S/0/1/0/all/0/1\">Sriraam Natarajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kersting_K/0/1/0/all/0/1\">Kristian Kersting</a>",
          "description": "While probabilistic models are an important tool for studying causality,\ndoing so suffers from the intractability of inference. As a step towards\ntractable causal models, we consider the problem of learning interventional\ndistributions using sum-product networks (SPNs) that are over-parameterized by\ngate functions, e.g., neural networks. Providing an arbitrarily intervened\ncausal graph as input, effectively subsuming Pearl's do-operator, the gate\nfunction predicts the parameters of the SPN. The resulting interventional SPNs\nare motivated and illustrated by a structural causal model themed around\npersonal health. Our empirical evaluation on three benchmark data sets as well\nas a synthetic health data set clearly demonstrates that interventional SPNs\nindeed are both expressive in modelling and flexible in adapting to the\ninterventions.",
          "link": "http://arxiv.org/abs/2102.10440",
          "publishedOn": "2021-07-20T02:04:46.980Z",
          "wordCount": null,
          "title": "Interventional Sum-Product Networks: Causal Inference with Tractable Probabilistic Models. (arXiv:2102.10440v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08756",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Perez_I/0/1/0/all/0/1\">Iker Perez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Skalski_P/0/1/0/all/0/1\">Piotr Skalski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barns_Graham_A/0/1/0/all/0/1\">Alec Barns-Graham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_J/0/1/0/all/0/1\">Jason Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sutton_D/0/1/0/all/0/1\">David Sutton</a>",
          "description": "Enabling interpretations of model uncertainties is of key importance in\nBayesian machine learning applications. Often, this requires to meaningfully\nattribute predictive uncertainties to source features in an image, text or\ncategorical array. However, popular attribution methods are particularly\ndesigned for classification and regression scores. In order to explain\nuncertainties, state of the art alternatives commonly procure counterfactual\nfeature vectors, and proceed by making direct comparisons. In this paper, we\nleverage path integrals to attribute uncertainties in Bayesian differentiable\nmodels. We present a novel algorithm that relies on in-distribution curves\nconnecting a feature vector to some counterfactual counterpart, and we retain\ndesirable properties of interpretability methods. We validate our approach on\nbenchmark image data sets with varying resolution, and show that it\nsignificantly simplifies interpretability over the existing alternatives.",
          "link": "http://arxiv.org/abs/2107.08756",
          "publishedOn": "2021-07-20T02:04:46.979Z",
          "wordCount": null,
          "title": "Path Integrals for the Attribution of Model Uncertainties. (arXiv:2107.08756v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2011.05601",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Tsai_K/0/1/0/all/0/1\">Katherine Tsai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kolar_M/0/1/0/all/0/1\">Mladen Kolar</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Koyejo_O/0/1/0/all/0/1\">Oluwasanmi Koyejo</a>",
          "description": "We propose a flexible yet interpretable model for high-dimensional data with\ntime-varying second order statistics, motivated and applied to functional\nneuroimaging data. Motivated by the neuroscience literature, we factorize the\ncovariances into sparse spatial and smooth temporal components. While this\nfactorization results in both parsimony and domain interpretability, the\nresulting estimation problem is nonconvex. To this end, we design a two-stage\noptimization scheme with a carefully tailored spectral initialization, combined\nwith iteratively refined alternating projected gradient descent. We prove a\nlinear convergence rate up to a nontrivial statistical error for the proposed\ndescent scheme and establish sample complexity guarantees for the estimator. We\nfurther quantify the statistical error for the multivariate Gaussian case.\nEmpirical results using simulated and real brain imaging data illustrate that\nour approach outperforms existing baselines.",
          "link": "http://arxiv.org/abs/2011.05601",
          "publishedOn": "2021-07-20T02:04:46.979Z",
          "wordCount": null,
          "title": "A Nonconvex Framework for Structured Dynamic Covariance Recovery. (arXiv:2011.05601v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08714",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1\">Zhenyu Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1\">Shuai Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhizhe Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_K/0/1/0/all/0/1\">Kun Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1\">Zhenfeng Zhu</a>",
          "description": "Treatment effect estimation, which refers to the estimation of causal effects\nand aims to measure the strength of the causal relationship, is of great\nimportance in many fields but is a challenging problem in practice. As present,\ndata-driven causal effect estimation faces two main challenges, i.e., selection\nbias and the missing of counterfactual. To address these two issues, most of\nthe existing approaches tend to reduce the selection bias by learning a\nbalanced representation, and then to estimate the counterfactual through the\nrepresentation. However, they heavily rely on the finely hand-crafted metric\nfunctions when learning balanced representations, which generally doesn't work\nwell for the situations where the original distribution is complicated. In this\npaper, we propose a CETransformer model for casual effect estimation via\ntransformer based representation learning. To learn the representation of\ncovariates(features) robustly, a self-supervised transformer is proposed, by\nwhich the correlation between covariates can be well exploited through\nself-attention mechanism. In addition, an adversarial network is adopted to\nbalance the distribution of the treated and control groups in the\nrepresentation space. Experimental results on three real-world datasets\ndemonstrate the advantages of the proposed CETransformer, compared with the\nstate-of-the-art treatment effect estimation methods.",
          "link": "http://arxiv.org/abs/2107.08714",
          "publishedOn": "2021-07-20T02:04:46.978Z",
          "wordCount": null,
          "title": "CETransformer: Casual Effect Estimation via Transformer Based Representation Learning. (arXiv:2107.08714v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08765",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xueting Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhenhuan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+An_B/0/1/0/all/0/1\">Bang An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_J/0/1/0/all/0/1\">Jing Bai</a>",
          "description": "Graph neural networks (GNNs) is widely used to learn a powerful\nrepresentation of graph-structured data. Recent work demonstrates that\ntransferring knowledge from self-supervised tasks to downstream tasks could\nfurther improve graph representation. However, there is an inherent gap between\nself-supervised tasks and downstream tasks in terms of optimization objective\nand training data. Conventional pre-training methods may be not effective\nenough on knowledge transfer since they do not make any adaptation for\ndownstream tasks. To solve such problems, we propose a new transfer learning\nparadigm on GNNs which could effectively leverage self-supervised tasks as\nauxiliary tasks to help the target task. Our methods would adaptively select\nand combine different auxiliary tasks with the target task in the fine-tuning\nstage. We design an adaptive auxiliary loss weighting model to learn the\nweights of auxiliary tasks by quantifying the consistency between auxiliary\ntasks and the target task. In addition, we learn the weighting model through\nmeta-learning. Our methods can be applied to various transfer learning\napproaches, it performs well not only in multi-task learning but also in\npre-training and fine-tuning. Comprehensive experiments on multiple downstream\ntasks demonstrate that the proposed methods can effectively combine auxiliary\ntasks with the target task and significantly improve the performance compared\nto state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2107.08765",
          "publishedOn": "2021-07-20T02:04:46.977Z",
          "wordCount": null,
          "title": "Adaptive Transfer Learning on Graph Neural Networks. (arXiv:2107.08765v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08721",
          "author": "<a href=\"http://arxiv.org/find/q-fin/1/au:+Chen_Q/0/1/0/all/0/1\">Qinkai Chen</a>",
          "description": "News events can greatly influence equity markets. In this paper, we are\ninterested in predicting the short-term movement of stock prices after\nfinancial news events using only the headlines of the news. To achieve this\ngoal, we introduce a new text mining method called Fine-Tuned\nContextualized-Embedding Recurrent Neural Network (FT-CE-RNN). Compared with\nprevious approaches which use static vector representations of the news (static\nembedding), our model uses contextualized vector representations of the\nheadlines (contextualized embeddings) generated from Bidirectional Encoder\nRepresentations from Transformers (BERT). Our model obtains the\nstate-of-the-art result on this stock movement prediction task. It shows\nsignificant improvement compared with other baseline models, in both accuracy\nand trading simulations. Through various trading simulations based on millions\nof headlines from Bloomberg News, we demonstrate the ability of this model in\nreal scenarios.",
          "link": "http://arxiv.org/abs/2107.08721",
          "publishedOn": "2021-07-20T02:04:46.976Z",
          "wordCount": null,
          "title": "Stock Movement Prediction with Financial News using Contextualized Embedding from BERT. (arXiv:2107.08721v1 [q-fin.ST])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08773",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jianwen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1\">Shuangjia Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Ying Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rao_J/0/1/0/all/0/1\">Jiahua Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yuedong Yang</a>",
          "description": "Constructing appropriate representations of molecules lies at the core of\nnumerous tasks such as material science, chemistry and drug designs. Recent\nresearches abstract molecules as attributed graphs and employ graph neural\nnetworks (GNN) for molecular representation learning, which have made\nremarkable achievements in molecular graph modeling. Albeit powerful, current\nmodels either are based on local aggregation operations and thus miss\nhigher-order graph properties or focus on only node information without fully\nusing the edge information. For this sake, we propose a Communicative Message\nPassing Transformer (CoMPT) neural network to improve the molecular graph\nrepresentation by reinforcing message interactions between nodes and edges\nbased on the Transformer architecture. Unlike the previous transformer-style\nGNNs that treat molecules as fully connected graphs, we introduce a message\ndiffusion mechanism to leverage the graph connectivity inductive bias and\nreduce the message enrichment explosion. Extensive experiments demonstrated\nthat the proposed model obtained superior performances (around 4$\\%$ on\naverage) against state-of-the-art baselines on seven chemical property datasets\n(graph-level tasks) and two chemical shift datasets (node-level tasks). Further\nvisualization studies also indicated a better representation capacity achieved\nby our model.",
          "link": "http://arxiv.org/abs/2107.08773",
          "publishedOn": "2021-07-20T02:04:46.975Z",
          "wordCount": null,
          "title": "Learning Attributed Graph Representations with Communicative Message Passing Transformer. (arXiv:2107.08773v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08814",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shehabi_S/0/1/0/all/0/1\">Shadi Al Shehabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baba_A/0/1/0/all/0/1\">Abdullatif Baba</a>",
          "description": "Association rules are useful to discover relationships, which are mostly\nhidden, between the different items in large datasets. Symbolic models are the\nprincipal tools to extract association rules. This basic technique is\ntime-consuming, and it generates a big number of associated rules. To overcome\nthis drawback, we suggest a new method, called MARC, to extract the more\nimportant association rules of two important levels: Type I, and Type II. This\napproach relies on a multi-topographic unsupervised neural network model as\nwell as clustering quality measures that evaluate the success of a given\nnumerical classification model to behave as a natural symbolic model.",
          "link": "http://arxiv.org/abs/2107.08814",
          "publishedOn": "2021-07-20T02:04:46.975Z",
          "wordCount": null,
          "title": "MARC: Mining Association Rules from datasets by using Clustering models. (arXiv:2107.08814v1 [cs.DB])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08823",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jo_H/0/1/0/all/0/1\">Ha Young Jo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Seong-Whan Lee</a>",
          "description": "Recently, semiconductors' demand has exploded in virtual reality,\nsmartphones, wearable devices, the internet of things, robotics, and\nautomobiles. Semiconductor manufacturers want to make semiconductors with high\nyields. To do this, manufacturers conduct many quality assurance activities.\nWafer map pattern classification is a typical way of quality assurance. The\ndefect pattern on the wafer map can tell us which process has a problem. Most\nof the existing wafer map classification methods are based on supervised\nmethods. The supervised methods tend to have high performance, but they require\nextensive labor and expert knowledge to produce labeled datasets with a\nbalanced distribution in mind. In the semiconductor manufacturing process, it\nis challenging to get defect data with balanced distribution. In this paper, we\npropose a one-class classification method using an Adversarial Autoencoder\n(AAE) with Deep Support Vector Data Description (DSVDD) prior, which generates\nrandom vectors within the hypersphere of DSVDD. We use the WM-811k dataset,\nwhich consists of a real-world wafer map. We compare the F1 score performance\nof our model with DSVDD and AAE.",
          "link": "http://arxiv.org/abs/2107.08823",
          "publishedOn": "2021-07-20T02:04:46.974Z",
          "wordCount": null,
          "title": "One-Class Classification for Wafer Map using Adversarial Autoencoder with DSVDD Prior. (arXiv:2107.08823v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08829",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rafailov_R/0/1/0/all/0/1\">Rafael Rafailov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1\">Tianhe Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajeswaran_A/0/1/0/all/0/1\">Aravind Rajeswaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1\">Chelsea Finn</a>",
          "description": "Reward function specification, which requires considerable human effort and\niteration, remains a major impediment for learning behaviors through deep\nreinforcement learning. In contrast, providing visual demonstrations of desired\nbehaviors often presents an easier and more natural way to teach agents. We\nconsider a setting where an agent is provided a fixed dataset of visual\ndemonstrations illustrating how to perform a task, and must learn to solve the\ntask using the provided demonstrations and unsupervised environment\ninteractions. This setting presents a number of challenges including\nrepresentation learning for visual observations, sample complexity due to high\ndimensional spaces, and learning instability due to the lack of a fixed reward\nor learning signal. Towards addressing these challenges, we develop a\nvariational model-based adversarial imitation learning (V-MAIL) algorithm. The\nmodel-based approach provides a strong signal for representation learning,\nenables sample efficiency, and improves the stability of adversarial training\nby enabling on-policy learning. Through experiments involving several\nvision-based locomotion and manipulation tasks, we find that V-MAIL learns\nsuccessful visuomotor policies in a sample-efficient manner, has better\nstability compared to prior work, and also achieves higher asymptotic\nperformance. We further find that by transferring the learned models, V-MAIL\ncan learn new tasks from visual demonstrations without any additional\nenvironment interactions. All results including videos can be found online at\n\\url{https://sites.google.com/view/variational-mail}.",
          "link": "http://arxiv.org/abs/2107.08829",
          "publishedOn": "2021-07-20T02:04:46.973Z",
          "wordCount": null,
          "title": "Visual Adversarial Imitation Learning using Variational Models. (arXiv:2107.08829v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08834",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaolong Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vanegas_F/0/1/0/all/0/1\">Fernando Vanegas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_F/0/1/0/all/0/1\">Felipe Gonzalez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanderson_C/0/1/0/all/0/1\">Conrad Sanderson</a>",
          "description": "The use of multi-rotor Unmanned Aerial Vehicles (UAVs) for search and rescue\nas well as remote sensing is rapidly increasing. Multi-rotor UAVs, however,\nhave limited endurance. The range of UAV applications can be widened if teams\nof multiple UAVs are used. We propose a framework for a team of UAVs to\ncooperatively explore and find a target in complex GPS-denied environments with\nobstacles. The team of UAVs autonomously navigates, explores, detects, and\nfinds the target in a cluttered environment with a known map. Examples of such\nenvironments include indoor scenarios, urban or natural canyons, caves, and\ntunnels, where the GPS signal is limited or blocked. The framework is based on\na probabilistic decentralised Partially Observable Markov Decision Process\nwhich accounts for the uncertainties in sensing and the environment. The team\ncan cooperate efficiently, with each UAV sharing only limited processed\nobservations and their locations during the mission. The system is simulated\nusing the Robotic Operating System and Gazebo. Performance of the system with\nan increasing number of UAVs in several indoor scenarios with obstacles is\ntested. Results indicate that the proposed multi-UAV system has improvements in\nterms of time-cost, the proportion of search area surveyed, as well as\nsuccessful rates for search and rescue missions.",
          "link": "http://arxiv.org/abs/2107.08834",
          "publishedOn": "2021-07-20T02:04:46.973Z",
          "wordCount": null,
          "title": "A Multi-UAV System for Exploration and Target Finding in Cluttered and GPS-Denied Environments. (arXiv:2107.08834v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2103.01488",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Itoh_T/0/1/0/all/0/1\">Takeshi D. Itoh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kubo_T/0/1/0/all/0/1\">Takatomi Kubo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ikeda_K/0/1/0/all/0/1\">Kazushi Ikeda</a>",
          "description": "Graph neural networks (GNNs) have been widely used to learn vector\nrepresentation of graph-structured data and achieved better task performance\nthan conventional methods. The foundation of GNNs is the message passing\nprocedure, which propagates the information in a node to its neighbors. Since\nthis procedure proceeds one step per layer, the range of the information\npropagation among nodes is small in the lower layers, and it expands toward the\nhigher layers. Therefore, a GNN model has to be deep enough to capture global\nstructural information in a graph. On the other hand, it is known that deep GNN\nmodels suffer from performance degradation because they lose nodes' local\ninformation, which would be essential for good model performance, through many\nmessage passing steps. In this study, we propose a multi-level attention\npooling (MLAP) for graph-level classification tasks, which can adapt to both\nlocal and global structural information in a graph. It has an attention pooling\nlayer for each message passing step and computes the final graph representation\nby unifying the layer-wise graph representations. The MLAP architecture allows\nmodels to utilize the structural information of graphs with multiple levels of\nlocalities because it preserves layer-wise information before losing them due\nto oversmoothing. Results of our experiments show that the MLAP architecture\nimproves deeper models' performance in graph classification tasks compared to\nthe baseline architectures. In addition, analyses on the layer-wise graph\nrepresentations suggest that aggregating information from multiple levels of\nlocalities indeed has the potential to improve the discriminability of learned\ngraph representations.",
          "link": "http://arxiv.org/abs/2103.01488",
          "publishedOn": "2021-07-20T02:04:46.972Z",
          "wordCount": null,
          "title": "Multi-Level Attention Pooling for Graph Neural Networks: Unifying Graph Representations with Multiple Localities. (arXiv:2103.01488v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.11186",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junjie Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Junwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_X/0/1/0/all/0/1\">Xiaoyu Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1\">Shuai L&#xfc;</a>",
          "description": "Generative Adversarial Networks (GAN) is an adversarial model, and it has\nbeen demonstrated to be effective for various generative tasks. However, GAN\nand its variants also suffer from many training problems, such as mode collapse\nand gradient vanish. In this paper, we firstly propose a general crossover\noperator, which can be widely applied to GANs using evolutionary strategies.\nThen we design an evolutionary GAN framework C-GAN based on it. And we combine\nthe crossover operator with evolutionary generative adversarial networks (EGAN)\nto implement the evolutionary generative adversarial networks with crossover\n(CE-GAN). Under the premise that a variety of loss functions are used as\nmutation operators to generate mutation individuals, we evaluate the generated\nsamples and allow the mutation individuals to learn experiences from the output\nin a knowledge distillation manner, imitating the best output outcome,\nresulting in better offspring. Then, we greedily selected the best offspring as\nparents for subsequent training using discriminator as evaluator. Experiments\non real datasets demonstrate the effectiveness of CE-GAN and show that our\nmethod is competitive in terms of generated images quality and time efficiency.",
          "link": "http://arxiv.org/abs/2101.11186",
          "publishedOn": "2021-07-20T02:04:46.971Z",
          "wordCount": null,
          "title": "Evolutionary Generative Adversarial Networks with Crossover Based Knowledge Distillation. (arXiv:2101.11186v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08241",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Plaat_A/0/1/0/all/0/1\">Aske Plaat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kosters_W/0/1/0/all/0/1\">Walter Kosters</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Preuss_M/0/1/0/all/0/1\">Mike Preuss</a>",
          "description": "Deep reinforcement learning has shown remarkable success in the past few\nyears. Highly complex sequential decision making problems from game playing and\nrobotics have been solved with deep model-free methods. Unfortunately, the\nsample complexity of model-free methods is often high. To reduce the number of\nenvironment samples, model-based reinforcement learning creates an explicit\nmodel of the environment dynamics. Achieving high model accuracy is a challenge\nin high-dimensional problems. In recent years, a diverse landscape of\nmodel-based methods has been introduced to improve model accuracy, using\nmethods such as uncertainty modeling, model-predictive control, latent models,\nand end-to-end learning and planning. Some of these methods succeed in\nachieving high accuracy at low sample complexity, most do so either in a\nrobotics or in a games context. In this paper, we survey these methods; we\nexplain in detail how they work and what their strengths and weaknesses are. We\nconclude with a research agenda for future work to make the methods more robust\nand more widely applicable to other applications.",
          "link": "http://arxiv.org/abs/2107.08241",
          "publishedOn": "2021-07-20T02:04:46.880Z",
          "wordCount": null,
          "title": "High-Accuracy Model-Based Reinforcement Learning, a Survey. (arXiv:2107.08241v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08265",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Jain_A/0/1/0/all/0/1\">Ayush Jain</a> (1), <a href=\"http://arxiv.org/find/stat/1/au:+Srijith_P/0/1/0/all/0/1\">P. K. Srijith</a> (1), <a href=\"http://arxiv.org/find/stat/1/au:+Khan_M/0/1/0/all/0/1\">Mohammad Emtiyaz Khan</a> (2) ((1) Department of Computer Science and Engineering, Indian Institute of Technology Hyderabad, India, (2) RIKEN Center for AI Project, Tokyo, Japan)",
          "description": "Deep Gaussian Processes (DGPs) are multi-layer, flexible extensions of\nGaussian processes but their training remains challenging. Sparse\napproximations simplify the training but often require optimization over a\nlarge number of inducing inputs and their locations across layers. In this\npaper, we simplify the training by setting the locations to a fixed subset of\ndata and sampling the inducing inputs from a variational distribution. This\nreduces the trainable parameters and computation cost without significant\nperformance degradations, as demonstrated by our empirical results on\nregression problems. Our modifications simplify and stabilize DGP training\nwhile making it amenable to sampling schemes for setting the inducing inputs.",
          "link": "http://arxiv.org/abs/2107.08265",
          "publishedOn": "2021-07-20T02:04:46.879Z",
          "wordCount": null,
          "title": "Subset-of-Data Variational Inference for Deep Gaussian-Processes Regression. (arXiv:2107.08265v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2008.12623",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Milli_S/0/1/0/all/0/1\">Smitha Milli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belli_L/0/1/0/all/0/1\">Luca Belli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hardt_M/0/1/0/all/0/1\">Moritz Hardt</a>",
          "description": "Most recommendation engines today are based on predicting user engagement,\ne.g. predicting whether a user will click on an item or not. However, there is\npotentially a large gap between engagement signals and a desired notion of\n\"value\" that is worth optimizing for. We use the framework of measurement\ntheory to (a) confront the designer with a normative question about what the\ndesigner values, (b) provide a general latent variable model approach that can\nbe used to operationalize the target construct and directly optimize for it,\nand (c) guide the designer in evaluating and revising their operationalization.\nWe implement our approach on the Twitter platform on millions of users. In line\nwith established approaches to assessing the validity of measurements, we\nperform a qualitative evaluation of how well our model captures a desired\nnotion of \"value\".",
          "link": "http://arxiv.org/abs/2008.12623",
          "publishedOn": "2021-07-20T02:04:46.878Z",
          "wordCount": null,
          "title": "From Optimizing Engagement to Measuring Value. (arXiv:2008.12623v2 [cs.SI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08199",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Parry_H/0/1/0/all/0/1\">Hishan Parry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xun_L/0/1/0/all/0/1\">Lei Xun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabet_A/0/1/0/all/0/1\">Amin Sabet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bi_J/0/1/0/all/0/1\">Jia Bi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hare_J/0/1/0/all/0/1\">Jonathon Hare</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Merrett_G/0/1/0/all/0/1\">Geoff V. Merrett</a>",
          "description": "The Transformer architecture is widely used for machine translation tasks.\nHowever, its resource-intensive nature makes it challenging to implement on\nconstrained embedded devices, particularly where available hardware resources\ncan vary at run-time. We propose a dynamic machine translation model that\nscales the Transformer architecture based on the available resources at any\nparticular time. The proposed approach, 'Dynamic-HAT', uses a HAT\nSuperTransformer as the backbone to search for SubTransformers with different\naccuracy-latency trade-offs at design time. The optimal SubTransformers are\nsampled from the SuperTransformer at run-time, depending on latency\nconstraints. The Dynamic-HAT is tested on the Jetson Nano and the approach uses\ninherited SubTransformers sampled directly from the SuperTransformer with a\nswitching time of <1s. Using inherited SubTransformers results in a BLEU score\nloss of <1.5% because the SubTransformer configuration is not retrained from\nscratch after sampling. However, to recover this loss in performance, the\ndimensions of the design space can be reduced to tailor it to a family of\ntarget hardware. The new reduced design space results in a BLEU score increase\nof approximately 1% for sub-optimal models from the original design space, with\na wide range for performance scaling between 0.356s - 1.526s for the GPU and\n2.9s - 7.31s for the CPU.",
          "link": "http://arxiv.org/abs/2107.08199",
          "publishedOn": "2021-07-20T02:04:46.868Z",
          "wordCount": null,
          "title": "Dynamic Transformer for Efficient Machine Translation on Embedded Devices. (arXiv:2107.08199v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2006.10483",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">Renzhe Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_P/0/1/0/all/0/1\">Peng Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuang_K/0/1/0/all/0/1\">Kun Kuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1\">Linjun Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1\">Zheyan Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_W/0/1/0/all/0/1\">Wei Cui</a>",
          "description": "Nowadays fairness issues have raised great concerns in decision-making\nsystems. Various fairness notions have been proposed to measure the degree to\nwhich an algorithm is unfair. In practice, there frequently exist a certain set\nof variables we term as fair variables, which are pre-decision covariates such\nas users' choices. The effects of fair variables are irrelevant in assessing\nthe fairness of the decision support algorithm. We thus define conditional\nfairness as a more sound fairness metric by conditioning on the fairness\nvariables. Given different prior knowledge of fair variables, we demonstrate\nthat traditional fairness notations, such as demographic parity and equalized\nodds, are special cases of our conditional fairness notations. Moreover, we\npropose a Derivable Conditional Fairness Regularizer (DCFR), which can be\nintegrated into any decision-making model, to track the trade-off between\nprecision and fairness of algorithmic decision making. Specifically, an\nadversarial representation based conditional independence loss is proposed in\nour DCFR to measure the degree of unfairness. With extensive experiments on\nthree real-world datasets, we demonstrate the advantages of our conditional\nfairness notation and DCFR.",
          "link": "http://arxiv.org/abs/2006.10483",
          "publishedOn": "2021-07-20T02:04:46.867Z",
          "wordCount": null,
          "title": "Algorithmic Decision Making with Conditional Fairness. (arXiv:2006.10483v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1705.07164",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Guo_X/0/1/0/all/0/1\">Xin Guo</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hong_J/0/1/0/all/0/1\">Johnny Hong</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lin_T/0/1/0/all/0/1\">Tianyi Lin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yang_N/0/1/0/all/0/1\">Nan Yang</a>",
          "description": "Wasserstein Generative Adversarial Networks (WGANs) provide a versatile class\nof models, which have attracted great attention in various applications.\nHowever, this framework has two main drawbacks: (i) Wasserstein-1 (or\nEarth-Mover) distance is restrictive such that WGANs cannot always fit data\ngeometry well; (ii) It is difficult to achieve fast training of WGANs. In this\npaper, we propose a new class of \\textit{Relaxed Wasserstein} (RW) distances by\ngeneralizing Wasserstein-1 distance with Bregman cost functions. We show that\nRW distances achieve nice statistical properties while not sacrificing the\ncomputational tractability. Combined with the GANs framework, we develop\nRelaxed WGANs (RWGANs) which are not only statistically flexible but can be\napproximated efficiently using heuristic approaches. Experiments on real images\ndemonstrate that the RWGAN with Kullback-Leibler (KL) cost function outperforms\nother competing approaches, e.g., WGANs, even with gradient penalty.",
          "link": "http://arxiv.org/abs/1705.07164",
          "publishedOn": "2021-07-20T02:04:46.866Z",
          "wordCount": null,
          "title": "Relaxed Wasserstein with Applications to GANs. (arXiv:1705.07164v8 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08369",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Paul_S/0/1/0/all/0/1\">Sayak Paul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganju_S/0/1/0/all/0/1\">Siddha Ganju</a>",
          "description": "Floods wreak havoc throughout the world, causing billions of dollars in\ndamages, and uprooting communities, ecosystems and economies. Accurate and\nrobust flood detection including delineating open water flood areas and\nidentifying flood levels can aid in disaster response and mitigation. However,\nestimating flood levels remotely is of essence as physical access to flooded\nareas is limited and the ability to deploy instruments in potential flood zones\ncan be dangerous. Aligning flood extent mapping with local topography can\nprovide a plan-of-action that the disaster response team can consider. Thus,\nremote flood level estimation via satellites like Sentinel-1 can prove to be\nremedial. The Emerging Techniques in Computational Intelligence (ETCI)\ncompetition on Flood Detection tasked participants with predicting flooded\npixels after training with synthetic aperture radar (SAR) images in a\nsupervised setting. We use a cyclical approach involving two stages (1)\ntraining an ensemble model of multiple UNet architectures with available high\nand low confidence labeled data and, (2) generating pseudo labels or low\nconfidence labels on the unlabeled test dataset, and then, combining the\ngenerated labels with the previously available high confidence labeled dataset.\nThis assimilated dataset is used for the next round of training ensemble\nmodels. This cyclical process is repeated until the performance improvement\nplateaus. Additionally, we post process our results with Conditional Random\nFields. Our approach sets a high score on the public leaderboard for the ETCI\ncompetition with 0.7654 IoU. Our method, which we release with all the code\nincluding trained models, can also be used as an open science benchmark for the\nSentinel-1 released dataset on GitHub.",
          "link": "http://arxiv.org/abs/2107.08369",
          "publishedOn": "2021-07-20T02:04:46.865Z",
          "wordCount": null,
          "title": "Flood Segmentation on Sentinel-1 SAR Imagery with Semi-Supervised Learning. (arXiv:2107.08369v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/1910.09739",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Ming-Chuan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Meng Chang Chen</a>",
          "description": "This work investigates the framework and performance issues of the composite\nneural network, which is composed of a collection of pre-trained and\nnon-instantiated neural network models connected as a rooted directed acyclic\ngraph for solving complicated applications. A pre-trained neural network model\nis generally well trained, targeted to approximate a specific function. Despite\na general belief that a composite neural network may perform better than a\nsingle component, the overall performance characteristics are not clear. In\nthis work, we construct the framework of a composite network, and prove that a\ncomposite neural network performs better than any of its pre-trained components\nwith a high probability bound. In addition, if an extra pre-trained component\nis added to a composite network, with high probability, the overall performance\nwill not be degraded. In the study, we explore a complicated application --\nPM2.5 prediction -- to illustrate the correctness of the proposed composite\nnetwork theory. In the empirical evaluations of PM2.5 prediction, the\nconstructed composite neural network models support the proposed theory and\nperform better than other machine learning models, demonstrate the advantages\nof the proposed framework.",
          "link": "http://arxiv.org/abs/1910.09739",
          "publishedOn": "2021-07-20T02:04:46.865Z",
          "wordCount": null,
          "title": "Composite Neural Network: Theory and Application to PM2.5 Prediction. (arXiv:1910.09739v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08194",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dandekar_A/0/1/0/all/0/1\">Abhishek Dandekar</a>",
          "description": "Machine learning (ML) techniques are being increasingly used in mobile\nnetworks for network planning, operation, management, optimisation and much\nmore. These techniques are realised using a set of logical nodes known as ML\npipeline. A single network operator might have thousands of such ML pipelines\ndistributed across its network. These pipelines need to be managed and\norchestrated across network domains. Thus it is essential to have autonomic\nmulti-domain orchestration of ML pipelines in mobile networks. International\nTelecommunications Union (ITU) has provided an architectural framework for\nmanagement and orchestration of ML pipelines in future networks. We extend this\nframework to enable autonomic orchestration of ML pipelines across multiple\nnetwork domains. We present our system architecture and describe its\napplication using a smart factory use case. Our work allows autonomic\norchestration of multi-domain ML pipelines in a standardised, technology\nagnostic, privacy preserving fashion.",
          "link": "http://arxiv.org/abs/2107.08194",
          "publishedOn": "2021-07-20T02:04:46.864Z",
          "wordCount": null,
          "title": "Towards autonomic orchestration of machine learning pipelines in future networks. (arXiv:2107.08194v1 [cs.NI])"
        },
        {
          "id": "http://arxiv.org/abs/2002.06470",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ashukha_A/0/1/0/all/0/1\">Arsenii Ashukha</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lyzhov_A/0/1/0/all/0/1\">Alexander Lyzhov</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Molchanov_D/0/1/0/all/0/1\">Dmitry Molchanov</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vetrov_D/0/1/0/all/0/1\">Dmitry Vetrov</a>",
          "description": "Uncertainty estimation and ensembling methods go hand-in-hand. Uncertainty\nestimation is one of the main benchmarks for assessment of ensembling\nperformance. At the same time, deep learning ensembles have provided\nstate-of-the-art results in uncertainty estimation. In this work, we focus on\nin-domain uncertainty for image classification. We explore the standards for\nits quantification and point out pitfalls of existing metrics. Avoiding these\npitfalls, we perform a broad study of different ensembling techniques. To\nprovide more insight in this study, we introduce the deep ensemble equivalent\nscore (DEE) and show that many sophisticated ensembling techniques are\nequivalent to an ensemble of only few independently trained networks in terms\nof test performance.",
          "link": "http://arxiv.org/abs/2002.06470",
          "publishedOn": "2021-07-20T02:04:46.864Z",
          "wordCount": null,
          "title": "Pitfalls of In-Domain Uncertainty Estimation and Ensembling in Deep Learning. (arXiv:2002.06470v4 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.08170",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianhao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Hao Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yingfeng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1\">Changjie Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chongjie Zhang</a>",
          "description": "Meta reinforcement learning (meta-RL) extracts knowledge from previous tasks\nand achieves fast adaptation to new tasks. Despite recent progress, efficient\nexploration in meta-RL remains a key challenge in sparse-reward tasks, as it\nrequires quickly finding informative task-relevant experiences in both\nmeta-training and adaptation. To address this challenge, we explicitly model an\nexploration policy learning problem for meta-RL, which is separated from\nexploitation policy learning, and introduce a novel empowerment-driven\nexploration objective, which aims to maximize information gain for task\nidentification. We derive a corresponding intrinsic reward and develop a new\noff-policy meta-RL framework, which efficiently learns separate context-aware\nexploration and exploitation policies by sharing the knowledge of task\ninference. Experimental evaluation shows that our meta-RL method significantly\noutperforms state-of-the-art baselines on various sparse-reward MuJoCo\nlocomotion tasks and more complex sparse-reward Meta-World tasks.",
          "link": "http://arxiv.org/abs/2006.08170",
          "publishedOn": "2021-07-20T02:04:46.863Z",
          "wordCount": null,
          "title": "MetaCURE: Meta Reinforcement Learning with Empowerment-Driven Exploration. (arXiv:2006.08170v3 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08212",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xuebo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Longyue Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_D/0/1/0/all/0/1\">Derek F. Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_L/0/1/0/all/0/1\">Liang Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chao_L/0/1/0/all/0/1\">Lidia S. Chao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1\">Shuming Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1\">Zhaopeng Tu</a>",
          "description": "Previous studies have shown that initializing neural machine translation\n(NMT) models with the pre-trained language models (LM) can speed up the model\ntraining and boost the model performance. In this work, we identify a critical\nside-effect of pre-training for NMT, which is due to the discrepancy between\nthe training objectives of LM-based pre-training and NMT. Since the LM\nobjective learns to reconstruct a few source tokens and copy most of them, the\npre-training initialization would affect the copying behaviors of NMT models.\nWe provide a quantitative analysis of copying behaviors by introducing a metric\ncalled copying ratio, which empirically shows that pre-training based NMT\nmodels have a larger copying ratio than the standard one. In response to this\nproblem, we propose a simple and effective method named copying penalty to\ncontrol the copying behaviors in decoding. Extensive experiments on both\nin-domain and out-of-domain benchmarks show that the copying penalty method\nconsistently improves translation performance by controlling copying behaviors\nfor pre-training based NMT models. Source code is freely available at\nhttps://github.com/SunbowLiu/CopyingPenalty.",
          "link": "http://arxiv.org/abs/2107.08212",
          "publishedOn": "2021-07-20T02:04:46.862Z",
          "wordCount": null,
          "title": "On the Copying Behaviors of Pre-Training for Neural Machine Translation. (arXiv:2107.08212v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2012.11860",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Garg_A/0/1/0/all/0/1\">Aksh Garg</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Salehi_S/0/1/0/all/0/1\">Sana Salehi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rocca_M/0/1/0/all/0/1\">Marianna La Rocca</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Garner_R/0/1/0/all/0/1\">Rachael Garner</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Duncan_D/0/1/0/all/0/1\">Dominique Duncan</a>",
          "description": "With COVID-19 cases rising rapidly, deep learning has emerged as a promising\ndiagnosis technique. However, identifying the most accurate models to\ncharacterize COVID-19 patients is challenging because comparing results\nobtained with different types of data and acquisition processes is non-trivial.\nIn this paper we designed, evaluated, and compared the performance of 20\nconvolutional neutral networks in classifying patients as COVID-19 positive,\nhealthy, or suffering from other pulmonary lung infections based on Chest CT\nscans, serving as the first to consider the EfficientNet family for COVID-19\ndiagnosis and employ intermediate activation maps for visualizing model\nperformance. All models are trained and evaluated in Python using 4173 Chest CT\nimages from the dataset entitled \"A COVID multiclass dataset of CT scans,\" with\n2168, 758, and 1247 images of patients that are COVID-19 positive, healthy, or\nsuffering from other pulmonary infections, respectively. EfficientNet-B5 was\nidentified as the best model with an F1 score of 0.9769+/-0.0046, accuracy of\n0.9759+/-0.0048, sensitivity of 0.9788+/-0.0055, specificity of\n0.9730+/-0.0057, and precision of 0.9751 +/- 0.0051. On an alternate 2-class\ndataset, EfficientNetB5 obtained an accuracy of 0.9845+/-0.0109, F1 score of\n0.9599+/-0.0251, sensitivity of 0.9682+/-0.0099, specificity of\n0.9883+/-0.0150, and precision of 0.9526 +/- 0.0523. Intermediate activation\nmaps and Gradient-weighted Class Activation Mappings offered\nhuman-interpretable evidence of the model's perception of ground-class\nopacities and consolidations, hinting towards a promising use-case of\nartificial intelligence-assisted radiology tools. With a prediction speed of\nunder 0.1 seconds on GPUs and 0.5 seconds on CPUs, our proposed model offers a\nrapid, scalable, and accurate diagnostic for COVID-19.",
          "link": "http://arxiv.org/abs/2012.11860",
          "publishedOn": "2021-07-20T02:04:46.862Z",
          "wordCount": null,
          "title": "Efficient and Visualizable Convolutional Neural Networks for COVID-19 Classification Using Chest CT. (arXiv:2012.11860v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08135",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Yamane_I/0/1/0/all/0/1\">Ikko Yamane</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Honda_J/0/1/0/all/0/1\">Junya Honda</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yger_F/0/1/0/all/0/1\">Florian Yger</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masashi Sugiyama</a>",
          "description": "Ordinary supervised learning is useful when we have paired training data of\ninput $X$ and output $Y$. However, such paired data can be difficult to collect\nin practice. In this paper, we consider the task of predicting $Y$ from $X$\nwhen we have no paired data of them, but we have two separate, independent\ndatasets of $X$ and $Y$ each observed with some mediating variable $U$, that\nis, we have two datasets $S_X = \\{(X_i, U_i)\\}$ and $S_Y = \\{(U'_j, Y'_j)\\}$. A\nnaive approach is to predict $U$ from $X$ using $S_X$ and then $Y$ from $U$\nusing $S_Y$, but we show that this is not statistically consistent. Moreover,\npredicting $U$ can be more difficult than predicting $Y$ in practice, e.g.,\nwhen $U$ has higher dimensionality. To circumvent the difficulty, we propose a\nnew method that avoids predicting $U$ but directly learns $Y = f(X)$ by\ntraining $f(X)$ with $S_{X}$ to predict $h(U)$ which is trained with $S_{Y}$ to\napproximate $Y$. We prove statistical consistency and error bounds of our\nmethod and experimentally confirm its practical usefulness.",
          "link": "http://arxiv.org/abs/2107.08135",
          "publishedOn": "2021-07-20T02:04:46.861Z",
          "wordCount": null,
          "title": "Mediated Uncoupled Learning: Learning Functions without Direct Input-output Correspondences. (arXiv:2107.08135v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08790",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">JoonSung Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_Y/0/1/0/all/0/1\">YeongHyeon Park</a>",
          "description": "Recently Autoencoder(AE) based models are widely used in the field of anomaly\ndetection. A model trained with normal data generates a larger restoration\nerror for abnormal data. Whether or not abnormal data is determined by\nobserving the restoration error. It takes a lot of cost and time to obtain\nabnormal data in the industrial field. Therefore the model trains only normal\ndata and detects abnormal data in the inference phase. However, the restoration\narea for the input data of AE is limited in the latent space. To solve this\nproblem, we propose Multiple-hypothesis Autoencoder(MH-AE) model composed of\nseveral decoders. MH-AE model increases the restoration area through contention\nbetween decoders. The proposed method shows that the anomaly detection\nperformance is improved compared to the traditional AE for various input\ndatasets.",
          "link": "http://arxiv.org/abs/2107.08790",
          "publishedOn": "2021-07-20T02:04:46.860Z",
          "wordCount": null,
          "title": "Anomaly Detection Based on Multiple-Hypothesis Autoencoder. (arXiv:2107.08790v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08195",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1\">Jiahua Luo</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Vong_C/0/1/0/all/0/1\">Chi-Man Vong</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Du_J/0/1/0/all/0/1\">Jie Du</a> (2) ((1) Department of Computer and Information Science, University of Macau, Macao SAR, China, (2) School of Biomedical Engineering, Health Science Center, Shenzhen University, Shenzhen, China)",
          "description": "Sparse Bayesian Learning (SBL) constructs an extremely sparse probabilistic\nmodel with very competitive generalization. However, SBL needs to invert a big\ncovariance matrix with complexity O(M^3 ) (M: feature size) for updating the\nregularization priors, making it difficult for practical use. There are three\nissues in SBL: 1) Inverting the covariance matrix may obtain singular solutions\nin some cases, which hinders SBL from convergence; 2) Poor scalability to\nproblems with high dimensional feature space or large data size; 3) SBL easily\nsuffers from memory overflow for large-scale data. This paper addresses these\nissues with a newly proposed diagonal Quasi-Newton (DQN) method for SBL called\nDQN-SBL where the inversion of big covariance matrix is ignored so that the\ncomplexity and memory storage are reduced to O(M). The DQN-SBL is thoroughly\nevaluated on non-linear classifiers and linear feature selection using various\nbenchmark datasets of different sizes. Experimental results verify that DQN-SBL\nreceives competitive generalization with a very sparse model and scales well to\nlarge-scale problems.",
          "link": "http://arxiv.org/abs/2107.08195",
          "publishedOn": "2021-07-20T02:04:46.829Z",
          "wordCount": null,
          "title": "Sparse Bayesian Learning with Diagonal Quasi-Newton Method For Large Scale Classification. (arXiv:2107.08195v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2008.12804",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fajcik_M/0/1/0/all/0/1\">Martin Fajcik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jon_J/0/1/0/all/0/1\">Josef Jon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smrz_P/0/1/0/all/0/1\">Pavel Smrz</a>",
          "description": "This work demonstrates that, contrary to a common belief, using the objective\nwith independence assumption for modelling the span probability $P(a_s,a_e) =\nP(a_s)P(a_e)$ of span starting at position $a_s$ and ending at position $a_e$\nhas adverse effects. Therefore we propose multiple approaches to modelling\njoint probability $P(a_s,a_e)$ directly. Among those, we propose a compound\nobjective, composed from the joint probability while still keeping the\nobjective with independence assumption as an auxiliary objective. We find that\nthe compound objective is consistently superior or equal to other assumptions\nin exact match. Additionally, we identified common errors caused by the\nassumption of independence and manually checked the counterpart predictions,\ndemonstrating the impact of the compound objective on the real examples. Our\nfindings are supported via experiments with three extractive QA models (BIDAF,\nBERT, ALBERT) over six datasets and our code, individual results and manual\nanalysis are available online.",
          "link": "http://arxiv.org/abs/2008.12804",
          "publishedOn": "2021-07-20T02:04:46.806Z",
          "wordCount": null,
          "title": "Rethinking the Objectives of Extractive Question Answering. (arXiv:2008.12804v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.11589",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chi-Heng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azabou_M/0/1/0/all/0/1\">Mehdi Azabou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dyer_E/0/1/0/all/0/1\">Eva L. Dyer</a>",
          "description": "Optimal transport (OT) is a widely used technique for distribution alignment,\nwith applications throughout the machine learning, graphics, and vision\ncommunities. Without any additional structural assumptions on trans-port,\nhowever, OT can be fragile to outliers or noise, especially in high dimensions.\nHere, we introduce a new form of structured OT that simultaneously learns\nlow-dimensional structure in data while leveraging this structure to solve the\nalignment task. Compared with OT, the resulting transport plan has better\nstructural interpretability, highlighting the connections between individual\ndata points and local geometry, and is more robust to noise and sampling. We\napply the method to synthetic as well as real datasets, where we show that our\nmethod can facilitate alignment in noisy settings and can be used to both\ncorrect and interpret domain shift.",
          "link": "http://arxiv.org/abs/2012.11589",
          "publishedOn": "2021-07-20T02:04:46.806Z",
          "wordCount": null,
          "title": "Making transport more robust and interpretable by moving data through a small number of anchor points. (arXiv:2012.11589v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2003.13955",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zafarani_F/0/1/0/all/0/1\">Farzad Zafarani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clifton_C/0/1/0/all/0/1\">Chris Clifton</a>",
          "description": "With the increasing collection of users' data, protecting individual privacy\nhas gained more interest. Differential Privacy is a strong concept of\nprotecting individuals. Naive Bayes is one of the popular machine learning\nalgorithm, used as a baseline for many tasks. In this work, we have provided a\ndifferentially private Naive Bayes classifier that adds noise proportional to\nthe Smooth Sensitivity of its parameters. We have compared our result to\nVaidya, Shafiq, Basu, and Hong in which they have scaled the noise to the\nglobal sensitivity of the parameters. Our experiment results on the real-world\ndatasets show that the accuracy of our method has improved significantly while\nstill preserving $\\varepsilon$-differential privacy.",
          "link": "http://arxiv.org/abs/2003.13955",
          "publishedOn": "2021-07-20T02:04:46.805Z",
          "wordCount": null,
          "title": "Differentially Private Naive Bayes Classifier using Smooth Sensitivity. (arXiv:2003.13955v2 [cs.CR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08346",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1\">Haipeng Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1\">Chen-Yu Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1\">Chung-Wei Lee</a>",
          "description": "Policy optimization is a widely-used method in reinforcement learning. Due to\nits local-search nature, however, theoretical guarantees on global optimality\noften rely on extra assumptions on the Markov Decision Processes (MDPs) that\nbypass the challenge of global exploration. To eliminate the need of such\nassumptions, in this work, we develop a general solution that adds dilated\nbonuses to the policy update to facilitate global exploration. To showcase the\npower and generality of this technique, we apply it to several episodic MDP\nsettings with adversarial losses and bandit feedback, improving and\ngeneralizing the state-of-the-art. Specifically, in the tabular case, we obtain\n$\\widetilde{\\mathcal{O}}(\\sqrt{T})$ regret where $T$ is the number of episodes,\nimproving the $\\widetilde{\\mathcal{O}}({T}^{2/3})$ regret bound by Shani et al.\n(2020). When the number of states is infinite, under the assumption that the\nstate-action values are linear in some low-dimensional features, we obtain\n$\\widetilde{\\mathcal{O}}({T}^{2/3})$ regret with the help of a simulator,\nmatching the result of Neu and Olkhovskaya (2020) while importantly removing\nthe need of an exploratory policy that their algorithm requires. When a\nsimulator is unavailable, we further consider a linear MDP setting and obtain\n$\\widetilde{\\mathcal{O}}({T}^{14/15})$ regret, which is the first result for\nlinear MDPs with adversarial losses and bandit feedback.",
          "link": "http://arxiv.org/abs/2107.08346",
          "publishedOn": "2021-07-20T02:04:46.804Z",
          "wordCount": null,
          "title": "Policy Optimization in Adversarial MDPs: Improved Exploration via Dilated Bonuses. (arXiv:2107.08346v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08819",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meiyazhagan_J/0/1/0/all/0/1\">J.Meiyazhagan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sudharsan_S/0/1/0/all/0/1\">S. Sudharsan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Senthilvelan_M/0/1/0/all/0/1\">M. Senthilvelan</a>",
          "description": "We predict the emergence of extreme events in a parametrically driven\nnonlinear dynamical system using three Deep Learning models, namely Multi-Layer\nPerceptron, Convolutional Neural Network and Long Short-Term Memory. The Deep\nLearning models are trained using the training set and are allowed to predict\nthe test set data. After prediction, the time series of the actual and the\npredicted values are plotted one over the other in order to visualize the\nperformance of the models. Upon evaluating the Root Mean Square Error value\nbetween predicted and the actual values of all three models, we find that the\nLong Short-Term Memory model can serve as the best model to forecast the\nchaotic time series and to predict the emergence of extreme events for the\nconsidered system.",
          "link": "http://arxiv.org/abs/2107.08819",
          "publishedOn": "2021-07-20T02:04:46.804Z",
          "wordCount": null,
          "title": "Model-free prediction of emergence of extreme events in a parametrically driven nonlinear dynamical system by Deep Learning. (arXiv:2107.08819v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2002.09478",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Ran Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parunandi_K/0/1/0/all/0/1\">Karthikeya S. Parunandi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Aayushman Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_R/0/1/0/all/0/1\">Raman Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakravorty_S/0/1/0/all/0/1\">Suman Chakravorty</a>",
          "description": "The problem of Reinforcement Learning (RL) in an unknown nonlinear dynamical\nsystem is equivalent to the search for an optimal feedback law utilizing the\nsimulations/ rollouts of the unknown dynamical system. Most RL techniques\nsearch over a complex global nonlinear feedback parametrization making them\nsuffer from high training times as well as variance. Instead, we advocate\nsearching over a local feedback representation consisting of an open-loop\nsequence, and an associated optimal linear feedback law completely determined\nby the open-loop. We show that this alternate approach results in highly\nefficient training, the answers obtained are repeatable and hence reliable, and\nthe resulting closed performance is superior to global state-of-the-art RL\ntechniques. Finally, if we replan, whenever required, which is feasible due to\nthe fast and reliable local solution, allows us to recover global optimality of\nthe resulting feedback law.",
          "link": "http://arxiv.org/abs/2002.09478",
          "publishedOn": "2021-07-20T02:04:46.803Z",
          "wordCount": null,
          "title": "On the Search for Feedback in Reinforcement Learning. (arXiv:2002.09478v5 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.02463",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mounir_R/0/1/0/all/0/1\">Ramy Mounir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gula_R/0/1/0/all/0/1\">Roman Gula</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Theuerkauf_J/0/1/0/all/0/1\">J&#xf6;rn Theuerkauf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarkar_S/0/1/0/all/0/1\">Sudeep Sarkar</a>",
          "description": "Using offline training schemes, researchers have tackled the event\nsegmentation problem by providing full or weak-supervision through manually\nannotated labels or self-supervised epoch-based training. Most works consider\nvideos that are at most 10's of minutes long. We present a self-supervised\nperceptual prediction framework capable of temporal event segmentation by\nbuilding stable representations of objects over time and demonstrate it on long\nvideos, spanning several days. The approach is deceptively simple but quite\neffective. We rely on predictions of high-level features computed by a standard\ndeep learning backbone. For prediction, we use an LSTM, augmented with an\nattention mechanism, trained in a self-supervised manner using the prediction\nerror. The self-learned attention maps effectively localize and track the\nevent-related objects in each frame. The proposed approach does not require\nlabels. It requires only a single pass through the video, with no separate\ntraining set. Given the lack of datasets of very long videos, we demonstrate\nour method on video from 10 days (254 hours) of continuous wildlife monitoring\ndata that we had collected with required permissions. We find that the approach\nis robust to various environmental conditions such as day/night conditions,\nrain, sharp shadows, and windy conditions. For the task of temporally locating\nevents, we had an 80% recall rate at 20% false-positive rate for frame-level\nsegmentation. At the activity level, we had an 80% activity recall rate for one\nfalse activity detection every 50 minutes. We will make the dataset, which is\nthe first of its kind, and the code available to the research community.",
          "link": "http://arxiv.org/abs/2005.02463",
          "publishedOn": "2021-07-20T02:04:46.803Z",
          "wordCount": null,
          "title": "Spatio-Temporal Event Segmentation and Localization for Wildlife Extended Videos. (arXiv:2005.02463v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.07458",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_T/0/1/0/all/0/1\">Tianyi Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1\">Chenyou Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ho_N/0/1/0/all/0/1\">Nhat Ho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cuturi_M/0/1/0/all/0/1\">Marco Cuturi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1\">Michael I. Jordan</a>",
          "description": "Projection robust Wasserstein (PRW) distance, or Wasserstein projection\npursuit (WPP), is a robust variant of the Wasserstein distance. Recent work\nsuggests that this quantity is more robust than the standard Wasserstein\ndistance, in particular when comparing probability measures in high-dimensions.\nHowever, it is ruled out for practical application because the optimization\nmodel is essentially non-convex and non-smooth which makes the computation\nintractable. Our contribution in this paper is to revisit the original\nmotivation behind WPP/PRW, but take the hard route of showing that, despite its\nnon-convexity and lack of nonsmoothness, and even despite some hardness results\nproved by~\\citet{Niles-2019-Estimation} in a minimax sense, the original\nformulation for PRW/WPP \\textit{can} be efficiently computed in practice using\nRiemannian optimization, yielding in relevant cases better behavior than its\nconvex relaxation. More specifically, we provide three simple algorithms with\nsolid theoretical guarantee on their complexity bound (one in the appendix),\nand demonstrate their effectiveness and efficiency by conducing extensive\nexperiments on synthetic and real data. This paper provides a first step into a\ncomputational theory of the PRW distance and provides the links between optimal\ntransport and Riemannian optimization.",
          "link": "http://arxiv.org/abs/2006.07458",
          "publishedOn": "2021-07-20T02:04:46.802Z",
          "wordCount": null,
          "title": "Projection Robust Wasserstein Distance and Riemannian Optimization. (arXiv:2006.07458v8 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.00038",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Birmpa_P/0/1/0/all/0/1\">Panagiota Birmpa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Katsoulakis_M/0/1/0/all/0/1\">Markos A. Katsoulakis</a>",
          "description": "We present an information-based uncertainty quantification method for general\nMarkov Random Fields. Markov Random Fields (MRF) are structured, probabilistic\ngraphical models over undirected graphs, and provide a fundamental unifying\nmodeling tool for statistical mechanics, probabilistic machine learning, and\nartificial intelligence. Typically MRFs are complex and high-dimensional with\nnodes and edges (connections) built in a modular fashion from simpler,\nlow-dimensional probabilistic models and their local connections; in turn, this\nmodularity allows to incorporate available data to MRFs and efficiently\nsimulate them by leveraging their graph-theoretic structure. Learning graphical\nmodels from data and/or constructing them from physical modeling and\nconstraints necessarily involves uncertainties inherited from data, modeling\nchoices, or numerical approximations. These uncertainties in the MRF can be\nmanifested either in the graph structure or the probability distribution\nfunctions, and necessarily will propagate in predictions for quantities of\ninterest. Here we quantify such uncertainties using tight, information based\nbounds on the predictions of quantities of interest; these bounds take\nadvantage of the graphical structure of MRFs and are capable of handling the\ninherent high-dimensionality of such graphical models. We demonstrate our\nmethods in MRFs for medical diagnostics and statistical mechanics models. In\nthe latter, we develop uncertainty quantification bounds for finite size\neffects and phase diagrams, which constitute two of the typical predictions\ngoals of statistical mechanics modeling.",
          "link": "http://arxiv.org/abs/2009.00038",
          "publishedOn": "2021-07-20T02:04:46.801Z",
          "wordCount": null,
          "title": "Uncertainty quantification for Markov Random Fields. (arXiv:2009.00038v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.00383",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Krishna_G/0/1/0/all/0/1\">Gautam Krishna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carnahan_M/0/1/0/all/0/1\">Mason Carnahan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shamapant_S/0/1/0/all/0/1\">Shilpa Shamapant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Surendranath_Y/0/1/0/all/0/1\">Yashitha Surendranath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1\">Saumya Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_A/0/1/0/all/0/1\">Arundhati Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_C/0/1/0/all/0/1\">Co Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Millan_J/0/1/0/all/0/1\">Jose del R Millan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tewfik_A/0/1/0/all/0/1\">Ahmed H Tewfik</a>",
          "description": "In this paper, we propose a deep learning-based algorithm to improve the\nperformance of automatic speech recognition (ASR) systems for aphasia, apraxia,\nand dysarthria speech by utilizing electroencephalography (EEG) features\nrecorded synchronously with aphasia, apraxia, and dysarthria speech. We\ndemonstrate a significant decoding performance improvement by more than 50\\%\nduring test time for isolated speech recognition task and we also provide\npreliminary results indicating performance improvement for the more challenging\ncontinuous speech recognition task by utilizing EEG features. The results\npresented in this paper show the first step towards demonstrating the\npossibility of utilizing non-invasive neural signals to design a real-time\nrobust speech prosthetic for stroke survivors recovering from aphasia, apraxia,\nand dysarthria. Our aphasia, apraxia, and dysarthria speech-EEG data set will\nbe released to the public to help further advance this interesting and crucial\nresearch.",
          "link": "http://arxiv.org/abs/2103.00383",
          "publishedOn": "2021-07-20T02:04:46.801Z",
          "wordCount": null,
          "title": "Brain Signals to Rescue Aphasia, Apraxia and Dysarthria Speech Recognition. (arXiv:2103.00383v2 [cs.SD] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08251",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weston_J/0/1/0/all/0/1\">Jack Weston</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lenain_R/0/1/0/all/0/1\">Raphael Lenain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meepegama_U/0/1/0/all/0/1\">Udeepa Meepegama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fristed_E/0/1/0/all/0/1\">Emil Fristed</a>",
          "description": "We introduce ParaBLEU, a paraphrase representation learning model and\nevaluation metric for text generation. Unlike previous approaches, ParaBLEU\nlearns to understand paraphrasis using generative conditioning as a pretraining\nobjective. ParaBLEU correlates more strongly with human judgements than\nexisting metrics, obtaining new state-of-the-art results on the 2017 WMT\nMetrics Shared Task. We show that our model is robust to data scarcity,\nexceeding previous state-of-the-art performance using only $50\\%$ of the\navailable training data and surpassing BLEU, ROUGE and METEOR with only $40$\nlabelled examples. Finally, we demonstrate that ParaBLEU can be used to\nconditionally generate novel paraphrases from a single demonstration, which we\nuse to confirm our hypothesis that it learns abstract, generalized paraphrase\nrepresentations.",
          "link": "http://arxiv.org/abs/2107.08251",
          "publishedOn": "2021-07-20T02:04:46.799Z",
          "wordCount": null,
          "title": "Generative Pretraining for Paraphrase Evaluation. (arXiv:2107.08251v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08362",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_B/0/1/0/all/0/1\">Bing Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jun Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_T/0/1/0/all/0/1\">Ting Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lijun Zhang</a>",
          "description": "Fairness is crucial for neural networks which are used in applications with\nimportant societal implication. Recently, there have been multiple attempts on\nimproving fairness of neural networks, with a focus on fairness testing (e.g.,\ngenerating individual discriminatory instances) and fairness training (e.g.,\nenhancing fairness through augmented training). In this work, we propose an\napproach to formally verify neural networks against fairness, with a focus on\nindependence-based fairness such as group fairness. Our method is built upon an\napproach for learning Markov Chains from a user-provided neural network (i.e.,\na feed-forward neural network or a recurrent neural network) which is\nguaranteed to facilitate sound analysis. The learned Markov Chain not only\nallows us to verify (with Probably Approximate Correctness guarantee) whether\nthe neural network is fair or not, but also facilities sensitivity analysis\nwhich helps to understand why fairness is violated. We demonstrate that with\nour analysis results, the neural weights can be optimized to improve fairness.\nOur approach has been evaluated with multiple models trained on benchmark\ndatasets and the experiment results show that our approach is effective and\nefficient.",
          "link": "http://arxiv.org/abs/2107.08362",
          "publishedOn": "2021-07-20T02:04:46.799Z",
          "wordCount": null,
          "title": "Probabilistic Verification of Neural Networks Against Group Fairness. (arXiv:2107.08362v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.11068",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1\">Ning Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_G/0/1/0/all/0/1\">Geng Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Che_Z/0/1/0/all/0/1\">Zhengping Che</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1\">Xuan Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xiaolong Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Q/0/1/0/all/0/1\">Qing Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1\">Jian Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jian Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Sijia Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanzhi Wang</a>",
          "description": "In deep model compression, the recent finding \"Lottery Ticket Hypothesis\"\n(LTH) (Frankle & Carbin, 2018) pointed out that there could exist a winning\nticket (i.e., a properly pruned sub-network together with original weight\ninitialization) that can achieve competitive performance than the original\ndense network. However, it is not easy to observe such winning property in many\nscenarios, where for example, a relatively large learning rate is used even if\nit benefits training the original dense model. In this work, we investigate the\nunderlying condition and rationale behind the winning property, and find that\nthe underlying reason is largely attributed to the correlation between\ninitialized weights and final-trained weights when the learning rate is not\nsufficiently large. Thus, the existence of winning property is correlated with\nan insufficient DNN pretraining, and is unlikely to occur for a well-trained\nDNN. To overcome this limitation, we propose the \"pruning & fine-tuning\" method\nthat consistently outperforms lottery ticket sparse training under the same\npruning algorithm and the same total training epochs. Extensive experiments\nover multiple deep models (VGG, ResNet, MobileNet-v2) on different datasets\nhave been conducted to justify our proposals.",
          "link": "http://arxiv.org/abs/2102.11068",
          "publishedOn": "2021-07-20T02:04:46.798Z",
          "wordCount": null,
          "title": "Lottery Ticket Preserves Weight Correlation: Is It Desirable or Not?. (arXiv:2102.11068v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08850",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ganz_J/0/1/0/all/0/1\">Jonathan Ganz</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kirsch_T/0/1/0/all/0/1\">Tobias Kirsch</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hoffmann_L/0/1/0/all/0/1\">Lucas Hoffmann</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bertram_C/0/1/0/all/0/1\">Christof A. Bertram</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hoffmann_C/0/1/0/all/0/1\">Christoph Hoffmann</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Maier_A/0/1/0/all/0/1\">Andreas Maier</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Breininger_K/0/1/0/all/0/1\">Katharina Breininger</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Blumcke_I/0/1/0/all/0/1\">Ingmar Bl&#xfc;mcke</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jabari_S/0/1/0/all/0/1\">Samir Jabari</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Aubreville_M/0/1/0/all/0/1\">Marc Aubreville</a>",
          "description": "Meningioma is one of the most prevalent brain tumors in adults. To determine\nits malignancy, it is graded by a pathologist into three grades according to\nWHO standards. This grade plays a decisive role in treatment, and yet may be\nsubject to inter-rater discordance. In this work, we present and compare three\napproaches towards fully automatic meningioma grading from histology whole\nslide images. All approaches are following a two-stage paradigm, where we first\nidentify a region of interest based on the detection of mitotic figures in the\nslide using a state-of-the-art object detection deep learning network. This\nregion of highest mitotic rate is considered characteristic for biological\ntumor behavior. In the second stage, we calculate a score corresponding to\ntumor malignancy based on information contained in this region using three\ndifferent settings. In a first approach, image patches are sampled from this\nregion and regression is based on morphological features encoded by a\nResNet-based network. We compare this to learning a logistic regression from\nthe determined mitotic count, an approach which is easily traceable and\nexplainable. Lastly, we combine both approaches in a single network. We trained\nthe pipeline on 951 slides from 341 patients and evaluated them on a separate\nset of 141 slides from 43 patients. All approaches yield a high correlation to\nthe WHO grade. The logistic regression and the combined approach had the best\nresults in our experiments, yielding correct predictions in 32 and 33 of all\ncases, respectively, with the image-based approach only predicting 25 cases\ncorrectly. Spearman's correlation was 0.716, 0.792 and 0.790 respectively. It\nmay seem counterintuitive at first that morphological features provided by\nimage patches do not improve model performance. Yet, this mirrors the criteria\nof the grading scheme, where mitotic count is the only unequivocal parameter.",
          "link": "http://arxiv.org/abs/2107.08850",
          "publishedOn": "2021-07-20T02:04:46.797Z",
          "wordCount": null,
          "title": "Automatic and explainable grading of meningiomas from histopathology images. (arXiv:2107.08850v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08248",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weston_J/0/1/0/all/0/1\">Jack Weston</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lenain_R/0/1/0/all/0/1\">Raphael Lenain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meepegama_U/0/1/0/all/0/1\">Udeepa Meepegama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fristed_E/0/1/0/all/0/1\">Emil Fristed</a>",
          "description": "We propose a method for learning de-identified prosody representations from\nraw audio using a contrastive self-supervised signal. Whereas prior work has\nrelied on conditioning models on bottlenecks, we introduce a set of inductive\nbiases that exploit the natural structure of prosody to minimize timbral\ninformation and decouple prosody from speaker representations. Despite\naggressive downsampling of the input and having no access to linguistic\ninformation, our model performs comparably to state-of-the-art speech\nrepresentations on DAMMP, a new benchmark we introduce for spoken language\nunderstanding. We use minimum description length probing to show that our\nrepresentations have selectively learned the subcomponents of non-timbral\nprosody, and that the product quantizer naturally disentangles them without\nusing bottlenecks. We derive an information-theoretic definition of speech\nde-identifiability and use it to demonstrate that our prosody representations\nare less identifiable than other speech representations.",
          "link": "http://arxiv.org/abs/2107.08248",
          "publishedOn": "2021-07-20T02:04:46.796Z",
          "wordCount": null,
          "title": "Learning De-identified Representations of Prosody from Raw Audio. (arXiv:2107.08248v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08285",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chan_A/0/1/0/all/0/1\">Alan Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silva_H/0/1/0/all/0/1\">Hugo Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lim_S/0/1/0/all/0/1\">Sungsu Lim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kozuno_T/0/1/0/all/0/1\">Tadashi Kozuno</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahmood_A/0/1/0/all/0/1\">A. Rupam Mahmood</a>, <a href=\"http://arxiv.org/find/cs/1/au:+White_M/0/1/0/all/0/1\">Martha White</a>",
          "description": "Approximate Policy Iteration (API) algorithms alternate between (approximate)\npolicy evaluation and (approximate) greedification. Many different approaches\nhave been explored for approximate policy evaluation, but less is understood\nabout approximate greedification and what choices guarantee policy improvement.\nIn this work, we investigate approximate greedification when reducing the KL\ndivergence between the parameterized policy and the Boltzmann distribution over\naction values. In particular, we investigate the difference between the forward\nand reverse KL divergences, with varying degrees of entropy regularization. We\nshow that the reverse KL has stronger policy improvement guarantees, but that\nreducing the forward KL can result in a worse policy. We also demonstrate,\nhowever, that a large enough reduction of the forward KL can induce improvement\nunder additional assumptions. Empirically, we show on simple continuous-action\nenvironments that the forward KL can induce more exploration, but at the cost\nof a more suboptimal policy. No significant differences were observed in the\ndiscrete-action setting or on a suite of benchmark problems. Throughout, we\nhighlight that many policy gradient methods can be seen as an instance of API,\nwith either the forward or reverse KL for the policy update, and discuss next\nsteps for understanding and improving our policy optimization algorithms.",
          "link": "http://arxiv.org/abs/2107.08285",
          "publishedOn": "2021-07-20T02:04:46.795Z",
          "wordCount": null,
          "title": "Greedification Operators for Policy Optimization: Investigating Forward and Reverse KL Divergences. (arXiv:2107.08285v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08815",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mu_J/0/1/0/all/0/1\">Jiandong Mu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mengdi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_F/0/1/0/all/0/1\">Feiwen Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1\">Wei Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wei Zhang</a>",
          "description": "Recently, neural network compression schemes like channel pruning have been\nwidely used to reduce the model size and computational complexity of deep\nneural network (DNN) for applications in power-constrained scenarios such as\nembedded systems. Reinforcement learning (RL)-based auto-pruning has been\nfurther proposed to automate the DNN pruning process to avoid expensive\nhand-crafted work. However, the RL-based pruner involves a time-consuming\ntraining process and the high expense of each sample further exacerbates this\nproblem. These impediments have greatly restricted the real-world application\nof RL-based auto-pruning. Thus, in this paper, we propose an efficient\nauto-pruning framework which solves this problem by taking advantage of the\nhistorical data from the previous auto-pruning process. In our framework, we\nfirst boost the convergence of the RL-pruner by transfer learning. Then, an\naugmented transfer learning scheme is proposed to further speed up the training\nprocess by improving the transferability. Finally, an assistant learning\nprocess is proposed to improve the sample efficiency of the RL agent. The\nexperiments have shown that our framework can accelerate the auto-pruning\nprocess by 1.5-2.5 times for ResNet20, and 1.81-2.375 times for other neural\nnetworks like ResNet56, ResNet18, and MobileNet v1.",
          "link": "http://arxiv.org/abs/2107.08815",
          "publishedOn": "2021-07-20T02:04:46.794Z",
          "wordCount": null,
          "title": "Boosting the Convergence of Reinforcement Learning-based Auto-pruning Using Historical Data. (arXiv:2107.08815v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08277",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fotakis_D/0/1/0/all/0/1\">Dimitris Fotakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gergatsouli_E/0/1/0/all/0/1\">Evangelia Gergatsouli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gouleakis_T/0/1/0/all/0/1\">Themis Gouleakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patris_N/0/1/0/all/0/1\">Nikolas Patris</a>",
          "description": "Following the research agenda initiated by Munoz & Vassilvitskii [1] and\nLykouris & Vassilvitskii [2] on learning-augmented online algorithms for\nclassical online optimization problems, in this work, we consider the Online\nFacility Location problem under this framework. In Online Facility Location\n(OFL), demands arrive one-by-one in a metric space and must be (irrevocably)\nassigned to an open facility upon arrival, without any knowledge about future\ndemands.\n\nWe present an online algorithm for OFL that exploits potentially imperfect\npredictions on the locations of the optimal facilities. We prove that the\ncompetitive ratio decreases smoothly from sublogarithmic in the number of\ndemands to constant, as the error, i.e., the total distance of the predicted\nlocations to the optimal facility locations, decreases towards zero. We\ncomplement our analysis with a matching lower bound establishing that the\ndependence of the algorithm's competitive ratio on the error is optimal, up to\nconstant factors. Finally, we evaluate our algorithm on real world data and\ncompare our learning augmented approach with the current best online algorithm\nfor the problem.",
          "link": "http://arxiv.org/abs/2107.08277",
          "publishedOn": "2021-07-20T02:04:46.793Z",
          "wordCount": null,
          "title": "Learning Augmented Online Facility Location. (arXiv:2107.08277v1 [cs.DS])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08364",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Le_T/0/1/0/all/0/1\">Triet H. M. Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huaming Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Babar_M/0/1/0/all/0/1\">M. Ali Babar</a>",
          "description": "Software Vulnerabilities (SVs) are increasing in complexity and scale, posing\ngreat security risks to many software systems. Given the limited resources in\npractice, SV assessment and prioritization help practitioners devise optimal SV\nmitigation plans based on various SV characteristics. The surge in SV data\nsources and data-driven techniques such as Machine Learning and Deep Learning\nhave taken SV assessment and prioritization to the next level. Our survey\nprovides a taxonomy of the past research efforts and highlights the best\npractices for data-driven SV assessment and prioritization. We also discuss the\ncurrent limitations and propose potential solutions to address such issues.",
          "link": "http://arxiv.org/abs/2107.08364",
          "publishedOn": "2021-07-20T02:04:46.792Z",
          "wordCount": null,
          "title": "A Survey on Data-driven Software Vulnerability Assessment and Prioritization. (arXiv:2107.08364v1 [cs.SE])"
        },
        {
          "id": "http://arxiv.org/abs/2102.10618",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_S/0/1/0/all/0/1\">Sushant Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jabbari_S/0/1/0/all/0/1\">Shahin Jabbari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_C/0/1/0/all/0/1\">Chirag Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Upadhyay_S/0/1/0/all/0/1\">Sohini Upadhyay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhiwei Steven Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lakkaraju_H/0/1/0/all/0/1\">Himabindu Lakkaraju</a>",
          "description": "As machine learning black boxes are increasingly being deployed in critical\ndomains such as healthcare and criminal justice, there has been a growing\nemphasis on developing techniques for explaining these black boxes in a post\nhoc manner. In this work, we analyze two popular post hoc interpretation\ntechniques: SmoothGrad which is a gradient based method, and a variant of LIME\nwhich is a perturbation based method. More specifically, we derive explicit\nclosed form expressions for the explanations output by these two methods and\nshow that they both converge to the same explanation in expectation, i.e., when\nthe number of perturbed samples used by these methods is large. We then\nleverage this connection to establish other desirable properties, such as\nrobustness, for these techniques. We also derive finite sample complexity\nbounds for the number of perturbations required for these methods to converge\nto their expected explanation. Finally, we empirically validate our theory\nusing extensive experimentation on both synthetic and real world datasets.",
          "link": "http://arxiv.org/abs/2102.10618",
          "publishedOn": "2021-07-20T02:04:46.792Z",
          "wordCount": null,
          "title": "Towards the Unification and Robustness of Perturbation and Gradient Based Explanations. (arXiv:2102.10618v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08293",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Feriani_A/0/1/0/all/0/1\">Amal Feriani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mezghani_A/0/1/0/all/0/1\">Amine Mezghani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hossain_E/0/1/0/all/0/1\">Ekram Hossain</a>",
          "description": "We consider an Intelligent Reflecting Surface (IRS)-aided multiple-input\nsingle-output (MISO) system for downlink transmission. We compare the\nperformance of Deep Reinforcement Learning (DRL) and conventional optimization\nmethods in finding optimal phase shifts of the IRS elements to maximize the\nuser signal-to-noise (SNR) ratio. Furthermore, we evaluate the robustness of\nthese methods to channel impairments and changes in the system. We demonstrate\nnumerically that DRL solutions show more robustness to noisy channels and user\nmobility.",
          "link": "http://arxiv.org/abs/2107.08293",
          "publishedOn": "2021-07-20T02:04:46.791Z",
          "wordCount": null,
          "title": "On the Robustness of Deep Reinforcement Learning in IRS-Aided Wireless Communications Systems. (arXiv:2107.08293v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08319",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sharma_K/0/1/0/all/0/1\">Karishma Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferrara_E/0/1/0/all/0/1\">Emilio Ferrara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yan Liu</a>",
          "description": "Identifying and characterizing disinformation in political discourse on\nsocial media is critical to ensure the integrity of elections and democratic\nprocesses around the world. Persistent manipulation of social media has\nresulted in increased concerns regarding the 2020 U.S. Presidential Election,\ndue to its potential to influence individual opinions and social dynamics. In\nthis work, we focus on the identification of distorted facts, in the form of\nunreliable and conspiratorial narratives in election-related tweets, to\ncharacterize discourse manipulation prior to the election. We apply a detection\nmodel to separate factual from unreliable (or conspiratorial) claims analyzing\na dataset of 242 million election-related tweets. The identified claims are\nused to investigate targeted topics of disinformation, and conspiracy groups,\nmost notably the far-right QAnon conspiracy group. Further, we characterize\naccount engagements with unreliable and conspiracy tweets, and with the QAnon\nconspiracy group, by political leaning and tweet types. Finally, using a\nregression discontinuity design, we investigate whether Twitter's actions to\ncurb QAnon activity on the platform were effective, and how QAnon accounts\nadapt to Twitter's restrictions.",
          "link": "http://arxiv.org/abs/2107.08319",
          "publishedOn": "2021-07-20T02:04:46.791Z",
          "wordCount": null,
          "title": "Characterizing Online Engagement with Disinformation and Conspiracies in the 2020 U.S. Presidential Election. (arXiv:2107.08319v1 [cs.SI])"
        },
        {
          "id": "http://arxiv.org/abs/2009.06342",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Paassen_B/0/1/0/all/0/1\">Benjamin Paa&#xdf;en</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schulz_A/0/1/0/all/0/1\">Alexander Schulz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stewart_T/0/1/0/all/0/1\">Terrence C. Stewart</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hammer_B/0/1/0/all/0/1\">Barbara Hammer</a>",
          "description": "Differentiable neural computers extend artificial neural networks with an\nexplicit memory without interference, thus enabling the model to perform\nclassic computation tasks such as graph traversal. However, such models are\ndifficult to train, requiring long training times and large datasets. In this\nwork, we achieve some of the computational capabilities of differentiable\nneural computers with a model that can be trained very efficiently, namely an\necho state network with an explicit memory without interference. This extension\nenables echo state networks to recognize all regular languages, including those\nthat contractive echo state networks provably can not recognize. Further, we\ndemonstrate experimentally that our model performs comparably to its\nfully-trained deep version on several typical benchmark tasks for\ndifferentiable neural computers.",
          "link": "http://arxiv.org/abs/2009.06342",
          "publishedOn": "2021-07-20T02:04:46.774Z",
          "wordCount": null,
          "title": "Reservoir Memory Machines as Neural Computers. (arXiv:2009.06342v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1910.06070",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zhou_H/0/1/0/all/0/1\">Hao Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Laval_J/0/1/0/all/0/1\">Jorge Laval</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhou_A/0/1/0/all/0/1\">Anye Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_Y/0/1/0/all/0/1\">Yu Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_W/0/1/0/all/0/1\">Wenchao Wu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Qing_Z/0/1/0/all/0/1\">Zhu Qing</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Peeta_S/0/1/0/all/0/1\">Srinivas Peeta</a>",
          "description": "Self-driving technology companies and the research community are accelerating\ntheir pace to use machine learning longitudinal motion planning (mMP) for\nautonomous vehicles (AVs). This paper reviews the current state of the art in\nmMP, with an exclusive focus on its impact on traffic congestion. We identify\nthe availability of congestion scenarios in current datasets, and summarize the\nrequired features for training mMP. For learning methods, we survey the major\nmethods in both imitation learning and non-imitation learning. We also\nhighlight the emerging technologies adopted by some leading AV companies, e.g.\nTesla, Waymo, and Comma.ai. We find that: i) the AV industry has been mostly\nfocusing on the long tail problem related to safety and overlooked the impact\non traffic congestion, ii) the current public self-driving datasets have not\nincluded enough congestion scenarios, and mostly lack the necessary input\nfeatures/output labels to train mMP, and iii) albeit reinforcement learning\n(RL) approach can integrate congestion mitigation into the learning goal, the\nmajor mMP method adopted by industry is still behavior cloning (BC), whose\ncapability to learn a congestion-mitigating mMP remains to be seen. Based on\nthe review, the study identifies the research gaps in current mMP development.\nSome suggestions towards congestion mitigation for future mMP studies are\nproposed: i) enrich data collection to facilitate the congestion learning, ii)\nincorporate non-imitation learning methods to combine traffic efficiency into a\nsafety-oriented technical route, and iii) integrate domain knowledge from the\ntraditional car following (CF) theory to improve the string stability of mMP.",
          "link": "http://arxiv.org/abs/1910.06070",
          "publishedOn": "2021-07-20T02:04:46.773Z",
          "wordCount": null,
          "title": "Review of Learning-based Longitudinal Motion Planning for Autonomous Vehicles: Research Gaps between Self-driving and Traffic Congestion. (arXiv:1910.06070v2 [eess.SP] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.13134",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shibata_K/0/1/0/all/0/1\">Katsunari Shibata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ejima_T/0/1/0/all/0/1\">Takuya Ejima</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tokumaru_Y/0/1/0/all/0/1\">Yuki Tokumaru</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matsuki_T/0/1/0/all/0/1\">Toshitaka Matsuki</a>",
          "description": "Here, we introduce a fully local index named \"sensitivity\" for each neuron to\ncontrol chaoticity or gradient globally in a neural network (NN). We also\npropose a learning method to adjust it named \"sensitivity adjustment learning\n(SAL)\". The index is the gradient magnitude of its output with respect to its\ninputs. By adjusting its time average to 1.0 in each neuron, information\ntransmission in the neuron changes to be moderate without shrinking or\nexpanding for both forward and backward computations. That results in moderate\ninformation transmission through a layer of neurons when the weights and inputs\nare random. Therefore, SAL can control the chaoticity of the network dynamics\nin a recurrent NN (RNN). It can also solve the vanishing gradient problem in\nerror backpropagation (BP) learning in a deep feedforward NN or an RNN. We\ndemonstrate that when applying SAL to an RNN with small and random initial\nweights, log-sensitivity, which is the logarithm of RMS (root mean square)\nsensitivity over all the neurons, is equivalent to the maximum Lyapunov\nexponent until it reaches 0.0. We also show that SAL works with BP or BPTT (BP\nthrough time) to avoid the vanishing gradient problem in a 300-layer NN or an\nRNN that learns a problem with a lag of 300 steps between the first input and\nthe output. Compared with manually fine-tuning the spectral radius of the\nweight matrix before learning, SAL's continuous nonlinear learning nature\nprevents loss of sensitivities during learning, resulting in a significant\nimprovement in learning performance.",
          "link": "http://arxiv.org/abs/2012.13134",
          "publishedOn": "2021-07-20T02:04:46.773Z",
          "wordCount": null,
          "title": "Sensitivity -- Local Index to Control Chaoticity or Gradient Globally. (arXiv:2012.13134v2 [cs.NE] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08865",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Siwei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xiao Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yunfan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsu_D/0/1/0/all/0/1\">David Hsu</a>",
          "description": "This paper presents Particle-based Object Manipulation (Prompt), a new\napproach to robot manipulation of novel objects ab initio, without prior object\nmodels or pre-training on a large object data set. The key element of Prompt is\na particle-based object representation, in which each particle represents a\npoint in the object, the local geometric, physical, and other features of the\npoint, and also its relation with other particles. Like the model-based\nanalytic approaches to manipulation, the particle representation enables the\nrobot to reason about the object's geometry and dynamics in order to choose\nsuitable manipulation actions. Like the data-driven approaches, the particle\nrepresentation is learned online in real-time from visual sensor input,\nspecifically, multi-view RGB images. The particle representation thus connects\nvisual perception with robot control. Prompt combines the benefits of both\nmodel-based reasoning and data-driven learning. We show empirically that Prompt\nsuccessfully handles a variety of everyday objects, some of which are\ntransparent. It handles various manipulation tasks, including grasping,\npushing, etc,. Our experiments also show that Prompt outperforms a\nstate-of-the-art data-driven grasping method on the daily objects, even though\nit does not use any offline training data.",
          "link": "http://arxiv.org/abs/2107.08865",
          "publishedOn": "2021-07-20T02:04:46.772Z",
          "wordCount": null,
          "title": "Ab Initio Particle-based Object Manipulation. (arXiv:2107.08865v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08096",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shanmugam_D/0/1/0/all/0/1\">Divya Shanmugam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shabanian_S/0/1/0/all/0/1\">Samira Shabanian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diaz_F/0/1/0/all/0/1\">Fernando Diaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Finck_M/0/1/0/all/0/1\">Mich&#xe8;le Finck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biega_A/0/1/0/all/0/1\">Asia Biega</a>",
          "description": "Data minimization is a legal obligation defined in the European Union's\nGeneral Data Protection Regulation (GDPR) as the responsibility to process an\nadequate, relevant, and limited amount of personal data in relation to a\nprocessing purpose. However, unlike fairness or transparency, the principle has\nnot seen wide adoption for machine learning systems due to a lack of\ncomputational interpretation. In this paper, we build on literature in machine\nlearning and law to propose the first learning framework for limiting data\ncollection based on an interpretation that ties the data collection purpose to\nsystem performance. We formalize a data minimization criterion based on\nperformance curve derivatives and provide an effective and interpretable\npiecewise power law technique that models distinct stages of an algorithm's\nperformance throughout data collection. Results from our empirical\ninvestigation offer deeper insights into the relevant considerations when\ndesigning a data minimization framework, including the choice of feature\nacquisition algorithm, initialization conditions, as well as impacts on\nindividuals that hint at tensions between data minimization and fairness.",
          "link": "http://arxiv.org/abs/2107.08096",
          "publishedOn": "2021-07-20T02:04:46.699Z",
          "wordCount": null,
          "title": "Learning to Limit Data Collection via Scaling Laws: Data Minimization Compliance in Practice. (arXiv:2107.08096v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08785",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Elflein_S/0/1/0/all/0/1\">Sven Elflein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Charpentier_B/0/1/0/all/0/1\">Bertrand Charpentier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zugner_D/0/1/0/all/0/1\">Daniel Z&#xfc;gner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gunnemann_S/0/1/0/all/0/1\">Stephan G&#xfc;nnemann</a>",
          "description": "Several density estimation methods have shown to fail to detect\nout-of-distribution (OOD) samples by assigning higher likelihoods to anomalous\ndata. Energy-based models (EBMs) are flexible, unnormalized density models\nwhich seem to be able to improve upon this failure mode. In this work, we\nprovide an extensive study investigating OOD detection with EBMs trained with\ndifferent approaches on tabular and image data and find that EBMs do not\nprovide consistent advantages. We hypothesize that EBMs do not learn semantic\nfeatures despite their discriminative structure similar to Normalizing Flows.\nTo verify this hypotheses, we show that supervision and architectural\nrestrictions improve the OOD detection of EBMs independent of the training\napproach.",
          "link": "http://arxiv.org/abs/2107.08785",
          "publishedOn": "2021-07-20T02:04:46.698Z",
          "wordCount": null,
          "title": "On Out-of-distribution Detection with Energy-based Models. (arXiv:2107.08785v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08090",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chepurko_N/0/1/0/all/0/1\">Nadiia Chepurko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clarkson_K/0/1/0/all/0/1\">Kenneth L. Clarkson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kacham_P/0/1/0/all/0/1\">Praneeth Kacham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1\">David P. Woodruff</a>",
          "description": "Currently, in the numerical linear algebra community, it is thought that to\nobtain nearly-optimal bounds for various problems such as rank computation,\nfinding a maximal linearly independent subset of columns, regression, low rank\napproximation, maximum matching on general graphs and linear matroid union, one\nwould need to resolve the main open question of Nelson and Nguyen (FOCS, 2013)\nregarding the logarithmic factors in the sketching dimension for existing\nconstant factor approximation oblivious subspace embeddings. We show how to\nbypass this question using a refined sketching technique, and obtain optimal or\nnearly optimal bounds for these problems. A key technique we use is an explicit\nmapping of Indyk based on uncertainty principles and extractors, which after\nfirst applying known oblivious subspace embeddings, allows us to quickly spread\nout the mass of the vector so that sampling is now effective, and we avoid a\nlogarithmic factor that is standard in the sketching dimension resulting from\nmatrix Chernoff bounds. For the fundamental problems of rank computation and\nfinding a linearly independent subset of columns, our algorithms improve\nCheung, Kwok, and Lau (JACM, 2013) and are optimal to within a constant factor\nand a $\\log\\log(n)$-factor, respectively. Further, for constant factor\nregression and low rank approximation we give the first optimal algorithms, for\nthe current matrix multiplication exponent.",
          "link": "http://arxiv.org/abs/2107.08090",
          "publishedOn": "2021-07-20T02:04:46.697Z",
          "wordCount": null,
          "title": "Near-Optimal Algorithms for Linear Algebra in the Current Matrix Multiplication Time. (arXiv:2107.08090v1 [cs.DS])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08183",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">JaeYoon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xuan_J/0/1/0/all/0/1\">Junyu Xuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_C/0/1/0/all/0/1\">Christy Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hussain_F/0/1/0/all/0/1\">Farookh Hussain</a>",
          "description": "The high-dimensional or sparse reward task of a reinforcement learning (RL)\nenvironment requires a superior potential controller such as hierarchical\nreinforcement learning (HRL) rather than an atomic RL because it absorbs the\ncomplexity of commands to achieve the purpose of the task in its hierarchical\nstructure. One of the HRL issues is how to train each level policy with the\noptimal data collection from its experience. That is to say, how to synchronize\nadjacent level policies optimally. Our research finds that a HRL model through\nthe off-policy correction technique of HRL, which trains a higher-level policy\nwith the goal of reflecting a lower-level policy which is newly trained using\nthe off-policy method, takes the critical role of synchronizing both level\npolicies at all times while they are being trained. We propose a novel HRL\nmodel supporting the optimal level synchronization using the off-policy\ncorrection technique with a deep generative model. This uses the advantage of\nthe inverse operation of a flow-based deep generative model (FDGM) to achieve\nthe goal corresponding to the current state of the lower-level policy. The\nproposed model also considers the freedom of the goal dimension between HRL\npolicies which makes it the generalized inverse model of the model-free RL in\nHRL with the optimal synchronization method. The comparative experiment results\nshow the performance of our proposed model.",
          "link": "http://arxiv.org/abs/2107.08183",
          "publishedOn": "2021-07-20T02:04:46.690Z",
          "wordCount": null,
          "title": "Hierarchical Reinforcement Learning with Optimal Level Synchronization based on a Deep Generative Model. (arXiv:2107.08183v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08083",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yue Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lui_K/0/1/0/all/0/1\">Kry Yik Chau Lui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hernandez_Leal_P/0/1/0/all/0/1\">Pablo Hernandez-Leal</a>",
          "description": "Trading markets represent a real-world financial application to deploy\nreinforcement learning agents, however, they carry hard fundamental challenges\nsuch as high variance and costly exploration. Moreover, markets are inherently\na multiagent domain composed of many actors taking actions and changing the\nenvironment. To tackle these type of scenarios agents need to exhibit certain\ncharacteristics such as risk-awareness, robustness to perturbations and low\nlearning variance. We take those as building blocks and propose a family of\nfour algorithms. First, we contribute with two algorithms that use risk-averse\nobjective functions and variance reduction techniques. Then, we augment the\nframework to multi-agent learning and assume an adversary which can take over\nand perturb the learning process. Our third and fourth algorithms perform well\nunder this setting and balance theoretical guarantees with practical use.\nAdditionally, we consider the multi-agent nature of the environment and our\nwork is the first one extending empirical game theory analysis for multi-agent\nlearning by considering risk-sensitive payoffs.",
          "link": "http://arxiv.org/abs/2107.08083",
          "publishedOn": "2021-07-20T02:04:46.689Z",
          "wordCount": null,
          "title": "Robust Risk-Sensitive Reinforcement Learning Agents for Trading Markets. (arXiv:2107.08083v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/1810.03024",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheung_W/0/1/0/all/0/1\">Wang Chi Cheung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simchi_Levi_D/0/1/0/all/0/1\">David Simchi-Levi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_R/0/1/0/all/0/1\">Ruihao Zhu</a>",
          "description": "We introduce algorithms that achieve state-of-the-art \\emph{dynamic regret}\nbounds for non-stationary linear stochastic bandit setting. It captures natural\napplications such as dynamic pricing and ads allocation in a changing\nenvironment. We show how the difficulty posed by the non-stationarity can be\novercome by a novel marriage between stochastic and adversarial bandits\nlearning algorithms. Defining $d,B_T,$ and $T$ as the problem dimension, the\n\\emph{variation budget}, and the total time horizon, respectively, our main\ncontributions are the tuned Sliding Window UCB (\\texttt{SW-UCB}) algorithm with\noptimal $\\widetilde{O}(d^{2/3}(B_T+1)^{1/3}T^{2/3})$ dynamic regret, and the\ntuning free bandit-over-bandit (\\texttt{BOB}) framework built on top of the\n\\texttt{SW-UCB} algorithm with best\n$\\widetilde{O}(d^{2/3}(B_T+1)^{1/4}T^{3/4})$ dynamic regret.",
          "link": "http://arxiv.org/abs/1810.03024",
          "publishedOn": "2021-07-20T02:04:46.689Z",
          "wordCount": null,
          "title": "Learning to Optimize under Non-Stationarity. (arXiv:1810.03024v6 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08326",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Silva_A/0/1/0/all/0/1\">Anderson da Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ludermir_T/0/1/0/all/0/1\">Teresa Ludermir</a>",
          "description": "This works proposes a methodology to searching for automatically Artificial\nNeural Networks (ANN) by using Cellular Genetic Algorithm (CGA). The goal of\nthis methodology is to find compact networks whit good performance for\nclassification problems. The main reason for developing this work is centered\nat the difficulties of configuring compact ANNs with good performance rating.\nThe use of CGAs aims at seeking the components of the RNA in the same way that\na common Genetic Algorithm (GA), but it has the differential of incorporating a\nCellular Automaton (CA) to give location for the GA individuals. The location\nimposed by the CA aims to control the spread of solutions in the populations to\nmaintain the genetic diversity for longer time. This genetic diversity is\nimportant for obtain good results with the GAs.",
          "link": "http://arxiv.org/abs/2107.08326",
          "publishedOn": "2021-07-20T02:04:46.687Z",
          "wordCount": null,
          "title": "Otimizacao de Redes Neurais atraves de Algoritmos Geneticos Celulares. (arXiv:2107.08326v1 [cs.NE])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08800",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Peiris_V/0/1/0/all/0/1\">Vinesha Peiris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sukhorukova_N/0/1/0/all/0/1\">Nadezda Sukhorukova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roshchina_V/0/1/0/all/0/1\">Vera Roshchina</a>",
          "description": "We explore the potential for using a nonsmooth loss function based on the\nmax-norm in the training of an artificial neural network. We hypothesise that\nthis may lead to superior classification results in some special cases where\nthe training data is either very small or unbalanced.\n\nOur numerical experiments performed on a simple artificial neural network\nwith no hidden layers (a setting immediately amenable to standard nonsmooth\noptimisation techniques) appear to confirm our hypothesis that uniform\napproximation based approaches may be more suitable for the datasets with\nreliable training data that either is limited size or biased in terms of\nrelative cluster sizes.",
          "link": "http://arxiv.org/abs/2107.08800",
          "publishedOn": "2021-07-20T02:04:46.686Z",
          "wordCount": null,
          "title": "Deep Learning with Nonsmooth Objectives. (arXiv:2107.08800v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08784",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_R/0/1/0/all/0/1\">Rong Pan</a>",
          "description": "Recurrence data arise from multi-disciplinary domains spanning reliability,\ncyber security, healthcare, online retailing, etc. This paper investigates an\nadditive-tree-based approach, known as Boost-R (Boosting for Recurrence Data),\nfor recurrent event data with both static and dynamic features. Boost-R\nconstructs an ensemble of gradient boosted additive trees to estimate the\ncumulative intensity function of the recurrent event process, where a new tree\nis added to the ensemble by minimizing the regularized L2 distance between the\nobserved and predicted cumulative intensity. Unlike conventional regression\ntrees, a time-dependent function is constructed by Boost-R on each tree leaf.\nThe sum of these functions, from multiple trees, yields the ensemble estimator\nof the cumulative intensity. The divide-and-conquer nature of tree-based\nmethods is appealing when hidden sub-populations exist within a heterogeneous\npopulation. The non-parametric nature of regression trees helps to avoid\nparametric assumptions on the complex interactions between event processes and\nfeatures. Critical insights and advantages of Boost-R are investigated through\ncomprehensive numerical examples. Datasets and computer code of Boost-R are\nmade available on GitHub. To our best knowledge, Boost-R is the first gradient\nboosted additive-tree-based approach for modeling large-scale recurrent event\ndata with both static and dynamic feature information.",
          "link": "http://arxiv.org/abs/2107.08784",
          "publishedOn": "2021-07-20T02:04:46.685Z",
          "wordCount": null,
          "title": "Boost-R: Gradient Boosted Trees for Recurrence Data. (arXiv:2107.08784v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08045",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Navarro_C/0/1/0/all/0/1\">Carlos Mougan Navarro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanellos_G/0/1/0/all/0/1\">Georgios Kanellos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gottron_T/0/1/0/all/0/1\">Thomas Gottron</a>",
          "description": "Explainable AI constitutes a fundamental step towards establishing fairness\nand addressing bias in algorithmic decision-making. Despite the large body of\nwork on the topic, the benefit of solutions is mostly evaluated from a\nconceptual or theoretical point of view and the usefulness for real-world use\ncases remains uncertain. In this work, we aim to state clear user-centric\ndesiderata for explainable AI reflecting common explainability needs\nexperienced in statistical production systems of the European Central Bank. We\nlink the desiderata to archetypical user roles and give examples of techniques\nand methods which can be used to address the user's needs. To this end, we\nprovide two concrete use cases from the domain of statistical data production\nin central banks: the detection of outliers in the Centralised Securities\nDatabase and the data-driven identification of data quality checks for the\nSupervisory Banking data system.",
          "link": "http://arxiv.org/abs/2107.08045",
          "publishedOn": "2021-07-20T02:04:46.586Z",
          "wordCount": null,
          "title": "Desiderata for Explainable AI in statistical production systems of the European Central Bank. (arXiv:2107.08045v1 [cs.CY])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08114",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yuanchao Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feriani_A/0/1/0/all/0/1\">Amal Feriani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hossain_E/0/1/0/all/0/1\">Ekram Hossain</a>",
          "description": "Multi-Agent Reinforcement Learning (MARL) is a challenging subarea of\nReinforcement Learning due to the non-stationarity of the environments and the\nlarge dimensionality of the combined action space. Deep MARL algorithms have\nbeen applied to solve different task offloading problems. However, in\nreal-world applications, information required by the agents (i.e. rewards and\nstates) are subject to noise and alterations. The stability and the robustness\nof deep MARL to practical challenges is still an open research problem. In this\nwork, we apply state-of-the art MARL algorithms to solve task offloading with\nreward uncertainty. We show that perturbations in the reward signal can induce\ndecrease in the performance compared to learning with perfect rewards. We\nexpect this paper to stimulate more research in studying and addressing the\npractical challenges of deploying deep MARL solutions in wireless\ncommunications systems.",
          "link": "http://arxiv.org/abs/2107.08114",
          "publishedOn": "2021-07-20T02:04:46.584Z",
          "wordCount": null,
          "title": "Decentralized Multi-Agent Reinforcement Learning for Task Offloading Under Uncertainty. (arXiv:2107.08114v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08074",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guevara_J/0/1/0/all/0/1\">Jorge Guevara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borges_D/0/1/0/all/0/1\">Dario Borges</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watson_C/0/1/0/all/0/1\">Campbell Watson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zadrozny_B/0/1/0/all/0/1\">Bianca Zadrozny</a>",
          "description": "Future climate change scenarios are usually hypothesized using simulations\nfrom weather generators. However, there only a few works comparing and\nevaluating promising deep learning models for weather generation against\nclassical approaches. This study shows preliminary results making such\nevaluations for the multisite precipitation synthesis task. We compared two\nopen-source weather generators: IBMWeathergen (an extension of the Weathergen\nlibrary) and RGeneratePrec, and two deep generative models: GAN and VAE, on a\nvariety of metrics. Our preliminary results can serve as a guide for improving\nthe design of deep learning architectures and algorithms for the multisite\nprecipitation synthesis task.",
          "link": "http://arxiv.org/abs/2107.08074",
          "publishedOn": "2021-07-20T02:04:46.581Z",
          "wordCount": null,
          "title": "A comparative study of stochastic and deep generative models for multisite precipitation synthesis. (arXiv:2107.08074v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08761",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bartz_E/0/1/0/all/0/1\">Eva Bartz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaefferer_M/0/1/0/all/0/1\">Martin Zaefferer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mersmann_O/0/1/0/all/0/1\">Olaf Mersmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bartz_Beielstein_T/0/1/0/all/0/1\">Thomas Bartz-Beielstein</a>",
          "description": "Machine learning algorithms such as random forests or xgboost are gaining\nmore importance and are increasingly incorporated into production processes in\norder to enable comprehensive digitization and, if possible, automation of\nprocesses. Hyperparameters of these algorithms used have to be set\nappropriately, which can be referred to as hyperparameter tuning or\noptimization. Based on the concept of tunability, this article presents an\noverview of theoretical and practical results for popular machine learning\nalgorithms. This overview is accompanied by an experimental analysis of 30\nhyperparameters from six relevant machine learning algorithms. In particular,\nit provides (i) a survey of important hyperparameters, (ii) two parameter\ntuning studies, and (iii) one extensive global parameter tuning study, as well\nas (iv) a new way, based on consensus ranking, to analyze results from multiple\nalgorithms. The R package mlr is used as a uniform interface to the machine\nlearning models. The R package SPOT is used to perform the actual tuning\n(optimization). All additional code is provided together with this paper.",
          "link": "http://arxiv.org/abs/2107.08761",
          "publishedOn": "2021-07-20T02:04:46.575Z",
          "wordCount": null,
          "title": "Experimental Investigation and Evaluation of Model-based Hyperparameter Optimization. (arXiv:2107.08761v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08751",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Memmel_M/0/1/0/all/0/1\">Marius Memmel</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gonzalez_C/0/1/0/all/0/1\">Camila Gonzalez</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mukhopadhyay_A/0/1/0/all/0/1\">Anirban Mukhopadhyay</a>",
          "description": "Deep learning for medical imaging suffers from temporal and privacy-related\nrestrictions on data availability. To still obtain viable models, continual\nlearning aims to train in sequential order, as and when data is available. The\nmain challenge that continual learning methods face is to prevent catastrophic\nforgetting, i.e., a decrease in performance on the data encountered earlier.\nThis issue makes continuous training of segmentation models for medical\napplications extremely difficult. Yet, often, data from at least two different\ndomains is available which we can exploit to train the model in a way that it\ndisregards domain-specific information. We propose an architecture that\nleverages the simultaneous availability of two or more datasets to learn a\ndisentanglement between the content and domain in an adversarial fashion. The\ndomain-invariant content representation then lays the base for continual\nsemantic segmentation. Our approach takes inspiration from domain adaptation\nand combines it with continual learning for hippocampal segmentation in brain\nMRI. We showcase that our method reduces catastrophic forgetting and\noutperforms state-of-the-art continual learning methods.",
          "link": "http://arxiv.org/abs/2107.08751",
          "publishedOn": "2021-07-20T02:04:46.574Z",
          "wordCount": null,
          "title": "Adversarial Continual Learning for Multi-Domain Hippocampal Segmentation. (arXiv:2107.08751v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08211",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1\">Soumyadeep Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Sanjay Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verma_J/0/1/0/all/0/1\">Janu Verma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1\">Awanish Kumar</a>",
          "description": "In order to train robust deep learning models, large amounts of labelled data\nis required. However, in the absence of such large repositories of labelled\ndata, unlabeled data can be exploited for the same. Semi-Supervised learning\naims to utilize such unlabeled data for training classification models. Recent\nprogress of self-training based approaches have shown promise in this area,\nwhich leads to this study where we utilize an ensemble approach for the same. A\nby-product of any semi-supervised approach may be loss of calibration of the\ntrained model especially in scenarios where unlabeled data may contain\nout-of-distribution samples, which leads to this investigation on how to adapt\nto such effects. Our proposed algorithm carefully avoids common pitfalls in\nutilizing unlabeled data and leads to a more accurate and calibrated supervised\nmodel compared to vanilla self-training based student-teacher algorithms. We\nperform several experiments on the popular STL-10 database followed by an\nextensive analysis of our approach and study its effects on model accuracy and\ncalibration.",
          "link": "http://arxiv.org/abs/2107.08211",
          "publishedOn": "2021-07-20T02:04:46.557Z",
          "wordCount": null,
          "title": "Self Training with Ensemble of Teacher Models. (arXiv:2107.08211v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08356",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xingbo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ming_Y/0/1/0/all/0/1\">Yao Ming</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1\">Tongshuang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_H/0/1/0/all/0/1\">Haipeng Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_H/0/1/0/all/0/1\">Huamin Qu</a>",
          "description": "Despite being a critical communication skill, grasping humor is challenging\n-- a successful use of humor requires a mixture of both engaging content\nbuild-up and an appropriate vocal delivery (e.g., pause). Prior studies on\ncomputational humor emphasize the textual and audio features immediately next\nto the punchline, yet overlooking longer-term context setup. Moreover, the\ntheories are usually too abstract for understanding each concrete humor\nsnippet. To fill in the gap, we develop DeHumor, a visual analytical system for\nanalyzing humorous behaviors in public speaking. To intuitively reveal the\nbuilding blocks of each concrete example, DeHumor decomposes each humorous\nvideo into multimodal features and provides inline annotations of them on the\nvideo script. In particular, to better capture the build-ups, we introduce\ncontent repetition as a complement to features introduced in theories of\ncomputational humor and visualize them in a context linking graph. To help\nusers locate the punchlines that have the desired features to learn, we\nsummarize the content (with keywords) and humor feature statistics on an\naugmented time matrix. With case studies on stand-up comedy shows and TED\ntalks, we show that DeHumor is able to highlight various building blocks of\nhumor examples. In addition, expert interviews with communication coaches and\nhumor researchers demonstrate the effectiveness of DeHumor for multimodal humor\nanalysis of speech content and vocal delivery.",
          "link": "http://arxiv.org/abs/2107.08356",
          "publishedOn": "2021-07-20T02:04:46.339Z",
          "wordCount": null,
          "title": "DeHumor: Visual Analytics for Decomposing Humor. (arXiv:2107.08356v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2004.05094",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Murray_M/0/1/0/all/0/1\">Michael Murray</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tanner_J/0/1/0/all/0/1\">Jared Tanner</a>",
          "description": "In its most elementary form, compressed sensing studies the design of\ndecoding algorithms to recover a sufficiently sparse vector or code from a\nlower dimensional linear measurement vector. Typically it is assumed that the\ndecoder has access to the encoder matrix, which in the combinatorial case is\nsparse and binary. In this paper we consider the problem of designing a decoder\nto recover a set of sparse codes from their linear measurements alone, that is\nwithout access to encoder matrix. To this end we study the matrix factorisation\ntask of recovering both the encoder and sparse coding matrices from the\nassociated linear measurement matrix. The contribution of this paper is a\ncomputationally efficient decoding algorithm, Decoder-Expander Based\nFactorisation, with strong performance guarantees. In particular, under mild\nassumptions on the sparse coding matrix and by deploying a novel random encoder\nmatrix, we prove that Decoder-Expander Based Factorisation recovers both the\nencoder and sparse coding matrix at the optimal measurement rate with high\nprobability and from a near optimal number of measurement vectors. In addition,\nour experiments demonstrate the efficacy and computational efficiency of our\nalgorithm in practice. Beyond compressed sensing our results may be of interest\nfor researchers working in areas such as linear sketching, coding theory and\nmatrix compression.",
          "link": "http://arxiv.org/abs/2004.05094",
          "publishedOn": "2021-07-20T02:04:46.339Z",
          "wordCount": null,
          "title": "Encoder blind combinatorial compressed sensing. (arXiv:2004.05094v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08353",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_C/0/1/0/all/0/1\">Chirag Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramdas_A/0/1/0/all/0/1\">Aaditya K. Ramdas</a>",
          "description": "We study the problem of post-hoc calibration for multiclass classification,\nwith an emphasis on histogram binning. Multiple works have focused on\ncalibration with respect to the confidence of just the predicted class (or\n'top-label'). We find that the popular notion of confidence calibration [Guo et\nal., 2017] is not sufficiently strong -- there exist predictors that are not\ncalibrated in any meaningful way but are perfectly confidence calibrated. We\npropose a closely related (but subtly different) notion, top-label calibration,\nthat accurately captures the intuition and simplicity of confidence\ncalibration, but addresses its drawbacks. We formalize a histogram binning (HB)\nalgorithm that reduces top-label multiclass calibration to the binary case,\nprove that it has clean theoretical guarantees without distributional\nassumptions, and perform a methodical study of its practical performance. Some\nprediction tasks require stricter notions of multiclass calibration such as\nclass-wise or canonical calibration. We formalize appropriate HB algorithms\ncorresponding to each of these goals. In experiments with deep neural nets, we\nfind that our principled versions of HB are often better than temperature\nscaling, for both top-label and class-wise calibration. Code for this work will\nbe made publicly available at https://github.com/aigen/df-posthoc-calibration.",
          "link": "http://arxiv.org/abs/2107.08353",
          "publishedOn": "2021-07-20T02:04:46.338Z",
          "wordCount": null,
          "title": "Top-label calibration. (arXiv:2107.08353v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2102.11830",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Richter_L/0/1/0/all/0/1\">Lorenz Richter</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sallandt_L/0/1/0/all/0/1\">Leon Sallandt</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nusken_N/0/1/0/all/0/1\">Nikolas N&#xfc;sken</a>",
          "description": "High-dimensional partial differential equations (PDEs) are ubiquitous in\neconomics, science and engineering. However, their numerical treatment poses\nformidable challenges since traditional grid-based methods tend to be\nfrustrated by the curse of dimensionality. In this paper, we argue that tensor\ntrains provide an appealing approximation framework for parabolic PDEs: the\ncombination of reformulations in terms of backward stochastic differential\nequations and regression-type methods in the tensor format holds the promise of\nleveraging latent low-rank structures enabling both compression and efficient\ncomputation. Following this paradigm, we develop novel iterative schemes,\ninvolving either explicit and fast or implicit and accurate updates. We\ndemonstrate in a number of examples that our methods achieve a favorable\ntrade-off between accuracy and computational efficiency in comparison with\nstate-of-the-art neural network based approaches.",
          "link": "http://arxiv.org/abs/2102.11830",
          "publishedOn": "2021-07-20T02:04:46.338Z",
          "wordCount": null,
          "title": "Solving high-dimensional parabolic PDEs using the tensor train format. (arXiv:2102.11830v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.12056",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Shi_C/0/1/0/all/0/1\">Changfa Shi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xian_M/0/1/0/all/0/1\">Min Xian</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhou_X/0/1/0/all/0/1\">Xiancheng Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_H/0/1/0/all/0/1\">Haotian Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cheng_H/0/1/0/all/0/1\">Heng-Da Cheng</a>",
          "description": "Liver segmentation from abdominal CT images is an essential step for liver\ncancer computer-aided diagnosis and surgical planning. However, both the\naccuracy and robustness of existing liver segmentation methods cannot meet the\nrequirements of clinical applications. In particular, for the common clinical\ncases where the liver tissue contains major pathology, current segmentation\nmethods show poor performance. In this paper, we propose a novel low-rank\ntensor decomposition (LRTD) based multi-atlas segmentation (MAS) framework that\nachieves accurate and robust pathological liver segmentation of CT images.\nFirstly, we propose a multi-slice LRTD scheme to recover the underlying\nlow-rank structure embedded in 3D medical images. It performs the LRTD on small\nimage segments consisting of multiple consecutive image slices. Then, we\npresent an LRTD-based atlas construction method to generate tumor-free liver\natlases that mitigates the performance degradation of liver segmentation due to\nthe presence of tumors. Finally, we introduce an LRTD-based MAS algorithm to\nderive patient-specific liver atlases for each test image, and to achieve\naccurate pairwise image registration and label propagation. Extensive\nexperiments on three public databases of pathological liver cases validate the\neffectiveness of the proposed method. Both qualitative and quantitative results\ndemonstrate that, in the presence of major pathology, the proposed method is\nmore accurate and robust than state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2102.12056",
          "publishedOn": "2021-07-20T02:04:46.337Z",
          "wordCount": null,
          "title": "Multi-Slice Low-Rank Tensor Decomposition Based Multi-Atlas Segmentation: Application to Automatic Pathological Liver CT Segmentation. (arXiv:2102.12056v3 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08928",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Blanzeisky_W/0/1/0/all/0/1\">William Blanzeisky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cunningham_P/0/1/0/all/0/1\">P&#xe1;draig Cunningham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kennedy_K/0/1/0/all/0/1\">Kenneth Kennedy</a>",
          "description": "A significant impediment to progress in research on bias in machine learning\n(ML) is the availability of relevant datasets. This situation is unlikely to\nchange much given the sensitivity of such data. For this reason, there is a\nrole for synthetic data in this research. In this short paper, we present one\nsuch family of synthetic data sets. We provide an overview of the data,\ndescribe how the level of bias can be varied, and present a simple example of\nan experiment on the data.",
          "link": "http://arxiv.org/abs/2107.08928",
          "publishedOn": "2021-07-20T02:04:46.336Z",
          "wordCount": null,
          "title": "Introducing a Family of Synthetic Datasets for Research on Bias in Machine Learning. (arXiv:2107.08928v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08273",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Hengguan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hongfu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1\">Chang Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Ye Wang</a>",
          "description": "Perception of time from sequentially acquired sensory inputs is rooted in\neveryday behaviors of individual organisms. Yet, most algorithms for\ntime-series modeling fail to learn dynamics of random event timings directly\nfrom visual or audio inputs, requiring timing annotations during training that\nare usually unavailable for real-world applications. For instance, neuroscience\nperspectives on postdiction imply that there exist variable temporal ranges\nwithin which the incoming sensory inputs can affect the earlier perception, but\nsuch temporal ranges are mostly unannotated for real applications such as\nautomatic speech recognition (ASR). In this paper, we present a probabilistic\nordinary differential equation (ODE), called STochastic boundaRy ODE (STRODE),\nthat learns both the timings and the dynamics of time series data without\nrequiring any timing annotations during training. STRODE allows the usage of\ndifferential equations to sample from the posterior point processes,\nefficiently and analytically. We further provide theoretical guarantees on the\nlearning of STRODE. Our empirical results show that our approach successfully\ninfers event timings of time series data. Our method achieves competitive or\nsuperior performances compared to existing state-of-the-art methods for both\nsynthetic and real-world datasets.",
          "link": "http://arxiv.org/abs/2107.08273",
          "publishedOn": "2021-07-20T02:04:46.247Z",
          "wordCount": null,
          "title": "STRODE: Stochastic Boundary Ordinary Differential Equation. (arXiv:2107.08273v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08264",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xingbo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jianben He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1\">Zhihua Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Muqiao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_H/0/1/0/all/0/1\">Huamin Qu</a>",
          "description": "Multimodal sentiment analysis aims to recognize people's attitudes from\nmultiple communication channels such as verbal content (i.e., text), voice, and\nfacial expressions. It has become a vibrant and important research topic in\nnatural language processing. Much research focuses on modeling the complex\nintra- and inter-modal interactions between different communication channels.\nHowever, current multimodal models with strong performance are often\ndeep-learning-based techniques and work like black boxes. It is not clear how\nmodels utilize multimodal information for sentiment predictions. Despite recent\nadvances in techniques for enhancing the explainability of machine learning\nmodels, they often target unimodal scenarios (e.g., images, sentences), and\nlittle research has been done on explaining multimodal models. In this paper,\nwe present an interactive visual analytics system, M2Lens, to visualize and\nexplain multimodal models for sentiment analysis. M2Lens provides explanations\non intra- and inter-modal interactions at the global, subset, and local levels.\nSpecifically, it summarizes the influence of three typical interaction types\n(i.e., dominance, complement, and conflict) on the model predictions. Moreover,\nM2Lens identifies frequent and influential multimodal features and supports the\nmulti-faceted exploration of model behaviors from language, acoustic, and\nvisual modalities. Through two case studies and expert interviews, we\ndemonstrate our system can help users gain deep insights into the multimodal\nmodels for sentiment analysis.",
          "link": "http://arxiv.org/abs/2107.08264",
          "publishedOn": "2021-07-20T02:04:46.210Z",
          "wordCount": null,
          "title": "M2Lens: Visualizing and Explaining Multimodal Models for Sentiment Analysis. (arXiv:2107.08264v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08310",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhe Yu</a>",
          "description": "This paper aims to improve machine learning fairness on multiple protected\nat-tributes. Machine learning fairness has attracted increasing attention since\nmachine learning models are increasingly used for high-stakes and high-risk\ndecisions. Most existing solutions for machine learning fairness only target\none protected attribute(e.g. sex) at a time. These solutions cannot generate a\nmachine learning model which is fair against every protected attribute (e.g.\nboth sex and race) at the same time. To solve this problem, we propose\nFairBalance in this paper to balance the distribution of training data across\nevery protected attribute before training the machine learning models. Our\nresults show that, under the assumption of unbiased ground truth labels,\nFairBalance can significantly reduce bias metrics (AOD, EOD, and SPD) on every\nknown protected attribute without much, if not any damage to the prediction\nperformance.",
          "link": "http://arxiv.org/abs/2107.08310",
          "publishedOn": "2021-07-20T02:04:46.210Z",
          "wordCount": null,
          "title": "Fair Balance: Mitigating Machine Learning Bias Against Multiple Protected Attributes With Data Balancing. (arXiv:2107.08310v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2101.11296",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yiying Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Wei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Huaimin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mi_H/0/1/0/all/0/1\">Haibo Mi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hospedales_T/0/1/0/all/0/1\">Timothy M. Hospedales</a>",
          "description": "Federated learning (FL) enables distributed participants to collectively\nlearn a strong global model without sacrificing their individual data privacy.\nMainstream FL approaches require each participant to share a common network\narchitecture and further assume that data are are sampled IID across\nparticipants. However, in real-world deployments participants may require\nheterogeneous network architectures; and the data distribution is almost\ncertainly non-uniform across participants. To address these issues we introduce\nFedH2L, which is agnostic to both the model architecture and robust to\ndifferent data distributions across participants. In contrast to approaches\nsharing parameters or gradients, FedH2L relies on mutual distillation,\nexchanging only posteriors on a shared seed set between participants in a\ndecentralized manner. This makes it extremely bandwidth efficient, model\nagnostic, and crucially produces models capable of performing well on the whole\ndata distribution when learning from heterogeneous silos.",
          "link": "http://arxiv.org/abs/2101.11296",
          "publishedOn": "2021-07-20T02:04:46.209Z",
          "wordCount": null,
          "title": "FedH2L: Federated Learning with Model and Statistical Heterogeneity. (arXiv:2101.11296v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.06979",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kato_M/0/1/0/all/0/1\">Masahiro Kato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teshima_T/0/1/0/all/0/1\">Takeshi Teshima</a>",
          "description": "Density ratio estimation (DRE) is at the core of various machine learning\ntasks such as anomaly detection and domain adaptation. In existing studies on\nDRE, methods based on Bregman divergence (BD) minimization have been\nextensively studied. However, BD minimization when applied with highly flexible\nmodels, such as deep neural networks, tends to suffer from what we call\ntrain-loss hacking, which is a source of overfitting caused by a typical\ncharacteristic of empirical BD estimators. In this paper, to mitigate\ntrain-loss hacking, we propose a non-negative correction for empirical BD\nestimators. Theoretically, we confirm the soundness of the proposed method\nthrough a generalization error bound. Through our experiments, the proposed\nmethods show a favorable performance in inlier-based outlier detection.",
          "link": "http://arxiv.org/abs/2006.06979",
          "publishedOn": "2021-07-20T02:04:46.206Z",
          "wordCount": null,
          "title": "Non-Negative Bregman Divergence Minimization for Deep Direct Density Ratio Estimation. (arXiv:2006.06979v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.02443",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Pomponi_J/0/1/0/all/0/1\">Jary Pomponi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Scardapane_S/0/1/0/all/0/1\">Simone Scardapane</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Uncini_A/0/1/0/all/0/1\">Aurelio Uncini</a>",
          "description": "Catastrophic forgetting (CF) happens whenever a neural network overwrites\npast knowledge while being trained on new tasks. Common techniques to handle CF\ninclude regularization of the weights (using, e.g., their importance on past\ntasks), and rehearsal strategies, where the network is constantly re-trained on\npast data. Generative models have also been applied for the latter, in order to\nhave endless sources of data. In this paper, we propose a novel method that\ncombines the strengths of regularization and generative-based rehearsal\napproaches. Our generative model consists of a normalizing flow (NF), a\nprobabilistic and invertible neural network, trained on the internal embeddings\nof the network. By keeping a single NF conditioned on the task, we show that\nour memory overhead remains constant. In addition, exploiting the invertibility\nof the NF, we propose a simple approach to regularize the network's embeddings\nwith respect to past tasks. We show that our method performs favorably with\nrespect to state-of-the-art approaches in the literature, with bounded\ncomputational power and memory overheads.",
          "link": "http://arxiv.org/abs/2007.02443",
          "publishedOn": "2021-07-20T02:04:46.205Z",
          "wordCount": null,
          "title": "Pseudo-Rehearsal for Continual Learning with Normalizing Flows. (arXiv:2007.02443v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08209",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Tasche_D/0/1/0/all/0/1\">Dirk Tasche</a>",
          "description": "For the binary prevalence quantification problem under prior probability\nshift, we determine the asymptotic variance of the maximum likelihood\nestimator. We find that it is a function of the Brier score for the regression\nof the class label against the features under the test data set distribution.\nThis observation suggests that optimising the accuracy of a base classifier on\nthe training data set helps to reduce the variance of the related quantifier on\nthe test data set. Therefore, we also point out training criteria for the base\nclassifier that imply optimisation of both of the Brier scores on the training\nand the test data sets.",
          "link": "http://arxiv.org/abs/2107.08209",
          "publishedOn": "2021-07-20T02:04:46.127Z",
          "wordCount": null,
          "title": "Minimising quantifier variance under prior probability shift. (arXiv:2107.08209v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2102.03088",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Li Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_X/0/1/0/all/0/1\">Xianghao Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_R/0/1/0/all/0/1\">Rumeng Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guan_X/0/1/0/all/0/1\">Xiaoqing Guan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pilanci_M/0/1/0/all/0/1\">Mert Pilanci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">You Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1\">Zhiyuan Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1\">Guang Li</a>",
          "description": "Electronic nose has been proven to be effective in alternative herbal\nmedicine classification, but due to the nature of supervised learning, previous\nresearch heavily relies on the labelled training data, which are time-costly\nand labor-intensive to collect. To alleviate the critical dependency on the\ntraining data in real-world applications, this study aims to improve\nclassification accuracy via data augmentation strategies. The effectiveness of\nfive data augmentation strategies under different training data inadequacy are\ninvestigated in two scenarios: the noise-free scenario where different\navailabilities of unlabelled data were considered, and the noisy scenario where\ndifferent levels of Gaussian noises and translational shifts were added to\nrepresent sensor drifts. The five augmentation strategies, namely noise-adding\ndata augmentation, semi-supervised learning, classifier-based online learning,\nInductive Conformal Prediction (ICP) online learning and our novel ensemble ICP\nonline learning proposed in this study, are experimented and compared against\nsupervised learning baseline, with Linear Discriminant Analysis (LDA) and\nSupport Vector Machine (SVM) as the classifiers. Our novel strategy, ensemble\nICP online learning, outperforms the others by showing non-decreasing\nclassification accuracy on all tasks and a significant improvement on most\nsimulated tasks (25out of 36 tasks,p<=0.05). Furthermore, this study provides a\nsystematic analysis of different augmentation strategies. It shows at least one\nstrategy significantly improved the classification accuracy with LDA (p<=0.05)\nand non-decreasing classification accuracy with SVM in each task. In\nparticular, our proposed strategy demonstrated both effectiveness and\nrobustness in boosting the classification model generalizability, which can be\nemployed in other machine learning applications.",
          "link": "http://arxiv.org/abs/2102.03088",
          "publishedOn": "2021-07-20T02:04:46.115Z",
          "wordCount": null,
          "title": "Boost AI Power: Data Augmentation Strategies with unlabelled Data and Conformal Prediction, a Case in Alternative Herbal Medicine Discrimination with Electronic Nose. (arXiv:2102.03088v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.12301",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Lin_T/0/1/0/all/0/1\">Tianyi Lin</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zheng_Z/0/1/0/all/0/1\">Zeyu Zheng</a>, <a href=\"http://arxiv.org/find/math/1/au:+Chen_E/0/1/0/all/0/1\">Elynn Y. Chen</a>, <a href=\"http://arxiv.org/find/math/1/au:+Cuturi_M/0/1/0/all/0/1\">Marco Cuturi</a>, <a href=\"http://arxiv.org/find/math/1/au:+Jordan_M/0/1/0/all/0/1\">Michael I. Jordan</a>",
          "description": "Optimal transport (OT) distances are increasingly used as loss functions for\nstatistical inference, notably in the learning of generative models or\nsupervised learning. Yet, the behavior of minimum Wasserstein estimators is\npoorly understood, notably in high-dimensional regimes or under model\nmisspecification. In this work we adopt the viewpoint of projection robust (PR)\nOT, which seeks to maximize the OT cost between two measures by choosing a\n$k$-dimensional subspace onto which they can be projected. Our first\ncontribution is to establish several fundamental statistical properties of PR\nWasserstein distances, complementing and improving previous literature that has\nbeen restricted to one-dimensional and well-specified cases. Next, we propose\nthe integral PR Wasserstein (IPRW) distance as an alternative to the PRW\ndistance, by averaging rather than optimizing on subspaces. Our complexity\nbounds can help explain why both PRW and IPRW distances outperform Wasserstein\ndistances empirically in high-dimensional inference tasks. Finally, we consider\nparametric inference using the PRW distance. We provide an asymptotic guarantee\nof two types of minimum PRW estimators and formulate a central limit theorem\nfor max-sliced Wasserstein estimator under model misspecification. To enable\nour analysis on PRW with projection dimension larger than one, we devise a\nnovel combination of variational analysis and statistical theory.",
          "link": "http://arxiv.org/abs/2006.12301",
          "publishedOn": "2021-07-20T02:04:46.114Z",
          "wordCount": null,
          "title": "On Projection Robust Optimal Transport: Sample Complexity and Model Misspecification. (arXiv:2006.12301v5 [math.ST] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08142",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1\">Ashesh Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pero_L/0/1/0/all/0/1\">Luca Del Pero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grimmett_H/0/1/0/all/0/1\">Hugo Grimmett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ondruska_P/0/1/0/all/0/1\">Peter Ondruska</a>",
          "description": "Despite the numerous successes of machine learning over the past decade\n(image recognition, decision-making, NLP, image synthesis), self-driving\ntechnology has not yet followed the same trend. In this paper, we study the\nhistory, composition, and development bottlenecks of the modern self-driving\nstack. We argue that the slow progress is caused by approaches that require too\nmuch hand-engineering, an over-reliance on road testing, and high fleet\ndeployment costs. We observe that the classical stack has several bottlenecks\nthat preclude the necessary scale needed to capture the long tail of rare\nevents. To resolve these problems, we outline the principles of Autonomy 2.0,\nan ML-first approach to self-driving, as a viable alternative to the currently\nadopted state-of-the-art. This approach is based on (i) a fully differentiable\nAV stack trainable from human demonstrations, (ii) closed-loop data-driven\nreactive simulation, and (iii) large-scale, low-cost data collections as\ncritical solutions towards scalability issues. We outline the general\narchitecture, survey promising works in this direction and propose key\nchallenges to be addressed by the community in the future.",
          "link": "http://arxiv.org/abs/2107.08142",
          "publishedOn": "2021-07-20T02:04:46.113Z",
          "wordCount": null,
          "title": "Autonomy 2.0: Why is self-driving always 5 years away?. (arXiv:2107.08142v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08179",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Birmpa_P/0/1/0/all/0/1\">Panagiota Birmpa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Feng_J/0/1/0/all/0/1\">Jinchao Feng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Katsoulakis_M/0/1/0/all/0/1\">Markos A. Katsoulakis</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rey_Bellet_L/0/1/0/all/0/1\">Luc Rey-Bellet</a>",
          "description": "Probabilistic graphical models are a fundamental tool in probabilistic\nmodeling, machine learning and artificial intelligence. They allow us to\nintegrate in a natural way expert knowledge, physical modeling, heterogeneous\nand correlated data and quantities of interest. For exactly this reason,\nmultiple sources of model uncertainty are inherent within the modular structure\nof the graphical model. In this paper we develop information-theoretic, robust\nuncertainty quantification methods and non-parametric stress tests for directed\ngraphical models to assess the effect and the propagation through the graph of\nmulti-sourced model uncertainties to quantities of interest. These methods\nallow us to rank the different sources of uncertainty and correct the graphical\nmodel by targeting its most impactful components with respect to the quantities\nof interest. Thus, from a machine learning perspective, we provide a\nmathematically rigorous approach to correctability that guarantees a systematic\nselection for improvement of components of a graphical model while controlling\npotential new errors created in the process in other parts of the model. We\ndemonstrate our methods in two physico-chemical examples, namely quantum\nscale-informed chemical kinetics and materials screening to improve the\nefficiency of fuel cells.",
          "link": "http://arxiv.org/abs/2107.08179",
          "publishedOn": "2021-07-20T02:04:46.106Z",
          "wordCount": null,
          "title": "Model Uncertainty and Correctability for Directed Graphical Models. (arXiv:2107.08179v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08066",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Samo_Y/0/1/0/all/0/1\">Yves-Laurent Kom Samo</a>",
          "description": "We introduce the first application of the lean methodology to machine\nlearning projects. Similar to lean startups and lean manufacturing, we argue\nthat lean machine learning (LeanML) can drastically slash avoidable wastes in\ncommercial machine learning projects, reduce the business risk in investing in\nmachine learning capabilities and, in so doing, further democratize access to\nmachine learning. The lean design pattern we propose in this paper is based on\ntwo realizations. First, it is possible to estimate the best performance one\nmay achieve when predicting an outcome $y \\in \\mathcal{Y}$ using a given set of\nexplanatory variables $x \\in \\mathcal{X}$, for a wide range of performance\nmetrics, and without training any predictive model. Second, doing so is\nconsiderably easier, faster, and cheaper than learning the best predictive\nmodel. We derive formulae expressing the best $R^2$, MSE, classification\naccuracy, and log-likelihood per observation achievable when using $x$ to\npredict $y$ as a function of the mutual information $I\\left(y; x\\right)$, and\npossibly a measure of the variability of $y$ (e.g. its Shannon entropy in the\ncase of classification accuracy, and its variance in the case regression MSE).\nWe illustrate the efficacy of the LeanML design pattern on a wide range of\nregression and classification problems, synthetic and real-life.",
          "link": "http://arxiv.org/abs/2107.08066",
          "publishedOn": "2021-07-20T02:04:46.095Z",
          "wordCount": null,
          "title": "LeanML: A Design Pattern To Slash Avoidable Wastes in Machine Learning Projects. (arXiv:2107.08066v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08068",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1\">J. G. Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gluzman_M/0/1/0/all/0/1\">Mark Gluzman</a>",
          "description": "The policy improvement bound on the difference of the discounted returns\nplays a crucial role in the theoretical justification of the trust-region\npolicy optimization (TRPO) algorithm. The existing bound leads to a degenerate\nbound when the discount factor approaches one, making the applicability of TRPO\nand related algorithms questionable when the discount factor is close to one.\nWe refine the results in \\cite{Schulman2015, Achiam2017} and propose a novel\nbound that is \"continuous\" in the discount factor. In particular, our bound is\napplicable for MDPs with the long-run average rewards as well.",
          "link": "http://arxiv.org/abs/2107.08068",
          "publishedOn": "2021-07-20T02:04:46.094Z",
          "wordCount": null,
          "title": "Refined Policy Improvement Bounds for MDPs. (arXiv:2107.08068v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2011.12916",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Holderrieth_P/0/1/0/all/0/1\">Peter Holderrieth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hutchinson_M/0/1/0/all/0/1\">Michael Hutchinson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teh_Y/0/1/0/all/0/1\">Yee Whye Teh</a>",
          "description": "Motivated by objects such as electric fields or fluid streams, we study the\nproblem of learning stochastic fields, i.e. stochastic processes whose samples\nare fields like those occurring in physics and engineering. Considering general\ntransformations such as rotations and reflections, we show that spatial\ninvariance of stochastic fields requires an inference model to be equivariant.\nLeveraging recent advances from the equivariance literature, we study\nequivariance in two classes of models. Firstly, we fully characterise\nequivariant Gaussian processes. Secondly, we introduce Steerable Conditional\nNeural Processes (SteerCNPs), a new, fully equivariant member of the Neural\nProcess family. In experiments with Gaussian process vector fields, images, and\nreal-world weather data, we observe that SteerCNPs significantly improve the\nperformance of previous models and equivariance leads to improvements in\ntransfer learning tasks.",
          "link": "http://arxiv.org/abs/2011.12916",
          "publishedOn": "2021-07-20T02:04:45.372Z",
          "wordCount": null,
          "title": "Equivariant Learning of Stochastic Fields: Gaussian Processes and Steerable Conditional Neural Processes. (arXiv:2011.12916v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.11866",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1\">Tengyu Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhuoran Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhaoran Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yingbin Liang</a>",
          "description": "Designing off-policy reinforcement learning algorithms is typically a very\nchallenging task, because a desirable iteration update often involves an\nexpectation over an on-policy distribution. Prior off-policy actor-critic (AC)\nalgorithms have introduced a new critic that uses the density ratio for\nadjusting the distribution mismatch in order to stabilize the convergence, but\nat the cost of potentially introducing high biases due to the estimation errors\nof both the density ratio and value function. In this paper, we develop a\ndoubly robust off-policy AC (DR-Off-PAC) for discounted MDP, which can take\nadvantage of learned nuisance functions to reduce estimation errors. Moreover,\nDR-Off-PAC adopts a single timescale structure, in which both actor and critics\nare updated simultaneously with constant stepsize, and is thus more sample\nefficient than prior algorithms that adopt either two timescale or nested-loop\nstructure. We study the finite-time convergence rate and characterize the\nsample complexity for DR-Off-PAC to attain an $\\epsilon$-accurate optimal\npolicy. We also show that the overall convergence of DR-Off-PAC is doubly\nrobust to the approximation errors that depend only on the expressive power of\napproximation functions. To the best of our knowledge, our study establishes\nthe first overall sample complexity analysis for a single time-scale off-policy\nAC algorithm.",
          "link": "http://arxiv.org/abs/2102.11866",
          "publishedOn": "2021-07-20T02:04:45.244Z",
          "wordCount": null,
          "title": "Doubly Robust Off-Policy Actor-Critic: Convergence and Optimality. (arXiv:2102.11866v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08190",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Eren_M/0/1/0/all/0/1\">Maksim E. Eren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Solovyev_N/0/1/0/all/0/1\">Nick Solovyev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamer_C/0/1/0/all/0/1\">Chris Hamer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McDonald_R/0/1/0/all/0/1\">Renee McDonald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alexandrov_B/0/1/0/all/0/1\">Boian S. Alexandrov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nicholas_C/0/1/0/all/0/1\">Charles Nicholas</a>",
          "description": "The unprecedented outbreak of Severe Acute Respiratory Syndrome Coronavirus-2\n(SARS-CoV-2), or COVID-19, continues to be a significant worldwide problem. As\na result, a surge of new COVID-19 related research has followed suit. The\ngrowing number of publications requires document organization methods to\nidentify relevant information. In this paper, we expand upon our previous work\nwith clustering the CORD-19 dataset by applying multi-dimensional analysis\nmethods. Tensor factorization is a powerful unsupervised learning method\ncapable of discovering hidden patterns in a document corpus. We show that a\nhigher-order representation of the corpus allows for the simultaneous grouping\nof similar articles, relevant journals, authors with similar research\ninterests, and topic keywords. These groupings are identified within and among\nthe latent components extracted via tensor decomposition. We further\ndemonstrate the application of this method with a publicly available\ninteractive visualization of the dataset.",
          "link": "http://arxiv.org/abs/2107.08190",
          "publishedOn": "2021-07-20T02:04:44.973Z",
          "wordCount": null,
          "title": "COVID-19 Multidimensional Kaggle Literature Organization. (arXiv:2107.08190v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08484",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chrostoforidis_A/0/1/0/all/0/1\">Aristeidis Chrostoforidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kyriakides_G/0/1/0/all/0/1\">George Kyriakides</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Margaritis_K/0/1/0/all/0/1\">Konstantinos Margaritis</a>",
          "description": "In this work, we propose a novel evolutionary algorithm for neural\narchitecture search, applicable to global search spaces. The algorithm's\narchitectural representation organizes the topology in multiple hierarchical\nmodules, while the design process exploits this representation, in order to\nexplore the search space. We also employ a curation system, which promotes the\nutilization of well performing sub-structures to subsequent generations. We\napply our method to Fashion-MNIST and NAS-Bench101, achieving accuracies of\n$93.2\\%$ and $94.8\\%$ respectively in a relatively small number of generations.",
          "link": "http://arxiv.org/abs/2107.08484",
          "publishedOn": "2021-07-20T02:04:44.663Z",
          "wordCount": 519,
          "title": "A Novel Evolutionary Algorithm for Hierarchical Neural Architecture Search. (arXiv:2107.08484v1 [cs.NE])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08649",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Lim_D/0/1/0/all/0/1\">Dong-Young Lim</a>, <a href=\"http://arxiv.org/find/math/1/au:+Neufeld_A/0/1/0/all/0/1\">Ariel Neufeld</a>, <a href=\"http://arxiv.org/find/math/1/au:+Sabanis_S/0/1/0/all/0/1\">Sotirios Sabanis</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhang_Y/0/1/0/all/0/1\">Ying Zhang</a>",
          "description": "We consider non-convex stochastic optimization problems where the objective\nfunctions have super-linearly growing and discontinuous stochastic gradients.\nIn such a setting, we provide a non-asymptotic analysis for the tamed\nunadjusted stochastic Langevin algorithm (TUSLA) introduced in Lovas et al.\n(2021). In particular, we establish non-asymptotic error bounds for the TUSLA\nalgorithm in Wasserstein-1 and Wasserstein-2 distances. The latter result\nenables us to further derive non-asymptotic estimates for the expected excess\nrisk. To illustrate the applicability of the main results, we consider an\nexample from transfer learning with ReLU neural networks, which represents a\nkey paradigm in machine learning. Numerical experiments are presented for the\naforementioned example which supports our theoretical findings. Hence, in this\nsetting, we demonstrate both theoretically and numerically that the TUSLA\nalgorithm can solve the optimization problem involving neural networks with\nReLU activation function. Besides, we provide simulation results for synthetic\nexamples where popular algorithms, e.g. ADAM, AMSGrad, RMSProp, and (vanilla)\nSGD, may fail to find the minimizer of the objective functions due to the\nsuper-linear growth and the discontinuity of the corresponding stochastic\ngradient, while the TUSLA algorithm converges rapidly to the optimal solution.",
          "link": "http://arxiv.org/abs/2107.08649",
          "publishedOn": "2021-07-20T02:04:44.607Z",
          "wordCount": 655,
          "title": "Non-asymptotic estimates for TUSLA algorithm for non-convex learning with applications to neural networks with ReLU activation function. (arXiv:2107.08649v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08442",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Huafeng Wang</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1\">Chonggang Lu</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qi Zhang</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Zhimin Hu</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_X/0/1/0/all/0/1\">Xiaodong Yuan</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Pingshu Zhang</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wanquan Liu</a> (3) ((1) School of Information, North China University of Technology,(2) Department of Neurology, Kailuan General Hospital, Tangshan,(3) School of Intelligent Systems Engineering, Sun Yat-sen University)",
          "description": "Sleep staging assumes an important role in the diagnosis of sleep disorders.\nIn general, experts classify sleep stages manually based on polysomnography\n(PSG), which is quite time-consuming. Meanwhile, the acquisition of multiple\nsignals is complex, which can affect the subject's sleep. Therefore, the use of\nsingle-channel electroencephalogram (EEG) for automatic sleep staging has\nbecome mainstream. In the literature, a large number of sleep staging methods\nbased on single-channel EEG have been proposed with good results and realize\nthe preliminary automation of sleep staging. However, the performance for most\nof these methods in the N1 stage is generally not high. In this paper, we\npropose a deep learning model SDAN based on raw EEG. The method utilises a\none-dimensional convolutional neural network (CNN) to automatically extract\nfeatures from raw EEG. It serially combines the channel attention and spatial\nattention mechanisms to filter and highlight key information and then uses soft\nthreshold to eliminate redundant information. Additionally, we introduce a\nresidual network to avoid degradation problems caused by network deepening.\nExperiments were conducted using two datasets with 5-fold cross-validation and\nhold-out validation method. The final average accuracy, overall accuracy, macro\nF1 score and Cohen's Kappa coefficient of the model reach 96.74%, 91.86%,\n82.64% and 0.8742 on the Sleep-EDF dataset, and 95.98%, 89.96%, 79.08% and\n0.8216 on the Sleep-EDFx dataset. Significantly, our model performed superiorly\nin the N1 stage, with F1 scores of 54.08% and 52.49% on the two datasets\nrespectively. The results show the superiority of our network over the best\nexisting methods, reaching a new state-of-the-art. In particular, the present\nmethod achieves excellent results in the N1 sleep stage compared to other\nmethods.",
          "link": "http://arxiv.org/abs/2107.08442",
          "publishedOn": "2021-07-20T02:04:44.589Z",
          "wordCount": 744,
          "title": "Sleep Staging Based on Serialized Dual Attention Network. (arXiv:2107.08442v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08562",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mrabah_N/0/1/0/all/0/1\">Nairouz Mrabah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bouguessa_M/0/1/0/all/0/1\">Mohamed Bouguessa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Touati_M/0/1/0/all/0/1\">Mohamed Fawzi Touati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ksantini_R/0/1/0/all/0/1\">Riadh Ksantini</a>",
          "description": "Most recent graph clustering methods have resorted to Graph Auto-Encoders\n(GAEs) to perform joint clustering and embedding learning. However, two\ncritical issues have been overlooked. First, the accumulative error, inflicted\nby learning with noisy clustering assignments, degrades the effectiveness and\nrobustness of the clustering model. This problem is called Feature Randomness.\nSecond, reconstructing the adjacency matrix sets the model to learn irrelevant\nsimilarities for the clustering task. This problem is called Feature Drift.\nInterestingly, the theoretical relation between the aforementioned problems has\nnot yet been investigated. We study these issues from two aspects: (1) the\nexistence of a trade-off between Feature Randomness and Feature Drift when\nclustering and reconstruction are performed at the same level, and (2) the\nproblem of Feature Drift is more pronounced for GAE models, compared with\nvanilla auto-encoder models, due to the graph convolutional operation and the\ngraph decoding design. Motivated by these findings, we reformulate the\nGAE-based clustering methodology. Our solution is two-fold. First, we propose a\nsampling operator $\\Xi$ that triggers a protection mechanism against the noisy\nclustering assignments. Second, we propose an operator $\\Upsilon$ that triggers\na correction mechanism against Feature Drift by gradually transforming the\nreconstructed graph into a clustering-oriented one. As principal advantages,\nour solution grants a considerable improvement in clustering effectiveness and\nrobustness and can be easily tailored to existing GAE models.",
          "link": "http://arxiv.org/abs/2107.08562",
          "publishedOn": "2021-07-20T02:04:44.571Z",
          "wordCount": 653,
          "title": "Rethinking Graph Autoencoder Models for Attributed Graph Clustering. (arXiv:2107.08562v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08593",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Wang_Y/0/1/0/all/0/1\">Yiran Wang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Li_Z/0/1/0/all/0/1\">Zhen Li</a>",
          "description": "In this work, we use an explainable convolutional neural network (NLS-Net) to\nsolve an inverse problem of the nonlinear Schr\\\"odinger equation, which is\nwidely used in fiber-optic communications. The landscape and minimizers of the\nnon-convex loss function of the learning problem are studied empirically. It\nprovides a guidance for choosing hyper-parameters of the method. The estimation\nerror of the optimal solution is discussed in terms of expressive power of the\nNLS-Net and data. Besides, we compare the performance of several training\nalgorithms that are popular in deep learning. It is shown that one can obtain a\nrelatively accurate estimate of the considered parameters using the proposed\nmethod. The study provides a natural framework of solving inverse problems of\nnonlinear partial differential equations with deep learning.",
          "link": "http://arxiv.org/abs/2107.08593",
          "publishedOn": "2021-07-20T02:04:44.554Z",
          "wordCount": 566,
          "title": "Inverse Problem of Nonlinear Schr\\\"odinger Equation as Learning of Convolutional Neural Network. (arXiv:2107.08593v1 [math.NA])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08662",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_P/0/1/0/all/0/1\">Peng Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_J/0/1/0/all/0/1\">Jiabao Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1\">Xuemin Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1\">Libin Zheng</a>",
          "description": "With the rapid development of smart mobile devices, the car-hailing platforms\n(e.g., Uber or Lyft) have attracted much attention from both the academia and\nthe industry. In this paper, we consider an important dynamic car-hailing\nproblem, namely \\textit{maximum revenue vehicle dispatching} (MRVD), in which\nrider requests dynamically arrive and drivers need to serve as many riders as\npossible such that the entire revenue of the platform is maximized. We prove\nthat the MRVD problem is NP-hard and intractable. In addition, the dynamic\ncar-hailing platforms have no information of the future riders, which makes the\nproblem even harder. To handle the MRVD problem, we propose a queueing-based\nvehicle dispatching framework, which first uses existing machine learning\nalgorithms to predict the future vehicle demand of each region, then estimates\nthe idle time periods of drivers through a queueing model for each region. With\nthe information of the predicted vehicle demands and estimated idle time\nperiods of drivers, we propose two batch-based vehicle dispatching algorithms\nto efficiently assign suitable drivers to riders such that the expected overall\nrevenue of the platform is maximized during each batch processing. Through\nextensive experiments, we demonstrate the efficiency and effectiveness of our\nproposed approaches over both real and synthetic datasets.",
          "link": "http://arxiv.org/abs/2107.08662",
          "publishedOn": "2021-07-20T02:04:44.536Z",
          "wordCount": 649,
          "title": "A Queueing-Theoretic Framework for Vehicle Dispatching in Dynamic Car-Hailing [technical report]. (arXiv:2107.08662v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08564",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Momeni_A/0/1/0/all/0/1\">Ali Momeni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fleury_R/0/1/0/all/0/1\">Romain Fleury</a>",
          "description": "Wave-based analog signal processing holds the promise of extremely fast,\non-the-fly, power-efficient data processing, occurring as a wave propagates\nthrough an artificially engineered medium. Yet, due to the fundamentally weak\nnon-linearities of traditional wave materials, such analog processors have been\nso far largely confined to simple linear projections such as image edge\ndetection or matrix multiplications. Complex neuromorphic computing tasks,\nwhich inherently require strong non-linearities, have so far remained\nout-of-reach of wave-based solutions, with a few attempts that implemented\nnon-linearities on the digital front, or used weak and inflexible non-linear\nsensors, restraining the learning performance. Here, we tackle this issue by\ndemonstrating the relevance of Time-Floquet physics to induce a strong\nnon-linear entanglement between signal inputs at different frequencies,\nenabling a power-efficient and versatile wave platform for analog extreme deep\nlearning involving a single, uniformly modulated dielectric layer and a\nscattering medium. We prove the efficiency of the method for extreme learning\nmachines and reservoir computing to solve a range of challenging learning\ntasks, from forecasting chaotic time series to the simultaneous classification\nof distinct datasets. Our results open the way for wave-based machine learning\nwith high energy efficiency, speed, and scalability.",
          "link": "http://arxiv.org/abs/2107.08564",
          "publishedOn": "2021-07-20T02:04:44.473Z",
          "wordCount": 643,
          "title": "Wave-based extreme deep learning based on non-linear time-Floquet entanglement. (arXiv:2107.08564v1 [cs.ET])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08396",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Podda_M/0/1/0/all/0/1\">Marco Podda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bacciu_D/0/1/0/all/0/1\">Davide Bacciu</a>",
          "description": "The problem of labeled graph generation is gaining attention in the Deep\nLearning community. The task is challenging due to the sparse and discrete\nnature of graph spaces. Several approaches have been proposed in the\nliterature, most of which require to transform the graphs into sequences that\nencode their structure and labels and to learn the distribution of such\nsequences through an auto-regressive generative model. Among this family of\napproaches, we focus on the GraphGen model. The preprocessing phase of GraphGen\ntransforms graphs into unique edge sequences called Depth-First Search (DFS)\ncodes, such that two isomorphic graphs are assigned the same DFS code. Each\nelement of a DFS code is associated with a graph edge: specifically, it is a\nquintuple comprising one node identifier for each of the two endpoints, their\nnode labels, and the edge label. GraphGen learns to generate such sequences\nauto-regressively and models the probability of each component of the quintuple\nindependently. While effective, the independence assumption made by the model\nis too loose to capture the complex label dependencies of real-world graphs\nprecisely. By introducing a novel graph preprocessing approach, we are able to\nprocess the labeling information of both nodes and edges jointly. The\ncorresponding model, which we term GraphGen-Redux, improves upon the generative\nperformances of GraphGen in a wide range of datasets of chemical and social\ngraphs. In addition, it uses approximately 78% fewer parameters than the\nvanilla variant and requires 50% fewer epochs of training on average.",
          "link": "http://arxiv.org/abs/2107.08396",
          "publishedOn": "2021-07-20T02:04:44.455Z",
          "wordCount": 677,
          "title": "GraphGen-Redux: a Fast and Lightweight Recurrent Model for labeled Graph Generation. (arXiv:2107.08396v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08444",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alon_N/0/1/0/all/0/1\">Noga Alon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hanneke_S/0/1/0/all/0/1\">Steve Hanneke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holzman_R/0/1/0/all/0/1\">Ron Holzman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moran_S/0/1/0/all/0/1\">Shay Moran</a>",
          "description": "We extend the theory of PAC learning in a way which allows to model a rich\nvariety of learning tasks where the data satisfy special properties that ease\nthe learning process. For example, tasks where the distance of the data from\nthe decision boundary is bounded away from zero. The basic and simple idea is\nto consider partial concepts: these are functions that can be undefined on\ncertain parts of the space. When learning a partial concept, we assume that the\nsource distribution is supported only on points where the partial concept is\ndefined.\n\nThis way, one can naturally express assumptions on the data such as lying on\na lower dimensional surface or margin conditions. In contrast, it is not at all\nclear that such assumptions can be expressed by the traditional PAC theory. In\nfact we exhibit easy-to-learn partial concept classes which provably cannot be\ncaptured by the traditional PAC theory. This also resolves a question posed by\nAttias, Kontorovich, and Mansour 2019.\n\nWe characterize PAC learnability of partial concept classes and reveal an\nalgorithmic landscape which is fundamentally different than the classical one.\nFor example, in the classical PAC model, learning boils down to Empirical Risk\nMinimization (ERM). In stark contrast, we show that the ERM principle fails in\nexplaining learnability of partial concept classes. In fact, we demonstrate\nclasses that are incredibly easy to learn, but such that any algorithm that\nlearns them must use an hypothesis space with unbounded VC dimension. We also\nfind that the sample compression conjecture fails in this setting.\n\nThus, this theory features problems that cannot be represented nor solved in\nthe traditional way. We view this as evidence that it might provide insights on\nthe nature of learnability in realistic scenarios which the classical theory\nfails to explain.",
          "link": "http://arxiv.org/abs/2107.08444",
          "publishedOn": "2021-07-20T02:04:44.435Z",
          "wordCount": 746,
          "title": "A Theory of PAC Learnability of Partial Concept Classes. (arXiv:2107.08444v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08687",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Klimek_J/0/1/0/all/0/1\">Jacek Klimek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klimek_J/0/1/0/all/0/1\">Jakub Klimek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kraskiewicz_W/0/1/0/all/0/1\">Witold Kraskiewicz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Topolewski_M/0/1/0/all/0/1\">Mateusz Topolewski</a>",
          "description": "Various modifications of TRANSFORMER were recently used to solve time-series\nforecasting problem. We propose Query Selector - an efficient, deterministic\nalgorithm for sparse attention matrix. Experiments show it achieves\nstate-of-the art results on ETT data set.",
          "link": "http://arxiv.org/abs/2107.08687",
          "publishedOn": "2021-07-20T02:04:44.416Z",
          "wordCount": 478,
          "title": "Long-term series forecasting with Query Selector -- efficient model of sparse attention. (arXiv:2107.08687v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08595",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ding_L/0/1/0/all/0/1\">Liang Ding</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tuo_R/0/1/0/all/0/1\">Rui Tuo</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaowei Zhang</a>",
          "description": "High-dimensional simulation optimization is notoriously challenging. We\npropose a new sampling algorithm that converges to a global optimal solution\nand suffers minimally from the curse of dimensionality. The algorithm consists\nof two stages. First, we take samples following a sparse grid experimental\ndesign and approximate the response surface via kernel ridge regression with a\nBrownian field kernel. Second, we follow the expected improvement strategy --\nwith critical modifications that boost the algorithm's sample efficiency -- to\niteratively sample from the next level of the sparse grid. Under mild\nconditions on the smoothness of the response surface and the simulation noise,\nwe establish upper bounds on the convergence rate for both noise-free and noisy\nsimulation samples. These upper rates deteriorate only slightly in the\ndimension of the feasible set, and they can be improved if the objective\nfunction is known be of a higher-order smoothness. Extensive numerical\nexperiments demonstrate that the proposed algorithm dramatically outperforms\ntypical alternatives in practice.",
          "link": "http://arxiv.org/abs/2107.08595",
          "publishedOn": "2021-07-20T02:04:44.400Z",
          "wordCount": 615,
          "title": "High-Dimensional Simulation Optimization via Brownian Fields and Sparse Grids. (arXiv:2107.08595v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08577",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singh_G/0/1/0/all/0/1\">Gautam Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peri_S/0/1/0/all/0/1\">Skand Peri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Junghyun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyunseok Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahn_S/0/1/0/all/0/1\">Sungjin Ahn</a>",
          "description": "Object-centric world models provide structured representation of the scene\nand can be an important backbone in reinforcement learning and planning.\nHowever, existing approaches suffer in partially-observable environments due to\nthe lack of belief states. In this paper, we propose Structured World Belief, a\nmodel for learning and inference of object-centric belief states. Inferred by\nSequential Monte Carlo (SMC), our belief states provide multiple object-centric\nscene hypotheses. To synergize the benefits of SMC particles with object\nrepresentations, we also propose a new object-centric dynamics model that\nconsiders the inductive bias of object permanence. This enables tracking of\nobject states even when they are invisible for a long time. To further\nfacilitate object tracking in this regime, we allow our model to attend\nflexibly to any spatial location in the image which was restricted in previous\nmodels. In experiments, we show that object-centric belief provides a more\naccurate and robust performance for filtering and generation. Furthermore, we\nshow the efficacy of structured world belief in improving the performance of\nreinforcement learning, planning and supervised reasoning.",
          "link": "http://arxiv.org/abs/2107.08577",
          "publishedOn": "2021-07-20T02:04:44.344Z",
          "wordCount": 614,
          "title": "Structured World Belief for Reinforcement Learning in POMDP. (arXiv:2107.08577v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08640",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lonkar_S/0/1/0/all/0/1\">Subodh Lonkar</a>",
          "description": "Over the centuries, humans have developed and acquired a number of ways to\ncommunicate. But hardly any of them can be as natural and instinctive as facial\nexpressions. On the other hand, neural networks have taken the world by storm.\nAnd no surprises, that the area of Computer Vision and the problem of facial\nexpressions recognitions hasn't remained untouched. Although a wide range of\ntechniques have been applied, achieving extremely high accuracies and preparing\nhighly robust FER systems still remains a challenge due to heterogeneous\ndetails in human faces. In this paper, we will be deep diving into implementing\na system for recognition of facial expressions (FER) by leveraging neural\nnetworks, and more specifically, Convolutional Neural Networks (CNNs). We adopt\nthe fundamental concepts of deep learning and computer vision with various\narchitectures, fine-tune it's hyperparameters and experiment with various\noptimization methods and demonstrate a state-of-the-art single-network-accuracy\nof 70.10% on the FER2013 dataset without using any additional training data.",
          "link": "http://arxiv.org/abs/2107.08640",
          "publishedOn": "2021-07-20T02:04:44.326Z",
          "wordCount": 592,
          "title": "Facial Expressions Recognition with Convolutional Neural Networks. (arXiv:2107.08640v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08686",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shaojie Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yong Liu</a>",
          "description": "Generalization performance of stochastic optimization stands a central place\nin machine learning. In this paper, we investigate the excess risk performance\nand towards improved learning rates for two popular approaches of stochastic\noptimization: empirical risk minimization (ERM) and stochastic gradient descent\n(SGD). Although there exists plentiful generalization analysis of ERM and SGD\nfor supervised learning, current theoretical understandings of ERM and SGD are\neither have stronger assumptions in convex learning, e.g., strong convexity\ncondition, or show slow rates and less studied in nonconvex learning. Motivated\nby these problems, we aim to provide improved rates under milder assumptions in\nconvex learning and derive faster rates in nonconvex learning. It is notable\nthat our analysis span two popular theoretical viewpoints: stability and\nuniform convergence. To be specific, in stability regime, we present high\nprobability rates of order $\\mathcal{O} (1/n)$ w.r.t. the sample size $n$ for\nERM and SGD with milder assumptions in convex learning and similar high\nprobability rates of order $\\mathcal{O} (1/n)$ in nonconvex learning, rather\nthan in expectation. Furthermore, this type of learning rate is improved to\nfaster order $\\mathcal{O} (1/n^2)$ in uniform convergence regime. To the best\nof our knowledge, for ERM and SGD, the learning rates presented in this paper\nare all state-of-the-art.",
          "link": "http://arxiv.org/abs/2107.08686",
          "publishedOn": "2021-07-20T02:04:44.309Z",
          "wordCount": 645,
          "title": "Improved Learning Rates for Stochastic Optimization: Two Theoretical Viewpoints. (arXiv:2107.08686v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08661",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1\">Ye Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramanovich_M/0/1/0/all/0/1\">Michelle Tadmor Ramanovich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Remez_T/0/1/0/all/0/1\">Tal Remez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pomerantz_R/0/1/0/all/0/1\">Roi Pomerantz</a>",
          "description": "We present Translatotron 2, a neural direct speech-to-speech translation\nmodel that can be trained end-to-end. Translatotron 2 consists of a speech\nencoder, a phoneme decoder, a mel-spectrogram synthesizer, and an attention\nmodule that connects all the previous three components. Experimental results\nsuggest that Translatotron 2 outperforms the original Translatotron by a large\nmargin in terms of translation quality and predicted speech naturalness, and\ndrastically improves the robustness of the predicted speech by mitigating\nover-generation, such as babbling or long pause. We also propose a new method\nfor retaining the source speaker's voice in the translated speech. The trained\nmodel is restricted to retain the source speaker's voice, and unlike the\noriginal Translatotron, it is not able to generate speech in a different\nspeaker's voice, making the model more robust for production deployment, by\nmitigating potential misuse for creating spoofing audio artifacts. When the new\nmethod is used together with a simple concatenation-based data augmentation,\nthe trained Translatotron 2 model is able to retain each speaker's voice for\ninput with speaker turns.",
          "link": "http://arxiv.org/abs/2107.08661",
          "publishedOn": "2021-07-20T02:04:44.288Z",
          "wordCount": 614,
          "title": "Translatotron 2: Robust direct speech-to-speech translation. (arXiv:2107.08661v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08488",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maran_D/0/1/0/all/0/1\">D. Maran</a>",
          "description": "We improve a theoretical result of the article \"On Exploiting Spectral\nProperties for Solving MDP with Large State Space\" showing that their\nalgorithm, which was proved to converge under some unrealistic assumptions, is\nactually guaranteed to converge always.",
          "link": "http://arxiv.org/abs/2107.08488",
          "publishedOn": "2021-07-20T02:04:44.270Z",
          "wordCount": 484,
          "title": "A note on the article \"On Exploiting Spectral Properties for Solving MDP with Large State Space\". (arXiv:2107.08488v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08558",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ibeling_D/0/1/0/all/0/1\">Duligur Ibeling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Icard_T/0/1/0/all/0/1\">Thomas Icard</a>",
          "description": "This paper presents a topological learning-theoretic perspective on causal\ninference by introducing a series of topologies defined on general spaces of\nstructural causal models (SCMs). As an illustration of the framework we prove a\ntopological causal hierarchy theorem, showing that substantive assumption-free\ncausal inference is possible only in a meager set of SCMs. Thanks to a known\ncorrespondence between open sets in the weak topology and statistically\nverifiable hypotheses, our results show that inductive assumptions sufficient\nto license valid causal inferences are statistically unverifiable in principle.\nSimilar to no-free-lunch theorems for statistical inference, the present\nresults clarify the inevitability of substantial assumptions for causal\ninference. An additional benefit of our topological approach is that it easily\naccommodates SCMs with infinitely many variables. We finally suggest that the\nframework may be helpful for the positive project of exploring and assessing\nalternative causal-inductive assumptions.",
          "link": "http://arxiv.org/abs/2107.08558",
          "publishedOn": "2021-07-20T02:04:44.206Z",
          "wordCount": 578,
          "title": "A Topological Perspective on Causal Inference. (arXiv:2107.08558v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08622",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chicheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhi Wang</a>",
          "description": "We study multi-task reinforcement learning (RL) in tabular episodic Markov\ndecision processes (MDPs). We formulate a heterogeneous multi-player RL\nproblem, in which a group of players concurrently face similar but not\nnecessarily identical MDPs, with a goal of improving their collective\nperformance through inter-player information sharing. We design and analyze an\nalgorithm based on the idea of model transfer, and provide gap-dependent and\ngap-independent upper and lower bounds that characterize the intrinsic\ncomplexity of the problem.",
          "link": "http://arxiv.org/abs/2107.08622",
          "publishedOn": "2021-07-20T02:04:44.188Z",
          "wordCount": 502,
          "title": "Provably Efficient Multi-Task Reinforcement Learning with Model Transfer. (arXiv:2107.08622v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08574",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abdelhack_M/0/1/0/all/0/1\">Mohamed Abdelhack</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiaming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tripathi_S/0/1/0/all/0/1\">Sandhya Tripathi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fritz_B/0/1/0/all/0/1\">Bradley Fritz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Avidan_M/0/1/0/all/0/1\">Michael Avidan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yixin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+King_C/0/1/0/all/0/1\">Christopher King</a>",
          "description": "Data quality is a common problem in machine learning, especially in\nhigh-stakes settings such as healthcare. Missing data affects accuracy,\ncalibration, and feature attribution in complex patterns. Developers often\ntrain models on carefully curated datasets to minimize missing data bias;\nhowever, this reduces the usability of such models in production environments,\nsuch as real-time healthcare records. Making machine learning models robust to\nmissing data is therefore crucial for practical application. While some\nclassifiers naturally handle missing data, others, such as deep neural\nnetworks, are not designed for unknown values. We propose a novel neural\nnetwork modification to mitigate the impacts of missing data. The approach is\ninspired by neuromodulation that is performed by biological neural networks.\nOur proposal replaces the fixed weights of a fully-connected layer with a\nfunction of an additional input (reliability score) at each input, mimicking\nthe ability of cortex to up- and down-weight inputs based on the presence of\nother data. The modulation function is jointly learned with the main task using\na multi-layer perceptron. We tested our modulating fully connected layer on\nmultiple classification, regression, and imputation problems, and it either\nimproved performance or generated comparable performance to conventional neural\nnetwork architectures concatenating reliability to the inputs. Models with\nmodulating layers were more robust against degradation of data quality by\nintroducing additional missingness at evaluation time. These results suggest\nthat explicitly accounting for reduced information quality with a modulating\nfully connected layer can enable the deployment of artificial intelligence\nsystems in real-time settings.",
          "link": "http://arxiv.org/abs/2107.08574",
          "publishedOn": "2021-07-20T02:04:44.170Z",
          "wordCount": 695,
          "title": "A Modulation Layer to Increase Neural Network Robustness Against Data Quality Issues. (arXiv:2107.08574v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08695",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sisejkovic_D/0/1/0/all/0/1\">Dominik Sisejkovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Merchant_F/0/1/0/all/0/1\">Farhad Merchant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reimann_L/0/1/0/all/0/1\">Lennart M. Reimann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leupers_R/0/1/0/all/0/1\">Rainer Leupers</a>",
          "description": "Logic locking has emerged as a prominent key-driven technique to protect the\nintegrity of integrated circuits. However, novel machine-learning-based attacks\nhave recently been introduced to challenge the security foundations of locking\nschemes. These attacks are able to recover a significant percentage of the key\nwithout having access to an activated circuit. This paper address this issue\nthrough two focal points. First, we present a theoretical model to test locking\nschemes for key-related structural leakage that can be exploited by machine\nlearning. Second, based on the theoretical model, we introduce D-MUX: a\ndeceptive multiplexer-based logic-locking scheme that is resilient against\nstructure-exploiting machine learning attacks. Through the design of D-MUX, we\nuncover a major fallacy in existing multiplexer-based locking schemes in the\nform of a structural-analysis attack. Finally, an extensive cost evaluation of\nD-MUX is presented. To the best of our knowledge, D-MUX is the first\nmachine-learning-resilient locking scheme capable of protecting against all\nknown learning-based attacks. Hereby, the presented work offers a starting\npoint for the design and evaluation of future-generation logic locking in the\nera of machine learning.",
          "link": "http://arxiv.org/abs/2107.08695",
          "publishedOn": "2021-07-20T02:04:44.143Z",
          "wordCount": 626,
          "title": "Deceptive Logic Locking for Hardware Integrity Protection against Machine Learning Attacks. (arXiv:2107.08695v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08681",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1\">Jinke Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chonghe Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_G/0/1/0/all/0/1\">Guanding Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_D/0/1/0/all/0/1\">Dongning Guo</a>",
          "description": "Generative adversarial networks (GANs) are emerging machine learning models\nfor generating synthesized data similar to real data by jointly training a\ngenerator and a discriminator. In many applications, data and computational\nresources are distributed over many devices, so centralized computation with\nall data in one location is infeasible due to privacy and/or communication\nconstraints. This paper proposes a new framework for training GANs in a\ndistributed fashion: Each device computes a local discriminator using local\ndata; a single server aggregates their results and computes a global GAN.\nSpecifically, in each iteration, the server sends the global GAN to the\ndevices, which then update their local discriminators; the devices send their\nresults to the server, which then computes their average as the global\ndiscriminator and updates the global generator accordingly. Two different\nupdate schedules are designed with different levels of parallelism between the\ndevices and the server. Numerical results obtained using three popular datasets\ndemonstrate that the proposed framework can outperform a state-of-the-art\nframework in terms of convergence speed.",
          "link": "http://arxiv.org/abs/2107.08681",
          "publishedOn": "2021-07-20T02:04:44.124Z",
          "wordCount": 627,
          "title": "A New Distributed Method for Training Generative Adversarial Networks. (arXiv:2107.08681v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08594",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pimpley_A/0/1/0/all/0/1\">Anish Pimpley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shuo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_A/0/1/0/all/0/1\">Anubha Srivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rohra_V/0/1/0/all/0/1\">Vishal Rohra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yi Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivasan_S/0/1/0/all/0/1\">Soundararajan Srinivasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jindal_A/0/1/0/all/0/1\">Alekh Jindal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patel_H/0/1/0/all/0/1\">Hiren Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_S/0/1/0/all/0/1\">Shi Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sen_R/0/1/0/all/0/1\">Rathijit Sen</a>",
          "description": "Optimizing resource allocation for analytical workloads is vital for reducing\ncosts of cloud-data services. At the same time, it is incredibly hard for users\nto allocate resources per query in serverless processing systems, and they\nfrequently misallocate by orders of magnitude. Unfortunately, prior work\nfocused on predicting peak allocation while ignoring aggressive trade-offs\nbetween resource allocation and run-time. Additionally, these methods fail to\npredict allocation for queries that have not been observed in the past. In this\npaper, we tackle both these problems. We introduce a system for optimal\nresource allocation that can predict performance with aggressive trade-offs,\nfor both new and past observed queries. We introduce the notion of a\nperformance characteristic curve (PCC) as a parameterized representation that\ncan compactly capture the relationship between resources and performance. To\ntackle training data sparsity, we introduce a novel data augmentation technique\nto efficiently synthesize the entire PCC using a single run of the query.\nLastly, we demonstrate the advantages of a constrained loss function coupled\nwith GNNs, over traditional ML methods, for capturing the domain specific\nbehavior through an extensive experimental evaluation over SCOPE big data\nworkloads at Microsoft.",
          "link": "http://arxiv.org/abs/2107.08594",
          "publishedOn": "2021-07-20T02:04:44.093Z",
          "wordCount": 628,
          "title": "Optimal Resource Allocation for Serverless Queries. (arXiv:2107.08594v1 [cs.DB])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08588",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yinjun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weimer_J/0/1/0/all/0/1\">James Weimer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Davidson_S/0/1/0/all/0/1\">Susan B. Davidson</a>",
          "description": "High-quality labels are expensive to obtain for many machine learning tasks,\nsuch as medical image classification tasks. Therefore, probabilistic (weak)\nlabels produced by weak supervision tools are used to seed a process in which\ninfluential samples with weak labels are identified and cleaned by several\nhuman annotators to improve the model performance. To lower the overall cost\nand computational overhead of this process, we propose a solution called\nChef(CHEap and Fast label cleaning), which consists of the following three\ncomponents. First, to reduce the cost of human annotators, we use Infl, which\nprioritizes the most influential training samples for cleaning and provides\ncleaned labels to save the cost of one human annotator. Second, to accelerate\nthe sample selector phase and the model constructor phase, we use Increm-Infl\nto incrementally produce influential samples, and DeltaGrad-L to incrementally\nupdate the model. Third, we redesign the typical label cleaning pipeline so\nthat human annotators iteratively clean smaller batch of samples rather than\none big batch of samples. This yields better over all model performance and\nenables possible early termination when the expected model performance has been\nachieved. Extensive experiments show that our approach gives good model\nprediction performance while achieving significant speed-ups.",
          "link": "http://arxiv.org/abs/2107.08588",
          "publishedOn": "2021-07-20T02:04:44.023Z",
          "wordCount": 636,
          "title": "Chef: a cheap and fast pipeline for iteratively cleaning label uncertainties. (arXiv:2107.08588v1 [cs.DB])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08673",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Massalimova_A/0/1/0/all/0/1\">Aidana Massalimova</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Varol_H/0/1/0/all/0/1\">Huseyin Atakan Varol</a>",
          "description": "Alzheimer's disease (AD) is a progressive brain disorder that causes memory\nand functional impairments. The advances in machine learning and publicly\navailable medical datasets initiated multiple studies in AD diagnosis. In this\nwork, we utilize a multi-modal deep learning approach in classifying normal\ncognition, mild cognitive impairment and AD classes on the basis of structural\nMRI and diffusion tensor imaging (DTI) scans from the OASIS-3 dataset. In\naddition to a conventional multi-modal network, we also present an input\nagnostic architecture that allows diagnosis with either sMRI or DTI scan, which\ndistinguishes our method from previous multi-modal machine learning-based\nmethods. The results show that the input agnostic model achieves 0.96 accuracy\nwhen both structural MRI and DTI scans are provided as inputs.",
          "link": "http://arxiv.org/abs/2107.08673",
          "publishedOn": "2021-07-20T02:04:44.004Z",
          "wordCount": 581,
          "title": "Input Agnostic Deep Learning for Alzheimer's Disease Classification Using Multimodal MRI Images. (arXiv:2107.08673v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08399",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Velichko_A/0/1/0/all/0/1\">Andrei Velichko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heidari_H/0/1/0/all/0/1\">Hanif Heidari</a>",
          "description": "Measuring the predictability and complexity of time series is an essential\ntool in designing and controlling the nonlinear system. There exist different\nentropy measures in the literature to analyze the predictability and complexity\nof time series. However, these measures have some drawbacks especially in short\ntime series. To overcome the difficulties, this paper proposes a new method for\nestimating the entropy of a time series using the LogNNet 784:25:10 neural\nnetwork model. The LogNNet reservoir matrix consists of 19625 elements which is\nfilled with the time series elements. After that, the network is trained on\nMNIST-10 dataset and the classification accuracy is calculated. The accuracy is\nconsidered as the entropy measure and denoted by NNetEn. A more complex\ntransformation of the input information by the time series in the reservoir\nleads to higher NNetEn values. Many practical time series data have less than\n19625 elements. Some duplicating or stretching methods are investigated to\novercome this difficulty and the most successful method is identified for\npractical applications. The epochs number in the training process of LogNNet is\nconsidered as the input parameter. A new time series characteristic called time\nseries learning inertia is introduced to investigate the effect of epochs\nnumber in the efficiency of neural network. To show the robustness and\nefficiency of the proposed method, it is applied on some chaotic, periodic,\nrandom, binary and constant time series. The NNetEn is compared with some\nexisting entropy measures. The results show that the proposed method is more\nrobust and accurate than existing methods.",
          "link": "http://arxiv.org/abs/2107.08399",
          "publishedOn": "2021-07-20T02:04:43.986Z",
          "wordCount": 712,
          "title": "A method for estimating the entropy of time series using artificial neural network. (arXiv:2107.08399v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08377",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shao_Z/0/1/0/all/0/1\">Zhou Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_T/0/1/0/all/0/1\">Tong Lin</a>",
          "description": "Adaptive gradient methods, especially Adam-type methods (such as Adam,\nAMSGrad, and AdaBound), have been proposed to speed up the training process\nwith an element-wise scaling term on learning rates. However, they often\ngeneralize poorly compared with stochastic gradient descent (SGD) and its\naccelerated schemes such as SGD with momentum (SGDM). In this paper, we propose\na new adaptive method called DecGD, which simultaneously achieves good\ngeneralization like SGDM and obtain rapid convergence like Adam-type methods.\nIn particular, DecGD decomposes the current gradient into the product of two\nterms including a surrogate gradient and a loss based vector. Our method\nadjusts the learning rates adaptively according to the current loss based\nvector instead of the squared gradients used in Adam-type methods. The\nintuition for adaptive learning rates of DecGD is that a good optimizer, in\ngeneral cases, needs to decrease the learning rates as the loss decreases,\nwhich is similar to the learning rates decay scheduling technique. Therefore,\nDecGD gets a rapid convergence in the early phases of training and controls the\neffective learning rates according to the loss based vectors which help lead to\na better generalization. Convergence analysis is discussed in both convex and\nnon-convex situations. Finally, empirical results on widely-used tasks and\nmodels demonstrate that DecGD shows better generalization performance than SGDM\nand rapid convergence like Adam-type methods.",
          "link": "http://arxiv.org/abs/2107.08377",
          "publishedOn": "2021-07-20T02:04:43.967Z",
          "wordCount": 652,
          "title": "A New Adaptive Gradient Method with Gradient Decomposition. (arXiv:2107.08377v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08710",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Higham_C/0/1/0/all/0/1\">Catherine F. Higham</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Bedford_A/0/1/0/all/0/1\">Adrian Bedford</a>",
          "description": "We demonstrate the feasibility of framing a classically learned deep neural\nnetwork as an energy based model that can be processed on a one-step quantum\nannealer in order to exploit fast sampling times. We propose approaches to\novercome two hurdles for high resolution image classification on a quantum\nprocessing unit (QPU): the required number and binary nature of the model\nstates. With this novel method we successfully transfer a convolutional neural\nnetwork to the QPU and show the potential for classification speedup of at\nleast one order of magnitude.",
          "link": "http://arxiv.org/abs/2107.08710",
          "publishedOn": "2021-07-20T02:04:43.913Z",
          "wordCount": 522,
          "title": "Quantum Deep Learning: Sampling Neural Nets with a Quantum Annealer. (arXiv:2107.08710v1 [quant-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08596",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Katsman_I/0/1/0/all/0/1\">Isay Katsman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lou_A/0/1/0/all/0/1\">Aaron Lou</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lim_D/0/1/0/all/0/1\">Derek Lim</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Jiang_Q/0/1/0/all/0/1\">Qingxuan Jiang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lim_S/0/1/0/all/0/1\">Ser-Nam Lim</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sa_C/0/1/0/all/0/1\">Christopher De Sa</a>",
          "description": "Tractably modelling distributions over manifolds has long been an important\ngoal in the natural sciences. Recent work has focused on developing general\nmachine learning models to learn such distributions. However, for many\napplications these distributions must respect manifold symmetries -- a trait\nwhich most previous models disregard. In this paper, we lay the theoretical\nfoundations for learning symmetry-invariant distributions on arbitrary\nmanifolds via equivariant manifold flows. We demonstrate the utility of our\napproach by using it to learn gauge invariant densities over $SU(n)$ in the\ncontext of quantum field theory.",
          "link": "http://arxiv.org/abs/2107.08596",
          "publishedOn": "2021-07-20T02:04:43.826Z",
          "wordCount": 526,
          "title": "Equivariant Manifold Flows. (arXiv:2107.08596v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08398",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nieto_J/0/1/0/all/0/1\">Juan Jos&#xe9; Nieto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Creus_R/0/1/0/all/0/1\">Roger Creus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giro_i_Nieto_X/0/1/0/all/0/1\">Xavier Giro-i-Nieto</a>",
          "description": "Pre-training Reinforcement Learning agents in a task-agnostic manner has\nshown promising results. However, previous works still struggle in learning and\ndiscovering meaningful skills in high-dimensional state-spaces, such as\npixel-spaces. We approach the problem by leveraging unsupervised skill\ndiscovery and self-supervised learning of state representations. In our work,\nwe learn a compact latent representation by making use of variational and\ncontrastive techniques. We demonstrate that both enable RL agents to learn a\nset of basic navigation skills by maximizing an information theoretic\nobjective. We assess our method in Minecraft 3D pixel maps with different\ncomplexities. Our results show that representations and conditioned policies\nlearned from pixels are enough for toy examples, but do not scale to realistic\nand complex maps. To overcome these limitations, we explore alternative input\nobservations such as the relative position of the agent along with the raw\npixels.",
          "link": "http://arxiv.org/abs/2107.08398",
          "publishedOn": "2021-07-20T02:04:43.808Z",
          "wordCount": 579,
          "title": "Unsupervised Skill-Discovery and Skill-Learning in Minecraft. (arXiv:2107.08398v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08429",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Naik_S/0/1/0/all/0/1\">Shibabrat Naik</a>, <a href=\"http://arxiv.org/find/math/1/au:+Krajnak_V/0/1/0/all/0/1\">Vladim&#xed;r Kraj&#x148;&#xe1;k</a>, <a href=\"http://arxiv.org/find/math/1/au:+Wiggins_S/0/1/0/all/0/1\">Stephen Wiggins</a>",
          "description": "We develop a machine learning framework that can be applied to data sets\nderived from the trajectories of Hamilton's equations. The goal is to learn the\nphase space structures that play the governing role for phase space transport\nrelevant to particular applications. Our focus is on learning reactive islands\nin two degrees-of-freedom Hamiltonian systems. Reactive islands are constructed\nfrom the stable and unstable manifolds of unstable periodic orbits and play the\nrole of quantifying transition dynamics. We show that support vector machines\n(SVM) is an appropriate machine learning framework for this purpose as it\nprovides an approach for finding the boundaries between qualitatively distinct\ndynamical behaviors, which is in the spirit of the phase space transport\nframework. We show how our method allows us to find reactive islands directly\nin the sense that we do not have to first compute unstable periodic orbits and\ntheir stable and unstable manifolds. We apply our approach to the\nH\\'enon-Heiles Hamiltonian system, which is a benchmark system in the dynamical\nsystems community. We discuss different sampling and learning approaches and\ntheir advantages and disadvantages.",
          "link": "http://arxiv.org/abs/2107.08429",
          "publishedOn": "2021-07-20T02:04:43.788Z",
          "wordCount": 625,
          "title": "Support vector machines for learning reactive islands. (arXiv:2107.08429v1 [math.DS])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08572",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ampanavos_S/0/1/0/all/0/1\">Spyridon Ampanavos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malkawi_A/0/1/0/all/0/1\">Ali Malkawi</a>",
          "description": "Current performance-driven building design methods are not widely adopted\noutside the research field for several reasons that make them difficult to\nintegrate into a typical design process. In the early design phase, in\nparticular, the time-intensity and the cognitive load associated with\noptimization and form parametrization are incompatible with design exploration,\nwhich requires quick iteration. This research introduces a novel method for\nperformance-driven geometry generation that can afford interaction directly in\nthe 3d modeling environment, eliminating the need for explicit parametrization,\nand is multiple orders faster than the equivalent form optimization. The method\nuses Machine Learning techniques to train a generative model offline. The\ngenerative model learns a distribution of optimal performing geometries and\ntheir simulation contexts based on a dataset that addresses the performance(s)\nof interest. By navigating the generative model's latent space, geometries with\nthe desired characteristics can be quickly generated. A case study is\npresented, demonstrating the generation of a synthetic dataset and the use of a\nVariational Autoencoder (VAE) as a generative model for geometries with optimal\nsolar gain. The results show that the VAE-generated geometries perform on\naverage at least as well as the optimized ones, suggesting that the introduced\nmethod shows a feasible path towards more intuitive and interactive early-phase\nperformance-driven design assistance.",
          "link": "http://arxiv.org/abs/2107.08572",
          "publishedOn": "2021-07-20T02:04:43.769Z",
          "wordCount": 637,
          "title": "Early-Phase Performance-Driven Design using Generative Models. (arXiv:2107.08572v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08470",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ho_Y/0/1/0/all/0/1\">Yung-Han Ho</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chan_C/0/1/0/all/0/1\">Chih-Chun Chan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Peng_W/0/1/0/all/0/1\">Wen-Hsiao Peng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hang_H/0/1/0/all/0/1\">Hsueh-Ming Hang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Domanski_M/0/1/0/all/0/1\">Marek Domanski</a>",
          "description": "This paper introduces an end-to-end learned image compression system, termed\nANFIC, based on Augmented Normalizing Flows (ANF). ANF is a new type of flow\nmodel, which stacks multiple variational autoencoders (VAE) for greater model\nexpressiveness. The VAE-based image compression has gone mainstream, showing\npromising compression performance. Our work presents the first attempt to\nleverage VAE-based compression in a flow-based framework. ANFIC advances\nfurther compression efficiency by stacking and extending hierarchically\nmultiple VAE's. The invertibility of ANF, together with our training\nstrategies, enables ANFIC to support a wide range of quality levels without\nchanging the encoding and decoding networks. Extensive experimental results\nshow that in terms of PSNR-RGB, ANFIC performs comparably to or better than the\nstate-of-the-art learned image compression. Moreover, it performs close to VVC\nintra coding, from low-rate compression up to nearly-lossless compression. In\nparticular, ANFIC achieves the state-of-the-art performance, when extended with\nconditional convolution for variable rate compression with a single model.",
          "link": "http://arxiv.org/abs/2107.08470",
          "publishedOn": "2021-07-20T02:04:43.752Z",
          "wordCount": 602,
          "title": "ANFIC: Image Compression Using Augmented Normalizing Flows. (arXiv:2107.08470v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08382",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chin_H/0/1/0/all/0/1\">Hsu-Hsun Chin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsay_R/0/1/0/all/0/1\">Ren-Song Tsay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Hsin-I Wu</a>",
          "description": "Recent convolutional neural network (CNN) development continues to advance\nthe state-of-the-art model accuracy for various applications. However, the\nenhanced accuracy comes at the cost of substantial memory bandwidth and storage\nrequirements and demanding computational resources. Although in the past the\nquantization methods have effectively reduced the deployment cost for edge\ndevices, it suffers from significant information loss when processing the\nbiased activations of contemporary CNNs. In this paper, we hence introduce an\nadaptive high-performance quantization method to resolve the issue of biased\nactivation by dynamically adjusting the scaling and shifting factors based on\nthe task loss. Our proposed method has been extensively evaluated on image\nclassification models (ResNet-18/34/50, MobileNet-V2, EfficientNet-B0) with\nImageNet dataset, object detection model (YOLO-V4) with COCO dataset, and\nlanguage models with PTB dataset. The results show that our 4-bit integer\n(INT4) quantization models achieve better accuracy than the state-of-the-art\n4-bit models, and in some cases, even surpass the golden full-precision models.\nThe final designs have been successfully deployed onto extremely\nresource-constrained edge devices for many practical applications.",
          "link": "http://arxiv.org/abs/2107.08382",
          "publishedOn": "2021-07-20T02:04:43.694Z",
          "wordCount": 609,
          "title": "A High-Performance Adaptive Quantization Approach for Edge CNN Applications. (arXiv:2107.08382v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08697",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1\">Chihcheng Hsieh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moreira_C/0/1/0/all/0/1\">Catarina Moreira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_C/0/1/0/all/0/1\">Chun Ouyang</a>",
          "description": "Predictive process analytics often apply machine learning to predict the\nfuture states of a running business process. However, the internal mechanisms\nof many existing predictive algorithms are opaque and a human decision-maker is\nunable to understand \\emph{why} a certain activity was predicted. Recently,\ncounterfactuals have been proposed in the literature to derive\nhuman-understandable explanations from predictive models. Current\ncounterfactual approaches consist of finding the minimum feature change that\ncan make a certain prediction flip its outcome. Although many algorithms have\nbeen proposed, their application to the sequence and multi-dimensional data\nlike event logs has not been explored in the literature.\n\nIn this paper, we explore the use of a recent, popular model-agnostic\ncounterfactual algorithm, DiCE, in the context of predictive process analytics.\nThe analysis reveals that the algorithm is limited when being applied to derive\nexplanations of process predictions, due to (1) process domain knowledge not\nbeing taken into account, (2) long traces that often tend to be less\nunderstandable, and (3) difficulties in optimising the counterfactual search\nwith categorical variables. We design an extension of DiCE that can generate\ncounterfactuals for process predictions, and propose an approach that supports\nderiving milestone-aware counterfactuals at different stages of a trace to\npromote interpretability. We apply our approach to BPIC2012 event log and the\nanalysis results demonstrate the effectiveness of the proposed approach.",
          "link": "http://arxiv.org/abs/2107.08697",
          "publishedOn": "2021-07-20T02:04:43.676Z",
          "wordCount": 652,
          "title": "Interpreting Process Predictions using a Milestone-Aware Counterfactual Approach. (arXiv:2107.08697v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08387",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ben_Assayag_S/0/1/0/all/0/1\">Shai Ben-Assayag</a>, <a href=\"http://arxiv.org/find/cs/1/au:+El_Yaniv_R/0/1/0/all/0/1\">Ran El-Yaniv</a>",
          "description": "Playing board games is considered a major challenge for both humans and AI\nresearchers. Because some complicated board games are quite hard to learn,\nhumans usually begin with playing on smaller boards and incrementally advance\nto master larger board strategies. Most neural network frameworks that are\ncurrently tasked with playing board games neither perform such incremental\nlearning nor possess capabilities to automatically scale up. In this work, we\nlook at the board as a graph and combine a graph neural network architecture\ninside the AlphaZero framework, along with some other innovative improvements.\nOur ScalableAlphaZero is capable of learning to play incrementally on small\nboards, and advancing to play on large ones. Our model can be trained quickly\nto play different challenging board games on multiple board sizes, without\nusing any domain knowledge. We demonstrate the effectiveness of\nScalableAlphaZero and show, for example, that by training it for only three\ndays on small Othello boards, it can defeat the AlphaZero model on a large\nboard, which was trained to play the large board for $30$ days.",
          "link": "http://arxiv.org/abs/2107.08387",
          "publishedOn": "2021-07-20T02:04:43.657Z",
          "wordCount": 616,
          "title": "Train on Small, Play the Large: Scaling Up Board Games with AlphaZero and GNN. (arXiv:2107.08387v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08598",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xuesi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huzhang_G/0/1/0/all/0/1\">Guangda Huzhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Q/0/1/0/all/0/1\">Qianying Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Da_Q/0/1/0/all/0/1\">Qing Da</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_D/0/1/0/all/0/1\">Dan Shen</a>",
          "description": "Ensemble models in E-commerce combine predictions from multiple sub-models\nfor ranking and revenue improvement. Industrial ensemble models are typically\ndeep neural networks, following the supervised learning paradigm to infer\nconversion rate given inputs from sub-models. However, this process has the\nfollowing two problems. Firstly, the point-wise scoring approach disregards the\nrelationships between items and leads to homogeneous displayed results, while\ndiversified display benefits user experience and revenue. Secondly, the\nlearning paradigm focuses on the ranking metrics and does not directly optimize\nthe revenue. In our work, we propose a new Learning-To-Ensemble (LTE) framework\nRAEGO, which replaces the ensemble model with a contextual Rank Aggregator (RA)\nand explores the best weights of sub-models by the Evaluator-Generator\nOptimization (EGO). To achieve the best online performance, we propose a new\nrank aggregation algorithm TournamentGreedy as a refinement of classic rank\naggregators, which also produces the best average weighted Kendall Tau Distance\n(KTD) amongst all the considered algorithms with quadratic time complexity.\nUnder the assumption that the best output list should be Pareto Optimal on the\nKTD metric for sub-models, we show that our RA algorithm has higher efficiency\nand coverage in exploring the optimal weights. Combined with the idea of\nBayesian Optimization and gradient descent, we solve the online contextual\nBlack-Box Optimization task that finds the optimal weights for sub-models given\na chosen RA model. RA-EGO has been deployed in our online system and has\nimproved the revenue significantly.",
          "link": "http://arxiv.org/abs/2107.08598",
          "publishedOn": "2021-07-20T02:04:43.636Z",
          "wordCount": 670,
          "title": "Learning-To-Ensemble by Contextual Rank Aggregation in E-Commerce. (arXiv:2107.08598v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08517",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Onoszko_N/0/1/0/all/0/1\">Noa Onoszko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karlsson_G/0/1/0/all/0/1\">Gustav Karlsson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mogren_O/0/1/0/all/0/1\">Olof Mogren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zec_E/0/1/0/all/0/1\">Edvin Listo Zec</a>",
          "description": "We tackle the non-convex problem of learning a personalized deep learning\nmodel in a decentralized setting. More specifically, we study decentralized\nfederated learning, a peer-to-peer setting where data is distributed among many\nclients and where there is no central server to orchestrate the training. In\nreal world scenarios, the data distributions are often heterogeneous between\nclients. Therefore, in this work we study the problem of how to efficiently\nlearn a model in a peer-to-peer system with non-iid client data. We propose a\nmethod named Performance-Based Neighbor Selection (PENS) where clients with\nsimilar data distributions detect each other and cooperate by evaluating their\ntraining losses on each other's data to learn a model suitable for the local\ndata distribution. Our experiments on benchmark datasets show that our proposed\nmethod is able to achieve higher accuracies as compared to strong baselines.",
          "link": "http://arxiv.org/abs/2107.08517",
          "publishedOn": "2021-07-20T02:04:43.618Z",
          "wordCount": 579,
          "title": "Decentralized federated learning of deep neural networks on non-iid data. (arXiv:2107.08517v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08471",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dengshan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rujing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1\">Chengjun Xie</a>",
          "description": "Artificial neural networks that simulate human achieves great successes. From\nthe perspective of simulating human memory method, we propose a stepped sampler\nbased on the \"repeated input\". We repeatedly inputted data to the LSTM model\nstepwise in a batch. The stepped sampler is used to strengthen the ability of\nfusing the temporal information in LSTM. We tested the stepped sampler on the\nLSTM built-in in PyTorch. Compared with the traditional sampler of PyTorch,\nsuch as sequential sampler, batch sampler, the training loss of the proposed\nstepped sampler converges faster in the training of the model, and the training\nloss after convergence is more stable. Meanwhile, it can maintain a higher test\naccuracy. We quantified the algorithm of the stepped sampler.",
          "link": "http://arxiv.org/abs/2107.08471",
          "publishedOn": "2021-07-20T02:04:43.555Z",
          "wordCount": 556,
          "title": "A stepped sampling method for video detection using LSTM. (arXiv:2107.08471v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08426",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abdolshah_M/0/1/0/all/0/1\">Majid Abdolshah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_H/0/1/0/all/0/1\">Hung Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+George_T/0/1/0/all/0/1\">Thommen Karimpanal George</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1\">Sunil Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rana_S/0/1/0/all/0/1\">Santu Rana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venkatesh_S/0/1/0/all/0/1\">Svetha Venkatesh</a>",
          "description": "Transfer in reinforcement learning is usually achieved through generalisation\nacross tasks. Whilst many studies have investigated transferring knowledge when\nthe reward function changes, they have assumed that the dynamics of the\nenvironments remain consistent. Many real-world RL problems require transfer\namong environments with different dynamics. To address this problem, we propose\nan approach based on successor features in which we model successor feature\nfunctions with Gaussian Processes permitting the source successor features to\nbe treated as noisy measurements of the target successor feature function. Our\ntheoretical analysis proves the convergence of this approach as well as the\nbounded error on modelling successor feature functions with Gaussian Processes\nin environments with both different dynamics and rewards. We demonstrate our\nmethod on benchmark datasets and show that it outperforms current baselines.",
          "link": "http://arxiv.org/abs/2107.08426",
          "publishedOn": "2021-07-20T02:04:43.537Z",
          "wordCount": 569,
          "title": "A New Representation of Successor Features for Transfer across Dissimilar Environments. (arXiv:2107.08426v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08383",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pan_F/0/1/0/all/0/1\">Feiyang Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haoming Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ao_X/0/1/0/all/0/1\">Xiang Ao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_Y/0/1/0/all/0/1\">Yanrong Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_A/0/1/0/all/0/1\">Ao Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Q/0/1/0/all/0/1\">Qing He</a>",
          "description": "The exploration/exploitation (E&E) dilemma lies at the core of interactive\nsystems such as online advertising, for which contextual bandit algorithms have\nbeen proposed. Bayesian approaches provide guided exploration with principled\nuncertainty estimation, but the applicability is often limited due to\nover-simplified assumptions. Non-Bayesian bootstrap methods, on the other hand,\ncan apply to complex problems by using deep reward models, but lacks clear\nguidance to the exploration behavior. It still remains largely unsolved to\ndevelop a practical method for complex deep contextual bandits.\n\nIn this paper, we introduce Guided Bootstrap (GuideBoot for short), combining\nthe best of both worlds. GuideBoot provides explicit guidance to the\nexploration behavior by training multiple models over both real samples and\nnoisy samples with fake labels, where the noise is added according to the\npredictive uncertainty. The proposed method is efficient as it can make\ndecisions on-the-fly by utilizing only one randomly chosen model, but is also\neffective as we show that it can be viewed as a non-Bayesian approximation of\nThompson sampling. Moreover, we extend it to an online version that can learn\nsolely from streaming data, which is favored in real applications. Extensive\nexperiments on both synthetic task and large-scale advertising environments\nshow that GuideBoot achieves significant improvements against previous\nstate-of-the-art methods.",
          "link": "http://arxiv.org/abs/2107.08383",
          "publishedOn": "2021-07-20T02:04:43.515Z",
          "wordCount": 649,
          "title": "GuideBoot: Guided Bootstrap for Deep Contextual Bandits. (arXiv:2107.08383v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08371",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qu_L/0/1/0/all/0/1\">Liangqiong Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balachandar_N/0/1/0/all/0/1\">Niranjan Balachandar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubin_D/0/1/0/all/0/1\">Daniel L Rubin</a>",
          "description": "Federated learning enables multiple institutions to collaboratively train\nmachine learning models on their local data in a privacy-preserving way.\nHowever, its distributed nature often leads to significant heterogeneity in\ndata distributions across institutions. In this paper, we investigate the\ndeleterious impact of a taxonomy of data heterogeneity regimes on federated\nlearning methods, including quantity skew, label distribution skew, and imaging\nacquisition skew. We show that the performance degrades with the increasing\ndegrees of data heterogeneity. We present several mitigation strategies to\novercome performance drops from data heterogeneity, including weighted average\nfor data quantity skew, weighted loss and batch normalization averaging for\nlabel distribution skew. The proposed optimizations to federated learning\nmethods improve their capability of handling heterogeneity across institutions,\nwhich provides valuable guidance for the deployment of federated learning in\nreal clinical applications.",
          "link": "http://arxiv.org/abs/2107.08371",
          "publishedOn": "2021-07-20T02:04:43.497Z",
          "wordCount": 583,
          "title": "An Experimental Study of Data Heterogeneity in Federated Learning Methods for Medical Imaging. (arXiv:2107.08371v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08467",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gruenbacher_S/0/1/0/all/0/1\">Sophie Gruenbacher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lechner_M/0/1/0/all/0/1\">Mathias Lechner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasani_R/0/1/0/all/0/1\">Ramin Hasani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rus_D/0/1/0/all/0/1\">Daniela Rus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henzinger_T/0/1/0/all/0/1\">Thomas A. Henzinger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smolka_S/0/1/0/all/0/1\">Scott Smolka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grosu_R/0/1/0/all/0/1\">Radu Grosu</a>",
          "description": "We introduce a new stochastic verification algorithm that formally quantifies\nthe behavioral robustness of any time-continuous process formulated as a\ncontinuous-depth model. The algorithm solves a set of global optimization (Go)\nproblems over a given time horizon to construct a tight enclosure (Tube) of the\nset of all process executions starting from a ball of initial states. We call\nour algorithm GoTube. Through its construction, GoTube ensures that the\nbounding tube is conservative up to a desired probability. GoTube is\nimplemented in JAX and optimized to scale to complex continuous-depth models.\nCompared to advanced reachability analysis tools for time-continuous neural\nnetworks, GoTube provably does not accumulate over-approximation errors between\ntime steps and avoids the infamous wrapping effect inherent in symbolic\ntechniques. We show that GoTube substantially outperforms state-of-the-art\nverification tools in terms of the size of the initial ball, speed,\ntime-horizon, task completion, and scalability, on a large set of experiments.\nGoTube is stable and sets the state-of-the-art for its ability to scale up to\ntime horizons well beyond what has been possible before.",
          "link": "http://arxiv.org/abs/2107.08467",
          "publishedOn": "2021-07-20T02:04:43.457Z",
          "wordCount": 631,
          "title": "GoTube: Scalable Stochastic Verification of Continuous-Depth Models. (arXiv:2107.08467v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08567",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ampanavos_S/0/1/0/all/0/1\">Spyridon Ampanavos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nourbakhsh_M/0/1/0/all/0/1\">Mehdi Nourbakhsh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1\">Chin-Yi Cheng</a>",
          "description": "Structural engineering knowledge can be of significant importance to the\narchitectural design team during the early design phase. However, architects\nand engineers do not typically work together during the conceptual phase; in\nfact, structural engineers are often called late into the process. As a result,\nupdates in the design are more difficult and time-consuming to complete. At the\nsame time, there is a lost opportunity for better design exploration guided by\nstructural feedback. In general, the earlier in the design process the\niteration happens, the greater the benefits in cost efficiency and informed\nde-sign exploration, which can lead to higher-quality creative results. In\norder to facilitate an informed exploration in the early design stage, we\nsuggest the automation of fundamental structural engineering tasks and\nintroduce ApproxiFramer, a Machine Learning-based system for the automatic\ngeneration of structural layouts from building plan sketches in real-time. The\nsystem aims to assist architects by presenting them with feasible structural\nsolutions during the conceptual phase so that they proceed with their design\nwith adequate knowledge of its structural implications. In this paper, we\ndescribe the system and evaluate the performance of a proof-of-concept\nimplementation in the domain of orthogonal, metal, rigid structures. We trained\na Convolutional Neural Net to iteratively generate structural design solutions\nfor sketch-level building plans using a synthetic dataset and achieved an\naverage error of 2.2% in the predicted positions of the columns.",
          "link": "http://arxiv.org/abs/2107.08567",
          "publishedOn": "2021-07-20T02:04:43.390Z",
          "wordCount": 671,
          "title": "Structural Design Recommendations in the Early Design Phase using Machine Learning. (arXiv:2107.08567v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08461",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qiyiwen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bu_Z/0/1/0/all/0/1\">Zhiqi Bu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1\">Kan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_Q/0/1/0/all/0/1\">Qi Long</a>",
          "description": "Bayesian neural network (BNN) allows for uncertainty quantification in\nprediction, offering an advantage over regular neural networks that has not\nbeen explored in the differential privacy (DP) framework. We fill this\nimportant gap by leveraging recent development in Bayesian deep learning and\nprivacy accounting to offer a more precise analysis of the trade-off between\nprivacy and accuracy in BNN. We propose three DP-BNNs that characterize the\nweight uncertainty for the same network architecture in distinct ways, namely\nDP-SGLD (via the noisy gradient method), DP-BBP (via changing the parameters of\ninterest) and DP-MC Dropout (via the model architecture). Interestingly, we\nshow a new equivalence between DP-SGD and DP-SGLD, implying that some\nnon-Bayesian DP training naturally allows for uncertainty quantification.\nHowever, the hyperparameters such as learning rate and batch size, can have\ndifferent or even opposite effects in DP-SGD and DP-SGLD.\n\nExtensive experiments are conducted to compare DP-BNNs, in terms of privacy\nguarantee, prediction accuracy, uncertainty quantification, calibration,\ncomputation speed, and generalizability to network architecture. As a result,\nwe observe a new tradeoff between the privacy and the reliability. When\ncompared to non-DP and non-Bayesian approaches, DP-SGLD is remarkably accurate\nunder strong privacy guarantee, demonstrating the great potential of DP-BNN in\nreal-world tasks.",
          "link": "http://arxiv.org/abs/2107.08461",
          "publishedOn": "2021-07-20T02:04:43.317Z",
          "wordCount": 645,
          "title": "Differentially Private Bayesian Neural Networks on Accuracy, Privacy and Reliability. (arXiv:2107.08461v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08514",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Kokate_P/0/1/0/all/0/1\">Pranali Kokate</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pancholi_S/0/1/0/all/0/1\">Sidharth Pancholi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Joshi_A/0/1/0/all/0/1\">Amit M. Joshi</a>",
          "description": "The Brain-Computer Interface system is a profoundly developing area of\nexperimentation for Motor activities which plays vital role in decoding\ncognitive activities. Classification of Cognitive-Motor Imagery activities from\nEEG signals is a critical task. Hence proposed a unique algorithm for\nclassifying left/right-hand movements by utilizing Multi-layer Perceptron\nNeural Network. Handcrafted statistical Time domain and Power spectral density\nfrequency domain features were extracted and obtained a combined accuracy of\n96.02%. Results were compared with the deep learning framework. In addition to\naccuracy, Precision, F1-Score, and recall was considered as the performance\nmetrics. The intervention of unwanted signals contaminates the EEG signals\nwhich influence the performance of the algorithm. Therefore, a novel approach\nwas approached to remove the artifacts using Independent Components Analysis\nwhich boosted the performance. Following the selection of appropriate feature\nvectors that provided acceptable accuracy. The same method was used on all nine\nsubjects. As a result, intra-subject accuracy was obtained for 9 subjects\n94.72%. The results show that the proposed approach would be useful to classify\nthe upper limb movements accurately.",
          "link": "http://arxiv.org/abs/2107.08514",
          "publishedOn": "2021-07-20T02:04:43.244Z",
          "wordCount": 639,
          "title": "Classification of Upper Arm Movements from EEG signals using Machine Learning with ICA Analysis. (arXiv:2107.08514v1 [eess.SP])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08402",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tahmasebian_F/0/1/0/all/0/1\">Farnaz Tahmasebian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lou_J/0/1/0/all/0/1\">Jian Lou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_L/0/1/0/all/0/1\">Li Xiong</a>",
          "description": "Federated learning is a prominent framework that enables clients (e.g.,\nmobile devices or organizations) to train a collaboratively global model under\na central server's orchestration while keeping local training datasets'\nprivacy. However, the aggregation step in federated learning is vulnerable to\nadversarial attacks as the central server cannot manage clients' behavior.\nTherefore, the global model's performance and convergence of the training\nprocess will be affected under such attacks.To mitigate this vulnerability\nissue, we propose a novel robust aggregation algorithm inspired by the truth\ninference methods in crowdsourcing via incorporating the worker's reliability\ninto aggregation. We evaluate our solution on three real-world datasets with a\nvariety of machine learning models. Experimental results show that our solution\nensures robust federated learning and is resilient to various types of attacks,\nincluding noisy data attacks, Byzantine attacks, and label flipping attacks.",
          "link": "http://arxiv.org/abs/2107.08402",
          "publishedOn": "2021-07-20T02:04:43.220Z",
          "wordCount": 582,
          "title": "RobustFed: A Truth Inference Approach for Robust Federated Learning. (arXiv:2107.08402v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.10507",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1\">Ke Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yufei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yingfeng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1\">Changjie Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Zhipeng Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1\">Wei Yang</a>",
          "description": "Graphically-rich applications such as games are ubiquitous with attractive\nvisual effects of Graphical User Interface (GUI) that offers a bridge between\nsoftware applications and end-users. However, various types of graphical\nglitches may arise from such GUI complexity and have become one of the main\ncomponent of software compatibility issues. Our study on bug reports from game\ndevelopment teams in NetEase Inc. indicates that graphical glitches frequently\noccur during the GUI rendering and severely degrade the quality of\ngraphically-rich applications such as video games. Existing automated testing\ntechniques for such applications focus mainly on generating various GUI test\nsequences and check whether the test sequences can cause crashes. These\ntechniques require constant human attention to captures non-crashing bugs such\nas bugs causing graphical glitches. In this paper, we present the first step in\nautomating the test oracle for detecting non-crashing bugs in graphically-rich\napplications. Specifically, we propose \\texttt{GLIB} based on a code-based data\naugmentation technique to detect game GUI glitches. We perform an evaluation of\n\\texttt{GLIB} on 20 real-world game apps (with bug reports available) and the\nresult shows that \\texttt{GLIB} can achieve 100\\% precision and 99.5\\% recall\nin detecting non-crashing bugs such as game GUI glitches. Practical application\nof \\texttt{GLIB} on another 14 real-world games (without bug reports) further\ndemonstrates that \\texttt{GLIB} can effectively uncover GUI glitches, with 48\nof 53 bugs reported by \\texttt{GLIB} having been confirmed and fixed so far.",
          "link": "http://arxiv.org/abs/2106.10507",
          "publishedOn": "2021-07-19T01:59:51.065Z",
          "wordCount": 727,
          "title": "GLIB: Towards Automated Test Oracle for Graphically-Rich Applications. (arXiv:2106.10507v3 [cs.SE] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.04388",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cooper_J/0/1/0/all/0/1\">Jessica Cooper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Um_I/0/1/0/all/0/1\">In Hwa Um</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arandjelovic_O/0/1/0/all/0/1\">Ognjen Arandjelovi&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harrison_D/0/1/0/all/0/1\">David J Harrison</a>",
          "description": "Multiplex immunofluorescence and immunohistochemistry benefit patients by\nallowing cancer pathologists to identify several proteins expressed on the\nsurface of cells, enabling cell classification, better understanding of the\ntumour micro-environment, more accurate diagnoses, prognoses, and tailored\nimmunotherapy based on the immune status of individual patients. However, they\nare expensive and time consuming processes which require complex staining and\nimaging techniques by expert technicians. Hoechst staining is much cheaper and\neasier to perform, but is not typically used in this case as it binds to DNA\nrather than to the proteins targeted by immunofluorescent techniques, and it\nwas not previously thought possible to differentiate cells expressing these\nproteins based only on DNA morphology. In this work we show otherwise, training\na deep convolutional neural network to identify cells expressing three proteins\n(T lymphocyte markers CD3 and CD8, and the B lymphocyte marker CD20) with\ngreater than 90% precision and recall, from Hoechst 33342 stained tissue only.\nOur model learns previously unknown morphological features associated with\nexpression of these proteins which can be used to accurately differentiate\nlymphocyte subtypes for use in key prognostic metrics such as assessment of\nimmune cell infiltration,and thereby predict and improve patient outcomes\nwithout the need for costly multiplex immunofluorescence.",
          "link": "http://arxiv.org/abs/2107.04388",
          "publishedOn": "2021-07-19T01:59:51.035Z",
          "wordCount": 673,
          "title": "Hoechst Is All You Need: Lymphocyte Classification with Deep Learning. (arXiv:2107.04388v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.00815",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_C/0/1/0/all/0/1\">Chi Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qinghua Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miryoosefi_S/0/1/0/all/0/1\">Sobhan Miryoosefi</a>",
          "description": "Finding the minimal structural assumptions that empower sample-efficient\nlearning is one of the most important research directions in Reinforcement\nLearning (RL). This paper advances our understanding of this fundamental\nquestion by introducing a new complexity measure -- Bellman Eluder (BE)\ndimension. We show that the family of RL problems of low BE dimension is\nremarkably rich, which subsumes a vast majority of existing tractable RL\nproblems including but not limited to tabular MDPs, linear MDPs, reactive\nPOMDPs, low Bellman rank problems as well as low Eluder dimension problems.\nThis paper further designs a new optimization-based algorithm -- GOLF, and\nreanalyzes a hypothesis elimination-based algorithm -- OLIVE (proposed in Jiang\net al., 2017). We prove that both algorithms learn the near-optimal policies of\nlow BE dimension problems in a number of samples that is polynomial in all\nrelevant parameters, but independent of the size of state-action space. Our\nregret and sample complexity results match or improve the best existing results\nfor several well-known subclasses of low BE dimension problems.",
          "link": "http://arxiv.org/abs/2102.00815",
          "publishedOn": "2021-07-19T00:49:08.148Z",
          "wordCount": 659,
          "title": "Bellman Eluder Dimension: New Rich Classes of RL Problems, and Sample-Efficient Algorithms. (arXiv:2102.00815v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.03686",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Thanthrige_U/0/1/0/all/0/1\">Udaya S.K.P. Miriya Thanthrige</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jung_P/0/1/0/all/0/1\">Peter Jung</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sezgin_A/0/1/0/all/0/1\">Aydin Sezgin</a>",
          "description": "We address the detection of material defects, which are inside a layered\nmaterial structure using compressive sensing based multiple-input and\nmultiple-output (MIMO) wireless radar. Here, the strong clutter due to the\nreflection of the layered structure's surface often makes the detection of the\ndefects challenging. Thus, sophisticated signal separation methods are required\nfor improved defect detection. In many scenarios, the number of defects that we\nare interested in is limited and the signaling response of the layered\nstructure can be modeled as a low-rank structure. Therefore, we propose joint\nrank and sparsity minimization for defect detection. In particular, we propose\na non-convex approach based on the iteratively reweighted nuclear and\n$\\ell_1-$norm (a double-reweighted approach) to obtain a higher accuracy\ncompared to the conventional nuclear norm and $\\ell_1-$norm minimization. To\nthis end, an iterative algorithm is designed to estimate the low-rank and\nsparse contributions. Further, we propose deep learning to learn the parameters\nof the algorithm (i.e., algorithm unfolding) to improve the accuracy and the\nspeed of convergence of the algorithm. Our numerical results show that the\nproposed approach outperforms the conventional approaches in terms of mean\nsquare errors of the recovered low-rank and sparse components and the speed of\nconvergence.",
          "link": "http://arxiv.org/abs/2106.03686",
          "publishedOn": "2021-07-19T00:49:08.127Z",
          "wordCount": 681,
          "title": "Deep Unfolding of Iteratively Reweighted ADMM for Wireless RF Sensing. (arXiv:2106.03686v2 [eess.SP] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.12789",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dubois_Y/0/1/0/all/0/1\">Yann Dubois</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiela_D/0/1/0/all/0/1\">Douwe Kiela</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schwab_D/0/1/0/all/0/1\">David J. Schwab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vedantam_R/0/1/0/all/0/1\">Ramakrishna Vedantam</a>",
          "description": "We address the question of characterizing and finding optimal representations\nfor supervised learning. Traditionally, this question has been tackled using\nthe Information Bottleneck, which compresses the inputs while retaining\ninformation about the targets, in a decoder-agnostic fashion. In machine\nlearning, however, our goal is not compression but rather generalization, which\nis intimately linked to the predictive family or decoder of interest (e.g.\nlinear classifier). We propose the Decodable Information Bottleneck (DIB) that\nconsiders information retention and compression from the perspective of the\ndesired predictive family. As a result, DIB gives rise to representations that\nare optimal in terms of expected test performance and can be estimated with\nguarantees. Empirically, we show that the framework can be used to enforce a\nsmall generalization gap on downstream classifiers and to predict the\ngeneralization ability of neural networks.",
          "link": "http://arxiv.org/abs/2009.12789",
          "publishedOn": "2021-07-19T00:49:08.103Z",
          "wordCount": 611,
          "title": "Learning Optimal Representations with the Decodable Information Bottleneck. (arXiv:2009.12789v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.00926",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yujiang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sick_B/0/1/0/all/0/1\">Bernhard Sick</a>",
          "description": "Catastrophic forgetting means that a trained neural network model gradually\nforgets the previously learned tasks when being retrained on new tasks.\nOvercoming the forgetting problem is a major problem in machine learning.\nNumerous continual learning algorithms are very successful in incremental\nlearning of classification tasks, where new samples with their labels appear\nfrequently. However, there is currently no research that addresses the\ncatastrophic forgetting problem in regression tasks as far as we know. This\nproblem has emerged as one of the primary constraints in some applications,\nsuch as renewable energy forecasts. This article clarifies problem-related\ndefinitions and proposes a new methodological framework that can forecast\ntargets and update itself by means of continual learning. The framework\nconsists of forecasting neural networks and buffers, which store newly\ncollected data from a non-stationary data stream in an application. The changed\nprobability distribution of the data stream, which the framework has\nidentified, will be learned sequentially. The framework is called CLeaR\n(Continual Learning for Regression Tasks), where components can be flexibly\ncustomized for a specific application scenario. We design two sets of\nexperiments to evaluate the CLeaR framework concerning fitting error\n(training), prediction error (test), and forgetting ratio. The first one is\nbased on an artificial time series to explore how hyperparameters affect the\nCLeaR framework. The second one is designed with data collected from European\nwind farms to evaluate the CLeaR framework's performance in a real-world\napplication. The experimental results demonstrate that the CLeaR framework can\ncontinually acquire knowledge in the data stream and improve the prediction\naccuracy. The article concludes with further research issues arising from\nrequirements to extend the framework.",
          "link": "http://arxiv.org/abs/2101.00926",
          "publishedOn": "2021-07-19T00:49:08.077Z",
          "wordCount": 751,
          "title": "CLeaR: An Adaptive Continual Learning Framework for Regression Tasks. (arXiv:2101.00926v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.01400",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shulman_Y/0/1/0/all/0/1\">Yaniv Shulman</a>",
          "description": "Quantization based model compression serves as high performing and fast\napproach for inference that yields models which are highly compressed when\ncompared to their full-precision floating point counterparts. The most extreme\nquantization is a 1-bit representation of parameters such that they have only\ntwo possible values, typically -1(0) or +1, enabling efficient implementation\nof the ubiquitous dot product using only additions. The main contribution of\nthis work is the introduction of a method to smooth the combinatorial problem\nof determining a binary vector of weights to minimize the expected loss for a\ngiven objective by means of empirical risk minimization with backpropagation.\nThis is achieved by approximating a multivariate binary state over the weights\nutilizing a deterministic and differentiable transformation of real-valued,\ncontinuous parameters. The proposed method adds little overhead in training,\ncan be readily applied without any substantial modifications to the original\narchitecture, does not introduce additional saturating nonlinearities or\nauxiliary losses, and does not prohibit applying other methods for binarizing\nthe activations. Contrary to common assertions made in the literature, it is\ndemonstrated that binary weighted networks can train well with the same\nstandard optimization techniques and similar hyperparameter settings as their\nfull-precision counterparts, specifically momentum SGD with large learning\nrates and $L_2$ regularization. To conclude experiments demonstrate the method\nperforms remarkably well across a number of inductive image classification\ntasks with various architectures compared to their full-precision counterparts.\nThe source code is publicly available at\nhttps://bitbucket.org/YanivShu/binary_weighted_networks_public.",
          "link": "http://arxiv.org/abs/2107.01400",
          "publishedOn": "2021-07-19T00:49:08.072Z",
          "wordCount": 691,
          "title": "Exact Backpropagation in Binary Weighted Networks with Group Weight Transformations. (arXiv:2107.01400v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.02359",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chari_S/0/1/0/all/0/1\">Shruthi Chari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_P/0/1/0/all/0/1\">Prithwish Chakraborty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghalwash_M/0/1/0/all/0/1\">Mohamed Ghalwash</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seneviratne_O/0/1/0/all/0/1\">Oshani Seneviratne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eyigoz_E/0/1/0/all/0/1\">Elif K. Eyigoz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gruen_D/0/1/0/all/0/1\">Daniel M. Gruen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saiz_F/0/1/0/all/0/1\">Fernando Suarez Saiz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Ching-Hua Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rojas_P/0/1/0/all/0/1\">Pablo Meyer Rojas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McGuinness_D/0/1/0/all/0/1\">Deborah L. McGuinness</a>",
          "description": "Academic advances of AI models in high-precision domains, like healthcare,\nneed to be made explainable in order to enhance real-world adoption. Our past\nstudies and ongoing interactions indicate that medical experts can use AI\nsystems with greater trust if there are ways to connect the model inferences\nabout patients to explanations that are tied back to the context of use.\nSpecifically, risk prediction is a complex problem of diagnostic and\ninterventional importance to clinicians wherein they consult different sources\nto make decisions. To enable the adoption of the ever improving AI risk\nprediction models in practice, we have begun to explore techniques to\ncontextualize such models along three dimensions of interest: the patients'\nclinical state, AI predictions about their risk of complications, and\nalgorithmic explanations supporting the predictions. We validate the importance\nof these dimensions by implementing a proof-of-concept (POC) in type-2 diabetes\n(T2DM) use case where we assess the risk of chronic kidney disease (CKD) - a\ncommon T2DM comorbidity. Within the POC, we include risk prediction models for\nCKD, post-hoc explainers of the predictions, and other natural-language modules\nwhich operationalize domain knowledge and CPGs to provide context. With primary\ncare physicians (PCP) as our end-users, we present our initial results and\nclinician feedback in this paper. Our POC approach covers multiple knowledge\nsources and clinical scenarios, blends knowledge to explain data and\npredictions to PCPs, and received an enthusiastic response from our medical\nexpert.",
          "link": "http://arxiv.org/abs/2107.02359",
          "publishedOn": "2021-07-19T00:49:07.963Z",
          "wordCount": 746,
          "title": "Leveraging Clinical Context for User-Centered Explainability: A Diabetes Use Case. (arXiv:2107.02359v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.14172",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kileel_J/0/1/0/all/0/1\">Joe Kileel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moscovich_A/0/1/0/all/0/1\">Amit Moscovich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zelesko_N/0/1/0/all/0/1\">Nathan Zelesko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singer_A/0/1/0/all/0/1\">Amit Singer</a>",
          "description": "Manifold learning methods play a prominent role in nonlinear dimensionality\nreduction and other tasks involving high-dimensional data sets with low\nintrinsic dimensionality. Many of these methods are graph-based: they associate\na vertex with each data point and a weighted edge with each pair. Existing\ntheory shows that the Laplacian matrix of the graph converges to the\nLaplace-Beltrami operator of the data manifold, under the assumption that the\npairwise affinities are based on the Euclidean norm. In this paper, we\ndetermine the limiting differential operator for graph Laplacians constructed\nusing $\\textit{any}$ norm. Our proof involves an interplay between the second\nfundamental form of the manifold and the convex geometry of the given norm's\nunit ball. To demonstrate the potential benefits of non-Euclidean norms in\nmanifold learning, we consider the task of mapping the motion of large\nmolecules with continuous variability. In a numerical simulation we show that a\nmodified Laplacian eigenmaps algorithm, based on the Earthmover's distance,\noutperforms the classic Euclidean Laplacian eigenmaps, both in terms of\ncomputational cost and the sample size needed to recover the intrinsic\ngeometry.",
          "link": "http://arxiv.org/abs/2012.14172",
          "publishedOn": "2021-07-19T00:49:07.957Z",
          "wordCount": 651,
          "title": "Manifold learning with arbitrary norms. (arXiv:2012.14172v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08039",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhizhong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ravichandran_A/0/1/0/all/0/1\">Avinash Ravichandran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fowlkes_C/0/1/0/all/0/1\">Charless Fowlkes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Polito_M/0/1/0/all/0/1\">Marzia Polito</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhotika_R/0/1/0/all/0/1\">Rahul Bhotika</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1\">Stefano Soatto</a>",
          "description": "Traditionally, distillation has been used to train a student model to emulate\nthe input/output functionality of a teacher. A more useful goal than emulation,\nyet under-explored, is for the student to learn feature representations that\ntransfer well to future tasks. However, we observe that standard distillation\nof task-specific teachers actually *reduces* the transferability of student\nrepresentations to downstream tasks. We show that a multi-head, multi-task\ndistillation method using an unlabeled proxy dataset and a generalist teacher\nis sufficient to consolidate representations from task-specific teacher(s) and\nimprove downstream performance, outperforming the teacher(s) and the strong\nbaseline of ImageNet pretrained features. Our method can also combine the\nrepresentational knowledge of multiple teachers trained on one or multiple\ndomains into a single model, whose representation is improved on all teachers'\ndomain(s).",
          "link": "http://arxiv.org/abs/2107.08039",
          "publishedOn": "2021-07-19T00:49:07.951Z",
          "wordCount": 568,
          "title": "Representation Consolidation for Training Expert Students. (arXiv:2107.08039v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.14706",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zombori_Z/0/1/0/all/0/1\">Zsolt Zombori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Urban_J/0/1/0/all/0/1\">Josef Urban</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Olsak_M/0/1/0/all/0/1\">Miroslav Ol&#x161;&#xe1;k</a>",
          "description": "In this work we study how to learn good algorithms for selecting reasoning\nsteps in theorem proving. We explore this in the connection tableau calculus\nimplemented by leanCoP where the partial tableau provides a clean and compact\nnotion of a state to which a limited number of inferences can be applied. We\nstart by incorporating a state-of-the-art learning algorithm -- a graph neural\nnetwork (GNN) -- into the plCoP theorem prover. Then we use it to observe the\nsystem's behaviour in a reinforcement learning setting, i.e., when learning\ninference guidance from successful Monte-Carlo tree searches on many problems.\nDespite its better pattern matching capability, the GNN initially performs\nworse than a simpler previously used learning algorithm. We observe that the\nsimpler algorithm is less confident, i.e., its recommendations have higher\nentropy. This leads us to explore how the entropy of the inference selection\nimplemented via the neural network influences the proof search. This is related\nto research in human decision-making under uncertainty, and in particular the\nprobability matching theory. Our main result shows that a proper entropy\nregularisation, i.e., training the GNN not to be overconfident, greatly\nimproves plCoP's performance on a large mathematical corpus.",
          "link": "http://arxiv.org/abs/2105.14706",
          "publishedOn": "2021-07-19T00:49:07.934Z",
          "wordCount": 664,
          "title": "The Role of Entropy in Guiding a Connection Prover. (arXiv:2105.14706v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.13907",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ablett_T/0/1/0/all/0/1\">Trevor Ablett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_Y/0/1/0/all/0/1\">Yifan Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kelly_J/0/1/0/all/0/1\">Jonathan Kelly</a>",
          "description": "Learned visuomotor policies have shown considerable success as an alternative\nto traditional, hand-crafted frameworks for robotic manipulation. Surprisingly,\nan extension of these methods to the multiview domain is relatively unexplored.\nA successful multiview policy could be deployed on a mobile manipulation\nplatform, allowing the robot to complete a task regardless of its view of the\nscene. In this work, we demonstrate that a multiview policy can be found\nthrough imitation learning by collecting data from a variety of viewpoints. We\nillustrate the general applicability of the method by learning to complete\nseveral challenging multi-stage and contact-rich tasks, from numerous\nviewpoints, both in a simulated environment and on a real mobile manipulation\nplatform. Furthermore, we analyze our policies to determine the benefits of\nlearning from multiview data compared to learning with data collected from a\nfixed perspective. We show that learning from multiview data results in little,\nif any, penalty to performance for a fixed-view task compared to learning with\nan equivalent amount of fixed-view data. Finally, we examine the visual\nfeatures learned by the multiview and fixed-view policies. Our results indicate\nthat multiview policies implicitly learn to identify spatially correlated\nfeatures.",
          "link": "http://arxiv.org/abs/2104.13907",
          "publishedOn": "2021-07-19T00:49:07.928Z",
          "wordCount": 673,
          "title": "Seeing All the Angles: Learning Multiview Manipulation Policies for Contact-Rich Tasks from Demonstrations. (arXiv:2104.13907v2 [cs.RO] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.02716",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1\">Charles Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lemay_A/0/1/0/all/0/1\">Andreanne Lemay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoebel_K/0/1/0/all/0/1\">Katharina Hoebel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalpathy_Cramer_J/0/1/0/all/0/1\">Jayashree Kalpathy-Cramer</a>",
          "description": "As machine learning (ML) continue to be integrated into healthcare systems\nthat affect clinical decision making, new strategies will need to be\nincorporated in order to effectively detect and evaluate subgroup disparities\nto ensure accountability and generalizability in clinical workflows. In this\npaper, we explore how epistemic uncertainty can be used to evaluate disparity\nin patient demographics (race) and data acquisition (scanner) subgroups for\nbreast density assessment on a dataset of 108,190 mammograms collected from 33\nclinical sites. Our results show that even if aggregate performance is\ncomparable, the choice of uncertainty quantification metric can significantly\nthe subgroup level. We hope this analysis can promote further work on how\nuncertainty can be leveraged to increase transparency of machine learning\napplications for clinical deployment.",
          "link": "http://arxiv.org/abs/2107.02716",
          "publishedOn": "2021-07-19T00:49:07.921Z",
          "wordCount": 591,
          "title": "Evaluating subgroup disparity using epistemic uncertainty in mammography. (arXiv:2107.02716v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.09048",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Rolle_A/0/1/0/all/0/1\">Alexander Rolle</a>, <a href=\"http://arxiv.org/find/math/1/au:+Scoccola_L/0/1/0/all/0/1\">Luis Scoccola</a>",
          "description": "We present a multiscale, consistent approach to density-based clustering that\nsatisfies stability theorems -- in both the input data and in the parameters --\nwhich hold without distributional assumptions. The stability in the input data\nis with respect to the Gromov--Hausdorff--Prokhorov distance on metric\nprobability spaces and interleaving distances between (multi-parameter)\nhierarchical clusterings we introduce. We prove stability results for standard\nsimplification procedures for hierarchical clusterings, which can be combined\nwith our approach to yield a stable flat clustering algorithm. We illustrate\nthe stability of the approach with computational examples. Our framework is\nbased on the concepts of persistence and interleaving distance from Topological\nData Analysis.",
          "link": "http://arxiv.org/abs/2005.09048",
          "publishedOn": "2021-07-19T00:49:07.914Z",
          "wordCount": 564,
          "title": "Stable and consistent density-based clustering. (arXiv:2005.09048v2 [math.ST] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.02522",
          "author": "<a href=\"http://arxiv.org/find/q-fin/1/au:+Wu_J/0/1/0/all/0/1\">Junran Wu</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Xu_K/0/1/0/all/0/1\">Ke Xu</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Chen_X/0/1/0/all/0/1\">Xueyuan Chen</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Li_S/0/1/0/all/0/1\">Shangzhe Li</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Zhao_J/0/1/0/all/0/1\">Jichang Zhao</a>",
          "description": "Great research efforts have been devoted to exploiting deep neural networks\nin stock prediction. While long-range dependencies and chaotic property are\nstill two major issues that lower the performance of state-of-the-art deep\nlearning models in forecasting future price trends. In this study, we propose a\nnovel framework to address both issues. Specifically, in terms of transforming\ntime series into complex networks, we convert market price series into graphs.\nThen, structural information, referring to associations among temporal points\nand the node weights, is extracted from the mapped graphs to resolve the\nproblems regarding long-range dependencies and the chaotic property. We take\ngraph embeddings to represent the associations among temporal points as the\nprediction model inputs. Node weights are used as a priori knowledge to enhance\nthe learning of temporal attention. The effectiveness of our proposed framework\nis validated using real-world stock data, and our approach obtains the best\nperformance among several state-of-the-art benchmarks. Moreover, in the\nconducted trading simulations, our framework further obtains the highest\ncumulative profits. Our results supplement the existing applications of complex\nnetwork methods in the financial realm and provide insightful implications for\ninvestment applications regarding decision support in financial markets.",
          "link": "http://arxiv.org/abs/2106.02522",
          "publishedOn": "2021-07-19T00:49:07.896Z",
          "wordCount": 671,
          "title": "Price graphs: Utilizing the structural information of financial time series for stock prediction. (arXiv:2106.02522v3 [q-fin.ST] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.05445",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yipeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hayes_T/0/1/0/all/0/1\">Tyler L. Hayes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanan_C/0/1/0/all/0/1\">Christopher Kanan</a>",
          "description": "Humans are incredibly good at transferring knowledge from one domain to\nanother, enabling rapid learning of new tasks. Likewise, transfer learning has\nenabled enormous success in many computer vision problems using pretraining.\nHowever, the benefits of transfer in multi-domain learning, where a network\nlearns multiple tasks defined by different datasets, has not been adequately\nstudied. Learning multiple domains could be beneficial or these domains could\ninterfere with each other given limited network capacity. In this work, we\ndecipher the conditions where interference and knowledge transfer occur in\nmulti-domain learning. We propose new metrics disentangling interference and\ntransfer and set up experimental protocols. We further examine the roles of\nnetwork capacity, task grouping, and dynamic loss weighting in reducing\ninterference and facilitating transfer. We demonstrate our findings on the\nCIFAR-100, MiniPlaces, and Tiny-ImageNet datasets.",
          "link": "http://arxiv.org/abs/2107.05445",
          "publishedOn": "2021-07-19T00:49:07.890Z",
          "wordCount": 591,
          "title": "Disentangling Transfer and Interference in Multi-Domain Learning. (arXiv:2107.05445v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.13805",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Frei_S/0/1/0/all/0/1\">Spencer Frei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_D/0/1/0/all/0/1\">Difan Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zixiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1\">Quanquan Gu</a>",
          "description": "We consider a binary classification problem when the data comes from a\nmixture of two isotropic distributions satisfying concentration and\nanti-concentration properties enjoyed by log-concave distributions among\nothers. We show that there exists a universal constant $C_{\\mathrm{err}}>0$\nsuch that if a pseudolabeler $\\boldsymbol{\\beta}_{\\mathrm{pl}}$ can achieve\nclassification error at most $C_{\\mathrm{err}}$, then for any $\\varepsilon>0$,\nan iterative self-training algorithm initialized at $\\boldsymbol{\\beta}_0 :=\n\\boldsymbol{\\beta}_{\\mathrm{pl}}$ using pseudolabels $\\hat y =\n\\mathrm{sgn}(\\langle \\boldsymbol{\\beta}_t, \\mathbf{x}\\rangle)$ and using at\nmost $\\tilde O(d/\\varepsilon^2)$ unlabeled examples suffices to learn the\nBayes-optimal classifier up to $\\varepsilon$ error, where $d$ is the ambient\ndimension. That is, self-training converts weak learners to strong learners\nusing only unlabeled examples. We additionally show that by running gradient\ndescent on the logistic loss one can obtain a pseudolabeler\n$\\boldsymbol{\\beta}_{\\mathrm{pl}}$ with classification error $C_{\\mathrm{err}}$\nusing only $O(d)$ labeled examples (i.e., independent of $\\varepsilon$).\nTogether our results imply that mixture models can be learned to within\n$\\varepsilon$ of the Bayes-optimal accuracy using at most $O(d)$ labeled\nexamples and $\\tilde O(d/\\varepsilon^2)$ unlabeled examples by way of a\nsemi-supervised self-training algorithm.",
          "link": "http://arxiv.org/abs/2106.13805",
          "publishedOn": "2021-07-19T00:49:07.884Z",
          "wordCount": 650,
          "title": "Self-training Converts Weak Learners to Strong Learners in Mixture Models. (arXiv:2106.13805v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.05457",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_G/0/1/0/all/0/1\">Guanya Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Honig_W/0/1/0/all/0/1\">Wolfgang H&#xf6;nig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1\">Xichen Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yue_Y/0/1/0/all/0/1\">Yisong Yue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chung_S/0/1/0/all/0/1\">Soon-Jo Chung</a>",
          "description": "We present Neural-Swarm2, a learning-based method for motion planning and\ncontrol that allows heterogeneous multirotors in a swarm to safely fly in close\nproximity. Such operation for drones is challenging due to complex aerodynamic\ninteraction forces, such as downwash generated by nearby drones and ground\neffect. Conventional planning and control methods neglect capturing these\ninteraction forces, resulting in sparse swarm configuration during flight. Our\napproach combines a physics-based nominal dynamics model with learned Deep\nNeural Networks (DNNs) with strong Lipschitz properties. We make use of two\ntechniques to accurately predict the aerodynamic interactions between\nheterogeneous multirotors: i) spectral normalization for stability and\ngeneralization guarantees of unseen data and ii) heterogeneous deep sets for\nsupporting any number of heterogeneous neighbors in a permutation-invariant\nmanner without reducing expressiveness. The learned residual dynamics benefit\nboth the proposed interaction-aware multi-robot motion planning and the\nnonlinear tracking control design because the learned interaction forces reduce\nthe modelling errors. Experimental results demonstrate that Neural-Swarm2 is\nable to generalize to larger swarms beyond training cases and significantly\noutperforms a baseline nonlinear tracking controller with up to three times\nreduction in worst-case tracking errors.",
          "link": "http://arxiv.org/abs/2012.05457",
          "publishedOn": "2021-07-19T00:49:07.877Z",
          "wordCount": 683,
          "title": "Neural-Swarm2: Planning and Control of Heterogeneous Multirotor Swarms using Learned Interactions. (arXiv:2012.05457v2 [cs.RO] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.05682",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_M/0/1/0/all/0/1\">Ming Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yizhen Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuan-Fang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_C/0/1/0/all/0/1\">Chen Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Chuan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1\">Shirui Pan</a>",
          "description": "Graph representation learning plays a vital role in processing\ngraph-structured data. However, prior arts on graph representation learning\nheavily rely on labeling information. To overcome this problem, inspired by the\nrecent success of graph contrastive learning and Siamese networks in visual\nrepresentation learning, we propose a novel self-supervised approach in this\npaper to learn node representations by enhancing Siamese self-distillation with\nmulti-scale contrastive learning. Specifically, we first generate two augmented\nviews from the input graph based on local and global perspectives. Then, we\nemploy two objectives called cross-view and cross-network contrastiveness to\nmaximize the agreement between node representations across different views and\nnetworks. To demonstrate the effectiveness of our approach, we perform\nempirical experiments on five real-world datasets. Our method not only achieves\nnew state-of-the-art results but also surpasses some semi-supervised\ncounterparts by large margins. Code is made available at\nhttps://github.com/GRAND-Lab/MERIT",
          "link": "http://arxiv.org/abs/2105.05682",
          "publishedOn": "2021-07-19T00:49:07.866Z",
          "wordCount": 632,
          "title": "Multi-Scale Contrastive Siamese Networks for Self-Supervised Graph Representation Learning. (arXiv:2105.05682v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.07878",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Muniz_I/0/1/0/all/0/1\">I. Muniz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Camargo_F/0/1/0/all/0/1\">F. H. F. Camargo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marques_A/0/1/0/all/0/1\">A. Marques</a>",
          "description": "With the constant advancements of genetic engineering, a common concern is to\nbe able to identify the lab-of-origin of genetically engineered DNA sequences.\nFor that reason, AltLabs has hosted the genetic Engineering Attribution\nChallenge to gather many teams to propose new tools to solve this problem. Here\nwe show our proposed method to rank the most likely labs-of-origin and generate\nembeddings for DNA sequences and labs. These embeddings can also perform\nvarious other tasks, like clustering both DNA sequences and labs and using them\nas features for Machine Learning models applied to solve other problems. This\nwork demonstrates that our method outperforms the classic training method for\nthis task while generating other helpful information.",
          "link": "http://arxiv.org/abs/2107.07878",
          "publishedOn": "2021-07-19T00:49:07.860Z",
          "wordCount": 567,
          "title": "Ranking labs-of-origin for genetically engineered DNA using Metric Learning. (arXiv:2107.07878v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2104.10785",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Godaz_R/0/1/0/all/0/1\">Reza Godaz</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Monsefi_R/0/1/0/all/0/1\">Reza Monsefi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Toutounian_F/0/1/0/all/0/1\">Faezeh Toutounian</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hosseini_R/0/1/0/all/0/1\">Reshad Hosseini</a>",
          "description": "In this paper we tackle two important challenges related to the accurate\npartial singular value decomposition (SVD) and numerical rank estimation of a\nhuge matrix to use in low-rank learning problems in a fast way. We use the\nconcepts of Krylov subspaces such as the Golub-Kahan bidiagonalization process\nas well as Ritz vectors to achieve these goals. Our experiments identify\nvarious advantages of the proposed methods compared to traditional and\nrandomized SVD (R-SVD) methods with respect to the accuracy of the singular\nvalues and corresponding singular vectors computed in a similar execution time.\nThe proposed methods are appropriate for applications involving huge matrices\nwhere accuracy in all spectrum of the desired singular values, and also all of\ncorresponding singular vectors is essential. We evaluate our method in the real\napplication of Riemannian similarity learning (RSL) between two various image\ndatasets of MNIST and USPS.",
          "link": "http://arxiv.org/abs/2104.10785",
          "publishedOn": "2021-07-19T00:49:07.855Z",
          "wordCount": 611,
          "title": "Accurate and fast matrix factorization for low-rank learning. (arXiv:2104.10785v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.04785",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_R/0/1/0/all/0/1\">Renqian Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1\">Xu Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1\">Tao Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_E/0/1/0/all/0/1\">Enhong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tie-Yan Liu</a>",
          "description": "Neural architecture search (NAS) with an accuracy predictor that predicts the\naccuracy of candidate architectures has drawn increasing attention due to its\nsimplicity and effectiveness. Previous works usually employ neural\nnetwork-based predictors which require more delicate design and are easy to\noverfit. Considering that most architectures are represented as sequences of\ndiscrete symbols which are more like tabular data and preferred by non-neural\npredictors, in this paper, we study an alternative approach which uses\nnon-neural model for accuracy prediction. Specifically, as decision tree based\nmodels can better handle tabular data, we leverage gradient boosting decision\ntree (GBDT) as the predictor for NAS. We demonstrate that the GBDT predictor\ncan achieve comparable (if not better) prediction accuracy than neural network\nbased predictors. Moreover, considering that a compact search space can ease\nthe search process, we propose to prune the search space gradually according to\nimportant features derived from GBDT. In this way, NAS can be performed by\nfirst pruning the search space and then searching a neural architecture, which\nis more efficient and effective. Experiments on NASBench-101 and ImageNet\ndemonstrate the effectiveness of using GBDT as predictor for NAS: (1) On\nNASBench-101, it is 22x, 8x, and 6x more sample efficient than random search,\nregularized evolution, and Monte Carlo Tree Search (MCTS) in finding the global\noptimum; (2) It achieves 24.2% top-1 error rate on ImageNet, and further\nachieves 23.4% top-1 error rate on ImageNet when enhanced with search space\npruning. Code is provided in the supplementary materials.",
          "link": "http://arxiv.org/abs/2007.04785",
          "publishedOn": "2021-07-19T00:49:07.849Z",
          "wordCount": 738,
          "title": "Accuracy Prediction with Non-neural Model for Neural Architecture Search. (arXiv:2007.04785v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.01600",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bansal_P/0/1/0/all/0/1\">Parikshit Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deshpande_P/0/1/0/all/0/1\">Prathamesh Deshpande</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarawagi_S/0/1/0/all/0/1\">Sunita Sarawagi</a>",
          "description": "We present DeepMVI, a deep learning method for missing value imputation in\nmultidimensional time-series datasets. Missing values are commonplace in\ndecision support platforms that aggregate data over long time stretches from\ndisparate sources, and reliable data analytics calls for careful handling of\nmissing data. One strategy is imputing the missing values, and a wide variety\nof algorithms exist spanning simple interpolation, matrix factorization methods\nlike SVD, statistical models like Kalman filters, and recent deep learning\nmethods. We show that often these provide worse results on aggregate analytics\ncompared to just excluding the missing data. DeepMVI uses a neural network to\ncombine fine-grained and coarse-grained patterns along a time series, and\ntrends from related series across categorical dimensions. After failing with\noff-the-shelf neural architectures, we design our own network that includes a\ntemporal transformer with a novel convolutional window feature, and kernel\nregression with learned embeddings. The parameters and their training are\ndesigned carefully to generalize across different placements of missing blocks\nand data characteristics. Experiments across nine real datasets, four different\nmissing scenarios, comparing seven existing methods show that DeepMVI is\nsignificantly more accurate, reducing error by more than 50% in more than half\nthe cases, compared to the best existing method. Although slower than simpler\nmatrix factorization methods, we justify the increased time overheads by\nshowing that DeepMVI is the only option that provided overall more accurate\nanalytics than dropping missing values.",
          "link": "http://arxiv.org/abs/2103.01600",
          "publishedOn": "2021-07-19T00:49:07.816Z",
          "wordCount": 694,
          "title": "Missing Value Imputation on Multidimensional Time Series. (arXiv:2103.01600v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.04565",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schoeffer_J/0/1/0/all/0/1\">Jakob Schoeffer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuehl_N/0/1/0/all/0/1\">Niklas Kuehl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valera_I/0/1/0/all/0/1\">Isabel Valera</a>",
          "description": "Algorithmic decision systems are increasingly used in areas such as hiring,\nschool admission, or loan approval. Typically, these systems rely on labeled\ndata for training a classification model. However, in many scenarios,\nground-truth labels are unavailable, and instead we have only access to\nimperfect labels as the result of (potentially biased) human-made decisions.\nDespite being imperfect, historical decisions often contain some useful\ninformation on the unobserved true labels. In this paper, we focus on scenarios\nwhere only imperfect labels are available and propose a new fair ranking-based\ndecision system based on monotonic relationships between legitimate features\nand the outcome. Our approach is both intuitive and easy to implement, and thus\nparticularly suitable for adoption in real-world settings. More in detail, we\nintroduce a distance-based decision criterion, which incorporates useful\ninformation from historical decisions and accounts for unwanted correlation\nbetween protected and legitimate features. Through extensive experiments on\nsynthetic and real-world data, we show that our method is fair in the sense\nthat a) it assigns the desirable outcome to the most qualified individuals, and\nb) it removes the effect of stereotypes in decision-making, thereby\noutperforming traditional classification algorithms. Additionally, we are able\nto show theoretically that our method is consistent with a prominent concept of\nindividual fairness which states that \"similar individuals should be treated\nsimilarly.\"",
          "link": "http://arxiv.org/abs/2102.04565",
          "publishedOn": "2021-07-19T00:49:07.808Z",
          "wordCount": 688,
          "title": "A Ranking Approach to Fair Classification. (arXiv:2102.04565v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.03245",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jia-Qi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Shuguang Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_T/0/1/0/all/0/1\">Tao Zhuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_D/0/1/0/all/0/1\">De-Chuan Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1\">Xiaoyi Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_B/0/1/0/all/0/1\">Bin Tong</a>",
          "description": "Conversion rate (CVR) prediction is one of the most critical tasks for\ndigital display advertising. Commercial systems often require to update models\nin an online learning manner to catch up with the evolving data distribution.\nHowever, conversions usually do not happen immediately after a user click. This\nmay result in inaccurate labeling, which is called delayed feedback problem. In\nprevious studies, delayed feedback problem is handled either by waiting\npositive label for a long period of time, or by consuming the negative sample\non its arrival and then insert a positive duplicate when a conversion happens\nlater. Indeed, there is a trade-off between waiting for more accurate labels\nand utilizing fresh data, which is not considered in existing works. To strike\na balance in this trade-off, we propose Elapsed-Time Sampling Delayed Feedback\nModel (ES-DFM), which models the relationship between the observed conversion\ndistribution and the true conversion distribution. Then we optimize the\nexpectation of true conversion distribution via importance sampling under the\nelapsed-time sampling distribution. We further estimate the importance weight\nfor each instance, which is used as the weight of loss function in CVR\nprediction. To demonstrate the effectiveness of ES-DFM, we conduct extensive\nexperiments on a public data and a private industrial dataset. Experimental\nresults confirm that our method consistently outperforms the previous\nstate-of-the-art results.",
          "link": "http://arxiv.org/abs/2012.03245",
          "publishedOn": "2021-07-19T00:49:07.797Z",
          "wordCount": 713,
          "title": "Capturing Delayed Feedback in Conversion Rate Prediction via Elapsed-Time Sampling. (arXiv:2012.03245v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2106.11026",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yifeng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zicheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Pei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galindo_Torres_S/0/1/0/all/0/1\">S.A. Galindo-Torres</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Stan Z. Li</a>",
          "description": "A better understanding of dispersion in natural streams requires knowledge of\nlongitudinal dispersion coefficient(LDC). Various methods have been proposed\nfor predictions of LDC. Those studies can be grouped into three types:\nanalytical, statistical and ML-driven researches(Implicit and explicit).\nHowever, a comprehensive evaluation of them is still lacking. In this paper, we\nfirst present an in-depth analysis of those methods and find out their defects.\nThis is carried out on an extensive database composed of 660 samples of\nhydraulic and channel properties worldwide. The reliability and\nrepresentativeness of utilized data are enhanced through the deployment of the\nSubset Selection of Maximum Dissimilarity(SSMD) for testing set selection and\nthe Inter Quartile Range(IQR) for removal of the outlier. The evaluation\nreveals the rank of those methods as: ML-driven method > the statistical method\n> the analytical method. Whereas implicit ML-driven methods are black-boxes in\nnature, explicit ML-driven methods have more potential in prediction of LDC.\nBesides, overfitting is a universal problem in existing models. Those models\nalso suffer from a fixed parameter combination. To establish an interpretable\nmodel for LDC prediction with higher performance, we then design a novel\nsymbolic regression method called evolutionary symbolic regression\nnetwork(ESRN). It is a combination of genetic algorithms and neural networks.\nStrategies are introduced to avoid overfitting and explore more parameter\ncombinations. Results show that the ESRN model has superiorities over other\nexisting symbolic models in performance. The proposed model is suitable for\npractical engineering problems due to its advantage in low requirement of\nparameters (only w and U* are required). It can provide convincing solutions\nfor situations where the field test cannot be carried out or limited field\ninformation can be obtained.",
          "link": "http://arxiv.org/abs/2106.11026",
          "publishedOn": "2021-07-19T00:49:07.788Z",
          "wordCount": 788,
          "title": "A data-based comparative review and AI-driven symbolic model for longitudinal dispersion coefficient in natural streams. (arXiv:2106.11026v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.07863",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Sengupta_U/0/1/0/all/0/1\">Ushnish Sengupta</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Kontogiannis_A/0/1/0/all/0/1\">Alexandros Kontogiannis</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Juniper_M/0/1/0/all/0/1\">Matthew P. Juniper</a>",
          "description": "Magnetic resonance velocimetry (MRV) is a non-invasive experimental technique\nwidely used in medicine and engineering to measure the velocity field of a\nfluid. These measurements are dense but have a low signal-to-noise ratio (SNR).\nThe measurements can be de-noised by imposing physical constraints on the flow,\nwhich are encapsulated in governing equations for mass and momentum. Previous\nstudies have required the shape of the boundary (for example, a blood vessel)\nto be known a priori. This, however, requires a set of additional measurements,\nwhich can be expensive to obtain. In this paper, we present a physics-informed\nneural network that instead uses the noisy MRV data alone to simultaneously\ninfer the most likely boundary shape and de-noised velocity field. We achieve\nthis by training an auxiliary neural network that takes the value 1.0 within\nthe inferred domain of the governing PDE and 0.0 outside. This network is used\nto weight the PDE residual term in the loss function accordingly and implicitly\nlearns the geometry of the system. We test our algorithm by assimilating both\nsynthetic and real MRV measurements for flows that can be well modeled by the\nPoisson and Stokes equations. We find that we are able to reconstruct very\nnoisy (SNR = 2.5) MRV signals and recover the ground truth with low\nreconstruction errors of 3.7 - 7.5%. The simplicity and flexibility of our\nphysics-informed neural network approach can readily scale to assimilating MRV\ndata with complex 3D geometries, time-varying 4D data, or unknown parameters in\nthe physical model.",
          "link": "http://arxiv.org/abs/2107.07863",
          "publishedOn": "2021-07-19T00:49:07.736Z",
          "wordCount": 698,
          "title": "Simultaneous boundary shape estimation and velocity field de-noising in Magnetic Resonance Velocimetry using Physics-informed Neural Networks. (arXiv:2107.07863v1 [physics.flu-dyn])"
        },
        {
          "id": "http://arxiv.org/abs/2102.12353",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1\">Chaochao Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yuhuai Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hernandez_Lobato_J/0/1/0/all/0/1\">Jo&#x15b;e Miguel Hern&#xe1;ndez-Lobato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1\">Bernhard Sch&#xf6;lkopf</a>",
          "description": "Due to spurious correlations, machine learning systems often fail to\ngeneralize to environments whose distributions differ from the ones used at\ntraining time. Prior work addressing this, either explicitly or implicitly,\nattempted to find a data representation that has an invariant relationship with\nthe target. This is done by leveraging a diverse set of training environments\nto reduce the effect of spurious features and build an invariant predictor.\nHowever, these methods have generalization guarantees only when both data\nrepresentation and classifiers come from a linear model class. We propose\ninvariant Causal Representation Learning (iCaRL), an approach that enables\nout-of-distribution (OOD) generalization in the nonlinear setting (i.e.,\nnonlinear representations and nonlinear classifiers). It builds upon a\npractical and general assumption: the prior over the data representation (i.e.,\na set of latent variables encoding the data) given the target and the\nenvironment belongs to general exponential family distributions. Based on this,\nwe show that it is possible to identify the data representation up to simple\ntransformations. We also prove that all direct causes of the target can be\nfully discovered, which further enables us to obtain generalization guarantees\nin the nonlinear setting. Extensive experiments on both synthetic and\nreal-world datasets show that our approach outperforms a variety of baseline\nmethods. Finally, in the discussion, we further explore the aforementioned\nassumption and propose a more general hypothesis, called the Agnostic\nHypothesis: there exist a set of hidden causal factors affecting both inputs\nand outcomes. The Agnostic Hypothesis can provide a unifying view of machine\nlearning. More importantly, it can inspire a new direction to explore a general\ntheory for identifying hidden causal factors, which is key to enabling the OOD\ngeneralization guarantees.",
          "link": "http://arxiv.org/abs/2102.12353",
          "publishedOn": "2021-07-19T00:49:07.724Z",
          "wordCount": 752,
          "title": "Nonlinear Invariant Risk Minimization: A Causal Approach. (arXiv:2102.12353v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.03390",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Minhui Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1\">Shiqian Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_L/0/1/0/all/0/1\">Lifeng Lai</a>",
          "description": "Collecting and aggregating information from several probability measures or\nhistograms is a fundamental task in machine learning. One of the popular\nsolution methods for this task is to compute the barycenter of the probability\nmeasures under the Wasserstein metric. However, approximating the Wasserstein\nbarycenter is numerically challenging because of the curse of dimensionality.\nThis paper proposes the projection robust Wasserstein barycenter (PRWB) that\nhas the potential to mitigate the curse of dimensionality. Since PRWB is\nnumerically very challenging to solve, we further propose a relaxed PRWB\n(RPRWB) model, which is more tractable. The RPRWB projects the probability\nmeasures onto a lower-dimensional subspace that maximizes the Wasserstein\nbarycenter objective. The resulting problem is a max-min problem over the\nStiefel manifold. By combining the iterative Bregman projection algorithm and\nRiemannian optimization, we propose two new algorithms for computing the RPRWB.\nThe complexity of arithmetic operations of the proposed algorithms for\nobtaining an $\\epsilon$-stationary solution is analyzed. We incorporate the\nRPRWB into a discrete distribution clustering algorithm, and the numerical\nresults on real text datasets confirm that our RPRWB model helps improve the\nclustering performance significantly.",
          "link": "http://arxiv.org/abs/2102.03390",
          "publishedOn": "2021-07-19T00:49:07.718Z",
          "wordCount": 644,
          "title": "Projection Robust Wasserstein Barycenters. (arXiv:2102.03390v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.05199",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Minhui Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1\">Shiqian Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_L/0/1/0/all/0/1\">Lifeng Lai</a>",
          "description": "The Wasserstein distance has become increasingly important in machine\nlearning and deep learning. Despite its popularity, the Wasserstein distance is\nhard to approximate because of the curse of dimensionality. A recently proposed\napproach to alleviate the curse of dimensionality is to project the sampled\ndata from the high dimensional probability distribution onto a\nlower-dimensional subspace, and then compute the Wasserstein distance between\nthe projected data. However, this approach requires to solve a max-min problem\nover the Stiefel manifold, which is very challenging in practice. The only\nexisting work that solves this problem directly is the RGAS (Riemannian\nGradient Ascent with Sinkhorn Iteration) algorithm, which requires to solve an\nentropy-regularized optimal transport problem in each iteration, and thus can\nbe costly for large-scale problems. In this paper, we propose a Riemannian\nblock coordinate descent (RBCD) method to solve this problem, which is based on\na novel reformulation of the regularized max-min problem over the Stiefel\nmanifold. We show that the complexity of arithmetic operations for RBCD to\nobtain an $\\epsilon$-stationary point is $O(\\epsilon^{-3})$. This significantly\nimproves the corresponding complexity of RGAS, which is $O(\\epsilon^{-12})$.\nMoreover, our RBCD has very low per-iteration complexity, and hence is suitable\nfor large-scale problems. Numerical results on both synthetic and real datasets\ndemonstrate that our method is more efficient than existing methods, especially\nwhen the number of sampled data is very large.",
          "link": "http://arxiv.org/abs/2012.05199",
          "publishedOn": "2021-07-19T00:49:07.702Z",
          "wordCount": 720,
          "title": "A Riemannian Block Coordinate Descent Method for Computing the Projection Robust Wasserstein Distance. (arXiv:2012.05199v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.11048",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Traganitis_P/0/1/0/all/0/1\">Panagiotis A. Traganitis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giannakis_G/0/1/0/all/0/1\">Georgios B. Giannakis</a>",
          "description": "Crowdsourcing has emerged as a powerful paradigm for efficiently labeling\nlarge datasets and performing various learning tasks, by leveraging crowds of\nhuman annotators. When additional information is available about the data,\nsemi-supervised crowdsourcing approaches that enhance the aggregation of labels\nfrom human annotators are well motivated. This work deals with semi-supervised\ncrowdsourced classification, under two regimes of semi-supervision: a) label\nconstraints, that provide ground-truth labels for a subset of data; and b)\npotentially easier to obtain instance-level constraints, that indicate\nrelationships between pairs of data. Bayesian algorithms based on variational\ninference are developed for each regime, and their quantifiably improved\nperformance, compared to unsupervised crowdsourcing, is analytically and\nempirically validated on several crowdsourcing datasets.",
          "link": "http://arxiv.org/abs/2012.11048",
          "publishedOn": "2021-07-19T00:49:07.695Z",
          "wordCount": 574,
          "title": "Bayesian Crowdsourcing with Constraints. (arXiv:2012.11048v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.07421",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Koh_P/0/1/0/all/0/1\">Pang Wei Koh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sagawa_S/0/1/0/all/0/1\">Shiori Sagawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marklund_H/0/1/0/all/0/1\">Henrik Marklund</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1\">Sang Michael Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Marvin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balsubramani_A/0/1/0/all/0/1\">Akshay Balsubramani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1\">Weihua Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yasunaga_M/0/1/0/all/0/1\">Michihiro Yasunaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Phillips_R/0/1/0/all/0/1\">Richard Lanas Phillips</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_I/0/1/0/all/0/1\">Irena Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_T/0/1/0/all/0/1\">Tony Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+David_E/0/1/0/all/0/1\">Etienne David</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stavness_I/0/1/0/all/0/1\">Ian Stavness</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_W/0/1/0/all/0/1\">Wei Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Earnshaw_B/0/1/0/all/0/1\">Berton A. Earnshaw</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haque_I/0/1/0/all/0/1\">Imran S. Haque</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beery_S/0/1/0/all/0/1\">Sara Beery</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leskovec_J/0/1/0/all/0/1\">Jure Leskovec</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kundaje_A/0/1/0/all/0/1\">Anshul Kundaje</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pierson_E/0/1/0/all/0/1\">Emma Pierson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1\">Sergey Levine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1\">Chelsea Finn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1\">Percy Liang</a>",
          "description": "Distribution shifts -- where the training distribution differs from the test\ndistribution -- can substantially degrade the accuracy of machine learning (ML)\nsystems deployed in the wild. Despite their ubiquity in the real-world\ndeployments, these distribution shifts are under-represented in the datasets\nwidely used in the ML community today. To address this gap, we present WILDS, a\ncurated benchmark of 10 datasets reflecting a diverse range of distribution\nshifts that naturally arise in real-world applications, such as shifts across\nhospitals for tumor identification; across camera traps for wildlife\nmonitoring; and across time and location in satellite imaging and poverty\nmapping. On each dataset, we show that standard training yields substantially\nlower out-of-distribution than in-distribution performance. This gap remains\neven with models trained by existing methods for tackling distribution shifts,\nunderscoring the need for new methods for training models that are more robust\nto the types of distribution shifts that arise in practice. To facilitate\nmethod development, we provide an open-source package that automates dataset\nloading, contains default model architectures and hyperparameters, and\nstandardizes evaluations. Code and leaderboards are available at\nhttps://wilds.stanford.edu.",
          "link": "http://arxiv.org/abs/2012.07421",
          "publishedOn": "2021-07-19T00:49:07.662Z",
          "wordCount": 696,
          "title": "WILDS: A Benchmark of in-the-Wild Distribution Shifts. (arXiv:2012.07421v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.11524",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Likhomanenko_T/0/1/0/all/0/1\">Tatiana Likhomanenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1\">Qiantong Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kahn_J/0/1/0/all/0/1\">Jacob Kahn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Synnaeve_G/0/1/0/all/0/1\">Gabriel Synnaeve</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Collobert_R/0/1/0/all/0/1\">Ronan Collobert</a>",
          "description": "Recent results in end-to-end automatic speech recognition have demonstrated\nthe efficacy of pseudo-labeling for semi-supervised models trained both with\nConnectionist Temporal Classification (CTC) and Sequence-to-Sequence (seq2seq)\nlosses. Iterative Pseudo-Labeling (IPL), which continuously trains a single\nmodel using pseudo-labels iteratively re-generated as the model learns, has\nbeen shown to further improve performance in ASR. We improve upon the IPL\nalgorithm: as the model learns, we propose to iteratively re-generate\ntranscriptions with hard labels (the most probable tokens), that is, without a\nlanguage model. We call this approach Language-Model-Free IPL (slimIPL) and\ngive a resultant training setup for low-resource settings with CTC-based\nmodels. slimIPL features a dynamic cache for pseudo-labels which reduces\nsensitivity to changes in relabeling hyperparameters and results in improves\ntraining stability. slimIPL is also highly-efficient and requires 3.5-4x fewer\ncomputational resources to converge than other state-of-the-art\nsemi/self-supervised approaches. With only 10 hours of labeled audio, slimIPL\nis competitive with self-supervised approaches, and is state-of-the-art with\n100 hours of labeled audio without the use of a language model both at test\ntime and during pseudo-label generation.",
          "link": "http://arxiv.org/abs/2010.11524",
          "publishedOn": "2021-07-19T00:49:07.642Z",
          "wordCount": 654,
          "title": "SlimIPL: Language-Model-Free Iterative Pseudo-Labeling. (arXiv:2010.11524v4 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.07831",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chaudhuri_A/0/1/0/all/0/1\">Arpita Chaudhuri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samanta_D/0/1/0/all/0/1\">Debasis Samanta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarma_M/0/1/0/all/0/1\">Monalisa Sarma</a>",
          "description": "User intention which often changes dynamically is considered to be an\nimportant factor for modeling users in the design of recommendation systems.\nRecent studies are starting to focus on predicting user intention (what users\nwant) beyond user preference (what users like). In this work, a user intention\nmodel is proposed based on deep sequential topic analysis. The model predicts a\nuser's intention in terms of the topic of interest. The Hybrid Topic Model\n(HTM) comprising Latent Dirichlet Allocation (LDA) and Word2Vec is proposed to\nderive the topic of interest of users and the history of preferences. HTM finds\nthe true topics of papers estimating word-topic distribution which includes\nsyntactic and semantic correlations among words. Next, to model user intention,\na Long Short Term Memory (LSTM) based sequential deep learning model is\nproposed. This model takes into account temporal context, namely the time\ndifference between clicks of two consecutive papers seen by a user. Extensive\nexperiments with the real-world research paper dataset indicate that the\nproposed approach significantly outperforms the state-of-the-art methods.\nFurther, the proposed approach introduces a new road map to model a user\nactivity suitable for the design of a research paper recommendation system.",
          "link": "http://arxiv.org/abs/2107.07831",
          "publishedOn": "2021-07-19T00:49:07.625Z",
          "wordCount": 630,
          "title": "Modeling User Behaviour in Research Paper Recommendation System. (arXiv:2107.07831v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2010.08853",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yehudai_G/0/1/0/all/0/1\">Gilad Yehudai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fetaya_E/0/1/0/all/0/1\">Ethan Fetaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meirom_E/0/1/0/all/0/1\">Eli Meirom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chechik_G/0/1/0/all/0/1\">Gal Chechik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maron_H/0/1/0/all/0/1\">Haggai Maron</a>",
          "description": "Graph neural networks (GNNs) can process graphs of different sizes, but their\nability to generalize across sizes, specifically from small to large graphs, is\nstill not well understood. In this paper, we identify an important type of data\nwhere generalization from small to large graphs is challenging: graph\ndistributions for which the local structure depends on the graph size. This\neffect occurs in multiple important graph learning domains, including social\nand biological networks. We first prove that when there is a difference between\nthe local structures, GNNs are not guaranteed to generalize across sizes: there\nare \"bad\" global minima that do well on small graphs but fail on large graphs.\nWe then study the size-generalization problem empirically and demonstrate that\nwhen there is a discrepancy in local structure, GNNs tend to converge to\nnon-generalizing solutions. Finally, we suggest two approaches for improving\nsize generalization, motivated by our findings. Notably, we propose a novel\nSelf-Supervised Learning (SSL) task aimed at learning meaningful\nrepresentations of local structures that appear in large graphs. Our SSL task\nimproves classification accuracy on several popular datasets.",
          "link": "http://arxiv.org/abs/2010.08853",
          "publishedOn": "2021-07-19T00:49:07.610Z",
          "wordCount": 674,
          "title": "From Local Structures to Size Generalization in Graph Neural Networks. (arXiv:2010.08853v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2004.13688",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Desai_S/0/1/0/all/0/1\">Shaan Desai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mattheakis_M/0/1/0/all/0/1\">Marios Mattheakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roberts_S/0/1/0/all/0/1\">Stephen Roberts</a>",
          "description": "Recent advances show that neural networks embedded with physics-informed\npriors significantly outperform vanilla neural networks in learning and\npredicting the long term dynamics of complex physical systems from noisy data.\nDespite this success, there has only been a limited study on how to optimally\ncombine physics priors to improve predictive performance. To tackle this\nproblem we unpack and generalize recent innovations into individual inductive\nbias segments. As such, we are able to systematically investigate all possible\ncombinations of inductive biases of which existing methods are a natural\nsubset. Using this framework we introduce Variational Integrator Graph Networks\n- a novel method that unifies the strengths of existing approaches by combining\nan energy constraint, high-order symplectic variational integrators, and graph\nneural networks. We demonstrate, across an extensive ablation, that the\nproposed unifying framework outperforms existing methods, for data-efficient\nlearning and in predictive accuracy, across both single and many-body problems\nstudied in recent literature. We empirically show that the improvements arise\nbecause high order variational integrators combined with a potential energy\nconstraint induce coupled learning of generalized position and momentum updates\nwhich can be formalized via the Partitioned Runge-Kutta method.",
          "link": "http://arxiv.org/abs/2004.13688",
          "publishedOn": "2021-07-19T00:49:07.603Z",
          "wordCount": 669,
          "title": "Variational Integrator Graph Networks for Learning Energy Conserving Dynamical Systems. (arXiv:2004.13688v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.07757",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Musso_D/0/1/0/all/0/1\">Daniele Musso</a>",
          "description": "Local entropic loss functions provide a versatile framework to define\narchitecture-aware regularization procedures. Besides the possibility of being\nanisotropic in the synaptic space, the local entropic smoothening of the loss\nfunction can vary during training, thus yielding a tunable model complexity. A\nscoping protocol where the regularization is strong in the early-stage of the\ntraining and then fades progressively away constitutes an alternative to\nstandard initialization procedures for deep convolutional neural networks,\nnonetheless, it has wider applicability. We analyze anisotropic, local entropic\nsmoothenings in the language of statistical physics and information theory,\nproviding insight into both their interpretation and workings. We comment some\naspects related to the physics of renormalization and the spacetime structure\nof convolutional networks.",
          "link": "http://arxiv.org/abs/2107.07757",
          "publishedOn": "2021-07-19T00:49:07.595Z",
          "wordCount": 563,
          "title": "Entropic alternatives to initialization. (arXiv:2107.07757v1 [cond-mat.dis-nn])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07684",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ishii_Y/0/1/0/all/0/1\">Yasunori Ishii</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamashita_T/0/1/0/all/0/1\">Takayoshi Yamashita</a>",
          "description": "It is difficult to collect data on a large scale in a monocular depth\nestimation because the task requires the simultaneous acquisition of RGB images\nand depths. Data augmentation is thus important to this task. However, there\nhas been little research on data augmentation for tasks such as monocular depth\nestimation, where the transformation is performed pixel by pixel. In this\npaper, we propose a data augmentation method, called CutDepth. In CutDepth,\npart of the depth is pasted onto an input image during training. The method\nextends variations data without destroying edge features. Experiments\nobjectively and subjectively show that the proposed method outperforms\nconventional methods of data augmentation. The estimation accuracy is improved\nwith CutDepth even though there are few training data at long distances.",
          "link": "http://arxiv.org/abs/2107.07684",
          "publishedOn": "2021-07-19T00:49:07.581Z",
          "wordCount": 561,
          "title": "CutDepth:Edge-aware Data Augmentation in Depth Estimation. (arXiv:2107.07684v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07696",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chung_L/0/1/0/all/0/1\">Long Kiu Chung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_A/0/1/0/all/0/1\">Adam Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Knowles_D/0/1/0/all/0/1\">Derek Knowles</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kousik_S/0/1/0/all/0/1\">Shreyas Kousik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_G/0/1/0/all/0/1\">Grace X. Gao</a>",
          "description": "Neural networks have recently become popular for a wide variety of uses, but\nhave seen limited application in safety-critical domains such as robotics near\nand around humans. This is because it remains an open challenge to train a\nneural network to obey safety constraints. Most existing safety-related methods\nonly seek to verify that already-trained networks obey constraints, requiring\nalternating training and verification. Instead, this work proposes a\nconstrained method to simultaneously train and verify a feedforward neural\nnetwork with rectified linear unit (ReLU) nonlinearities. Constraints are\nenforced by computing the network's output-space reachable set and ensuring\nthat it does not intersect with unsafe sets; training is achieved by\nformulating a novel collision-check loss function between the reachable set and\nunsafe portions of the output space. The reachable and unsafe sets are\nrepresented by constrained zonotopes, a convex polytope representation that\nenables differentiable collision checking. The proposed method is demonstrated\nsuccessfully on a network with one nonlinearity layer and approximately 50\nparameters.",
          "link": "http://arxiv.org/abs/2107.07696",
          "publishedOn": "2021-07-19T00:49:07.574Z",
          "wordCount": 608,
          "title": "Constrained Feedforward Neural Network Training via Reachability Analysis. (arXiv:2107.07696v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2106.00628",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Frasch_M/0/1/0/all/0/1\">Martin G. Frasch</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Strong_S/0/1/0/all/0/1\">Shadrian B. Strong</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Nilosek_D/0/1/0/all/0/1\">David Nilosek</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Leaverton_J/0/1/0/all/0/1\">Joshua Leaverton</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Schifrin_B/0/1/0/all/0/1\">Barry S. Schifrin</a>",
          "description": "Despite broad application during labor and delivery, there remains\nconsiderable debate about the value of electronic fetal monitoring (EFM). EFM\nincludes the surveillance of the fetal heart rate (FHR) patterns in conjunction\nwith the maternal uterine contractions providing a wealth of data about fetal\nbehavior and the threat of diminished oxygenation and perfusion. Adverse\noutcomes universally associate a fetal injury with the failure to timely\nrespond to FHR pattern information. Historically, the EFM data, stored\ndigitally, are available only as rasterized pdf images for contemporary or\nhistorical discussion and examination. In reality, however, they are rarely\nreviewed systematically. Using a unique archive of EFM collected over 50 years\nof practice in conjunction with adverse outcomes, we present a deep learning\nframework for training and detection of incipient or past fetal injury. We\nreport 94% accuracy in identifying early, preventable fetal injury intrapartum.\nThis framework is suited for automating an early warning and decision support\nsystem for maintaining fetal well-being during the stresses of labor.\nUltimately, such a system could enable a physician to timely respond during\nlabor and prevent adverse outcomes. When adverse outcomes cannot be avoided,\nthey can provide guidance to the early neuroprotective treatment of the\nnewborn.",
          "link": "http://arxiv.org/abs/2106.00628",
          "publishedOn": "2021-07-19T00:49:07.517Z",
          "wordCount": 666,
          "title": "Detection of preventable fetal distress during labor from scanned cardiotocogram tracings using deep learning. (arXiv:2106.00628v2 [q-bio.QM] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.00589",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Silver_T/0/1/0/all/0/1\">Tom Silver</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chitnis_R/0/1/0/all/0/1\">Rohan Chitnis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1\">Joshua Tenenbaum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaelbling_L/0/1/0/all/0/1\">Leslie Pack Kaelbling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lozano_Perez_T/0/1/0/all/0/1\">Tomas Lozano-Perez</a>",
          "description": "Robotic planning problems in hybrid state and action spaces can be solved by\nintegrated task and motion planners (TAMP) that handle the complex interaction\nbetween motion-level decisions and task-level plan feasibility. TAMP approaches\nrely on domain-specific symbolic operators to guide the task-level search,\nmaking planning efficient. In this work, we formalize and study the problem of\noperator learning for TAMP. Central to this study is the view that operators\ndefine a lossy abstraction of the transition model of a domain. We then propose\na bottom-up relational learning method for operator learning and show how the\nlearned operators can be used for planning in a TAMP system. Experimentally, we\nprovide results in three domains, including long-horizon robotic planning\ntasks. We find our approach to substantially outperform several baselines,\nincluding three graph neural network-based model-free approaches from the\nrecent literature. Video: https://youtu.be/iVfpX9BpBRo Code:\nhttps://git.io/JCT0g",
          "link": "http://arxiv.org/abs/2103.00589",
          "publishedOn": "2021-07-19T00:49:07.500Z",
          "wordCount": 619,
          "title": "Learning Symbolic Operators for Task and Motion Planning. (arXiv:2103.00589v2 [cs.RO] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.07886",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Trauble_F/0/1/0/all/0/1\">Frederik Tr&#xe4;uble</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Creager_E/0/1/0/all/0/1\">Elliot Creager</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kilbertus_N/0/1/0/all/0/1\">Niki Kilbertus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Locatello_F/0/1/0/all/0/1\">Francesco Locatello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dittadi_A/0/1/0/all/0/1\">Andrea Dittadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_A/0/1/0/all/0/1\">Anirudh Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1\">Bernhard Sch&#xf6;lkopf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bauer_S/0/1/0/all/0/1\">Stefan Bauer</a>",
          "description": "The focus of disentanglement approaches has been on identifying independent\nfactors of variation in data. However, the causal variables underlying\nreal-world observations are often not statistically independent. In this work,\nwe bridge the gap to real-world scenarios by analyzing the behavior of the most\nprominent disentanglement approaches on correlated data in a large-scale\nempirical study (including 4260 models). We show and quantify that\nsystematically induced correlations in the dataset are being learned and\nreflected in the latent representations, which has implications for downstream\napplications of disentanglement such as fairness. We also demonstrate how to\nresolve these latent correlations, either using weak supervision during\ntraining or by post-hoc correcting a pre-trained model with a small number of\nlabels.",
          "link": "http://arxiv.org/abs/2006.07886",
          "publishedOn": "2021-07-19T00:49:07.484Z",
          "wordCount": 610,
          "title": "On Disentangled Representations Learned From Correlated Data. (arXiv:2006.07886v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.07634",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Higuchi_T/0/1/0/all/0/1\">Takuya Higuchi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gupta_A/0/1/0/all/0/1\">Anmol Gupta</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dhir_C/0/1/0/all/0/1\">Chandra Dhir</a>",
          "description": "Keyword spotting (KWS) is an important technique for speech applications,\nwhich enables users to activate devices by speaking a keyword phrase. Although\na phoneme classifier can be used for KWS, exploiting a large amount of\ntranscribed data for automatic speech recognition (ASR), there is a mismatch\nbetween the training criterion (phoneme recognition) and the target task (KWS).\nRecently, multi-task learning has been applied to KWS to exploit both ASR and\nKWS training data. In this approach, an output of an acoustic model is split\ninto two branches for the two tasks, one for phoneme transcription trained with\nthe ASR data and one for keyword classification trained with the KWS data. In\nthis paper, we introduce a cross attention decoder in the multi-task learning\nframework. Unlike the conventional multi-task learning approach with the simple\nsplit of the output layer, the cross attention decoder summarizes information\nfrom a phonetic encoder by performing cross attention between the encoder\noutputs and a trainable query sequence to predict a confidence score for the\nKWS task. Experimental results on KWS tasks show that the proposed approach\noutperformed the conventional multi-task learning with split branches and a\nbi-directional long short-team memory decoder by 12% on average.",
          "link": "http://arxiv.org/abs/2107.07634",
          "publishedOn": "2021-07-19T00:49:07.478Z",
          "wordCount": 652,
          "title": "Multi-task Learning with Cross Attention for Keyword Spotting. (arXiv:2107.07634v1 [eess.AS])"
        },
        {
          "id": "http://arxiv.org/abs/2102.05073",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Mikuni_V/0/1/0/all/0/1\">Vinicius Mikuni</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Canelli_F/0/1/0/all/0/1\">Florencia Canelli</a>",
          "description": "Methods for processing point cloud information have seen a great success in\ncollider physics applications. One recent breakthrough in machine learning is\nthe usage of Transformer networks to learn semantic relationships between\nsequences in language processing. In this work, we apply a modified Transformer\nnetwork called Point Cloud Transformer as a method to incorporate the\nadvantages of the Transformer architecture to an unordered set of particles\nresulting from collision events. To compare the performance with other\nstrategies, we study jet-tagging applications for highly-boosted particles.",
          "link": "http://arxiv.org/abs/2102.05073",
          "publishedOn": "2021-07-19T00:49:07.471Z",
          "wordCount": 559,
          "title": "Point Cloud Transformers applied to Collider Physics. (arXiv:2102.05073v2 [physics.data-an] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.07402",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sungyeop Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jo_J/0/1/0/all/0/1\">Junghyo Jo</a>",
          "description": "The outstanding performance of deep learning in various fields has been a\nfundamental query, which can be potentially examined using information theory\nthat interprets the learning process as the transmission and compression of\ninformation. Information plane analyses of the mutual information between the\ninput-hidden-output layers demonstrated two distinct learning phases of fitting\nand compression. It is debatable if the compression phase is necessary to\ngeneralize the input-output relations extracted from training data. In this\nstudy, we investigated this through experiments with various species of\nautoencoders and evaluated their information processing phase with an accurate\nkernel-based estimator of mutual information. Given sufficient training data,\nvanilla autoencoders demonstrated the compression phase, which was amplified\nafter imposing sparsity regularization for hidden activities. However, we found\nthat the compression phase is not universally observed in different species of\nautoencoders, including variational autoencoders, that have special constraints\non network weights or manifold of hidden space. These types of autoencoders\nexhibited perfect generalization ability for test data without requiring the\ncompression phase. Thus, we conclude that the compression phase is not\nnecessary for generalization in representation learning.",
          "link": "http://arxiv.org/abs/2102.07402",
          "publishedOn": "2021-07-19T00:49:07.466Z",
          "wordCount": 633,
          "title": "Information flows of diverse autoencoders. (arXiv:2102.07402v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.07706",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chaojian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wuyang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1\">Yuchen Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tianlong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1\">Yonggan Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhangyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yingyan Lin</a>",
          "description": "Semantic segmentation for scene understanding is nowadays widely demanded,\nraising significant challenges for the algorithm efficiency, especially its\napplications on resource-limited platforms. Current segmentation models are\ntrained and evaluated on massive high-resolution scene images (\"data level\")\nand suffer from the expensive computation arising from the required multi-scale\naggregation(\"network level\"). In both folds, the computational and energy costs\nin training and inference are notable due to the often desired large input\nresolutions and heavy computational burden of segmentation models. To this end,\nwe propose DANCE, general automated DAta-Network Co-optimization for Efficient\nsegmentation model training and inference. Distinct from existing efficient\nsegmentation approaches that focus merely on light-weight network design, DANCE\ndistinguishes itself as an automated simultaneous data-network co-optimization\nvia both input data manipulation and network architecture slimming.\nSpecifically, DANCE integrates automated data slimming which adaptively\ndownsamples/drops input images and controls their corresponding contribution to\nthe training loss guided by the images' spatial complexity. Such a downsampling\noperation, in addition to slimming down the cost associated with the input size\ndirectly, also shrinks the dynamic range of input object and context scales,\ntherefore motivating us to also adaptively slim the network to match the\ndownsampled data. Extensive experiments and ablating studies (on four SOTA\nsegmentation models with three popular segmentation datasets under two training\nsettings) demonstrate that DANCE can achieve \"all-win\" towards efficient\nsegmentation(reduced training cost, less expensive inference, and better mean\nIntersection-over-Union (mIoU)).",
          "link": "http://arxiv.org/abs/2107.07706",
          "publishedOn": "2021-07-19T00:49:07.450Z",
          "wordCount": 687,
          "title": "DANCE: DAta-Network Co-optimization for Efficient Segmentation Model Training and Inference. (arXiv:2107.07706v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08028",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Berg_J/0/1/0/all/0/1\">Jan Berg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drossos_K/0/1/0/all/0/1\">Konstantinos Drossos</a>",
          "description": "Automated audio captioning (AAC) is the task of automatically creating\ntextual descriptions (i.e. captions) for the contents of a general audio\nsignal. Most AAC methods are using existing datasets to optimize and/or\nevaluate upon. Given the limited information held by the AAC datasets, it is\nvery likely that AAC methods learn only the information contained in the\nutilized datasets. In this paper we present a first approach for continuously\nadapting an AAC method to new information, using a continual learning method.\nIn our scenario, a pre-optimized AAC method is used for some unseen general\naudio signals and can update its parameters in order to adapt to the new\ninformation, given a new reference caption. We evaluate our method using a\nfreely available, pre-optimized AAC method and two freely available AAC\ndatasets. We compare our proposed method with three scenarios, two of training\non one of the datasets and evaluating on the other and a third of training on\none dataset and fine-tuning on the other. Obtained results show that our method\nachieves a good balance between distilling new knowledge and not forgetting the\nprevious one.",
          "link": "http://arxiv.org/abs/2107.08028",
          "publishedOn": "2021-07-19T00:49:07.440Z",
          "wordCount": 628,
          "title": "Continual Learning for Automated Audio Captioning Using The Learning Without Forgetting Approach. (arXiv:2107.08028v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2010.04029",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qu_M/0/1/0/all/0/1\">Meng Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Junkun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xhonneux_L/0/1/0/all/0/1\">Louis-Pascal Xhonneux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1\">Yoshua Bengio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jian Tang</a>",
          "description": "This paper studies learning logic rules for reasoning on knowledge graphs.\nLogic rules provide interpretable explanations when used for prediction as well\nas being able to generalize to other tasks, and hence are critical to learn.\nExisting methods either suffer from the problem of searching in a large search\nspace (e.g., neural logic programming) or ineffective optimization due to\nsparse rewards (e.g., techniques based on reinforcement learning). To address\nthese limitations, this paper proposes a probabilistic model called RNNLogic.\nRNNLogic treats logic rules as a latent variable, and simultaneously trains a\nrule generator as well as a reasoning predictor with logic rules. We develop an\nEM-based algorithm for optimization. In each iteration, the reasoning predictor\nis first updated to explore some generated logic rules for reasoning. Then in\nthe E-step, we select a set of high-quality rules from all generated rules with\nboth the rule generator and reasoning predictor via posterior inference; and in\nthe M-step, the rule generator is updated with the rules selected in the\nE-step. Experiments on four datasets prove the effectiveness of RNNLogic.",
          "link": "http://arxiv.org/abs/2010.04029",
          "publishedOn": "2021-07-19T00:49:07.391Z",
          "wordCount": 647,
          "title": "RNNLogic: Learning Logic Rules for Reasoning on Knowledge Graphs. (arXiv:2010.04029v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1809.09910",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fanghui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_L/0/1/0/all/0/1\">Lei Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xiaolin Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jie Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suykens_J/0/1/0/all/0/1\">Johan A.K. Suykens</a>",
          "description": "This paper generalizes regularized regression problems in a hyper-reproducing\nkernel Hilbert space (hyper-RKHS), illustrates its utility for kernel learning\nand out-of-sample extensions, and proves asymptotic convergence results for the\nintroduced regression models in an approximation theory view. Algorithmically,\nwe consider two regularized regression models with bivariate forms in this\nspace, including kernel ridge regression (KRR) and support vector regression\n(SVR) endowed with hyper-RKHS, and further combine divide-and-conquer with\nNystr\\\"{o}m approximation for scalability in large sample cases. This framework\nis general: the underlying kernel is learned from a broad class, and can be\npositive definite or not, which adapts to various requirements in kernel\nlearning. Theoretically, we study the convergence behavior of regularized\nregression algorithms in hyper-RKHS and derive the learning rates, which goes\nbeyond the classical analysis on RKHS due to the non-trivial independence of\npairwise samples and the characterisation of hyper-RKHS. Experimentally,\nresults on several benchmarks suggest that the employed framework is able to\nlearn a general kernel function form an arbitrary similarity matrix, and thus\nachieves a satisfactory performance on classification tasks.",
          "link": "http://arxiv.org/abs/1809.09910",
          "publishedOn": "2021-07-19T00:49:07.386Z",
          "wordCount": 656,
          "title": "Generalization Properties of hyper-RKHS and its Applications. (arXiv:1809.09910v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08031",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Achaji_L/0/1/0/all/0/1\">Lina Achaji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moreau_J/0/1/0/all/0/1\">Julien Moreau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fouqueray_T/0/1/0/all/0/1\">Thibault Fouqueray</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aioun_F/0/1/0/all/0/1\">Francois Aioun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Charpillet_F/0/1/0/all/0/1\">Francois Charpillet</a>",
          "description": "The human driver is no longer the only one concerned with the complexity of\nthe driving scenarios. Autonomous vehicles (AV) are similarly becoming involved\nin the process. Nowadays, the development of AV in urban places underpins\nessential safety concerns for vulnerable road users (VRUs) such as pedestrians.\nTherefore, to make the roads safer, it is critical to classify and predict\ntheir future behavior. In this paper, we present a framework based on multiple\nvariations of the Transformer models to reason attentively about the dynamic\nevolution of the pedestrians' past trajectory and predict its future actions of\ncrossing or not crossing the street. We proved that using only bounding boxes\nas input to our model can outperform the previous state-of-the-art models and\nreach a prediction accuracy of 91 % and an F1-score of 0.83 on the PIE dataset\nup to two seconds ahead in the future. In addition, we introduced a large-size\nsimulated dataset (CP2A) using CARLA for action prediction. Our model has\nsimilarly reached high accuracy (91 %) and F1-score (0.91) on this dataset.\nInterestingly, we showed that pre-training our Transformer model on the\nsimulated dataset and then fine-tuning it on the real dataset can be very\neffective for the action prediction task.",
          "link": "http://arxiv.org/abs/2107.08031",
          "publishedOn": "2021-07-19T00:49:07.373Z",
          "wordCount": 656,
          "title": "Is attention to bounding boxes all you need for pedestrian action prediction?. (arXiv:2107.08031v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07999",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Choromanski_K/0/1/0/all/0/1\">Krzysztof Choromanski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Han Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Haoxian Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parker_Holder_J/0/1/0/all/0/1\">Jack Parker-Holder</a>",
          "description": "We introduce a new class of graph neural networks (GNNs), by combining\nseveral concepts that were so far studied independently - graph kernels,\nattention-based networks with structural priors and more recently, efficient\nTransformers architectures applying small memory footprint implicit attention\nmethods via low rank decomposition techniques. The goal of the paper is\ntwofold. Proposed by us Graph Kernel Attention Transformers (or GKATs) are much\nmore expressive than SOTA GNNs as capable of modeling longer-range dependencies\nwithin a single layer. Consequently, they can use more shallow architecture\ndesign. Furthermore, GKAT attention layers scale linearly rather than\nquadratically in the number of nodes of the input graphs, even when those\ngraphs are dense, requiring less compute than their regular graph attention\ncounterparts. They achieve it by applying new classes of graph kernels\nadmitting random feature map decomposition via random walks on graphs. As a\nbyproduct of the introduced techniques, we obtain a new class of learnable\ngraph sketches, called graphots, compactly encoding topological graph\nproperties as well as nodes' features. We conducted exhaustive empirical\ncomparison of our method with nine different GNN classes on tasks ranging from\nmotif detection through social network classification to bioinformatics\nchallenges, showing consistent gains coming from GKATs.",
          "link": "http://arxiv.org/abs/2107.07999",
          "publishedOn": "2021-07-19T00:49:07.330Z",
          "wordCount": 630,
          "title": "Graph Kernel Attention Transformers. (arXiv:2107.07999v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08027",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khan_T/0/1/0/all/0/1\">Tanveer Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Michalas_A/0/1/0/all/0/1\">Antonis Michalas</a>",
          "description": "Social networking and micro-blogging services, such as Twitter, play an\nimportant role in sharing digital information. Despite the popularity and\nusefulness of social media, there have been many instances where corrupted\nusers found ways to abuse it, as for instance, through raising or lowering\nuser's credibility. As a result, while social media facilitates an\nunprecedented ease of access to information, it also introduces a new challenge\n- that of ascertaining the credibility of shared information. Currently, there\nis no automated way of determining which news or users are credible and which\nare not. Hence, establishing a system that can measure the social media user's\ncredibility has become an issue of great importance. Assigning a credibility\nscore to a user has piqued the interest of not only the research community but\nalso most of the big players on both sides - such as Facebook, on the side of\nindustry, and political parties on the societal one. In this work, we created a\nmodel which, we hope, will ultimately facilitate and support the increase of\ntrust in the social network communities. Our model collected data and analysed\nthe behaviour of~50,000 politicians on Twitter. Influence score, based on\nseveral chosen features, was assigned to each evaluated user. Further, we\nclassified the political Twitter users as either trusted or untrusted using\nrandom forest, multilayer perceptron, and support vector machine. An active\nlearning model was used to classify any unlabelled ambiguous records from our\ndataset. Finally, to measure the performance of the proposed model, we used\nprecision, recall, F1 score, and accuracy as the main evaluation metrics.",
          "link": "http://arxiv.org/abs/2107.08027",
          "publishedOn": "2021-07-19T00:49:07.323Z",
          "wordCount": 704,
          "title": "SOK: Seeing and Believing: Evaluating the Trustworthiness of Twitter Users. (arXiv:2107.08027v1 [cs.SI])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07983",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhi-Gang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Whatmough_P/0/1/0/all/0/1\">Paul N. Whatmough</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yuhao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mattina_M/0/1/0/all/0/1\">Matthew Mattina</a>",
          "description": "Exploiting sparsity is a key technique in accelerating quantized\nconvolutional neural network (CNN) inference on mobile devices. Prior sparse\nCNN accelerators largely exploit un-structured sparsity and achieve significant\nspeedups. Due to the unbounded, largely unpredictable sparsity patterns,\nhowever, exploiting unstructured sparsity requires complicated hardware design\nwith significant energy and area overhead, which is particularly detrimental to\nmobile/IoT inference scenarios where energy and area efficiency are crucial. We\npropose to exploit structured sparsity, more specifically, Density Bound Block\n(DBB) sparsity for both weights and activations. DBB block tensors bound the\nmaximum number of non-zeros per block. DBB thus exposes statically predictable\nsparsity patterns that enable lean sparsity-exploiting hardware. We propose new\nhardware primitives to implement DBB sparsity for (static) weights and\n(dynamic) activations, respectively, with very low overheads. Building on top\nof the primitives, we describe S2TA, a systolic array-based CNN accelerator\nthat exploits joint weight and activation DBB sparsity and new dimensions of\ndata reuse unavailable on the traditional systolic array. S2TA in 16nm achieves\nmore than 2x speedup and energy reduction compared to a strong baseline of a\nsystolic array with zero-value clock gating, over five popular CNN benchmarks.\nCompared to two recent non-systolic sparse accelerators, Eyeriss v2 (65nm) and\nSparTen (45nm), S2TA in 65nm uses about 2.2x and 3.1x less energy per\ninference, respectively.",
          "link": "http://arxiv.org/abs/2107.07983",
          "publishedOn": "2021-07-19T00:49:07.318Z",
          "wordCount": 652,
          "title": "S2TA: Exploiting Structured Sparsity for Energy-Efficient Mobile CNN Acceleration. (arXiv:2107.07983v1 [cs.AR])"
        },
        {
          "id": "http://arxiv.org/abs/2004.02653",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sigrist_F/0/1/0/all/0/1\">Fabio Sigrist</a>",
          "description": "We introduce a novel way to combine boosting with Gaussian process and mixed\neffects models. This allows for relaxing, first, the linearity assumption for\nthe mean function in Gaussian process and grouped random effects models in a\nflexible non-parametric way and, second, the independence assumption made in\nmost boosting algorithms. The former is advantageous for predictive accuracy\nand for avoiding model misspecifications. The latter is important for more\nefficient learning of the mean function and for obtaining probabilistic\npredictions. In addition, we present an extension that scales to large data\nusing a Vecchia approximation for the Gaussian process model relying on novel\nresults for covariance parameter inference. We obtain increased predictive\naccuracy compared to existing approaches on several simulated and real-world\ndata sets.",
          "link": "http://arxiv.org/abs/2004.02653",
          "publishedOn": "2021-07-19T00:49:07.312Z",
          "wordCount": 583,
          "title": "Gaussian Process Boosting. (arXiv:2004.02653v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2107.08013",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Miles_C/0/1/0/all/0/1\">Cole Miles</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Carbone_M/0/1/0/all/0/1\">Matthew R. Carbone</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Sturm_E/0/1/0/all/0/1\">Erica J. Sturm</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Lu_D/0/1/0/all/0/1\">Deyu Lu</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Weichselbaum_A/0/1/0/all/0/1\">Andreas Weichselbaum</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Barros_K/0/1/0/all/0/1\">Kipton Barros</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Konik_R/0/1/0/all/0/1\">Robert M. Konik</a>",
          "description": "We employ variational autoencoders to extract physical insight from a dataset\nof one-particle Anderson impurity model spectral functions. Autoencoders are\ntrained to find a low-dimensional, latent space representation that faithfully\ncharacterizes each element of the training set, as measured by a reconstruction\nerror. Variational autoencoders, a probabilistic generalization of standard\nautoencoders, further condition the learned latent space to promote highly\ninterpretable features. In our study, we find that the learned latent space\ncomponents strongly correlate with well known, but nontrivial, parameters that\ncharacterize emergent behaviors in the Anderson impurity model. In particular,\none latent space component correlates with particle-hole asymmetry, while\nanother is in near one-to-one correspondence with the Kondo temperature, a\ndynamically generated low-energy scale in the impurity model. With symbolic\nregression, we model this component as a function of bare physical input\nparameters and \"rediscover\" the non-perturbative formula for the Kondo\ntemperature. The machine learning pipeline we develop opens opportunities to\ndiscover new domain knowledge in other physical systems.",
          "link": "http://arxiv.org/abs/2107.08013",
          "publishedOn": "2021-07-19T00:49:07.294Z",
          "wordCount": 623,
          "title": "Machine-learning Kondo physics using variational autoencoders. (arXiv:2107.08013v1 [cond-mat.str-el])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07988",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liang_H/0/1/0/all/0/1\">Hao Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1\">Lulan Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_G/0/1/0/all/0/1\">Guikang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raj_B/0/1/0/all/0/1\">Bhiksha Raj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1\">Rita Singh</a>",
          "description": "Multiple studies in the past have shown that there is a strong correlation\nbetween human vocal characteristics and facial features. However, existing\napproaches generate faces simply from voice, without exploring the set of\nfeatures that contribute to these observed correlations. A computational\nmethodology to explore this can be devised by rephrasing the question to: \"how\nmuch would a target face have to change in order to be perceived as the\noriginator of a source voice?\" With this in perspective, we propose a framework\nto morph a target face in response to a given voice in a way that facial\nfeatures are implicitly guided by learned voice-face correlation in this paper.\nOur framework includes a guided autoencoder that converts one face to another,\ncontrolled by a unique model-conditioning component called a gating controller\nwhich modifies the reconstructed face based on input voice recordings. We\nevaluate the framework on VoxCelab and VGGFace datasets through human subjects\nand face retrieval. Various experiments demonstrate the effectiveness of our\nproposed model.",
          "link": "http://arxiv.org/abs/2107.07988",
          "publishedOn": "2021-07-19T00:49:07.288Z",
          "wordCount": 621,
          "title": "Controlled AutoEncoders to Generate Faces from Voices. (arXiv:2107.07988v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08001",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Gabrie_M/0/1/0/all/0/1\">Marylou Gabri&#xe9;</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rotskoff_G/0/1/0/all/0/1\">Grant M. Rotskoff</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vanden_Eijnden_E/0/1/0/all/0/1\">Eric Vanden-Eijnden</a>",
          "description": "Normalizing flows can generate complex target distributions and thus show\npromise in many applications in Bayesian statistics as an alternative or\ncomplement to MCMC for sampling posteriors. Since no data set from the target\nposterior distribution is available beforehand, the flow is typically trained\nusing the reverse Kullback-Leibler (KL) divergence that only requires samples\nfrom a base distribution. This strategy may perform poorly when the posterior\nis complicated and hard to sample with an untrained normalizing flow. Here we\nexplore a distinct training strategy, using the direct KL divergence as loss,\nin which samples from the posterior are generated by (i) assisting a local MCMC\nalgorithm on the posterior with a normalizing flow to accelerate its mixing\nrate and (ii) using the data generated this way to train the flow. The method\nonly requires a limited amount of \\textit{a~priori} input about the posterior,\nand can be used to estimate the evidence required for model validation, as we\nillustrate on examples.",
          "link": "http://arxiv.org/abs/2107.08001",
          "publishedOn": "2021-07-19T00:49:07.282Z",
          "wordCount": 613,
          "title": "Efficient Bayesian Sampling Using Normalizing Flows to Assist Markov Chain Monte Carlo Methods. (arXiv:2107.08001v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07886",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Jiang_H/0/1/0/all/0/1\">Haodi Jiang</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Jing_J/0/1/0/all/0/1\">Ju Jing</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Wang_J/0/1/0/all/0/1\">Jiasheng Wang</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Liu_C/0/1/0/all/0/1\">Chang Liu</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Li_Q/0/1/0/all/0/1\">Qin Li</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Xu_Y/0/1/0/all/0/1\">Yan Xu</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Wang_J/0/1/0/all/0/1\">Jason T. L. Wang</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Wang_H/0/1/0/all/0/1\">Haimin Wang</a>",
          "description": "We present a new deep learning method, dubbed FibrilNet, for tracing\nchromospheric fibrils in Halpha images of solar observations. Our method\nconsists of a data pre-processing component that prepares training data from a\nthreshold-based tool, a deep learning model implemented as a Bayesian\nconvolutional neural network for probabilistic image segmentation with\nuncertainty quantification to predict fibrils, and a post-processing component\ncontaining a fibril-fitting algorithm to determine fibril orientations. The\nFibrilNet tool is applied to high-resolution Halpha images from an active\nregion (AR 12665) collected by the 1.6 m Goode Solar Telescope (GST) equipped\nwith high-order adaptive optics at the Big Bear Solar Observatory (BBSO). We\nquantitatively assess the FibrilNet tool, comparing its image segmentation\nalgorithm and fibril-fitting algorithm with those employed by the\nthreshold-based tool. Our experimental results and major findings are\nsummarized as follows. First, the image segmentation results (i.e., detected\nfibrils) of the two tools are quite similar, demonstrating the good learning\ncapability of FibrilNet. Second, FibrilNet finds more accurate and smoother\nfibril orientation angles than the threshold-based tool. Third, FibrilNet is\nfaster than the threshold-based tool and the uncertainty maps produced by\nFibrilNet not only provide a quantitative way to measure the confidence on each\ndetected fibril, but also help identify fibril structures that are not detected\nby the threshold-based tool but are inferred through machine learning. Finally,\nwe apply FibrilNet to full-disk Halpha images from other solar observatories\nand additional high-resolution Halpha images collected by BBSO/GST,\ndemonstrating the tool's usability in diverse datasets.",
          "link": "http://arxiv.org/abs/2107.07886",
          "publishedOn": "2021-07-19T00:49:07.276Z",
          "wordCount": 700,
          "title": "Tracing Halpha Fibrils through Bayesian Deep Learning. (arXiv:2107.07886v1 [astro-ph.SR])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07859",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jeon_H/0/1/0/all/0/1\">Hyeon Jeon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ko_H/0/1/0/all/0/1\">Hyung-Kwon Ko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jo_J/0/1/0/all/0/1\">Jaemin Jo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Youngtaek Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seo_J/0/1/0/all/0/1\">Jinwook Seo</a>",
          "description": "We propose Steadiness and Cohesiveness, two novel metrics to measure the\ninter-cluster reliability of multidimensional projection (MDP), specifically\nhow well the inter-cluster structures are preserved between the original\nhigh-dimensional space and the low-dimensional projection space. Measuring\ninter-cluster reliability is crucial as it directly affects how well\ninter-cluster tasks (e.g., identifying cluster relationships in the original\nspace from a projected view) can be conducted; however, despite the importance\nof inter-cluster tasks, we found that previous metrics, such as Trustworthiness\nand Continuity, fail to measure inter-cluster reliability. Our metrics consider\ntwo aspects of the inter-cluster reliability: Steadiness measures the extent to\nwhich clusters in the projected space form clusters in the original space, and\nCohesiveness measures the opposite. They extract random clusters with arbitrary\nshapes and positions in one space and evaluate how much the clusters are\nstretched or dispersed in the other space. Furthermore, our metrics can\nquantify pointwise distortions, allowing for the visualization of inter-cluster\nreliability in a projection, which we call a reliability map. Through\nquantitative experiments, we verify that our metrics precisely capture the\ndistortions that harm inter-cluster reliability while previous metrics have\ndifficulty capturing the distortions. A case study also demonstrates that our\nmetrics and the reliability map 1) support users in selecting the proper\nprojection techniques or hyperparameters and 2) prevent misinterpretation while\nperforming inter-cluster tasks, thus allow an adequate identification of\ninter-cluster structure.",
          "link": "http://arxiv.org/abs/2107.07859",
          "publishedOn": "2021-07-19T00:49:07.270Z",
          "wordCount": 686,
          "title": "Measuring and Explaining the Inter-Cluster Reliability of Multidimensional Projections. (arXiv:2107.07859v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07994",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yaqing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abuduweili_A/0/1/0/all/0/1\">Abulikemu Abuduweili</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dou_D/0/1/0/all/0/1\">Dejing Dou</a>",
          "description": "Molecular property prediction plays a fundamental role in drug discovery to\ndiscover candidate molecules with target properties. However, molecular\nproperty prediction is essentially a few-shot problem which makes it hard to\nobtain regular models. In this paper, we propose a property-aware adaptive\nrelation networks (PAR) for the few-shot molecular property prediction problem.\nIn comparison to existing works, we leverage the facts that both substructures\nand relationships among molecules are different considering various molecular\nproperties. Our PAR is compatible with existing graph-based molecular encoders,\nand are further equipped with the ability to obtain property-aware molecular\nembedding and model molecular relation graph adaptively. The resultant relation\ngraph also facilitates effective label propagation within each task. Extensive\nexperiments on benchmark molecular property prediction datasets show that our\nmethod consistently outperforms state-of-the-art methods and is able to obtain\nproperty-aware molecular embedding and model molecular relation graph properly.",
          "link": "http://arxiv.org/abs/2107.07994",
          "publishedOn": "2021-07-19T00:49:07.265Z",
          "wordCount": 579,
          "title": "Property-aware Adaptive Relation Networks for Molecular Property Prediction. (arXiv:2107.07994v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07977",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hahn_T/0/1/0/all/0/1\">Tim Hahn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ernsting_J/0/1/0/all/0/1\">Jan Ernsting</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Winter_N/0/1/0/all/0/1\">Nils R. Winter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holstein_V/0/1/0/all/0/1\">Vincent Holstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leenings_R/0/1/0/all/0/1\">Ramona Leenings</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beisemann_M/0/1/0/all/0/1\">Marie Beisemann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fisch_L/0/1/0/all/0/1\">Lukas Fisch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarink_K/0/1/0/all/0/1\">Kelvin Sarink</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Emden_D/0/1/0/all/0/1\">Daniel Emden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Opel_N/0/1/0/all/0/1\">Nils Opel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Redlich_R/0/1/0/all/0/1\">Ronny Redlich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Repple_J/0/1/0/all/0/1\">Jonathan Repple</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grotegerd_D/0/1/0/all/0/1\">Dominik Grotegerd</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meinert_S/0/1/0/all/0/1\">Susanne Meinert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hirsch_J/0/1/0/all/0/1\">Jochen G. Hirsch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niendorf_T/0/1/0/all/0/1\">Thoralf Niendorf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Endemann_B/0/1/0/all/0/1\">Beate Endemann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bamberg_F/0/1/0/all/0/1\">Fabian Bamberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kroncke_T/0/1/0/all/0/1\">Thomas Kr&#xf6;ncke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bulow_R/0/1/0/all/0/1\">Robin B&#xfc;low</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Volzke_H/0/1/0/all/0/1\">Henry V&#xf6;lzke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stackelberg_O/0/1/0/all/0/1\">Oyunbileg von Stackelberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sowade_R/0/1/0/all/0/1\">Ramona Felizitas Sowade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Umutlu_L/0/1/0/all/0/1\">Lale Umutlu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidt_B/0/1/0/all/0/1\">B&#xf6;rge Schmidt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caspers_S/0/1/0/all/0/1\">Svenja Caspers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Consortium_G/0/1/0/all/0/1\">German National Cohort Study Center Consortium</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kugel_H/0/1/0/all/0/1\">Harald Kugel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kircher_T/0/1/0/all/0/1\">Tilo Kircher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Risse_B/0/1/0/all/0/1\">Benjamin Risse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaser_C/0/1/0/all/0/1\">Christian Gaser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cole_J/0/1/0/all/0/1\">James H. Cole</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dannlowski_U/0/1/0/all/0/1\">Udo Dannlowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berger_K/0/1/0/all/0/1\">Klaus Berger</a>",
          "description": "The deviation between chronological age and age predicted from neuroimaging\ndata has been identified as a sensitive risk-marker of cross-disorder brain\nchanges, growing into a cornerstone of biological age-research. However,\nMachine Learning models underlying the field do not consider uncertainty,\nthereby confounding results with training data density and variability. Also,\nexisting models are commonly based on homogeneous training sets, often not\nindependently validated, and cannot be shared due to data protection issues.\nHere, we introduce an uncertainty-aware, shareable, and transparent Monte-Carlo\nDropout Composite-Quantile-Regression (MCCQR) Neural Network trained on\nN=10,691 datasets from the German National Cohort. The MCCQR model provides\nrobust, distribution-free uncertainty quantification in high-dimensional\nneuroimaging data, achieving lower error rates compared to existing models\nacross ten recruitment centers and in three independent validation samples\n(N=4,004). In two examples, we demonstrate that it prevents spurious\nassociations and increases power to detect accelerated brain-aging. We make the\npre-trained model publicly available.",
          "link": "http://arxiv.org/abs/2107.07977",
          "publishedOn": "2021-07-19T00:49:07.248Z",
          "wordCount": 661,
          "title": "An Uncertainty-Aware, Shareable and Transparent Neural Network Architecture for Brain-Age Modeling. (arXiv:2107.07977v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08020",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Jiang_Y/0/1/0/all/0/1\">Yiye Jiang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bigot_J/0/1/0/all/0/1\">J&#xe9;r&#xe9;mie Bigot</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Maabout_S/0/1/0/all/0/1\">Sofian Maabout</a>",
          "description": "This paper is concerned with the statistical analysis of matrix-valued time\nseries. These are data collected over a network of sensors (typically a set of\nspatial locations), recording, over time, observations of multiple\nmeasurements. From such data, we propose to learn, in an online fashion, a\ngraph that captures two aspects of dependency: one describing the sparse\nspatial relationship between sensors, and the other characterizing the\nmeasurement relationship. To this purpose, we introduce a novel multivariate\nautoregressive model to infer the graph topology encoded in the coefficient\nmatrix which captures the sparse Granger causality dependency structure present\nin such matrix-valued time series. We decompose the graph by imposing a\nKronecker sum structure on the coefficient matrix. We develop two online\napproaches to learn the graph in a recursive way. The first one uses Wald test\nfor the projected OLS estimation, where we derive the asymptotic distribution\nfor the estimator. For the second one, we formalize a Lasso-type optimization\nproblem. We rely on homotopy algorithms to derive updating rules for estimating\nthe coefficient matrix. Furthermore, we provide an adaptive tuning procedure\nfor the regularization parameter. Numerical experiments using both synthetic\nand real data, are performed to support the effectiveness of the proposed\nlearning approaches.",
          "link": "http://arxiv.org/abs/2107.08020",
          "publishedOn": "2021-07-19T00:49:07.242Z",
          "wordCount": 635,
          "title": "Online Graph Topology Learning from Matrix-valued Time Series. (arXiv:2107.08020v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07997",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tavazza_F/0/1/0/all/0/1\">Francesca Tavazza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cost_B/0/1/0/all/0/1\">Brian De Cost</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choudhary_K/0/1/0/all/0/1\">Kamal Choudhary</a>",
          "description": "Uncertainty quantification in Artificial Intelligence (AI)-based predictions\nof material properties is of immense importance for the success and reliability\nof AI applications in material science. While confidence intervals are commonly\nreported for machine learning (ML) models, prediction intervals, i.e., the\nevaluation of the uncertainty on each prediction, are seldomly available. In\nthis work we compare 3 different approaches to obtain such individual\nuncertainty, testing them on 12 ML-physical properties. Specifically, we\ninvestigated using the Quantile loss function, machine learning the prediction\nintervals directly and using Gaussian Processes. We identify each approachs\nadvantages and disadvantages and end up slightly favoring the modeling of the\nindividual uncertainties directly, as it is the easiest to fit and, in most\ncases, minimizes over-and under-estimation of the predicted errors. All data\nfor training and testing were taken from the publicly available JARVIS-DFT\ndatabase, and the codes developed for computing the prediction intervals are\navailable through JARVIS-Tools.",
          "link": "http://arxiv.org/abs/2107.07997",
          "publishedOn": "2021-07-19T00:49:07.236Z",
          "wordCount": 585,
          "title": "Uncertainty Prediction for Machine Learning Models of Material Properties. (arXiv:2107.07997v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08024",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Desai_S/0/1/0/all/0/1\">Shaan Desai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mattheakis_M/0/1/0/all/0/1\">Marios Mattheakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sondak_D/0/1/0/all/0/1\">David Sondak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Protopapas_P/0/1/0/all/0/1\">Pavlos Protopapas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roberts_S/0/1/0/all/0/1\">Stephen Roberts</a>",
          "description": "Accurately learning the temporal behavior of dynamical systems requires\nmodels with well-chosen learning biases. Recent innovations embed the\nHamiltonian and Lagrangian formalisms into neural networks and demonstrate a\nsignificant improvement over other approaches in predicting trajectories of\nphysical systems. These methods generally tackle autonomous systems that depend\nimplicitly on time or systems for which a control signal is known apriori.\nDespite this success, many real world dynamical systems are non-autonomous,\ndriven by time-dependent forces and experience energy dissipation. In this\nstudy, we address the challenge of learning from such non-autonomous systems by\nembedding the port-Hamiltonian formalism into neural networks, a versatile\nframework that can capture energy dissipation and time-dependent control\nforces. We show that the proposed \\emph{port-Hamiltonian neural network} can\nefficiently learn the dynamics of nonlinear physical systems of practical\ninterest and accurately recover the underlying stationary Hamiltonian,\ntime-dependent force, and dissipative coefficient. A promising outcome of our\nnetwork is its ability to learn and predict chaotic systems such as the Duffing\nequation, for which the trajectories are typically hard to learn.",
          "link": "http://arxiv.org/abs/2107.08024",
          "publishedOn": "2021-07-19T00:49:07.219Z",
          "wordCount": 619,
          "title": "Port-Hamiltonian Neural Networks for Learning Explicit Time-Dependent Dynamical Systems. (arXiv:2107.08024v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07869",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zaidi_S/0/1/0/all/0/1\">Syed Ali Raza Zaidi</a>",
          "description": "In this paper, we present an overview of Nearest neighbor (NN) methods, which\nare frequently employed for solving classification problems using supervised\nlearning. The article concisely introduces the theoretical background,\nalgorithmic, and implementation aspects along with the key applications. From\nan application standpoint, this article explores the challenges related to the\n5G and beyond wireless networks which can be solved using NN classification\ntechniques.",
          "link": "http://arxiv.org/abs/2107.07869",
          "publishedOn": "2021-07-19T00:49:07.212Z",
          "wordCount": 516,
          "title": "Nearest neighbor Methods and their Applications in Design of 5G & Beyond Wireless Networks. (arXiv:2107.07869v1 [cs.NI])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07871",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Moseley_B/0/1/0/all/0/1\">Ben Moseley</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Markham_A/0/1/0/all/0/1\">Andrew Markham</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Nissen_Meyer_T/0/1/0/all/0/1\">Tarje Nissen-Meyer</a>",
          "description": "Recently, physics-informed neural networks (PINNs) have offered a powerful\nnew paradigm for solving problems relating to differential equations. Compared\nto classical numerical methods PINNs have several advantages, for example their\nability to provide mesh-free solutions of differential equations and their\nability to carry out forward and inverse modelling within the same optimisation\nproblem. Whilst promising, a key limitation to date is that PINNs have\nstruggled to accurately and efficiently solve problems with large domains\nand/or multi-scale solutions, which is crucial for their real-world\napplication. Multiple significant and related factors contribute to this issue,\nincluding the increasing complexity of the underlying PINN optimisation problem\nas the problem size grows and the spectral bias of neural networks. In this\nwork we propose a new, scalable approach for solving large problems relating to\ndifferential equations called Finite Basis PINNs (FBPINNs). FBPINNs are\ninspired by classical finite element methods, where the solution of the\ndifferential equation is expressed as the sum of a finite set of basis\nfunctions with compact support. In FBPINNs neural networks are used to learn\nthese basis functions, which are defined over small, overlapping subdomains.\nFBINNs are designed to address the spectral bias of neural networks by using\nseparate input normalisation over each subdomain, and reduce the complexity of\nthe underlying optimisation problem by using many smaller neural networks in a\nparallel divide-and-conquer approach. Our numerical experiments show that\nFBPINNs are effective in solving both small and larger, multi-scale problems,\noutperforming standard PINNs in both accuracy and computational resources\nrequired, potentially paving the way to the application of PINNs on large,\nreal-world problems.",
          "link": "http://arxiv.org/abs/2107.07871",
          "publishedOn": "2021-07-19T00:49:07.205Z",
          "wordCount": 721,
          "title": "Finite Basis Physics-Informed Neural Networks (FBPINNs): a scalable domain decomposition approach for solving differential equations. (arXiv:2107.07871v1 [physics.comp-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2107.08011",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Antonakopoulos_K/0/1/0/all/0/1\">Kimon Antonakopoulos</a>, <a href=\"http://arxiv.org/find/math/1/au:+Mertikopoulos_P/0/1/0/all/0/1\">Panayotis Mertikopoulos</a>",
          "description": "We propose a new family of adaptive first-order methods for a class of convex\nminimization problems that may fail to be Lipschitz continuous or smooth in the\nstandard sense. Specifically, motivated by a recent flurry of activity on\nnon-Lipschitz (NoLips) optimization, we consider problems that are continuous\nor smooth relative to a reference Bregman function - as opposed to a global,\nambient norm (Euclidean or otherwise). These conditions encompass a wide range\nof problems with singular objectives, such as Fisher markets, Poisson\ntomography, D-design, and the like. In this setting, the application of\nexisting order-optimal adaptive methods - like UnixGrad or AcceleGrad - is not\npossible, especially in the presence of randomness and uncertainty. The\nproposed method - which we call adaptive mirror descent (AdaMir) - aims to\nclose this gap by concurrently achieving min-max optimal rates in problems that\nare relatively continuous or smooth, including stochastic ones.",
          "link": "http://arxiv.org/abs/2107.08011",
          "publishedOn": "2021-07-19T00:49:07.198Z",
          "wordCount": 596,
          "title": "Adaptive first-order methods revisited: Convex optimization without Lipschitz requirements. (arXiv:2107.08011v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07889",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yifei Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yiming Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiaxin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1\">David P. Woodruff</a>",
          "description": "In applications such as natural language processing or computer vision, one\nis given a large $n \\times d$ matrix $A = (a_{i,j})$ and would like to compute\na matrix decomposition, e.g., a low rank approximation, of a function $f(A) =\n(f(a_{i,j}))$ applied entrywise to $A$. A very important special case is the\nlikelihood function $f\\left( A \\right ) = \\log{\\left( \\left| a_{ij}\\right|\n+1\\right)}$. A natural way to do this would be to simply apply $f$ to each\nentry of $A$, and then compute the matrix decomposition, but this requires\nstoring all of $A$ as well as multiple passes over its entries. Recent work of\nLiang et al.\\ shows how to find a rank-$k$ factorization to $f(A)$ for an $n\n\\times n$ matrix $A$ using only $n \\cdot \\operatorname{poly}(\\epsilon^{-1}k\\log\nn)$ words of memory, with overall error $10\\|f(A)-[f(A)]_k\\|_F^2 +\n\\operatorname{poly}(\\epsilon/k) \\|f(A)\\|_{1,2}^2$, where $[f(A)]_k$ is the best\nrank-$k$ approximation to $f(A)$ and $\\|f(A)\\|_{1,2}^2$ is the square of the\nsum of Euclidean lengths of rows of $f(A)$. Their algorithm uses three passes\nover the entries of $A$. The authors pose the open question of obtaining an\nalgorithm with $n \\cdot \\operatorname{poly}(\\epsilon^{-1}k\\log n)$ words of\nmemory using only a single pass over the entries of $A$. In this paper we\nresolve this open question, obtaining the first single-pass algorithm for this\nproblem and for the same class of functions $f$ studied by Liang et al.\nMoreover, our error is $\\|f(A)-[f(A)]_k\\|_F^2 + \\operatorname{poly}(\\epsilon/k)\n\\|f(A)\\|_F^2$, where $\\|f(A)\\|_F^2$ is the sum of squares of Euclidean lengths\nof rows of $f(A)$. Thus our error is significantly smaller, as it removes the\nfactor of $10$ and also $\\|f(A)\\|_F^2 \\leq \\|f(A)\\|_{1,2}^2$. We also give an\nalgorithm for regression, pointing out an error in previous work, and\nempirically validate our results.",
          "link": "http://arxiv.org/abs/2107.07889",
          "publishedOn": "2021-07-19T00:49:07.186Z",
          "wordCount": 731,
          "title": "Single Pass Entrywise-Transformed Low Rank Approximation. (arXiv:2107.07889v1 [cs.DS])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07818",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kolcun_R/0/1/0/all/0/1\">Roman Kolcun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Popescu_D/0/1/0/all/0/1\">Diana Andreea Popescu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Safronov_V/0/1/0/all/0/1\">Vadim Safronov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yadav_P/0/1/0/all/0/1\">Poonam Yadav</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mandalari_A/0/1/0/all/0/1\">Anna Maria Mandalari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mortier_R/0/1/0/all/0/1\">Richard Mortier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haddadi_H/0/1/0/all/0/1\">Hamed Haddadi</a>",
          "description": "Internet-of-Things (IoT) devices are known to be the source of many security\nproblems, and as such, they would greatly benefit from automated management.\nThis requires robustly identifying devices so that appropriate network security\npolicies can be applied. We address this challenge by exploring how to\naccurately identify IoT devices based on their network behavior, while\nleveraging approaches previously proposed by other researchers.\n\nWe compare the accuracy of four different previously proposed machine\nlearning models (tree-based and neural network-based) for identifying IoT\ndevices. We use packet trace data collected over a period of six months from a\nlarge IoT test-bed. We show that, while all models achieve high accuracy when\nevaluated on the same dataset as they were trained on, their accuracy degrades\nover time, when evaluated on data collected outside the training set. We show\nthat on average the models' accuracy degrades after a couple of weeks by up to\n40 percentage points (on average between 12 and 21 percentage points). We argue\nthat, in order to keep the models' accuracy at a high level, these need to be\ncontinuously updated.",
          "link": "http://arxiv.org/abs/2107.07818",
          "publishedOn": "2021-07-19T00:49:07.140Z",
          "wordCount": 634,
          "title": "Revisiting IoT Device Identification. (arXiv:2107.07818v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07844",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Thor_M/0/1/0/all/0/1\">Mathias Thor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manoonpong_P/0/1/0/all/0/1\">Poramate Manoonpong</a>",
          "description": "Legged robots have significant potential to operate in highly unstructured\nenvironments. The design of locomotion control is, however, still challenging.\nCurrently, controllers must be either manually designed for specific robots and\ntasks, or automatically designed via machine learning methods that require long\ntraining times and yield large opaque controllers. Drawing inspiration from\nanimal locomotion, we propose a simple yet versatile modular neural control\nstructure with fast learning. The key advantages of our approach are that\nbehavior-specific control modules can be added incrementally to obtain\nincreasingly complex emergent locomotion behaviors, and that neural connections\ninterfacing with existing modules can be quickly and automatically learned. In\na series of experiments, we show how eight modules can be quickly learned and\nadded to a base control module to obtain emergent adaptive behaviors allowing a\nhexapod robot to navigate in complex environments. We also show that modules\ncan be added and removed during operation without affecting the functionality\nof the remaining controller. Finally, the control approach was successfully\ndemonstrated on a physical hexapod robot. Taken together, our study reveals a\nsignificant step towards fast automatic design of versatile neural locomotion\ncontrol for complex robotic systems.",
          "link": "http://arxiv.org/abs/2107.07844",
          "publishedOn": "2021-07-19T00:49:07.134Z",
          "wordCount": 641,
          "title": "Versatile modular neural locomotion control with fast learning. (arXiv:2107.07844v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07875",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Nalamada_T/0/1/0/all/0/1\">Trikay Nalamada</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Agarwal_S/0/1/0/all/0/1\">Shruti Agarwal</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Jahja_M/0/1/0/all/0/1\">Maria Jahja</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chakraborty_B/0/1/0/all/0/1\">Bibhas Chakraborty</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ghosh_P/0/1/0/all/0/1\">Palash Ghosh</a>",
          "description": "A dynamic treatment regimen (DTR) is a set of decision rules to personalize\ntreatments for an individual using their medical history. The Q-learning based\nQ-shared algorithm has been used to develop DTRs that involve decision rules\nshared across multiple stages of intervention. We show that the existing\nQ-shared algorithm can suffer from non-convergence due to the use of linear\nmodels in the Q-learning setup, and identify the condition in which Q-shared\nfails. Leveraging properties from expansion-constrained ordinary least-squares,\nwe give a penalized Q-shared algorithm that not only converges in settings that\nviolate the condition, but can outperform the original Q-shared algorithm even\nwhen the condition is satisfied. We give evidence for the proposed method in a\nreal-world application and several synthetic simulations.",
          "link": "http://arxiv.org/abs/2107.07875",
          "publishedOn": "2021-07-19T00:49:07.126Z",
          "wordCount": 561,
          "title": "A Penalized Shared-parameter Algorithm for Estimating Optimal Dynamic Treatment Regimens. (arXiv:2107.07875v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07853",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Konig_G/0/1/0/all/0/1\">Gunnar K&#xf6;nig</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Freiesleben_T/0/1/0/all/0/1\">Timo Freiesleben</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Grosse_Wentrup_M/0/1/0/all/0/1\">Moritz Grosse-Wentrup</a>",
          "description": "Algorithmic recourse explanations inform stakeholders on how to act to revert\nunfavorable predictions. However, in general ML models do not predict well in\ninterventional distributions. Thus, an action that changes the prediction in\nthe desired way may not lead to an improvement of the underlying target. Such\nrecourse is neither meaningful nor robust to model refits. Extending the work\nof Karimi et al. (2021), we propose meaningful algorithmic recourse (MAR) that\nonly recommends actions that improve both prediction and target. We justify\nthis selection constraint by highlighting the differences between model audit\nand meaningful, actionable recourse explanations. Additionally, we introduce a\nrelaxation of MAR called effective algorithmic recourse (EAR), which, under\ncertain assumptions, yields meaningful recourse by only allowing interventions\non causes of the target.",
          "link": "http://arxiv.org/abs/2107.07853",
          "publishedOn": "2021-07-19T00:49:07.073Z",
          "wordCount": 570,
          "title": "A Causal Perspective on Meaningful and Robust Algorithmic Recourse. (arXiv:2107.07853v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07820",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Haan_P/0/1/0/all/0/1\">Puck de Haan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lowe_S/0/1/0/all/0/1\">Sindy L&#xf6;we</a>",
          "description": "Reliable detection of anomalies is crucial when deploying machine learning\nmodels in practice, but remains challenging due to the lack of labeled data. To\ntackle this challenge, contrastive learning approaches are becoming\nincreasingly popular, given the impressive results they have achieved in\nself-supervised representation learning settings. However, while most existing\ncontrastive anomaly detection and segmentation approaches have been applied to\nimages, none of them can use the contrastive losses directly for both anomaly\ndetection and segmentation. In this paper, we close this gap by making use of\nthe Contrastive Predictive Coding model (arXiv:1807.03748). We show that its\npatch-wise contrastive loss can directly be interpreted as an anomaly score,\nand how this allows for the creation of anomaly segmentation masks. The\nresulting model achieves promising results for both anomaly detection and\nsegmentation on the challenging MVTec-AD dataset.",
          "link": "http://arxiv.org/abs/2107.07820",
          "publishedOn": "2021-07-19T00:49:07.065Z",
          "wordCount": 583,
          "title": "Contrastive Predictive Coding for Anomaly Detection. (arXiv:2107.07820v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07791",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gharaee_Z/0/1/0/all/0/1\">Zahra Gharaee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kowshik_S/0/1/0/all/0/1\">Shreyas Kowshik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stromann_O/0/1/0/all/0/1\">Oliver Stromann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Felsberg_M/0/1/0/all/0/1\">Michael Felsberg</a>",
          "description": "We present a novel learning-based approach to graph representations of road\nnetworks employing state-of-the-art graph convolutional neural networks. Our\napproach is applied to realistic road networks of 17 cities from Open Street\nMap. While edge features are crucial to generate descriptive graph\nrepresentations of road networks, graph convolutional networks usually rely on\nnode features only. We show that the highly representative edge features can\nstill be integrated into such networks by applying a line graph transformation.\nWe also propose a method for neighborhood sampling based on a topological\nneighborhood composed of both local and global neighbors. We compare the\nperformance of learning representations using different types of neighborhood\naggregation functions in transductive and inductive tasks and in supervised and\nunsupervised learning. Furthermore, we propose a novel aggregation approach,\nGraph Attention Isomorphism Network, GAIN. Our results show that GAIN\noutperforms state-of-the-art methods on the road type classification problem.",
          "link": "http://arxiv.org/abs/2107.07791",
          "publishedOn": "2021-07-19T00:49:07.046Z",
          "wordCount": 587,
          "title": "Graph Representation Learning for Road Type Classification. (arXiv:2107.07791v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07737",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jinyin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dunjie Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ming_Z/0/1/0/all/0/1\">Zhaoyan Ming</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_M/0/1/0/all/0/1\">Mingwei Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yi Liu</a>",
          "description": "Graph classification plays a significant role in network analysis. It also\nfaces potential security threat like adversarial attacks. Some defense methods\nmay sacrifice algorithm complexity for robustness like adversarial training,\nwhile others may sacrifice the clean example performance such as\nsmoothing-based defense. Most of them are suffered from high-complexity or less\ntransferability. To address this problem, we proposed EGC$^2$, an enhanced\ngraph classification model with easy graph compression. EGC$^2$ captures the\nrelationship between features of different nodes by constructing feature graphs\nand improving aggregate node-level representation. To achieve lower complexity\ndefense applied to various graph classification models, EGC$^2$ utilizes a\ncentrality-based edge importance index to compress graphs, filtering out\ntrivial structures and even adversarial perturbations of the input graphs, thus\nimproves its robustness. Experiments on seven benchmark datasets demonstrate\nthat the proposed feature read-out and graph compression mechanisms enhance the\nrobustness of various basic models, thus achieving the state-of-the-art\nperformance of accuracy and robustness in the threat of different adversarial\nattacks.",
          "link": "http://arxiv.org/abs/2107.07737",
          "publishedOn": "2021-07-19T00:49:07.040Z",
          "wordCount": 600,
          "title": "EGC2: Enhanced Graph Classification with Easy Graph Compression. (arXiv:2107.07737v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07729",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Reddy_S/0/1/0/all/0/1\">Shivshankar Reddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chauhan_A/0/1/0/all/0/1\">Anand Vir Singh Chauhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_M/0/1/0/all/0/1\">Maneet Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_K/0/1/0/all/0/1\">Karamjit Singh</a>",
          "description": "Temporal Point Processes (TPPs) are often used to represent the sequence of\nevents ordered as per the time of occurrence. Owing to their flexible nature,\nTPPs have been used to model different scenarios and have shown applicability\nin various real-world applications. While TPPs focus on modeling the event\noccurrence, Marked Temporal Point Process (MTPP) focuses on modeling the\ncategory/class of the event as well (termed as the marker). Research in MTPP\nhas garnered substantial attention over the past few years, with an extensive\nfocus on supervised algorithms. Despite the research focus, limited attention\nhas been given to the challenging problem of developing solutions in\nsemi-supervised settings, where algorithms have access to a mix of labeled and\nunlabeled data. This research proposes a novel algorithm for Semi-supervised\nLearning for Marked Temporal Point Processes (SSL-MTPP) applicable in such\nscenarios. The proposed SSL-MTPP algorithm utilizes a combination of labeled\nand unlabeled data for learning a robust marker prediction model. The proposed\nalgorithm utilizes an RNN-based Encoder-Decoder module for learning effective\nrepresentations of the time sequence. The efficacy of the proposed algorithm\nhas been demonstrated via multiple protocols on the Retweet dataset, where the\nproposed SSL-MTPP demonstrates improved performance in comparison to the\ntraditional supervised learning approach.",
          "link": "http://arxiv.org/abs/2107.07729",
          "publishedOn": "2021-07-19T00:49:07.033Z",
          "wordCount": 637,
          "title": "Semi-supervised Learning for Marked Temporal Point Processes. (arXiv:2107.07729v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07728",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Henkel_C/0/1/0/all/0/1\">Christof Henkel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfeiffer_P/0/1/0/all/0/1\">Pascal Pfeiffer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singer_P/0/1/0/all/0/1\">Philipp Singer</a>",
          "description": "We present a robust classification approach for avian vocalization in complex\nand diverse soundscapes, achieving second place in the BirdCLEF2021 challenge.\nWe illustrate how to make full use of pre-trained convolutional neural\nnetworks, by using an efficient modeling and training routine supplemented by\nnovel augmentation methods. Thereby, we improve the generalization of weakly\nlabeled crowd-sourced data to productive data collected by autonomous recording\nunits. As such, we illustrate how to progress towards an accurate automated\nassessment of avian population which would enable global biodiversity\nmonitoring at scale, impossible by manual annotation.",
          "link": "http://arxiv.org/abs/2107.07728",
          "publishedOn": "2021-07-19T00:49:07.026Z",
          "wordCount": 541,
          "title": "Recognizing bird species in diverse soundscapes under weak supervision. (arXiv:2107.07728v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07705",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ruan_Q/0/1/0/all/0/1\">Qin Ruan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Namee_B/0/1/0/all/0/1\">Brian Mac Namee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_R/0/1/0/all/0/1\">Ruihai Dong</a>",
          "description": "Leveraging unlabelled data through weak or distant supervision is a\ncompelling approach to developing more effective text classification models.\nThis paper proposes a simple but effective data augmentation method, which\nleverages the idea of pseudo-labelling to select samples from noisy distant\nsupervision annotation datasets. The result shows that the proposed method\nimproves the accuracy of biased news detection models.",
          "link": "http://arxiv.org/abs/2107.07705",
          "publishedOn": "2021-07-19T00:49:07.019Z",
          "wordCount": 491,
          "title": "Pseudo-labelling Enhanced Media Bias Detection. (arXiv:2107.07705v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07709",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mondal_A/0/1/0/all/0/1\">Arnab Kumar Mondal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asnani_H/0/1/0/all/0/1\">Himanshu Asnani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singla_P/0/1/0/all/0/1\">Parag Singla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+AP_P/0/1/0/all/0/1\">Prathosh AP</a>",
          "description": "Clustering single-cell RNA sequence (scRNA-seq) data poses statistical and\ncomputational challenges due to their high-dimensionality and data-sparsity,\nalso known as `dropout' events. Recently, Regularized Auto-Encoder (RAE) based\ndeep neural network models have achieved remarkable success in learning robust\nlow-dimensional representations. The basic idea in RAEs is to learn a\nnon-linear mapping from the high-dimensional data space to a low-dimensional\nlatent space and vice-versa, simultaneously imposing a distributional prior on\nthe latent space, which brings in a regularization effect. This paper argues\nthat RAEs suffer from the infamous problem of bias-variance trade-off in their\nnaive formulation. While a simple AE without a latent regularization results in\ndata over-fitting, a very strong prior leads to under-representation and thus\nbad clustering. To address the above issues, we propose a modified RAE\nframework (called the scRAE) for effective clustering of the single-cell RNA\nsequencing data. scRAE consists of deterministic AE with a flexibly learnable\nprior generator network, which is jointly trained with the AE. This facilitates\nscRAE to trade-off better between the bias and variance in the latent space. We\ndemonstrate the efficacy of the proposed method through extensive\nexperimentation on several real-world single-cell Gene expression datasets.",
          "link": "http://arxiv.org/abs/2107.07709",
          "publishedOn": "2021-07-19T00:49:07.002Z",
          "wordCount": 642,
          "title": "ScRAE: Deterministic Regularized Autoencoders with Flexible Priors for Clustering Single-cell Gene Expression Data. (arXiv:2107.07709v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07713",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_R/0/1/0/all/0/1\">Rushil Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_V/0/1/0/all/0/1\">Vishal Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_Y/0/1/0/all/0/1\">Yash Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yitao Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Broeck_G/0/1/0/all/0/1\">Guy Van den Broeck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singla_P/0/1/0/all/0/1\">Parag Singla</a>",
          "description": "We focus on the task of future frame prediction in video governed by\nunderlying physical dynamics. We work with models which are object-centric,\ni.e., explicitly work with object representations, and propagate a loss in the\nlatent space. Specifically, our research builds on recent work by Kipf et al.\n\\cite{kipf&al20}, which predicts the next state via contrastive learning of\nobject interactions in a latent space using a Graph Neural Network. We argue\nthat injecting explicit inductive bias in the model, in form of general\nphysical laws, can help not only make the model more interpretable, but also\nimprove the overall prediction of model. As a natural by-product, our model can\nlearn feature maps which closely resemble actual object positions in the image,\nwithout having any explicit supervision about the object positions at the\ntraining time. In comparison with earlier works \\cite{jaques&al20}, which\nassume a complete knowledge of the dynamics governing the motion in the form of\na physics engine, we rely only on the knowledge of general physical laws, such\nas, world consists of objects, which have position and velocity. We propose an\nadditional decoder based loss in the pixel space, imposed in a curriculum\nmanner, to further refine the latent space predictions. Experiments in multiple\ndifferent settings demonstrate that while Kipf et al. model is effective at\ncapturing object interactions, our model can be significantly more effective at\nlocalising objects, resulting in improved performance in 3 out of 4 domains\nthat we experiment with. Additionally, our model can learn highly intrepretable\nfeature maps, resembling actual object positions.",
          "link": "http://arxiv.org/abs/2107.07713",
          "publishedOn": "2021-07-19T00:49:06.996Z",
          "wordCount": 709,
          "title": "Towards an Interpretable Latent Space in Structured Models for Video Prediction. (arXiv:2107.07713v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07732",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Chen_X/0/1/0/all/0/1\">Xinyi Chen</a>, <a href=\"http://arxiv.org/find/math/1/au:+Ghai_U/0/1/0/all/0/1\">Udaya Ghai</a>, <a href=\"http://arxiv.org/find/math/1/au:+Hazan_E/0/1/0/all/0/1\">Elad Hazan</a>, <a href=\"http://arxiv.org/find/math/1/au:+Megretski_A/0/1/0/all/0/1\">Alexandre Megretski</a>",
          "description": "We study online control of an unknown nonlinear dynamical system that is\napproximated by a time-invariant linear system with model misspecification. Our\nstudy focuses on robustness, which measures how much deviation from the assumed\nlinear approximation can be tolerated while maintaining a bounded $\\ell_2$-gain\ncompared to the optimal control in hindsight. Some models cannot be stabilized\neven with perfect knowledge of their coefficients: the robustness is limited by\nthe minimal distance between the assumed dynamics and the set of unstabilizable\ndynamics. Therefore it is necessary to assume a lower bound on this distance.\nUnder this assumption, and with full observation of the $d$ dimensional state,\nwe describe an efficient controller that attains $\\Omega(\\frac{1}{\\sqrt{d}})$\nrobustness together with an $\\ell_2$-gain whose dimension dependence is near\noptimal. We also give an inefficient algorithm that attains constant robustness\nindependent of the dimension, with a finite but sub-optimal $\\ell_2$-gain.",
          "link": "http://arxiv.org/abs/2107.07732",
          "publishedOn": "2021-07-19T00:49:06.989Z",
          "wordCount": 576,
          "title": "Robust Online Control with Model Misspecification. (arXiv:2107.07732v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07752",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Cognolato_F/0/1/0/all/0/1\">Francesco Cognolato</a>, <a href=\"http://arxiv.org/find/eess/1/au:+OBrien_K/0/1/0/all/0/1\">Kieran O&#x27;Brien</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jin_J/0/1/0/all/0/1\">Jin Jin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Robinson_S/0/1/0/all/0/1\">Simon Robinson</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Laun_F/0/1/0/all/0/1\">Frederik B. Laun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Barth_M/0/1/0/all/0/1\">Markus Barth</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bollmann_S/0/1/0/all/0/1\">Steffen Bollmann</a>",
          "description": "Deep learning based Quantitative Susceptibility Mapping (QSM) has shown great\npotential in recent years, outperforming traditional non-learning approaches in\nspeed and accuracy. However, many of the current deep learning approaches are\nnot data consistent, require in vivo training data or do not solve all steps of\nthe QSM processing pipeline. Here we aim to overcome these limitations and\ndeveloped a framework to solve the QSM processing steps jointly. We developed a\nnew hybrid training data generation method that enables the end-to-end training\nfor solving background field correction and dipole inversion in a\ndata-consistent fashion using a variational network that combines the QSM model\nterm and a learned regularizer. We demonstrate that NeXtQSM overcomes the\nlimitations of previous model-agnostic deep learning methods and show that\nNeXtQSM offers a complete deep learning based pipeline for computing robust,\nfast and accurate quantitative susceptibility maps.",
          "link": "http://arxiv.org/abs/2107.07752",
          "publishedOn": "2021-07-19T00:49:06.983Z",
          "wordCount": 613,
          "title": "NeXtQSM -- A complete deep learning pipeline for data-consistent quantitative susceptibility mapping trained with hybrid data. (arXiv:2107.07752v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07788",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Pang_B/0/1/0/all/0/1\">Bo Pang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jiang_Z/0/1/0/all/0/1\">Zhong-Ping Jiang</a>",
          "description": "This paper studies the optimal stationary control of continuous-time linear\nstochastic systems with both additive and multiplicative noises, using\nreinforcement learning techniques. Based on policy iteration, a novel\noff-policy reinforcement learning algorithm, named optimistic\nleast-squares-based policy iteration, is proposed which is able to iteratively\nfind near-optimal policies of the optimal stationary control problem directly\nfrom input/state data without explicitly identifying any system matrices,\nstarting from an initial admissible control policy. The solutions given by the\nproposed optimistic least-squares-based policy iteration are proved to converge\nto a small neighborhood of the optimal solution with probability one, under\nmild conditions. The application of the proposed algorithm to a triple inverted\npendulum example validates its feasibility and effectiveness.",
          "link": "http://arxiv.org/abs/2107.07788",
          "publishedOn": "2021-07-19T00:49:06.976Z",
          "wordCount": 567,
          "title": "Reinforcement Learning for Optimal Stationary Control of Linear Stochastic Systems. (arXiv:2107.07788v1 [eess.SY])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07582",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Mamandipoor_B/0/1/0/all/0/1\">Behrooz Mamandipoor</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Yeung_W/0/1/0/all/0/1\">Wesley Yeung</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Agha_Mir_Salim_L/0/1/0/all/0/1\">Louis Agha-Mir-Salim</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Stone_D/0/1/0/all/0/1\">David J. Stone</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Osmani_V/0/1/0/all/0/1\">Venet Osmani</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Celi_L/0/1/0/all/0/1\">Leo Anthony Celi</a>",
          "description": "Purpose. Elevations in initially obtained serum lactate levels are strong\npredictors of mortality in critically ill patients. Identifying patients whose\nserum lactate levels are more likely to increase can alert physicians to\nintensify care and guide them in the frequency of tending the blood test. We\ninvestigate whether machine learning models can predict subsequent serum\nlactate changes.\n\nMethods. We investigated serum lactate change prediction using the MIMIC-III\nand eICU-CRD datasets in internal as well as external validation of the eICU\ncohort on the MIMIC-III cohort. Three subgroups were defined based on the\ninitial lactate levels: i) normal group (<2 mmol/L), ii) mild group (2-4\nmmol/L), and iii) severe group (>4 mmol/L). Outcomes were defined based on\nincrease or decrease of serum lactate levels between the groups. We also\nperformed sensitivity analysis by defining the outcome as lactate change of\n>10% and furthermore investigated the influence of the time interval between\nsubsequent lactate measurements on predictive performance.\n\nResults. The LSTM models were able to predict deterioration of serum lactate\nvalues of MIMIC-III patients with an AUC of 0.77 (95% CI 0.762-0.771) for the\nnormal group, 0.77 (95% CI 0.768-0.772) for the mild group, and 0.85 (95% CI\n0.840-0.851) for the severe group, with a slightly lower performance in the\nexternal validation.\n\nConclusion. The LSTM demonstrated good discrimination of patients who had\ndeterioration in serum lactate levels. Clinical studies are needed to evaluate\nwhether utilization of a clinical decision support tool based on these results\ncould positively impact decision-making and patient outcomes.",
          "link": "http://arxiv.org/abs/2107.07582",
          "publishedOn": "2021-07-19T00:49:06.959Z",
          "wordCount": 727,
          "title": "Prediction of Blood Lactate Values in Critically Ill Patients: A Retrospective Multi-center Cohort Study. (arXiv:2107.07582v1 [q-bio.QM])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07754",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Teo_C/0/1/0/all/0/1\">Christopher T.H Teo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheung_N/0/1/0/all/0/1\">Ngai-Man Cheung</a>",
          "description": "Deep generative models have made much progress in improving training\nstability and quality of generated data. Recently there has been increased\ninterest in the fairness of deep-generated data. Fairness is important in many\napplications, e.g. law enforcement, as biases will affect efficacy. Central to\nfair data generation are the fairness metrics for the assessment and evaluation\nof different generative models. In this paper, we first review fairness metrics\nproposed in previous works and highlight potential weaknesses. We then discuss\na performance benchmark framework along with the assessment of alternative\nmetrics.",
          "link": "http://arxiv.org/abs/2107.07754",
          "publishedOn": "2021-07-19T00:49:06.952Z",
          "wordCount": 525,
          "title": "Measuring Fairness in Generative Models. (arXiv:2107.07754v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07659",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kitamura_T/0/1/0/all/0/1\">Toshinori Kitamura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1\">Lingwei Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matsubara_T/0/1/0/all/0/1\">Takamitsu Matsubara</a>",
          "description": "The recent booming of entropy-regularized literature reveals that\nKullback-Leibler (KL) regularization brings advantages to Reinforcement\nLearning (RL) algorithms by canceling out errors under mild assumptions.\nHowever, existing analyses focus on fixed regularization with a constant\nweighting coefficient and have not considered the case where the coefficient is\nallowed to change dynamically. In this paper, we study the dynamic coefficient\nscheme and present the first asymptotic error bound. Based on the dynamic\ncoefficient error bound, we propose an effective scheme to tune the coefficient\naccording to the magnitude of error in favor of more robust learning. On top of\nthis development, we propose a novel algorithm: Geometric Value Iteration (GVI)\nthat features a dynamic error-aware KL coefficient design aiming to mitigate\nthe impact of errors on the performance. Our experiments demonstrate that GVI\ncan effectively exploit the trade-off between learning speed and robustness\nover uniform averaging of constant KL coefficient. The combination of GVI and\ndeep networks shows stable learning behavior even in the absence of a target\nnetwork where algorithms with a constant KL coefficient would greatly oscillate\nor even fail to converge.",
          "link": "http://arxiv.org/abs/2107.07659",
          "publishedOn": "2021-07-19T00:49:06.946Z",
          "wordCount": 616,
          "title": "Geometric Value Iteration: Dynamic Error-Aware KL Regularization for Reinforcement Learning. (arXiv:2107.07659v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07724",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Barata_R/0/1/0/all/0/1\">Ricardo Barata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leite_M/0/1/0/all/0/1\">Miguel Leite</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pacheco_R/0/1/0/all/0/1\">Ricardo Pacheco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sampaio_M/0/1/0/all/0/1\">Marco O. P. Sampaio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ascensao_J/0/1/0/all/0/1\">Jo&#xe3;o Tiago Ascens&#xe3;o</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bizarro_P/0/1/0/all/0/1\">Pedro Bizarro</a>",
          "description": "Labeled data is essential in modern systems that rely on Machine Learning\n(ML) for predictive modelling. Such systems may suffer from the cold-start\nproblem: supervised models work well but, initially, there are no labels, which\nare costly or slow to obtain. This problem is even worse in imbalanced data\nscenarios. Online financial fraud detection is an example where labeling is: i)\nexpensive, or ii) it suffers from long delays, if relying on victims filing\ncomplaints. The latter may not be viable if a model has to be in place\nimmediately, so an option is to ask analysts to label events while minimizing\nthe number of annotations to control costs. We propose an Active Learning (AL)\nannotation system for datasets with orders of magnitude of class imbalance, in\na cold start streaming scenario. We present a computationally efficient\nOutlier-based Discriminative AL approach (ODAL) and design a novel 3-stage\nsequence of AL labeling policies where it is used as warm-up. Then, we perform\nempirical studies in four real world datasets, with various magnitudes of class\nimbalance. The results show that our method can more quickly reach a high\nperformance model than standard AL policies. Its observed gains over random\nsampling can reach 80% and be competitive with policies with an unlimited\nannotation budget or additional historical data (with 1/10 to 1/50 of the\nlabels).",
          "link": "http://arxiv.org/abs/2107.07724",
          "publishedOn": "2021-07-19T00:49:06.939Z",
          "wordCount": 678,
          "title": "Active learning for online training in imbalanced data streams under cold start. (arXiv:2107.07724v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07740",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_M/0/1/0/all/0/1\">Ming Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhunan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1\">Cunhang Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jinpeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1\">Huiguang He</a>",
          "description": "As an essential element for the diagnosis and rehabilitation of psychiatric\ndisorders, the electroencephalogram (EEG) based emotion recognition has\nachieved significant progress due to its high precision and reliability.\nHowever, one obstacle to practicality lies in the variability between subjects\nand sessions. Although several studies have adopted domain adaptation (DA)\napproaches to tackle this problem, most of them treat multiple EEG data from\ndifferent subjects and sessions together as a single source domain for\ntransfer, which either fails to satisfy the assumption of domain adaptation\nthat the source has a certain marginal distribution, or increases the\ndifficulty of adaptation. We therefore propose the multi-source marginal\ndistribution adaptation (MS-MDA) for EEG emotion recognition, which takes both\ndomain-invariant and domain-specific features into consideration. First, we\nassume that different EEG data share the same low-level features, then we\nconstruct independent branches for multiple EEG data source domains to adopt\none-to-one domain adaptation and extract domain-specific features. Finally, the\ninference is made by multiple branches. We evaluate our method on SEED and\nSEED-IV for recognizing three and four emotions, respectively. Experimental\nresults show that the MS-MDA outperforms the comparison methods and\nstate-of-the-art models in cross-session and cross-subject transfer scenarios\nin our settings. Codes at https://github.com/VoiceBeer/MS-MDA.",
          "link": "http://arxiv.org/abs/2107.07740",
          "publishedOn": "2021-07-19T00:49:06.933Z",
          "wordCount": 657,
          "title": "MS-MDA: Multisource Marginal Distribution Adaptation for Cross-subject and Cross-session EEG Emotion Recognition. (arXiv:2107.07740v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07741",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_N/0/1/0/all/0/1\">Niel Teng Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xinyu Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1\">Rosanne Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hooker_S/0/1/0/all/0/1\">Sara Hooker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yosinski_J/0/1/0/all/0/1\">Jason Yosinski</a>",
          "description": "Not all examples are created equal, but standard deep neural network training\nprotocols treat each training point uniformly. Each example is propagated\nforward and backward through the network the same amount of times, independent\nof how much the example contributes to the learning protocol. Recent work has\nproposed ways to accelerate training by deviating from this uniform treatment.\nPopular methods entail up-weighting examples that contribute more to the loss\nwith the intuition that examples with low loss have already been learned by the\nmodel, so their marginal value to the training procedure should be lower. This\nview assumes that updating the model with high loss examples will be beneficial\nto the model. However, this may not hold for noisy, real world data. In this\npaper, we theorize and then empirically demonstrate that loss-based\nacceleration methods degrade in scenarios with noisy and corrupted data. Our\nwork suggests measures of example difficulty need to correctly separate out\nnoise from other types of challenging examples.",
          "link": "http://arxiv.org/abs/2107.07741",
          "publishedOn": "2021-07-19T00:49:06.895Z",
          "wordCount": 589,
          "title": "When does loss-based prioritization fail?. (arXiv:2107.07741v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07738",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiazheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yi Wang</a>",
          "description": "Scenario generation is a fundamental and crucial tool for decision-making in\npower systems with high-penetration renewables. Based on big historical data, a\nnovel federated deep generative learning framework, called Fed-LSGAN, is\nproposed by integrating federated learning and least square generative\nadversarial networks (LSGANs) for renewable scenario generation. Specifically,\nfederated learning learns a shared global model in a central server from\nrenewable sites at network edges, which enables the Fed-LSGAN to generate\nscenarios in a privacy-preserving manner without sacrificing the generation\nquality by transferring model parameters, rather than all data. Meanwhile, the\nLSGANs-based deep generative model generates scenarios that conform to the\ndistribution of historical data through fully capturing the spatial-temporal\ncharacteristics of renewable powers, which leverages the least squares loss\nfunction to improve the training stability and generation quality. The\nsimulation results demonstrate that the proposal manages to generate\nhigh-quality renewable scenarios and outperforms the state-of-the-art\ncentralized methods. Besides, an experiment with different federated learning\nsettings is designed and conducted to verify the robustness of our method.",
          "link": "http://arxiv.org/abs/2107.07738",
          "publishedOn": "2021-07-19T00:49:06.886Z",
          "wordCount": 626,
          "title": "Privacy-preserving Spatiotemporal Scenario Generation of Renewable Energies: A Federated Deep Generative Learning Approach. (arXiv:2107.07738v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07687",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1\">Yuming Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sanz_Alonso_D/0/1/0/all/0/1\">Daniel Sanz-Alonso</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Willett_R/0/1/0/all/0/1\">Rebecca Willett</a>",
          "description": "Data assimilation is concerned with sequentially estimating a\ntemporally-evolving state. This task, which arises in a wide range of\nscientific and engineering applications, is particularly challenging when the\nstate is high-dimensional and the state-space dynamics are unknown. This paper\nintroduces a machine learning framework for learning dynamical systems in data\nassimilation. Our auto-differentiable ensemble Kalman filters (AD-EnKFs) blend\nensemble Kalman filters for state recovery with machine learning tools for\nlearning the dynamics. In doing so, AD-EnKFs leverage the ability of ensemble\nKalman filters to scale to high-dimensional states and the power of automatic\ndifferentiation to train high-dimensional surrogate models for the dynamics.\nNumerical results using the Lorenz-96 model show that AD-EnKFs outperform\nexisting methods that use expectation-maximization or particle filters to merge\ndata assimilation and machine learning. In addition, AD-EnKFs are easy to\nimplement and require minimal tuning.",
          "link": "http://arxiv.org/abs/2107.07687",
          "publishedOn": "2021-07-19T00:49:06.870Z",
          "wordCount": 564,
          "title": "Auto-differentiable Ensemble Kalman Filters. (arXiv:2107.07687v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07617",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yang Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dasgupta_S/0/1/0/all/0/1\">Sanjoy Dasgupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Navlakha_S/0/1/0/all/0/1\">Saket Navlakha</a>",
          "description": "Continual learning in computational systems is challenging due to\ncatastrophic forgetting. We discovered a two layer neural circuit in the fruit\nfly olfactory system that addresses this challenge by uniquely combining sparse\ncoding and associative learning. In the first layer, odors are encoded using\nsparse, high dimensional representations, which reduces memory interference by\nactivating non overlapping populations of neurons for different odors. In the\nsecond layer, only the synapses between odor activated neurons and the output\nneuron associated with the odor are modified during learning; the rest of the\nweights are frozen to prevent unrelated memories from being overwritten. We\nshow empirically and analytically that this simple and lightweight algorithm\nsignificantly boosts continual learning performance. The fly associative\nlearning algorithm is strikingly similar to the classic perceptron learning\nalgorithm, albeit two modifications, which we show are critical for reducing\ncatastrophic forgetting. Overall, fruit flies evolved an efficient lifelong\nlearning algorithm, and circuit mechanisms from neuroscience can be translated\nto improve machine computation.",
          "link": "http://arxiv.org/abs/2107.07617",
          "publishedOn": "2021-07-19T00:49:06.824Z",
          "wordCount": 595,
          "title": "Algorithmic insights on continual learning from fruit flies. (arXiv:2107.07617v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07677",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hossain_K/0/1/0/all/0/1\">Khondker Fariha Hossain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamran_S/0/1/0/all/0/1\">Sharif Amit Kamran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tavakkoli_A/0/1/0/all/0/1\">Alireza Tavakkoli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_L/0/1/0/all/0/1\">Lei Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_D/0/1/0/all/0/1\">Daniel Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajasegarar_S/0/1/0/all/0/1\">Sutharshan Rajasegarar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karmaker_C/0/1/0/all/0/1\">Chandan Karmaker</a>",
          "description": "Electrocardiogram (ECG) acquisition requires an automated system and analysis\npipeline for understanding specific rhythm irregularities. Deep neural networks\nhave become a popular technique for tracing ECG signals, outperforming human\nexperts. Despite this, convolutional neural networks are susceptible to\nadversarial examples that can misclassify ECG signals and decrease the model's\nprecision. Moreover, they do not generalize well on the out-of-distribution\ndataset. The GAN architecture has been employed in recent works to synthesize\nadversarial ECG signals to increase existing training data. However, they use a\ndisjointed CNN-based classification architecture to detect arrhythmia. Till\nnow, no versatile architecture has been proposed that can detect adversarial\nexamples and classify arrhythmia simultaneously. To alleviate this, we propose\na novel Conditional Generative Adversarial Network to simultaneously generate\nECG signals for different categories and detect cardiac abnormalities.\nMoreover, the model is conditioned on class-specific ECG signals to synthesize\nrealistic adversarial examples. Consequently, we compare our architecture and\nshow how it outperforms other classification models in normal/abnormal ECG\nsignal detection by benchmarking real world and adversarial signals.",
          "link": "http://arxiv.org/abs/2107.07677",
          "publishedOn": "2021-07-19T00:49:06.794Z",
          "wordCount": 618,
          "title": "ECG-Adv-GAN: Detecting ECG Adversarial Examples with Conditional Generative Adversarial Networks. (arXiv:2107.07677v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07576",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Irbaz_M/0/1/0/all/0/1\">Mohammad Sabik Irbaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nasim_M/0/1/0/all/0/1\">MD Abdullah Al Nasim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferdous_R/0/1/0/all/0/1\">Refat E Ferdous</a>",
          "description": "During the COVID-19 pandemic, most of the human-to-human interactions have\nbeen stopped. To mitigate the spread of deadly coronavirus, many offices took\nthe initiative so that the employees can work from home. But, tracking the\nemployees and finding out if they are really performing what they were supposed\nto turn out to be a serious challenge for all the companies and organizations\nwho are facilitating \"Work From Home\". To deal with the challenge effectively,\nwe came up with a solution to track the employees with face recognition. We\nhave been testing this system experimentally for our office. To train the face\nrecognition module, we used FaceNet with KNN using the Labeled Faces in the\nWild (LFW) dataset and achieved 97.8% accuracy. We integrated the trained model\ninto our central system, where the employees log their time. In this paper, we\ndiscuss in brief the system we have been experimenting with and the pros and\ncons of the system.",
          "link": "http://arxiv.org/abs/2107.07576",
          "publishedOn": "2021-07-19T00:49:06.772Z",
          "wordCount": 666,
          "title": "Real-Time Face Recognition System for Remote Employee Tracking. (arXiv:2107.07576v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07702",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Carmona_C/0/1/0/all/0/1\">Chris U. Carmona</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aubet_F/0/1/0/all/0/1\">Fran&#xe7;ois-Xavier Aubet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Flunkert_V/0/1/0/all/0/1\">Valentin Flunkert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gasthaus_J/0/1/0/all/0/1\">Jan Gasthaus</a>",
          "description": "We introduce Neural Contextual Anomaly Detection (NCAD), a framework for\nanomaly detection on time series that scales seamlessly from the unsupervised\nto supervised setting, and is applicable to both univariate and multivariate\ntime series. This is achieved by effectively combining recent developments in\nrepresentation learning for multivariate time series, with techniques for deep\nanomaly detection originally developed for computer vision that we tailor to\nthe time series setting. Our window-based approach facilitates learning the\nboundary between normal and anomalous classes by injecting generic synthetic\nanomalies into the available data. Moreover, our method can effectively take\nadvantage of all the available information, be it as domain knowledge, or as\ntraining labels in the semi-supervised setting. We demonstrate empirically on\nstandard benchmark datasets that our approach obtains a state-of-the-art\nperformance in these settings.",
          "link": "http://arxiv.org/abs/2107.07702",
          "publishedOn": "2021-07-19T00:49:06.765Z",
          "wordCount": 570,
          "title": "Neural Contextual Anomaly Detection for Time Series. (arXiv:2107.07702v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07642",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Lohani_S/0/1/0/all/0/1\">Sanjaya Lohani</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Lukens_J/0/1/0/all/0/1\">Joseph M. Lukens</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Jones_D/0/1/0/all/0/1\">Daniel E. Jones</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Searles_T/0/1/0/all/0/1\">Thomas A. Searles</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Glasser_R/0/1/0/all/0/1\">Ryan T. Glasser</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Kirby_B/0/1/0/all/0/1\">Brian T. Kirby</a>",
          "description": "We consider the properties of a specific distribution of mixed quantum states\nof arbitrary dimension that can be biased towards a specific mean purity. In\nparticular, we analyze mixtures of Haar-random pure states with\nDirichlet-distributed coefficients. We analytically derive the concentration\nparameters required to match the mean purity of the Bures and Hilbert--Schmidt\ndistributions in any dimension. Numerical simulations suggest that this value\nrecovers the Hilbert--Schmidt distribution exactly, offering an alternative and\nintuitive physical interpretation for ensembles of Hilbert--Schmidt-distributed\nrandom quantum states. We then demonstrate how substituting these\nDirichlet-weighted Haar mixtures in place of the Bures and Hilbert--Schmidt\ndistributions results in measurable performance advantages in\nmachine-learning-based quantum state tomography systems and Bayesian quantum\nstate reconstruction. Finally, we experimentally characterize the distribution\nof quantum states generated by both a cloud-accessed IBM quantum computer and\nan in-house source of polarization-entangled photons. In each case, our method\ncan more closely match the underlying distribution than either Bures or\nHilbert--Schmidt distributed states for various experimental conditions.",
          "link": "http://arxiv.org/abs/2107.07642",
          "publishedOn": "2021-07-19T00:49:06.759Z",
          "wordCount": 611,
          "title": "Improving application performance with biased distributions of quantum states. (arXiv:2107.07642v1 [quant-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07691",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Magee_L/0/1/0/all/0/1\">Liam Magee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghahremanlou_L/0/1/0/all/0/1\">Lida Ghahremanlou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soldatic_K/0/1/0/all/0/1\">Karen Soldatic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Robertson_S/0/1/0/all/0/1\">Shanthi Robertson</a>",
          "description": "To examine whether intersectional bias can be observed in language\ngeneration, we examine \\emph{GPT-2} and \\emph{GPT-NEO} models, ranging in size\nfrom 124 million to ~2.7 billion parameters. We conduct an experiment combining\nup to three social categories - gender, religion and disability - into\nunconditional or zero-shot prompts used to generate sentences that are then\nanalysed for sentiment. Our results confirm earlier tests conducted with\nauto-regressive causal models, including the \\emph{GPT} family of models. We\nalso illustrate why bias may be resistant to techniques that target single\ncategories (e.g. gender, religion and race), as it can also manifest, in often\nsubtle ways, in texts prompted by concatenated social categories. To address\nthese difficulties, we suggest technical and community-based approaches need to\ncombine to acknowledge and address complex and intersectional language model\nbias.",
          "link": "http://arxiv.org/abs/2107.07691",
          "publishedOn": "2021-07-19T00:49:06.746Z",
          "wordCount": 568,
          "title": "Intersectional Bias in Causal Language Models. (arXiv:2107.07691v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07603",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Scurll_J/0/1/0/all/0/1\">Joshua M. Scurll</a>",
          "description": "Clustering and visualizing high-dimensional (HD) data are important tasks in\na variety of fields. For example, in bioinformatics, they are crucial for\nanalyses of single-cell data such as mass cytometry (CyTOF) data. Some of the\nmost effective algorithms for clustering HD data are based on representing the\ndata by nodes in a graph, with edges connecting neighbouring nodes according to\nsome measure of similarity or distance. However, users of graph-based\nalgorithms are typically faced with the critical but challenging task of\nchoosing the value of an input parameter that sets the size of neighbourhoods\nin the graph, e.g. the number of nearest neighbours to which to connect each\nnode or a threshold distance for connecting nodes. The burden on the user could\nbe alleviated by a measure of inter-node similarity that can have value 0 for\ndissimilar nodes without requiring any user-defined parameters or thresholds.\nThis would determine the neighbourhoods automatically while still yielding a\nsparse graph. To this end, I propose a new method called ASTRICS to measure\nsimilarity between clusters of HD data points based on local dimensionality\nreduction and triangulation of critical alpha shapes. I show that my ASTRICS\nsimilarity measure can facilitate both clustering and visualization of HD data\nby using it in Stage 2 of a three-stage pipeline: Stage 1 = perform an initial\nclustering of the data by any method; Stage 2 = let graph nodes represent\ninitial clusters instead of individual data points and use ASTRICS to\nautomatically define edges between nodes; Stage 3 = use the graph for further\nclustering and visualization. This trades the critical task of choosing a graph\nneighbourhood size for the easier task of essentially choosing a resolution at\nwhich to view the data. The graph and consequently downstream clustering and\nvisualization are then automatically adapted to the chosen resolution.",
          "link": "http://arxiv.org/abs/2107.07603",
          "publishedOn": "2021-07-19T00:49:06.719Z",
          "wordCount": 764,
          "title": "Measuring inter-cluster similarities with Alpha Shape TRIangulation in loCal Subspaces (ASTRICS) facilitates visualization and clustering of high-dimensional data. (arXiv:2107.07603v1 [q-bio.QM])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07675",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Johnson_D/0/1/0/all/0/1\">Daniel D. Johnson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Austin_J/0/1/0/all/0/1\">Jacob Austin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berg_R/0/1/0/all/0/1\">Rianne van den Berg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tarlow_D/0/1/0/all/0/1\">Daniel Tarlow</a>",
          "description": "Denoising diffusion probabilistic models (DDPMs) have shown impressive\nresults on sequence generation by iteratively corrupting each example and then\nlearning to map corrupted versions back to the original. However, previous work\nhas largely focused on in-place corruption, adding noise to each pixel or token\nindividually while keeping their locations the same. In this work, we consider\na broader class of corruption processes and denoising models over sequence data\nthat can insert and delete elements, while still being efficient to train and\nsample from. We demonstrate that these models outperform standard in-place\nmodels on an arithmetic sequence task, and that when trained on the text8\ndataset they can be used to fix spelling errors without any fine-tuning.",
          "link": "http://arxiv.org/abs/2107.07675",
          "publishedOn": "2021-07-19T00:49:06.696Z",
          "wordCount": 572,
          "title": "Beyond In-Place Corruption: Insertion and Deletion In Denoising Probabilistic Models. (arXiv:2107.07675v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07682",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yukun Jiang</a>",
          "description": "Active learning is a state-of-art machine learning approach to deal with an\nabundance of unlabeled data. In the field of Natural Language Processing,\ntypically it is costly and time-consuming to have all the data annotated. This\ninefficiency inspires out our application of active learning in text\nclassification. Traditional unsupervised k-means clustering is first modified\ninto a semi-supervised version in this research. Then, a novel attempt is\napplied to further extend the algorithm into active learning scenario with\nPenalized Min-Max-selection, so as to make limited queries that yield more\nstable initial centroids. This method utilizes both the interactive query\nresults from users and the underlying distance representation. After tested on\na Chinese news dataset, it shows a consistent increase in accuracy while\nlowering the cost in training.",
          "link": "http://arxiv.org/abs/2107.07682",
          "publishedOn": "2021-07-19T00:49:06.689Z",
          "wordCount": 600,
          "title": "The Application of Active Query K-Means in Text Classification. (arXiv:2107.07682v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07618",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alarab_I/0/1/0/all/0/1\">Ismail Alarab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prakoonwit_S/0/1/0/all/0/1\">Simant Prakoonwit</a>",
          "description": "We propose a novel method to capture data points near decision boundary in\nneural network that are often referred to a specific type of uncertainty. In\nour approach, we sought to perform uncertainty estimation based on the idea of\nadversarial attack method. In this paper, uncertainty estimates are derived\nfrom the input perturbations, unlike previous studies that provide\nperturbations on the model's parameters as in Bayesian approach. We are able to\nproduce uncertainty with couple of perturbations on the inputs. Interestingly,\nwe apply the proposed method to datasets derived from blockchain. We compare\nthe performance of model uncertainty with the most recent uncertainty methods.\nWe show that the proposed method has revealed a significant outperformance over\nother methods and provided less risk to capture model uncertainty in machine\nlearning.",
          "link": "http://arxiv.org/abs/2107.07618",
          "publishedOn": "2021-07-19T00:49:06.684Z",
          "wordCount": 576,
          "title": "Adversarial Attack for Uncertainty Estimation: Identifying Critical Regions in Neural Networks. (arXiv:2107.07618v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07623",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ganassali_L/0/1/0/all/0/1\">Luca Ganassali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Massoulie_L/0/1/0/all/0/1\">Laurent Massouli&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lelarge_M/0/1/0/all/0/1\">Marc Lelarge</a>",
          "description": "We consider alignment of sparse graphs, which consists in finding a mapping\nbetween the nodes of two graphs which preserves most of the edges. Our approach\nis to compare local structures in the two graphs, matching two nodes if their\nneighborhoods are 'close enough': for correlated Erd\\H{o}s-R\\'enyi random\ngraphs, this problem can be locally rephrased in terms of testing whether a\npair of branching trees is drawn from either a product distribution, or a\ncorrelated distribution. We design an optimal test for this problem which gives\nrise to a message-passing algorithm for graph alignment, which provably returns\nin polynomial time a positive fraction of correctly matched vertices, and a\nvanishing fraction of mismatches. With an average degree $\\lambda = O(1)$ in\nthe graphs, and a correlation parameter $s \\in [0,1]$, this result holds with\n$\\lambda s$ large enough, and $1-s$ small enough, completing the recent\nstate-of-the-art diagram. Tighter conditions for determining whether partial\ngraph alignment (or correlation detection in trees) is feasible in polynomial\ntime are given in terms of Kullback-Leibler divergences.",
          "link": "http://arxiv.org/abs/2107.07623",
          "publishedOn": "2021-07-19T00:49:06.669Z",
          "wordCount": 629,
          "title": "Correlation detection in trees for partial graph alignment. (arXiv:2107.07623v1 [cs.DS])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07572",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kopanicakova_A/0/1/0/all/0/1\">Alena Kopani&#x10d;&#xe1;kov&#xe1;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krause_R/0/1/0/all/0/1\">Rolf Krause</a>",
          "description": "We propose a globally convergent multilevel training method for deep residual\nnetworks (ResNets). The devised method can be seen as a novel variant of the\nrecursive multilevel trust-region (RMTR) method, which operates in hybrid\n(stochastic-deterministic) settings by adaptively adjusting mini-batch sizes\nduring the training. The multilevel hierarchy and the transfer operators are\nconstructed by exploiting a dynamical system's viewpoint, which interprets\nforward propagation through the ResNet as a forward Euler discretization of an\ninitial value problem. In contrast to traditional training approaches, our\nnovel RMTR method also incorporates curvature information on all levels of the\nmultilevel hierarchy by means of the limited-memory SR1 method. The overall\nperformance and the convergence properties of our multilevel training method\nare numerically investigated using examples from the field of classification\nand regression.",
          "link": "http://arxiv.org/abs/2107.07572",
          "publishedOn": "2021-07-19T00:49:06.659Z",
          "wordCount": 564,
          "title": "Globally Convergent Multilevel Training of Deep Residual Networks. (arXiv:2107.07572v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07564",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mitros_J/0/1/0/all/0/1\">John Mitros</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Namee_B/0/1/0/all/0/1\">Brian Mac Namee</a>",
          "description": "Neural networks are often utilised in critical domain applications\n(e.g.~self-driving cars, financial markets, and aerospace engineering), even\nthough they exhibit overconfident predictions for ambiguous inputs. This\ndeficiency demonstrates a fundamental flaw indicating that neural networks\noften overfit on spurious correlations. To address this problem in this work we\npresent two novel objectives that improve the ability of a network to detect\nout-of-distribution samples and therefore avoid overconfident predictions for\nambiguous inputs. We empirically demonstrate that our methods outperform the\nbaseline and perform better than the majority of existing approaches, while\nperforming competitively those that they don't outperform. Additionally, we\nempirically demonstrate the robustness of our approach against common\ncorruptions and demonstrate the importance of regularisation and auxiliary\ninformation in out-of-distribution detection.",
          "link": "http://arxiv.org/abs/2107.07564",
          "publishedOn": "2021-07-19T00:49:06.653Z",
          "wordCount": 554,
          "title": "On the Importance of Regularisation & Auxiliary Information in OOD Detection. (arXiv:2107.07564v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07579",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Rui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bohdal_O/0/1/0/all/0/1\">Ondrej Bohdal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_R/0/1/0/all/0/1\">Rajesh Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyeji Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Da Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lane_N/0/1/0/all/0/1\">Nicholas Lane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hospedales_T/0/1/0/all/0/1\">Timothy Hospedales</a>",
          "description": "Meta-learning provides a popular and effective family of methods for\ndata-efficient learning of new tasks. However, several important issues in\nmeta-learning have proven hard to study thus far. For example, performance\ndegrades in real-world settings where meta-learners must learn from a wide and\npotentially multi-modal distribution of training tasks; and when distribution\nshift exists between meta-train and meta-test task distributions. These issues\nare typically hard to study since the shape of task distributions, and shift\nbetween them are not straightforward to measure or control in standard\nbenchmarks. We propose the channel coding problem as a benchmark for\nmeta-learning. Channel coding is an important practical application where task\ndistributions naturally arise, and fast adaptation to new tasks is practically\nvaluable. We use this benchmark to study several aspects of meta-learning,\nincluding the impact of task distribution breadth and shift, which can be\ncontrolled in the coding problem. Going forward, this benchmark provides a tool\nfor the community to study the capabilities and limitations of meta-learning,\nand to drive research on practically robust and effective meta-learners.",
          "link": "http://arxiv.org/abs/2107.07579",
          "publishedOn": "2021-07-19T00:49:06.648Z",
          "wordCount": 616,
          "title": "A Channel Coding Benchmark for Meta-Learning. (arXiv:2107.07579v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07647",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Colbert_I/0/1/0/all/0/1\">Ian Colbert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kreutz_Delgado_K/0/1/0/all/0/1\">Ken Kreutz-Delgado</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1\">Srinjoy Das</a>",
          "description": "A novel energy-efficient edge computing paradigm is proposed for real-time\ndeep learning-based image upsampling applications. State-of-the-art deep\nlearning solutions for image upsampling are currently trained using either\nresize or sub-pixel convolution to learn kernels that generate high fidelity\nimages with minimal artifacts. However, performing inference with these learned\nconvolution kernels requires memory-intensive feature map transformations that\ndominate time and energy costs in real-time applications. To alleviate this\npressure on memory bandwidth, we confine the use of resize or sub-pixel\nconvolution to training in the cloud by transforming learned convolution\nkernels to deconvolution kernels before deploying them for inference as a\nfunctionally equivalent deconvolution. These kernel transformations, intended\nas a one-time cost when shifting from training to inference, enable a systems\ndesigner to use each algorithm in their optimal context by preserving the image\nfidelity learned when training in the cloud while minimizing data transfer\npenalties during inference at the edge. We also explore existing variants of\ndeconvolution inference algorithms and introduce a novel variant for\nconsideration. We analyze and compare the inference properties of\nconvolution-based upsampling algorithms using a quantitative model of incurred\ntime and energy costs and show that using deconvolution for inference at the\nedge improves both system latency and energy efficiency when compared to their\nsub-pixel or resize convolution counterparts.",
          "link": "http://arxiv.org/abs/2107.07647",
          "publishedOn": "2021-07-19T00:49:06.633Z",
          "wordCount": 664,
          "title": "An Energy-Efficient Edge Computing Paradigm for Convolution-based Image Upsampling. (arXiv:2107.07647v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2107.07558",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cai_Z/0/1/0/all/0/1\">Zhicheng Cai</a>",
          "description": "Gradient descent algorithm is the most utilized method when optimizing\nmachine learning issues. However, there exists many local minimums and saddle\npoints in the loss function, especially for high dimensional non-convex\noptimization problems like deep learning. Gradient descent may make loss\nfunction trapped in these local intervals which impedes further optimization,\nresulting in poor generalization ability. This paper proposes the SA-GD\nalgorithm which introduces the thought of simulated annealing algorithm to\ngradient descent. SA-GD method offers model the ability of mounting hills in\nprobability, tending to enable the model to jump out of these local areas and\nconverge to a optimal state finally. We took CNN models as an example and\ntested the basic CNN models on various benchmark datasets. Compared to the\nbaseline models with traditional gradient descent algorithm, models with SA-GD\nalgorithm possess better generalization ability without sacrificing the\nefficiency and stability of model convergence. In addition, SA-GD can be\nutilized as an effective ensemble learning approach which improves the final\nperformance significantly.",
          "link": "http://arxiv.org/abs/2107.07558",
          "publishedOn": "2021-07-19T00:49:06.611Z",
          "wordCount": 596,
          "title": "SA-GD: Improved Gradient Descent Learning Strategy with Simulated Annealing. (arXiv:2107.07558v1 [cs.LG])"
        }
      ]
    }
  ],
  "cliVersion": "1.11.0"
}